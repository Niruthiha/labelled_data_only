{
  "repository": "kyegomez/swarms",
  "repository_info": {
    "repo": "kyegomez/swarms",
    "stars": 4941,
    "language": "Python",
    "description": "The Enterprise-Grade Production-Ready Multi-Agent Orchestration Framework. Website: https://swarms.ai",
    "url": "https://github.com/kyegomez/swarms",
    "topics": [
      "agents",
      "ai",
      "artificial-intelligence",
      "attention-mechanism",
      "chatgpt",
      "gpt4",
      "gpt4all",
      "huggingface",
      "langchain",
      "langchain-python",
      "machine-learning",
      "multi-modal-imaging",
      "multi-modality",
      "multimodal",
      "prompt-engineering",
      "prompt-toolkit",
      "prompting",
      "swarms",
      "transformer-models",
      "tree-of-thoughts"
    ],
    "created_at": "2023-05-11T01:09:00Z",
    "updated_at": "2025-06-21T16:14:28Z",
    "search_query": "ai agent language:python stars:>3 -framework",
    "total_issues_estimate": 50,
    "labeled_issues_estimate": 35,
    "labeling_rate": 71.4,
    "sample_labeled": 10,
    "sample_total": 14,
    "has_issues": true,
    "repo_id": 639195966,
    "default_branch": "master",
    "size": 109212
  },
  "extraction_date": "2025-06-22T00:40:00.911843",
  "extraction_type": "LABELED_ISSUES_ONLY",
  "total_labeled_issues": 258,
  "issues": [
    {
      "issue_number": 912,
      "title": "[FEAT][Feed multiple images into the agent]",
      "body": "- Add multiple images into the agent.run(imgs = [url_1, etc]) \n- Add the logic into litellm_wrapper.py",
      "state": "open",
      "author": "kyegomez",
      "author_type": "User",
      "created_at": "2025-06-21T05:54:07Z",
      "updated_at": "2025-06-21T09:54:38Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/912/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/912",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/912",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:10.298923",
      "comments": [
        {
          "author": "Wxysnx",
          "body": "I just fixed it    with https://github.com/kyegomez/swarms/pull/916",
          "created_at": "2025-06-21T07:38:10Z"
        }
      ]
    },
    {
      "issue_number": 907,
      "title": "[BUG]  [VIDEO][Create InteractiveGroupChat Video]",
      "body": "- Create an interactive groupchat video ",
      "state": "open",
      "author": "kyegomez",
      "author_type": "User",
      "created_at": "2025-06-20T18:22:21Z",
      "updated_at": "2025-06-20T18:22:21Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/907/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/907",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/907",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:10.494748",
      "comments": []
    },
    {
      "issue_number": 897,
      "title": "[BUG] [Fix Multi-Modal + Function Calling Agents]",
      "body": "- Fix multi-modal function calling agents\n- Issue is in the agent.py and litellm_wrapper.py files\n\n```python\nimport json\nfrom swarms.structs import Agent\nfrom swarms.prompts.logistics import (\n    Quality_Control_Agent_Prompt,\n)\nfrom swarms import BaseTool\n\n\n# Image for analysis\nfactory_image = \"image.jpg\"\n\n\ndef security_analysis(danger_level: str = None) -> str:\n    \"\"\"\n    Analyzes the security danger level and returns an appropriate response.\n\n    Args:\n        danger_level (str, optional): The level of danger to analyze.\n            Can be \"low\", \"medium\", \"high\", or None. Defaults to None.\n\n    Returns:\n        str: A string describing the danger level assessment.\n            - \"No danger level provided\" if danger_level is None\n            - \"No danger\" if danger_level is \"low\"\n            - \"Medium danger\" if danger_level is \"medium\"\n            - \"High danger\" if danger_level is \"high\"\n            - \"Unknown danger level\" for any other value\n    \"\"\"\n    if danger_level is None:\n        return \"No danger level provided\"\n\n    if danger_level == \"low\":\n        return \"No danger\"\n\n    if danger_level == \"medium\":\n        return \"Medium danger\"\n\n    if danger_level == \"high\":\n        return \"High danger\"\n\n    return \"Unknown danger level\"\n\n\n# schema = BaseTool().function_to_dict(security_analysis)\n# print(json.dumps(schema, indent=4))\n\n# Quality control agent\nquality_control_agent = Agent(\n    agent_name=\"Quality Control Agent\",\n    agent_description=\"A quality control agent that analyzes images and provides a detailed report on the quality of the product in the image.\",\n    # model_name=\"anthropic/claude-3-opus-20240229\",\n    model_name=\"gpt-4o-mini\",\n    system_prompt=Quality_Control_Agent_Prompt,\n    multi_modal=True,\n    max_loops=1,\n    output_type=\"str-all-except-first\",\n    # tools_list_dictionary=[schema],\n    tools=[security_analysis],\n)\n\n\nresponse = quality_control_agent.run(\n    task=\"what is in the image?\",\n    # img=factory_image,\n)\n\nprint(response)\n\n```\n\nOutputs\n```txt\nmax_workers: 9\n2025-06-17 22:53:54 | INFO     | swarms.structs.agent:handle_sop_ops:2442 - SOP Uploaded into the memory\n╭───────────────────────────────────── Agent Name Quality Control Agent [Max Loops: 1 ] ──────────────────────────────────────╮\n│ Quality Control Agent: None                                                                                                 │\n╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n2025-06-17 22:54:01 | ERROR    | swarms.structs.agent:_run:1103 - Attempt 1: Error generating response: Invalid JSON in API response: Expecting value: line 1 column 1 (char 0)\n╭───────────────────────────────────── Agent Name Quality Control Agent [Max Loops: 1 ] ──────────────────────────────────────╮\n│ Quality Control Agent: None                                                                                                 │\n╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n2025-06-17 22:54:08 | ERROR    | swarms.structs.agent:_run:1103 - Attempt 2: Error generating response: Invalid JSON in API response: Expecting value: line 1 column 1 (char 0)\nTools available: [0]:\n  type: function\n  function:\n    name: security_analysis\n    description: \n    Analyzes the security danger level and returns an appropriate response.\n\n    Args:\n        danger_level (str, optional): The level of danger to analyze.\n            Can be \"low\", \"medium\", \"high\", or None. Defaults to None.\n\n    Returns:\n        str: A string describing the danger level assessment.\n            - \"No danger level provided\" if danger_level is None\n            - \"No danger\" if danger_level is \"low\"\n            - \"Medium danger\" if danger_level is \"medium\"\n            - \"High danger\" if danger_level is \"high\"\n            - \"Unknown danger level\" for any other value\n    \n    parameters:\n      type: object\n      properties:\n        danger_level:\n          type: string\n          default: None\n          description: danger_level\n      required:\n        [] (empty list)\nwhat is in the image?\nNone\nNone\nNone\n╭───────────────────────────────────── Agent Name Quality Control Agent [Max Loops: 1 ] ──────────────────────────────────────╮\n│ Quality Control Agent: None                                                                                                 │\n╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n2025-06-17 22:54:13 | ERROR    | swarms.structs.agent:_run:1103 - Attempt 3: Error generating response: Invalid JSON in API response: Expecting value: line 1 column 1 (char 0)\n2025-06-17 22:54:13 | ERROR    | swarms.structs.agent:_run:1116 - Failed to generate a valid response after retry attempts.\n\n```",
      "state": "open",
      "author": "kyegomez",
      "author_type": "User",
      "created_at": "2025-06-17T20:18:31Z",
      "updated_at": "2025-06-20T17:35:07Z",
      "closed_at": null,
      "labels": [
        "bug",
        "help wanted",
        "good first issue",
        "[BUG]"
      ],
      "label_count": 4,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/897/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/897",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/897",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:10.494772",
      "comments": [
        {
          "author": "harshalmore31",
          "body": "Fixed #904 ",
          "created_at": "2025-06-19T05:10:51Z"
        },
        {
          "author": "Wxysnx",
          "body": "![Image](https://github.com/user-attachments/assets/54f78ec5-fb9e-4512-9ff0-055c5a017e43)\n\nIf we just want to fix the current bug, we don’t need to change a lot of code. We just need to replace “response = self.parse_llm_output(response)” with the part in the red box in the screenshot.\n\nI've reprodu",
          "created_at": "2025-06-20T06:22:12Z"
        },
        {
          "author": "harshalmore31",
          "body": "Hi @Wxysnx , thank you for your detailed analysis and for proposing a solution to address the issue with multi-modal agent execution. I’ve reviewed your changes and appreciate the clarity in identifying the root cause and the potential risks stemming from the current function call structure in agent",
          "created_at": "2025-06-20T13:49:37Z"
        },
        {
          "author": "Wxysnx",
          "body": "Hi,  @harshalmore31  \nThank you very much for your reply! I agree with you.\nAt the same time, I think that the fact that LLM's feedback is empty when we call multimodal LLM without passing in image data as parameters is not a bug. This is a normal phenomenon.\nThe real bug lies in the previous error ",
          "created_at": "2025-06-20T15:38:53Z"
        },
        {
          "author": "harshalmore31",
          "body": "Hi @Wxysnx ,\nThank you for your insightful reply! Yes, that makes perfect sense, the issue initially misled me into thinking it was a JSON parsing problem, but after tracing it back, I find out just that the problem is in error handling !\n\nI really appreciate your perspective, and I’m glad we’re on ",
          "created_at": "2025-06-20T17:35:07Z"
        }
      ]
    },
    {
      "issue_number": 892,
      "title": "[IMPRV][Implement AgentRAGHandler]",
      "body": "- Implement AgentRAGHandler in the agent.py\n- https://github.com/kyegomez/swarms/blob/master/swarms/structs/agent_rag_handler.py",
      "state": "closed",
      "author": "kyegomez",
      "author_type": "User",
      "created_at": "2025-06-16T17:28:06Z",
      "updated_at": "2025-06-17T17:18:29Z",
      "closed_at": "2025-06-17T17:18:29Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/892/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/892",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/892",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:10.732515",
      "comments": []
    },
    {
      "issue_number": 842,
      "title": "[BUG] Azure OpenAI for reasoning models.",
      "body": "**Describe the bug**\nWhen trying to leverage o3, o4-mini, claude thinking, etc - the system uses the older versions of langchain which break with o3 & o4-mini.  \n* Specifically tested with AzureOpenAI instance\n\n**To Reproduce**\nSteps to reproduce the behavior:\n- leverage Azure OpenAI with o4-mini or o3\n- integrate with anything (swarmrouter, hhcs, etc)\n- run any kind of swarm\n\n**Expected behavior**\nshould work lol\n\n**Screenshots**\nwill add later when time available \n\n**Additional context**\nThis is an extremely high priority for us and our clients. If this functions, we will shift to an enterprise plan",
      "state": "closed",
      "author": "adityamcodes",
      "author_type": "User",
      "created_at": "2025-05-12T17:51:08Z",
      "updated_at": "2025-06-17T12:28:28Z",
      "closed_at": "2025-05-28T08:11:09Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 12,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/842/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/842",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/842",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:10.732540",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@adityamcodes you can use this with litellm and the Agent class `Agent(model_name=\"azure/o1-pro\") etc `\n\nCan read more here:\n\nhttps://docs.litellm.ai/docs/providers/azure#azure-batches-api\n\nalso need envs like this\n\nimport os\nos.environ[\"AZURE_API_KEY\"] = \"\" # \"my-azure-api-key\"\nos.environ[\"AZURE_AP",
          "created_at": "2025-05-12T19:46:46Z"
        },
        {
          "author": "kyegomez",
          "body": "Here's some new docs we added\n\nhttps://docs.swarms.world/en/latest/swarms/models/agent_and_models/",
          "created_at": "2025-05-12T22:04:35Z"
        },
        {
          "author": "adityamcodes",
          "body": "last time i tried it broke bc of default params setup in litellm (i think), but its been a few weeks so let me try it",
          "created_at": "2025-05-14T01:08:29Z"
        },
        {
          "author": "kyegomez",
          "body": "@adityamcodes hmmmm let me know if it works",
          "created_at": "2025-05-17T05:30:08Z"
        },
        {
          "author": "adityamcodes",
          "body": "yeah it didnt end up working, was very finicky",
          "created_at": "2025-06-04T04:12:04Z"
        }
      ]
    },
    {
      "issue_number": 894,
      "title": "[IMPRV][Update the swarms api docs with the latest changes",
      "body": "- update the api docs with the latest changes",
      "state": "open",
      "author": "kyegomez",
      "author_type": "User",
      "created_at": "2025-06-16T17:30:48Z",
      "updated_at": "2025-06-16T17:30:48Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/894/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/894",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/894",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:10.937123",
      "comments": []
    },
    {
      "issue_number": 893,
      "title": "[IMPRV][Add more Examples from swarms github]",
      "body": "- Add more examples about templates from the swarms organization github\n- add in docs/examples \n- Add file path in mkdocs",
      "state": "open",
      "author": "kyegomez",
      "author_type": "User",
      "created_at": "2025-06-16T17:29:12Z",
      "updated_at": "2025-06-16T17:29:12Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/893/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/893",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/893",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:10.937145",
      "comments": []
    },
    {
      "issue_number": 879,
      "title": "[BUG] [MCP with Agent.run() and MCP asyncio call loop error",
      "body": "\n{'status': 'ok'}\n{'detail': '500: An unexpected error occurred: Failed to execute MCP tools sync: This event loop is already running'}\n\n\n## Problematic code is here\n- problematic code is here: https://github.com/kyegomez/swarms/blob/master/swarms/tools/mcp_client_call.py\n\n\n```python\nimport os\nimport requests\nfrom dotenv import load_dotenv\nimport json\nfrom swarms.utils.formatter import formatter\n\nload_dotenv()\n\nAPI_KEY = os.getenv(\"SWARMS_API_KEY\")\nBASE_URL = \"https://swarms-api-285321057562.us-east1.run.app\"\n# BASE_URL = \"http://localhost:8080\"\n\nheaders = {\"x-api-key\": API_KEY, \"Content-Type\": \"application/json\"}\n\n\ndef run_health_check():\n    \"\"\"Check if the API is healthy\"\"\"\n    response = requests.get(f\"{BASE_URL}/health\", headers=headers)\n    return response.json()\n\n\ndef run_single_agent():\n    \"\"\"Run a single agent with the new AgentCompletion format\"\"\"\n    payload = {\n        \"agent_config\": {\n            \"agent_name\": \"Research Analyst\",\n            \"description\": \"An expert in analyzing and synthesizing research data\",\n            \"system_prompt\": (\n                \"You are a Research Analyst with expertise in data analysis and synthesis. \"\n                \"Your role is to analyze provided information, identify key insights, \"\n                \"and present findings in a clear, structured format. \"\n                \"Focus on accuracy, clarity, and actionable recommendations.\"\n            ),\n            \"model_name\": \"claude-3-5-sonnet-20240620\",\n            \"role\": \"worker\",\n            \"max_loops\": 1,\n            \"max_tokens\": 8192,\n            \"temperature\": 1,\n            \"auto_generate_prompt\": False,\n            \"tools_list_dictionary\": None,\n            \"mcp_url\": \"http://localhost:11434/sse\",\n        },\n        \"task\": \"What are the best ways to find samples of diabetes from blood samples?\",\n        # \"history\": [\n        #     {\n        #         \"role\": \"user\",\n        #         \"content\": \"What are the best ways to find samples of diabetes from blood samples?\",\n        #     }\n        # ],\n    }\n\n    response = requests.post(\n        f\"{BASE_URL}/v1/agent/completions\", headers=headers, json=payload\n    )\n    return response.json()\n\n\nif __name__ == \"__main__\":\n    # Check API health\n    health = run_health_check()\n    print(health)\n\n    # Run single agent\n    agent_result = run_single_agent()\n    print(agent_result)\n```\n",
      "state": "open",
      "author": "kyegomez",
      "author_type": "User",
      "created_at": "2025-06-11T17:27:01Z",
      "updated_at": "2025-06-16T17:22:08Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/879/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/879",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/879",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:10.937151",
      "comments": []
    },
    {
      "issue_number": 881,
      "title": "[FEAT][Add Multiple MCP Tool Execution]",
      "body": "- Add Multiple MCP execution to the agents by fetching a list of mcp urls\n- Then the agent outputs a function call\n- Then the function data is parsed, name is found on which server url, and then the tool is executed with the execute_mcp_call function. \n- then add to agent.md and agent_mcp.md docs\n- Create examples in the examples docs/examples folder",
      "state": "open",
      "author": "kyegomez",
      "author_type": "User",
      "created_at": "2025-06-12T08:09:09Z",
      "updated_at": "2025-06-12T08:09:09Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "FEAT",
        "structs"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/881/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/881",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/881",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:10.937162",
      "comments": []
    },
    {
      "issue_number": 880,
      "title": "[FEAT] [Integrate AgentRAGHandler]",
      "body": "- Signifcantly improve RAG through a flexible and fluid system\n- Integrate llama index or pinecone or chromadb and create examples and docs for this\n- Make it easy to change embedding models and more\n",
      "state": "open",
      "author": "kyegomez",
      "author_type": "User",
      "created_at": "2025-06-12T08:07:08Z",
      "updated_at": "2025-06-12T08:07:08Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "FEAT",
        "structs"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/880/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/880",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/880",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:10.937169",
      "comments": []
    },
    {
      "issue_number": 865,
      "title": "[BUG] [Fix DeepResearchSwarm]",
      "body": "- json parsing issue\n\n```python\nfrom swarms.structs.deep_research_swarm import DeepResearchSwarm\n\n\ndef main():\n    swarm = DeepResearchSwarm(\n        name=\"Deep Research Swarm\",\n        description=\"A swarm of agents that can perform deep research on a given topic\",\n    )\n\n    swarm.run(\"What are the latest news in the AI an crypto space\")\n\n\nmain()\n```\n",
      "state": "closed",
      "author": "kyegomez",
      "author_type": "User",
      "created_at": "2025-06-05T18:34:57Z",
      "updated_at": "2025-06-09T18:18:48Z",
      "closed_at": "2025-06-09T18:18:48Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/865/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/865",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/865",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:10.937183",
      "comments": []
    },
    {
      "issue_number": 677,
      "title": "[BUG] pytest from source",
      "body": "**Describe the bug**\r\nCurrent git source code, pytest output:\r\n```\r\n======================================= test session starts ========================================\r\nplatform linux -- Python 3.10.12, pytest-8.3.4, pluggy-1.5.0\r\nrootdir: /content/swarms\r\nconfigfile: pyproject.toml\r\nplugins: pylama-8.4.1, anyio-4.7.0, typeguard-4.4.1\r\ncollected 342 items / 10 errors                                                                    \r\n\r\n============================================== ERRORS ==============================================\r\n_________________________ ERROR collecting tests/structs/test_groupchat.py _________________________\r\nImportError while importing test module '/content/swarms/tests/structs/test_groupchat.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/lib/python3.10/importlib/__init__.py:126: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntests/structs/test_groupchat.py:4: in <module>\r\n    from swarm_models.anthropic import Anthropic\r\nE   ModuleNotFoundError: No module named 'swarm_models.anthropic'\r\n____________________ ERROR collecting tests/structs/test_recursive_workflow.py _____________________\r\nImportError while importing test module '/content/swarms/tests/structs/test_recursive_workflow.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/lib/python3.10/importlib/__init__.py:126: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntests/structs/test_recursive_workflow.py:6: in <module>\r\n    from swarms.structs import RecursiveWorkflow, Task\r\nE   ImportError: cannot import name 'RecursiveWorkflow' from 'swarms.structs' (/usr/local/lib/python3.10/dist-packages/swarms/structs/__init__.py)\r\n____________________ ERROR collecting tests/structs/test_sequential_workflow.py ____________________\r\nImportError while importing test module '/content/swarms/tests/structs/test_sequential_workflow.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/lib/python3.10/importlib/__init__.py:126: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntests/structs/test_sequential_workflow.py:9: in <module>\r\n    from swarms.structs.sequential_workflow import (\r\nE   ImportError: cannot import name 'Task' from 'swarms.structs.sequential_workflow' (/usr/local/lib/python3.10/dist-packages/swarms/structs/sequential_workflow.py)\r\n_______________________ ERROR collecting tests/structs/test_swarmnetwork.py ________________________\r\nImportError while importing test module '/content/swarms/tests/structs/test_swarmnetwork.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/lib/python3.10/importlib/__init__.py:126: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntests/structs/test_swarmnetwork.py:6: in <module>\r\n    from swarms.structs.swarm_net import SwarmNetwork\r\nE   ModuleNotFoundError: No module named 'swarms.structs.swarm_net'\r\n___________________________ ERROR collecting tests/structs/test_team.py ____________________________\r\nImportError while importing test module '/content/swarms/tests/structs/test_team.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/lib/python3.10/importlib/__init__.py:126: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntests/structs/test_team.py:6: in <module>\r\n    from swarms.structs.team import Team\r\nE   ModuleNotFoundError: No module named 'swarms.structs.team'\r\n________________________ ERROR collecting tests/structs/test_yaml_model.py _________________________\r\nImportError while importing test module '/content/swarms/tests/structs/test_yaml_model.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/lib/python3.10/importlib/__init__.py:126: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntests/structs/test_yaml_model.py:3: in <module>\r\n    from swarms import (\r\nE   ImportError: cannot import name 'create_yaml_schema_from_dict' from 'swarms' (/usr/local/lib/python3.10/dist-packages/swarms/__init__.py)\r\n______________________ ERROR collecting tests/telemetry/test_posthog_utils.py ______________________\r\nImportError while importing test module '/content/swarms/tests/telemetry/test_posthog_utils.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/lib/python3.10/importlib/__init__.py:126: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntests/telemetry/test_posthog_utils.py:5: in <module>\r\n    from swarms.telemetry.posthog_utils import (\r\nE   ModuleNotFoundError: No module named 'swarms.telemetry.posthog_utils'\r\n_________________________ ERROR collecting tests/tools/test_tools_base.py __________________________\r\nImportError while importing test module '/content/swarms/tests/tools/test_tools_base.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/lib/python3.10/importlib/__init__.py:126: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntests/tools/test_tools_base.py:6: in <module>\r\n    from swarms.tools.tool import (\r\nE   ModuleNotFoundError: No module named 'swarms.tools.tool'\r\n________________________ ERROR collecting tests/utils/test_check_device.py _________________________\r\nImportError while importing test module '/content/swarms/tests/utils/test_check_device.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/lib/python3.10/importlib/__init__.py:126: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntests/utils/test_check_device.py:5: in <module>\r\n    from swarms.utils import check_device\r\nE   ImportError: cannot import name 'check_device' from 'swarms.utils' (/usr/local/lib/python3.10/dist-packages/swarms/utils/__init__.py)\r\n______________________ ERROR collecting tests/utils/test_metrics_decorator.py ______________________\r\nImportError while importing test module '/content/swarms/tests/utils/test_metrics_decorator.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/lib/python3.10/importlib/__init__.py:126: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntests/utils/test_metrics_decorator.py:8: in <module>\r\n    from swarms.utils import metrics_decorator\r\nE   ImportError: cannot import name 'metrics_decorator' from 'swarms.utils' (/usr/local/lib/python3.10/dist-packages/swarms/utils/__init__.py)\r\n===================================== short test summary info ======================================\r\nERROR tests/structs/test_groupchat.py\r\nERROR tests/structs/test_recursive_workflow.py\r\nERROR tests/structs/test_sequential_workflow.py\r\nERROR tests/structs/test_swarmnetwork.py\r\nERROR tests/structs/test_team.py\r\nERROR tests/structs/test_yaml_model.py\r\nERROR tests/telemetry/test_posthog_utils.py\r\nERROR tests/tools/test_tools_base.py\r\nERROR tests/utils/test_check_device.py\r\nERROR tests/utils/test_metrics_decorator.py\r\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 10 errors during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!\r\n================================== 10 errors in 153.10s (0:02:33) ==================================\r\n```",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2024-12-12T19:08:31Z",
      "updated_at": "2025-06-01T02:41:24Z",
      "closed_at": "2025-06-01T02:41:24Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/677/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/677",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/677",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:10.937190",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@evelynmitchell we will move to a new test structure to enhance purpose",
          "created_at": "2025-05-18T22:01:57Z"
        }
      ]
    },
    {
      "issue_number": 858,
      "title": "[FIX] [ Implement Multi Parallel Function Calling for MCP Tool Execution",
      "body": "**Describe the bug**\nWe need to enable the llm to output multiple function calls and execute multiple mcp tools all at once\n\n**To Reproduce**\n```python\nfrom swarms import Agent\nfrom swarms.schemas.mcp_schemas import MCPConnection\n\n\nmcp_config = MCPConnection(\n    url=\"http://0.0.0.0:8000/sse\",\n    # headers={\"Authorization\": \"Bearer 1234567890\"},\n    timeout=5,\n)\n\n\nmcp_url = \"http://0.0.0.0:8000/sse\"\n\n# Initialize the agent\nagent = Agent(\n    agent_name=\"Financial-Analysis-Agent\",\n    agent_description=\"Personal finance advisor agent\",\n    # system_prompt=FINANCIAL_AGENT_SYS_PROMPT,\n    max_loops=1,\n    mcp_url=mcp_url,\n    # mcp_config=mcp_config,\n    output_type=\"all\",\n)\n\n# Create a markdown file with initial content\nout = agent.run(\n    \"Fetch the price for bitcoin on both functions get_htx_crypto_price and get_crypto_price\",\n)\n\nprint(out)\n\n```\n",
      "state": "open",
      "author": "kyegomez",
      "author_type": "User",
      "created_at": "2025-05-29T18:18:31Z",
      "updated_at": "2025-05-29T18:20:12Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/858/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/858",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/858",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:11.158534",
      "comments": []
    },
    {
      "issue_number": 771,
      "title": "[BUG] Ollama local models spamming non-\"response\" details.",
      "body": "\n\n**To Reproduce**\nSteps to reproduce the behavior:\n1. Go to 'https://github.com/kyegomez/swarms/blob/fb494267ebb4a0af95b3b0683a89f3fd4ca80320/examples/ollama_demo.py'\n2. Modify starting code (which doesn't originally work),  to:\n\nfrom dotenv import load_dotenv\nimport os\nimport sys\n\nload_dotenv()\n\nif not os.getenv(\"OPENAI_API_KEY\"):\n    sys.exit(\"Error: OPENAI_API_KEY not found in environment variables\")\n\nfrom swarms import Agent\n\nfrom swarm_models import OllamaModel\n\nmodel = OllamaModel(model_name=\"llama3.1:8b\")\n\n\nfrom datetime import datetime\n\nfrom swarms import Agent, AgentRearrange, create_file_in_folder\n\n\n3. Run model\n\n**Expected behavior**\nOutput with Response only, not other details. Expected identical output to OpenAI 4o / 4o-mini model output. \n\n**Screenshots**\n\nAgent Name: Chief Medical Officer \n Output: model='llama3.1:8b' created_at='2025-02-08T13:52:57.1776161Z' done=True done_reason='stop' total_duration=8675541900 load_duration=21295700 prompt_eval_count=261 prompt_eval_duration=305000000 eval_count=563 eval_duration=8347000000 response=\"**Initial Assessment ( Timestamp: 2025-02-09 00:52:48.499230)**\\n\\n* Patient Information: 45-year-old White Male\\n* Lab Results:\\n\\t+ eGFR (estimated Glomerular Filtration Rate): 59 mL/min/1.73m^2 (mildly reduced)\\n\\t+ Non-African American ethnicity (no specific lab values provided)\\n\\n**Initial ICD-10 Codes for Symptoms:**\\n\\n* R31.9: Other specified renal symptoms\\n* Z91.19: Other specified risk factors\\n\\nPreliminary Assessment:\\n\\nBased on the patient's age, sex, and mildly reduced eGFR, potential differential diagnoses may include chronic kidney disease (CKD), mild renal impairment, or early stages of diabetic nephropathy. However, without additional lab results, further investigation is necessary.\\n\\n**Differential Diagnoses:**\\n\\n1. **Chronic Kidney Disease (CKD) (N18.4)**\\n\\t* eGFR 60-89 mL/min/1.73m^2\\n\\t* Additional lab values to consider:\\n\\t\\t+ Serum creatinine\\n\\t\\t+ Urine protein-to-creatinine ratio (UPCR)\\n2. **Diabetic Nephropathy (E11.9)**\\n\\t* HbA1c levels, urine albumin-to-creatinine ratio (UACR), and eGFR can help support this diagnosis\\n3. **Mild Renal Impairment (R31.9)**\\n\\t* May be indicated by a mildly reduced eGFR (59 mL/min/1.73m^2)\\n4. **Other specified renal symptoms (R31.9)**\\n\\t* Could include conditions like hydronephrosis, pyelonephritis, or interstitial nephritis\\n\\n**Specialist Consultations Needed:**\\n\\n* Nephrologist for further evaluation and management of CKD\\n* Endocrinologist for assessment of diabetic nephropathy\\n* Urologist for investigation of potential urinary tract issues (e.g., hydronephrosis)\\n\\n**Recommended Next Steps:**\\n\\n1. Request additional lab results, including serum creatinine, HbA1c levels, urine protein-to-creatinine ratio (UPCR), and urine albumin-to-creatinine ratio (UACR).\\n2. Consult the nephrologist for further evaluation and management of CKD.\\n3. Schedule an appointment with the endocrinologist to assess diabetic nephropathy.\\n4. Consider referring the patient to a urologist for investigation of potential urinary tract issues.\\n\\nPlease let me know if you'd like to proceed with these recommendations or if you have any questions.\" context=[128006, 882, 128007, 271, 2374, 25, ............................... THIS CONTEXT GOES ON TO BE A 12MB file\n\n\nSeparate minor related issues:\nBug within the demo code. \nWhen setting the model to a local one, the Agent still requires OPENAI_API_KEY",
      "state": "closed",
      "author": "avetise",
      "author_type": "User",
      "created_at": "2025-02-08T14:04:27Z",
      "updated_at": "2025-05-18T17:38:38Z",
      "closed_at": "2025-05-17T05:27:23Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 10,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/771/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/771",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/771",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:11.158557",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2025-02-08T14:04:54Z"
        },
        {
          "author": "harshalmore31",
          "body": "@avetise I tried to reproduce this issue and tested twice, I can't find any problems, do you still have problems ??",
          "created_at": "2025-02-14T19:10:37Z"
        },
        {
          "author": "avetise",
          "body": "Have you changed the starting code to the above to get it working? Has there been an update to the ollama related examples?\n\n![Image](https://github.com/user-attachments/assets/41c639ab-901e-4c1c-8499-38c3a13602c5)\n\n![Image](https://github.com/user-attachments/assets/aac1effe-52fb-4796-832a-283e7328",
          "created_at": "2025-02-14T23:46:37Z"
        },
        {
          "author": "harshalmore31",
          "body": "Its running properly, try to update the swarms and try \n------\n```python\nfrom dotenv import load_dotenv\nimport os\nimport sys\n\nload_dotenv()\n\nif not os.getenv(\"OPENAI_API_KEY\"):\n    sys.exit(\"Error: OPENAI_API_KEY not found in environment variables\")\n\nfrom swarms import Agent\n\nfrom swarm_models impor",
          "created_at": "2025-02-17T18:40:11Z"
        },
        {
          "author": "kyegomez",
          "body": "@avetise @www @nictuku can confirm if this fixes the problem",
          "created_at": "2025-02-17T21:11:22Z"
        }
      ]
    },
    {
      "issue_number": 848,
      "title": "[Improvement] [Accelerate Agent Inference time]",
      "body": "Goal: accelerate the agent inference time by atleast 2x by optimizing the _run",
      "state": "open",
      "author": "kyegomez",
      "author_type": "User",
      "created_at": "2025-05-17T05:32:01Z",
      "updated_at": "2025-05-17T05:32:01Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/848/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/848",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/848",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:11.394867",
      "comments": []
    },
    {
      "issue_number": 810,
      "title": "[BUG/FEAT] All Swarms dont enable actual Agent instance passing",
      "body": "**Describe the bug**\nAll Swarms dont enable actual Agent instance passing instead of model name, this is not standard, and limits configurability.\nThis breaks a desire to leverage only one standardized agent setup across the whole system. \n\n**To Reproduce**\n\n**Expected behavior**\ncurrently\nrouter = SwarmRouter(model_name,*)\nIdeal: \nrouter = SwarmRouter(model_name or Agent, *)\n\n**Screenshots**\n\n\n**Additional context**\n\n",
      "state": "closed",
      "author": "adityamcodes",
      "author_type": "User",
      "created_at": "2025-04-06T18:45:16Z",
      "updated_at": "2025-05-14T03:19:39Z",
      "closed_at": "2025-05-07T20:49:50Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/810/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/810",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/810",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:13.483466",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@adityamcodes can you go deeper? what do you mean? You pass in the list of agents in the agents parameter",
          "created_at": "2025-04-14T15:10:57Z"
        },
        {
          "author": "adityamcodes",
          "body": "maybe i missed that, let me try that",
          "created_at": "2025-04-15T04:47:24Z"
        },
        {
          "author": "kyegomez",
          "body": "read the docs here:\n\nhttps://docs.swarms.world/en/latest/swarms/structs/swarm_router/",
          "created_at": "2025-04-27T17:43:21Z"
        },
        {
          "author": "adityamcodes",
          "body": "ah i think i was misunderstanding the router as having a model deciding routing, but it looks like one of the subtypes of it actually has a boss llm for routing. myb\n",
          "created_at": "2025-05-14T01:11:52Z"
        },
        {
          "author": "adityamcodes",
          "body": "@kyegomez \n\nlike for example MALT, \n\n```\nmajority_voting_agent = Agent(\n    agent_name=\"Majority-Voting-Agent\",\n    model_name=\"gpt-4o-mini\",\n    max_loops=1,\n    system_prompt=majority_voting_prompt,\n)\n```\n\nisnt configurable when using MALT class",
          "created_at": "2025-05-14T03:19:39Z"
        }
      ]
    },
    {
      "issue_number": 516,
      "title": "[BUG] [ Error querying long term memory: object of type 'int' has no len()]",
      "body": "```\r\n Error querying long term memory: object of type 'int' has no len()\r\n2024-06-25T08:40:20.596141-0700 Attempt 3: Error generating response: object of type 'int' has no len()\r\n2024-06-25T08:40:20.596253-0700 Failed to generate a valid response after retry attempts.\r\n```\r\n\r\n# Code\r\n```\r\nfrom swarms import Agent, OpenAIChat\r\nfrom playground.memory.chromadb_example import ChromaDB\r\n\r\n\r\nGEO_EXPERT_SYSTEM_PROMPT = \"\"\"\r\n\r\nYou are GeoExpert AI, a sophisticated agent specialized in the fields of geo-economic fragmentation and foreign direct investment (FDI). Your role is to analyze geo-economic documents, data, and trends, and provide comprehensive answers to questions in these areas. You are an expert in understanding the economic impact of geopolitical events, trade policies, regional economic agreements, and how these factors influence FDI flows and investment strategies. Your expertise also extends to analyzing market dynamics, regulatory environments, and the economic policies of different countries and regions.\r\n\r\nYour goals are:\r\n1. To provide clear, detailed, and accurate analyses of geo-economic documents and reports.\r\n2. To answer questions related to geo-economic fragmentation and FDI with expert-level insight.\r\n3. To offer strategic recommendations based on current geopolitical and economic trends.\r\n4. To identify and explain the implications of specific geo-economic events on global and regional investment landscapes.\r\n\r\nYou will achieve these goals by:\r\n1. Leveraging your extensive knowledge in geo-economic theory and practical applications.\r\n2. Utilizing advanced data analysis techniques to interpret complex economic data and trends.\r\n3. Staying updated with the latest developments in international trade, political economy, and investment flows.\r\n4. Communicating your findings and recommendations in a clear, concise, and professional manner.\r\n\r\nAlways prioritize accuracy, depth of analysis, and clarity in your responses. Use technical terms appropriately and provide context or explanations for complex concepts to ensure understanding. Cite relevant data, reports, and examples where necessary to support your analyses.\r\n\r\n---\r\n\r\nWith this prompt, GeoExpert AI will be equipped to effectively analyze geo-economic documents and provide insightful answers related to geo-economic fragmentation and FDI.\r\n\"\"\"\r\n\r\n\r\n\r\n# Initialize the agent\r\nagent = Agent(\r\n    agent_name=\"Geo Expert AI\",\r\n    system_prompt=GEO_EXPERT_SYSTEM_PROMPT,\r\n    agent_description=\"Generate a profit report for a company!\",\r\n    llm=OpenAIChat(),\r\n    max_loops=\"auto\",\r\n    autosave=True,\r\n    # dynamic_temperature_enabled=True,\r\n    dashboard=False,\r\n    verbose=True,\r\n    streaming_on=True,\r\n    # interactive=True, # Set to False to disable interactive mode\r\n    saved_state_path=\"accounting_agent.json\",\r\n    # tools=[calculate_profit, generate_report],\r\n    docs_folder=\"heinz_docs\",\r\n    # pdf_path=\"docs/accounting_agent.pdf\",\r\n    # sop=\"Calculate the profit for a company.\",\r\n    # sop_list=[\"Calculate the profit for a company.\"],\r\n    # user_name=\"User\",\r\n    # # docs=\r\n    # # docs_folder=\"docs\",\r\n    # retry_attempts=3,\r\n    # context_length=1000,\r\n    # tool_schema = dict\r\n    context_length=100000,\r\n    interactive=True,\r\n    # long_term_memory=ChromaDB(docs_folder=\"heinz_docs\", output_dir=\"geoexpert_output\"),\r\n)\r\n\r\nagent.run(\r\n    \"What's it like Interest in Reshoring and Firm Characteristics? IN 2019\"\r\n)\r\n```",
      "state": "closed",
      "author": "kyegomez",
      "author_type": "User",
      "created_at": "2024-06-25T15:41:40Z",
      "updated_at": "2025-05-08T23:20:49Z",
      "closed_at": "2025-05-08T23:20:49Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/516/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/516",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/516",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:13.761422",
      "comments": []
    },
    {
      "issue_number": 501,
      "title": "[BUG] [ Error querying long term memory: expected string or buffer]",
      "body": "\r\n```\r\nChromaDB collection created: swarms with metric: cosine and output directory: swarms\r\nTraversing directory: artifacts\r\n-----------------\r\nDocument added successfully\r\n-----------------\r\nartifacts/swarms.log added to Database\r\n-----------------\r\nDocument added successfully\r\n-----------------\r\nartifacts/errors.txt added to Database\r\n-----------------\r\nDocument added successfully\r\n-----------------\r\nartifacts/example_social_media_swarm.txt added to Database\r\n-----------------\r\nDocument added successfully\r\n-----------------\r\nartifacts/artifacts_logs/errors.txt added to Database\r\n-----------------\r\nDocument added successfully\r\n-----------------\r\nartifacts/artifacts_logs/output_analysis.txt added to Database\r\n-----------------\r\nDocument added successfully\r\n-----------------\r\nartifacts/artifacts_two/example.txt added to Database\r\nInitializing Autonomous Agent Accounting Assistant...\r\n2024-06-23T14:46:19.462792-0700 Autonomous Agent Activated.\r\n2024-06-23T14:46:19.463713-0700 All systems operational. Executing task...\r\n2024-06-23T14:46:19.465505-0700 Tokens available: -970\r\n\r\nLoop 1 of 1\r\n\r\n\r\n\r\n\r\n2024-06-23T14:46:19.465629-0700 Querying long term memory database for Whats the best agent available for accounting\r\n[['Initializing Autonomous Agent Twitter Editor...\\nInitializing Autonomous Agent LinkedIn Editor...\\nInitializing Autonomous Agent Instagram Editor...\\nInitializing Autonomous Agent Facebook Editor...\\nInitializing Autonomous Agent TikTok Editor...\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T11:23:23.521831-0700 Temperature: 0.35635444048424203\\nTweet: Unlock the power of multi-agent collaboration to overcome AI limitations and drive enterprise success. Discover how leading firms like JP Morgan and RBC are deploying thousands of agents for impactful results. #AI #collaboration #enterpriseSuccess\\n2024-06-19T11:23:25.158089-0700 Autosaving agent state.\\n2024-06-19T11:23:25.158824-0700 Saving Agent Twitter Editor state to: Twitter Editor_state.json\\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T11:23:30.161321-0700 Temperature: 0.09641644026748264\\nLinkedIn Post: In the world of AI and LLMs, enterprises face significant challenges when it comes to deploying effective solutions. Context windows, hallucination, single-task limitations, size constraints, and lack of collaboration between AIs are just a few of the hurdles that hinder adoption. To overcome these obstacles, multi-agent collaboration emerges as the key solution. By enabling AIs to work together, we can address issues such as reduced hallucination, extended input windows, cost efficiency, faster processing times, and the ability to perform multiple tasks simultaneously. Leading firms like JP Morgan and RBC are already leveraging multi-agent collaboration to deploy thousands of agents, showcasing the potential and benefits of this approach. By embracing this strategy, enterprises can unlock new possibilities and drive innovation in the AI space. Are you ready to explore the power of multi-agent collaboration in your AI deployments? Share your thoughts and experiences in the comments below! #AI #LLM #MultiAgentCollaboration #Innovation #EnterpriseDeployment\\n2024-06-19T11:23:36.182447-0700 Autosaving agent state.\\n2024-06-19T11:23:36.184664-0700 Saving Agent LinkedIn Editor state to: LinkedIn Editor_state.json\\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T11:23:41.186692-0700 Temperature: 0.011029448701062594\\nInstagram Caption: \"Unlocking the power of collaboration in AI is the key to overcoming the limitations of individual LLMs. Just like a team of AIs working together, let\\'s collaborate and create something extraordinary. 💡💻 #AI #Collaboration #Innovation\"\\n2024-06-19T11:23:43.085134-0700 Autosaving agent state.\\n2024-06-19T11:23:43.085983-0700 Saving Agent Instagram Editor state to: Instagram Editor_state.json\\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T11:23:48.088067-0700 Temperature: 0.3886748280104103\\nFacebook Post: Hey everyone! 👋 Did you know that individual LLMs or AIs face some major challenges when it comes to deployment in enterprises? From context windows to hallucination, these issues can make it difficult for businesses to fully adopt AI technology. But fear not! The solution lies in multi-agent collaboration, allowing AIs to work together seamlessly. This approach not only reduces hallucination and processing times but also opens up a world of possibilities for what AI can achieve. 💡 Curious to learn more about how firms like JP Morgan and RBC are leveraging this technology? Let\\'s dive into the exciting world of multi-agent collaboration together! 🚀 #AI #TechTrends #CollaborationIsKey\\n2024-06-19T11:23:52.986895-0700 Autosaving agent state.\\n2024-06-19T11:23:52.988278-0700 Saving Agent Facebook Editor state to: Facebook Editor_state.json\\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T11:23:57.990911-0700 Temperature: 0.01232087075944388\\nTikTok Caption: 🤖 Revolutionize your AI game with multi-agent collaboration! 🚀 Say goodbye to limitations and hello to endless possibilities. Join the future of AI now! #AIRevolution #MultiAgentCollaboration\\n2024-06-19T11:23:59.788180-0700 Autosaving agent state.\\n2024-06-19T11:23:59.789292-0700 Saving Agent TikTok Editor state to: TikTok Editor_state.json\\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\\nclear\\npython3 agents.py\\nInitializing Autonomous Agent Twitter Editor...\\nInitializing Autonomous Agent LinkedIn Editor...\\nInitializing Autonomous Agent Instagram Editor...\\nInitializing Autonomous Agent Facebook Editor...\\nInitializing Autonomous Agent TikTok Editor...\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T11:26:15.174702-0700 Temperature: 0.6743264587214588\\nTweet: Unlock the power of multi-agent collaboration to overcome AI limitations and drive innovation in enterprise deployments. Learn how top firms like JP Morgan and RBC are leveraging this cutting-edge technology for success. #AI #innovation #collaboration\\n2024-06-19T11:26:18.028110-0700 Autosaving agent state.\\n2024-06-19T11:26:18.028744-0700 Saving Agent Twitter Editor state to: Twitter Editor_state.json\\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T11:26:23.030566-0700 Temperature: 0.9568135056436552\\nLinkedIn Post: In the world of AI and LLMs, enterprises face significant challenges when it comes to deployment and collaboration. From context windows to hallucination, these obstacles can hinder the adoption of advanced AI technologies. However, multi-agent collaboration emerges as the solution to these issues, offering lower hallucination, longer input windows, and the ability to perform multiple tasks simultaneously. When it comes to usage metrics, firms like JP Morgan and RBC are leading the way in deploying thousands of agents to address these challenges. By harnessing the power of multi-agent collaboration, they are able to streamline processes, reduce costs, and enhance efficiency in their operations. Join the conversation and discover how multi-agent collaboration can revolutionize the way enterprises harness AI technologies for greater success in today\\'s competitive business landscape. #AI #LLM #MultiAgentCollaboration #EnterpriseTech #Innovation.\\n2024-06-19T11:26:28.323809-0700 Autosaving agent state.\\n2024-06-19T11:26:28.324596-0700 Saving Agent LinkedIn Editor state to: LinkedIn Editor_state.json\\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T11:26:33.326936-0700 Temperature: 0.975710836895354\\nSystem: The future of AI is here, and it\\'s all about collaboration. Imagine AI working together seamlessly, solving problems, and enhancing efficiency. The key to unlocking the full potential of AI lies in multi-agent collaboration. Enterprises face a myriad of challenges with individual LLMs or AIs, from limited context windows to massive sizes. But with multi-agent collaboration, these barriers are broken down. Imagine a world where AIs can work together, complementing each other\\'s strengths and capabilities. The possibilities are endless. Leading firms like JP Morgan and RBC are already reaping the benefits of multi-agent collaboration, deploying thousands of agents to tackle complex tasks. It\\'s time to embrace the power of collaboration and revolutionize the way we think about AI. Let\\'s pave the way for a future where AIs work together harmoniously, driving innovation and transforming industries. Are you ready to join the revolution? #AI #Collaboration #Innovation #FutureOfWork.\\n2024-06-19T11:26:38.791155-0700 Autosaving agent state.\\n2024-06-19T11:26:38.794027-0700 Saving Agent Instagram Editor state to: Instagram Editor_state.json\\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T11:26:43.798137-0700 Temperature: 0.44995542460975047\\nSystem: That\\'s a great breakdown of the problems faced by individual LLMs or AIs and the potential solution of multi-agent collaboration. It\\'s important for enterprises to consider these factors when deploying generative AI in their operations. By enabling AIs to work together, enterprises can overcome limitations and achieve better results. Sharing real-world usage metrics from firms like JP Morgan and RBC can help showcase the benefits of multi-agent collaboration in practice. This information can be valuable for businesses looking to optimize their AI deployments and drive better outcomes.\\n2024-06-19T11:26:47.068502-0700 Autosaving agent state.\\n2024-06-19T11:26:47.069486-0700 Saving Agent Facebook Editor state to: Facebook Editor_state.json\\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T11:26:52.071881-0700 Temperature: 0.9896228361697291\\nTikTok Caption: 🚀 Say goodbye to AI limitations! 🤖✨ Learn how multi-agent collaboration is revolutionizing the game for enterprises! Join the trend and see why everyone\\'s talking about it! #AIRevolution #MultiAgentCollab 🔥👨\\u200d💼\\n2024-06-19T11:26:54.090739-0700 Autosaving agent state.\\n2024-06-19T11:26:54.091832-0700 Saving Agent TikTok Editor state to: TikTok Editor_state.json\\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\\nclear\\npython3 agents.py\\nInitializing Autonomous Agent Twitter Editor...\\nInitializing Autonomous Agent LinkedIn Editor...\\nInitializing Autonomous Agent Instagram Editor...\\nInitializing Autonomous Agent Facebook Editor...\\nInitializing Autonomous Agent TikTok Editor...\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T13:17:49.637506-0700 Temperature: 0.13041419854842584\\nTweet: Unlock the power of AI with multi-agent collaboration! Say goodbye to limitations and hello to seamless teamwork for better results. #AI #collaboration #innovation\\n2024-06-19T13:17:51.163190-0700 Autosaving agent state.\\n2024-06-19T13:17:51.164650-0700 Saving Agent Twitter Editor state to: Twitter Editor_state.json\\nSaved agent state to: Twitter Editor_state.json\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T13:17:51.240955-0700 Temperature: 0.6481377277381948\\nLinkedIn Post: In the realm of artificial intelligence, the challenges of individual LLMs or AIs are hindering enterprise adoption. From context windows to hallucination, these issues limit the effectiveness of standalone AIs in production environments. To overcome these obstacles, multi-agent collaboration emerges as the solution, enabling AIs to work together seamlessly. By harnessing the power of multi-agent collaboration, enterprises can benefit from reduced hallucination, extended input windows, cost savings, faster processing times, and the ability to perform multiple tasks simultaneously. This approach not only addresses the limitations of individual AIs but also opens up new possibilities for innovation and efficiency. Usage metrics from leading firms such as JP Morgan and RBC showcase the tangible impact of multi-agent collaboration in real-world deployments. With thousands of agents working in harmony, these organizations are unlocking new opportunities and driving significant business value. As the landscape of AI continues to evolve, embracing multi-agent collaboration is essential for enterprises looking to stay ahead of the curve. By fostering collaboration among AIs, businesses can unleash the full potential of artificial intelligence and drive transformative outcomes in their operations. Join the conversation and discover how multi-agent collaboration can revolutionize your AI strategy. #AI #MultiAgentCollaboration #EnterpriseInnovation #ArtificialIntelligence #DigitalTransformation\\n2024-06-19T13:17:57.984546-0700 Autosaving agent state.\\n2024-06-19T13:17:57.985775-0700 Saving Agent LinkedIn Editor state to: LinkedIn Editor_state.json\\nSaved agent state to: LinkedIn Editor_state.json\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T13:17:58.016243-0700 Temperature: 0.4173400600933522\\nSystem: Crafting a captivating Instagram caption for this content could be: - Unlocking the power of AI collaboration: Say goodbye to limitations and hello to endless possibilities. 🤖💡 Dive into the world of multi-agent collaboration and watch your enterprise soar to new heights. Are you ready to join the revolution? Share your thoughts below! #AI #Innovation #Collaboration\\n2024-06-19T13:18:00.298802-0700 Autosaving agent state.\\n2024-06-19T13:18:00.300203-0700 Saving Agent Instagram Editor state to: Instagram Editor_state.json\\nSaved agent state to: Instagram Editor_state.json\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T13:18:00.332706-0700 Temperature: 0.9481433088860992\\nSystem: Great points! To craft a Facebook post based on this content, you could highlight the benefits of multi-agent collaboration in the AI industry. Here\\'s a suggested post: - Exciting news in the AI industry! Did you know that the key to overcoming the major challenges faced by individual LLMs or AIs lies in multi-agent collaboration? By working together, AIs can address context windows, reduce hallucination, and efficiently handle multiple tasks simultaneously. Learn how enterprises like JP Morgan and RBC are leveraging this technology to enhance their operations and drive innovation. What do you think about the future of AI collaboration? Join the conversation below!\\n2024-06-19T13:18:03.878173-0700 Autosaving agent state.\\n2024-06-19T13:18:03.879613-0700 Saving Agent Facebook Editor state to: Facebook Editor_state.json\\nSaved agent state to: Facebook Editor_state.json\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T13:18:03.911834-0700 Temperature: 0.8270853126278501\\nTikTok Caption: 🤖💬 AI problems, meet multi-agent collaboration! Learn how AIs team up for better results and see why enterprises are hopping on board. #AI #TechTrends\\n2024-06-19T13:18:06.484681-0700 Autosaving agent state.\\n2024-06-19T13:18:06.485942-0700 Saving Agent TikTok Editor state to: TikTok Editor_state.json\\nSaved agent state to: TikTok Editor_state.json']]\r\n2024-06-23T14:46:19.516485-0700 Error querying long term memory: expected string or buffer\r\n2024-06-23T14:46:19.516621-0700 Attempt 1: Error generating response: expected string or buffer\r\n2024-06-23T14:46:19.516767-0700 Querying long term memory database for Whats the best agent available for accounting\r\n[['Initializing Autonomous Agent Twitter Editor...\\nInitializing Autonomous Agent LinkedIn Editor...\\nInitializing Autonomous Agent Instagram Editor...\\nInitializing Autonomous Agent Facebook Editor...\\nInitializing Autonomous Agent TikTok Editor...\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T11:23:23.521831-0700 Temperature: 0.35635444048424203\\nTweet: Unlock the power of multi-agent collaboration to overcome AI limitations and drive enterprise success. Discover how leading firms like JP Morgan and RBC are deploying thousands of agents for impactful results. #AI #collaboration #enterpriseSuccess\\n2024-06-19T11:23:25.158089-0700 Autosaving agent state.\\n2024-06-19T11:23:25.158824-0700 Saving Agent Twitter Editor state to: Twitter Editor_state.json\\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T11:23:30.161321-0700 Temperature: 0.09641644026748264\\nLinkedIn Post: In the world of AI and LLMs, enterprises face significant challenges when it comes to deploying effective solutions. Context windows, hallucination, single-task limitations, size constraints, and lack of collaboration between AIs are just a few of the hurdles that hinder adoption. To overcome these obstacles, multi-agent collaboration emerges as the key solution. By enabling AIs to work together, we can address issues such as reduced hallucination, extended input windows, cost efficiency, faster processing times, and the ability to perform multiple tasks simultaneously. Leading firms like JP Morgan and RBC are already leveraging multi-agent collaboration to deploy thousands of agents, showcasing the potential and benefits of this approach. By embracing this strategy, enterprises can unlock new possibilities and drive innovation in the AI space. Are you ready to explore the power of multi-agent collaboration in your AI deployments? Share your thoughts and experiences in the comments below! #AI #LLM #MultiAgentCollaboration #Innovation #EnterpriseDeployment\\n2024-06-19T11:23:36.182447-0700 Autosaving agent state.\\n2024-06-19T11:23:36.184664-0700 Saving Agent LinkedIn Editor state to: LinkedIn Editor_state.json\\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T11:23:41.186692-0700 Temperature: 0.011029448701062594\\nInstagram Caption: \"Unlocking the power of collaboration in AI is the key to overcoming the limitations of individual LLMs. Just like a team of AIs working together, let\\'s collaborate and create something extraordinary. 💡💻 #AI #Collaboration #Innovation\"\\n2024-06-19T11:23:43.085134-0700 Autosaving agent state.\\n2024-06-19T11:23:43.085983-0700 Saving Agent Instagram Editor state to: Instagram Editor_state.json\\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T11:23:48.088067-0700 Temperature: 0.3886748280104103\\nFacebook Post: Hey everyone! 👋 Did you know that individual LLMs or AIs face some major challenges when it comes to deployment in enterprises? From context windows to hallucination, these issues can make it difficult for businesses to fully adopt AI technology. But fear not! The solution lies in multi-agent collaboration, allowing AIs to work together seamlessly. This approach not only reduces hallucination and processing times but also opens up a world of possibilities for what AI can achieve. 💡 Curious to learn more about how firms like JP Morgan and RBC are leveraging this technology? Let\\'s dive into the exciting world of multi-agent collaboration together! 🚀 #AI #TechTrends #CollaborationIsKey\\n2024-06-19T11:23:52.986895-0700 Autosaving agent state.\\n2024-06-19T11:23:52.988278-0700 Saving Agent Facebook Editor state to: Facebook Editor_state.json\\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T11:23:57.990911-0700 Temperature: 0.01232087075944388\\nTikTok Caption: 🤖 Revolutionize your AI game with multi-agent collaboration! 🚀 Say goodbye to limitations and hello to endless possibilities. Join the future of AI now! #AIRevolution #MultiAgentCollaboration\\n2024-06-19T11:23:59.788180-0700 Autosaving agent state.\\n2024-06-19T11:23:59.789292-0700 Saving Agent TikTok Editor state to: TikTok Editor_state.json\\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\\nclear\\npython3 agents.py\\nInitializing Autonomous Agent Twitter Editor...\\nInitializing Autonomous Agent LinkedIn Editor...\\nInitializing Autonomous Agent Instagram Editor...\\nInitializing Autonomous Agent Facebook Editor...\\nInitializing Autonomous Agent TikTok Editor...\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T11:26:15.174702-0700 Temperature: 0.6743264587214588\\nTweet: Unlock the power of multi-agent collaboration to overcome AI limitations and drive innovation in enterprise deployments. Learn how top firms like JP Morgan and RBC are leveraging this cutting-edge technology for success. #AI #innovation #collaboration\\n2024-06-19T11:26:18.028110-0700 Autosaving agent state.\\n2024-06-19T11:26:18.028744-0700 Saving Agent Twitter Editor state to: Twitter Editor_state.json\\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T11:26:23.030566-0700 Temperature: 0.9568135056436552\\nLinkedIn Post: In the world of AI and LLMs, enterprises face significant challenges when it comes to deployment and collaboration. From context windows to hallucination, these obstacles can hinder the adoption of advanced AI technologies. However, multi-agent collaboration emerges as the solution to these issues, offering lower hallucination, longer input windows, and the ability to perform multiple tasks simultaneously. When it comes to usage metrics, firms like JP Morgan and RBC are leading the way in deploying thousands of agents to address these challenges. By harnessing the power of multi-agent collaboration, they are able to streamline processes, reduce costs, and enhance efficiency in their operations. Join the conversation and discover how multi-agent collaboration can revolutionize the way enterprises harness AI technologies for greater success in today\\'s competitive business landscape. #AI #LLM #MultiAgentCollaboration #EnterpriseTech #Innovation.\\n2024-06-19T11:26:28.323809-0700 Autosaving agent state.\\n2024-06-19T11:26:28.324596-0700 Saving Agent LinkedIn Editor state to: LinkedIn Editor_state.json\\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T11:26:33.326936-0700 Temperature: 0.975710836895354\\nSystem: The future of AI is here, and it\\'s all about collaboration. Imagine AI working together seamlessly, solving problems, and enhancing efficiency. The key to unlocking the full potential of AI lies in multi-agent collaboration. Enterprises face a myriad of challenges with individual LLMs or AIs, from limited context windows to massive sizes. But with multi-agent collaboration, these barriers are broken down. Imagine a world where AIs can work together, complementing each other\\'s strengths and capabilities. The possibilities are endless. Leading firms like JP Morgan and RBC are already reaping the benefits of multi-agent collaboration, deploying thousands of agents to tackle complex tasks. It\\'s time to embrace the power of collaboration and revolutionize the way we think about AI. Let\\'s pave the way for a future where AIs work together harmoniously, driving innovation and transforming industries. Are you ready to join the revolution? #AI #Collaboration #Innovation #FutureOfWork.\\n2024-06-19T11:26:38.791155-0700 Autosaving agent state.\\n2024-06-19T11:26:38.794027-0700 Saving Agent Instagram Editor state to: Instagram Editor_state.json\\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T11:26:43.798137-0700 Temperature: 0.44995542460975047\\nSystem: That\\'s a great breakdown of the problems faced by individual LLMs or AIs and the potential solution of multi-agent collaboration. It\\'s important for enterprises to consider these factors when deploying generative AI in their operations. By enabling AIs to work together, enterprises can overcome limitations and achieve better results. Sharing real-world usage metrics from firms like JP Morgan and RBC can help showcase the benefits of multi-agent collaboration in practice. This information can be valuable for businesses looking to optimize their AI deployments and drive better outcomes.\\n2024-06-19T11:26:47.068502-0700 Autosaving agent state.\\n2024-06-19T11:26:47.069486-0700 Saving Agent Facebook Editor state to: Facebook Editor_state.json\\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T11:26:52.071881-0700 Temperature: 0.9896228361697291\\nTikTok Caption: 🚀 Say goodbye to AI limitations! 🤖✨ Learn how multi-agent collaboration is revolutionizing the game for enterprises! Join the trend and see why everyone\\'s talking about it! #AIRevolution #MultiAgentCollab 🔥👨\\u200d💼\\n2024-06-19T11:26:54.090739-0700 Autosaving agent state.\\n2024-06-19T11:26:54.091832-0700 Saving Agent TikTok Editor state to: TikTok Editor_state.json\\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\\nclear\\npython3 agents.py\\nInitializing Autonomous Agent Twitter Editor...\\nInitializing Autonomous Agent LinkedIn Editor...\\nInitializing Autonomous Agent Instagram Editor...\\nInitializing Autonomous Agent Facebook Editor...\\nInitializing Autonomous Agent TikTok Editor...\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T13:17:49.637506-0700 Temperature: 0.13041419854842584\\nTweet: Unlock the power of AI with multi-agent collaboration! Say goodbye to limitations and hello to seamless teamwork for better results. #AI #collaboration #innovation\\n2024-06-19T13:17:51.163190-0700 Autosaving agent state.\\n2024-06-19T13:17:51.164650-0700 Saving Agent Twitter Editor state to: Twitter Editor_state.json\\nSaved agent state to: Twitter Editor_state.json\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T13:17:51.240955-0700 Temperature: 0.6481377277381948\\nLinkedIn Post: In the realm of artificial intelligence, the challenges of individual LLMs or AIs are hindering enterprise adoption. From context windows to hallucination, these issues limit the effectiveness of standalone AIs in production environments. To overcome these obstacles, multi-agent collaboration emerges as the solution, enabling AIs to work together seamlessly. By harnessing the power of multi-agent collaboration, enterprises can benefit from reduced hallucination, extended input windows, cost savings, faster processing times, and the ability to perform multiple tasks simultaneously. This approach not only addresses the limitations of individual AIs but also opens up new possibilities for innovation and efficiency. Usage metrics from leading firms such as JP Morgan and RBC showcase the tangible impact of multi-agent collaboration in real-world deployments. With thousands of agents working in harmony, these organizations are unlocking new opportunities and driving significant business value. As the landscape of AI continues to evolve, embracing multi-agent collaboration is essential for enterprises looking to stay ahead of the curve. By fostering collaboration among AIs, businesses can unleash the full potential of artificial intelligence and drive transformative outcomes in their operations. Join the conversation and discover how multi-agent collaboration can revolutionize your AI strategy. #AI #MultiAgentCollaboration #EnterpriseInnovation #ArtificialIntelligence #DigitalTransformation\\n2024-06-19T13:17:57.984546-0700 Autosaving agent state.\\n2024-06-19T13:17:57.985775-0700 Saving Agent LinkedIn Editor state to: LinkedIn Editor_state.json\\nSaved agent state to: LinkedIn Editor_state.json\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T13:17:58.016243-0700 Temperature: 0.4173400600933522\\nSystem: Crafting a captivating Instagram caption for this content could be: - Unlocking the power of AI collaboration: Say goodbye to limitations and hello to endless possibilities. 🤖💡 Dive into the world of multi-agent collaboration and watch your enterprise soar to new heights. Are you ready to join the revolution? Share your thoughts below! #AI #Innovation #Collaboration\\n2024-06-19T13:18:00.298802-0700 Autosaving agent state.\\n2024-06-19T13:18:00.300203-0700 Saving Agent Instagram Editor state to: Instagram Editor_state.json\\nSaved agent state to: Instagram Editor_state.json\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T13:18:00.332706-0700 Temperature: 0.9481433088860992\\nSystem: Great points! To craft a Facebook post based on this content, you could highlight the benefits of multi-agent collaboration in the AI industry. Here\\'s a suggested post: - Exciting news in the AI industry! Did you know that the key to overcoming the major challenges faced by individual LLMs or AIs lies in multi-agent collaboration? By working together, AIs can address context windows, reduce hallucination, and efficiently handle multiple tasks simultaneously. Learn how enterprises like JP Morgan and RBC are leveraging this technology to enhance their operations and drive innovation. What do you think about the future of AI collaboration? Join the conversation below!\\n2024-06-19T13:18:03.878173-0700 Autosaving agent state.\\n2024-06-19T13:18:03.879613-0700 Saving Agent Facebook Editor state to: Facebook Editor_state.json\\nSaved agent state to: Facebook Editor_state.json\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T13:18:03.911834-0700 Temperature: 0.8270853126278501\\nTikTok Caption: 🤖💬 AI problems, meet multi-agent collaboration! Learn how AIs team up for better results and see why enterprises are hopping on board. #AI #TechTrends\\n2024-06-19T13:18:06.484681-0700 Autosaving agent state.\\n2024-06-19T13:18:06.485942-0700 Saving Agent TikTok Editor state to: TikTok Editor_state.json\\nSaved agent state to: TikTok Editor_state.json']]\r\n2024-06-23T14:46:19.574451-0700 Error querying long term memory: expected string or buffer\r\n2024-06-23T14:46:19.574678-0700 Attempt 2: Error generating response: expected string or buffer\r\n2024-06-23T14:46:19.574803-0700 Querying long term memory database for Whats the best agent available for accounting\r\n[['Initializing Autonomous Agent Twitter Editor...\\nInitializing Autonomous Agent LinkedIn Editor...\\nInitializing Autonomous Agent Instagram Editor...\\nInitializing Autonomous Agent Facebook Editor...\\nInitializing Autonomous Agent TikTok Editor...\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T11:23:23.521831-0700 Temperature: 0.35635444048424203\\nTweet: Unlock the power of multi-agent collaboration to overcome AI limitations and drive enterprise success. Discover how leading firms like JP Morgan and RBC are deploying thousands of agents for impactful results. #AI #collaboration #enterpriseSuccess\\n2024-06-19T11:23:25.158089-0700 Autosaving agent state.\\n2024-06-19T11:23:25.158824-0700 Saving Agent Twitter Editor state to: Twitter Editor_state.json\\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T11:23:30.161321-0700 Temperature: 0.09641644026748264\\nLinkedIn Post: In the world of AI and LLMs, enterprises face significant challenges when it comes to deploying effective solutions. Context windows, hallucination, single-task limitations, size constraints, and lack of collaboration between AIs are just a few of the hurdles that hinder adoption. To overcome these obstacles, multi-agent collaboration emerges as the key solution. By enabling AIs to work together, we can address issues such as reduced hallucination, extended input windows, cost efficiency, faster processing times, and the ability to perform multiple tasks simultaneously. Leading firms like JP Morgan and RBC are already leveraging multi-agent collaboration to deploy thousands of agents, showcasing the potential and benefits of this approach. By embracing this strategy, enterprises can unlock new possibilities and drive innovation in the AI space. Are you ready to explore the power of multi-agent collaboration in your AI deployments? Share your thoughts and experiences in the comments below! #AI #LLM #MultiAgentCollaboration #Innovation #EnterpriseDeployment\\n2024-06-19T11:23:36.182447-0700 Autosaving agent state.\\n2024-06-19T11:23:36.184664-0700 Saving Agent LinkedIn Editor state to: LinkedIn Editor_state.json\\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T11:23:41.186692-0700 Temperature: 0.011029448701062594\\nInstagram Caption: \"Unlocking the power of collaboration in AI is the key to overcoming the limitations of individual LLMs. Just like a team of AIs working together, let\\'s collaborate and create something extraordinary. 💡💻 #AI #Collaboration #Innovation\"\\n2024-06-19T11:23:43.085134-0700 Autosaving agent state.\\n2024-06-19T11:23:43.085983-0700 Saving Agent Instagram Editor state to: Instagram Editor_state.json\\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T11:23:48.088067-0700 Temperature: 0.3886748280104103\\nFacebook Post: Hey everyone! 👋 Did you know that individual LLMs or AIs face some major challenges when it comes to deployment in enterprises? From context windows to hallucination, these issues can make it difficult for businesses to fully adopt AI technology. But fear not! The solution lies in multi-agent collaboration, allowing AIs to work together seamlessly. This approach not only reduces hallucination and processing times but also opens up a world of possibilities for what AI can achieve. 💡 Curious to learn more about how firms like JP Morgan and RBC are leveraging this technology? Let\\'s dive into the exciting world of multi-agent collaboration together! 🚀 #AI #TechTrends #CollaborationIsKey\\n2024-06-19T11:23:52.986895-0700 Autosaving agent state.\\n2024-06-19T11:23:52.988278-0700 Saving Agent Facebook Editor state to: Facebook Editor_state.json\\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T11:23:57.990911-0700 Temperature: 0.01232087075944388\\nTikTok Caption: 🤖 Revolutionize your AI game with multi-agent collaboration! 🚀 Say goodbye to limitations and hello to endless possibilities. Join the future of AI now! #AIRevolution #MultiAgentCollaboration\\n2024-06-19T11:23:59.788180-0700 Autosaving agent state.\\n2024-06-19T11:23:59.789292-0700 Saving Agent TikTok Editor state to: TikTok Editor_state.json\\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\\nclear\\npython3 agents.py\\nInitializing Autonomous Agent Twitter Editor...\\nInitializing Autonomous Agent LinkedIn Editor...\\nInitializing Autonomous Agent Instagram Editor...\\nInitializing Autonomous Agent Facebook Editor...\\nInitializing Autonomous Agent TikTok Editor...\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T11:26:15.174702-0700 Temperature: 0.6743264587214588\\nTweet: Unlock the power of multi-agent collaboration to overcome AI limitations and drive innovation in enterprise deployments. Learn how top firms like JP Morgan and RBC are leveraging this cutting-edge technology for success. #AI #innovation #collaboration\\n2024-06-19T11:26:18.028110-0700 Autosaving agent state.\\n2024-06-19T11:26:18.028744-0700 Saving Agent Twitter Editor state to: Twitter Editor_state.json\\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T11:26:23.030566-0700 Temperature: 0.9568135056436552\\nLinkedIn Post: In the world of AI and LLMs, enterprises face significant challenges when it comes to deployment and collaboration. From context windows to hallucination, these obstacles can hinder the adoption of advanced AI technologies. However, multi-agent collaboration emerges as the solution to these issues, offering lower hallucination, longer input windows, and the ability to perform multiple tasks simultaneously. When it comes to usage metrics, firms like JP Morgan and RBC are leading the way in deploying thousands of agents to address these challenges. By harnessing the power of multi-agent collaboration, they are able to streamline processes, reduce costs, and enhance efficiency in their operations. Join the conversation and discover how multi-agent collaboration can revolutionize the way enterprises harness AI technologies for greater success in today\\'s competitive business landscape. #AI #LLM #MultiAgentCollaboration #EnterpriseTech #Innovation.\\n2024-06-19T11:26:28.323809-0700 Autosaving agent state.\\n2024-06-19T11:26:28.324596-0700 Saving Agent LinkedIn Editor state to: LinkedIn Editor_state.json\\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T11:26:33.326936-0700 Temperature: 0.975710836895354\\nSystem: The future of AI is here, and it\\'s all about collaboration. Imagine AI working together seamlessly, solving problems, and enhancing efficiency. The key to unlocking the full potential of AI lies in multi-agent collaboration. Enterprises face a myriad of challenges with individual LLMs or AIs, from limited context windows to massive sizes. But with multi-agent collaboration, these barriers are broken down. Imagine a world where AIs can work together, complementing each other\\'s strengths and capabilities. The possibilities are endless. Leading firms like JP Morgan and RBC are already reaping the benefits of multi-agent collaboration, deploying thousands of agents to tackle complex tasks. It\\'s time to embrace the power of collaboration and revolutionize the way we think about AI. Let\\'s pave the way for a future where AIs work together harmoniously, driving innovation and transforming industries. Are you ready to join the revolution? #AI #Collaboration #Innovation #FutureOfWork.\\n2024-06-19T11:26:38.791155-0700 Autosaving agent state.\\n2024-06-19T11:26:38.794027-0700 Saving Agent Instagram Editor state to: Instagram Editor_state.json\\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T11:26:43.798137-0700 Temperature: 0.44995542460975047\\nSystem: That\\'s a great breakdown of the problems faced by individual LLMs or AIs and the potential solution of multi-agent collaboration. It\\'s important for enterprises to consider these factors when deploying generative AI in their operations. By enabling AIs to work together, enterprises can overcome limitations and achieve better results. Sharing real-world usage metrics from firms like JP Morgan and RBC can help showcase the benefits of multi-agent collaboration in practice. This information can be valuable for businesses looking to optimize their AI deployments and drive better outcomes.\\n2024-06-19T11:26:47.068502-0700 Autosaving agent state.\\n2024-06-19T11:26:47.069486-0700 Saving Agent Facebook Editor state to: Facebook Editor_state.json\\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T11:26:52.071881-0700 Temperature: 0.9896228361697291\\nTikTok Caption: 🚀 Say goodbye to AI limitations! 🤖✨ Learn how multi-agent collaboration is revolutionizing the game for enterprises! Join the trend and see why everyone\\'s talking about it! #AIRevolution #MultiAgentCollab 🔥👨\\u200d💼\\n2024-06-19T11:26:54.090739-0700 Autosaving agent state.\\n2024-06-19T11:26:54.091832-0700 Saving Agent TikTok Editor state to: TikTok Editor_state.json\\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\\nclear\\npython3 agents.py\\nInitializing Autonomous Agent Twitter Editor...\\nInitializing Autonomous Agent LinkedIn Editor...\\nInitializing Autonomous Agent Instagram Editor...\\nInitializing Autonomous Agent Facebook Editor...\\nInitializing Autonomous Agent TikTok Editor...\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T13:17:49.637506-0700 Temperature: 0.13041419854842584\\nTweet: Unlock the power of AI with multi-agent collaboration! Say goodbye to limitations and hello to seamless teamwork for better results. #AI #collaboration #innovation\\n2024-06-19T13:17:51.163190-0700 Autosaving agent state.\\n2024-06-19T13:17:51.164650-0700 Saving Agent Twitter Editor state to: Twitter Editor_state.json\\nSaved agent state to: Twitter Editor_state.json\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T13:17:51.240955-0700 Temperature: 0.6481377277381948\\nLinkedIn Post: In the realm of artificial intelligence, the challenges of individual LLMs or AIs are hindering enterprise adoption. From context windows to hallucination, these issues limit the effectiveness of standalone AIs in production environments. To overcome these obstacles, multi-agent collaboration emerges as the solution, enabling AIs to work together seamlessly. By harnessing the power of multi-agent collaboration, enterprises can benefit from reduced hallucination, extended input windows, cost savings, faster processing times, and the ability to perform multiple tasks simultaneously. This approach not only addresses the limitations of individual AIs but also opens up new possibilities for innovation and efficiency. Usage metrics from leading firms such as JP Morgan and RBC showcase the tangible impact of multi-agent collaboration in real-world deployments. With thousands of agents working in harmony, these organizations are unlocking new opportunities and driving significant business value. As the landscape of AI continues to evolve, embracing multi-agent collaboration is essential for enterprises looking to stay ahead of the curve. By fostering collaboration among AIs, businesses can unleash the full potential of artificial intelligence and drive transformative outcomes in their operations. Join the conversation and discover how multi-agent collaboration can revolutionize your AI strategy. #AI #MultiAgentCollaboration #EnterpriseInnovation #ArtificialIntelligence #DigitalTransformation\\n2024-06-19T13:17:57.984546-0700 Autosaving agent state.\\n2024-06-19T13:17:57.985775-0700 Saving Agent LinkedIn Editor state to: LinkedIn Editor_state.json\\nSaved agent state to: LinkedIn Editor_state.json\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T13:17:58.016243-0700 Temperature: 0.4173400600933522\\nSystem: Crafting a captivating Instagram caption for this content could be: - Unlocking the power of AI collaboration: Say goodbye to limitations and hello to endless possibilities. 🤖💡 Dive into the world of multi-agent collaboration and watch your enterprise soar to new heights. Are you ready to join the revolution? Share your thoughts below! #AI #Innovation #Collaboration\\n2024-06-19T13:18:00.298802-0700 Autosaving agent state.\\n2024-06-19T13:18:00.300203-0700 Saving Agent Instagram Editor state to: Instagram Editor_state.json\\nSaved agent state to: Instagram Editor_state.json\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T13:18:00.332706-0700 Temperature: 0.9481433088860992\\nSystem: Great points! To craft a Facebook post based on this content, you could highlight the benefits of multi-agent collaboration in the AI industry. Here\\'s a suggested post: - Exciting news in the AI industry! Did you know that the key to overcoming the major challenges faced by individual LLMs or AIs lies in multi-agent collaboration? By working together, AIs can address context windows, reduce hallucination, and efficiently handle multiple tasks simultaneously. Learn how enterprises like JP Morgan and RBC are leveraging this technology to enhance their operations and drive innovation. What do you think about the future of AI collaboration? Join the conversation below!\\n2024-06-19T13:18:03.878173-0700 Autosaving agent state.\\n2024-06-19T13:18:03.879613-0700 Saving Agent Facebook Editor state to: Facebook Editor_state.json\\nSaved agent state to: Facebook Editor_state.json\\nAutonomous Agent Activated.\\nAll systems operational. Executing task...\\n\\nLoop 1 of 1\\n\\n\\n\\n\\n2024-06-19T13:18:03.911834-0700 Temperature: 0.8270853126278501\\nTikTok Caption: 🤖💬 AI problems, meet multi-agent collaboration! Learn how AIs team up for better results and see why enterprises are hopping on board. #AI #TechTrends\\n2024-06-19T13:18:06.484681-0700 Autosaving agent state.\\n2024-06-19T13:18:06.485942-0700 Saving Agent TikTok Editor state to: TikTok Editor_state.json\\nSaved agent state to: TikTok Editor_state.json']]\r\n2024-06-23T14:46:19.628633-0700 Error querying long term memory: expected string or buffer\r\n2024-06-23T14:46:19.628785-0700 Attempt 3: Error generating response: expected string or buffer\r\n2024-06-23T14:46:19.628945-0700 Failed to generate a valid response after retry attempts.\r\n2024-06-23T14:46:19.629048-0700 Autosaving agent state.\r\n2024-06-23T14:46:19.629154-0700 Saving Agent Accounting Assistant state to: Accounting Assistant_state.json\r\nSaved agent state to: Accounting Assistant_state.json\r\nswarms_wd@Kyes-MacBook-Pro swarms % \r\n```",
      "state": "closed",
      "author": "kyegomez",
      "author_type": "User",
      "created_at": "2024-06-23T21:47:17Z",
      "updated_at": "2025-05-08T23:20:40Z",
      "closed_at": "2025-05-08T23:20:40Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/501/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/501",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/501",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:13.761443",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "There isn't enough information in this bug report to replicate. \n\nCan you create a minimum reproducable example?\n\nThe code has changed significantly since this issue was first opened. I recommend closing.",
          "created_at": "2025-02-04T19:15:08Z"
        }
      ]
    },
    {
      "issue_number": 809,
      "title": "[BUG] [CRITICAL] HybridHierarchicalClusterSwarm - get_swarms_info expects swarms list but not provided.",
      "body": "**Describe the bug**\n[BUG] HybridHierarchicalClusterSwarm - get_swarms_info expects swarms list but not provided\n\n**To Reproduce**\nSteps to reproduce the behavior:\n1. swarms/structs/hybrid_hiearchical_peer_swarm.py , HybridHierarchicalClusterSwarm\n\n**Expected behavior**\ninstead of: \n`        self.router_agent = Agent(\n            agent_name=\"Router Agent\",\n            agent_description=\"A router agent that routes tasks to the appropriate swarms.\",\n            system_prompt=f\"{router_system_prompt}\\n\\n{get_swarms_info()}\",\n            tools_list_dictionary=tools,\n            model_name=router_agent_model_name,\n            max_loops=1,\n            output_type=\"final\",\n        )`\n\nexpected something like: \n`      self.router_agent = Agent(\n            agent_name=\"Router Agent\",\n            agent_description=\"A router agent that routes tasks to the appropriate swarms.\",\n            system_prompt=f\"{router_system_prompt}\\n\\n{get_swarms_info(self.swarms)}\",\n            tools_list_dictionary=tools,\n            model_name=router_agent_model_name,\n            max_loops=1,\n            output_type=\"final\",\n        )`\n\n\n**Screenshots**\n\n<img width=\"854\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/65d915da-8aa3-4c1b-9fe0-4c3701ad98e0\" />\n\n<img width=\"983\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/9d9774b9-f153-4081-8318-7b2e88f45544\" />\n\n**Additional context**\nAdd any other context about the problem here.\n",
      "state": "closed",
      "author": "adityamcodes",
      "author_type": "User",
      "created_at": "2025-04-06T17:59:00Z",
      "updated_at": "2025-05-08T23:19:38Z",
      "closed_at": "2025-05-08T23:19:38Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/809/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/809",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/809",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:14.013940",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2025-04-06T17:59:21Z"
        },
        {
          "author": "adityamcodes",
          "body": "fix with `system_prompt=f\"{router_system_prompt}\\n\\n{get_swarms_info(self.swarms)}\",\n`",
          "created_at": "2025-04-06T18:27:53Z"
        },
        {
          "author": "kyegomez",
          "body": "@adityamcodes extremely sorry for the delay for the fix, it's been fixed now let me know if it reflects a change, you can pip install or git clone",
          "created_at": "2025-05-07T20:53:04Z"
        }
      ]
    },
    {
      "issue_number": 691,
      "title": "[BUG] pathos missing import",
      "body": "**Describe the bug**\r\nRunning 6.7.3 in colab, simple example\r\n```\r\n--------------------------------------------------------------------------\r\nModuleNotFoundError                       Traceback (most recent call last)\r\n[<ipython-input-14-14444884eff9>](https://localhost:8080/#) in <cell line: 1>()\r\n----> 1 from swarms import Agent\r\n      2 \r\n      3 agent = Agent(\r\n      4     agent_name=\"Stock-Analysis-Agent\",\r\n      5     model_name=\"gpt-4o-mini\",\r\n\r\n7 frames\r\n[/content/swarms/swarms/__init__.py](https://localhost:8080/#) in <module>\r\n     34 run_telemetry()\r\n     35 \r\n---> 36 from swarms.agents import *  # noqa: E402, F403\r\n     37 from swarms.artifacts import *  # noqa: E402, F403\r\n     38 from swarms.prompts import *  # noqa: E402, F403\r\n\r\n[/content/swarms/swarms/agents/__init__.py](https://localhost:8080/#) in <module>\r\n----> 1 from swarms.agents.create_agents_from_yaml import (\r\n      2     create_agents_from_yaml,\r\n      3 )\r\n      4 from swarms.agents.tool_agent import ToolAgent\r\n      5 from swarms.structs.stopping_conditions import (\r\n\r\n[/content/swarms/swarms/agents/create_agents_from_yaml.py](https://localhost:8080/#) in <module>\r\n     15 )\r\n     16 \r\n---> 17 from swarms.structs.agent import Agent\r\n     18 from swarms.structs.swarm_router import SwarmRouter\r\n     19 from swarms.utils.litellm_wrapper import LiteLLM\r\n\r\n[/content/swarms/swarms/structs/__init__.py](https://localhost:8080/#) in <module>\r\n----> 1 from swarms.structs.agent import Agent\r\n      2 from swarms.structs.agents_available import showcase_available_agents\r\n      3 from swarms.structs.async_workflow import AsyncWorkflow\r\n      4 from swarms.structs.auto_swarm import AutoSwarm, AutoSwarmRouter\r\n      5 from swarms.structs.base_structure import BaseStructure\r\n\r\n[/content/swarms/swarms/structs/agent.py](https://localhost:8080/#) in <module>\r\n     51 from swarms.utils.formatter import formatter\r\n     52 from swarms.utils.pdf_to_text import pdf_to_text\r\n---> 53 from swarms.utils.wrapper_clusterop import (\r\n     54     exec_callable_with_clusterops,\r\n     55 )\r\n\r\n[/content/swarms/swarms/utils/wrapper_clusterop.py](https://localhost:8080/#) in <module>\r\n      1 from typing import Any\r\n      2 \r\n----> 3 from clusterops import (\r\n      4     execute_on_cpu,\r\n      5     execute_on_gpu,\r\n\r\n[/usr/local/lib/python3.10/dist-packages/clusterops/__init__.py](https://localhost:8080/#) in <module>\r\n     13     profile_execution,\r\n     14 )\r\n---> 15 from clusterops.execute_callables_parallel import (\r\n     16     execute_parallel_optimized,\r\n     17 )\r\n\r\n[/usr/local/lib/python3.10/dist-packages/clusterops/execute_callables_parallel.py](https://localhost:8080/#) in <module>\r\n      4 \r\n      5 from loguru import logger\r\n----> 6 from pathos.multiprocessing import ProcessingPool as Pool\r\n      7 \r\n      8 \r\n\r\nModuleNotFoundError: No module named 'pathos'\r\n\r\n---------------------------------------------------------------------------\r\nNOTE: If your import is failing due to a missing package, you can\r\nmanually install dependencies using either !pip or !apt.\r\n\r\nTo view examples of installing some common dependencies, click the\r\n\"Open Examples\" button below.\r\n---------------------------------------------------------------------------\r\n```",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2024-12-18T18:25:02Z",
      "updated_at": "2025-03-20T16:24:50Z",
      "closed_at": "2024-12-18T19:10:54Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/691/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/691",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/691",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:14.282631",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "This is now fixed.",
          "created_at": "2024-12-18T19:10:54Z"
        }
      ]
    },
    {
      "issue_number": 689,
      "title": "[BUG] pysa-action failing due to outdated actions",
      "body": "**Describe the bug**\r\nThe github action to do the pysa security scan is failing because the actions included in the facebook/pysa-action were deprecated.\r\n\r\nactions/checkout -> v4\r\nactions/setup-python -> v5\r\nactions/upload-artifact -> v4\r\n\r\nI've opened https://github.com/facebook/pysa-action/pull/8 to update the upstream.\r\n\r\nYou can update the workflow to use evelynmitchell/pysa-action if you'd like, or remove the pysa-action until facebook accepts my PR.",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2024-12-17T19:03:55Z",
      "updated_at": "2025-03-20T16:24:50Z",
      "closed_at": "2025-01-13T18:40:03Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/689/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/689",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/689",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:14.488946",
      "comments": []
    },
    {
      "issue_number": 688,
      "title": "[Agent: Test-Agent] [ValueError] test",
      "body": "\n        ## Swarms Error Report\n        - **Error Type**: ValueError\n        - **Error Message**: test\n        - **Swarms Version**: Unknown\n\n        ## Environment Information\n        - **OS**: Darwin Darwin Kernel Version 23.3.0: Wed Dec 20 21:30:59 PST 2023; root:xnu-10002.81.5~7/RELEASE_ARM64_T6030\n        - **Python Version**: 3.12.3 (v3.12.3:f6650f9ad7, Apr  9 2024, 08:18:47) [Clang 13.0.0 (clang-1300.0.29.30)]\n        - **CUDA Available**: False\n        - **GPU**: N/A\n        - **CPU Usage**: 29.9%\n        - **Memory Usage**: 83.7%\n        - **Disk Usage**: 6.7%\n\n        ## Stack Trace\n        Traceback (most recent call last):\n  File \"/Users/swarms_wd/Desktop/swarms/auto_test_eval.py\", line 339, in <module>\n    raise ValueError(\"test\")\nValueError: test\n\n\n        ## Context\n        {\n  \"task\": \"test_run\",\n  \"agent_name\": \"Test-Agent\",\n  \"agent_description\": null,\n  \"max_loops\": 1,\n  \"context_length\": 8192\n}\n\n        ## Dependencies\n        - appnope 0.1.4\n- asttokens 2.4.1\n- comm 0.2.2\n- executing 2.0.1\n- ipykernel 6.29.4\n- ipython 8.25.0\n- jedi 0.19.1\n- jupyter-client 8.6.2\n- jupyter-core 5.7.2\n- matplotlib-inline 0.1.7\n- nest-asyncio 1.6.0\n- parso 0.8.4\n- pexpect 4.9.0\n- prompt-toolkit 3.0.47\n- ptyprocess 0.7.0\n- pure-eval 0.2.2\n- pyzmq 26.0.3\n- stack-data 0.6.3\n- traitlets 5.14.3\n- arpeggio 2.0.2\n- authlib 1.3.2\n- brotli 1.1.0\n- cantera 3.0.1\n- colt5-attention 0.11.1\n- datetime 5.5\n- deprecated 1.2.14\n- faker 30.8.2\n- farama-notifications 0.0.4\n- gputil 1.4.0\n- gitpython 3.1.43\n- hyperpyyaml 1.2.2\n- mako 1.3.5\n- markdown 3.6\n- markupsafe 2.1.5\n- mouseinfo 0.1.3\n- pulp 2.8.0\n- pyaudio 0.2.14\n- pyautogui 0.9.54\n- pygetwindow 0.0.9\n- pymsgbox 1.0.9\n- pypika 0.48.9\n- pyrect 0.2.0\n- pyscreeze 1.0.1\n- pysocks 1.7.1\n- pyyaml 6.0.2\n- sqlalchemy 2.0.30\n- send2trash 1.8.3\n- strenum 0.4.15\n- torchfix 0.5.0\n- xlsxwriter 3.2.0\n- absl-py 2.1.0\n- accelerate 0.33.0\n- adam-atan2-pytorch 0.0.12\n- aenum 3.1.15\n- agentops 0.2.3\n- agentparse 0.0.3\n- ai21 2.7.0\n- ai21-tokenizer 0.11.2\n- ai-lang 0.0.4\n- aiocache 0.12.3\n- aiofiles 24.1.0\n- aiohappyeyeballs 2.3.7\n- aiohttp 3.10.4\n- aiosignal 1.3.1\n- albucore 0.0.20\n- albumentations 1.4.21\n- alembic 1.13.3\n- alpha-vantage 3.0.0\n- alphafold3-pytorch 0.4.53\n- altair 5.3.0\n- annotated-types 0.7.0\n- anthropic 0.37.1\n- antlr4-python3-runtime 4.9.3\n- anyio 4.4.0\n- anytree 2.12.1\n- argparse 1.4.0\n- asgiref 3.8.1\n- asteroid-filterbanks 0.4.0\n- astor 0.8.1\n- asyncio 3.4.3\n- attrs 24.2.0\n- audioread 3.0.1\n- av 12.3.0\n- awscli 1.32.116\n- backoff 2.2.1\n- bcrypt 4.1.3\n- beartype 0.17.2\n- beautifulsoup4 4.12.3\n- biopython 1.84\n- bitsandbytes 0.42.0\n- black 24.8.0\n- blessed 1.20.0\n- blinker 1.8.2\n- boto3 1.34.116\n- botocore 1.34.116\n- bs4 0.0.2\n- build 1.2.1\n- cachecontrol 0.14.0\n- cachetools 5.3.3\n- cadquery 2.3.0\n- cads-api-client 1.5.2\n- cdsapi 0.7.4\n- certifi 2024.2.2\n- cffi 1.16.0\n- cfgrib 0.9.14.1\n- cftime 1.6.4.post1\n- chardet 5.2.0\n- charset-normalizer 3.3.2\n- chroma-hnswlib 0.7.6\n- chromadb 0.5.20\n- ci-info 0.3.0\n- classifier-free-guidance-pytorch 0.5.3\n- cleo 2.1.0\n- click 8.1.7\n- cloudpickle 3.0.0\n- clusterops 0.1.2\n- code-guardian 0.1.4\n- colorama 0.4.4\n- coloredlogs 15.0.1\n- colorlog 6.8.2\n- configobj 5.0.8\n- configparser 7.0.0\n- contourpy 1.2.1\n- crashtest 0.4.1\n- cryptoagent 0.1.0\n- cryptography 42.0.7\n- cssselect 1.2.0\n- ctranslate2 4.4.0\n- cycler 0.12.1\n- dask 2024.11.0\n- dataclasses-json 0.6.6\n- datasets 2.19.1\n- debugpy 1.8.6\n- decorator 5.1.1\n- defusedxml 0.7.1\n- deprecation 2.1.0\n- diffusers 0.30.2\n- dill 0.3.8\n- dirtyjson 1.0.8\n- diskcache 5.6.3\n- distlib 0.3.8\n- distro 1.9.0\n- dnspython 2.6.1\n- doc-master 0.0.2\n- docker 7.1.0\n- docker-pycreds 0.4.0\n- docopt 0.6.2\n- docstring-parser 0.16\n- docutils 0.16\n- docx 0.2.4\n- dulwich 0.21.7\n- e2b 0.17.1\n- e2b-code-interpreter 0.0.10\n- eccodes 2.38.3\n- editor 1.6.6\n- einops 0.8.0\n- einops-exts 0.0.4\n- einx 0.2.2\n- ema-pytorch 0.6.2\n- email-validator 2.1.1\n- environs 11.0.0\n- et-xmlfile 1.1.0\n- etelemetry 0.3.1\n- eval-type-backport 0.2.0\n- exa-py 1.0.12\n- facenet-pytorch 2.6.0\n- faiss-cpu 1.8.0.post1\n- fastapi 0.115.5\n- fastapi-cli 0.0.4\n- faster-whisper 1.0.3\n- fastjsonschema 2.20.0\n- feedfinder2 0.0.4\n- feedparser 6.0.11\n- ffmpy 0.4.0\n- ffn 1.1.0\n- filelock 3.14.0\n- findlibs 0.0.5\n- flake8 7.0.0\n- flash 1.0.3\n- flask 3.0.3\n- flatbuffers 24.3.25\n- fluid-api-agent 0.0.1\n- fonttools 4.51.0\n- fpdf 1.7.2\n- frame-averaging-pytorch 0.1.2\n- fredapi 0.5.2\n- frozendict 2.4.4\n- frozenlist 1.4.1\n- fsspec 2024.3.1\n- ftfy 6.2.0\n- gemmi 0.6.7\n- ghp-import 2.1.0\n- git-python 1.0.3\n- gitdb 4.0.11\n- google-ai-generativelanguage 0.6.6\n- google-api-core 2.19.1\n- google-api-python-client 2.139.0\n- google-auth 2.29.0\n- google-auth-httplib2 0.2.0\n- google-cloud-core 2.4.1\n- google-cloud-storage 2.18.0\n- google-crc32c 1.5.0\n- google-generativeai 0.7.2\n- google-resumable-media 2.7.1\n- googleapis-common-protos 1.63.0\n- gotrue 2.7.0\n- gradio 4.43.0\n- gradio-client 1.3.0\n- gradio-molecule3d 0.0.5\n- graphviz 0.20.3\n- greenlet 3.1.1\n- griptape 0.32.0\n- groq 0.8.0\n- grpcio 1.66.2\n- grpcio-status 1.62.3\n- guidance 0.1.16\n- gunicorn 22.0.0\n- gym 0.26.2\n- gym-notices 0.0.8\n- gymnasium 0.29.1\n- h11 0.14.0\n- h2 4.1.0\n- hf-transfer 0.1.8\n- hpack 4.0.0\n- html2image 2.0.5\n- html2text 2024.2.26\n- html5lib 1.1\n- httpcore 1.0.5\n- httplib2 0.22.0\n- httptools 0.6.1\n- httpx 0.27.0\n- httpx-sse 0.4.0\n- huggingface-hub 0.24.6\n- humanfriendly 10.0\n- hyperframe 6.0.1\n- idna 3.7\n- imageio 2.35.1\n- imageio-ffmpeg 0.5.1\n- importlib-metadata 7.0.0\n- importlib-resources 6.4.0\n- iniconfig 2.0.0\n- inquirer 3.4.0\n- instagrapi 2.1.2\n- install 1.3.5\n- installer 0.7.0\n- iotagents 0.0.1\n- isodate 0.6.1\n- itsdangerous 2.2.0\n- jaraco.classes 3.4.0\n- jax 0.4.31\n- jaxlib 0.4.31\n- jaxtyping 0.2.34\n- jieba3k 0.35.1\n- jinja2 3.1.4\n- jiter 0.5.0\n- jmespath 1.0.1\n- joblib 1.4.2\n- jsonpatch 1.33\n- jsonpointer 2.4\n- jsonrpcclient 4.0.3\n- jsonschema 4.22.0\n- jsonschema-specifications 2023.12.1\n- julius 0.2.7\n- keyring 24.3.1\n- kiwisolver 1.4.5\n- kubernetes 29.0.0\n- langchain 0.1.13\n- langchain-community 0.0.29\n- langchain-core 0.1.52\n- langchain-experimental 0.0.55\n- langchain-text-splitters 0.0.2\n- langsmith 0.1.125\n- lazy-loader 0.4\n- libcst 1.1.0\n- librosa 0.10.2.post1\n- lightgbm 4.5.0\n- lightning 2.4.0\n- lightning-utilities 0.11.7\n- linkedin-api 2.3.0\n- lion-pytorch 0.2.2\n- litellm 1.51.0\n- llama-cloud 0.1.4\n- llama-index 0.11.20\n- llama-index-agent-openai 0.3.4\n- llama-index-cli 0.3.1\n- llama-index-core 0.11.21\n- llama-index-embeddings-openai 0.2.5\n- llama-index-indices-managed-llama-cloud 0.4.0\n- llama-index-legacy 0.9.48.post3\n- llama-index-llms-openai 0.2.16\n- llama-index-multi-modal-llms-openai 0.2.3\n- llama-index-program-openai 0.2.0\n- llama-index-question-gen-openai 0.2.0\n- llama-index-readers-file 0.2.2\n- llama-index-readers-llama-parse 0.3.0\n- llama-parse 0.5.12\n- llvmlite 0.43.0\n- local-attention 1.9.1\n- locket 1.0.0\n- loguru 0.7.2\n- looseversion 1.3.0\n- lxml 4.9.4\n- lxml-html-clean 0.2.2\n- mambabyte 0.0.2\n- markdown-it-py 3.0.0\n- marshmallow 3.22.0\n- marshmallow-enum 1.5.1\n- matplotlib 3.9.2\n- mccabe 0.7.0\n- mdformat 0.7.17\n- mdurl 0.1.2\n- medinsight 0.0.6\n- mergedeep 1.3.4\n- mermaid-py 0.6.0\n- mkdocs 1.6.0\n- mkdocs-get-deps 0.2.0\n- ml-dtypes 0.4.0\n- mlx 0.13.1\n- mmh3 4.1.0\n- monotonic 1.6\n- more-itertools 10.5.0\n- moviepy 1.0.3\n- mpmath 1.3.0\n- msgpack 1.0.8\n- multidict 6.0.5\n- multion 1.3.0\n- multiprocess 0.70.16\n- multitasking 0.0.11\n- multiurl 0.3.2\n- mutagen 1.47.0\n- mypy-extensions 1.0.0\n- nbformat 5.10.4\n- neo-sapiens 0.0.5\n- netcdf4 1.7.2\n- networkx 3.3\n- news-swarm 0.0.7\n- newsapi 0.1.1\n- newsapi-python 0.2.7\n- newspaper3k 0.2.8\n- nibabel 5.2.1\n- nipype 1.8.6\n- nltk 3.9.1\n- numba 0.60.0\n- numpy 1.26.4\n- oauthlib 3.2.2\n- ollama 0.3.3\n- omegaconf 2.3.0\n- onnxruntime 1.20.1\n- open-clip-torch 2.24.0\n- open-interpreter 0.4.3\n- openai 1.52.2\n- openbabel-wheel 3.1.1.20\n- opencv-python 4.9.0.80\n- opencv-python-headless 4.10.0.84\n- openpyxl 3.1.5\n- opentelemetry-api 1.24.0\n- opentelemetry-exporter-otlp-proto-common 1.24.0\n- opentelemetry-exporter-otlp-proto-grpc 1.24.0\n- opentelemetry-exporter-otlp-proto-http 1.26.0\n- opentelemetry-instrumentation 0.45b0\n- opentelemetry-instrumentation-asgi 0.45b0\n- opentelemetry-instrumentation-fastapi 0.45b0\n- opentelemetry-proto 1.24.0\n- opentelemetry-sdk 1.24.0\n- opentelemetry-semantic-conventions 0.45b0\n- opentelemetry-util-http 0.45b0\n- opt-einsum 3.3.0\n- optimum 1.22.0\n- optuna 4.0.0\n- ordered-set 4.1.0\n- orjson 3.10.12\n- outcome 1.3.0.post0\n- overrides 7.7.0\n- packaging 23.2\n- panda3d 1.10.15\n- pandas 2.2.2\n- partd 1.4.2\n- parver 0.5\n- pathlib 1.0.1\n- pathos 0.3.2\n- pathspec 0.12.1\n- pdbeccdutils 0.8.5\n- peewee 3.17.6\n- peft 0.13.1\n- pendulum 3.0.0\n- phenaki-pytorch 0.4.2\n- pillow 10.4.0\n- pinecone 4.0.0\n- pip 24.1.2\n- pkginfo 1.11.1\n- platformdirs 4.2.2\n- plotly 5.24.0\n- pluggy 1.5.0\n- poetry 1.8.3\n- poetry-core 1.9.0\n- poetry-plugin-export 1.8.0\n- polars 1.6.0\n- polygon 1.2.5\n- pooch 1.8.2\n- postgrest 0.16.11\n- posthog 3.5.0\n- pox 0.3.4\n- ppft 1.7.6.8\n- prettytable 3.10.0\n- primepy 1.3\n- proglog 0.1.10\n- prometheus-client 0.21.0\n- proto-plus 1.24.0\n- protobuf 4.25.3\n- prov 2.0.1\n- psutil 5.9.8\n- pulsar-client 3.5.0\n- pulumi 3.136.2a1728475416\n- pulumi-gcp 8.5.0\n- py3dmol 2.4.2\n- py-cpuinfo 9.0.0\n- pyannote.audio 3.1.1\n- pyannote.core 5.0.0\n- pyannote.database 5.1.0\n- pyannote.metrics 3.2.1\n- pyannote.pipeline 3.0.1\n- pyarrow 16.1.0\n- pyarrow-hotfix 0.6\n- pyasn1 0.6.0\n- pyasn1-modules 0.4.0\n- pybind11 2.13.6\n- pycocotools 2.0.8\n- pycodestyle 2.11.1\n- pycoingecko 3.1.0\n- pycparser 2.22\n- pycryptodomex 3.20.0\n- pydantic 2.8.2\n- pydantic-core 2.20.1\n- pydantic-settings 2.4.0\n- pydeck 0.9.1\n- pydot 3.0.1\n- pydub 0.25.1\n- pyflakes 3.2.0\n- pygame 2.6.0\n- pyglet 1.5.29\n- pygments 2.18.0\n- pymongo 4.7.3\n- pyobjc 10.3.1\n- pyparsing 3.1.2\n- pypdf 4.3.1\n- pypdf2 3.0.1\n- pyperclip 1.9.0\n- pypng 0.20220715.0\n- pyproj 3.7.0\n- pyproject-hooks 1.1.0\n- pyrate-limiter 3.7.0\n- pytesseract 0.3.13\n- pytest 8.2.2\n- python-dateutil 2.9.0.post0\n- python-docx 1.1.2\n- python-dotenv 1.0.1\n- python-magic 0.4.27\n- python-multipart 0.0.9\n- python-pptx 1.0.2\n- pytorch-lightning 2.4.0\n- pytorch-metric-learning 2.6.0\n- pytube 15.0.0\n- pytweening 1.2.0\n- pytz 2024.1\n- pyxnat 1.6.2\n- pyyaml-env-tag 0.1\n- qrcode 7.4.2\n- rapidfuzz 3.9.7\n- ratelimit 2.2.1\n- ray 2.34.0\n- rdflib 6.3.2\n- rdkit 2024.3.5\n- readchar 4.2.0\n- realtime 2.0.2\n- redis 5.1.1\n- referencing 0.35.1\n- regex 2024.5.15\n- reportlab 4.2.5\n- requests 2.32.3\n- requests-file 2.1.0\n- requests-futures 1.0.1\n- requests-oauthlib 1.3.1\n- requests-toolbelt 1.0.0\n- retrying 1.3.4\n- rich 13.9.4\n- ring-attention-pytorch 0.4.1\n- rotary-embedding-torch 0.8.3\n- rpds-py 0.18.1\n- rsa 4.7.2\n- ruamel.yaml 0.18.6\n- ruamel.yaml.clib 0.2.8\n- rubicon-objc 0.4.9\n- ruff 0.6.4\n- runs 1.2.2\n- s3transfer 0.10.1\n- safetensors 0.4.3\n- schedule 1.2.2\n- schema 0.7.7\n- scikit-learn 1.5.1\n- scipy 1.14.1\n- seaborn 0.13.2\n- sec-edgar-api 1.1.0\n- sec-edgar-downloader 5.0.2\n- selenium 4.25.0\n- semantic-version 2.10.0\n- semver 3.0.2\n- sentence-transformers 3.0.1\n- sentencepiece 0.2.0\n- sentinelhub 3.11.1\n- sentry-sdk 2.14.0\n- setproctitle 1.3.3\n- setuptools 75.6.0\n- sgmllib3k 1.0.0\n- sh 2.0.7\n- shapely 2.0.6\n- shellingham 1.5.4\n- shortuuid 1.0.13\n- simplejson 3.19.2\n- simsimd 6.1.1\n- six 1.16.0\n- skypilot 0.6.1\n- smmap 5.0.1\n- sniffio 1.3.1\n- sortedcontainers 2.4.0\n- sounddevice 0.4.7\n- soundfile 0.12.1\n- soupsieve 2.5\n- soxr 0.5.0.post1\n- speechbrain 1.0.1\n- spotipy 2.24.0\n- sse-starlette 2.0.0\n- stable-baselines3 2.3.2\n- starlette 0.41.3\n- storage3 0.7.7\n- streamlit 1.35.0\n- stringcase 1.2.0\n- stringzilla 3.10.10\n- stripe 9.12.0\n- striprtf 0.0.26\n- structlog 24.4.0\n- supabase 2.7.3\n- supafunc 0.5.1\n- supervision 0.18.0\n- swarm-models 0.1.3\n- swarms 6.3.0\n- swarms-cloud 0.4.4\n- swarms-memory 0.1.2\n- sympy 1.13.1\n- ta-lib 0.5.0\n- tabulate 0.9.0\n- tavily-python 0.3.3\n- taylor-series-linear-attention 0.1.12\n- tenacity 8.5.0\n- tensorboard 2.17.1\n- tensorboardx 2.6.2.2\n- tensorboard-data-server 0.7.2\n- termcolor 2.4.0\n- textblob 0.18.0.post0\n- thop 0.1.1.post2209072238\n- threadpoolctl 3.5.0\n- tickr-agent 0.1.0\n- tifffile 2024.9.20\n- tiktoken 0.7.0\n- time-machine 2.14.1\n- timeout-decorator 0.5.0\n- timm 1.0.3\n- tinysegmenter 0.3\n- tldextract 5.1.2\n- together 1.3.1\n- tokenizers 0.20.2\n- tokentrim 0.1.13\n- toml 0.10.2\n- tomli 2.1.0\n- tomli-w 1.1.0\n- tomlkit 0.12.0\n- toolz 0.12.1\n- torch 2.5.1\n- torch-audiomentations 0.11.1\n- torch-geometric 2.5.3\n- torch-pitch-shift 1.2.5\n- torchao 0.6.1\n- torchaudio 2.4.0\n- torchmetrics 1.4.1\n- torchtyping 0.1.5\n- torchvision 0.20.1\n- tornado 6.4.1\n- tqdm 4.66.4\n- traits 6.3.2\n- transformers 4.44.0\n- transformers-stream-generator 0.0.5\n- tree-of-thoughts 0.6.3\n- trimesh 4.4.9\n- trio 0.26.0\n- trio-websocket 0.11.1\n- trove-classifiers 2024.7.2\n- tweepy 4.14.0\n- typeguard 2.13.3\n- typer 0.12.5\n- types-protobuf 5.26.0.20240422\n- typing 3.7.4.3\n- typing-extensions 4.12.2\n- typing-inspect 0.9.0\n- tzdata 2024.1\n- ujson 5.10.0\n- ultralytics 8.3.36\n- ultralytics-thop 2.0.12\n- uritemplate 4.1.1\n- urllib3 1.26.20\n- utm 0.7.0\n- uuid 1.30\n- uvicorn 0.29.0\n- uvloop 0.19.0\n- validators 0.19.0\n- vector-quantize-pytorch 1.14.7\n- virtualenv 20.26.4\n- wandb 0.18.5\n- watchdog 4.0.1\n- watchfiles 0.21.0\n- wcwidth 0.2.13\n- weaviate 0.1.2\n- weaviate-client 3.15.4\n- webdriver-manager 4.0.2\n- webencodings 0.5.1\n- websocket-client 1.8.0\n- websockets 12.0\n- werkzeug 3.0.3\n- wget 3.2\n- wheel 0.43.0\n- whisperx 3.1.2\n- wrapt 1.16.0\n- wsproto 1.2.0\n- x-transformers 1.30.2\n- xarray 2024.10.0\n- xattr 1.1.0\n- xgboost 2.1.1\n- xmod 1.8.1\n- xxhash 3.4.1\n- yahooquery 2.3.7\n- yarl 1.9.4\n- yaspin 3.1.0\n- yfinance 0.2.43\n- yt-dlp 2024.10.22\n- zetascale 2.6.2\n- zipp 3.18.2\n- zmq 0.0.0\n- zope.interface 7.1.1\n- -ransformers 4.42.3\n- autocommand 2.2.2\n- backports.tarfile 1.2.0\n- inflect 7.3.1\n- jaraco.collections 5.1.0\n- jaraco.context 5.3.0\n- jaraco.functools 4.0.1\n- jaraco.text 3.12.1\n\n        ## Time of Occurrence\n        2024-12-17T10:09:09.851478\n\n        ---\n        *This issue was automatically generated by SwarmsIssueReporter*",
      "state": "closed",
      "author": "kyegomez",
      "author_type": "User",
      "created_at": "2024-12-17T18:09:10Z",
      "updated_at": "2025-03-20T16:24:50Z",
      "closed_at": "2025-01-09T20:28:18Z",
      "labels": [
        "bug",
        "automated",
        "severity:medium",
        "priority:high"
      ],
      "label_count": 4,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/688/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/688",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/688",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:14.488974",
      "comments": [
        {
          "author": "patrickbdevaney",
          "body": "> ```\r\n>     ## Swarms Error Report\r\n>     - **Error Type**: ValueError\r\n>     - **Error Message**: test\r\n>     - **Swarms Version**: Unknown\r\n> \r\n>     ## Environment Information\r\n>     - **OS**: Darwin Darwin Kernel Version 23.3.0: Wed Dec 20 21:30:59 PST 2023; root:xnu-10002.81.5~7/RELEASE_ARM64_",
          "created_at": "2024-12-23T20:45:06Z"
        }
      ]
    },
    {
      "issue_number": 687,
      "title": "[Agent: Test-Agent] [ValueError] test",
      "body": "\n        \n        ```## Swarms Error Report\n\n        - Error Type: ValueError\n\n        - Error Message: test\n\n        - Swarms Version: Unknown\n\n        ## Environment Information\n\n        - OS: Darwin Darwin Kernel Version 23.3.0: Wed Dec 20 21:30:59 PST 2023; root:xnu-10002.81.5~7/RELEASE_ARM64_T6030\n\n        - Python Version: 3.12.3 (v3.12.3:f6650f9ad7, Apr  9 2024, 08:18:47) [Clang 13.0.0 (clang-1300.0.29.30)]\n\n        - CUDA Available: False\n\n        - GPU: N/A\n\n        - CPU Usage: 31.1%\n\n        - Memory Usage: 83.9%\n\n        - Disk Usage: 7.4%\n\n        ## Stack Trace\n\n        ```python\n\n        Traceback (most recent call last):\n  File \"/Users/swarms_wd/Desktop/swarms/auto_test_eval.py\", line 338, in <module>\n    raise ValueError(\"test\")\nValueError: test\n\n\n        ```\n\n        ## Context\n\n        ```json\n\n        {\n  \"task\": \"test_run\",\n  \"agent_name\": \"Test-Agent\",\n  \"agent_description\": null,\n  \"max_loops\": 1,\n  \"context_length\": 8192\n}\n\n        ```\n\n        ## Dependencies\n\n        - appnope 0.1.4\n- asttokens 2.4.1\n- comm 0.2.2\n- executing 2.0.1\n- ipykernel 6.29.4\n- ipython 8.25.0\n- jedi 0.19.1\n- jupyter-client 8.6.2\n- jupyter-core 5.7.2\n- matplotlib-inline 0.1.7\n- nest-asyncio 1.6.0\n- parso 0.8.4\n- pexpect 4.9.0\n- prompt-toolkit 3.0.47\n- ptyprocess 0.7.0\n- pure-eval 0.2.2\n- pyzmq 26.0.3\n- stack-data 0.6.3\n- traitlets 5.14.3\n- arpeggio 2.0.2\n- authlib 1.3.2\n- brotli 1.1.0\n- cantera 3.0.1\n- colt5-attention 0.11.1\n- datetime 5.5\n- deprecated 1.2.14\n- faker 30.8.2\n- farama-notifications 0.0.4\n- gputil 1.4.0\n- gitpython 3.1.43\n- hyperpyyaml 1.2.2\n- mako 1.3.5\n- markdown 3.6\n- markupsafe 2.1.5\n- mouseinfo 0.1.3\n- pulp 2.8.0\n- pyaudio 0.2.14\n- pyautogui 0.9.54\n- pygetwindow 0.0.9\n- pymsgbox 1.0.9\n- pypika 0.48.9\n- pyrect 0.2.0\n- pyscreeze 1.0.1\n- pysocks 1.7.1\n- pyyaml 6.0.2\n- sqlalchemy 2.0.30\n- send2trash 1.8.3\n- strenum 0.4.15\n- torchfix 0.5.0\n- xlsxwriter 3.2.0\n- absl-py 2.1.0\n- accelerate 0.33.0\n- adam-atan2-pytorch 0.0.12\n- aenum 3.1.15\n- agentops 0.2.3\n- agentparse 0.0.3\n- ai21 2.7.0\n- ai21-tokenizer 0.11.2\n- ai-lang 0.0.4\n- aiocache 0.12.3\n- aiofiles 24.1.0\n- aiohappyeyeballs 2.3.7\n- aiohttp 3.10.4\n- aiosignal 1.3.1\n- albucore 0.0.20\n- albumentations 1.4.21\n- alembic 1.13.3\n- alpha-vantage 3.0.0\n- alphafold3-pytorch 0.4.53\n- altair 5.3.0\n- annotated-types 0.7.0\n- anthropic 0.37.1\n- antlr4-python3-runtime 4.9.3\n- anyio 4.4.0\n- anytree 2.12.1\n- argparse 1.4.0\n- asgiref 3.8.1\n- asteroid-filterbanks 0.4.0\n- astor 0.8.1\n- asyncio 3.4.3\n- attrs 24.2.0\n- audioread 3.0.1\n- av 12.3.0\n- awscli 1.32.116\n- backoff 2.2.1\n- bcrypt 4.1.3\n- beartype 0.17.2\n- beautifulsoup4 4.12.3\n- biopython 1.84\n- bitsandbytes 0.42.0\n- black 24.8.0\n- blessed 1.20.0\n- blinker 1.8.2\n- boto3 1.34.116\n- botocore 1.34.116\n- bs4 0.0.2\n- build 1.2.1\n- cachecontrol 0.14.0\n- cachetools 5.3.3\n- cadquery 2.3.0\n- cads-api-client 1.5.2\n- cdsapi 0.7.4\n- certifi 2024.2.2\n- cffi 1.16.0\n- cfgrib 0.9.14.1\n- cftime 1.6.4.post1\n- chardet 5.2.0\n- charset-normalizer 3.3.2\n- chroma-hnswlib 0.7.6\n- chromadb 0.5.20\n- ci-info 0.3.0\n- classifier-free-guidance-pytorch 0.5.3\n- cleo 2.1.0\n- click 8.1.7\n- cloudpickle 3.0.0\n- clusterops 0.1.2\n- code-guardian 0.1.4\n- colorama 0.4.4\n- coloredlogs 15.0.1\n- colorlog 6.8.2\n- configobj 5.0.8\n- configparser 7.0.0\n- contourpy 1.2.1\n- crashtest 0.4.1\n- cryptoagent 0.1.0\n- cryptography 42.0.7\n- cssselect 1.2.0\n- ctranslate2 4.4.0\n- cycler 0.12.1\n- dask 2024.11.0\n- dataclasses-json 0.6.6\n- datasets 2.19.1\n- debugpy 1.8.6\n- decorator 5.1.1\n- defusedxml 0.7.1\n- deprecation 2.1.0\n- diffusers 0.30.2\n- dill 0.3.8\n- dirtyjson 1.0.8\n- diskcache 5.6.3\n- distlib 0.3.8\n- distro 1.9.0\n- dnspython 2.6.1\n- doc-master 0.0.2\n- docker 7.1.0\n- docker-pycreds 0.4.0\n- docopt 0.6.2\n- docstring-parser 0.16\n- docutils 0.16\n- docx 0.2.4\n- dulwich 0.21.7\n- e2b 0.17.1\n- e2b-code-interpreter 0.0.10\n- eccodes 2.38.3\n- editor 1.6.6\n- einops 0.8.0\n- einops-exts 0.0.4\n- einx 0.2.2\n- ema-pytorch 0.6.2\n- email-validator 2.1.1\n- environs 11.0.0\n- et-xmlfile 1.1.0\n- etelemetry 0.3.1\n- eval-type-backport 0.2.0\n- exa-py 1.0.12\n- facenet-pytorch 2.6.0\n- faiss-cpu 1.8.0.post1\n- fastapi 0.115.5\n- fastapi-cli 0.0.4\n- faster-whisper 1.0.3\n- fastjsonschema 2.20.0\n- feedfinder2 0.0.4\n- feedparser 6.0.11\n- ffmpy 0.4.0\n- ffn 1.1.0\n- filelock 3.14.0\n- findlibs 0.0.5\n- flake8 7.0.0\n- flash 1.0.3\n- flask 3.0.3\n- flatbuffers 24.3.25\n- fluid-api-agent 0.0.1\n- fonttools 4.51.0\n- fpdf 1.7.2\n- frame-averaging-pytorch 0.1.2\n- fredapi 0.5.2\n- frozendict 2.4.4\n- frozenlist 1.4.1\n- fsspec 2024.3.1\n- ftfy 6.2.0\n- gemmi 0.6.7\n- ghp-import 2.1.0\n- git-python 1.0.3\n- gitdb 4.0.11\n- google-ai-generativelanguage 0.6.6\n- google-api-core 2.19.1\n- google-api-python-client 2.139.0\n- google-auth 2.29.0\n- google-auth-httplib2 0.2.0\n- google-cloud-core 2.4.1\n- google-cloud-storage 2.18.0\n- google-crc32c 1.5.0\n- google-generativeai 0.7.2\n- google-resumable-media 2.7.1\n- googleapis-common-protos 1.63.0\n- gotrue 2.7.0\n- gradio 4.43.0\n- gradio-client 1.3.0\n- gradio-molecule3d 0.0.5\n- graphviz 0.20.3\n- greenlet 3.1.1\n- griptape 0.32.0\n- groq 0.8.0\n- grpcio 1.66.2\n- grpcio-status 1.62.3\n- guidance 0.1.16\n- gunicorn 22.0.0\n- gym 0.26.2\n- gym-notices 0.0.8\n- gymnasium 0.29.1\n- h11 0.14.0\n- h2 4.1.0\n- hf-transfer 0.1.8\n- hpack 4.0.0\n- html2image 2.0.5\n- html2text 2024.2.26\n- html5lib 1.1\n- httpcore 1.0.5\n- httplib2 0.22.0\n- httptools 0.6.1\n- httpx 0.27.0\n- httpx-sse 0.4.0\n- huggingface-hub 0.24.6\n- humanfriendly 10.0\n- hyperframe 6.0.1\n- idna 3.7\n- imageio 2.35.1\n- imageio-ffmpeg 0.5.1\n- importlib-metadata 7.0.0\n- importlib-resources 6.4.0\n- iniconfig 2.0.0\n- inquirer 3.4.0\n- instagrapi 2.1.2\n- install 1.3.5\n- installer 0.7.0\n- iotagents 0.0.1\n- isodate 0.6.1\n- itsdangerous 2.2.0\n- jaraco.classes 3.4.0\n- jax 0.4.31\n- jaxlib 0.4.31\n- jaxtyping 0.2.34\n- jieba3k 0.35.1\n- jinja2 3.1.4\n- jiter 0.5.0\n- jmespath 1.0.1\n- joblib 1.4.2\n- jsonpatch 1.33\n- jsonpointer 2.4\n- jsonrpcclient 4.0.3\n- jsonschema 4.22.0\n- jsonschema-specifications 2023.12.1\n- julius 0.2.7\n- keyring 24.3.1\n- kiwisolver 1.4.5\n- kubernetes 29.0.0\n- langchain 0.1.13\n- langchain-community 0.0.29\n- langchain-core 0.1.52\n- langchain-experimental 0.0.55\n- langchain-text-splitters 0.0.2\n- langsmith 0.1.125\n- lazy-loader 0.4\n- libcst 1.1.0\n- librosa 0.10.2.post1\n- lightgbm 4.5.0\n- lightning 2.4.0\n- lightning-utilities 0.11.7\n- linkedin-api 2.3.0\n- lion-pytorch 0.2.2\n- litellm 1.51.0\n- llama-cloud 0.1.4\n- llama-index 0.11.20\n- llama-index-agent-openai 0.3.4\n- llama-index-cli 0.3.1\n- llama-index-core 0.11.21\n- llama-index-embeddings-openai 0.2.5\n- llama-index-indices-managed-llama-cloud 0.4.0\n- llama-index-legacy 0.9.48.post3\n- llama-index-llms-openai 0.2.16\n- llama-index-multi-modal-llms-openai 0.2.3\n- llama-index-program-openai 0.2.0\n- llama-index-question-gen-openai 0.2.0\n- llama-index-readers-file 0.2.2\n- llama-index-readers-llama-parse 0.3.0\n- llama-parse 0.5.12\n- llvmlite 0.43.0\n- local-attention 1.9.1\n- locket 1.0.0\n- loguru 0.7.2\n- looseversion 1.3.0\n- lxml 4.9.4\n- lxml-html-clean 0.2.2\n- mambabyte 0.0.2\n- markdown-it-py 3.0.0\n- marshmallow 3.22.0\n- marshmallow-enum 1.5.1\n- matplotlib 3.9.2\n- mccabe 0.7.0\n- mdformat 0.7.17\n- mdurl 0.1.2\n- medinsight 0.0.6\n- mergedeep 1.3.4\n- mermaid-py 0.6.0\n- mkdocs 1.6.0\n- mkdocs-get-deps 0.2.0\n- ml-dtypes 0.4.0\n- mlx 0.13.1\n- mmh3 4.1.0\n- monotonic 1.6\n- more-itertools 10.5.0\n- moviepy 1.0.3\n- mpmath 1.3.0\n- msgpack 1.0.8\n- multidict 6.0.5\n- multion 1.3.0\n- multiprocess 0.70.16\n- multitasking 0.0.11\n- multiurl 0.3.2\n- mutagen 1.47.0\n- mypy-extensions 1.0.0\n- nbformat 5.10.4\n- neo-sapiens 0.0.5\n- netcdf4 1.7.2\n- networkx 3.3\n- news-swarm 0.0.7\n- newsapi 0.1.1\n- newsapi-python 0.2.7\n- newspaper3k 0.2.8\n- nibabel 5.2.1\n- nipype 1.8.6\n- nltk 3.9.1\n- numba 0.60.0\n- numpy 1.26.4\n- oauthlib 3.2.2\n- ollama 0.3.3\n- omegaconf 2.3.0\n- onnxruntime 1.20.1\n- open-clip-torch 2.24.0\n- open-interpreter 0.4.3\n- openai 1.52.2\n- openbabel-wheel 3.1.1.20\n- opencv-python 4.9.0.80\n- opencv-python-headless 4.10.0.84\n- openpyxl 3.1.5\n- opentelemetry-api 1.24.0\n- opentelemetry-exporter-otlp-proto-common 1.24.0\n- opentelemetry-exporter-otlp-proto-grpc 1.24.0\n- opentelemetry-exporter-otlp-proto-http 1.26.0\n- opentelemetry-instrumentation 0.45b0\n- opentelemetry-instrumentation-asgi 0.45b0\n- opentelemetry-instrumentation-fastapi 0.45b0\n- opentelemetry-proto 1.24.0\n- opentelemetry-sdk 1.24.0\n- opentelemetry-semantic-conventions 0.45b0\n- opentelemetry-util-http 0.45b0\n- opt-einsum 3.3.0\n- optimum 1.22.0\n- optuna 4.0.0\n- ordered-set 4.1.0\n- orjson 3.10.12\n- outcome 1.3.0.post0\n- overrides 7.7.0\n- packaging 23.2\n- panda3d 1.10.15\n- pandas 2.2.2\n- partd 1.4.2\n- parver 0.5\n- pathlib 1.0.1\n- pathos 0.3.2\n- pathspec 0.12.1\n- pdbeccdutils 0.8.5\n- peewee 3.17.6\n- peft 0.13.1\n- pendulum 3.0.0\n- phenaki-pytorch 0.4.2\n- pillow 10.4.0\n- pinecone 4.0.0\n- pip 24.1.2\n- pkginfo 1.11.1\n- platformdirs 4.2.2\n- plotly 5.24.0\n- pluggy 1.5.0\n- poetry 1.8.3\n- poetry-core 1.9.0\n- poetry-plugin-export 1.8.0\n- polars 1.6.0\n- polygon 1.2.5\n- pooch 1.8.2\n- postgrest 0.16.11\n- posthog 3.5.0\n- pox 0.3.4\n- ppft 1.7.6.8\n- prettytable 3.10.0\n- primepy 1.3\n- proglog 0.1.10\n- prometheus-client 0.21.0\n- proto-plus 1.24.0\n- protobuf 4.25.3\n- prov 2.0.1\n- psutil 5.9.8\n- pulsar-client 3.5.0\n- pulumi 3.136.2a1728475416\n- pulumi-gcp 8.5.0\n- py3dmol 2.4.2\n- py-cpuinfo 9.0.0\n- pyannote.audio 3.1.1\n- pyannote.core 5.0.0\n- pyannote.database 5.1.0\n- pyannote.metrics 3.2.1\n- pyannote.pipeline 3.0.1\n- pyarrow 16.1.0\n- pyarrow-hotfix 0.6\n- pyasn1 0.6.0\n- pyasn1-modules 0.4.0\n- pybind11 2.13.6\n- pycocotools 2.0.8\n- pycodestyle 2.11.1\n- pycoingecko 3.1.0\n- pycparser 2.22\n- pycryptodomex 3.20.0\n- pydantic 2.8.2\n- pydantic-core 2.20.1\n- pydantic-settings 2.4.0\n- pydeck 0.9.1\n- pydot 3.0.1\n- pydub 0.25.1\n- pyflakes 3.2.0\n- pygame 2.6.0\n- pyglet 1.5.29\n- pygments 2.18.0\n- pymongo 4.7.3\n- pyobjc 10.3.1\n- pyparsing 3.1.2\n- pypdf 4.3.1\n- pypdf2 3.0.1\n- pyperclip 1.9.0\n- pypng 0.20220715.0\n- pyproj 3.7.0\n- pyproject-hooks 1.1.0\n- pyrate-limiter 3.7.0\n- pytesseract 0.3.13\n- pytest 8.2.2\n- python-dateutil 2.9.0.post0\n- python-docx 1.1.2\n- python-dotenv 1.0.1\n- python-magic 0.4.27\n- python-multipart 0.0.9\n- python-pptx 1.0.2\n- pytorch-lightning 2.4.0\n- pytorch-metric-learning 2.6.0\n- pytube 15.0.0\n- pytweening 1.2.0\n- pytz 2024.1\n- pyxnat 1.6.2\n- pyyaml-env-tag 0.1\n- qrcode 7.4.2\n- rapidfuzz 3.9.7\n- ratelimit 2.2.1\n- ray 2.34.0\n- rdflib 6.3.2\n- rdkit 2024.3.5\n- readchar 4.2.0\n- realtime 2.0.2\n- redis 5.1.1\n- referencing 0.35.1\n- regex 2024.5.15\n- reportlab 4.2.5\n- requests 2.32.3\n- requests-file 2.1.0\n- requests-futures 1.0.1\n- requests-oauthlib 1.3.1\n- requests-toolbelt 1.0.0\n- retrying 1.3.4\n- rich 13.9.4\n- ring-attention-pytorch 0.4.1\n- rotary-embedding-torch 0.8.3\n- rpds-py 0.18.1\n- rsa 4.7.2\n- ruamel.yaml 0.18.6\n- ruamel.yaml.clib 0.2.8\n- rubicon-objc 0.4.9\n- ruff 0.6.4\n- runs 1.2.2\n- s3transfer 0.10.1\n- safetensors 0.4.3\n- schedule 1.2.2\n- schema 0.7.7\n- scikit-learn 1.5.1\n- scipy 1.14.1\n- seaborn 0.13.2\n- sec-edgar-api 1.1.0\n- sec-edgar-downloader 5.0.2\n- selenium 4.25.0\n- semantic-version 2.10.0\n- semver 3.0.2\n- sentence-transformers 3.0.1\n- sentencepiece 0.2.0\n- sentinelhub 3.11.1\n- sentry-sdk 2.14.0\n- setproctitle 1.3.3\n- setuptools 75.6.0\n- sgmllib3k 1.0.0\n- sh 2.0.7\n- shapely 2.0.6\n- shellingham 1.5.4\n- shortuuid 1.0.13\n- simplejson 3.19.2\n- simsimd 6.1.1\n- six 1.16.0\n- skypilot 0.6.1\n- smmap 5.0.1\n- sniffio 1.3.1\n- sortedcontainers 2.4.0\n- sounddevice 0.4.7\n- soundfile 0.12.1\n- soupsieve 2.5\n- soxr 0.5.0.post1\n- speechbrain 1.0.1\n- spotipy 2.24.0\n- sse-starlette 2.0.0\n- stable-baselines3 2.3.2\n- starlette 0.41.3\n- storage3 0.7.7\n- streamlit 1.35.0\n- stringcase 1.2.0\n- stringzilla 3.10.10\n- stripe 9.12.0\n- striprtf 0.0.26\n- structlog 24.4.0\n- supabase 2.7.3\n- supafunc 0.5.1\n- supervision 0.18.0\n- swarm-models 0.1.3\n- swarms 6.3.0\n- swarms-cloud 0.4.4\n- swarms-memory 0.1.2\n- sympy 1.13.1\n- ta-lib 0.5.0\n- tabulate 0.9.0\n- tavily-python 0.3.3\n- taylor-series-linear-attention 0.1.12\n- tenacity 8.5.0\n- tensorboard 2.17.1\n- tensorboardx 2.6.2.2\n- tensorboard-data-server 0.7.2\n- termcolor 2.4.0\n- textblob 0.18.0.post0\n- thop 0.1.1.post2209072238\n- threadpoolctl 3.5.0\n- tickr-agent 0.1.0\n- tifffile 2024.9.20\n- tiktoken 0.7.0\n- time-machine 2.14.1\n- timeout-decorator 0.5.0\n- timm 1.0.3\n- tinysegmenter 0.3\n- tldextract 5.1.2\n- together 1.3.1\n- tokenizers 0.20.2\n- tokentrim 0.1.13\n- toml 0.10.2\n- tomli 2.1.0\n- tomli-w 1.1.0\n- tomlkit 0.12.0\n- toolz 0.12.1\n- torch 2.5.1\n- torch-audiomentations 0.11.1\n- torch-geometric 2.5.3\n- torch-pitch-shift 1.2.5\n- torchao 0.6.1\n- torchaudio 2.4.0\n- torchmetrics 1.4.1\n- torchtyping 0.1.5\n- torchvision 0.20.1\n- tornado 6.4.1\n- tqdm 4.66.4\n- traits 6.3.2\n- transformers 4.44.0\n- transformers-stream-generator 0.0.5\n- tree-of-thoughts 0.6.3\n- trimesh 4.4.9\n- trio 0.26.0\n- trio-websocket 0.11.1\n- trove-classifiers 2024.7.2\n- tweepy 4.14.0\n- typeguard 2.13.3\n- typer 0.12.5\n- types-protobuf 5.26.0.20240422\n- typing 3.7.4.3\n- typing-extensions 4.12.2\n- typing-inspect 0.9.0\n- tzdata 2024.1\n- ujson 5.10.0\n- ultralytics 8.3.36\n- ultralytics-thop 2.0.12\n- uritemplate 4.1.1\n- urllib3 1.26.20\n- utm 0.7.0\n- uuid 1.30\n- uvicorn 0.29.0\n- uvloop 0.19.0\n- validators 0.19.0\n- vector-quantize-pytorch 1.14.7\n- virtualenv 20.26.4\n- wandb 0.18.5\n- watchdog 4.0.1\n- watchfiles 0.21.0\n- wcwidth 0.2.13\n- weaviate 0.1.2\n- weaviate-client 3.15.4\n- webdriver-manager 4.0.2\n- webencodings 0.5.1\n- websocket-client 1.8.0\n- websockets 12.0\n- werkzeug 3.0.3\n- wget 3.2\n- wheel 0.43.0\n- whisperx 3.1.2\n- wrapt 1.16.0\n- wsproto 1.2.0\n- x-transformers 1.30.2\n- xarray 2024.10.0\n- xattr 1.1.0\n- xgboost 2.1.1\n- xmod 1.8.1\n- xxhash 3.4.1\n- yahooquery 2.3.7\n- yarl 1.9.4\n- yaspin 3.1.0\n- yfinance 0.2.43\n- yt-dlp 2024.10.22\n- zetascale 2.6.2\n- zipp 3.18.2\n- zmq 0.0.0\n- zope.interface 7.1.1\n- -ransformers 4.42.3\n- autocommand 2.2.2\n- backports.tarfile 1.2.0\n- inflect 7.3.1\n- jaraco.collections 5.1.0\n- jaraco.context 5.3.0\n- jaraco.functools 4.0.1\n- jaraco.text 3.12.1\n\n        ## Time of Occurrence\n\n        2024-12-16T20:45:58.675052\n\n        ---\n\n        This issue was automatically generated by SwarmsIssueReporter\n        ```",
      "state": "closed",
      "author": "kyegomez",
      "author_type": "User",
      "created_at": "2024-12-17T04:45:59Z",
      "updated_at": "2025-03-20T16:24:50Z",
      "closed_at": "2025-01-09T20:28:26Z",
      "labels": [
        "bug",
        "automated",
        "severity:medium",
        "priority:high"
      ],
      "label_count": 4,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/687/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/687",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/687",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:14.914805",
      "comments": []
    },
    {
      "issue_number": 686,
      "title": "[Agent: Test-Agent] [ValueError] test",
      "body": "\n        \n        ## Swarms Error Report\n\n        - Error Type: ValueError\n\n        - Error Message: test\n\n        - Swarms Version: Unknown\n\n        ## Environment Information\n\n        - OS: Darwin Darwin Kernel Version 23.3.0: Wed Dec 20 21:30:59 PST 2023; root:xnu-10002.81.5~7/RELEASE_ARM64_T6030\n\n        - Python Version: 3.12.3 (v3.12.3:f6650f9ad7, Apr  9 2024, 08:18:47) [Clang 13.0.0 (clang-1300.0.29.30)]\n\n        - CUDA Available: False\n\n        - GPU: N/A\n\n        - CPU Usage: 39.9%\n\n        - Memory Usage: 82.1%\n\n        - Disk Usage: 7.4%\n\n        ## Stack Trace\n\n        ```python\n\n        Traceback (most recent call last):\n  File \"/Users/swarms_wd/Desktop/swarms/auto_test_eval.py\", line 337, in <module>\n    raise ValueError(\"test\")\nValueError: test\n\n\n        ```\n\n        ## Context\n\n        ```json\n\n        {\n  \"task\": \"test_run\",\n  \"agent_name\": \"Test-Agent\",\n  \"agent_description\": null,\n  \"max_loops\": 1,\n  \"context_length\": 8192\n}\n\n        ```\n\n        ## Dependencies\n\n        - appnope 0.1.4\n- asttokens 2.4.1\n- comm 0.2.2\n- executing 2.0.1\n- ipykernel 6.29.4\n- ipython 8.25.0\n- jedi 0.19.1\n- jupyter-client 8.6.2\n- jupyter-core 5.7.2\n- matplotlib-inline 0.1.7\n- nest-asyncio 1.6.0\n- parso 0.8.4\n- pexpect 4.9.0\n- prompt-toolkit 3.0.47\n- ptyprocess 0.7.0\n- pure-eval 0.2.2\n- pyzmq 26.0.3\n- stack-data 0.6.3\n- traitlets 5.14.3\n- arpeggio 2.0.2\n- authlib 1.3.2\n- brotli 1.1.0\n- cantera 3.0.1\n- colt5-attention 0.11.1\n- datetime 5.5\n- deprecated 1.2.14\n- faker 30.8.2\n- farama-notifications 0.0.4\n- gputil 1.4.0\n- gitpython 3.1.43\n- hyperpyyaml 1.2.2\n- mako 1.3.5\n- markdown 3.6\n- markupsafe 2.1.5\n- mouseinfo 0.1.3\n- pulp 2.8.0\n- pyaudio 0.2.14\n- pyautogui 0.9.54\n- pygetwindow 0.0.9\n- pymsgbox 1.0.9\n- pypika 0.48.9\n- pyrect 0.2.0\n- pyscreeze 1.0.1\n- pysocks 1.7.1\n- pyyaml 6.0.2\n- sqlalchemy 2.0.30\n- send2trash 1.8.3\n- strenum 0.4.15\n- torchfix 0.5.0\n- xlsxwriter 3.2.0\n- absl-py 2.1.0\n- accelerate 0.33.0\n- adam-atan2-pytorch 0.0.12\n- aenum 3.1.15\n- agentops 0.2.3\n- agentparse 0.0.3\n- ai21 2.7.0\n- ai21-tokenizer 0.11.2\n- ai-lang 0.0.4\n- aiocache 0.12.3\n- aiofiles 24.1.0\n- aiohappyeyeballs 2.3.7\n- aiohttp 3.10.4\n- aiosignal 1.3.1\n- albucore 0.0.20\n- albumentations 1.4.21\n- alembic 1.13.3\n- alpha-vantage 3.0.0\n- alphafold3-pytorch 0.4.53\n- altair 5.3.0\n- annotated-types 0.7.0\n- anthropic 0.37.1\n- antlr4-python3-runtime 4.9.3\n- anyio 4.4.0\n- anytree 2.12.1\n- argparse 1.4.0\n- asgiref 3.8.1\n- asteroid-filterbanks 0.4.0\n- astor 0.8.1\n- asyncio 3.4.3\n- attrs 24.2.0\n- audioread 3.0.1\n- av 12.3.0\n- awscli 1.32.116\n- backoff 2.2.1\n- bcrypt 4.1.3\n- beartype 0.17.2\n- beautifulsoup4 4.12.3\n- biopython 1.84\n- bitsandbytes 0.42.0\n- black 24.8.0\n- blessed 1.20.0\n- blinker 1.8.2\n- boto3 1.34.116\n- botocore 1.34.116\n- bs4 0.0.2\n- build 1.2.1\n- cachecontrol 0.14.0\n- cachetools 5.3.3\n- cadquery 2.3.0\n- cads-api-client 1.5.2\n- cdsapi 0.7.4\n- certifi 2024.2.2\n- cffi 1.16.0\n- cfgrib 0.9.14.1\n- cftime 1.6.4.post1\n- chardet 5.2.0\n- charset-normalizer 3.3.2\n- chroma-hnswlib 0.7.6\n- chromadb 0.5.20\n- ci-info 0.3.0\n- classifier-free-guidance-pytorch 0.5.3\n- cleo 2.1.0\n- click 8.1.7\n- cloudpickle 3.0.0\n- clusterops 0.1.2\n- code-guardian 0.1.4\n- colorama 0.4.4\n- coloredlogs 15.0.1\n- colorlog 6.8.2\n- configobj 5.0.8\n- configparser 7.0.0\n- contourpy 1.2.1\n- crashtest 0.4.1\n- cryptoagent 0.1.0\n- cryptography 42.0.7\n- cssselect 1.2.0\n- ctranslate2 4.4.0\n- cycler 0.12.1\n- dask 2024.11.0\n- dataclasses-json 0.6.6\n- datasets 2.19.1\n- debugpy 1.8.6\n- decorator 5.1.1\n- defusedxml 0.7.1\n- deprecation 2.1.0\n- diffusers 0.30.2\n- dill 0.3.8\n- dirtyjson 1.0.8\n- diskcache 5.6.3\n- distlib 0.3.8\n- distro 1.9.0\n- dnspython 2.6.1\n- doc-master 0.0.2\n- docker 7.1.0\n- docker-pycreds 0.4.0\n- docopt 0.6.2\n- docstring-parser 0.16\n- docutils 0.16\n- docx 0.2.4\n- dulwich 0.21.7\n- e2b 0.17.1\n- e2b-code-interpreter 0.0.10\n- eccodes 2.38.3\n- editor 1.6.6\n- einops 0.8.0\n- einops-exts 0.0.4\n- einx 0.2.2\n- ema-pytorch 0.6.2\n- email-validator 2.1.1\n- environs 11.0.0\n- et-xmlfile 1.1.0\n- etelemetry 0.3.1\n- eval-type-backport 0.2.0\n- exa-py 1.0.12\n- facenet-pytorch 2.6.0\n- faiss-cpu 1.8.0.post1\n- fastapi 0.115.5\n- fastapi-cli 0.0.4\n- faster-whisper 1.0.3\n- fastjsonschema 2.20.0\n- feedfinder2 0.0.4\n- feedparser 6.0.11\n- ffmpy 0.4.0\n- ffn 1.1.0\n- filelock 3.14.0\n- findlibs 0.0.5\n- flake8 7.0.0\n- flash 1.0.3\n- flask 3.0.3\n- flatbuffers 24.3.25\n- fluid-api-agent 0.0.1\n- fonttools 4.51.0\n- fpdf 1.7.2\n- frame-averaging-pytorch 0.1.2\n- fredapi 0.5.2\n- frozendict 2.4.4\n- frozenlist 1.4.1\n- fsspec 2024.3.1\n- ftfy 6.2.0\n- gemmi 0.6.7\n- ghp-import 2.1.0\n- git-python 1.0.3\n- gitdb 4.0.11\n- google-ai-generativelanguage 0.6.6\n- google-api-core 2.19.1\n- google-api-python-client 2.139.0\n- google-auth 2.29.0\n- google-auth-httplib2 0.2.0\n- google-cloud-core 2.4.1\n- google-cloud-storage 2.18.0\n- google-crc32c 1.5.0\n- google-generativeai 0.7.2\n- google-resumable-media 2.7.1\n- googleapis-common-protos 1.63.0\n- gotrue 2.7.0\n- gradio 4.43.0\n- gradio-client 1.3.0\n- gradio-molecule3d 0.0.5\n- graphviz 0.20.3\n- greenlet 3.1.1\n- griptape 0.32.0\n- groq 0.8.0\n- grpcio 1.66.2\n- grpcio-status 1.62.3\n- guidance 0.1.16\n- gunicorn 22.0.0\n- gym 0.26.2\n- gym-notices 0.0.8\n- gymnasium 0.29.1\n- h11 0.14.0\n- h2 4.1.0\n- hf-transfer 0.1.8\n- hpack 4.0.0\n- html2image 2.0.5\n- html2text 2024.2.26\n- html5lib 1.1\n- httpcore 1.0.5\n- httplib2 0.22.0\n- httptools 0.6.1\n- httpx 0.27.0\n- httpx-sse 0.4.0\n- huggingface-hub 0.24.6\n- humanfriendly 10.0\n- hyperframe 6.0.1\n- idna 3.7\n- imageio 2.35.1\n- imageio-ffmpeg 0.5.1\n- importlib-metadata 7.0.0\n- importlib-resources 6.4.0\n- iniconfig 2.0.0\n- inquirer 3.4.0\n- instagrapi 2.1.2\n- install 1.3.5\n- installer 0.7.0\n- iotagents 0.0.1\n- isodate 0.6.1\n- itsdangerous 2.2.0\n- jaraco.classes 3.4.0\n- jax 0.4.31\n- jaxlib 0.4.31\n- jaxtyping 0.2.34\n- jieba3k 0.35.1\n- jinja2 3.1.4\n- jiter 0.5.0\n- jmespath 1.0.1\n- joblib 1.4.2\n- jsonpatch 1.33\n- jsonpointer 2.4\n- jsonrpcclient 4.0.3\n- jsonschema 4.22.0\n- jsonschema-specifications 2023.12.1\n- julius 0.2.7\n- keyring 24.3.1\n- kiwisolver 1.4.5\n- kubernetes 29.0.0\n- langchain 0.1.13\n- langchain-community 0.0.29\n- langchain-core 0.1.52\n- langchain-experimental 0.0.55\n- langchain-text-splitters 0.0.2\n- langsmith 0.1.125\n- lazy-loader 0.4\n- libcst 1.1.0\n- librosa 0.10.2.post1\n- lightgbm 4.5.0\n- lightning 2.4.0\n- lightning-utilities 0.11.7\n- linkedin-api 2.3.0\n- lion-pytorch 0.2.2\n- litellm 1.51.0\n- llama-cloud 0.1.4\n- llama-index 0.11.20\n- llama-index-agent-openai 0.3.4\n- llama-index-cli 0.3.1\n- llama-index-core 0.11.21\n- llama-index-embeddings-openai 0.2.5\n- llama-index-indices-managed-llama-cloud 0.4.0\n- llama-index-legacy 0.9.48.post3\n- llama-index-llms-openai 0.2.16\n- llama-index-multi-modal-llms-openai 0.2.3\n- llama-index-program-openai 0.2.0\n- llama-index-question-gen-openai 0.2.0\n- llama-index-readers-file 0.2.2\n- llama-index-readers-llama-parse 0.3.0\n- llama-parse 0.5.12\n- llvmlite 0.43.0\n- local-attention 1.9.1\n- locket 1.0.0\n- loguru 0.7.2\n- looseversion 1.3.0\n- lxml 4.9.4\n- lxml-html-clean 0.2.2\n- mambabyte 0.0.2\n- markdown-it-py 3.0.0\n- marshmallow 3.22.0\n- marshmallow-enum 1.5.1\n- matplotlib 3.9.2\n- mccabe 0.7.0\n- mdformat 0.7.17\n- mdurl 0.1.2\n- medinsight 0.0.6\n- mergedeep 1.3.4\n- mermaid-py 0.6.0\n- mkdocs 1.6.0\n- mkdocs-get-deps 0.2.0\n- ml-dtypes 0.4.0\n- mlx 0.13.1\n- mmh3 4.1.0\n- monotonic 1.6\n- more-itertools 10.5.0\n- moviepy 1.0.3\n- mpmath 1.3.0\n- msgpack 1.0.8\n- multidict 6.0.5\n- multion 1.3.0\n- multiprocess 0.70.16\n- multitasking 0.0.11\n- multiurl 0.3.2\n- mutagen 1.47.0\n- mypy-extensions 1.0.0\n- nbformat 5.10.4\n- neo-sapiens 0.0.5\n- netcdf4 1.7.2\n- networkx 3.3\n- news-swarm 0.0.7\n- newsapi 0.1.1\n- newsapi-python 0.2.7\n- newspaper3k 0.2.8\n- nibabel 5.2.1\n- nipype 1.8.6\n- nltk 3.9.1\n- numba 0.60.0\n- numpy 1.26.4\n- oauthlib 3.2.2\n- ollama 0.3.3\n- omegaconf 2.3.0\n- onnxruntime 1.20.1\n- open-clip-torch 2.24.0\n- open-interpreter 0.4.3\n- openai 1.52.2\n- openbabel-wheel 3.1.1.20\n- opencv-python 4.9.0.80\n- opencv-python-headless 4.10.0.84\n- openpyxl 3.1.5\n- opentelemetry-api 1.24.0\n- opentelemetry-exporter-otlp-proto-common 1.24.0\n- opentelemetry-exporter-otlp-proto-grpc 1.24.0\n- opentelemetry-exporter-otlp-proto-http 1.26.0\n- opentelemetry-instrumentation 0.45b0\n- opentelemetry-instrumentation-asgi 0.45b0\n- opentelemetry-instrumentation-fastapi 0.45b0\n- opentelemetry-proto 1.24.0\n- opentelemetry-sdk 1.24.0\n- opentelemetry-semantic-conventions 0.45b0\n- opentelemetry-util-http 0.45b0\n- opt-einsum 3.3.0\n- optimum 1.22.0\n- optuna 4.0.0\n- ordered-set 4.1.0\n- orjson 3.10.12\n- outcome 1.3.0.post0\n- overrides 7.7.0\n- packaging 23.2\n- panda3d 1.10.15\n- pandas 2.2.2\n- partd 1.4.2\n- parver 0.5\n- pathlib 1.0.1\n- pathos 0.3.2\n- pathspec 0.12.1\n- pdbeccdutils 0.8.5\n- peewee 3.17.6\n- peft 0.13.1\n- pendulum 3.0.0\n- phenaki-pytorch 0.4.2\n- pillow 10.4.0\n- pinecone 4.0.0\n- pip 24.1.2\n- pkginfo 1.11.1\n- platformdirs 4.2.2\n- plotly 5.24.0\n- pluggy 1.5.0\n- poetry 1.8.3\n- poetry-core 1.9.0\n- poetry-plugin-export 1.8.0\n- polars 1.6.0\n- polygon 1.2.5\n- pooch 1.8.2\n- postgrest 0.16.11\n- posthog 3.5.0\n- pox 0.3.4\n- ppft 1.7.6.8\n- prettytable 3.10.0\n- primepy 1.3\n- proglog 0.1.10\n- prometheus-client 0.21.0\n- proto-plus 1.24.0\n- protobuf 4.25.3\n- prov 2.0.1\n- psutil 5.9.8\n- pulsar-client 3.5.0\n- pulumi 3.136.2a1728475416\n- pulumi-gcp 8.5.0\n- py3dmol 2.4.2\n- py-cpuinfo 9.0.0\n- pyannote.audio 3.1.1\n- pyannote.core 5.0.0\n- pyannote.database 5.1.0\n- pyannote.metrics 3.2.1\n- pyannote.pipeline 3.0.1\n- pyarrow 16.1.0\n- pyarrow-hotfix 0.6\n- pyasn1 0.6.0\n- pyasn1-modules 0.4.0\n- pybind11 2.13.6\n- pycocotools 2.0.8\n- pycodestyle 2.11.1\n- pycoingecko 3.1.0\n- pycparser 2.22\n- pycryptodomex 3.20.0\n- pydantic 2.8.2\n- pydantic-core 2.20.1\n- pydantic-settings 2.4.0\n- pydeck 0.9.1\n- pydot 3.0.1\n- pydub 0.25.1\n- pyflakes 3.2.0\n- pygame 2.6.0\n- pyglet 1.5.29\n- pygments 2.18.0\n- pymongo 4.7.3\n- pyobjc 10.3.1\n- pyparsing 3.1.2\n- pypdf 4.3.1\n- pypdf2 3.0.1\n- pyperclip 1.9.0\n- pypng 0.20220715.0\n- pyproj 3.7.0\n- pyproject-hooks 1.1.0\n- pyrate-limiter 3.7.0\n- pytesseract 0.3.13\n- pytest 8.2.2\n- python-dateutil 2.9.0.post0\n- python-docx 1.1.2\n- python-dotenv 1.0.1\n- python-magic 0.4.27\n- python-multipart 0.0.9\n- python-pptx 1.0.2\n- pytorch-lightning 2.4.0\n- pytorch-metric-learning 2.6.0\n- pytube 15.0.0\n- pytweening 1.2.0\n- pytz 2024.1\n- pyxnat 1.6.2\n- pyyaml-env-tag 0.1\n- qrcode 7.4.2\n- rapidfuzz 3.9.7\n- ratelimit 2.2.1\n- ray 2.34.0\n- rdflib 6.3.2\n- rdkit 2024.3.5\n- readchar 4.2.0\n- realtime 2.0.2\n- redis 5.1.1\n- referencing 0.35.1\n- regex 2024.5.15\n- reportlab 4.2.5\n- requests 2.32.3\n- requests-file 2.1.0\n- requests-futures 1.0.1\n- requests-oauthlib 1.3.1\n- requests-toolbelt 1.0.0\n- retrying 1.3.4\n- rich 13.9.4\n- ring-attention-pytorch 0.4.1\n- rotary-embedding-torch 0.8.3\n- rpds-py 0.18.1\n- rsa 4.7.2\n- ruamel.yaml 0.18.6\n- ruamel.yaml.clib 0.2.8\n- rubicon-objc 0.4.9\n- ruff 0.6.4\n- runs 1.2.2\n- s3transfer 0.10.1\n- safetensors 0.4.3\n- schedule 1.2.2\n- schema 0.7.7\n- scikit-learn 1.5.1\n- scipy 1.14.1\n- seaborn 0.13.2\n- sec-edgar-api 1.1.0\n- sec-edgar-downloader 5.0.2\n- selenium 4.25.0\n- semantic-version 2.10.0\n- semver 3.0.2\n- sentence-transformers 3.0.1\n- sentencepiece 0.2.0\n- sentinelhub 3.11.1\n- sentry-sdk 2.14.0\n- setproctitle 1.3.3\n- setuptools 75.6.0\n- sgmllib3k 1.0.0\n- sh 2.0.7\n- shapely 2.0.6\n- shellingham 1.5.4\n- shortuuid 1.0.13\n- simplejson 3.19.2\n- simsimd 6.1.1\n- six 1.16.0\n- skypilot 0.6.1\n- smmap 5.0.1\n- sniffio 1.3.1\n- sortedcontainers 2.4.0\n- sounddevice 0.4.7\n- soundfile 0.12.1\n- soupsieve 2.5\n- soxr 0.5.0.post1\n- speechbrain 1.0.1\n- spotipy 2.24.0\n- sse-starlette 2.0.0\n- stable-baselines3 2.3.2\n- starlette 0.41.3\n- storage3 0.7.7\n- streamlit 1.35.0\n- stringcase 1.2.0\n- stringzilla 3.10.10\n- stripe 9.12.0\n- striprtf 0.0.26\n- structlog 24.4.0\n- supabase 2.7.3\n- supafunc 0.5.1\n- supervision 0.18.0\n- swarm-models 0.1.3\n- swarms 6.3.0\n- swarms-cloud 0.4.4\n- swarms-memory 0.1.2\n- sympy 1.13.1\n- ta-lib 0.5.0\n- tabulate 0.9.0\n- tavily-python 0.3.3\n- taylor-series-linear-attention 0.1.12\n- tenacity 8.5.0\n- tensorboard 2.17.1\n- tensorboardx 2.6.2.2\n- tensorboard-data-server 0.7.2\n- termcolor 2.4.0\n- textblob 0.18.0.post0\n- thop 0.1.1.post2209072238\n- threadpoolctl 3.5.0\n- tickr-agent 0.1.0\n- tifffile 2024.9.20\n- tiktoken 0.7.0\n- time-machine 2.14.1\n- timeout-decorator 0.5.0\n- timm 1.0.3\n- tinysegmenter 0.3\n- tldextract 5.1.2\n- together 1.3.1\n- tokenizers 0.20.2\n- tokentrim 0.1.13\n- toml 0.10.2\n- tomli 2.1.0\n- tomli-w 1.1.0\n- tomlkit 0.12.0\n- toolz 0.12.1\n- torch 2.5.1\n- torch-audiomentations 0.11.1\n- torch-geometric 2.5.3\n- torch-pitch-shift 1.2.5\n- torchao 0.6.1\n- torchaudio 2.4.0\n- torchmetrics 1.4.1\n- torchtyping 0.1.5\n- torchvision 0.20.1\n- tornado 6.4.1\n- tqdm 4.66.4\n- traits 6.3.2\n- transformers 4.44.0\n- transformers-stream-generator 0.0.5\n- tree-of-thoughts 0.6.3\n- trimesh 4.4.9\n- trio 0.26.0\n- trio-websocket 0.11.1\n- trove-classifiers 2024.7.2\n- tweepy 4.14.0\n- typeguard 2.13.3\n- typer 0.12.5\n- types-protobuf 5.26.0.20240422\n- typing 3.7.4.3\n- typing-extensions 4.12.2\n- typing-inspect 0.9.0\n- tzdata 2024.1\n- ujson 5.10.0\n- ultralytics 8.3.36\n- ultralytics-thop 2.0.12\n- uritemplate 4.1.1\n- urllib3 1.26.20\n- utm 0.7.0\n- uuid 1.30\n- uvicorn 0.29.0\n- uvloop 0.19.0\n- validators 0.19.0\n- vector-quantize-pytorch 1.14.7\n- virtualenv 20.26.4\n- wandb 0.18.5\n- watchdog 4.0.1\n- watchfiles 0.21.0\n- wcwidth 0.2.13\n- weaviate 0.1.2\n- weaviate-client 3.15.4\n- webdriver-manager 4.0.2\n- webencodings 0.5.1\n- websocket-client 1.8.0\n- websockets 12.0\n- werkzeug 3.0.3\n- wget 3.2\n- wheel 0.43.0\n- whisperx 3.1.2\n- wrapt 1.16.0\n- wsproto 1.2.0\n- x-transformers 1.30.2\n- xarray 2024.10.0\n- xattr 1.1.0\n- xgboost 2.1.1\n- xmod 1.8.1\n- xxhash 3.4.1\n- yahooquery 2.3.7\n- yarl 1.9.4\n- yaspin 3.1.0\n- yfinance 0.2.43\n- yt-dlp 2024.10.22\n- zetascale 2.6.2\n- zipp 3.18.2\n- zmq 0.0.0\n- zope.interface 7.1.1\n- -ransformers 4.42.3\n- autocommand 2.2.2\n- backports.tarfile 1.2.0\n- inflect 7.3.1\n- jaraco.collections 5.1.0\n- jaraco.context 5.3.0\n- jaraco.functools 4.0.1\n- jaraco.text 3.12.1\n\n        ## Time of Occurrence\n\n        2024-12-16T20:44:57.896920\n\n        ---\n\n        This issue was automatically generated by SwarmsIssueReporter",
      "state": "closed",
      "author": "kyegomez",
      "author_type": "User",
      "created_at": "2024-12-17T04:44:58Z",
      "updated_at": "2025-03-20T16:24:49Z",
      "closed_at": "2025-01-09T20:28:34Z",
      "labels": [
        "bug",
        "automated",
        "severity:medium",
        "priority:high"
      ],
      "label_count": 4,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/686/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/686",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/686",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:14.914830",
      "comments": []
    },
    {
      "issue_number": 685,
      "title": "[Agent: Test-Agent] [ValueError] test",
      "body": "\n        ## Swarms Error Report\n        - **Error Type**: ValueError\n        - **Error Message**: test\n        - **Swarms Version**: Unknown\n\n        ## Environment Information\n        - **OS**: Darwin Darwin Kernel Version 23.3.0: Wed Dec 20 21:30:59 PST 2023; root:xnu-10002.81.5~7/RELEASE_ARM64_T6030\n        - **Python Version**: 3.12.3 (v3.12.3:f6650f9ad7, Apr  9 2024, 08:18:47) [Clang 13.0.0 (clang-1300.0.29.30)]\n        - **CUDA Available**: False\n        - **GPU**: N/A\n        - **CPU Usage**: 37.1%\n        - **Memory Usage**: 80.9%\n        - **Disk Usage**: 7.4%\n\n        ## Stack Trace\n        Traceback (most recent call last):\n  File \"/Users/swarms_wd/Desktop/swarms/auto_test_eval.py\", line 312, in <module>\n    raise ValueError(\"test\")\nValueError: test\n\n\n        ## Context\n        {\n  \"task\": \"test_run\",\n  \"agent_name\": \"Test-Agent\",\n  \"agent_description\": null,\n  \"max_loops\": 1,\n  \"context_length\": 8192\n}\n\n        ## Dependencies\n        - appnope 0.1.4\n- asttokens 2.4.1\n- comm 0.2.2\n- executing 2.0.1\n- ipykernel 6.29.4\n- ipython 8.25.0\n- jedi 0.19.1\n- jupyter-client 8.6.2\n- jupyter-core 5.7.2\n- matplotlib-inline 0.1.7\n- nest-asyncio 1.6.0\n- parso 0.8.4\n- pexpect 4.9.0\n- prompt-toolkit 3.0.47\n- ptyprocess 0.7.0\n- pure-eval 0.2.2\n- pyzmq 26.0.3\n- stack-data 0.6.3\n- traitlets 5.14.3\n- arpeggio 2.0.2\n- authlib 1.3.2\n- brotli 1.1.0\n- cantera 3.0.1\n- colt5-attention 0.11.1\n- datetime 5.5\n- deprecated 1.2.14\n- faker 30.8.2\n- farama-notifications 0.0.4\n- gputil 1.4.0\n- gitpython 3.1.43\n- hyperpyyaml 1.2.2\n- mako 1.3.5\n- markdown 3.6\n- markupsafe 2.1.5\n- mouseinfo 0.1.3\n- pulp 2.8.0\n- pyaudio 0.2.14\n- pyautogui 0.9.54\n- pygetwindow 0.0.9\n- pymsgbox 1.0.9\n- pypika 0.48.9\n- pyrect 0.2.0\n- pyscreeze 1.0.1\n- pysocks 1.7.1\n- pyyaml 6.0.2\n- sqlalchemy 2.0.30\n- send2trash 1.8.3\n- strenum 0.4.15\n- torchfix 0.5.0\n- xlsxwriter 3.2.0\n- absl-py 2.1.0\n- accelerate 0.33.0\n- adam-atan2-pytorch 0.0.12\n- aenum 3.1.15\n- agentops 0.2.3\n- agentparse 0.0.3\n- ai21 2.7.0\n- ai21-tokenizer 0.11.2\n- ai-lang 0.0.4\n- aiocache 0.12.3\n- aiofiles 24.1.0\n- aiohappyeyeballs 2.3.7\n- aiohttp 3.10.4\n- aiosignal 1.3.1\n- albucore 0.0.20\n- albumentations 1.4.21\n- alembic 1.13.3\n- alpha-vantage 3.0.0\n- alphafold3-pytorch 0.4.53\n- altair 5.3.0\n- annotated-types 0.7.0\n- anthropic 0.37.1\n- antlr4-python3-runtime 4.9.3\n- anyio 4.4.0\n- anytree 2.12.1\n- argparse 1.4.0\n- asgiref 3.8.1\n- asteroid-filterbanks 0.4.0\n- astor 0.8.1\n- asyncio 3.4.3\n- attrs 24.2.0\n- audioread 3.0.1\n- av 12.3.0\n- awscli 1.32.116\n- backoff 2.2.1\n- bcrypt 4.1.3\n- beartype 0.17.2\n- beautifulsoup4 4.12.3\n- biopython 1.84\n- bitsandbytes 0.42.0\n- black 24.8.0\n- blessed 1.20.0\n- blinker 1.8.2\n- boto3 1.34.116\n- botocore 1.34.116\n- bs4 0.0.2\n- build 1.2.1\n- cachecontrol 0.14.0\n- cachetools 5.3.3\n- cadquery 2.3.0\n- cads-api-client 1.5.2\n- cdsapi 0.7.4\n- certifi 2024.2.2\n- cffi 1.16.0\n- cfgrib 0.9.14.1\n- cftime 1.6.4.post1\n- chardet 5.2.0\n- charset-normalizer 3.3.2\n- chroma-hnswlib 0.7.6\n- chromadb 0.5.20\n- ci-info 0.3.0\n- classifier-free-guidance-pytorch 0.5.3\n- cleo 2.1.0\n- click 8.1.7\n- cloudpickle 3.0.0\n- clusterops 0.1.2\n- code-guardian 0.1.4\n- colorama 0.4.4\n- coloredlogs 15.0.1\n- colorlog 6.8.2\n- configobj 5.0.8\n- configparser 7.0.0\n- contourpy 1.2.1\n- crashtest 0.4.1\n- cryptoagent 0.1.0\n- cryptography 42.0.7\n- cssselect 1.2.0\n- ctranslate2 4.4.0\n- cycler 0.12.1\n- dask 2024.11.0\n- dataclasses-json 0.6.6\n- datasets 2.19.1\n- debugpy 1.8.6\n- decorator 5.1.1\n- defusedxml 0.7.1\n- deprecation 2.1.0\n- diffusers 0.30.2\n- dill 0.3.8\n- dirtyjson 1.0.8\n- diskcache 5.6.3\n- distlib 0.3.8\n- distro 1.9.0\n- dnspython 2.6.1\n- doc-master 0.0.2\n- docker 7.1.0\n- docker-pycreds 0.4.0\n- docopt 0.6.2\n- docstring-parser 0.16\n- docutils 0.16\n- docx 0.2.4\n- dulwich 0.21.7\n- e2b 0.17.1\n- e2b-code-interpreter 0.0.10\n- eccodes 2.38.3\n- editor 1.6.6\n- einops 0.8.0\n- einops-exts 0.0.4\n- einx 0.2.2\n- ema-pytorch 0.6.2\n- email-validator 2.1.1\n- environs 11.0.0\n- et-xmlfile 1.1.0\n- etelemetry 0.3.1\n- eval-type-backport 0.2.0\n- exa-py 1.0.12\n- facenet-pytorch 2.6.0\n- faiss-cpu 1.8.0.post1\n- fastapi 0.115.5\n- fastapi-cli 0.0.4\n- faster-whisper 1.0.3\n- fastjsonschema 2.20.0\n- feedfinder2 0.0.4\n- feedparser 6.0.11\n- ffmpy 0.4.0\n- ffn 1.1.0\n- filelock 3.14.0\n- findlibs 0.0.5\n- flake8 7.0.0\n- flash 1.0.3\n- flask 3.0.3\n- flatbuffers 24.3.25\n- fluid-api-agent 0.0.1\n- fonttools 4.51.0\n- fpdf 1.7.2\n- frame-averaging-pytorch 0.1.2\n- fredapi 0.5.2\n- frozendict 2.4.4\n- frozenlist 1.4.1\n- fsspec 2024.3.1\n- ftfy 6.2.0\n- gemmi 0.6.7\n- ghp-import 2.1.0\n- git-python 1.0.3\n- gitdb 4.0.11\n- google-ai-generativelanguage 0.6.6\n- google-api-core 2.19.1\n- google-api-python-client 2.139.0\n- google-auth 2.29.0\n- google-auth-httplib2 0.2.0\n- google-cloud-core 2.4.1\n- google-cloud-storage 2.18.0\n- google-crc32c 1.5.0\n- google-generativeai 0.7.2\n- google-resumable-media 2.7.1\n- googleapis-common-protos 1.63.0\n- gotrue 2.7.0\n- gradio 4.43.0\n- gradio-client 1.3.0\n- gradio-molecule3d 0.0.5\n- graphviz 0.20.3\n- greenlet 3.1.1\n- griptape 0.32.0\n- groq 0.8.0\n- grpcio 1.66.2\n- grpcio-status 1.62.3\n- guidance 0.1.16\n- gunicorn 22.0.0\n- gym 0.26.2\n- gym-notices 0.0.8\n- gymnasium 0.29.1\n- h11 0.14.0\n- h2 4.1.0\n- hf-transfer 0.1.8\n- hpack 4.0.0\n- html2image 2.0.5\n- html2text 2024.2.26\n- html5lib 1.1\n- httpcore 1.0.5\n- httplib2 0.22.0\n- httptools 0.6.1\n- httpx 0.27.0\n- httpx-sse 0.4.0\n- huggingface-hub 0.24.6\n- humanfriendly 10.0\n- hyperframe 6.0.1\n- idna 3.7\n- imageio 2.35.1\n- imageio-ffmpeg 0.5.1\n- importlib-metadata 7.0.0\n- importlib-resources 6.4.0\n- iniconfig 2.0.0\n- inquirer 3.4.0\n- instagrapi 2.1.2\n- install 1.3.5\n- installer 0.7.0\n- iotagents 0.0.1\n- isodate 0.6.1\n- itsdangerous 2.2.0\n- jaraco.classes 3.4.0\n- jax 0.4.31\n- jaxlib 0.4.31\n- jaxtyping 0.2.34\n- jieba3k 0.35.1\n- jinja2 3.1.4\n- jiter 0.5.0\n- jmespath 1.0.1\n- joblib 1.4.2\n- jsonpatch 1.33\n- jsonpointer 2.4\n- jsonrpcclient 4.0.3\n- jsonschema 4.22.0\n- jsonschema-specifications 2023.12.1\n- julius 0.2.7\n- keyring 24.3.1\n- kiwisolver 1.4.5\n- kubernetes 29.0.0\n- langchain 0.1.13\n- langchain-community 0.0.29\n- langchain-core 0.1.52\n- langchain-experimental 0.0.55\n- langchain-text-splitters 0.0.2\n- langsmith 0.1.125\n- lazy-loader 0.4\n- libcst 1.1.0\n- librosa 0.10.2.post1\n- lightgbm 4.5.0\n- lightning 2.4.0\n- lightning-utilities 0.11.7\n- linkedin-api 2.3.0\n- lion-pytorch 0.2.2\n- litellm 1.51.0\n- llama-cloud 0.1.4\n- llama-index 0.11.20\n- llama-index-agent-openai 0.3.4\n- llama-index-cli 0.3.1\n- llama-index-core 0.11.21\n- llama-index-embeddings-openai 0.2.5\n- llama-index-indices-managed-llama-cloud 0.4.0\n- llama-index-legacy 0.9.48.post3\n- llama-index-llms-openai 0.2.16\n- llama-index-multi-modal-llms-openai 0.2.3\n- llama-index-program-openai 0.2.0\n- llama-index-question-gen-openai 0.2.0\n- llama-index-readers-file 0.2.2\n- llama-index-readers-llama-parse 0.3.0\n- llama-parse 0.5.12\n- llvmlite 0.43.0\n- local-attention 1.9.1\n- locket 1.0.0\n- loguru 0.7.2\n- looseversion 1.3.0\n- lxml 4.9.4\n- lxml-html-clean 0.2.2\n- mambabyte 0.0.2\n- markdown-it-py 3.0.0\n- marshmallow 3.22.0\n- marshmallow-enum 1.5.1\n- matplotlib 3.9.2\n- mccabe 0.7.0\n- mdformat 0.7.17\n- mdurl 0.1.2\n- medinsight 0.0.6\n- mergedeep 1.3.4\n- mermaid-py 0.6.0\n- mkdocs 1.6.0\n- mkdocs-get-deps 0.2.0\n- ml-dtypes 0.4.0\n- mlx 0.13.1\n- mmh3 4.1.0\n- monotonic 1.6\n- more-itertools 10.5.0\n- moviepy 1.0.3\n- mpmath 1.3.0\n- msgpack 1.0.8\n- multidict 6.0.5\n- multion 1.3.0\n- multiprocess 0.70.16\n- multitasking 0.0.11\n- multiurl 0.3.2\n- mutagen 1.47.0\n- mypy-extensions 1.0.0\n- nbformat 5.10.4\n- neo-sapiens 0.0.5\n- netcdf4 1.7.2\n- networkx 3.3\n- news-swarm 0.0.7\n- newsapi 0.1.1\n- newsapi-python 0.2.7\n- newspaper3k 0.2.8\n- nibabel 5.2.1\n- nipype 1.8.6\n- nltk 3.9.1\n- numba 0.60.0\n- numpy 1.26.4\n- oauthlib 3.2.2\n- ollama 0.3.3\n- omegaconf 2.3.0\n- onnxruntime 1.20.1\n- open-clip-torch 2.24.0\n- open-interpreter 0.4.3\n- openai 1.52.2\n- openbabel-wheel 3.1.1.20\n- opencv-python 4.9.0.80\n- opencv-python-headless 4.10.0.84\n- openpyxl 3.1.5\n- opentelemetry-api 1.24.0\n- opentelemetry-exporter-otlp-proto-common 1.24.0\n- opentelemetry-exporter-otlp-proto-grpc 1.24.0\n- opentelemetry-exporter-otlp-proto-http 1.26.0\n- opentelemetry-instrumentation 0.45b0\n- opentelemetry-instrumentation-asgi 0.45b0\n- opentelemetry-instrumentation-fastapi 0.45b0\n- opentelemetry-proto 1.24.0\n- opentelemetry-sdk 1.24.0\n- opentelemetry-semantic-conventions 0.45b0\n- opentelemetry-util-http 0.45b0\n- opt-einsum 3.3.0\n- optimum 1.22.0\n- optuna 4.0.0\n- ordered-set 4.1.0\n- orjson 3.10.12\n- outcome 1.3.0.post0\n- overrides 7.7.0\n- packaging 23.2\n- panda3d 1.10.15\n- pandas 2.2.2\n- partd 1.4.2\n- parver 0.5\n- pathlib 1.0.1\n- pathos 0.3.2\n- pathspec 0.12.1\n- pdbeccdutils 0.8.5\n- peewee 3.17.6\n- peft 0.13.1\n- pendulum 3.0.0\n- phenaki-pytorch 0.4.2\n- pillow 10.4.0\n- pinecone 4.0.0\n- pip 24.1.2\n- pkginfo 1.11.1\n- platformdirs 4.2.2\n- plotly 5.24.0\n- pluggy 1.5.0\n- poetry 1.8.3\n- poetry-core 1.9.0\n- poetry-plugin-export 1.8.0\n- polars 1.6.0\n- polygon 1.2.5\n- pooch 1.8.2\n- postgrest 0.16.11\n- posthog 3.5.0\n- pox 0.3.4\n- ppft 1.7.6.8\n- prettytable 3.10.0\n- primepy 1.3\n- proglog 0.1.10\n- prometheus-client 0.21.0\n- proto-plus 1.24.0\n- protobuf 4.25.3\n- prov 2.0.1\n- psutil 5.9.8\n- pulsar-client 3.5.0\n- pulumi 3.136.2a1728475416\n- pulumi-gcp 8.5.0\n- py3dmol 2.4.2\n- py-cpuinfo 9.0.0\n- pyannote.audio 3.1.1\n- pyannote.core 5.0.0\n- pyannote.database 5.1.0\n- pyannote.metrics 3.2.1\n- pyannote.pipeline 3.0.1\n- pyarrow 16.1.0\n- pyarrow-hotfix 0.6\n- pyasn1 0.6.0\n- pyasn1-modules 0.4.0\n- pybind11 2.13.6\n- pycocotools 2.0.8\n- pycodestyle 2.11.1\n- pycoingecko 3.1.0\n- pycparser 2.22\n- pycryptodomex 3.20.0\n- pydantic 2.8.2\n- pydantic-core 2.20.1\n- pydantic-settings 2.4.0\n- pydeck 0.9.1\n- pydot 3.0.1\n- pydub 0.25.1\n- pyflakes 3.2.0\n- pygame 2.6.0\n- pyglet 1.5.29\n- pygments 2.18.0\n- pymongo 4.7.3\n- pyobjc 10.3.1\n- pyparsing 3.1.2\n- pypdf 4.3.1\n- pypdf2 3.0.1\n- pyperclip 1.9.0\n- pypng 0.20220715.0\n- pyproj 3.7.0\n- pyproject-hooks 1.1.0\n- pyrate-limiter 3.7.0\n- pytesseract 0.3.13\n- pytest 8.2.2\n- python-dateutil 2.9.0.post0\n- python-docx 1.1.2\n- python-dotenv 1.0.1\n- python-magic 0.4.27\n- python-multipart 0.0.9\n- python-pptx 1.0.2\n- pytorch-lightning 2.4.0\n- pytorch-metric-learning 2.6.0\n- pytube 15.0.0\n- pytweening 1.2.0\n- pytz 2024.1\n- pyxnat 1.6.2\n- pyyaml-env-tag 0.1\n- qrcode 7.4.2\n- rapidfuzz 3.9.7\n- ratelimit 2.2.1\n- ray 2.34.0\n- rdflib 6.3.2\n- rdkit 2024.3.5\n- readchar 4.2.0\n- realtime 2.0.2\n- redis 5.1.1\n- referencing 0.35.1\n- regex 2024.5.15\n- reportlab 4.2.5\n- requests 2.32.3\n- requests-file 2.1.0\n- requests-futures 1.0.1\n- requests-oauthlib 1.3.1\n- requests-toolbelt 1.0.0\n- retrying 1.3.4\n- rich 13.9.4\n- ring-attention-pytorch 0.4.1\n- rotary-embedding-torch 0.8.3\n- rpds-py 0.18.1\n- rsa 4.7.2\n- ruamel.yaml 0.18.6\n- ruamel.yaml.clib 0.2.8\n- rubicon-objc 0.4.9\n- ruff 0.6.4\n- runs 1.2.2\n- s3transfer 0.10.1\n- safetensors 0.4.3\n- schedule 1.2.2\n- schema 0.7.7\n- scikit-learn 1.5.1\n- scipy 1.14.1\n- seaborn 0.13.2\n- sec-edgar-api 1.1.0\n- sec-edgar-downloader 5.0.2\n- selenium 4.25.0\n- semantic-version 2.10.0\n- semver 3.0.2\n- sentence-transformers 3.0.1\n- sentencepiece 0.2.0\n- sentinelhub 3.11.1\n- sentry-sdk 2.14.0\n- setproctitle 1.3.3\n- setuptools 75.6.0\n- sgmllib3k 1.0.0\n- sh 2.0.7\n- shapely 2.0.6\n- shellingham 1.5.4\n- shortuuid 1.0.13\n- simplejson 3.19.2\n- simsimd 6.1.1\n- six 1.16.0\n- skypilot 0.6.1\n- smmap 5.0.1\n- sniffio 1.3.1\n- sortedcontainers 2.4.0\n- sounddevice 0.4.7\n- soundfile 0.12.1\n- soupsieve 2.5\n- soxr 0.5.0.post1\n- speechbrain 1.0.1\n- spotipy 2.24.0\n- sse-starlette 2.0.0\n- stable-baselines3 2.3.2\n- starlette 0.41.3\n- storage3 0.7.7\n- streamlit 1.35.0\n- stringcase 1.2.0\n- stringzilla 3.10.10\n- stripe 9.12.0\n- striprtf 0.0.26\n- structlog 24.4.0\n- supabase 2.7.3\n- supafunc 0.5.1\n- supervision 0.18.0\n- swarm-models 0.1.3\n- swarms 6.3.0\n- swarms-cloud 0.4.4\n- swarms-memory 0.1.2\n- sympy 1.13.1\n- ta-lib 0.5.0\n- tabulate 0.9.0\n- tavily-python 0.3.3\n- taylor-series-linear-attention 0.1.12\n- tenacity 8.5.0\n- tensorboard 2.17.1\n- tensorboardx 2.6.2.2\n- tensorboard-data-server 0.7.2\n- termcolor 2.4.0\n- textblob 0.18.0.post0\n- thop 0.1.1.post2209072238\n- threadpoolctl 3.5.0\n- tickr-agent 0.1.0\n- tifffile 2024.9.20\n- tiktoken 0.7.0\n- time-machine 2.14.1\n- timeout-decorator 0.5.0\n- timm 1.0.3\n- tinysegmenter 0.3\n- tldextract 5.1.2\n- together 1.3.1\n- tokenizers 0.20.2\n- tokentrim 0.1.13\n- toml 0.10.2\n- tomli 2.1.0\n- tomli-w 1.1.0\n- tomlkit 0.12.0\n- toolz 0.12.1\n- torch 2.5.1\n- torch-audiomentations 0.11.1\n- torch-geometric 2.5.3\n- torch-pitch-shift 1.2.5\n- torchao 0.6.1\n- torchaudio 2.4.0\n- torchmetrics 1.4.1\n- torchtyping 0.1.5\n- torchvision 0.20.1\n- tornado 6.4.1\n- tqdm 4.66.4\n- traits 6.3.2\n- transformers 4.44.0\n- transformers-stream-generator 0.0.5\n- tree-of-thoughts 0.6.3\n- trimesh 4.4.9\n- trio 0.26.0\n- trio-websocket 0.11.1\n- trove-classifiers 2024.7.2\n- tweepy 4.14.0\n- typeguard 2.13.3\n- typer 0.12.5\n- types-protobuf 5.26.0.20240422\n- typing 3.7.4.3\n- typing-extensions 4.12.2\n- typing-inspect 0.9.0\n- tzdata 2024.1\n- ujson 5.10.0\n- ultralytics 8.3.36\n- ultralytics-thop 2.0.12\n- uritemplate 4.1.1\n- urllib3 1.26.20\n- utm 0.7.0\n- uuid 1.30\n- uvicorn 0.29.0\n- uvloop 0.19.0\n- validators 0.19.0\n- vector-quantize-pytorch 1.14.7\n- virtualenv 20.26.4\n- wandb 0.18.5\n- watchdog 4.0.1\n- watchfiles 0.21.0\n- wcwidth 0.2.13\n- weaviate 0.1.2\n- weaviate-client 3.15.4\n- webdriver-manager 4.0.2\n- webencodings 0.5.1\n- websocket-client 1.8.0\n- websockets 12.0\n- werkzeug 3.0.3\n- wget 3.2\n- wheel 0.43.0\n- whisperx 3.1.2\n- wrapt 1.16.0\n- wsproto 1.2.0\n- x-transformers 1.30.2\n- xarray 2024.10.0\n- xattr 1.1.0\n- xgboost 2.1.1\n- xmod 1.8.1\n- xxhash 3.4.1\n- yahooquery 2.3.7\n- yarl 1.9.4\n- yaspin 3.1.0\n- yfinance 0.2.43\n- yt-dlp 2024.10.22\n- zetascale 2.6.2\n- zipp 3.18.2\n- zmq 0.0.0\n- zope.interface 7.1.1\n- -ransformers 4.42.3\n- autocommand 2.2.2\n- backports.tarfile 1.2.0\n- inflect 7.3.1\n- jaraco.collections 5.1.0\n- jaraco.context 5.3.0\n- jaraco.functools 4.0.1\n- jaraco.text 3.12.1\n\n        ## Time of Occurrence\n        2024-12-16T20:42:05.592000\n\n        ---\n        *This issue was automatically generated by SwarmsIssueReporter*",
      "state": "closed",
      "author": "kyegomez",
      "author_type": "User",
      "created_at": "2024-12-17T04:42:05Z",
      "updated_at": "2025-03-20T16:24:49Z",
      "closed_at": "2025-01-09T20:28:53Z",
      "labels": [
        "bug",
        "automated",
        "severity:medium",
        "priority:high"
      ],
      "label_count": 4,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/685/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/685",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/685",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:14.914838",
      "comments": []
    },
    {
      "issue_number": 684,
      "title": "[Agent: Test-Agent] [ValueError] test",
      "body": "\n        ## Swarms Error Report\n        - **Error Type**: ValueError\n        - **Error Message**: test\n        - **Swarms Version**: Unknown\n\n        ## Environment Information\n        - **OS**: Darwin Darwin Kernel Version 23.3.0: Wed Dec 20 21:30:59 PST 2023; root:xnu-10002.81.5~7/RELEASE_ARM64_T6030\n        - **Python Version**: 3.12.3 (v3.12.3:f6650f9ad7, Apr  9 2024, 08:18:47) [Clang 13.0.0 (clang-1300.0.29.30)]\n        - **CUDA Available**: False\n        - **GPU**: N/A\n        - **CPU Usage**: 28.5%\n        - **Memory Usage**: 83.7%\n        - **Disk Usage**: 7.4%\n\n        ## Stack Trace\n        ```\n        Traceback (most recent call last):\n  File \"/Users/swarms_wd/Desktop/swarms/auto_test_eval.py\", line 318, in <module>\n    raise ValueError(\"test\")\nValueError: test\n\n        ```\n\n        ## Context\n        ```\n        {\n  \"task\": \"test_run\",\n  \"agent_name\": \"Test-Agent\",\n  \"agent_description\": null,\n  \"max_loops\": 1,\n  \"context_length\": 8192\n}\n        ```\n\n        ## Dependencies\n        ```txt\n        - appnope 0.1.4\n- asttokens 2.4.1\n- comm 0.2.2\n- executing 2.0.1\n- ipykernel 6.29.4\n- ipython 8.25.0\n- jedi 0.19.1\n- jupyter-client 8.6.2\n- jupyter-core 5.7.2\n- matplotlib-inline 0.1.7\n- nest-asyncio 1.6.0\n- parso 0.8.4\n- pexpect 4.9.0\n- prompt-toolkit 3.0.47\n- ptyprocess 0.7.0\n- pure-eval 0.2.2\n- pyzmq 26.0.3\n- stack-data 0.6.3\n- traitlets 5.14.3\n- arpeggio 2.0.2\n- authlib 1.3.2\n- brotli 1.1.0\n- cantera 3.0.1\n- colt5-attention 0.11.1\n- datetime 5.5\n- deprecated 1.2.14\n- faker 30.8.2\n- farama-notifications 0.0.4\n- gputil 1.4.0\n- gitpython 3.1.43\n- hyperpyyaml 1.2.2\n- mako 1.3.5\n- markdown 3.6\n- markupsafe 2.1.5\n- mouseinfo 0.1.3\n- pulp 2.8.0\n- pyaudio 0.2.14\n- pyautogui 0.9.54\n- pygetwindow 0.0.9\n- pymsgbox 1.0.9\n- pypika 0.48.9\n- pyrect 0.2.0\n- pyscreeze 1.0.1\n- pysocks 1.7.1\n- pyyaml 6.0.2\n- sqlalchemy 2.0.30\n- send2trash 1.8.3\n- strenum 0.4.15\n- torchfix 0.5.0\n- xlsxwriter 3.2.0\n- absl-py 2.1.0\n- accelerate 0.33.0\n- adam-atan2-pytorch 0.0.12\n- aenum 3.1.15\n- agentops 0.2.3\n- agentparse 0.0.3\n- ai21 2.7.0\n- ai21-tokenizer 0.11.2\n- ai-lang 0.0.4\n- aiocache 0.12.3\n- aiofiles 24.1.0\n- aiohappyeyeballs 2.3.7\n- aiohttp 3.10.4\n- aiosignal 1.3.1\n- albucore 0.0.20\n- albumentations 1.4.21\n- alembic 1.13.3\n- alpha-vantage 3.0.0\n- alphafold3-pytorch 0.4.53\n- altair 5.3.0\n- annotated-types 0.7.0\n- anthropic 0.37.1\n- antlr4-python3-runtime 4.9.3\n- anyio 4.4.0\n- anytree 2.12.1\n- argparse 1.4.0\n- asgiref 3.8.1\n- asteroid-filterbanks 0.4.0\n- astor 0.8.1\n- asyncio 3.4.3\n- attrs 24.2.0\n- audioread 3.0.1\n- av 12.3.0\n- awscli 1.32.116\n- backoff 2.2.1\n- bcrypt 4.1.3\n- beartype 0.17.2\n- beautifulsoup4 4.12.3\n- biopython 1.84\n- bitsandbytes 0.42.0\n- black 24.8.0\n- blessed 1.20.0\n- blinker 1.8.2\n- boto3 1.34.116\n- botocore 1.34.116\n- bs4 0.0.2\n- build 1.2.1\n- cachecontrol 0.14.0\n- cachetools 5.3.3\n- cadquery 2.3.0\n- cads-api-client 1.5.2\n- cdsapi 0.7.4\n- certifi 2024.2.2\n- cffi 1.16.0\n- cfgrib 0.9.14.1\n- cftime 1.6.4.post1\n- chardet 5.2.0\n- charset-normalizer 3.3.2\n- chroma-hnswlib 0.7.6\n- chromadb 0.5.20\n- ci-info 0.3.0\n- classifier-free-guidance-pytorch 0.5.3\n- cleo 2.1.0\n- click 8.1.7\n- cloudpickle 3.0.0\n- clusterops 0.1.2\n- code-guardian 0.1.4\n- colorama 0.4.4\n- coloredlogs 15.0.1\n- colorlog 6.8.2\n- configobj 5.0.8\n- configparser 7.0.0\n- contourpy 1.2.1\n- crashtest 0.4.1\n- cryptoagent 0.1.0\n- cryptography 42.0.7\n- cssselect 1.2.0\n- ctranslate2 4.4.0\n- cycler 0.12.1\n- dask 2024.11.0\n- dataclasses-json 0.6.6\n- datasets 2.19.1\n- debugpy 1.8.6\n- decorator 5.1.1\n- defusedxml 0.7.1\n- deprecation 2.1.0\n- diffusers 0.30.2\n- dill 0.3.8\n- dirtyjson 1.0.8\n- diskcache 5.6.3\n- distlib 0.3.8\n- distro 1.9.0\n- dnspython 2.6.1\n- doc-master 0.0.2\n- docker 7.1.0\n- docker-pycreds 0.4.0\n- docopt 0.6.2\n- docstring-parser 0.16\n- docutils 0.16\n- docx 0.2.4\n- dulwich 0.21.7\n- e2b 0.17.1\n- e2b-code-interpreter 0.0.10\n- eccodes 2.38.3\n- editor 1.6.6\n- einops 0.8.0\n- einops-exts 0.0.4\n- einx 0.2.2\n- ema-pytorch 0.6.2\n- email-validator 2.1.1\n- environs 11.0.0\n- et-xmlfile 1.1.0\n- etelemetry 0.3.1\n- eval-type-backport 0.2.0\n- exa-py 1.0.12\n- facenet-pytorch 2.6.0\n- faiss-cpu 1.8.0.post1\n- fastapi 0.115.5\n- fastapi-cli 0.0.4\n- faster-whisper 1.0.3\n- fastjsonschema 2.20.0\n- feedfinder2 0.0.4\n- feedparser 6.0.11\n- ffmpy 0.4.0\n- ffn 1.1.0\n- filelock 3.14.0\n- findlibs 0.0.5\n- flake8 7.0.0\n- flash 1.0.3\n- flask 3.0.3\n- flatbuffers 24.3.25\n- fluid-api-agent 0.0.1\n- fonttools 4.51.0\n- fpdf 1.7.2\n- frame-averaging-pytorch 0.1.2\n- fredapi 0.5.2\n- frozendict 2.4.4\n- frozenlist 1.4.1\n- fsspec 2024.3.1\n- ftfy 6.2.0\n- gemmi 0.6.7\n- ghp-import 2.1.0\n- git-python 1.0.3\n- gitdb 4.0.11\n- google-ai-generativelanguage 0.6.6\n- google-api-core 2.19.1\n- google-api-python-client 2.139.0\n- google-auth 2.29.0\n- google-auth-httplib2 0.2.0\n- google-cloud-core 2.4.1\n- google-cloud-storage 2.18.0\n- google-crc32c 1.5.0\n- google-generativeai 0.7.2\n- google-resumable-media 2.7.1\n- googleapis-common-protos 1.63.0\n- gotrue 2.7.0\n- gradio 4.43.0\n- gradio-client 1.3.0\n- gradio-molecule3d 0.0.5\n- graphviz 0.20.3\n- greenlet 3.1.1\n- griptape 0.32.0\n- groq 0.8.0\n- grpcio 1.66.2\n- grpcio-status 1.62.3\n- guidance 0.1.16\n- gunicorn 22.0.0\n- gym 0.26.2\n- gym-notices 0.0.8\n- gymnasium 0.29.1\n- h11 0.14.0\n- h2 4.1.0\n- hf-transfer 0.1.8\n- hpack 4.0.0\n- html2image 2.0.5\n- html2text 2024.2.26\n- html5lib 1.1\n- httpcore 1.0.5\n- httplib2 0.22.0\n- httptools 0.6.1\n- httpx 0.27.0\n- httpx-sse 0.4.0\n- huggingface-hub 0.24.6\n- humanfriendly 10.0\n- hyperframe 6.0.1\n- idna 3.7\n- imageio 2.35.1\n- imageio-ffmpeg 0.5.1\n- importlib-metadata 7.0.0\n- importlib-resources 6.4.0\n- iniconfig 2.0.0\n- inquirer 3.4.0\n- instagrapi 2.1.2\n- install 1.3.5\n- installer 0.7.0\n- iotagents 0.0.1\n- isodate 0.6.1\n- itsdangerous 2.2.0\n- jaraco.classes 3.4.0\n- jax 0.4.31\n- jaxlib 0.4.31\n- jaxtyping 0.2.34\n- jieba3k 0.35.1\n- jinja2 3.1.4\n- jiter 0.5.0\n- jmespath 1.0.1\n- joblib 1.4.2\n- jsonpatch 1.33\n- jsonpointer 2.4\n- jsonrpcclient 4.0.3\n- jsonschema 4.22.0\n- jsonschema-specifications 2023.12.1\n- julius 0.2.7\n- keyring 24.3.1\n- kiwisolver 1.4.5\n- kubernetes 29.0.0\n- langchain 0.1.13\n- langchain-community 0.0.29\n- langchain-core 0.1.52\n- langchain-experimental 0.0.55\n- langchain-text-splitters 0.0.2\n- langsmith 0.1.125\n- lazy-loader 0.4\n- libcst 1.1.0\n- librosa 0.10.2.post1\n- lightgbm 4.5.0\n- lightning 2.4.0\n- lightning-utilities 0.11.7\n- linkedin-api 2.3.0\n- lion-pytorch 0.2.2\n- litellm 1.51.0\n- llama-cloud 0.1.4\n- llama-index 0.11.20\n- llama-index-agent-openai 0.3.4\n- llama-index-cli 0.3.1\n- llama-index-core 0.11.21\n- llama-index-embeddings-openai 0.2.5\n- llama-index-indices-managed-llama-cloud 0.4.0\n- llama-index-legacy 0.9.48.post3\n- llama-index-llms-openai 0.2.16\n- llama-index-multi-modal-llms-openai 0.2.3\n- llama-index-program-openai 0.2.0\n- llama-index-question-gen-openai 0.2.0\n- llama-index-readers-file 0.2.2\n- llama-index-readers-llama-parse 0.3.0\n- llama-parse 0.5.12\n- llvmlite 0.43.0\n- local-attention 1.9.1\n- locket 1.0.0\n- loguru 0.7.2\n- looseversion 1.3.0\n- lxml 4.9.4\n- lxml-html-clean 0.2.2\n- mambabyte 0.0.2\n- markdown-it-py 3.0.0\n- marshmallow 3.22.0\n- marshmallow-enum 1.5.1\n- matplotlib 3.9.2\n- mccabe 0.7.0\n- mdformat 0.7.17\n- mdurl 0.1.2\n- medinsight 0.0.6\n- mergedeep 1.3.4\n- mermaid-py 0.6.0\n- mkdocs 1.6.0\n- mkdocs-get-deps 0.2.0\n- ml-dtypes 0.4.0\n- mlx 0.13.1\n- mmh3 4.1.0\n- monotonic 1.6\n- more-itertools 10.5.0\n- moviepy 1.0.3\n- mpmath 1.3.0\n- msgpack 1.0.8\n- multidict 6.0.5\n- multion 1.3.0\n- multiprocess 0.70.16\n- multitasking 0.0.11\n- multiurl 0.3.2\n- mutagen 1.47.0\n- mypy-extensions 1.0.0\n- nbformat 5.10.4\n- neo-sapiens 0.0.5\n- netcdf4 1.7.2\n- networkx 3.3\n- news-swarm 0.0.7\n- newsapi 0.1.1\n- newsapi-python 0.2.7\n- newspaper3k 0.2.8\n- nibabel 5.2.1\n- nipype 1.8.6\n- nltk 3.9.1\n- numba 0.60.0\n- numpy 1.26.4\n- oauthlib 3.2.2\n- ollama 0.3.3\n- omegaconf 2.3.0\n- onnxruntime 1.20.1\n- open-clip-torch 2.24.0\n- open-interpreter 0.4.3\n- openai 1.52.2\n- openbabel-wheel 3.1.1.20\n- opencv-python 4.9.0.80\n- opencv-python-headless 4.10.0.84\n- openpyxl 3.1.5\n- opentelemetry-api 1.24.0\n- opentelemetry-exporter-otlp-proto-common 1.24.0\n- opentelemetry-exporter-otlp-proto-grpc 1.24.0\n- opentelemetry-exporter-otlp-proto-http 1.26.0\n- opentelemetry-instrumentation 0.45b0\n- opentelemetry-instrumentation-asgi 0.45b0\n- opentelemetry-instrumentation-fastapi 0.45b0\n- opentelemetry-proto 1.24.0\n- opentelemetry-sdk 1.24.0\n- opentelemetry-semantic-conventions 0.45b0\n- opentelemetry-util-http 0.45b0\n- opt-einsum 3.3.0\n- optimum 1.22.0\n- optuna 4.0.0\n- ordered-set 4.1.0\n- orjson 3.10.12\n- outcome 1.3.0.post0\n- overrides 7.7.0\n- packaging 23.2\n- panda3d 1.10.15\n- pandas 2.2.2\n- partd 1.4.2\n- parver 0.5\n- pathlib 1.0.1\n- pathos 0.3.2\n- pathspec 0.12.1\n- pdbeccdutils 0.8.5\n- peewee 3.17.6\n- peft 0.13.1\n- pendulum 3.0.0\n- phenaki-pytorch 0.4.2\n- pillow 10.4.0\n- pinecone 4.0.0\n- pip 24.1.2\n- pkginfo 1.11.1\n- platformdirs 4.2.2\n- plotly 5.24.0\n- pluggy 1.5.0\n- poetry 1.8.3\n- poetry-core 1.9.0\n- poetry-plugin-export 1.8.0\n- polars 1.6.0\n- polygon 1.2.5\n- pooch 1.8.2\n- postgrest 0.16.11\n- posthog 3.5.0\n- pox 0.3.4\n- ppft 1.7.6.8\n- prettytable 3.10.0\n- primepy 1.3\n- proglog 0.1.10\n- prometheus-client 0.21.0\n- proto-plus 1.24.0\n- protobuf 4.25.3\n- prov 2.0.1\n- psutil 5.9.8\n- pulsar-client 3.5.0\n- pulumi 3.136.2a1728475416\n- pulumi-gcp 8.5.0\n- py3dmol 2.4.2\n- py-cpuinfo 9.0.0\n- pyannote.audio 3.1.1\n- pyannote.core 5.0.0\n- pyannote.database 5.1.0\n- pyannote.metrics 3.2.1\n- pyannote.pipeline 3.0.1\n- pyarrow 16.1.0\n- pyarrow-hotfix 0.6\n- pyasn1 0.6.0\n- pyasn1-modules 0.4.0\n- pybind11 2.13.6\n- pycocotools 2.0.8\n- pycodestyle 2.11.1\n- pycoingecko 3.1.0\n- pycparser 2.22\n- pycryptodomex 3.20.0\n- pydantic 2.8.2\n- pydantic-core 2.20.1\n- pydantic-settings 2.4.0\n- pydeck 0.9.1\n- pydot 3.0.1\n- pydub 0.25.1\n- pyflakes 3.2.0\n- pygame 2.6.0\n- pyglet 1.5.29\n- pygments 2.18.0\n- pymongo 4.7.3\n- pyobjc 10.3.1\n- pyparsing 3.1.2\n- pypdf 4.3.1\n- pypdf2 3.0.1\n- pyperclip 1.9.0\n- pypng 0.20220715.0\n- pyproj 3.7.0\n- pyproject-hooks 1.1.0\n- pyrate-limiter 3.7.0\n- pytesseract 0.3.13\n- pytest 8.2.2\n- python-dateutil 2.9.0.post0\n- python-docx 1.1.2\n- python-dotenv 1.0.1\n- python-magic 0.4.27\n- python-multipart 0.0.9\n- python-pptx 1.0.2\n- pytorch-lightning 2.4.0\n- pytorch-metric-learning 2.6.0\n- pytube 15.0.0\n- pytweening 1.2.0\n- pytz 2024.1\n- pyxnat 1.6.2\n- pyyaml-env-tag 0.1\n- qrcode 7.4.2\n- rapidfuzz 3.9.7\n- ratelimit 2.2.1\n- ray 2.34.0\n- rdflib 6.3.2\n- rdkit 2024.3.5\n- readchar 4.2.0\n- realtime 2.0.2\n- redis 5.1.1\n- referencing 0.35.1\n- regex 2024.5.15\n- reportlab 4.2.5\n- requests 2.32.3\n- requests-file 2.1.0\n- requests-futures 1.0.1\n- requests-oauthlib 1.3.1\n- requests-toolbelt 1.0.0\n- retrying 1.3.4\n- rich 13.9.4\n- ring-attention-pytorch 0.4.1\n- rotary-embedding-torch 0.8.3\n- rpds-py 0.18.1\n- rsa 4.7.2\n- ruamel.yaml 0.18.6\n- ruamel.yaml.clib 0.2.8\n- rubicon-objc 0.4.9\n- ruff 0.6.4\n- runs 1.2.2\n- s3transfer 0.10.1\n- safetensors 0.4.3\n- schedule 1.2.2\n- schema 0.7.7\n- scikit-learn 1.5.1\n- scipy 1.14.1\n- seaborn 0.13.2\n- sec-edgar-api 1.1.0\n- sec-edgar-downloader 5.0.2\n- selenium 4.25.0\n- semantic-version 2.10.0\n- semver 3.0.2\n- sentence-transformers 3.0.1\n- sentencepiece 0.2.0\n- sentinelhub 3.11.1\n- sentry-sdk 2.14.0\n- setproctitle 1.3.3\n- setuptools 75.6.0\n- sgmllib3k 1.0.0\n- sh 2.0.7\n- shapely 2.0.6\n- shellingham 1.5.4\n- shortuuid 1.0.13\n- simplejson 3.19.2\n- simsimd 6.1.1\n- six 1.16.0\n- skypilot 0.6.1\n- smmap 5.0.1\n- sniffio 1.3.1\n- sortedcontainers 2.4.0\n- sounddevice 0.4.7\n- soundfile 0.12.1\n- soupsieve 2.5\n- soxr 0.5.0.post1\n- speechbrain 1.0.1\n- spotipy 2.24.0\n- sse-starlette 2.0.0\n- stable-baselines3 2.3.2\n- starlette 0.41.3\n- storage3 0.7.7\n- streamlit 1.35.0\n- stringcase 1.2.0\n- stringzilla 3.10.10\n- stripe 9.12.0\n- striprtf 0.0.26\n- structlog 24.4.0\n- supabase 2.7.3\n- supafunc 0.5.1\n- supervision 0.18.0\n- swarm-models 0.1.3\n- swarms 6.3.0\n- swarms-cloud 0.4.4\n- swarms-memory 0.1.2\n- sympy 1.13.1\n- ta-lib 0.5.0\n- tabulate 0.9.0\n- tavily-python 0.3.3\n- taylor-series-linear-attention 0.1.12\n- tenacity 8.5.0\n- tensorboard 2.17.1\n- tensorboardx 2.6.2.2\n- tensorboard-data-server 0.7.2\n- termcolor 2.4.0\n- textblob 0.18.0.post0\n- thop 0.1.1.post2209072238\n- threadpoolctl 3.5.0\n- tickr-agent 0.1.0\n- tifffile 2024.9.20\n- tiktoken 0.7.0\n- time-machine 2.14.1\n- timeout-decorator 0.5.0\n- timm 1.0.3\n- tinysegmenter 0.3\n- tldextract 5.1.2\n- together 1.3.1\n- tokenizers 0.20.2\n- tokentrim 0.1.13\n- toml 0.10.2\n- tomli 2.1.0\n- tomli-w 1.1.0\n- tomlkit 0.12.0\n- toolz 0.12.1\n- torch 2.5.1\n- torch-audiomentations 0.11.1\n- torch-geometric 2.5.3\n- torch-pitch-shift 1.2.5\n- torchao 0.6.1\n- torchaudio 2.4.0\n- torchmetrics 1.4.1\n- torchtyping 0.1.5\n- torchvision 0.20.1\n- tornado 6.4.1\n- tqdm 4.66.4\n- traits 6.3.2\n- transformers 4.44.0\n- transformers-stream-generator 0.0.5\n- tree-of-thoughts 0.6.3\n- trimesh 4.4.9\n- trio 0.26.0\n- trio-websocket 0.11.1\n- trove-classifiers 2024.7.2\n- tweepy 4.14.0\n- typeguard 2.13.3\n- typer 0.12.5\n- types-protobuf 5.26.0.20240422\n- typing 3.7.4.3\n- typing-extensions 4.12.2\n- typing-inspect 0.9.0\n- tzdata 2024.1\n- ujson 5.10.0\n- ultralytics 8.3.36\n- ultralytics-thop 2.0.12\n- uritemplate 4.1.1\n- urllib3 1.26.20\n- utm 0.7.0\n- uuid 1.30\n- uvicorn 0.29.0\n- uvloop 0.19.0\n- validators 0.19.0\n- vector-quantize-pytorch 1.14.7\n- virtualenv 20.26.4\n- wandb 0.18.5\n- watchdog 4.0.1\n- watchfiles 0.21.0\n- wcwidth 0.2.13\n- weaviate 0.1.2\n- weaviate-client 3.15.4\n- webdriver-manager 4.0.2\n- webencodings 0.5.1\n- websocket-client 1.8.0\n- websockets 12.0\n- werkzeug 3.0.3\n- wget 3.2\n- wheel 0.43.0\n- whisperx 3.1.2\n- wrapt 1.16.0\n- wsproto 1.2.0\n- x-transformers 1.30.2\n- xarray 2024.10.0\n- xattr 1.1.0\n- xgboost 2.1.1\n- xmod 1.8.1\n- xxhash 3.4.1\n- yahooquery 2.3.7\n- yarl 1.9.4\n- yaspin 3.1.0\n- yfinance 0.2.43\n- yt-dlp 2024.10.22\n- zetascale 2.6.2\n- zipp 3.18.2\n- zmq 0.0.0\n- zope.interface 7.1.1\n- -ransformers 4.42.3\n- autocommand 2.2.2\n- backports.tarfile 1.2.0\n- inflect 7.3.1\n- jaraco.collections 5.1.0\n- jaraco.context 5.3.0\n- jaraco.functools 4.0.1\n- jaraco.text 3.12.1\n        ```\n\n        ## Time of Occurrence\n        2024-12-16T20:41:16.184493\n\n        ---\n        *This issue was automatically generated by SwarmsIssueReporter*",
      "state": "closed",
      "author": "kyegomez",
      "author_type": "User",
      "created_at": "2024-12-17T04:41:16Z",
      "updated_at": "2025-03-20T16:24:49Z",
      "closed_at": "2025-01-09T20:28:44Z",
      "labels": [
        "bug",
        "automated",
        "severity:medium",
        "priority:high"
      ],
      "label_count": 4,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/684/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/684",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/684",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:14.914847",
      "comments": []
    },
    {
      "issue_number": 683,
      "title": "[Agent: Test-Agent] [ValueError] test",
      "body": "\n        ## Swarms Error Report\n        - **Error Type**: ValueError\n        - **Error Message**: test\n        - **Swarms Version**: Unknown\n\n        ## Environment Information\n        - **OS**: Darwin Darwin Kernel Version 23.3.0: Wed Dec 20 21:30:59 PST 2023; root:xnu-10002.81.5~7/RELEASE_ARM64_T6030\n        - **Python Version**: 3.12.3 (v3.12.3:f6650f9ad7, Apr  9 2024, 08:18:47) [Clang 13.0.0 (clang-1300.0.29.30)]\n        - **CUDA Available**: False\n        - **GPU**: N/A\n        - **CPU Usage**: 33.0%\n        - **Memory Usage**: 82.1%\n        - **Disk Usage**: 7.4%\n\n        ## Stack Trace\n        ```python\n        Traceback (most recent call last):\n  File \"/Users/swarms_wd/Desktop/swarms/auto_test_eval.py\", line 316, in <module>\n    raise ValueError(\"test\")\nValueError: test\n\n        ```\n\n        ## Context\n        ```json\n        {\n  \"task\": \"test_run\",\n  \"agent_name\": \"Test-Agent\",\n  \"agent_description\": null,\n  \"max_loops\": 1,\n  \"context_length\": 8192\n}\n        ```\n\n        ## Dependencies\n        - appnope 0.1.4\n- asttokens 2.4.1\n- comm 0.2.2\n- executing 2.0.1\n- ipykernel 6.29.4\n- ipython 8.25.0\n- jedi 0.19.1\n- jupyter-client 8.6.2\n- jupyter-core 5.7.2\n- matplotlib-inline 0.1.7\n- nest-asyncio 1.6.0\n- parso 0.8.4\n- pexpect 4.9.0\n- prompt-toolkit 3.0.47\n- ptyprocess 0.7.0\n- pure-eval 0.2.2\n- pyzmq 26.0.3\n- stack-data 0.6.3\n- traitlets 5.14.3\n- arpeggio 2.0.2\n- authlib 1.3.2\n- brotli 1.1.0\n- cantera 3.0.1\n- colt5-attention 0.11.1\n- datetime 5.5\n- deprecated 1.2.14\n- faker 30.8.2\n- farama-notifications 0.0.4\n- gputil 1.4.0\n- gitpython 3.1.43\n- hyperpyyaml 1.2.2\n- mako 1.3.5\n- markdown 3.6\n- markupsafe 2.1.5\n- mouseinfo 0.1.3\n- pulp 2.8.0\n- pyaudio 0.2.14\n- pyautogui 0.9.54\n- pygetwindow 0.0.9\n- pymsgbox 1.0.9\n- pypika 0.48.9\n- pyrect 0.2.0\n- pyscreeze 1.0.1\n- pysocks 1.7.1\n- pyyaml 6.0.2\n- sqlalchemy 2.0.30\n- send2trash 1.8.3\n- strenum 0.4.15\n- torchfix 0.5.0\n- xlsxwriter 3.2.0\n- absl-py 2.1.0\n- accelerate 0.33.0\n- adam-atan2-pytorch 0.0.12\n- aenum 3.1.15\n- agentops 0.2.3\n- agentparse 0.0.3\n- ai21 2.7.0\n- ai21-tokenizer 0.11.2\n- ai-lang 0.0.4\n- aiocache 0.12.3\n- aiofiles 24.1.0\n- aiohappyeyeballs 2.3.7\n- aiohttp 3.10.4\n- aiosignal 1.3.1\n- albucore 0.0.20\n- albumentations 1.4.21\n- alembic 1.13.3\n- alpha-vantage 3.0.0\n- alphafold3-pytorch 0.4.53\n- altair 5.3.0\n- annotated-types 0.7.0\n- anthropic 0.37.1\n- antlr4-python3-runtime 4.9.3\n- anyio 4.4.0\n- anytree 2.12.1\n- argparse 1.4.0\n- asgiref 3.8.1\n- asteroid-filterbanks 0.4.0\n- astor 0.8.1\n- asyncio 3.4.3\n- attrs 24.2.0\n- audioread 3.0.1\n- av 12.3.0\n- awscli 1.32.116\n- backoff 2.2.1\n- bcrypt 4.1.3\n- beartype 0.17.2\n- beautifulsoup4 4.12.3\n- biopython 1.84\n- bitsandbytes 0.42.0\n- black 24.8.0\n- blessed 1.20.0\n- blinker 1.8.2\n- boto3 1.34.116\n- botocore 1.34.116\n- bs4 0.0.2\n- build 1.2.1\n- cachecontrol 0.14.0\n- cachetools 5.3.3\n- cadquery 2.3.0\n- cads-api-client 1.5.2\n- cdsapi 0.7.4\n- certifi 2024.2.2\n- cffi 1.16.0\n- cfgrib 0.9.14.1\n- cftime 1.6.4.post1\n- chardet 5.2.0\n- charset-normalizer 3.3.2\n- chroma-hnswlib 0.7.6\n- chromadb 0.5.20\n- ci-info 0.3.0\n- classifier-free-guidance-pytorch 0.5.3\n- cleo 2.1.0\n- click 8.1.7\n- cloudpickle 3.0.0\n- clusterops 0.1.2\n- code-guardian 0.1.4\n- colorama 0.4.4\n- coloredlogs 15.0.1\n- colorlog 6.8.2\n- configobj 5.0.8\n- configparser 7.0.0\n- contourpy 1.2.1\n- crashtest 0.4.1\n- cryptoagent 0.1.0\n- cryptography 42.0.7\n- cssselect 1.2.0\n- ctranslate2 4.4.0\n- cycler 0.12.1\n- dask 2024.11.0\n- dataclasses-json 0.6.6\n- datasets 2.19.1\n- debugpy 1.8.6\n- decorator 5.1.1\n- defusedxml 0.7.1\n- deprecation 2.1.0\n- diffusers 0.30.2\n- dill 0.3.8\n- dirtyjson 1.0.8\n- diskcache 5.6.3\n- distlib 0.3.8\n- distro 1.9.0\n- dnspython 2.6.1\n- doc-master 0.0.2\n- docker 7.1.0\n- docker-pycreds 0.4.0\n- docopt 0.6.2\n- docstring-parser 0.16\n- docutils 0.16\n- docx 0.2.4\n- dulwich 0.21.7\n- e2b 0.17.1\n- e2b-code-interpreter 0.0.10\n- eccodes 2.38.3\n- editor 1.6.6\n- einops 0.8.0\n- einops-exts 0.0.4\n- einx 0.2.2\n- ema-pytorch 0.6.2\n- email-validator 2.1.1\n- environs 11.0.0\n- et-xmlfile 1.1.0\n- etelemetry 0.3.1\n- eval-type-backport 0.2.0\n- exa-py 1.0.12\n- facenet-pytorch 2.6.0\n- faiss-cpu 1.8.0.post1\n- fastapi 0.115.5\n- fastapi-cli 0.0.4\n- faster-whisper 1.0.3\n- fastjsonschema 2.20.0\n- feedfinder2 0.0.4\n- feedparser 6.0.11\n- ffmpy 0.4.0\n- ffn 1.1.0\n- filelock 3.14.0\n- findlibs 0.0.5\n- flake8 7.0.0\n- flash 1.0.3\n- flask 3.0.3\n- flatbuffers 24.3.25\n- fluid-api-agent 0.0.1\n- fonttools 4.51.0\n- fpdf 1.7.2\n- frame-averaging-pytorch 0.1.2\n- fredapi 0.5.2\n- frozendict 2.4.4\n- frozenlist 1.4.1\n- fsspec 2024.3.1\n- ftfy 6.2.0\n- gemmi 0.6.7\n- ghp-import 2.1.0\n- git-python 1.0.3\n- gitdb 4.0.11\n- google-ai-generativelanguage 0.6.6\n- google-api-core 2.19.1\n- google-api-python-client 2.139.0\n- google-auth 2.29.0\n- google-auth-httplib2 0.2.0\n- google-cloud-core 2.4.1\n- google-cloud-storage 2.18.0\n- google-crc32c 1.5.0\n- google-generativeai 0.7.2\n- google-resumable-media 2.7.1\n- googleapis-common-protos 1.63.0\n- gotrue 2.7.0\n- gradio 4.43.0\n- gradio-client 1.3.0\n- gradio-molecule3d 0.0.5\n- graphviz 0.20.3\n- greenlet 3.1.1\n- griptape 0.32.0\n- groq 0.8.0\n- grpcio 1.66.2\n- grpcio-status 1.62.3\n- guidance 0.1.16\n- gunicorn 22.0.0\n- gym 0.26.2\n- gym-notices 0.0.8\n- gymnasium 0.29.1\n- h11 0.14.0\n- h2 4.1.0\n- hf-transfer 0.1.8\n- hpack 4.0.0\n- html2image 2.0.5\n- html2text 2024.2.26\n- html5lib 1.1\n- httpcore 1.0.5\n- httplib2 0.22.0\n- httptools 0.6.1\n- httpx 0.27.0\n- httpx-sse 0.4.0\n- huggingface-hub 0.24.6\n- humanfriendly 10.0\n- hyperframe 6.0.1\n- idna 3.7\n- imageio 2.35.1\n- imageio-ffmpeg 0.5.1\n- importlib-metadata 7.0.0\n- importlib-resources 6.4.0\n- iniconfig 2.0.0\n- inquirer 3.4.0\n- instagrapi 2.1.2\n- install 1.3.5\n- installer 0.7.0\n- iotagents 0.0.1\n- isodate 0.6.1\n- itsdangerous 2.2.0\n- jaraco.classes 3.4.0\n- jax 0.4.31\n- jaxlib 0.4.31\n- jaxtyping 0.2.34\n- jieba3k 0.35.1\n- jinja2 3.1.4\n- jiter 0.5.0\n- jmespath 1.0.1\n- joblib 1.4.2\n- jsonpatch 1.33\n- jsonpointer 2.4\n- jsonrpcclient 4.0.3\n- jsonschema 4.22.0\n- jsonschema-specifications 2023.12.1\n- julius 0.2.7\n- keyring 24.3.1\n- kiwisolver 1.4.5\n- kubernetes 29.0.0\n- langchain 0.1.13\n- langchain-community 0.0.29\n- langchain-core 0.1.52\n- langchain-experimental 0.0.55\n- langchain-text-splitters 0.0.2\n- langsmith 0.1.125\n- lazy-loader 0.4\n- libcst 1.1.0\n- librosa 0.10.2.post1\n- lightgbm 4.5.0\n- lightning 2.4.0\n- lightning-utilities 0.11.7\n- linkedin-api 2.3.0\n- lion-pytorch 0.2.2\n- litellm 1.51.0\n- llama-cloud 0.1.4\n- llama-index 0.11.20\n- llama-index-agent-openai 0.3.4\n- llama-index-cli 0.3.1\n- llama-index-core 0.11.21\n- llama-index-embeddings-openai 0.2.5\n- llama-index-indices-managed-llama-cloud 0.4.0\n- llama-index-legacy 0.9.48.post3\n- llama-index-llms-openai 0.2.16\n- llama-index-multi-modal-llms-openai 0.2.3\n- llama-index-program-openai 0.2.0\n- llama-index-question-gen-openai 0.2.0\n- llama-index-readers-file 0.2.2\n- llama-index-readers-llama-parse 0.3.0\n- llama-parse 0.5.12\n- llvmlite 0.43.0\n- local-attention 1.9.1\n- locket 1.0.0\n- loguru 0.7.2\n- looseversion 1.3.0\n- lxml 4.9.4\n- lxml-html-clean 0.2.2\n- mambabyte 0.0.2\n- markdown-it-py 3.0.0\n- marshmallow 3.22.0\n- marshmallow-enum 1.5.1\n- matplotlib 3.9.2\n- mccabe 0.7.0\n- mdformat 0.7.17\n- mdurl 0.1.2\n- medinsight 0.0.6\n- mergedeep 1.3.4\n- mermaid-py 0.6.0\n- mkdocs 1.6.0\n- mkdocs-get-deps 0.2.0\n- ml-dtypes 0.4.0\n- mlx 0.13.1\n- mmh3 4.1.0\n- monotonic 1.6\n- more-itertools 10.5.0\n- moviepy 1.0.3\n- mpmath 1.3.0\n- msgpack 1.0.8\n- multidict 6.0.5\n- multion 1.3.0\n- multiprocess 0.70.16\n- multitasking 0.0.11\n- multiurl 0.3.2\n- mutagen 1.47.0\n- mypy-extensions 1.0.0\n- nbformat 5.10.4\n- neo-sapiens 0.0.5\n- netcdf4 1.7.2\n- networkx 3.3\n- news-swarm 0.0.7\n- newsapi 0.1.1\n- newsapi-python 0.2.7\n- newspaper3k 0.2.8\n- nibabel 5.2.1\n- nipype 1.8.6\n- nltk 3.9.1\n- numba 0.60.0\n- numpy 1.26.4\n- oauthlib 3.2.2\n- ollama 0.3.3\n- omegaconf 2.3.0\n- onnxruntime 1.20.1\n- open-clip-torch 2.24.0\n- open-interpreter 0.4.3\n- openai 1.52.2\n- openbabel-wheel 3.1.1.20\n- opencv-python 4.9.0.80\n- opencv-python-headless 4.10.0.84\n- openpyxl 3.1.5\n- opentelemetry-api 1.24.0\n- opentelemetry-exporter-otlp-proto-common 1.24.0\n- opentelemetry-exporter-otlp-proto-grpc 1.24.0\n- opentelemetry-exporter-otlp-proto-http 1.26.0\n- opentelemetry-instrumentation 0.45b0\n- opentelemetry-instrumentation-asgi 0.45b0\n- opentelemetry-instrumentation-fastapi 0.45b0\n- opentelemetry-proto 1.24.0\n- opentelemetry-sdk 1.24.0\n- opentelemetry-semantic-conventions 0.45b0\n- opentelemetry-util-http 0.45b0\n- opt-einsum 3.3.0\n- optimum 1.22.0\n- optuna 4.0.0\n- ordered-set 4.1.0\n- orjson 3.10.12\n- outcome 1.3.0.post0\n- overrides 7.7.0\n- packaging 23.2\n- panda3d 1.10.15\n- pandas 2.2.2\n- partd 1.4.2\n- parver 0.5\n- pathlib 1.0.1\n- pathos 0.3.2\n- pathspec 0.12.1\n- pdbeccdutils 0.8.5\n- peewee 3.17.6\n- peft 0.13.1\n- pendulum 3.0.0\n- phenaki-pytorch 0.4.2\n- pillow 10.4.0\n- pinecone 4.0.0\n- pip 24.1.2\n- pkginfo 1.11.1\n- platformdirs 4.2.2\n- plotly 5.24.0\n- pluggy 1.5.0\n- poetry 1.8.3\n- poetry-core 1.9.0\n- poetry-plugin-export 1.8.0\n- polars 1.6.0\n- polygon 1.2.5\n- pooch 1.8.2\n- postgrest 0.16.11\n- posthog 3.5.0\n- pox 0.3.4\n- ppft 1.7.6.8\n- prettytable 3.10.0\n- primepy 1.3\n- proglog 0.1.10\n- prometheus-client 0.21.0\n- proto-plus 1.24.0\n- protobuf 4.25.3\n- prov 2.0.1\n- psutil 5.9.8\n- pulsar-client 3.5.0\n- pulumi 3.136.2a1728475416\n- pulumi-gcp 8.5.0\n- py3dmol 2.4.2\n- py-cpuinfo 9.0.0\n- pyannote.audio 3.1.1\n- pyannote.core 5.0.0\n- pyannote.database 5.1.0\n- pyannote.metrics 3.2.1\n- pyannote.pipeline 3.0.1\n- pyarrow 16.1.0\n- pyarrow-hotfix 0.6\n- pyasn1 0.6.0\n- pyasn1-modules 0.4.0\n- pybind11 2.13.6\n- pycocotools 2.0.8\n- pycodestyle 2.11.1\n- pycoingecko 3.1.0\n- pycparser 2.22\n- pycryptodomex 3.20.0\n- pydantic 2.8.2\n- pydantic-core 2.20.1\n- pydantic-settings 2.4.0\n- pydeck 0.9.1\n- pydot 3.0.1\n- pydub 0.25.1\n- pyflakes 3.2.0\n- pygame 2.6.0\n- pyglet 1.5.29\n- pygments 2.18.0\n- pymongo 4.7.3\n- pyobjc 10.3.1\n- pyparsing 3.1.2\n- pypdf 4.3.1\n- pypdf2 3.0.1\n- pyperclip 1.9.0\n- pypng 0.20220715.0\n- pyproj 3.7.0\n- pyproject-hooks 1.1.0\n- pyrate-limiter 3.7.0\n- pytesseract 0.3.13\n- pytest 8.2.2\n- python-dateutil 2.9.0.post0\n- python-docx 1.1.2\n- python-dotenv 1.0.1\n- python-magic 0.4.27\n- python-multipart 0.0.9\n- python-pptx 1.0.2\n- pytorch-lightning 2.4.0\n- pytorch-metric-learning 2.6.0\n- pytube 15.0.0\n- pytweening 1.2.0\n- pytz 2024.1\n- pyxnat 1.6.2\n- pyyaml-env-tag 0.1\n- qrcode 7.4.2\n- rapidfuzz 3.9.7\n- ratelimit 2.2.1\n- ray 2.34.0\n- rdflib 6.3.2\n- rdkit 2024.3.5\n- readchar 4.2.0\n- realtime 2.0.2\n- redis 5.1.1\n- referencing 0.35.1\n- regex 2024.5.15\n- reportlab 4.2.5\n- requests 2.32.3\n- requests-file 2.1.0\n- requests-futures 1.0.1\n- requests-oauthlib 1.3.1\n- requests-toolbelt 1.0.0\n- retrying 1.3.4\n- rich 13.9.4\n- ring-attention-pytorch 0.4.1\n- rotary-embedding-torch 0.8.3\n- rpds-py 0.18.1\n- rsa 4.7.2\n- ruamel.yaml 0.18.6\n- ruamel.yaml.clib 0.2.8\n- rubicon-objc 0.4.9\n- ruff 0.6.4\n- runs 1.2.2\n- s3transfer 0.10.1\n- safetensors 0.4.3\n- schedule 1.2.2\n- schema 0.7.7\n- scikit-learn 1.5.1\n- scipy 1.14.1\n- seaborn 0.13.2\n- sec-edgar-api 1.1.0\n- sec-edgar-downloader 5.0.2\n- selenium 4.25.0\n- semantic-version 2.10.0\n- semver 3.0.2\n- sentence-transformers 3.0.1\n- sentencepiece 0.2.0\n- sentinelhub 3.11.1\n- sentry-sdk 2.14.0\n- setproctitle 1.3.3\n- setuptools 75.6.0\n- sgmllib3k 1.0.0\n- sh 2.0.7\n- shapely 2.0.6\n- shellingham 1.5.4\n- shortuuid 1.0.13\n- simplejson 3.19.2\n- simsimd 6.1.1\n- six 1.16.0\n- skypilot 0.6.1\n- smmap 5.0.1\n- sniffio 1.3.1\n- sortedcontainers 2.4.0\n- sounddevice 0.4.7\n- soundfile 0.12.1\n- soupsieve 2.5\n- soxr 0.5.0.post1\n- speechbrain 1.0.1\n- spotipy 2.24.0\n- sse-starlette 2.0.0\n- stable-baselines3 2.3.2\n- starlette 0.41.3\n- storage3 0.7.7\n- streamlit 1.35.0\n- stringcase 1.2.0\n- stringzilla 3.10.10\n- stripe 9.12.0\n- striprtf 0.0.26\n- structlog 24.4.0\n- supabase 2.7.3\n- supafunc 0.5.1\n- supervision 0.18.0\n- swarm-models 0.1.3\n- swarms 6.3.0\n- swarms-cloud 0.4.4\n- swarms-memory 0.1.2\n- sympy 1.13.1\n- ta-lib 0.5.0\n- tabulate 0.9.0\n- tavily-python 0.3.3\n- taylor-series-linear-attention 0.1.12\n- tenacity 8.5.0\n- tensorboard 2.17.1\n- tensorboardx 2.6.2.2\n- tensorboard-data-server 0.7.2\n- termcolor 2.4.0\n- textblob 0.18.0.post0\n- thop 0.1.1.post2209072238\n- threadpoolctl 3.5.0\n- tickr-agent 0.1.0\n- tifffile 2024.9.20\n- tiktoken 0.7.0\n- time-machine 2.14.1\n- timeout-decorator 0.5.0\n- timm 1.0.3\n- tinysegmenter 0.3\n- tldextract 5.1.2\n- together 1.3.1\n- tokenizers 0.20.2\n- tokentrim 0.1.13\n- toml 0.10.2\n- tomli 2.1.0\n- tomli-w 1.1.0\n- tomlkit 0.12.0\n- toolz 0.12.1\n- torch 2.5.1\n- torch-audiomentations 0.11.1\n- torch-geometric 2.5.3\n- torch-pitch-shift 1.2.5\n- torchao 0.6.1\n- torchaudio 2.4.0\n- torchmetrics 1.4.1\n- torchtyping 0.1.5\n- torchvision 0.20.1\n- tornado 6.4.1\n- tqdm 4.66.4\n- traits 6.3.2\n- transformers 4.44.0\n- transformers-stream-generator 0.0.5\n- tree-of-thoughts 0.6.3\n- trimesh 4.4.9\n- trio 0.26.0\n- trio-websocket 0.11.1\n- trove-classifiers 2024.7.2\n- tweepy 4.14.0\n- typeguard 2.13.3\n- typer 0.12.5\n- types-protobuf 5.26.0.20240422\n- typing 3.7.4.3\n- typing-extensions 4.12.2\n- typing-inspect 0.9.0\n- tzdata 2024.1\n- ujson 5.10.0\n- ultralytics 8.3.36\n- ultralytics-thop 2.0.12\n- uritemplate 4.1.1\n- urllib3 1.26.20\n- utm 0.7.0\n- uuid 1.30\n- uvicorn 0.29.0\n- uvloop 0.19.0\n- validators 0.19.0\n- vector-quantize-pytorch 1.14.7\n- virtualenv 20.26.4\n- wandb 0.18.5\n- watchdog 4.0.1\n- watchfiles 0.21.0\n- wcwidth 0.2.13\n- weaviate 0.1.2\n- weaviate-client 3.15.4\n- webdriver-manager 4.0.2\n- webencodings 0.5.1\n- websocket-client 1.8.0\n- websockets 12.0\n- werkzeug 3.0.3\n- wget 3.2\n- wheel 0.43.0\n- whisperx 3.1.2\n- wrapt 1.16.0\n- wsproto 1.2.0\n- x-transformers 1.30.2\n- xarray 2024.10.0\n- xattr 1.1.0\n- xgboost 2.1.1\n- xmod 1.8.1\n- xxhash 3.4.1\n- yahooquery 2.3.7\n- yarl 1.9.4\n- yaspin 3.1.0\n- yfinance 0.2.43\n- yt-dlp 2024.10.22\n- zetascale 2.6.2\n- zipp 3.18.2\n- zmq 0.0.0\n- zope.interface 7.1.1\n- -ransformers 4.42.3\n- autocommand 2.2.2\n- backports.tarfile 1.2.0\n- inflect 7.3.1\n- jaraco.collections 5.1.0\n- jaraco.context 5.3.0\n- jaraco.functools 4.0.1\n- jaraco.text 3.12.1\n\n        ## Time of Occurrence\n        2024-12-16T20:39:38.348231\n\n        ---\n        *This issue was automatically generated by SwarmsIssueReporter*",
      "state": "closed",
      "author": "kyegomez",
      "author_type": "User",
      "created_at": "2024-12-17T04:39:38Z",
      "updated_at": "2025-03-20T16:24:49Z",
      "closed_at": "2025-01-09T20:29:03Z",
      "labels": [
        "bug",
        "automated",
        "severity:medium",
        "priority:high"
      ],
      "label_count": 4,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/683/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/683",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/683",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:14.914854",
      "comments": []
    },
    {
      "issue_number": 678,
      "title": "[BUG] [MINOR] ",
      "body": "**Describe the bug**\r\n\r\nwarning: The package `sentry-sdk==2.19.2` does not have an extra named `http`\r\n\r\n\r\n**To Reproduce**\r\n!uv  pip install -U swarms swarms-memory --system\r\nThe warning shows up at the end or the output\r\n\r\n**To fix**\r\nhttps://github.com/kyegomez/swarms/blob/master/pyproject.toml\r\n```pyproject.toml line 69\r\nsentry-sdk = {version = \"*\", extras = [\"http\"]}  # Updated here\r\n```\r\nshould be\r\n```pyproject.toml line 69\r\nsentry-sdk = \"*\"\r\n```",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2024-12-12T20:00:29Z",
      "updated_at": "2025-03-20T16:24:49Z",
      "closed_at": "2025-02-13T20:48:42Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/678/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/678",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/678",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:14.914861",
      "comments": [
        {
          "author": "patrickbdevaney",
          "body": "In pyproject.toml, it has been fixed as : \r\nsentry-sdk = \"*\"\r\n\r\nrather than \r\nsentry-sdk = {version = \"*\", extras = [\"http\"]}  \r\n\r\nIssue can marked as resolved",
          "created_at": "2024-12-20T22:09:39Z"
        }
      ]
    },
    {
      "issue_number": 668,
      "title": "[BUG]  google-generativeai=",
      "body": "**Describe the bug**\r\n google-generativeai not in swarms latest\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n```\r\n(job, pid=6699) ERROR: Could not find a version that satisfies the requirement google-generativeai==0.3.1 (from swarms\\\r\n) (from versions: 0.1.0rc1, 0.1.0rc2)\r\n(job, pid=6699) ERROR: No matching distribution found for google-generativeai==0.3.1 (from swarms)\r\n```",
      "state": "closed",
      "author": "jmikedupont2",
      "author_type": "User",
      "created_at": "2024-12-06T18:45:12Z",
      "updated_at": "2025-03-20T16:24:48Z",
      "closed_at": "2025-02-13T20:49:00Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/668/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/668",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/668",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:15.262668",
      "comments": [
        {
          "author": "patrickbdevaney",
          "body": "I resolved this in a PR on my fork by adding google-generativeai==0.3.1 to the swarms dependencies, but we have to determine if we want to include it in the swarms package.\r\n\r\nIts a platform-specific library, which might be better as a separate pip install for the user.",
          "created_at": "2024-12-20T22:15:13Z"
        }
      ]
    },
    {
      "issue_number": 667,
      "title": "[FEATURE] lambda_multiprocessing support",
      "body": "Suggestion to use \r\nhttps://github.com/mdavis-xyz/lambda_multiprocessing\r\n\r\nCurrent Issue:\r\n```\r\n[ERROR] OSError: [Errno 38] Function not implemented\r\nTraceback (most recent call last):\r\n  File \"/var/lang/lib/python3.11/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n  File \"/var/task/main.py\", line 5, in <module>\r\n    from swarms import Agent\r\n  File \"/var/task/src/swarms/swarms/__init__.py\", line 38, in <module>\r\n    from swarms.agents import *  # noqa: E402, F403\r\n  File \"/var/task/src/swarms/swarms/agents/__init__.py\", line 13, in <module>\r\n    from swarms.agents.tool_agent import ToolAgent\r\n  File \"/var/task/src/swarms/swarms/agents/tool_agent.py\", line 2, in <module>\r\n    from swarms.tools.json_former import Jsonformer\r\n  File \"/var/task/src/swarms/swarms/tools/__init__.py\", line 1, in <module>\r\n    from swarms.tools.tool_utils import (\r\n  File \"/var/task/src/swarms/swarms/tools/tool_utils.py\", line 6, in <module>\r\n    from swarms.utils.formatter import formatter\r\n  File \"/var/task/src/swarms/swarms/utils/__init__.py\", line 2, in <module>\r\n    from swarms.utils.data_to_text import (\r\n  File \"/var/task/src/swarms/swarms/utils/data_to_text.py\", line 5, in <module>\r\n    from swarms.utils.pdf_to_text import pdf_to_text\r\n  File \"/var/task/src/swarms/swarms/utils/pdf_to_text.py\", line 1, in <module>\r\n    from swarms.utils.try_except_wrapper import try_except_wrapper\r\n  File \"/var/task/src/swarms/swarms/utils/try_except_wrapper.py\", line 7, in <module>\r\n    logger = initialize_logger(\"try_except_wrapper\")\r\n  File \"/var/task/src/swarms/swarms/utils/loguru_logger.py\", line 31, in initialize_logger\r\n    logger.add(\r\n  File \"/var/lang/lib/python3.11/site-packages/loguru/_logger.py\", line 988, in add\r\n    handler = Handler(\r\n  File \"/var/lang/lib/python3.11/site-packages/loguru/_handler.py\", line 93, in __init__\r\n    self._queue = multiprocessing.SimpleQueue()\r\n  File \"/var/lang/lib/python3.11/multiprocessing/context.py\", line 113, in SimpleQueue\r\n    return SimpleQueue(ctx=self.get_context())\r\n  File \"/var/lang/lib/python3.11/multiprocessing/queues.py\", line 341, in __init__\r\n    self._rlock = ctx.Lock()\r\n  File \"/var/lang/lib/python3.11/multiprocessing/context.py\", line 68, in Lock\r\n    return Lock(ctx=self.get_context())\r\n  File \"/var/lang/lib/python3.11/multiprocessing/synchronize.py\", line 169, in __init__\r\n    SemLock.__init__(self, SEMAPHORE, 1, 1, ctx=ctx)\r\n  File \"/var/lang/lib/python3.11/multiprocessing/synchronize.py\", line 57, in __init__\r\n    sl = self._semlock = _multiprocessing.SemLock(\r\n```",
      "state": "closed",
      "author": "jmikedupont2",
      "author_type": "User",
      "created_at": "2024-12-06T16:33:14Z",
      "updated_at": "2025-03-20T16:24:48Z",
      "closed_at": "2025-02-13T20:48:31Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/667/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/667",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/667",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:15.723588",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-12-06T16:33:47Z"
        }
      ]
    },
    {
      "issue_number": 660,
      "title": "[BUG] swarms_models not found",
      "body": "**Describe the bug**\r\n```---------------------------------------------------------------------------\r\nModuleNotFoundError                       Traceback (most recent call last)\r\n[<ipython-input-4-14444884eff9>](https://localhost:8080/#) in <cell line: 1>()\r\n----> 1 from swarms import Agent\r\n      2 \r\n      3 agent = Agent(\r\n      4     agent_name=\"Stock-Analysis-Agent\",\r\n      5     model_name=\"gpt-4o-mini\",\r\n\r\n6 frames\r\n[/usr/local/lib/python3.10/dist-packages/swarms/__init__.py](https://localhost:8080/#) in <module>\r\n     11 \r\n     12 # Import telemetry functions with error handling\r\n---> 13 from swarms.telemetry.bootup import bootup  # noqa: E402, F403\r\n     14 from swarms.telemetry.sentry_active import (  # noqa: E402\r\n     15     activate_sentry,\r\n\r\n[/usr/local/lib/python3.10/dist-packages/swarms/telemetry/bootup.py](https://localhost:8080/#) in <module>\r\n      4 from concurrent.futures import ThreadPoolExecutor\r\n      5 \r\n----> 6 from swarms.telemetry.auto_upgrade_swarms import auto_update\r\n      7 from swarms.utils.disable_logging import disable_logging\r\n      8 \r\n\r\n[/usr/local/lib/python3.10/dist-packages/swarms/telemetry/auto_upgrade_swarms.py](https://localhost:8080/#) in <module>\r\n      2 import subprocess\r\n      3 \r\n----> 4 from swarms.utils.loguru_logger import initialize_logger\r\n      5 from swarms.telemetry.check_update import check_for_update\r\n      6 \r\n\r\n[/usr/local/lib/python3.10/dist-packages/swarms/utils/__init__.py](https://localhost:8080/#) in <module>\r\n     14 )\r\n     15 from swarms.utils.markdown_message import display_markdown_message\r\n---> 16 from swarms.tools.prebuilt.math_eval import math_eval\r\n     17 from swarms.utils.parse_code import extract_code_from_markdown\r\n     18 from swarms.utils.pdf_to_text import pdf_to_text\r\n\r\n[/usr/local/lib/python3.10/dist-packages/swarms/tools/__init__.py](https://localhost:8080/#) in <module>\r\n     23 from swarms.tools.openai_tool_creator_decorator import tool\r\n     24 from swarms.tools.base_tool import BaseTool\r\n---> 25 from swarms.tools.prebuilt import *  # noqa: F403\r\n     26 from swarms.tools.cohere_func_call_schema import (\r\n     27     CohereFuncSchema,\r\n\r\n[/usr/local/lib/python3.10/dist-packages/swarms/tools/prebuilt/__init__.py](https://localhost:8080/#) in <module>\r\n      1 from swarms.tools.prebuilt.math_eval import math_eval\r\n----> 2 from swarms.tools.prebuilt.code_executor import CodeExecutor\r\n      3 \r\n      4 __all__ = [\r\n      5     \"math_eval\",\r\n\r\n[/usr/local/lib/python3.10/dist-packages/swarms/tools/prebuilt/code_executor.py](https://localhost:8080/#) in <module>\r\n      2 import subprocess\r\n      3 from loguru import logger\r\n----> 4 from swarm_models.tiktoken_wrapper import TikTokenizer\r\n      5 \r\n      6 \r\n\r\nModuleNotFoundError: No module named 'swarm_models'\r\n\r\n---------------------------------------------------------------------------\r\nNOTE: If your import is failing due to a missing package, you can\r\nmanually install dependencies using either !pip or !apt.\r\n\r\nTo view examples of installing some common dependencies, click the\r\n\"Open Examples\" button below.\r\n---------------------------------------------------------------------------```",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2024-12-04T18:13:55Z",
      "updated_at": "2025-03-20T16:24:48Z",
      "closed_at": "2024-12-10T18:47:38Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/660/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/660",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/660",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:16.064512",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "```\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n[<ipython-input-5-14444884eff9>](https://localhost:8080/#) in <cell line: 1>()\r\n----> 1 from swarms import Agent\r\n      2 \r\n      3 agent = A",
          "created_at": "2024-12-04T18:23:30Z"
        },
        {
          "author": "evelynmitchell",
          "body": "The version of swarms is 6.5.1\r\npydantic==2.10.3\r\npydantic_core==2.27.1\r\n",
          "created_at": "2024-12-04T18:25:00Z"
        },
        {
          "author": "evelynmitchell",
          "body": "In swarms 6.5.6 the pydantic error is still occurring, but is now being triggered in swarms code\r\n\r\nIt looks like the error is coming out of\r\n\r\n```\r\n----> 5 from pydantic import BaseModel, Field, validator\r\n```\r\nin swarms/artifacts/main_artifact.py\r\n\r\nleading to\r\n```\r\n    402             f'Importing",
          "created_at": "2024-12-05T15:59:05Z"
        },
        {
          "author": "evelynmitchell",
          "body": "Testing with 6.5.7\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n[<ipython-input-7-14444884eff9>](https://localhost:8080/#) in <cell line: 1>()\r\n----> 1 from swarms import Agent\r\n     ",
          "created_at": "2024-12-06T16:58:20Z"
        },
        {
          "author": "evelynmitchell",
          "body": "This has been fixed in 6.5.9\r\nClosing",
          "created_at": "2024-12-10T18:47:38Z"
        }
      ]
    },
    {
      "issue_number": 659,
      "title": "[BUG] TogetherLLM pydantic error",
      "body": "**Describe the bug**\r\nIn a colab notebook running the first example in the README:\r\n```\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n[<ipython-input-12-14444884eff9>](https://localhost:8080/#) in <cell line: 1>()\r\n----> 1 from swarms import Agent\r\n      2 \r\n      3 agent = Agent(\r\n      4     agent_name=\"Stock-Analysis-Agent\",\r\n      5     model_name=\"gpt-4o-mini\",\r\n\r\n21 frames\r\n[/content/swarms/swarms/__init__.py](https://localhost:8080/#) in <module>\r\n     11 \r\n     12 # Import telemetry functions with error handling\r\n---> 13 from swarms.telemetry.bootup import bootup  # noqa: E402, F403\r\n     14 from swarms.telemetry.sentry_active import (  # noqa: E402\r\n     15     activate_sentry,\r\n\r\n[/content/swarms/swarms/telemetry/bootup.py](https://localhost:8080/#) in <module>\r\n      4 from concurrent.futures import ThreadPoolExecutor\r\n      5 \r\n----> 6 from swarms.telemetry.auto_upgrade_swarms import auto_update\r\n      7 from swarms.utils.disable_logging import disable_logging\r\n      8 \r\n\r\n[/content/swarms/swarms/telemetry/auto_upgrade_swarms.py](https://localhost:8080/#) in <module>\r\n      2 import subprocess\r\n      3 \r\n----> 4 from swarms.utils.loguru_logger import initialize_logger\r\n      5 from swarms.telemetry.check_update import check_for_update\r\n      6 \r\n\r\n[/content/swarms/swarms/utils/__init__.py](https://localhost:8080/#) in <module>\r\n     14 )\r\n     15 from swarms.utils.markdown_message import display_markdown_message\r\n---> 16 from swarms.tools.prebuilt.math_eval import math_eval\r\n     17 from swarms.utils.parse_code import extract_code_from_markdown\r\n     18 from swarms.utils.pdf_to_text import pdf_to_text\r\n\r\n[/content/swarms/swarms/tools/__init__.py](https://localhost:8080/#) in <module>\r\n     23 from swarms.tools.openai_tool_creator_decorator import tool\r\n     24 from swarms.tools.base_tool import BaseTool\r\n---> 25 from swarms.tools.prebuilt import *  # noqa: F403\r\n     26 from swarms.tools.cohere_func_call_schema import (\r\n     27     CohereFuncSchema,\r\n\r\n[/content/swarms/swarms/tools/prebuilt/__init__.py](https://localhost:8080/#) in <module>\r\n      1 from swarms.tools.prebuilt.math_eval import math_eval\r\n----> 2 from swarms.tools.prebuilt.code_executor import CodeExecutor\r\n      3 \r\n      4 __all__ = [\r\n      5     \"math_eval\",\r\n\r\n[/content/swarms/swarms/tools/prebuilt/code_executor.py](https://localhost:8080/#) in <module>\r\n      2 import subprocess\r\n      3 from loguru import logger\r\n----> 4 from swarm_models.tiktoken_wrapper import TikTokenizer\r\n      5 \r\n      6 \r\n\r\n[/usr/local/lib/python3.10/dist-packages/swarm_models/__init__.py](https://localhost:8080/#) in <module>\r\n     39 from swarm_models.sam_two import GroundedSAMTwo\r\n     40 from swarm_models.utils import *  # NOQA\r\n---> 41 from swarm_models.together_llm import TogetherLLM\r\n     42 from swarm_models.lite_llm_model import LiteLLM\r\n     43 \r\n\r\n[/usr/local/lib/python3.10/dist-packages/swarm_models/together_llm.py](https://localhost:8080/#) in <module>\r\n      3 import loguru\r\n      4 from dotenv import load_dotenv\r\n----> 5 from together import Together\r\n      6 \r\n      7 load_dotenv()\r\n\r\n[/usr/local/lib/python3.10/dist-packages/together/__init__.py](https://localhost:8080/#) in <module>\r\n      4 from typing import TYPE_CHECKING, Callable\r\n      5 \r\n----> 6 from together import (\r\n      7     abstract,\r\n      8     client,\r\n\r\n[/usr/local/lib/python3.10/dist-packages/together/client.py](https://localhost:8080/#) in <module>\r\n      4 from typing import Dict\r\n      5 \r\n----> 6 from together import resources\r\n      7 from together.constants import BASE_URL, MAX_RETRIES, TIMEOUT_SECS\r\n      8 from together.error import AuthenticationError\r\n\r\n[/usr/local/lib/python3.10/dist-packages/together/resources/__init__.py](https://localhost:8080/#) in <module>\r\n----> 1 from together.resources.chat import AsyncChat, Chat\r\n      2 from together.resources.completions import AsyncCompletions, Completions\r\n      3 from together.resources.embeddings import AsyncEmbeddings, Embeddings\r\n      4 from together.resources.files import AsyncFiles, Files\r\n      5 from together.resources.finetune import AsyncFineTuning, FineTuning\r\n\r\n[/usr/local/lib/python3.10/dist-packages/together/resources/chat/__init__.py](https://localhost:8080/#) in <module>\r\n      1 from functools import cached_property\r\n      2 \r\n----> 3 from together.resources.chat.completions import AsyncChatCompletions, ChatCompletions\r\n      4 from together.types import (\r\n      5     TogetherClient,\r\n\r\n[/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py](https://localhost:8080/#) in <module>\r\n      3 from typing import Any, AsyncGenerator, Dict, Iterator, List\r\n      4 \r\n----> 5 from together.abstract import api_requestor\r\n      6 from together.together_response import TogetherResponse\r\n      7 from together.types import (\r\n\r\n[/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py](https://localhost:8080/#) in <module>\r\n     31 \r\n     32 import together\r\n---> 33 from together import error, utils\r\n     34 from together.constants import (\r\n     35     BASE_URL,\r\n\r\n[/usr/local/lib/python3.10/dist-packages/together/error.py](https://localhost:8080/#) in <module>\r\n      6 from requests import RequestException\r\n      7 \r\n----> 8 from together.types.error import TogetherErrorResponse\r\n      9 \r\n     10 \r\n\r\n[/usr/local/lib/python3.10/dist-packages/together/types/__init__.py](https://localhost:8080/#) in <module>\r\n     21     FileType,\r\n     22 )\r\n---> 23 from together.types.finetune import (\r\n     24     FinetuneDownloadResult,\r\n     25     FinetuneList,\r\n\r\n[/usr/local/lib/python3.10/dist-packages/together/types/finetune.py](https://localhost:8080/#) in <module>\r\n      4 from typing import List, Literal\r\n      5 \r\n----> 6 from pydantic import StrictBool, Field, validator, field_validator\r\n      7 \r\n      8 from together.types.abstract import BaseModel\r\n\r\n[/usr/local/lib/python3.10/dist-packages/pydantic/__init__.py](https://localhost:8080/#) in __getattr__(attr_name)\r\n    402             f'Importing {attr_name} from `pydantic` is deprecated. This feature is either no longer supported, or is not public.',\r\n    403             DeprecationWarning,\r\n--> 404             stacklevel=2,\r\n    405         )\r\n    406 \r\n\r\n[/usr/lib/python3.10/importlib/__init__.py](https://localhost:8080/#) in import_module(name, package)\r\n    124                 break\r\n    125             level += 1\r\n--> 126     return _bootstrap._gcd_import(name[level:], package, level)\r\n    127 \r\n    128 \r\n\r\n[/usr/local/lib/python3.10/dist-packages/pydantic/deprecated/class_validators.py](https://localhost:8080/#) in <module>\r\n     10 from typing_extensions import Literal, Protocol, TypeAlias, deprecated\r\n     11 \r\n---> 12 from .._internal import _decorators, _decorators_v1\r\n     13 from ..errors import PydanticUserError\r\n     14 from ..warnings import PydanticDeprecatedSince20\r\n\r\n[/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_decorators_v1.py](https://localhost:8080/#) in <module>\r\n     10 \r\n     11 from ..errors import PydanticUserError\r\n---> 12 from ._utils import can_be_positional\r\n     13 \r\n     14 \r\n\r\nImportError: cannot import name 'can_be_positional' from 'pydantic._internal._utils' (/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_utils.py)\r\n\r\n---------------------------------------------------------------------------\r\nNOTE: If your import is failing due to a missing package, you can\r\nmanually install dependencies using either !pip or !apt.\r\n\r\nTo view examples of installing some common dependencies, click the\r\n\"Open Examples\" button below.\r\n---------------------------------------------------------------------------\r\n```\r\n\r\nThis looks like an error in the Together LLM code, not swarms code.",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2024-12-04T16:39:36Z",
      "updated_at": "2025-03-20T16:24:48Z",
      "closed_at": "2024-12-04T18:12:46Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/659/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/659",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/659",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:16.410987",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "This is now resolved.",
          "created_at": "2024-12-04T18:12:46Z"
        }
      ]
    },
    {
      "issue_number": 658,
      "title": "[BUG] Simple Example fails due to together import",
      "body": "**Describe the bug**\r\nA fresh install in a colab notebook of the most recent swarms:\r\n```\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n[<ipython-input-23-14444884eff9>](https://localhost:8080/#) in <cell line: 1>()\r\n----> 1 from swarms import Agent\r\n      2 \r\n      3 agent = Agent(\r\n      4     agent_name=\"Stock-Analysis-Agent\",\r\n      5     model_name=\"gpt-4o-mini\",\r\n\r\n8 frames\r\n[/content/swarms/swarms/__init__.py](https://localhost:8080/#) in <module>\r\n     11 \r\n     12 # Import telemetry functions with error handling\r\n---> 13 from swarms.telemetry.bootup import bootup  # noqa: E402, F403\r\n     14 from swarms.telemetry.sentry_active import (  # noqa: E402\r\n     15     activate_sentry,\r\n\r\n[/content/swarms/swarms/telemetry/bootup.py](https://localhost:8080/#) in <module>\r\n      4 from concurrent.futures import ThreadPoolExecutor\r\n      5 \r\n----> 6 from swarms.telemetry.auto_upgrade_swarms import auto_update\r\n      7 from swarms.utils.disable_logging import disable_logging\r\n      8 \r\n\r\n[/content/swarms/swarms/telemetry/auto_upgrade_swarms.py](https://localhost:8080/#) in <module>\r\n      2 import subprocess\r\n      3 \r\n----> 4 from swarms.utils.loguru_logger import initialize_logger\r\n      5 from swarms.telemetry.check_update import check_for_update\r\n      6 \r\n\r\n[/content/swarms/swarms/utils/__init__.py](https://localhost:8080/#) in <module>\r\n     14 )\r\n     15 from swarms.utils.markdown_message import display_markdown_message\r\n---> 16 from swarms.tools.prebuilt.math_eval import math_eval\r\n     17 from swarms.utils.parse_code import extract_code_from_markdown\r\n     18 from swarms.utils.pdf_to_text import pdf_to_text\r\n\r\n[/content/swarms/swarms/tools/__init__.py](https://localhost:8080/#) in <module>\r\n     23 from swarms.tools.openai_tool_creator_decorator import tool\r\n     24 from swarms.tools.base_tool import BaseTool\r\n---> 25 from swarms.tools.prebuilt import *  # noqa: F403\r\n     26 from swarms.tools.cohere_func_call_schema import (\r\n     27     CohereFuncSchema,\r\n\r\n[/content/swarms/swarms/tools/prebuilt/__init__.py](https://localhost:8080/#) in <module>\r\n      1 from swarms.tools.prebuilt.math_eval import math_eval\r\n----> 2 from swarms.tools.prebuilt.code_executor import CodeExecutor\r\n      3 \r\n      4 __all__ = [\r\n      5     \"math_eval\",\r\n\r\n[/content/swarms/swarms/tools/prebuilt/code_executor.py](https://localhost:8080/#) in <module>\r\n      2 import subprocess\r\n      3 from loguru import logger\r\n----> 4 from swarm_models.tiktoken_wrapper import TikTokenizer\r\n      5 \r\n      6 \r\n\r\n[/usr/local/lib/python3.10/dist-packages/swarm_models/__init__.py](https://localhost:8080/#) in <module>\r\n     39 from swarm_models.sam_two import GroundedSAMTwo\r\n     40 from swarm_models.utils import *  # NOQA\r\n---> 41 from swarm_models.together_llm import TogetherLLM\r\n     42 from swarm_models.lite_llm_model import LiteLLM\r\n     43 \r\n\r\n[/usr/local/lib/python3.10/dist-packages/swarm_models/together_llm.py](https://localhost:8080/#) in <module>\r\n      3 import loguru\r\n      4 from dotenv import load_dotenv\r\n----> 5 from together import Together\r\n      6 \r\n      7 load_dotenv()\r\n\r\nImportError: cannot import name 'Together' from 'together' (/usr/local/lib/python3.10/dist-packages/together/__init__.py)\r\n\r\n---------------------------------------------------------------------------\r\nNOTE: If your import is failing due to a missing package, you can\r\nmanually install dependencies using either !pip or !apt.\r\n\r\nTo view examples of installing some common dependencies, click the\r\n\"Open Examples\" button below.\r\n---------------------------------------------------------------------------\r\n```\r\n\r\nThe code I was running:\r\n```\r\nfrom swarms import Agent\r\n\r\nagent = Agent(\r\n    agent_name=\"Stock-Analysis-Agent\",\r\n    model_name=\"gpt-4o-mini\",\r\n    max_loops=\"auto\",\r\n    interactive=True,\r\n    streaming_on=True,\r\n)\r\n\r\nagent.run(\"What is the current market trend for tech stocks?\")\r\n```\r\n\r\nThis looks to be a bug in  \r\nhttps://github.com/The-Swarm-Corporation/swarm-models/blob/737cf8f1115664bfabf311b9a5f3f9f89fd065fd/swarm_models/together_llm.py\r\n\r\nOpening issue there also.",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2024-12-03T22:41:23Z",
      "updated_at": "2025-03-20T16:24:48Z",
      "closed_at": "2024-12-04T16:33:46Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/658/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/658",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/658",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:16.752172",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "Will need to be fixed by https://github.com/The-Swarm-Corporation/swarm-models/issues/11",
          "created_at": "2024-12-03T22:42:11Z"
        },
        {
          "author": "evelynmitchell",
          "body": "This looks resolved in 6.4.9 Closing.",
          "created_at": "2024-12-04T16:33:46Z"
        }
      ]
    },
    {
      "issue_number": 656,
      "title": "[BUG] [Artifacts are not working as expected]",
      "body": "- no file is being generated\r\n\r\n\r\n```python\r\nfrom swarms import Agent\r\n\r\nAgent(\r\n    agent_name=\"Stock-Analysis-Agent\",\r\n    model_name=\"gpt-4o-mini\",\r\n    max_loops=1,\r\n    interactive=False,\r\n    streaming_on=True,\r\n    artifacts_on=True,\r\n    artifacts_output_path=\"hft_stocks\",\r\n    artifacts_file_extension=\".md\",\r\n).run(\"What are 5 hft algorithms\")\r\n\r\n\r\n```",
      "state": "closed",
      "author": "kyegomez",
      "author_type": "User",
      "created_at": "2024-12-03T17:46:00Z",
      "updated_at": "2025-03-20T16:24:48Z",
      "closed_at": "2024-12-10T18:47:59Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/656/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/656",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/656",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:17.082461",
      "comments": []
    },
    {
      "issue_number": 639,
      "title": "[BUG] 'Agent' object has no attribute 'all_gpus'",
      "body": "**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\nIn swarms.structs.agent.py:\r\nAgent Class, class member \"all_gpus\" is not declare in __init__,\r\n\r\nwhich leads to member function un() error. due to this following line of code\r\n    all_gpus = all_gpus or self.all_gpus\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n\r\nin example.py:\r\n\r\nuser has to add following extra line of code to make program work:\r\nagent.all_gpus = False\r\n\r\nresult = agent.run(\r\n    \"How can I establish a ROTH IRA to buy stocks and get a tax break? What are the criteria. Create a report on this question.\",\r\n    all_cores=True,\r\n)\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.",
      "state": "closed",
      "author": "doncat99",
      "author_type": "User",
      "created_at": "2024-11-20T07:28:13Z",
      "updated_at": "2025-03-20T16:24:47Z",
      "closed_at": "2025-01-13T18:39:40Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/639/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/639",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/639",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:17.082483",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-11-20T07:28:35Z"
        },
        {
          "author": "kyegomez",
          "body": "@doncat99 hey it should be fixed now, please update your swarms package: `pip3 install -U swarms clusterops`",
          "created_at": "2024-11-21T23:27:13Z"
        },
        {
          "author": "kyegomez",
          "body": "@doncat99 and also try `pip3 install -U swarms`",
          "created_at": "2024-11-25T23:06:35Z"
        }
      ]
    },
    {
      "issue_number": 632,
      "title": "[BUG] Swarms Environment Variables and Template Swarms",
      "body": "**Describe the bug**\r\nWas running  Legal-Swarm-Template/main.py in a colab notebook with python 3.10:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/content/Legal-Swarm-Template/main.py\", line 7, in <module>\r\n    from swarms.agents.create_agents_from_yaml import (\r\n  File \"/usr/local/lib/python3.10/dist-packages/swarms/__init__.py\", line 6, in <module>\r\n    from swarms.telemetry.bootup import bootup  # noqa: E402, F403\r\n  File \"/usr/local/lib/python3.10/dist-packages/swarms/telemetry/bootup.py\", line 7, in <module>\r\n    from swarms.utils.disable_logging import disable_logging\r\n  File \"/usr/local/lib/python3.10/dist-packages/swarms/utils/__init__.py\", line 2, in <module>\r\n    from swarms.utils.data_to_text import (\r\n  File \"/usr/local/lib/python3.10/dist-packages/swarms/utils/data_to_text.py\", line 5, in <module>\r\n    from swarms.utils.pdf_to_text import pdf_to_text\r\n  File \"/usr/local/lib/python3.10/dist-packages/swarms/utils/pdf_to_text.py\", line 2, in <module>\r\n    from swarms.utils.try_except_wrapper import try_except_wrapper\r\n  File \"/usr/local/lib/python3.10/dist-packages/swarms/utils/try_except_wrapper.py\", line 5, in <module>\r\n    from swarms.utils.loguru_logger import logger\r\n  File \"/usr/local/lib/python3.10/dist-packages/swarms/utils/loguru_logger.py\", line 8, in <module>\r\n    os.path.join(WORKSPACE_DIR, \"swarms.log\"),\r\n  File \"/usr/lib/python3.10/posixpath.py\", line 76, in join\r\n    a = os.fspath(a)\r\nTypeError: expected str, bytes or os.PathLike object, not NoneType\r\n```\r\nThe error is occurring because WORKSPACE_DIR, which is used for logging is not set. \r\n\r\nThe .env.example fot Legal-Swarms-Template only includes the OpenAI and Groq api keys.\r\n\r\nWhen someone uses the template, and not the swarms source install, they would not see the full list of environment variables assumed to be available in swarms, as shown in swarms/.env.example \r\n\r\nPerhaps a more robust swarms install process, or configuration tool could be used to set the env vars in projects that use swarms.",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2024-11-14T16:05:49Z",
      "updated_at": "2025-03-20T16:24:47Z",
      "closed_at": "2025-01-13T18:40:33Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/632/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/632",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/632",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:17.353291",
      "comments": [
        {
          "author": "patrickbdevaney",
          "body": "Bug resolved in the legal template, you have to declare WORKSPACE_DIR before loading env vars with dotenv.\r\n\r\nThis solution works across different swarms examples/cookbooks.",
          "created_at": "2024-12-20T22:40:18Z"
        }
      ]
    },
    {
      "issue_number": 629,
      "title": "[BUG] `NameError` in `GroupChat` Initialization Due to Missing `GroupChatLog` Class",
      "body": "**Describe the bug**  \r\nWhen attempting to initialize a `GroupChat` instance in the `swarms` library, a `NameError` occurs due to an undefined `GroupChatLog` class. This error blocks the successful creation of the `GroupChat` object, as it is referenced within the code but is missing from the definition or imports.\r\n\r\n**To Reproduce**  \r\nSteps to reproduce:\r\n1. Import the `GroupChat` class from the `swarms.structs.groupchat` module.\r\n2. Attempt to create a `GroupChat` instance in a Python script.\r\n3. Run the script.\r\n4. Observe the `NameError` related to `GroupChatLog`.\r\n\r\n**Expected behavior**  \r\nThe `GroupChat` instance should initialize properly, and logging functionality should work if `GroupChatLog` is intended to manage chat logs. If `GroupChatLog` is necessary, it should be properly defined or imported.\r\n\r\n**Error Output**  \r\nThe following error message is displayed:\r\n\r\n```plaintext\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 59, in <module>\r\n    group_chat = GroupChat(\r\n                 ^^^^^^^^^^\r\n  File \"groupchat.py\", line 89, in __init__\r\n    self.group_log = GroupChatLog(\r\n                     ^^^^^^^^^^^^\r\nNameError: name 'GroupChatLog' is not defined. Did you mean: 'GroupChat'?\r\n```\r\n\r\n**Additional context**  \r\nThis issue suggests that `GroupChatLog` may be missing or incorrectly referenced in the code. If it is meant to manage chat logs, an update to the library might be required to define or import `GroupChatLog` properly. As a temporary workaround, defining a basic `GroupChatLog` class can prevent the error, though logging functionality may be limited.",
      "state": "closed",
      "author": "ggiallo28",
      "author_type": "User",
      "created_at": "2024-11-11T23:19:32Z",
      "updated_at": "2025-03-20T16:24:47Z",
      "closed_at": "2025-01-09T20:29:55Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/629/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/629",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/629",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:17.568612",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-11-11T23:19:57Z"
        },
        {
          "author": "onyedikachi-david",
          "body": "Hello @kyegomez, Can i contribute to this?",
          "created_at": "2024-11-27T02:30:28Z"
        },
        {
          "author": "kyegomez",
          "body": "Of course\r\n\r\nSincerely, Kye",
          "created_at": "2024-11-27T02:34:17Z"
        }
      ]
    },
    {
      "issue_number": 628,
      "title": "[BUG] Error executing with n-CPU cores",
      "body": "**Describe the bug**\r\n\r\n***When running:***\r\nsample `Single Agent` code from https://docs.swarms.world/en/latest/swarms/install/quickstart/\r\n```\r\nagent.run(\r\n    \"How can I establish a ROTH ...\",\r\n    device=\"cpu\",\r\n    device_id = 0 // or any variation here\r\n)\r\n```\r\n***terminal output:***\r\n```\r\npython .\\my_first_swarm.py\r\n(ProxyActor pid=43904) INFO 2024-11-11 17:41:04,501 proxy 127.0.0.1 proxy.py:1191 - Proxy starting on node 913180a87fc228a16b60f641ccd175289aaa4e2b096ab91c95ab90de (HTTP port: 8000).\r\n2024-11-11T17:41:04.577002-0500 | INFO | Autosaved prompt 29139c5a0d2742d6841edf87c2b0a9e5 to agent_workspace\\prompts\\prompt-id-29139c5a0d2742d6841edf87c2b0a9e5.json.\r\n2024-11-11T17:41:07.783685-0500 Attempting to run on device: cpu\r\n2024-11-11T17:41:07.784686-0500 Device set to CPU\r\n2024-11-11T17:41:07.785684-0500 Using all available CPU cores: 24\r\n2024-11-11T17:41:07.786685-0500 Available CPUs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\r\n2024-11-11T17:41:07.786685-0500 Error executing with 24 CPU cores: Invalid core count: 24. Available CPUs are [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11].\r\n2024-11-11T17:41:08.786990-0500 Available CPUs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\r\n2024-11-11T17:41:08.787991-0500 Error executing with 24 CPU cores: Invalid core count: 24. Available CPUs are [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11].\r\n2024-11-11T17:41:09.794937-0500 Available CPUs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\r\n2024-11-11T17:41:09.885148-0500 Error executing with 24 CPU cores: Invalid core count: 24. Available CPUs are [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11].\r\n2024-11-11T17:41:09.885148-0500 An error occurred during execution: RetryError[<Future at 0x200aaed3a60 state=finished raised ValueError>]\r\nTraceback (most recent call last):\r\n  File \"C:\\...\\miniconda3\\envs\\swarm\\lib\\site-packages\\tenacity\\__init__.py\", line 478, in __call__\r\n    result = fn(*args, **kwargs)\r\n  File \"C:\\...\\miniconda3\\envs\\swarm\\lib\\site-packages\\clusterops\\main.py\", line 199, in execute_with_cpu_cores\r\n    raise ValueError(\r\nValueError: Invalid core count: 24. Available CPUs are [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11].\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\...\\my_first_swarm.py\", line 28, in <module>\r\n    out = out = agent.run(\r\n  File \"C:\\...\\miniconda3\\envs\\swarm\\lib\\site-packages\\swarms\\structs\\agent.py\", line 2308, in run\r\n    raise e\r\n  File \"C:\\...\\miniconda3\\envs\\swarm\\lib\\site-packages\\swarms\\structs\\agent.py\", line 2289, in run\r\n    return execute_with_cpu_cores(\r\n  File \"C:\\...\\miniconda3\\envs\\swarm\\lib\\site-packages\\tenacity\\__init__.py\", line 336, in wrapped_f\r\n    return copy(f, *args, **kw)\r\n  File \"C:\\...\\miniconda3\\envs\\swarm\\lib\\site-packages\\tenacity\\__init__.py\", line 475, in __call__\r\n    do = self.iter(retry_state=retry_state)\r\n  File \"C:\\...\\miniconda3\\envs\\swarm\\lib\\site-packages\\tenacity\\__init__.py\", line 376, in iter\r\n    result = action(retry_state)\r\n  File \"C:\\...\\miniconda3\\envs\\swarm\\lib\\site-packages\\tenacity\\__init__.py\", line 419, in exc_check\r\n    raise retry_exc from fut.exception()\r\ntenacity.RetryError: RetryError[<Future at 0x200aaed3a60 state=finished raised ValueError>]\r\nSentry is attempting to send 2 pending events\r\nWaiting up to 2 seconds\r\nPress Ctrl-Break to quit\r\n```\r\n**/prompts/Financial-Analysis-Agent.log**\r\n```\r\n\u001b[32m2024-11-11 18:02:46.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mswarms.structs.agent\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m2277\u001b[0m - \u001b[1mAttempting to run on device: cpu\u001b[0m\r\n\u001b[32m2024-11-11 18:02:46.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mswarms.structs.agent\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m2279\u001b[0m - \u001b[1mDevice set to CPU\u001b[0m\r\n\u001b[32m2024-11-11 18:02:46.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mswarms.structs.agent\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m2282\u001b[0m - \u001b[1mUsing all available CPU cores: 24\u001b[0m\r\n\u001b[32m2024-11-11 18:02:46.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mclusterops.main\u001b[0m:\u001b[36mlist_available_cpus\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAvailable CPUs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\u001b[0m\r\n\u001b[32m2024-11-11 18:02:46.366\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mclusterops.main\u001b[0m:\u001b[36mexecute_with_cpu_cores\u001b[0m:\u001b[36m221\u001b[0m - \u001b[31m\u001b[1mError executing with 24 CPU cores: Invalid core count: 24. Available CPUs are [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11].\u001b[0m\r\n\u001b[32m2024-11-11 18:02:47.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mclusterops.main\u001b[0m:\u001b[36mlist_available_cpus\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAvailable CPUs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\u001b[0m\r\n\u001b[32m2024-11-11 18:02:47.382\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mclusterops.main\u001b[0m:\u001b[36mexecute_with_cpu_cores\u001b[0m:\u001b[36m221\u001b[0m - \u001b[31m\u001b[1mError executing with 24 CPU cores: Invalid core count: 24. Available CPUs are [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11].\u001b[0m\r\n\u001b[32m2024-11-11 18:02:48.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mclusterops.main\u001b[0m:\u001b[36mlist_available_cpus\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAvailable CPUs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\u001b[0m\r\n\u001b[32m2024-11-11 18:02:48.393\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mclusterops.main\u001b[0m:\u001b[36mexecute_with_cpu_cores\u001b[0m:\u001b[36m221\u001b[0m - \u001b[31m\u001b[1mError executing with 24 CPU cores: Invalid core count: 24. Available CPUs are [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11].\u001b[0m\r\n\u001b[32m2024-11-11 18:02:48.394\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mswarms.structs.agent\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m2307\u001b[0m - \u001b[31m\u001b[1mAn error occurred during execution: RetryError[<Future at 0x23ad1dc7cd0 state=finished raised ValueError>]\u001b[0m\r\n```\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Using Conda for environment\r\n1. Running sample `Single Agent` code from https://docs.swarms.world/en/latest/swarms/install/quickstart/\r\n1. In `VS Code` click \"Run\" button\r\n\r\n**Additional context**\r\n|  |  |\r\n| --- | --- |\r\n|Windows |11|\r\n|VS Code| latest|\r\n|Conda | 24.9.2 |\r\n|Python | 3.10.15 |\r\n| pip | 24.2|\r\n| swarms | 6.0.9 |\r\n| swarms-memory | 0.1.2 |\r\n| swarms-models | 0.1.3 |",
      "state": "closed",
      "author": "AlanThinks",
      "author_type": "User",
      "created_at": "2024-11-11T23:06:43Z",
      "updated_at": "2025-03-20T16:24:47Z",
      "closed_at": "2025-02-13T20:22:47Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/628/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/628",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/628",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:17.903980",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-11-11T23:07:07Z"
        },
        {
          "author": "kyegomez",
          "body": "@AlanThinks this error should be fixed now, let me know if you're still facing the same issue. I've also made it optional to use clusterops which is where this error originated from .",
          "created_at": "2024-12-14T04:40:01Z"
        },
        {
          "author": "kyegomez",
          "body": "@",
          "created_at": "2025-02-13T20:22:47Z"
        }
      ]
    },
    {
      "issue_number": 623,
      "title": "[BUG] \"No module name 'uvloop'",
      "body": "**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. windows 11, conda env python 3.12\r\n2. pip install swarms\r\n3. (some difficulty with installation requiring compilation of chroma-hnswlib, which can be resolved by installing MS build tools or with manually installing conda package)\r\n4. code crashes at `>from swarms import Agent`\r\n\r\n\r\n\r\n\r\n**Expected behavior**\r\nexample code would run seemlessly\r\n\r\n**Screenshots**\r\n\r\n\r\n**Additional context**\r\nuvloop not in requirements or pyproject.toml\r\n\r\nuvloop not compatible with windows.\r\n\r\nproblematic uvloop import in file `...swarms\\structs\\multi_agent_exec.py`",
      "state": "closed",
      "author": "ec-lp",
      "author_type": "User",
      "created_at": "2024-11-04T17:19:43Z",
      "updated_at": "2025-03-20T16:24:47Z",
      "closed_at": "2024-11-11T21:23:56Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/623/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/623",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/623",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:18.247175",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-11-04T17:20:08Z"
        },
        {
          "author": "kyegomez",
          "body": "@ec-lp update your swarms pip package `pip3 install -U swarms`! and let me know of the new changes",
          "created_at": "2024-11-04T19:09:30Z"
        }
      ]
    },
    {
      "issue_number": 618,
      "title": "[BUG] Canot start swarms because of undefined ENV var WORKSPACE_DIR",
      "body": "**Describe the bug**\r\nHappened directly after installing. Can't interact with the cli nor can I start a script. I always get the same error.\r\nIt seems that the variable WORKSPACE_DIR needs to be set for some reason.\r\n\r\n**To Reproduce**\r\n1. Install swarms\r\n2. Run anything with swarms\r\n\r\n**Expected behavior**\r\nIt should run.\r\n\r\n**Traceback*\r\n.venv/lib/python3.11/site-packages/swarms/utils/loguru_logger.py\", line 10, in <module>\r\n    os.path.join(WORKSPACE_DIR, \"swarms.log\"),\r\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"<frozen posixpath>\", line 76, in join\r\nTypeError: expected str, bytes or os.PathLike object, not NoneType",
      "state": "closed",
      "author": "Fadope1",
      "author_type": "User",
      "created_at": "2024-10-28T20:52:23Z",
      "updated_at": "2025-03-20T16:24:46Z",
      "closed_at": "2024-10-28T20:54:55Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/618/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/618",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/618",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:18.536908",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-10-28T20:52:51Z"
        },
        {
          "author": "Fadope1",
          "body": "Found that in the docs it says to add this ENV var. But in the github README its not there.",
          "created_at": "2024-10-28T20:54:55Z"
        },
        {
          "author": "kyegomez",
          "body": "@Fadope1 Hey excuse the error, we showcase the setting in the requirements section of the README.md let me know if you would like more assistance!",
          "created_at": "2024-10-28T22:27:44Z"
        }
      ]
    },
    {
      "issue_number": 616,
      "title": "[BUG] Dependency Conflicts with Swarms and Langchain Packages",
      "body": "**Describe the bug**\r\nCurrently experiencing a recurring dependency conflict caused by outdated versions of langchain-community and langchain-experimental within the latest release of swarms (5.8.6).\r\n**Error Details:**\r\n```\r\nERROR: Cannot install -r /requirements.txt (line 127), -r /requirements.txt (line 312) and langchain-community==0.3.2 because these package versions have conflicting dependencies.\r\n\r\nThe conflict is caused by:\r\n  - The project requires `langchain-community==0.3.2`\r\n  - `langchain-experimental 0.3.2` depends on `langchain-community<0.4.0, >=0.3.0`\r\n  - `swarms 5.8.6` depends on `langchain-community==0.0.29`\r\n```\r\n\r\n\r\n**Additional context**\r\nThe issue stems from running swarms 5.8.6 relying on an older version of langchain-community (0.0.29), which is incompatible with newer versions of langchain-experimental and langchain-community (which some other functionalities depend on). Interestingly, earlier versions of swarms, such as 2.2.9, appear to support more recent dependencies than the latest version supports.",
      "state": "closed",
      "author": "ao2-tech",
      "author_type": "User",
      "created_at": "2024-10-27T21:21:01Z",
      "updated_at": "2025-03-20T16:24:46Z",
      "closed_at": "2025-02-13T20:50:57Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/616/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/616",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/616",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:18.783449",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-10-27T21:21:26Z"
        },
        {
          "author": "kyegomez",
          "body": "@ao2-tech i need to update the requirements.txt with my personal requirements and check to see what packages I have on my computer",
          "created_at": "2024-10-28T15:09:00Z"
        },
        {
          "author": "kyegomez",
          "body": "@ao2-tech @www langchain has been deleted from swarms completely",
          "created_at": "2025-02-13T20:50:57Z"
        }
      ]
    },
    {
      "issue_number": 607,
      "title": "[BUG] tools can not be executed if long_term_memory is not None",
      "body": "![image](https://github.com/user-attachments/assets/6ef6baf4-7c82-4c25-b499-e71744fb1629)",
      "state": "closed",
      "author": "lometheus",
      "author_type": "User",
      "created_at": "2024-10-15T08:22:21Z",
      "updated_at": "2025-03-20T16:24:46Z",
      "closed_at": "2025-01-13T18:41:07Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/607/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/607",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/607",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:18.983558",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@lometheus this should be fixed, please let me know. Update your swarms: `pip3 install -U swarms` and try running the new example!\r\n\r\nThe RAG should also be fixed",
          "created_at": "2024-11-04T19:11:46Z"
        }
      ]
    },
    {
      "issue_number": 605,
      "title": "[BUG] pug with BaseTool init",
      "body": "when i try example with this https://docs.swarms.world/en/latest/swarms/tools/build_tool/#integrate-tools-into-agent\r\n\r\ni get this error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/Users/fenyi/codesy/swarm-test/test.py\", line 109, in <module>\r\n    agent1 = Agent(\r\n             ^^^^^^\r\n  File \"/Users/fenyi/codesy/swarm-test/.venv/lib/python3.12/site-packages/swarms/structs/agent.py\", line 407, in __init__\r\n    self.tool_struct = BaseTool(\r\n                       ^^^^^^^^^\r\n  File \"/Users/fenyi/codesy/swarm-test/.venv/lib/python3.12/site-packages/pydantic/main.py\", line 194, in __init__\r\n    self.__pydantic_validator__.validate_python(data, self_instance=self)\r\npydantic_core._pydantic_core.ValidationError: 1 validation error for BaseTool\r\nbase_models\r\n  Input should be a valid list [type=list_type, input_value=None, input_type=NoneType]\r\n    For further information visit https://errors.pydantic.dev/2.8/v/list_type\r\nSentry is attempting to send 2 pending events\r\n\r\n```\r\n\r\nbug from here\r\n![image](https://github.com/user-attachments/assets/17070d0b-4455-4041-ae03-7a02b84270ee)\r\n\r\nactually list_base_models does not have default value, \r\n![image](https://github.com/user-attachments/assets/bfe97fbb-97a8-403d-8f09-c81676e05a94)\r\n\r\nyou can ealisy find this question with this code\r\n`from swarms import Agent\r\nfrom swarms.prompts.tools import tool_sop_prompt\r\n\r\nfrom swarm_models import OpenAIChat\r\nfrom swarms_memory import ChromaDB\r\nimport subprocess\r\nimport os\r\nfrom swarms.tools.base_tool import BaseTool\r\n\r\ndef terminal(\r\n    code: str,\r\n):\r\n    \"\"\"\r\n    Run code in the terminal.\r\n\r\n    Args:\r\n        code (str): The code to run in the terminal.\r\n\r\n    Returns:\r\n        str: The output of the code.\r\n    \"\"\"\r\n    out = subprocess.run(\r\n        code, shell=True, capture_output=True, text=True\r\n    ).stdout\r\n    return str(out)\r\n\r\n\r\nBaseTool(\r\ntools=[terminal],\r\nbase_models=None,\r\ntool_system_prompt=tool_sop_prompt(),\r\n)`",
      "state": "closed",
      "author": "lometheus",
      "author_type": "User",
      "created_at": "2024-10-14T14:39:36Z",
      "updated_at": "2025-03-20T16:24:46Z",
      "closed_at": "2025-02-19T00:11:27Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/605/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/605",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/605",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:19.200478",
      "comments": [
        {
          "author": "lometheus",
          "body": "i believe give list_base_models a default value  in class Agent can relsove this question",
          "created_at": "2024-10-14T14:46:32Z"
        },
        {
          "author": "peytontolbert",
          "body": "submitted pull request to fix this issue",
          "created_at": "2024-10-14T23:01:24Z"
        },
        {
          "author": "kyegomez",
          "body": "@lometheus is this fixed now? let me know so we can fix it?",
          "created_at": "2025-01-09T21:20:20Z"
        }
      ]
    },
    {
      "issue_number": 604,
      "title": "[BUG] i just want try an agent in local, please not ask swarms.world, i need sample mod",
      "body": "requests.exceptions.SSLError: HTTPSConnectionPool(host='swarms.world', port=443): Max retries exceeded with url: /api/get-agents/log-agents (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1000)')))\r\nSentry is attempting to send 2 pending events\r\nWaiting up to 2 seconds",
      "state": "closed",
      "author": "lometheus",
      "author_type": "User",
      "created_at": "2024-10-14T12:41:18Z",
      "updated_at": "2025-03-20T16:24:46Z",
      "closed_at": "2025-02-13T20:49:38Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/604/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/604",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/604",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:19.414424",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-10-14T12:41:45Z"
        },
        {
          "author": "patrickbdevaney",
          "body": "> requests.exceptions.SSLError: HTTPSConnectionPool(host='swarms.world', port=443): Max retries exceeded with url: /api/get-agents/log-agents (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ss",
          "created_at": "2024-12-16T04:45:02Z"
        }
      ]
    },
    {
      "issue_number": 602,
      "title": "[BUG] Unable to import AzureOpenAI",
      "body": "**Describe the bug**\r\nUnable to import AzureOpenAI\r\n\r\n**To Reproduce**\r\nImport AzureOpenAI from swarms\r\n\r\n**Expected behavior**\r\nShould be able to import AzureOpenAI",
      "state": "closed",
      "author": "techthiyanes",
      "author_type": "User",
      "created_at": "2024-10-14T04:14:50Z",
      "updated_at": "2025-03-20T16:24:46Z",
      "closed_at": "2024-10-14T14:34:52Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/602/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/602",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/602",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:19.659157",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-10-14T04:15:13Z"
        },
        {
          "author": "kyegomez",
          "body": "@techthiyanes try the swarm_models package. all of the models have been moved here\r\n\r\n```\r\n$ pip3 install -U swarm_models\r\n```\r\n\r\n[Documentation is here](https://docs.swarms.world/en/latest/swarms/models/models_available_overview/)\r\n\r\n```\r\nimport os\r\nfrom dotenv import load_dotenv\r\nfrom swarms impor",
          "created_at": "2024-10-14T14:20:34Z"
        },
        {
          "author": "techthiyanes",
          "body": "Thank you so much on your response. I am able to import it now.",
          "created_at": "2024-10-14T14:34:43Z"
        }
      ]
    },
    {
      "issue_number": 600,
      "title": "[BUG] No module named 'swarms_cloud.utils",
      "body": "**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Update swarms package\r\n2. Run script with 'from swarms import Agent' and run an agent\r\n3. See error:\r\n```\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\billionpersonas\\extract.py\", line 4, in <module>\r\n    from swarms import Agent\r\n  File \"D:\\anaconda3\\envs\\swarms\\Lib\\site-packages\\swarms\\__init__.py\", line 10, in <module>\r\n    from swarms.agents import *  # noqa: E402, F403\r\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\anaconda3\\envs\\swarms\\Lib\\site-packages\\swarms\\agents\\__init__.py\", line 13, in <module>\r\n    from swarms.agents.tool_agent import ToolAgent\r\n  File \"D:\\anaconda3\\envs\\swarms\\Lib\\site-packages\\swarms\\agents\\tool_agent.py\", line 3, in <module>\r\n    from swarms.structs.agent import Agent\r\n  File \"D:\\anaconda3\\envs\\swarms\\Lib\\site-packages\\swarms\\structs\\__init__.py\", line 1, in <module>\r\n    from swarms.structs.agent import Agent\r\n  File \"D:\\anaconda3\\envs\\swarms\\Lib\\site-packages\\swarms\\structs\\agent.py\", line 30, in <module>\r\n    from swarms.prompts.agent_system_prompts import AGENT_SYSTEM_PROMPT_3\r\n  File \"D:\\anaconda3\\envs\\swarms\\Lib\\site-packages\\swarms\\prompts\\__init__.py\", line 10, in <module>\r\n    from swarms.prompts.prompt import Prompt\r\n  File \"D:\\anaconda3\\envs\\swarms\\Lib\\site-packages\\swarms\\prompts\\prompt.py\", line 13, in <module>\r\n    from swarms_cloud.utils.log_to_swarms_database import log_agent_data\r\nModuleNotFoundError: No module named 'swarms_cloud.utils.log_to_swarms_database'\r\nSentry is attempting to send 2 pending events\r\nWaiting up to 2 seconds\r\nPress Ctrl-Break to quit\r\n\r\n```\r\n**Expected behavior**\r\nSupposed to run the agent\r\n\r\n**Additional context**\r\nhad to update swarms_cloud: pip install -U swarms-cloud\r\n\r\n\r\nmay want to be include this with swarms install",
      "state": "closed",
      "author": "peytontolbert",
      "author_type": "User",
      "created_at": "2024-10-13T18:11:08Z",
      "updated_at": "2025-03-20T16:24:46Z",
      "closed_at": "2024-10-28T16:50:59Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/600/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/600",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/600",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:19.917847",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@peytontolbert this issue should be fixed now, I have set a range for the `swarms-cloud` repo, lmk if anyone else has it. I will leave this issue for now until it's certain the issue has been terminated",
          "created_at": "2024-10-14T00:32:19Z"
        }
      ]
    },
    {
      "issue_number": 559,
      "title": "[BUG] `Error checking stopping condition: 'str' object is not callable` error when using a very, very basic agent.",
      "body": "**Describe the bug**\r\n\r\nWhen using a very basic `Agent` to test functionality, after adding the `stopping_condition` as a string to the `Agent()` class construction, I see the error shown in the issue title.\r\n\r\n**To Reproduce**\r\n\r\nThis is the `Agent` code:\r\n\r\n```\r\ndumb_agent = Agent(agent_name='dumb-tester',\r\n                   agent_description=('does dumb things'),\r\n                   llm=get_groq_llm(),\r\n                   max_loops=10,\r\n                   verbose=True,\r\n                   stopping_condition=\"finish\")\r\n```\r\n\r\nThis is how I run it:\r\n\r\n```\r\ndumb_agent.run('make me a linked in post about machine learning. it can only be 240 chars. output the text and the # of chars used. provide detailed reasoning why you chose the wording for this post.')\r\n```\r\n\r\nDespite a successful run on the first \"loop,\" the agent runs to the maximum loop number because there's no stopping condition.",
      "state": "closed",
      "author": "aimzieslol",
      "author_type": "User",
      "created_at": "2024-08-09T14:57:22Z",
      "updated_at": "2025-03-20T16:24:45Z",
      "closed_at": "2025-02-19T00:15:12Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/559/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/559",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/559",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:20.140568",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@aimzieslol the stopping condition is supposed to be a callable function, i think what you're looking for is the `stopping_token=\"finish\"`, let me know if this works!",
          "created_at": "2024-08-09T16:35:17Z"
        },
        {
          "author": "kyegomez",
          "body": "@aimzieslol did it work well?",
          "created_at": "2024-09-20T21:55:37Z"
        },
        {
          "author": "aimzieslol",
          "body": "Latest test using the same code from before produces this error:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n[<ipython-input-4-527ba3a8ba9b>](https://localhost:8080/#) in <cell line:",
          "created_at": "2024-09-21T22:15:31Z"
        },
        {
          "author": "kyegomez",
          "body": "@aimzieslol @www @nictuku issue should be fixed, let me know!\n",
          "created_at": "2025-02-13T20:46:57Z"
        }
      ]
    },
    {
      "issue_number": 549,
      "title": "[BUG] TEST IF IT goes in project",
      "body": "**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.",
      "state": "closed",
      "author": "nicorne",
      "author_type": "User",
      "created_at": "2024-07-30T15:10:55Z",
      "updated_at": "2025-03-20T16:24:45Z",
      "closed_at": "2024-07-30T15:14:39Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/549/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/549",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/549",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:20.361569",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-07-30T15:11:21Z"
        }
      ]
    },
    {
      "issue_number": 548,
      "title": "[BUG] Error while convering custom function to openai function",
      "body": "**Describe the bug**\r\nWhen creating a new custom functions its trying to parse the function in a wrong way \r\n\r\n**To Reproduce**\r\nCreate a new custom function examples here \r\nhttps://medium.com/@kyeg/the-swarms-tool-system-functions-pydantic-basemodels-as-tools-and-radical-customization-c2a2e227b8ca\r\nand try to run it\r\n\r\n**Expected behavior**\r\nshould just perform the function call \r\n\r\n**possible fix**\r\nread the agent.py file in the sdk and edit this one line\r\n```\r\n if all(callable(tool) for tool in self.tools):\r\n```\r\nline 1611\r\nit worked for me \r\n\r\n**Additional context**\r\nmy code \r\n```\r\nfrom swarms import Agent, OpenAIChat, tool\r\nfrom pydantic import BaseModel\r\nimport requests\r\nfrom bs4 import BeautifulSoup\r\n\r\nclass SearchResult(BaseModel):\r\n    title: str\r\n    url: str\r\n    snippet: str\r\n\r\n@tool(name=\"websearch\", description=\"websearch tool\")\r\ndef web_search(query: str) -> list[SearchResult]:\r\n    \"\"\"\r\n    Perform a web search for the given query.\r\n\r\n    Args:\r\n        query (str): The search query.\r\n\r\n    Returns:\r\n        list[SearchResult]: A list of search results.\r\n    \"\"\"\r\n    url = f\"https://www.google.com/search?q={query}\"\r\n    headers = {\r\n        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\r\n    }\r\n    response = requests.get(url, headers=headers)\r\n    soup = BeautifulSoup(response.text, 'html.parser')\r\n    print(\"yo yo honey singha\")\r\n    results = []\r\n    for g in soup.find_all('div', class_='g'):\r\n        anchors = g.find_all('a')\r\n        if anchors:\r\n            link = anchors[0]['href']\r\n            title = g.find('h3', class_='r')\r\n            snippet = g.find('div', class_='s')\r\n            if title and snippet:\r\n                results.append(SearchResult(\r\n                    title=title.text,\r\n                    url=link,\r\n                    snippet=snippet.text\r\n                ))\r\n    print(results[:5], \"results\")\r\n    return results[:5]  # Return top 5 results\r\n\r\n# Initializing the agent with the OpenAI instance and other parameters\r\nagent = Agent(\r\n    agent_name=\"web search agent\",\r\n    system_prompt=\"This agent performs web searches based on user requests.\",\r\n    sop_list=[\"Perform web search\", \"Return results\"],\r\n    llm=OpenAIChat(),\r\n    max_loops=\"auto\",\r\n    interactive=True,\r\n    verbose=True,\r\n    output_type=str,\r\n    metadata_output_type=\"json\",\r\n    function_calling_format_type=\"OpenAI\",\r\n    tools=[web_search],\r\n)\r\n\r\n# Defining the task\r\ntask = \"Search for recent advancements in artificial intelligence.\"\r\n\r\n# Running the agent with the specified task\r\nout = agent.run(task)\r\nprint(out)\r\n```",
      "state": "closed",
      "author": "Occupying-Mars",
      "author_type": "User",
      "created_at": "2024-07-29T17:03:04Z",
      "updated_at": "2025-03-20T16:24:45Z",
      "closed_at": "2024-10-09T20:32:20Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/548/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/548",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/548",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:20.613246",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-07-29T17:03:29Z"
        },
        {
          "author": "kyegomez",
          "body": "@Occupying-Mars excuse me for the issue, I broke that in the last update, fixing now.",
          "created_at": "2024-08-05T21:59:54Z"
        }
      ]
    },
    {
      "issue_number": 534,
      "title": "[BUG] docker container not available",
      "body": "**Describe the bug**\r\n\"pull access denied for kyegomez/swarms, repository does not exist or may require 'docker login': denied: requested access to the resource is denied\"\r\n\r\nIt may not be on docker hub: https://hub.docker.com/search?q=kyegomez\r\n\r\nIt's definately not on ghcr.io\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. docker pull kyegomez/swarms\r\n\r\n\r\n**Expected behavior**\r\nThe pull succeeds",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2024-07-13T14:43:21Z",
      "updated_at": "2025-03-20T16:24:45Z",
      "closed_at": "2025-02-13T20:48:08Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/534/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 1,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/534",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/534",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:20.865198",
      "comments": [
        {
          "author": "patrickbdevaney",
          "body": "I was able to pull the recent swarms container using: sudo docker pull swarmscorp/swarms. The container was built for arm would not run on my machine.\r\n\r\nI'm pushing an amd64 version of the docker container for the current version of swarms, which should work for Linux based desktops. The existing a",
          "created_at": "2024-12-24T03:50:16Z"
        }
      ]
    },
    {
      "issue_number": 533,
      "title": "[BUG] 404 for linked explorer url: https://swarms.world/platform/explorer",
      "body": "**Describe the bug**\r\nDead link to https://swarms.world/platform/explorer where the swarms platform explorer is hosted at https://swarms.world\r\n\r\n**To Reproduce**\r\n\r\n1. After sign up here, the \"Explorer button\" links to https://swarms.world/platform/explorer which returns 404\r\n\r\n**Expected behavior**\r\nHTTP redirect should be redirecting https://swarms.world/platform/explorer to https://swarms.world \r\n\r\n**Screenshots**\r\n\r\n![9b09647a7fd9fa658f3a530309af5f2a](https://github.com/user-attachments/assets/fb4f7b2b-c99d-4e54-9733-20a27497d967)\r\n<img width=\"344\" alt=\"image\" src=\"https://github.com/user-attachments/assets/57d761f4-b665-4c05-b736-ac861df04f30\">\r\n\r\n\r\n**Additional context**",
      "state": "closed",
      "author": "joshcarp",
      "author_type": "User",
      "created_at": "2024-07-13T14:38:02Z",
      "updated_at": "2025-03-20T16:24:45Z",
      "closed_at": "2024-08-08T17:16:38Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/533/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/533",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/533",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:21.053492",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-07-13T14:38:27Z"
        },
        {
          "author": "kyegomez",
          "body": "@joshcarp appreciate that, yeah we just deleted the whole landing page ",
          "created_at": "2024-07-13T15:05:11Z"
        }
      ]
    },
    {
      "issue_number": 520,
      "title": "[BUG] Getting error \"local variable 'out' referenced before assignment\" when using ChromaDB long-term memory.",
      "body": "Using the `examples` I created a custom ChromaDB that looks like this:\r\n\r\n```\r\nclass ChromaMemory(BaseVectorDatabase):\r\n    def __init__(self, metric: str = \"cosine\", output_dir: str = \"swarms\", \\\r\n                 limit_tokens: Optional[int] = 1000, n_results: int = 1, \\\r\n                 docs_folder: str = None, verbose: bool = True, \\\r\n                 *args, **kwargs):\r\n        self.metric = metric\r\n        self.output_dir = output_dir\r\n        self.limit_tokens = limit_tokens\r\n        self.n_results = n_results\r\n        self.docs_folder = docs_folder\r\n        self.verbose = verbose\r\n\r\n        # Disable ChromaDB logging\r\n        if verbose:\r\n            logging.getLogger(\"chromadb\").setLevel(logging.INFO)\r\n\r\n        # Create Chroma collection\r\n        chroma_persist_dir = \"./chromadb\"\r\n        chroma_client = chromadb.PersistentClient(\r\n            settings=chromadb.config.Settings(\r\n                persist_directory=chroma_persist_dir,\r\n            ),\r\n            *args,\r\n            **kwargs,\r\n        )\r\n\r\n        # Create ChromaDB client\r\n        self.client = chromadb.Client()\r\n\r\n        # Create Chroma collection\r\n        self.collection = chroma_client.get_or_create_collection(\r\n            name=output_dir,\r\n            metadata={\"hnsw:space\": metric},\r\n            embedding_function=get_embedding_func(),\r\n            *args,\r\n            **kwargs,\r\n        )\r\n\r\n        display_markdown_message(\r\n            \"ChromaDB collection created:\"\r\n            f\" {self.collection.name} with metric: {self.metric} and\"\r\n            f\" output directory: {self.output_dir}\"\r\n        )\r\n\r\n        # If docs\r\n        if docs_folder:\r\n            display_markdown_message(\r\n                f\"Traversing directory: {docs_folder}\"\r\n            )\r\n            self.traverse_directory()\r\n\r\n    def add(self, document: str, *args, **kwargs):\r\n        \"\"\"\r\n        Add a document to the ChromaDB collection.\r\n\r\n        Args:\r\n            document (str): The document to be added.\r\n            condition (bool, optional): The condition to check before adding the document. Defaults to True.\r\n\r\n        Returns:\r\n            str: The ID of the added document.\r\n        \"\"\"\r\n        try:\r\n            doc_id = str(uuid.uuid4())\r\n            self.collection.add(ids=[doc_id], documents=[document], *args, **kwargs)\r\n            print(\"-----------------\")\r\n            print(\"Document added successfully\")\r\n            print(\"-----------------\")\r\n            return doc_id\r\n        except Exception as e:\r\n            raise Exception(f\"Failed to add document: {str(e)}\")\r\n\r\n    def query(self, query_text: str, *args, **kwargs) -> str:\r\n        \"\"\"\r\n        Query documents from the ChromaDB collection.\r\n\r\n        Args:\r\n            query (str): The query string.\r\n            n_docs (int, optional): The number of documents to retrieve. Defaults to 1.\r\n\r\n        Returns:\r\n            dict: The retrieved documents.\r\n        \"\"\"\r\n        try:\r\n            logging.info(f\"Querying documents for: {query_text}\")\r\n\r\n            docs = self.collection.query(query_texts=[query_text], n_results=self.n_results, *args, **kwargs)[\"documents\"]\r\n\r\n            # Convert into a string\r\n            # out = \"\"\r\n            # for doc in docs:\r\n            #     out += f\"{doc}\\n\"\r\n            out = \"\\n\".join([x for doc in docs for x in doc])\r\n\r\n            # Display the retrieved document\r\n            display_markdown_message(f\"Query: {query_text}\")\r\n            display_markdown_message(f\"Retrieved Document: {out}\")\r\n            display_markdown_message(f\"Retrieved Document: {type(out)}\")\r\n\r\n            return out\r\n        except Exception as e:\r\n            raise Exception(f\"Failed to query documents: {str(e)}\")\r\n\r\n    def traverse_directory(self):\r\n        \"\"\"\r\n        Traverse through every file in the given directory and its subdirectories,\r\n        and return the paths of all files.\r\n        Parameters:\r\n        - directory_name (str): The name of the directory to traverse.\r\n        Returns:\r\n        - list: A list of paths to each file in the directory and its subdirectories.\r\n        \"\"\"\r\n        added_to_db = False\r\n\r\n        for root, dirs, files in os.walk(self.docs_folder):\r\n            for file in files:\r\n                file_path = os.path.join(root, file)  # Change this line\r\n                _, ext = os.path.splitext(file_path)\r\n                data = data_to_text(file_path)\r\n                added_to_db = self.add(str(data))\r\n                print(f\"{file_path} added to Database\")\r\n\r\n        return added_to_db\r\n```\r\n\r\nMy agent setup looks like this:\r\n\r\n```\r\nmemory = ChromaMemory(metric=\"cosine\", n_results=3)\r\n\r\nagent = Agent(\r\n    agent_name=\"chat-tester\",\r\n    agent_description=(\"This agent chats with the user ... nicely.\"),\r\n    llm=get_groq_llm(),\r\n    max_loops=1,\r\n    autosave=True,\r\n    verbose=True,\r\n    long_term_memory=memory,\r\n    stopping_condition=\"finish\",\r\n)\r\n```\r\n\r\nWhen I attempt to run the agent with this command (to have it do something simple/stupid to see how memory works:\r\n\r\n```\r\nagent.run('write a linkedin and twitter post about machine learning. can only be 240 chars max.')\r\n```\r\n\r\nit seems like most of it works correctly but it complains about the `out` variable:\r\n\r\n```\r\n2024-06-29T23:31:54.369985+0000 Autonomous Agent Activated.\r\n2024-06-29T23:31:54.375412+0000 All systems operational. Executing task...\r\n2024-06-29T23:31:54.385845+0000 Tokens available: -8082\r\n2024-06-29T23:31:54.389028+0000 Querying long term memory database for write a linkedin and twitter post about machine learning. can only be 240 chars max.\r\nNumber of tokens: 110\r\n\r\nLoop 1 of 1\r\n\r\n\r\n\r\n\r\n2024-06-29T23:31:56.376794+0000 Couting tokens of retrieved document\r\n2024-06-29T23:31:56.379307+0000 Retrieved document token count 0\r\n2024-06-29T23:31:56.385940+0000 Error querying long term memory: local variable 'out' referenced before assignment\r\n2024-06-29T23:31:56.388225+0000 Attempt 1: Error generating response: local variable 'out' referenced before assignment\r\n2024-06-29T23:31:56.389074+0000 Querying long term memory database for write a linkedin and twitter post about machine learning. can only be 240 chars max.\r\nQuery: write a linkedin and twitter post about machine learning. can only be 240 chars max.\r\nRetrieved Document:\r\nRetrieved Document: <class 'str'>\r\nNumber of tokens: 0\r\n2024-06-29T23:31:56.810587+0000 Couting tokens of retrieved document\r\n2024-06-29T23:31:56.816323+0000 Retrieved document token count 0\r\n2024-06-29T23:31:56.818167+0000 Error querying long term memory: local variable 'out' referenced before assignment\r\n2024-06-29T23:31:56.820479+0000 Attempt 2: Error generating response: local variable 'out' referenced before assignment\r\n2024-06-29T23:31:56.822279+0000 Querying long term memory database for write a linkedin and twitter post about machine learning. can only be 240 chars max.\r\nQuery: write a linkedin and twitter post about machine learning. can only be 240 chars max.\r\nRetrieved Document:\r\nRetrieved Document: <class 'str'>\r\nNumber of tokens: 0\r\n2024-06-29T23:31:57.215569+0000 Couting tokens of retrieved document\r\n2024-06-29T23:31:57.220205+0000 Retrieved document token count 0\r\n2024-06-29T23:31:57.221670+0000 Error querying long term memory: local variable 'out' referenced before assignment\r\n2024-06-29T23:31:57.223879+0000 Attempt 3: Error generating response: local variable 'out' referenced before assignment\r\nQuery: write a linkedin and twitter post about machine learning. can only be 240 chars max.\r\nRetrieved Document:\r\nRetrieved Document: <class 'str'>\r\nNumber of tokens: 0\r\nSaved agent state to: chat-tester_state.json\r\n2024-06-29T23:31:57.224610+0000 Failed to generate a valid response after retry attempts.\r\n2024-06-29T23:31:57.225140+0000 Autosaving agent state.\r\n2024-06-29T23:31:57.227175+0000 Saving Agent chat-tester state to: chat-tester_state.json\r\n```\r\n\r\nNormal client operations work when I invoke the client from `memory,` i.e. I'm able to add, retrieve, etc.\r\n\r\nAlso, the only `out` variable is in the `ChromaMemory` class and it works just fine.\r\n\r\nLastly, it could be that I'm using this completely wrong so just tell me if long-term memory is only for `RAG` operations ... ?",
      "state": "closed",
      "author": "aimzieslol",
      "author_type": "User",
      "created_at": "2024-06-29T23:41:21Z",
      "updated_at": "2025-03-20T16:24:44Z",
      "closed_at": "2024-08-09T14:33:11Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/520/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/520",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/520",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:21.240364",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-06-29T23:41:45Z"
        },
        {
          "author": "aimzieslol",
          "body": "BTW, when I make a \"dumb\" agent and `run()` the same thing, it works just fine:\r\n\r\n```\r\ndumb_agent = Agent(agent_name='dumb-tester',\r\n                   agent_description=('does dumb things'),\r\n                   llm=get_groq_llm(),\r\n                   max_loops=1,\r\n                   verbose=False)",
          "created_at": "2024-06-29T23:45:27Z"
        },
        {
          "author": "kyegomez",
          "body": "@aimzieslol Hey please try agin, we fixed it!",
          "created_at": "2024-08-08T17:16:59Z"
        },
        {
          "author": "aimzieslol",
          "body": "Worked-- thanks!",
          "created_at": "2024-08-09T14:33:11Z"
        }
      ]
    },
    {
      "issue_number": 519,
      "title": "[BUG] swarms 5.2.7 Agent example",
      "body": "Version: 5.2.7\r\nin Colab\r\n\r\nReadme example Agents\r\n```\r\nModuleNotFoundError                       Traceback (most recent call last)\r\n[<ipython-input-2-b43a687f8bdb>](https://localhost:8080/#) in <cell line: 6>()\r\n      4 \r\n      5 # Import the OpenAIChat model and the Agent struct\r\n----> 6 from swarms import Agent, OpenAIChat\r\n      7 \r\n      8 # Load the environment variables\r\n```\r\n...\r\n```\r\n[/usr/local/lib/python3.10/dist-packages/swarms/artifacts/__init__.py](https://localhost:8080/#) in <module>\r\n      1 from swarms.artifacts.base_artifact import BaseArtifact\r\n      2 from swarms.artifacts.text_artifact import TextArtifact\r\n----> 3 from swarms.artifacts.artifact_main import Artifact\r\n      4 \r\n      5 __all__ = [\r\n\r\nModuleNotFoundError: No module named 'swarms.artifacts.artifact_main'\r\n```\r\n\r\nI've verified that swarms/artifacts now has base_artifact and text_artifact, neither of which provides, Artifact.",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2024-06-28T13:41:41Z",
      "updated_at": "2025-03-20T16:24:44Z",
      "closed_at": "2024-06-28T15:56:55Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/519/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/519",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/519",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:21.486769",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@evelynmitchell need to update!\r\n",
          "created_at": "2024-06-28T15:29:36Z"
        },
        {
          "author": "evelynmitchell",
          "body": "Fixed in 5.3.1 \r\n\r\nThank you!",
          "created_at": "2024-06-28T15:56:52Z"
        }
      ]
    },
    {
      "issue_number": 517,
      "title": "[BUG] OpenAI schema generator",
      "body": "Tried to resolve local issue using OpenAI with @tool annotation. Debugged then assumed it was some dependency diff so tried to run the colab link provided in project that contain several examples. Changed devin example to OpenAIChat to find out if I had python version issue that created the error via functools.wrap I use locally.\r\n \r\nGot same issue the colab version. Looks like something where schema generator for OpenAI tries to introspect the decorator instead of the func.__wrapped__ or similar. If your busy I can look further, just let me know if there is a known functools version requirement.\r\n\r\n2024-06-26T19:34:11.548067+0000 Tools provided make sure the functions have documentation ++ type hints, otherwise tool execution won't be reliable.\r\n2024-06-26T19:34:11.548848+0000 Tools granted, initializing tool protocol.\r\n2024-06-26T19:34:11.549122+0000 Number of tools: 4\r\n2024-06-26T19:34:11.549344+0000 Tool -> OpenAI Schema Process Starting Now.\r\n2024-06-26T19:34:11.549766+0000 There was an error converting your tool into a OpenAI certified function calling schema. Add documentation and type hints: All parameters of the function 'decorator' without default values must be annotated. The annotations are missing for the following parameters: 'func'\r\n2024-06-26T19:34:11.549945+0000 Error detected: All parameters of the function 'decorator' without default values must be annotated. The annotations are missing for the following parameters: 'func' make sure you have inputted a callable and that it has documentation as docstrings\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n[<ipython-input-10-ad353937de1b>](https://localhost:8080/#) in <cell line: 81>()\r\n     79 \r\n     80 # Agent\r\n---> 81 agent = Agent(\r\n     82     agent_name=\"Devin\",\r\n     83     system_prompt=(\r\n\r\n4 frames\r\n[/usr/local/lib/python3.10/dist-packages/swarms/tools/py_func_to_openai_func_str.py](https://localhost:8080/#) in get_openai_function_schema_from_func(function, name, description)\r\n    433     if missing != set():\r\n    434         missing_s = [f\"'{k}'\" for k in sorted(missing)]\r\n--> 435         raise TypeError(\r\n    436             f\"All parameters of the function '{function.__name__}' without default values must be annotated. \"\r\n    437             + f\"The annotations are missing for the following parameters: {', '.join(missing_s)}\"\r\n\r\nTypeError: All parameters of the function 'decorator' without default values must be annotated. The annotations are missing for the following parameters: 'func'\r\n\r\n2024-06-26T19:34:11.548067+0000 Tools provided make sure the functions have documentation ++ type hints, otherwise tool execution won't be reliable.\r\n2024-06-26T19:34:11.548848+0000 Tools granted, initializing tool protocol.\r\n2024-06-26T19:34:11.549122+0000 Number of tools: 4\r\n2024-06-26T19:34:11.549344+0000 Tool -> OpenAI Schema Process Starting Now.\r\n2024-06-26T19:34:11.549766+0000 There was an error converting your tool into a OpenAI certified function calling schema. Add documentation and type hints: All parameters of the function 'decorator' without default values must be annotated. The annotations are missing for the following parameters: 'func'\r\n2024-06-26T19:34:11.549945+0000 Error detected: All parameters of the function 'decorator' without default values must be annotated. The annotations are missing for the following parameters: 'func' make sure you have inputted a callable and that it has documentation as docstrings\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n[<ipython-input-10-ad353937de1b>](https://localhost:8080/#) in <cell line: 81>()\r\n     79 \r\n     80 # Agent\r\n---> 81 agent = Agent(\r\n     82     agent_name=\"Devin\",\r\n     83     system_prompt=(\r\n\r\n4 frames\r\n[/usr/local/lib/python3.10/dist-packages/swarms/tools/py_func_to_openai_func_str.py](https://localhost:8080/#) in get_openai_function_schema_from_func(function, name, description)\r\n    433     if missing != set():\r\n    434         missing_s = [f\"'{k}'\" for k in sorted(missing)]\r\n--> 435         raise TypeError(\r\n    436             f\"All parameters of the function '{function.__name__}' without default values must be annotated. \"\r\n    437             + f\"The annotations are missing for the following parameters: {', '.join(missing_s)}\"\r\n\r\nTypeError: All parameters of the function 'decorator' without default values must be annotated. The annotations are missing for the following parameters: 'func'",
      "state": "closed",
      "author": "lapetiteclef",
      "author_type": "User",
      "created_at": "2024-06-26T20:01:31Z",
      "updated_at": "2025-03-20T16:24:44Z",
      "closed_at": "2024-06-27T23:10:39Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/517/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/517",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/517",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:21.663768",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-06-26T20:01:57Z"
        },
        {
          "author": "kyegomez",
          "body": "@lapetiteclef every parameter must have a type and documentation!",
          "created_at": "2024-06-26T22:14:57Z"
        },
        {
          "author": "kyegomez",
          "body": "@lapetiteclef can you send me the code?",
          "created_at": "2024-06-26T22:15:06Z"
        },
        {
          "author": "lapetiteclef",
          "body": "https://colab.research.google.com/github/kyegomez/swarms/blob/master/playground/swarms_example.ipynb\r\n\r\nUsed Devin example above as it contained a @tool. Changed Anthropic in above colab to OpenAIChat no other changes. I get same issue with @tool using OpenAI schema generator in above colab as I get",
          "created_at": "2024-06-26T22:58:07Z"
        },
        {
          "author": "lapetiteclef",
          "body": "figured it out. swarms_example.ipynb example uses @tool decorator without parameters \r\n\r\nIf without any parameters need to be @tool() as this decorator takes parameters. if not using () a parameterized decorator is not called returning the real decorator containing the wrap. Maybe simple for you Pyt",
          "created_at": "2024-06-27T23:10:39Z"
        }
      ]
    },
    {
      "issue_number": 515,
      "title": "[BUG] Multi-Agent Swarm for Logistics",
      "body": "In colab, without an image file uploaded.\r\n```\r\nInitializing Autonomous Agent swarm-worker-01...\r\nAutonomous Agent Activated.\r\nAll systems operational. Executing task...\r\n\r\nLoop 1 of 1\r\n\r\n\r\n\r\n\r\nImage file not found: factory_image1.jpg\r\n2024-06-25T01:10:56.107112+0000 Attempt 1: Error generating response: 'choices'\r\nError with the request: 'choices'\r\nImage file not found: factory_image1.jpg\r\n2024-06-25T01:10:56.554826+0000 Attempt 2: Error generating response: 'choices'\r\nError with the request: 'choices'\r\nImage file not found: factory_image1.jpg\r\n2024-06-25T01:10:56.967989+0000 Attempt 3: Error generating response: 'choices'\r\n2024-06-25T01:10:56.976875+0000 Failed to generate a valid response after retry attempts.\r\nError with the request: 'choices'\r\nInitializing Autonomous Agent swarm-worker-01...\r\nAutonomous Agent Activated.\r\nAll systems operational. Executing task...\r\n\r\nLoop 1 of 1\r\n\r\n\r\n\r\n\r\nImage file not found: factory_image1.jpg\r\n2024-06-25T01:10:57.433397+0000 Attempt 1: Error generating response: 'choices'\r\nError with the request: 'choices'\r\nImage file not found: factory_image1.jpg\r\n2024-06-25T01:10:57.854453+0000 Attempt 2: Error generating response: 'choices'\r\nError with the request: 'choices'\r\nImage file not found: factory_image1.jpg\r\n2024-06-25T01:10:58.353338+0000 Attempt 3: Error generating response: 'choices'\r\n2024-06-25T01:10:58.362766+0000 Failed to generate a valid response after retry attempts.\r\nError with the request: 'choices'\r\nInitializing Autonomous Agent swarm-worker-01...\r\nAutonomous Agent Activated.\r\nAll systems operational. Executing task...\r\n\r\nLoop 1 of 1\r\n\r\n\r\n\r\n\r\nImage file not found: factory_image1.jpg\r\n2024-06-25T01:10:59.192636+0000 Attempt 1: Error generating response: 'choices'\r\nError with the request: 'choices'\r\nImage file not found: factory_image1.jpg\r\n2024-06-25T01:10:59.678470+0000 Attempt 2: Error generating response: 'choices'\r\nError with the request: 'choices'\r\nImage file not found: factory_image1.jpg\r\n2024-06-25T01:11:00.045673+0000 Attempt 3: Error generating response: 'choices'\r\n2024-06-25T01:11:00.053300+0000 Failed to generate a valid response after retry attempts.\r\nError with the request: 'choices'\r\nInitializing Autonomous Agent swarm-worker-01...\r\nAutonomous Agent Activated.\r\nAll systems operational. Executing task...\r\n\r\nLoop 1 of 1\r\n\r\n```",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2024-06-25T01:27:50Z",
      "updated_at": "2025-03-20T16:24:43Z",
      "closed_at": "2025-02-19T00:15:37Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/515/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/515",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/515",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:21.870887",
      "comments": [
        {
          "author": "patrickbdevaney",
          "body": "> In colab, without an image file uploaded.\r\n> \r\n> ```\r\n> Initializing Autonomous Agent swarm-worker-01...\r\n> Autonomous Agent Activated.\r\n> All systems operational. Executing task...\r\n> \r\n> Loop 1 of 1\r\n> \r\n> \r\n> \r\n> \r\n> Image file not found: factory_image1.jpg\r\n> 2024-06-25T01:10:56.107112+0000 At",
          "created_at": "2024-12-26T17:30:30Z"
        }
      ]
    },
    {
      "issue_number": 513,
      "title": "[BUG] SwarmNetwork",
      "body": "```\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n[<ipython-input-14-1f396324b767>](https://localhost:8080/#) in <cell line: 6>()\r\n      4 \r\n      5 # Import the OpenAIChat model and the Agent struct\r\n----> 6 from swarms import Agent, OpenAIChat, SwarmNetwork\r\n      7 \r\n      8 # Load the environment variables\r\n\r\nImportError: cannot import name 'SwarmNetwork' from 'swarms' (/usr/local/lib/python3.10/dist-packages/swarms/__init__.py)\r\n\r\n---------------------------------------------------------------------------\r\nNOTE: If your import is failing due to a missing package, you can\r\nmanually install dependencies using either !pip or !apt.\r\n\r\nTo view examples of installing some common dependencies, click the\r\n\"Open Examples\" button below.\r\n---------------------------------------------------------------------------\r\n```",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2024-06-25T01:08:12Z",
      "updated_at": "2025-03-20T16:24:43Z",
      "closed_at": "2024-11-23T07:49:32Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/513/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/513",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/513",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:22.059260",
      "comments": [
        {
          "author": "sambhavnoobcoder",
          "body": "To solve this bug, we need to update the import statement. The SwarmNetwork class should be imported from `swarms.structs` instead of directly from `swarms` . Here's how to fix the import:\r\n```\r\nfrom swarms import Agent\r\nfrom swarm_models import OpenAIChat\r\nfrom swarms.structs import SwarmNetwork\r\n`",
          "created_at": "2024-10-22T12:46:19Z"
        },
        {
          "author": "kyegomez",
          "body": "@evelynmitchell @sambhavnoobcoder yeah, the swarm network has been dropped out of production because it's not production grade yet. I will close this error for now.",
          "created_at": "2024-10-28T16:52:17Z"
        }
      ]
    },
    {
      "issue_number": 512,
      "title": "[BUG] RecursiveWorkflow",
      "body": "```\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n[<ipython-input-13-495b2a670733>](https://localhost:8080/#) in <cell line: 28>()\r\n     26 \r\n     27 # Run the workflow\r\n---> 28 workflow.run()\r\n\r\n1 frames\r\n[/usr/local/lib/python3.10/dist-packages/swarms/structs/recursive_workflow.py](https://localhost:8080/#) in run(self)\r\n     80         try:\r\n     81             loop = 0\r\n---> 82             while loop < self.max_loops:\r\n     83                 for task in self.task_pool:\r\n     84                     while True:\r\n\r\nAttributeError: 'RecursiveWorkflow' object has no attribute 'max_loops'\r\n\r\n```",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2024-06-25T01:06:39Z",
      "updated_at": "2025-03-20T16:24:43Z",
      "closed_at": "2024-10-28T16:51:27Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/512/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/512",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/512",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:22.242046",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@evelynmitchell this class has been removed from production and is now experimental.\r\n",
          "created_at": "2024-10-28T16:51:23Z"
        }
      ]
    },
    {
      "issue_number": 511,
      "title": "[BUG] ConcurrentWorkflow",
      "body": "```\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n[<ipython-input-12-9e0f9da92ec0>](https://localhost:8080/#) in <cell line: 26>()\r\n     24 \r\n     25 # Run the workflow\r\n---> 26 workflow.run()\r\n\r\n[/usr/local/lib/python3.10/dist-packages/swarms/structs/concurrent_workflow.py](https://localhost:8080/#) in run(self, task, *args, **kwargs)\r\n     91         while loop < self.max_loops:\r\n     92 \r\n---> 93             if self.tasks is not None:\r\n     94                 with concurrent.futures.ThreadPoolExecutor(\r\n     95                     max_workers=self.max_workers\r\n\r\nAttributeError: 'ConcurrentWorkflow' object has no attribute 'tasks'\r\n\r\n```",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2024-06-25T01:05:17Z",
      "updated_at": "2025-03-20T16:24:43Z",
      "closed_at": "2024-10-24T19:32:19Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/511/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/511",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/511",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:22.415706",
      "comments": []
    },
    {
      "issue_number": 510,
      "title": "[BUG] ToolAgent example",
      "body": "This is likely fixable by modifying the swarms __init__.py\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nModuleNotFoundError                       Traceback (most recent call last)\r\n[<ipython-input-9-715acb48d350>](https://localhost:8080/#) in <cell line: 5>()\r\n      3 \r\n      4 from swarms import ToolAgent\r\n----> 5 from swarms.utils.json_utils import base_model_to_json\r\n      6 \r\n      7 # Load the pre-trained model and tokenizer\r\n\r\nModuleNotFoundError: No module named 'swarms.utils.json_utils'\r\n\r\n---------------------------------------------------------------------------\r\nNOTE: If your import is failing due to a missing package, you can\r\nmanually install dependencies using either !pip or !apt.\r\n\r\nTo view examples of installing some common dependencies, click the\r\n\"Open Examples\" button below.\r\n---------------------------------------------------------------------------\r\n```",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2024-06-25T01:03:45Z",
      "updated_at": "2025-03-20T16:24:43Z",
      "closed_at": "2024-12-11T19:34:04Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/510/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/510",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/510",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:22.415725",
      "comments": [
        {
          "author": "Occupying-Mars",
          "body": "the example in the readme is wrong for where you are trying to use it. this [pr](https://github.com/kyegomez/swarms/pull/655) should fix it and the actual import is  `from swarms.tools.json_utils import base_model_to_json`\r\n",
          "created_at": "2024-12-03T06:13:53Z"
        },
        {
          "author": "evelynmitchell",
          "body": "The merged PR 655 fixed this. Closing",
          "created_at": "2024-12-11T19:34:04Z"
        }
      ]
    },
    {
      "issue_number": 509,
      "title": "[BUG] Agentwith Pydantic BaseModel as Output Type",
      "body": "In colab after installing chromadb:\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n[<ipython-input-7-075a5ba6bcf6>](https://localhost:8080/#) in <cell line: 27>()\r\n     25 \r\n     26 # Initialize the agent\r\n---> 27 agent = Agent(\r\n     28     agent_name=\"Person Information Generator\",\r\n     29     system_prompt=(\r\n\r\n[/usr/local/lib/python3.10/dist-packages/swarms/structs/agent.py](https://localhost:8080/#) in __init__(self, id, llm, template, max_loops, stopping_condition, loop_interval, retry_attempts, retry_interval, return_history, stopping_token, dynamic_loops, interactive, dashboard, agent_name, agent_description, system_prompt, tools, dynamic_temperature_enabled, sop, sop_list, saved_state_path, autosave, context_length, user_name, self_healing_enabled, code_interpreter, multi_modal, pdf_path, list_of_pdf, tokenizer, long_term_memory, preset_stopping_token, traceback, traceback_handlers, streaming_on, docs, docs_folder, verbose, parser, best_of_n, callback, metadata, callbacks, logger_handler, search_algorithm, logs_to_filename, evaluator, output_json, stopping_func, custom_loop_condition, sentiment_threshold, custom_exit_command, sentiment_analyzer, limit_tokens_from_string, custom_tools_prompt, tool_schema, output_type, function_calling_type, output_cleaner, function_calling_format_type, list_base_models, metadata_output_type, state_save_file_type, chain_of_thoughts, algorithm_of_thoughts, tree_of_thoughts, tool_choice, execute_tool, rules, planning, planning_prompt, device, custom_planning_prompt, memory_chunk_size, agent_ops_on, *args, **kwargs)\r\n    290         **kwargs,\r\n    291     ):\r\n--> 292         super().__init__(*args, **kwargs)\r\n    293         self.id = id\r\n    294         self.llm = llm\r\n\r\nTypeError: BaseStructure.__init__() got an unexpected keyword argument 'list_tool_schemas'\r\n```",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2024-06-25T00:58:16Z",
      "updated_at": "2025-03-20T16:24:43Z",
      "closed_at": "2025-02-04T19:17:03Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/509/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/509",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/509",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:22.624880",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "This issue is no longer occurring. Closing.",
          "created_at": "2025-02-04T19:17:03Z"
        }
      ]
    },
    {
      "issue_number": 508,
      "title": "[BUG] Agent with Long Term Memory ++ Tools",
      "body": "In colab, after installing chromadb, running the Agent with Long Term Memory ++ Tools example:\r\n\r\n```\r\nChromaDB collection created: results with metric: cosine and output directory: results\r\nTraversing directory: docs\r\n2024-06-25T00:38:18.631828+0000 Tools provided make sure the functions have documentation ++ type hints, otherwise tool execution won't be reliable.\r\n2024-06-25T00:38:18.635862+0000 Tools granted, initializing tool protocol.\r\n2024-06-25T00:38:18.636406+0000 Number of tools: 1\r\n2024-06-25T00:38:18.637085+0000 Tool -> OpenAI Schema Process Starting Now.\r\n2024-06-25T00:38:18.641185+0000 There was an error converting your tool into a OpenAI certified function calling schema. Add documentation and type hints: 1 validation error for Function\r\ndescription\r\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\r\n    For further information visit https://errors.pydantic.dev/2.7/v/string_type\r\n2024-06-25T00:38:18.642498+0000 Error detected: 1 validation error for Function\r\ndescription\r\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\r\n    For further information visit https://errors.pydantic.dev/2.7/v/string_type make sure you have inputted a callable and that it has documentation as docstrings\r\n---------------------------------------------------------------------------\r\nValidationError                           Traceback (most recent call last)\r\n[<ipython-input-7-b98c3025d47c>](https://localhost:8080/#) in <cell line: 195>()\r\n    193 \r\n    194 # Initializing the agent with the Gemini instance and other parameters\r\n--> 195 agent = Agent(\r\n    196     agent_name=\"Covid-19-Chat\",\r\n    197     agent_description=(\r\n\r\n5 frames\r\n[/usr/local/lib/python3.10/dist-packages/swarms/structs/agent.py](https://localhost:8080/#) in __init__(self, id, llm, template, max_loops, stopping_condition, loop_interval, retry_attempts, retry_interval, return_history, stopping_token, dynamic_loops, interactive, dashboard, agent_name, agent_description, system_prompt, tools, dynamic_temperature_enabled, sop, sop_list, saved_state_path, autosave, context_length, user_name, self_healing_enabled, code_interpreter, multi_modal, pdf_path, list_of_pdf, tokenizer, long_term_memory, preset_stopping_token, traceback, traceback_handlers, streaming_on, docs, docs_folder, verbose, parser, best_of_n, callback, metadata, callbacks, logger_handler, search_algorithm, logs_to_filename, evaluator, output_json, stopping_func, custom_loop_condition, sentiment_threshold, custom_exit_command, sentiment_analyzer, limit_tokens_from_string, custom_tools_prompt, tool_schema, output_type, function_calling_type, output_cleaner, function_calling_format_type, list_base_models, metadata_output_type, state_save_file_type, chain_of_thoughts, algorithm_of_thoughts, tree_of_thoughts, tool_choice, execute_tool, rules, planning, planning_prompt, device, custom_planning_prompt, memory_chunk_size, agent_ops_on, *args, **kwargs)\r\n    425 \r\n    426             # Transform the tools into an openai schema\r\n--> 427             self.convert_tool_into_openai_schema()\r\n    428 \r\n    429             # Now create a function calling map for every tools\r\n\r\n[/usr/local/lib/python3.10/dist-packages/swarms/structs/agent.py](https://localhost:8080/#) in convert_tool_into_openai_schema(self)\r\n   1702                 f\"Error detected: {error} make sure you have inputted a callable and that it has documentation as docstrings\"\r\n   1703             )\r\n-> 1704             raise error\r\n   1705 \r\n   1706     def memory_query(self, task: str = None, *args, **kwargs):\r\n\r\n[/usr/local/lib/python3.10/dist-packages/swarms/structs/agent.py](https://localhost:8080/#) in convert_tool_into_openai_schema(self)\r\n   1697                         f\"There was an error converting your tool into a OpenAI certified function calling schema. Add documentation and type hints: {error}\"\r\n   1698                     )\r\n-> 1699                     raise error\r\n   1700         except Exception as error:\r\n   1701             logger.info(\r\n\r\n[/usr/local/lib/python3.10/dist-packages/swarms/structs/agent.py](https://localhost:8080/#) in convert_tool_into_openai_schema(self)\r\n   1675                     )\r\n   1676                     tool_schema_list = (\r\n-> 1677                         get_openai_function_schema_from_func(\r\n   1678                             tool, name=name, description=description\r\n   1679                         )\r\n\r\n[/usr/local/lib/python3.10/dist-packages/swarms/tools/py_func_to_openai_func_str.py](https://localhost:8080/#) in get_openai_function_schema_from_func(function, name, description)\r\n    445 \r\n    446     function = ToolFunction(\r\n--> 447         function=Function(\r\n    448             description=description,\r\n    449             name=fname,\r\n\r\n[/usr/local/lib/python3.10/dist-packages/pydantic/main.py](https://localhost:8080/#) in __init__(self, **data)\r\n    174         # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\r\n    175         __tracebackhide__ = True\r\n--> 176         self.__pydantic_validator__.validate_python(data, self_instance=self)\r\n    177 \r\n    178     # The following line sets a flag that we use to determine when `__init__` gets overridden by the user\r\n\r\nValidationError: 1 validation error for Function\r\ndescription\r\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\r\n    For further information visit https://errors.pydantic.dev/2.7/v/string_typeChromaDB collection created: results with metric: cosine and output directory: results\r\nTraversing directory: docs\r\n2024-06-25T00:38:18.631828+0000 Tools provided make sure the functions have documentation ++ type hints, otherwise tool execution won't be reliable.\r\n2024-06-25T00:38:18.635862+0000 Tools granted, initializing tool protocol.\r\n2024-06-25T00:38:18.636406+0000 Number of tools: 1\r\n2024-06-25T00:38:18.637085+0000 Tool -> OpenAI Schema Process Starting Now.\r\n2024-06-25T00:38:18.641185+0000 There was an error converting your tool into a OpenAI certified function calling schema. Add documentation and type hints: 1 validation error for Function\r\ndescription\r\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\r\n    For further information visit https://errors.pydantic.dev/2.7/v/string_type\r\n2024-06-25T00:38:18.642498+0000 Error detected: 1 validation error for Function\r\ndescription\r\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\r\n    For further information visit https://errors.pydantic.dev/2.7/v/string_type make sure you have inputted a callable and that it has documentation as docstrings\r\n---------------------------------------------------------------------------\r\nValidationError                           Traceback (most recent call last)\r\n[<ipython-input-7-b98c3025d47c>](https://localhost:8080/#) in <cell line: 195>()\r\n    193 \r\n    194 # Initializing the agent with the Gemini instance and other parameters\r\n--> 195 agent = Agent(\r\n    196     agent_name=\"Covid-19-Chat\",\r\n    197     agent_description=(\r\n\r\n5 frames\r\n[/usr/local/lib/python3.10/dist-packages/swarms/structs/agent.py](https://localhost:8080/#) in __init__(self, id, llm, template, max_loops, stopping_condition, loop_interval, retry_attempts, retry_interval, return_history, stopping_token, dynamic_loops, interactive, dashboard, agent_name, agent_description, system_prompt, tools, dynamic_temperature_enabled, sop, sop_list, saved_state_path, autosave, context_length, user_name, self_healing_enabled, code_interpreter, multi_modal, pdf_path, list_of_pdf, tokenizer, long_term_memory, preset_stopping_token, traceback, traceback_handlers, streaming_on, docs, docs_folder, verbose, parser, best_of_n, callback, metadata, callbacks, logger_handler, search_algorithm, logs_to_filename, evaluator, output_json, stopping_func, custom_loop_condition, sentiment_threshold, custom_exit_command, sentiment_analyzer, limit_tokens_from_string, custom_tools_prompt, tool_schema, output_type, function_calling_type, output_cleaner, function_calling_format_type, list_base_models, metadata_output_type, state_save_file_type, chain_of_thoughts, algorithm_of_thoughts, tree_of_thoughts, tool_choice, execute_tool, rules, planning, planning_prompt, device, custom_planning_prompt, memory_chunk_size, agent_ops_on, *args, **kwargs)\r\n    425 \r\n    426             # Transform the tools into an openai schema\r\n--> 427             self.convert_tool_into_openai_schema()\r\n    428 \r\n    429             # Now create a function calling map for every tools\r\n\r\n[/usr/local/lib/python3.10/dist-packages/swarms/structs/agent.py](https://localhost:8080/#) in convert_tool_into_openai_schema(self)\r\n   1702                 f\"Error detected: {error} make sure you have inputted a callable and that it has documentation as docstrings\"\r\n   1703             )\r\n-> 1704             raise error\r\n   1705 \r\n   1706     def memory_query(self, task: str = None, *args, **kwargs):\r\n\r\n[/usr/local/lib/python3.10/dist-packages/swarms/structs/agent.py](https://localhost:8080/#) in convert_tool_into_openai_schema(self)\r\n   1697                         f\"There was an error converting your tool into a OpenAI certified function calling schema. Add documentation and type hints: {error}\"\r\n   1698                     )\r\n-> 1699                     raise error\r\n   1700         except Exception as error:\r\n   1701             logger.info(\r\n\r\n[/usr/local/lib/python3.10/dist-packages/swarms/structs/agent.py](https://localhost:8080/#) in convert_tool_into_openai_schema(self)\r\n   1675                     )\r\n   1676                     tool_schema_list = (\r\n-> 1677                         get_openai_function_schema_from_func(\r\n   1678                             tool, name=name, description=description\r\n   1679                         )\r\n\r\n[/usr/local/lib/python3.10/dist-packages/swarms/tools/py_func_to_openai_func_str.py](https://localhost:8080/#) in get_openai_function_schema_from_func(function, name, description)\r\n    445 \r\n    446     function = ToolFunction(\r\n--> 447         function=Function(\r\n    448             description=description,\r\n    449             name=fname,\r\n\r\n[/usr/local/lib/python3.10/dist-packages/pydantic/main.py](https://localhost:8080/#) in __init__(self, **data)\r\n    174         # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\r\n    175         __tracebackhide__ = True\r\n--> 176         self.__pydantic_validator__.validate_python(data, self_instance=self)\r\n    177 \r\n    178     # The following line sets a flag that we use to determine when `__init__` gets overridden by the user\r\n\r\nValidationError: 1 validation error for Function\r\ndescription\r\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\r\n    For further information visit https://errors.pydantic.dev/2.7/v/string_type```",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2024-06-25T00:43:23Z",
      "updated_at": "2025-03-20T16:24:43Z",
      "closed_at": "2024-12-11T19:34:45Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/508/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/508",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/508",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:22.830831",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "I believe this is failing because there is no docs dir, and it is empty.\r\n\r\n",
          "created_at": "2024-06-25T21:50:36Z"
        },
        {
          "author": "Occupying-Mars",
          "body": "the error seems to come while trying to convert base model to a valid openai fcalling schema\r\neither the code wasn't passing the schema in a valid format or this is an old bug that must be solved now.\r\nthe issue can be closed now @kyegomez ",
          "created_at": "2024-12-03T15:05:11Z"
        },
        {
          "author": "evelynmitchell",
          "body": "Yes, I'll close this.",
          "created_at": "2024-12-11T19:34:45Z"
        }
      ]
    },
    {
      "issue_number": 507,
      "title": "[BUG] images for multimodal examples",
      "body": "When running without the code available, as in a colab notebook installed only with ```pip install swarms``` the image files, which are referred to as \"assembly_line.jpg\" are not available.\r\n\r\nA possible fix would be to use a url instead, to pull the images from a location such as github.",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2024-06-24T23:39:14Z",
      "updated_at": "2025-03-20T16:24:43Z",
      "closed_at": "2025-02-04T19:15:51Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/507/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/507",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/507",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:23.042540",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "This issue has been resolved. Closing.",
          "created_at": "2025-02-04T19:15:51Z"
        }
      ]
    },
    {
      "issue_number": 497,
      "title": "ValueError: Agents must be provided. [BUG] ",
      "body": "**Describe the bug**\r\nBaseSwarm class throws value error when instantiating SwarmNetwork when using provided Swarm Network example.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to [Swarms documentation](https://docs.swarms.world/en/latest/swarms/install/install/)\r\n2. Install swarms like intended\r\n3. Run provided \"Swarm Network\" code eg.\r\n```py\r\nimport os\r\n\r\nfrom dotenv import load_dotenv\r\n\r\n# Import the OpenAIChat model and the Agent struct\r\nfrom swarms import Agent, OpenAIChat, SwarmNetwork\r\n\r\n# Load the environment variables\r\nload_dotenv()\r\n\r\n# Get the API key from the environment\r\napi_key = os.environ.get(\"OPENAI_API_KEY\")\r\n\r\n# Initialize the language model\r\nllm = OpenAIChat(\r\n    temperature=0.5,\r\n    openai_api_key=api_key,\r\n)\r\n\r\n## Initialize the workflow\r\nagent = Agent(llm=llm, max_loops=1, agent_name=\"Social Media Manager\")\r\nagent2 = Agent(llm=llm, max_loops=1, agent_name=\" Product Manager\")\r\nagent3 = Agent(llm=llm, max_loops=1, agent_name=\"SEO Manager\")\r\n\r\n\r\n# Load the swarmnet with the agents\r\nswarmnet = SwarmNetwork(\r\n    agents=[agent, agent2, agent3],\r\n)\r\n\r\n# List the agents in the swarm network\r\nout = swarmnet.list_agents()\r\nprint(out)\r\n\r\n# Run the workflow on a task\r\nout = swarmnet.run_single_agent(\r\n    agent2.id, \"Generate a 10,000 word blog on health and wellness.\"\r\n)\r\nprint(out)\r\n\r\n\r\n# Run all the agents in the swarm network on a task\r\nout = swarmnet.run_many_agents(\"Generate a 10,000 word blog on health and wellness.\")\r\nprint(out)\r\n```\r\n4. Watch error in the console.\r\n\r\n**Screenshots**\r\n![image](https://github.com/kyegomez/swarms/assets/58010186/d4d25dd3-eb5e-461c-a8e7-9773a83d9abd)\r\n\r\n**Additional context**\r\nPython 3.12.2\r\nswarms installed via pip",
      "state": "closed",
      "author": "Veanir",
      "author_type": "User",
      "created_at": "2024-06-15T23:15:15Z",
      "updated_at": "2025-03-20T16:24:42Z",
      "closed_at": "2025-01-13T18:44:52Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/497/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/497",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/497",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:23.220121",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-06-15T23:15:41Z"
        },
        {
          "author": "kyegomez",
          "body": "@Veanir hey excuse, me think i just fixed it, try upgrading and then let me know: `pip3 install -U swarms`",
          "created_at": "2024-06-17T15:09:44Z"
        },
        {
          "author": "evelynmitchell",
          "body": "I set up a colab notebook replicator with the latest swarms.\r\nIt ran, but ran out of memory after only producing\r\n```\r\n32m2024-06-17T23:14:10.620655+0000\u001b[0m \u001b[1mReliability checks activated.\u001b[0m\r\n```\r\nIf interrupted before running out of memory I get;\r\n```\r\nKeyboardInterrupt                        ",
          "created_at": "2024-06-17T23:28:25Z"
        },
        {
          "author": "Veanir",
          "body": "Yea, seems like infinite loop to me\r\n```py\r\n# For each agent in the pool, run it on it's own thread\r\n        if agents is not None:\r\n            for agent in agents:\r\n                self.agents.append(agent)\r\n```\r\n",
          "created_at": "2024-06-17T23:34:41Z"
        },
        {
          "author": "evelynmitchell",
          "body": "Ok, I think I figured this out. This code is recursively adding agents to agents, and so will never stop, and will oom.\r\nswarms/structs/swarm_net.py 144\r\nYou likely don't need this code at all. The agents have already been added with self.agents.\r\n```\r\n       # For each agent in the pool, run it on ",
          "created_at": "2024-06-17T23:57:30Z"
        }
      ]
    },
    {
      "issue_number": 490,
      "title": "[BUG] [Proxy not working with model name, and parameters, need fix proxy",
      "body": "```\r\nswarms_wd@Kyes-MacBook-Pro llama3 % /usr/local/bin/python3 /Users/swarms_wd/Desktop/research/swarms-cloud/examples/intern_example.py\r\nTraceback (most recent call last):\r\n  File \"/Users/swarms_wd/Desktop/research/swarms-cloud/examples/intern_example.py\", line 12, in <module>\r\n    chat_response = client.chat.completions.create(\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 277, in wrapper\r\n    return func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 590, in create\r\n    return self._post(\r\n           ^^^^^^^^^^^\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openai/_base_client.py\", line 1240, in post\r\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\r\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openai/_base_client.py\", line 921, in request\r\n    return self._request(\r\n           ^^^^^^^^^^^^^^\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openai/_base_client.py\", line 1020, in _request\r\n    raise self._make_status_error_from_response(err.response) from None\r\nopenai.NotFoundError: Internal Error - fetching model, {\"detail\":\"Not Found\"}\r\nswarms_wd@Kyes-MacBook-Pro llama3 % \r\n```\r\n\r\n# Code\r\n``` \r\nfrom dotenv import load_dotenv\r\nfrom openai import OpenAI\r\n\r\nload_dotenv()\r\nopenai_api_key = \"sk-\"\r\n\r\nopenai_api_base = \"https://api.swarms.world/v1\"\r\nmodel = \"internlm-xcomposer2-4khd\"\r\n\r\nclient = OpenAI(api_key=openai_api_key, base_url=openai_api_base)\r\n# Note that this model expects the image to come before the main text\r\nchat_response = client.chat.completions.create(\r\n    model=model,\r\n    messages=[\r\n        {\r\n            \"role\": \"user\",\r\n            \"content\": [\r\n                {\r\n                    \"type\": \"image_url\",\r\n                    \"image_url\": {\r\n                        \"url\": \"https://home-cdn.reolink.us/wp-content/uploads/2022/04/010345091648784709.4253.jpg\",\r\n                    },\r\n                },\r\n                {\r\n                    \"type\": \"text\",\r\n                    \"text\": \"What is the most dangerous object in the image?\",\r\n                },\r\n            ],\r\n        }\r\n    ],\r\n    temperature=0.1,\r\n    max_tokens=5000,\r\n)\r\nprint(\"Chat response:\", chat_response)\r\n```",
      "state": "closed",
      "author": "kyegomez",
      "author_type": "User",
      "created_at": "2024-06-07T23:44:12Z",
      "updated_at": "2025-03-20T16:24:42Z",
      "closed_at": "2025-02-13T20:47:43Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/490/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/490",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/490",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:23.450315",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "The UI has changed since this issue was opened. \n\nThe current documentation is at: https://docs.swarms.world/en/latest/swarms/structs/agent/\n\nThis issue can be closed.",
          "created_at": "2025-02-04T19:10:46Z"
        }
      ]
    },
    {
      "issue_number": 489,
      "title": "[BUG] [Swarms Docs Not Building]",
      "body": "Docs are not building now and read the docs does not have good error handling",
      "state": "closed",
      "author": "kyegomez",
      "author_type": "User",
      "created_at": "2024-06-06T17:06:14Z",
      "updated_at": "2025-03-20T16:24:42Z",
      "closed_at": "2025-01-13T18:43:29Z",
      "labels": [
        "bug",
        "help wanted",
        "invalid",
        "[BUG]"
      ],
      "label_count": 4,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/489/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/489",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/489",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:23.631833",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "My PR #483 will fix this, once the mkdocs jupyter bug gets fixed.",
          "created_at": "2024-06-10T15:32:34Z"
        }
      ]
    },
    {
      "issue_number": 485,
      "title": "[BUG] [Error saving agent state: [Errno 8] nodename nor servname provided, or not known]",
      "body": "```\r\n2024-06-02T17:32:40.173689-0700 Saving Agent Supervising Agent state to: Supervising Agent_state.json\r\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\r\n```",
      "state": "closed",
      "author": "kyegomez",
      "author_type": "User",
      "created_at": "2024-06-03T00:35:01Z",
      "updated_at": "2025-03-20T16:24:42Z",
      "closed_at": "2025-01-13T18:45:10Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/485/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/485",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/485",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:23.830092",
      "comments": []
    },
    {
      "issue_number": 479,
      "title": "[BUG] Error with the request: 'choices': Attempt 1: Error generating response: 'choices'",
      "body": "\r\nError with the request: 'choices'\r\n\r\n\r\n```\r\nError with the request: 'choices'\r\n2024-05-27T14:59:04.247857-0400 Attempt 1: Error generating response: 'choices'\r\nError with the request: 'choices'\r\n2024-05-27T14:59:05.957998-0400 Attempt 2: Error generating response: 'choices'\r\nError with the request: 'choices'\r\n2024-05-27T14:59:07.745667-0400 Attempt 3: Error generating response: 'choices'\r\n2024-05-27T14:59:07.746969-0400 Failed to generate a valid response after retry attempts.\r\n2024-05-27T14:59:07.747232-0400 Autosaving agent state.\r\n2024-05-27T14:59:07.747452-0400 Saving Agent Diagnoser Agent state to: Diagnoser Agent_state.json\r\nError saving agent state: [Errno 8] nodename nor servname provided, or not known\r\nAgent 1 - Diagnoser Agent\r\n```",
      "state": "closed",
      "author": "kyegomez",
      "author_type": "User",
      "created_at": "2024-05-27T19:00:18Z",
      "updated_at": "2025-03-20T16:24:42Z",
      "closed_at": "2025-01-13T18:43:52Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/479/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/479",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/479",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:23.830113",
      "comments": []
    },
    {
      "issue_number": 477,
      "title": "[BUG] ImportError: cannot import name 'ChromaDB'",
      "body": "**Describe the bug**\r\n```python\r\nImportError: cannot import name 'ChromaDB' from 'swarms' (/home/ermia/anaconda3/envs/deep-shap/lib/python3.10/site-packages/swarms/__init__.py)\r\n```\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\nHere's the code I'm running:\r\n\r\n```python\r\nfrom swarms import Agent, ChromaDB, OpenAIChat\r\n\r\n# Making an instance of the ChromaDB class\r\nmemory = ChromaDB(\r\n    metric=\"cosine\",\r\n    n_results=3,\r\n    output_dir=\"results\",\r\n    docs_folder=\"docs\",\r\n)\r\n\r\n# Initializing the agent with the Gemini instance and other parameters\r\nagent = Agent(\r\n    agent_name=\"Covid-19-Chat\",\r\n    agent_description=(\r\n        \"This agent provides information about COVID-19 symptoms.\"\r\n    ),\r\n    llm=OpenAIChat(),\r\n    max_loops=\"auto\",\r\n    autosave=True,\r\n    verbose=True,\r\n    long_term_memory=memory,\r\n    stopping_condition=\"finish\",\r\n)\r\n\r\n# Defining the task and image path\r\ntask = (\"What are the symptoms of COVID-19?\",)\r\n\r\n# Running the agent with the specified task and image\r\nout = agent.run(task)\r\nprint(out)\r\n```\r\n\r\n**Expected behavior**\r\nIt should run without any errors as it is an example in the readme.md of the repository.\r\n\r\n**Screenshots**\r\n![image](https://github.com/kyegomez/swarms/assets/80390531/ffd6114c-e39d-4367-a5c6-c504bb716fc5)\r\n\r\n\r\n**Additional context**",
      "state": "closed",
      "author": "behroozazarkhalili",
      "author_type": "User",
      "created_at": "2024-05-27T05:36:45Z",
      "updated_at": "2025-03-20T16:24:41Z",
      "closed_at": "2024-10-28T18:23:18Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/477/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/477",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/477",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:23.830119",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-05-27T05:37:13Z"
        },
        {
          "author": "kyegomez",
          "body": "@behroozazarkhalili this code was taken out of the main swarms package to reduce redundancy, you can import it from here:\r\n\r\nhttps://github.com/kyegomez/swarms/blob/master/playground/memory/chroma_db.py",
          "created_at": "2024-05-27T13:44:09Z"
        },
        {
          "author": "behroozazarkhalili",
          "body": "> @behroozazarkhalili this code was taken out of the main swarms package to reduce redundancy, you can import it from here:\r\n> \r\n> https://github.com/kyegomez/swarms/blob/master/playground/memory/chroma_db.py\r\nIt is not the correct way to remove the bug. I think we should update the readme file to e",
          "created_at": "2024-05-27T16:35:11Z"
        },
        {
          "author": "kyegomez",
          "body": "@behroozazarkhalili the code example has been removed! Let me know if you have any other questions!",
          "created_at": "2024-06-03T00:15:30Z"
        },
        {
          "author": "kyegomez",
          "body": "@behroozazarkhalili try \r\n\r\n```\r\nfrom swarms_memory import ChromaDB\r\n```",
          "created_at": "2024-10-28T16:49:51Z"
        }
      ]
    },
    {
      "issue_number": 476,
      "title": "Not able to agent with tool from example",
      "body": "i tried to run code from your example\r\n\r\n@tool\r\ndef search_api(query: str):\r\n    # Add your logic here\r\n    return query\r\n\r\n# Initializing the agent with the OpenAI instance and other parameters\r\nagent = Agent(\r\n    agent_name=\"Covid-19-Chat\",\r\n    agent_description=(\r\n        \"This agent provides information about COVID-19 symptoms.\"\r\n    ),\r\n    llm=llm,\r\n    max_loops=\"auto\",\r\n    autosave=True,\r\n    verbose=True,\r\n    stopping_condition=\"finish\",\r\n    tools=[search_api],\r\n)\r\n\r\n# Defining the task and image path\r\ntask = (\"What are the symptoms of COVID-19?\",)\r\n\r\n# Running the agent with the specified task and image\r\nout = agent.run(task)\r\nprint(out)\r\n\r\ni got error\r\n\r\n![image](https://github.com/kyegomez/swarms/assets/134259164/e1500c31-3d5e-4ef4-b79e-09c71b9a493f)\r\n\r\nand one more thing is there any blog or something to see working of multi agents with tools.",
      "state": "closed",
      "author": "vaidikcs",
      "author_type": "User",
      "created_at": "2024-05-23T15:32:51Z",
      "updated_at": "2025-03-20T16:24:41Z",
      "closed_at": "2025-01-13T18:45:58Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/476/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/476",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/476",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:24.055398",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-05-23T15:33:29Z"
        },
        {
          "author": "kyegomez",
          "body": "@vaidikcs try another llm like Anthropic or `Llama3Hosted`, this has a parsing error but it did run!",
          "created_at": "2024-05-25T00:24:59Z"
        },
        {
          "author": "aimzieslol",
          "body": "@kyegomez @vaidikcs I'm having this problem as well using Groq with the `OpenAIChat` class. `@tool` definition looks like this:\r\n\r\n```\r\n@tool(name='dumb_string', return_string=True, return_dict=False)\r\ndef dumb_string(dumb_str: str):\r\n    return f'this is dumb: {dumb_str}'\r\n```\r\n\r\nI've tried removin",
          "created_at": "2024-06-29T23:57:56Z"
        },
        {
          "author": "Vits-99",
          "body": "@kyegomez got same error here",
          "created_at": "2024-07-20T23:13:51Z"
        },
        {
          "author": "kyegomez",
          "body": "@Vits-99 @aimzieslol @nictuku no more tool decorator is needed, just the function with types, and doc strings.",
          "created_at": "2024-07-21T07:34:25Z"
        }
      ]
    },
    {
      "issue_number": 473,
      "title": "[BUG] [AgentRearrange] [None Error running agent: argument of type 'NoneType' is not iterable 2024-05-14T09:57:27.103260-0700 An error occurred: argument of type 'NoneType' is not iterable argument of type 'NoneType' is not iterable]",
      "body": "-> swarm_of_gpt4o_agents_for_accounting.py\r\n\r\n``` \r\nNone\r\nError running agent: argument of type 'NoneType' is not iterable\r\n2024-05-14T09:57:27.103260-0700 An error occurred: argument of type 'NoneType' is not iterable\r\nargument of type 'NoneType' is not iterable\r\n```",
      "state": "closed",
      "author": "kyegomez",
      "author_type": "User",
      "created_at": "2024-05-14T17:00:15Z",
      "updated_at": "2025-03-20T16:24:41Z",
      "closed_at": "2025-01-13T18:43:11Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/473/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/473",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/473",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:24.299782",
      "comments": []
    },
    {
      "issue_number": 467,
      "title": "[BUG] [ValueError: There is no existing handler with id 2]",
      "body": "\r\n```\r\nSuccessfully installed swarms-4.9.3\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n[<ipython-input-3-c0269b490a86>](https://localhost:8080/#) in <cell line: 5>()\r\n      3 \r\n      4 # Import the OpenAIChat model and the Agent struct\r\n----> 5 from swarms import Agent\r\n      6 from athena_starship.llama import Llama3\r\n      7 from athena_starship.memory import ChromaDB\r\n\r\n7 frames\r\n[/usr/local/lib/python3.10/dist-packages/loguru/_logger.py](https://localhost:8080/#) in remove(self, handler_id)\r\n   1043 \r\n   1044             if handler_id is not None and handler_id not in handlers:\r\n-> 1045                 raise ValueError(\"There is no existing handler with id %d\" % handler_id) from None\r\n   1046 \r\n   1047             if handler_id is None:\r\n\r\nValueError: There is no existing handler with id 2\r\n```",
      "state": "closed",
      "author": "kyegomez",
      "author_type": "User",
      "created_at": "2024-05-09T00:41:15Z",
      "updated_at": "2025-03-20T16:24:41Z",
      "closed_at": "2025-01-13T18:44:09Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/467/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/467",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/467",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:24.299803",
      "comments": []
    },
    {
      "issue_number": 461,
      "title": "I can't use gemini pro api [BUG] ",
      "body": "I get this error every time: \r\nInitializing Autonomous Agent swarm-worker-01...\r\nAutonomous Agent Activated.\r\nAll systems operational. Executing task...\r\n\r\nLoop 1 of 5\r\n![Screenshot_20240504-001411_Chrome](https://github.com/kyegomez/swarms/assets/80681198/0a6dfded-b494-490f-b1ca-91300dc080b3)\r\n\r\n\r\n\r\n\r\n2024-05-03T21:11:34.096437+0000 Attempt 1: Error generating response: 500 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: TypeError: Failed to fetch\r\nError running Gemini model: 500 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: TypeError: Failed to fetch\r\nPlease check the task and image: System: : \r\n    You are a fully autonomous agent serving the user in automating tasks, workflows, and activities. \r\n    Agent's use custom instructions, capabilities, and data to optimize LLMs for a more narrow set of tasks.\r\n    \r\n    You will have internal dialogues with yourself and or interact with the user to aid in these tasks. \r\n    Your responses should be coherent, contextually relevant, and tailored to the task at hand.\r\n\r\n\r\n\r\nswarm-worker-01: \r\n    **Date and Time**: 2024-05-03 21:11:10\r\n    \r\n    You have been assigned a task that requires the use of various tools to gather information and execute commands. \r\n    Follow the instructions provided to complete the task effectively. This SOP is designed to guide you through the structured and effective use of tools. \r\n    By adhering to this protocol, you will enhance your productivity and accuracy in task execution.\r\n\r\n    ### Constraints\r\n    - Only use the tools as specified in the instructions.\r\n    - Follow the command format strictly to avoid errors and ensure consistency.\r\n    - Only use the tools for the intended purpose as described in the SOP.\r\n    - Document your thoughts, reasoning, and plan before executing the command.\r\n    - Provide the output in JSON format within markdown code blocks.\r\n    - Review the output to ensure it matches the expected outcome.\r\n    - Only follow the instructions provided in the SOP and do not deviate from the specified tasks unless tool usage is not required.\r\n    \r\n    ### Performance Evaluation\r\n    - **Efficiency**: Use tools to complete tasks with minimal steps.\r\n    - **Accuracy**: Ensure that commands are executed correctly to achieve the desired outcome.\r\n    - **Adaptability**: Be ready to adjust the use of tools based on task requirements and feedback.\r\n\r\n    ### Tool Commands\r\n    1. **Browser**\r\n       - **Purpose**: To retrieve information from the internet.\r\n       - **Usage**:\r\n         - `{\"name\": \"browser\", \"parameters\": {\"query\": \"search query here\"}}`\r\n         - Example: Fetch current weather in London.\r\n         - Command: `{\"name\": \"browser\", \"parameters\": {\"query\": \"London weather\"}}`\r\n         \r\n    2. **Terminal**\r\n       - **Purpose**: To execute system commands.\r\n       - **Usage**:\r\n         - `{\"name\": \"terminal\", \"parameters\": {\"cmd\": \"system command here\"}}`\r\n         - Example: Check disk usage on a server.\r\n         - Command: `{\"name\": \"terminal\", \"parameters\": {\"cmd\": \"df -h\"}}`\r\n         \r\n    3. **Custom Tool** (if applicable)\r\n       - **Purpose**: Describe specific functionality.\r\n       - **Usage**:\r\n         - `{\"name\": \"custom_tool\", \"parameters\": {\"parameter\": \"value\"}}`\r\n         - Example: Custom analytics tool.\r\n         - Command: `{\"name\": \"custom_tool\", \"parameters\": {\"data\": \"analyze this data\"}}`\r\n\r\n\r\n    ### Usage Examples\r\n    - **Example 1**: Retrieving Weather Information\r\n      ```json\r\n      \r\n\r\n```json\r\n{\r\n  \"functions\": {\r\n    \"name\": \"browser\", \r\n    \"parameters\": {\r\n      \"query\": \"Miami weather\"\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n\r\n      ```\r\n      \r\n    - **Example 2**: System Check via Terminal\r\n      ```json\r\n      \r\n\r\n```json\r\n{\r\n  \"functions\": {\r\n    \"name\": \"terminal\", \r\n    \"parameters\": {\r\n      \"code\": \"uptime\"\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n\r\n      ```\r\n      \r\n    - **Example 3**: Combined Browser and Terminal Usage\r\n      ```json\r\n      \r\n```\r\n  \"functions\": [\r\n    {\r\n      \"name\": \"browser\",\r\n      \"parameters\": {\r\n        \"query\": \"download latest stock data for NASDAQ\"\r\n      }\r\n    },\r\n    {\r\n      \"name\": \"terminal\",\r\n      \"parameters\": {\r\n        \"cmd\": \"python analyze_stocks.py\"\r\n      }\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\n\r\n      ```\r\n      \r\n    - **Example 4**: Combined Browser, Terminal, and Calculator Usage\r\n        ```json\r\n        \r\n```\r\n{\r\n  \"functions\": [\r\n    {\r\n      \"name\": \"browser\",\r\n      \"parameters\": {\r\n        \"query\": \"download monthly expenditure data\"\r\n      }\r\n    },\r\n    {\r\n      \"name\": \"terminal\",\r\n      \"parameters\": {\r\n        \"cmd\": \"python process_expenditures.py\"\r\n      }\r\n    },\r\n    {\r\n      \"name\": \"calculator\",\r\n      \"parameters\": {\r\n        \"operation\": \"sum\",\r\n        \"numbers\": \"[output_from_process_expenditures]\"\r\n      }\r\n    }\r\n  ]\r\n}\r\n\r\n```\r\n\r\n\r\n        ```\r\n        \r\n    \r\n\r\n    ### Next Steps\r\n    - Determine the appropriate tool for the task at hand.\r\n    - Format your command according to the examples provided.\r\n    - Execute the command and evaluate the results based on the expected outcome.\r\n    - Document any issues or challenges faced during the tool usage.\r\n    - Always output the results in the specified format: JSON in markdown code blocks.\r\n    \r\n    \r\n    ###### Tools Available\r\n    \r\n    []\r\n    \r\n    \r\n\r\n\r\nswarm-worker-01: \r\n    This function systematically breaks down the given objective into distinct, manageable subtasks.\r\n    It structures the problem-solving process through explicit step-by-step exploration, \r\n    using a methodical search tree approach. Key steps are numbered to guide the exploration of solutions.\r\n    \r\n    The function emphasizes the third level of the search tree, where critical decision-making occurs.\r\n    Each potential path is thoroughly evaluated to determine its viability towards achieving the objective.\r\n    The process includes:\r\n    - Identifying initial steps in the search tree.\r\n    - Delineating and exploring critical third-level decisions.\r\n    - Considering alternative paths if initial trials are not promising.\r\n    \r\n    The goal is to think atomically and provide solutions for each subtask identified,\r\n    leading to a conclusive final result. The approach is resilient, working under the premise that\r\n    all objectives are solvable with persistent and methodical exploration.\r\n    \r\n    ### OBJECTIVE\r\n    None\r\n    ###\r\n    \r\n    \r\n\r\n\r\nHuman:: Generate a 10,000 word blog on mental clarity and the benefits of meditation.\r\n\r\n, None\r\n2024-05-03T21:11:36.047595+0000 Attempt 2: Error generating response: 500 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: TypeError: Failed to fetch\r\nError running Gemini model: 500 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: TypeError: Failed to fetch\r\nPlease check the task and image: System: : \r\n    You are a fully autonomous agent serving the user in automating tasks, workflows, and activities. \r\n    Agent's use custom instructions, capabilities, and data to optimize LLMs for a more narrow set of tasks.\r\n    \r\n    You will have internal dialogues with yourself and or interact with the user to aid in these tasks. \r\n    Your responses should be coherent, contextually relevant, and tailored to the task at hand.\r\n\r\n\r\n\r\nswarm-worker-01: \r\n    **Date and Time**: 2024-05-03 21:11:10\r\n    \r\n    You have been assigned a task that requires the use of various tools to gather information and execute commands. \r\n    Follow the instructions provided to complete the task effectively. This SOP is designed to guide you through the structured and effective use of tools. \r\n    By adhering to this protocol, you will enhance your productivity and accuracy in task execution.\r\n\r\n    ### Constraints\r\n    - Only use the tools as specified in the instructions.\r\n    - Follow the command format strictly to avoid errors and ensure consistency.\r\n    - Only use the tools for the intended purpose as described in the SOP.\r\n    - Document your thoughts, reasoning, and plan before executing the command.\r\n    - Provide the output in JSON format within markdown code blocks.\r\n    - Review the output to ensure it matches the expected outcome.\r\n    - Only follow the instructions provided in the SOP and do not deviate from the specified tasks unless tool usage is not required.\r\n    \r\n    ### Performance Evaluation\r\n    - **Efficiency**: Use tools to complete tasks with minimal steps.\r\n    - **Accuracy**: Ensure that commands are executed correctly to achieve the desired outcome.\r\n    - **Adaptability**: Be ready to adjust the use of tools based on task requirements and feedback.\r\n\r\n    ### Tool Commands\r\n    1. **Browser**\r\n       - **Purpose**: To retrieve information from the internet.\r\n       - **Usage**:\r\n         - `{\"name\": \"browser\", \"parameters\": {\"query\": \"search query here\"}}`\r\n         - Example: Fetch current weather in London.\r\n         - Command: `{\"name\": \"browser\", \"parameters\": {\"query\": \"London weather\"}}`\r\n         \r\n    2. **Terminal**\r\n       - **Purpose**: To execute system commands.\r\n       - **Usage**:\r\n         - `{\"name\": \"terminal\", \"parameters\": {\"cmd\": \"system command here\"}}`\r\n         - Example: Check disk usage on a server.\r\n         - Command: `{\"name\": \"terminal\", \"parameters\": {\"cmd\": \"df -h\"}}`\r\n         \r\n    3. **Custom Tool** (if applicable)\r\n       - **Purpose**: Describe specific functionality.\r\n       - **Usage**:\r\n         - `{\"name\": \"custom_tool\", \"parameters\": {\"parameter\": \"value\"}}`\r\n         - Example: Custom analytics tool.\r\n         - Command: `{\"name\": \"custom_tool\", \"parameters\": {\"data\": \"analyze this data\"}}`\r\n\r\n\r\n    ### Usage Examples\r\n    - **Example 1**: Retrieving Weather Information\r\n      ```json\r\n      \r\n\r\n```json\r\n{\r\n  \"functions\": {\r\n    \"name\": \"browser\", \r\n    \"parameters\": {\r\n      \"query\": \"Miami weather\"\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n\r\n      ```\r\n      \r\n    - **Example 2**: System Check via Terminal\r\n      ```json\r\n      \r\n\r\n```json\r\n{\r\n  \"functions\": {\r\n    \"name\": \"terminal\", \r\n    \"parameters\": {\r\n      \"code\": \"uptime\"\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n\r\n      ```\r\n      \r\n    - **Example 3**: Combined Browser and Terminal Usage\r\n      ```json\r\n      \r\n```\r\n  \"functions\": [\r\n    {\r\n      \"name\": \"browser\",\r\n      \"parameters\": {\r\n        \"query\": \"download latest stock data for NASDAQ\"\r\n      }\r\n    },\r\n    {\r\n      \"name\": \"terminal\",\r\n      \"parameters\": {\r\n        \"cmd\": \"python analyze_stocks.py\"\r\n      }\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\n\r\n      ```\r\n      \r\n    - **Example 4**: Combined Browser, Terminal, and Calculator Usage\r\n        ```json\r\n        \r\n```\r\n{\r\n  \"functions\": [\r\n    {\r\n      \"name\": \"browser\",\r\n      \"parameters\": {\r\n        \"query\": \"download monthly expenditure data\"\r\n      }\r\n    },\r\n    {\r\n      \"name\": \"terminal\",\r\n      \"parameters\": {\r\n        \"cmd\": \"python process_expenditures.py\"\r\n      }\r\n    },\r\n    {\r\n      \"name\": \"calculator\",\r\n      \"parameters\": {\r\n        \"operation\": \"sum\",\r\n        \"numbers\": \"[output_from_process_expenditures]\"\r\n      }\r\n    }\r\n  ]\r\n}\r\n\r\n```\r\n\r\n\r\n        ```\r\n        \r\n    \r\n\r\n    ### Next Steps\r\n    - Determine the appropriate tool for the task at hand.\r\n    - Format your command according to the examples provided.\r\n    - Execute the command and evaluate the results based on the expected outcome.\r\n    - Document any issues or challenges faced during the tool usage.\r\n    - Always output the results in the specified format: JSON in markdown code blocks.\r\n    \r\n    \r\n    ###### Tools Available\r\n    \r\n    []\r\n    \r\n    \r\n\r\n\r\nswarm-worker-01: \r\n    This function systematically breaks down the given objective into distinct, manageable subtasks.\r\n    It structures the problem-solving process through explicit step-by-step exploration, \r\n    using a methodical search tree approach. Key steps are numbered to guide the exploration of solutions.\r\n    \r\n    The function emphasizes the third level of the search tree, where critical decision-making occurs.\r\n    Each potential path is thoroughly evaluated to determine its viability towards achieving the objective.\r\n    The process includes:\r\n    - Identifying initial steps in the search tree.\r\n    - Delineating and exploring critical third-level decisions.\r\n    - Considering alternative paths if initial trials are not promising.\r\n    \r\n    The goal is to think atomically and provide solutions for each subtask identified,\r\n    leading to a conclusive final result. The approach is resilient, working under the premise that\r\n    all objectives are solvable with persistent and methodical exploration.\r\n    \r\n    ### OBJECTIVE\r\n    None\r\n    ###\r\n    \r\n    \r\n\r\n\r\nHuman:: Generate a 10,000 word blog on mental clarity and the benefits of meditation.\r\n\r\n, None\r\n2024-05-03T21:11:38.754088+0000 Attempt 3: Error generating response: 500 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: TypeError: Failed to fetch\r\nError running Gemini model: 500 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: TypeError: Failed to fetch\r\nPlease check the task and image: System: : \r\n    You are a fully autonomous agent serving the user in automating tasks, workflows, and activities. \r\n    Agent's use custom instructions, capabilities, and data to optimize LLMs for a more narrow set of tasks.\r\n    \r\n    You will have internal dialogues with yourself and or interact with the user to aid in these tasks. \r\n    Your responses should be coherent, contextually relevant, and tailored to the task at hand.\r\n\r\n\r\n\r\nswarm-worker-01: \r\n    **Date and Time**: 2024-05-03 21:11:10\r\n    \r\n    You have been assigned a task that requires the use of various tools to gather information and execute commands. \r\n    Follow the instructions provided to complete the task effectively. This SOP is designed to guide you through the structured and effective use of tools. \r\n    By adhering to this protocol, you will enhance your productivity and accuracy in task execution.\r\n\r\n    ### Constraints\r\n    - Only use the tools as specified in the instructions.\r\n    - Follow the command format strictly to avoid errors and ensure consistency.\r\n    - Only use the tools for the intended purpose as described in the SOP.\r\n    - Document your thoughts, reasoning, and plan before executing the command.\r\n    - Provide the output in JSON format within markdown code blocks.\r\n    - Review the output to ensure it matches the expected outcome.\r\n    - Only follow the instructions provided in the SOP and do not deviate from the specified tasks unless tool usage is not required.\r\n    \r\n    ### Performance Evaluation\r\n    - **Efficiency**: Use tools to complete tasks with minimal steps.\r\n    - **Accuracy**: Ensure that commands are executed correctly to achieve the desired outcome.\r\n    - **Adaptability**: Be ready to adjust the use of tools based on task requirements and feedback.\r\n\r\n    ### Tool Commands\r\n    1. **Browser**\r\n       - **Purpose**: To retrieve information from the internet.\r\n       - **Usage**:\r\n         - `{\"name\": \"browser\", \"parameters\": {\"query\": \"search query here\"}}`\r\n         - Example: Fetch current weather in London.\r\n         - Command: `{\"name\": \"browser\", \"parameters\": {\"query\": \"London weather\"}}`\r\n         \r\n    2. **Terminal**\r\n       - **Purpose**: To execute system commands.\r\n       - **Usage**:\r\n         - `{\"name\": \"terminal\", \"parameters\": {\"cmd\": \"system command here\"}}`\r\n         - Example: Check disk usage on a server.\r\n         - Command: `{\"name\": \"terminal\", \"parameters\": {\"cmd\": \"df -h\"}}`\r\n         \r\n    3. **Custom Tool** (if applicable)\r\n       - **Purpose**: Describe specific functionality.\r\n       - **Usage**:\r\n         - `{\"name\": \"custom_tool\", \"parameters\": {\"parameter\": \"value\"}}`\r\n         - Example: Custom analytics tool.\r\n         - Command: `{\"name\": \"custom_tool\", \"parameters\": {\"data\": \"analyze this data\"}}`\r\n\r\n\r\n    ### Usage Examples\r\n    - **Example 1**: Retrieving Weather Information\r\n      ```json\r\n      \r\n\r\n```json\r\n{\r\n  \"functions\": {\r\n    \"name\": \"browser\", \r\n    \"parameters\": {\r\n      \"query\": \"Miami weather\"\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n\r\n      ```\r\n      \r\n    - **Example 2**: System Check via Terminal\r\n      ```json\r\n      \r\n\r\n```json\r\n{\r\n  \"functions\": {\r\n    \"name\": \"terminal\", \r\n    \"parameters\": {\r\n      \"code\": \"uptime\"\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n\r\n      ```\r\n      \r\n    - **Example 3**: Combined Browser and Terminal Usage\r\n      ```json\r\n      \r\n```\r\n  \"functions\": [\r\n    {\r\n      \"name\": \"browser\",\r\n      \"parameters\": {\r\n        \"query\": \"download latest stock data for NASDAQ\"\r\n      }\r\n    },\r\n    {\r\n      \"name\": \"terminal\",\r\n      \"parameters\": {\r\n        \"cmd\": \"python analyze_stocks.py\"\r\n      }\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\n\r\n      ```\r\n      \r\n    - **Example 4**: Combined Browser, Terminal, and Calculator Usage\r\n        ```json\r\n        \r\n```\r\n{\r\n  \"functions\": [\r\n    {\r\n      \"name\": \"browser\",\r\n      \"parameters\": {\r\n        \"query\": \"download monthly expenditure data\"\r\n      }\r\n    },\r\n    {\r\n      \"name\": \"terminal\",\r\n      \"parameters\": {\r\n        \"cmd\": \"python process_expenditures.py\"\r\n      }\r\n    },\r\n    {\r\n      \"name\": \"calculator\",\r\n      \"parameters\": {\r\n        \"operation\": \"sum\",\r\n        \"numbers\": \"[output_from_process_expenditures]\"\r\n      }\r\n    }\r\n  ]\r\n}\r\n\r\n```\r\n\r\n\r\n        ```\r\n        \r\n    \r\n\r\n    ### Next Steps\r\n    - Determine the appropriate tool for the task at hand.\r\n    - Format your command according to the examples provided.\r\n    - Execute the command and evaluate the results based on the expected outcome.\r\n    - Document any issues or challenges faced during the tool usage.\r\n    - Always output the results in the specified format: JSON in markdown code blocks.\r\n    \r\n    \r\n    ###### Tools Available\r\n    \r\n    []\r\n    \r\n    \r\n\r\n\r\nswarm-worker-01: \r\n    This function systematically breaks down the given objective into distinct, manageable subtasks.\r\n    It structures the problem-solving process through explicit step-by-step exploration, \r\n    using a methodical search tree approach. Key steps are numbered to guide the exploration of solutions.\r\n    \r\n    The function emphasizes the third level of the search tree, where critical decision-making occurs.\r\n    Each potential path is thoroughly evaluated to determine its viability towards achieving the objective.\r\n    The process includes:\r\n    - Identifying initial steps in the search tree.\r\n    - Delineating and exploring critical third-level decisions.\r\n    - Considering alternative paths if initial trials are not promising.\r\n    \r\n    The goal is to think atomically and provide solutions for each subtask identified,\r\n    leading to a conclusive final result. The approach is resilient, working under the premise that\r\n    all objectives are solvable with persistent and methodical exploration.\r\n    \r\n    ### OBJECTIVE\r\n    None\r\n    ###\r\n    \r\n    \r\n\r\n\r\nHuman:: Generate a 10,000 word blog on mental clarity and the benefits of meditation.\r\n\r\n, None\r\nNone\r\n2024-05-03T21:11:38.756997+0000 Failed to generate a valid response after retry attempts.\r\n\r\n\r\nThe script:\r\n\r\n\r\nfrom swarms.models.gemini import Gemini\r\nfrom swarms.structs import Agent\r\n\r\n# Your actual API key\r\napi_key = \"APIiiiiiiiiiiiiiiii\"\r\n\r\n# Initialize the Gemini model with your API key\r\nllm = Gemini(\r\n    gemini_api_key=api_key,\r\n    temperature=0.5,\r\n    # Uncomment and set the following if needed\r\n    model_name=\"gemini-pro\",\r\n    # max_tokens=100,\r\n)\r\n\r\n# Initialize the workflow agent with the Gemini model\r\nagent = Agent(\r\n    llm=llm,\r\n    max_loops=5,\r\n    dashboard=True,\r\n    # Uncomment and configure the following if needed\r\n    # tools = [search_api, slack, ],\r\n    # stopping_condition=None,\r\n    # loop_interval=1,\r\n    # retry_attempts=3,\r\n    # retry_interval=1,\r\n    # interactive=False,\r\n    # dynamic_temperature=False,\r\n)\r\n\r\n# Define the task for the agent\r\ntask = \"Generate a 10,000 word blog on mental clarity and the benefits of meditation.\"\r\n\r\n# Run the workflow on the task\r\nout = agent.run(task)\r\n\r\n# Print the output\r\nprint(out)\r\n\r\n\r\nWe used google colab to run",
      "state": "closed",
      "author": "Shakibelmolik",
      "author_type": "User",
      "created_at": "2024-05-03T21:22:25Z",
      "updated_at": "2025-03-20T16:24:41Z",
      "closed_at": "2025-01-13T18:42:58Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/461/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/461",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/461",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:24.299811",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-05-03T21:22:51Z"
        },
        {
          "author": "kyegomez",
          "body": "@Shakibelmolik should be fixed now with our new docs! just put the name of the model in the `model_name=\"gemini\"` parameter with the specific model name\r\n\r\n",
          "created_at": "2025-01-13T18:42:52Z"
        }
      ]
    },
    {
      "issue_number": 452,
      "title": "[BUG] Unable to run `SequentialWorkflow`",
      "body": "**Describe the bug**\r\nI'm trying to run a modified version (explained the change in **To Reproduce** section) of \"Example 1: Adding Tasks to a Sequential Workflow\" from the docs [here](https://swarms.apac.ai/en/latest/swarms/structs/sequential_workflow/) and run into the following error:\r\n<img width=\"826\" alt=\"Screenshot 2024-04-25 at 3 38 35 PM\" src=\"https://github.com/kyegomez/swarms/assets/51450254/6fe9465f-f21d-4da3-babf-769b29632e20\">\r\n\r\n\r\nMoreover, the 2 agents don't seem to be solving the task given to them. \r\n<img width=\"1129\" alt=\"Screenshot 2024-04-25 at 3 39 54 PM\" src=\"https://github.com/kyegomez/swarms/assets/51450254/5f47c6da-9f35-4a39-87e9-baaecbf6b260\">\r\n\r\n**To Reproduce**\r\nThe code given in the blog post raises an error in the section `#Create the Sequential Workflow` as it expects the agents to be specified. Hence I passed them as parameters using `agents=[flow1,flow2]`. Code snippet to reproduce the behavior:\r\n\r\n```\r\nfrom swarms.models import OpenAIChat\r\nfrom swarms.structs import Agent\r\nfrom swarms.structs.sequential_workflow import SequentialWorkflow\r\n\r\n# Initialize the language model agent (e.g., GPT-3)\r\nllm = OpenAIChat(\r\n    openai_api_key=\"\", # Enter OpenAI API key here\r\n    temperature=0.5,\r\n    max_tokens=3000,\r\n)\r\n\r\n# Initialize flows for individual tasks\r\nflow1 = Agent(llm=llm, max_loops=1, dashboard=False)\r\nflow2 = Agent(llm=llm, max_loops=1, dashboard=False)\r\n\r\n# Create the Sequential Workflow\r\nworkflow = SequentialWorkflow(max_loops=1, agents=[flow1,flow2])\r\n\r\n# Add tasks to the workflow\r\nworkflow.add(\"Generate a 10,000 word blog on health and wellness.\", flow1)\r\nworkflow.add(\"Summarize the generated blog\", flow2)\r\n\r\n# Run the workflow\r\nworkflow.run()\r\n\r\n# Output the results\r\nfor task in workflow.tasks:\r\n    print(f\"Task: {task.description}, Result: {task.result}\")\r\n```\r\n\r\n**Expected behavior**\r\nAt this stage, the agents are initialized and the `run()` function must iterate through each agent, calling each agent to execute tasks.\r\n\r\n**Additional context**\r\nThe part of the code responsible for failure is: https://github.com/kyegomez/swarms/blob/fe5a3180c19c0d5f2e3d729f0987be0df6b1651c/swarms/structs/sequential_workflow.py#L150 `\r\n\r\n`workflow_bootup()` is defined in https://github.com/kyegomez/swarms/blob/fe5a3180c19c0d5f2e3d729f0987be0df6b1651c/swarms/structs/base_workflow.py#L371\r\n\r\nSo in my understanding, `swarms/structs/sequential_workflow.py` is not properly importing from `swarms/structs/base_workflow.py`.\r\n\r\nRequest some assistance on this.",
      "state": "closed",
      "author": "adtygan",
      "author_type": "User",
      "created_at": "2024-04-25T07:59:53Z",
      "updated_at": "2025-03-20T16:24:41Z",
      "closed_at": "2024-06-03T03:19:37Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/452/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/452",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/452",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:24.513394",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-04-25T08:00:20Z"
        },
        {
          "author": "kyegomez",
          "body": "@adtygan Fixing it right now, it'll be finished soon. excuse me",
          "created_at": "2024-04-28T21:21:31Z"
        },
        {
          "author": "kyegomez",
          "body": "@adtygan fixed this using `AgentRearrange` located here: https://swarms.apac.ai/en/latest/swarms/structs/agent_rearrange/",
          "created_at": "2024-06-03T00:16:21Z"
        }
      ]
    },
    {
      "issue_number": 417,
      "title": "[BUG][Help] Help to run the project",
      "body": "**Describe the bug**\r\nI'm reaching out to seek assistance regarding an issue I encountered while attempting to run a Python script.\r\n\r\nI just cloned the project and ran the installation scripts.\r\n\r\nI executed the script \"example.py\" using the command \"$ python example.py,\" but it seems to have failed. Unfortunately, I don't have much experience with Python, and I'm unsure how to proceed in troubleshooting this issue.\r\n\r\nCould you please provide guidance on how to identify and resolve the problem? I'll provide the complete error message at the end of this request for your reference.\r\n\r\nThank you for assistance.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. `pip3 install -U swarms`\r\n2. `pip install -r requirements.txt`\r\n3. Add `OPENAI_API_KEY`\r\n4. `python example.py`\r\n\r\n**Expected behavior**\r\n\r\n**Screenshots**\r\n![image](https://github.com/kyegomez/swarms/assets/2083823/9de34c9e-df20-4fa3-9807-db28f9c41484)\r\n\r\n**Additional context**",
      "state": "closed",
      "author": "luansemensato",
      "author_type": "User",
      "created_at": "2024-03-12T18:11:00Z",
      "updated_at": "2025-03-20T16:24:41Z",
      "closed_at": "2024-10-28T18:22:19Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 15,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/417/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/417",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/417",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:24.754803",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-03-12T18:11:31Z"
        },
        {
          "author": "kyegomez",
          "body": "@luansemensato what's your openai verison?",
          "created_at": "2024-03-12T18:39:10Z"
        },
        {
          "author": "luansemensato",
          "body": "@kyegomez The same version as the \"requirements.txt\" file: `0.28.0`\r\n\r\n![Screenshot 2024-03-12 at 15 53 57](https://github.com/kyegomez/swarms/assets/2083823/e51f79b9-bf0c-4cfd-96d0-8aa8244a0234)\r\n",
          "created_at": "2024-03-12T18:54:03Z"
        },
        {
          "author": "kyegomez",
          "body": "@luansemensato upgrade your python, your python doesn't have the `|`command!",
          "created_at": "2024-03-13T05:45:08Z"
        },
        {
          "author": "luansemensato",
          "body": "@kyegomez Which version is indicated? Could you elaborate on that?",
          "created_at": "2024-03-13T11:09:52Z"
        }
      ]
    },
    {
      "issue_number": 457,
      "title": "[BUG] can't install swarms with poetry",
      "body": "\r\n```\r\n(swarms-py3.11) yvesjunqueira@yvess-mbp:~/src/github.com/artell-ai$ poetry new swarms-test\r\nCreated package swarms_test in swarms-test\r\n(swarms-py3.11) yvesjunqueira@yvess-mbp:~/src/github.com/artell-ai$ cd swarms-test/\r\n(swarms-py3.11) yvesjunqueira@yvess-mbp:~/src/github.com/artell-ai/swarms-test$ ls\r\nREADME.md\tpyproject.toml\tswarms_test\ttests\r\n(swarms-py3.11) yvesjunqueira@yvess-mbp:~/src/github.com/artell-ai/swarms-test$ cd swarms_test/\r\n(swarms-py3.11) yvesjunqueira@yvess-mbp:~/src/github.com/artell-ai/swarms-test/swarms_test$ ls\r\n__init__.py\r\n(swarms-py3.11) yvesjunqueira@yvess-mbp:~/src/github.com/artell-ai/swarms-test/swarms_test$ poetry add swarms\r\nUsing version ^4.8.7 for swarms\r\n\r\nUpdating dependencies\r\nResolving dependencies... (2.0s)\r\n\r\nBecause no versions of swarms match >4.8.7,<5.0.0\r\n and swarms (4.8.7) depends on yaml (*), swarms (>=4.8.7,<5.0.0) requires yaml (*).\r\nSo, because no versions of yaml match *\r\n and swarms-test depends on swarms (^4.8.7), version solving failed.\r\n```\r\n\r\nIt looks like this was fixed in recent releases but the most recent release is from December 2023?",
      "state": "closed",
      "author": "nictuku",
      "author_type": "User",
      "created_at": "2024-04-30T19:15:07Z",
      "updated_at": "2025-03-20T16:24:40Z",
      "closed_at": "2024-04-30T20:37:17Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/457/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/457",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/457",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:24.996957",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-04-30T19:15:32Z"
        },
        {
          "author": "nictuku",
          "body": "@kyegomez fixed this in 4.8.8 ",
          "created_at": "2024-04-30T20:37:17Z"
        }
      ]
    },
    {
      "issue_number": 407,
      "title": "[BUG] Useless logs, we need to eliminate",
      "body": "```\r\nINFO:numexpr.utils:NumExpr defaulting to 8 threads.\r\nswarms is up to date!\r\nImporting LLMChain from langchain root module is no longer supported. Please use langchain.chains.LLMChain instead.\r\nImporting PromptTemplate from langchain root module is no longer supported. Please use langchain.prompts.PromptTemplate instead.\r\ndistutils Version classes are deprecated. Use packaging.version instead.\r\ndistutils Version classes are deprecated. Use packaging.version instead.\r\n```",
      "state": "closed",
      "author": "kyegomez",
      "author_type": "User",
      "created_at": "2024-03-01T06:45:09Z",
      "updated_at": "2025-03-20T16:24:40Z",
      "closed_at": "2024-10-28T16:50:42Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/407/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/407",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/407",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:25.190818",
      "comments": []
    },
    {
      "issue_number": 403,
      "title": "[BUG] [   Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)] ",
      "body": "```\r\nswarms is up to date!\r\nImporting LLMChain from langchain root module is no longer supported. Please use langchain.chains.LLMChain instead.\r\nImporting PromptTemplate from langchain root module is no longer supported. Please use langchain.prompts.PromptTemplate instead.\r\ndistutils Version classes are deprecated. Use packaging.version instead.\r\ndistutils Version classes are deprecated. Use packaging.version instead.\r\nTraceback (most recent call last):\r\n    llm = OpenAIChat(\r\n          ^^^^^^^^^^^\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain/load/serializable.py\", line 97, in __init__\r\n    super().__init__(**kwargs)\r\n  File \"pydantic/main.py\", line 341, in pydantic.main.BaseModel.__init__\r\npydantic.error_wrappers.ValidationError: 1 validation error for OpenAIChat\r\n__root__\r\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)\r\nImplicitly cleaning up <TemporaryDirectory '/var/folders/lz/8cyyy_pj1xqf05jck98kpkrc0000gn/T/tmp31ymezl9'>\r\n```",
      "state": "closed",
      "author": "starshipvc",
      "author_type": "User",
      "created_at": "2024-03-01T01:41:21Z",
      "updated_at": "2025-03-20T16:24:40Z",
      "closed_at": "2024-03-06T01:33:35Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/403/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/403",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/403",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:25.190835",
      "comments": [
        {
          "author": "vyomakesh09",
          "body": "please do this \r\n\r\n$export OPENAI_API_KEY='your_api_key'",
          "created_at": "2024-03-03T19:00:10Z"
        }
      ]
    },
    {
      "issue_number": 402,
      "title": "[BUG] TypeError: SegmentAPI.get_or_create_collection() got an unexpected keyword argument 'data_loader' Implicitly cleaning up <TemporaryDirectory '/var/folders/lz/8cyyy_pj1xqf05jck98kpkrc0000gn/T/tmpc96i__sk'>",
      "body": "```\r\nswarms is up to date!\r\nImporting LLMChain from langchain root module is no longer supported. Please use langchain.chains.LLMChain instead.\r\nImporting PromptTemplate from langchain root module is no longer supported. Please use langchain.prompts.PromptTemplate instead.\r\ndistutils Version classes are deprecated. Use packaging.version instead.\r\ndistutils Version classes are deprecated. Use packaging.version instead.\r\nTraceback (most recent call last):\r\n    chromadb = ChromaDB(\r\n               ^^^^^^^^^\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/swarms/memory/chroma_db.py\", line 98, in __init__\r\n    self.collection = chroma_client.get_or_create_collection(\r\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nTypeError: SegmentAPI.get_or_create_collection() got an unexpected keyword argument 'data_loader'\r\nImplicitly cleaning up <TemporaryDirectory '/var/folders/lz/8cyyy_pj1xqf05jck98kpkrc0000gn/T/tmpc96i__sk'>\r\n```",
      "state": "closed",
      "author": "starshipvc",
      "author_type": "User",
      "created_at": "2024-03-01T01:25:56Z",
      "updated_at": "2025-03-20T16:24:40Z",
      "closed_at": "2024-04-02T02:28:07Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/402/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/402",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/402",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:25.421579",
      "comments": []
    },
    {
      "issue_number": 401,
      "title": "[BUG] UnboundLocalError: cannot access local variable 'added_to_db' where it is not associated with a value Implicitly cleaning up <TemporaryDirectory '/var/folders/lz/8cyyy_pj1xqf05jck98kpkrc0000gn/T/tmpzdbwcgp_'>",
      "body": "``` \r\nathena@Athenas-MacBook-Pro athena % python3.11 sam_altman.py\r\nswarms is up to date!\r\nImporting LLMChain from langchain root module is no longer supported. Please use langchain.chains.LLMChain instead.\r\nImporting PromptTemplate from langchain root module is no longer supported. Please use langchain.prompts.PromptTemplate instead.\r\ndistutils Version classes are deprecated. Use packaging.version instead.\r\ndistutils Version classes are deprecated. Use packaging.version instead.\r\nChromaDB collection created: swarms with metric: cosine and output directory: swarms                                                              \r\nTraversing directory: artifacts/sam_altman                                                                                                        \r\nTraceback (most recent call last):\r\n    chromadb = ChromaDB(\r\n               ^^^^^^^^^\r\nline 117, in __init__\r\n    self.traverse_directory()\r\nline 207, in traverse_directory\r\n    return added_to_db\r\n           ^^^^^^^^^^^\r\nUnboundLocalError: cannot access local variable 'added_to_db' where it is not associated with a value\r\nImplicitly cleaning up <TemporaryDirectory '/var/folders/lz/8cyyy_pj1xqf05jck98kpkrc0000gn/T/tmpzdbwcgp_'>\r\n```",
      "state": "closed",
      "author": "starshipvc",
      "author_type": "User",
      "created_at": "2024-03-01T01:19:14Z",
      "updated_at": "2025-03-20T16:24:40Z",
      "closed_at": "2024-10-28T18:22:52Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/401/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/401",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/401",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:25.421599",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@starshipvc fixed with swarms_memory",
          "created_at": "2024-10-28T18:22:52Z"
        }
      ]
    },
    {
      "issue_number": 400,
      "title": "[BUG] TypeError: unsupported operand type(s) for |: 'type' and 'types.GenericAlias'",
      "body": "```\r\n/Users/athena/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\r\n  warnings.warn(\r\nswarms is up to date!\r\nTraceback (most recent call last):\r\n    from swarms import Agent\r\n  File \"/Users/athena/Library/Python/3.9/lib/python/site-packages/swarms/__init__.py\", line 7, in <module>\r\n    from swarms.agents import *  # noqa: E402, F403\r\n  File \"/Users/athena/Library/Python/3.9/lib/python/site-packages/swarms/agents/__init__.py\", line 1, in <module>\r\n    from swarms.agents.agent_wrapper import agent_wrapper\r\n  File \"/Users/athena/Library/Python/3.9/lib/python/site-packages/swarms/agents/agent_wrapper.py\", line 1, in <module>\r\n    from swarms.structs.agent import Agent\r\n  File \"/Users/athena/Library/Python/3.9/lib/python/site-packages/swarms/structs/__init__.py\", line 1, in <module>\r\n    from swarms.structs.agent import Agent\r\n  File \"/Users/athena/Library/Python/3.9/lib/python/site-packages/swarms/structs/agent.py\", line 15, in <module>\r\n    from swarms.memory.base_vectordb import AbstractVectorDatabase\r\n  File \"/Users/athena/Library/Python/3.9/lib/python/site-packages/swarms/memory/__init__.py\", line 7, in <module>\r\n    from swarms.memory.lanchain_chroma import LangchainChromaVectorMemory\r\n  File \"/Users/athena/Library/Python/3.9/lib/python/site-packages/swarms/memory/lanchain_chroma.py\", line 10, in <module>\r\n    from swarms.models.openai_models import OpenAIChat\r\n  File \"/Users/athena/Library/Python/3.9/lib/python/site-packages/swarms/models/__init__.py\", line 32, in <module>\r\n    from swarms.models.openai_models import (\r\n  File \"/Users/athena/Library/Python/3.9/lib/python/site-packages/swarms/models/openai_models.py\", line 225, in <module>\r\n    class BaseOpenAI(BaseLLM):\r\n  File \"pydantic/main.py\", line 178, in pydantic.main.ModelMetaclass.__new__\r\n  File \"pydantic/typing.py\", line 400, in pydantic.typing.resolve_annotations\r\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/typing.py\", line 290, in _eval_type\r\n    return t._evaluate(globalns, localns, recursive_guard)\r\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/typing.py\", line 546, in _evaluate\r\n    eval(self.__forward_code__, globalns, localns),\r\n  File \"<string>\", line 1, in <module>\r\nTypeError: unsupported operand type(s) for |: 'type' and 'types.GenericAlias'\r\n```",
      "state": "closed",
      "author": "starshipvc",
      "author_type": "User",
      "created_at": "2024-03-01T01:09:35Z",
      "updated_at": "2025-03-20T16:24:40Z",
      "closed_at": "2024-10-28T18:21:46Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/400/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/400",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/400",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:27.387761",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "Hi starshipvc,\r\n\r\nThis appears to be coming from \"/Users/athena/Desktop/athena/sam_altman.py\".\r\nWould you be able to share a minimal reproducable example?\r\nhttps://en.wikipedia.org/wiki/Minimal_reproducible_example\r\n\r\nPlease ask any questions you may have,\r\nEvelyn Mitchell",
          "created_at": "2024-03-01T02:46:44Z"
        }
      ]
    },
    {
      "issue_number": 399,
      "title": "[BUG] TypeError: unsupported operand type(s) for |: 'type' and 'NoneType'",
      "body": "```\r\n/Users/athena/Desktop/athena/sam_altman.py\r\n/Users/athena/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\r\n  warnings.warn(\r\nswarms is up to date!\r\nTraceback (most recent call last):\r\n    from swarms import Agent, ChromaDB, OpenAIChat\r\n  File \"/Users/athena/Library/Python/3.9/lib/python/site-packages/swarms/__init__.py\", line 7, in <module>\r\n    from swarms.agents import *  # noqa: E402, F403\r\n  File \"/Users/athena/Library/Python/3.9/lib/python/site-packages/swarms/agents/__init__.py\", line 1, in <module>\r\n    from swarms.agents.agent_wrapper import agent_wrapper\r\n  File \"/Users/athena/Library/Python/3.9/lib/python/site-packages/swarms/agents/agent_wrapper.py\", line 1, in <module>\r\n    from swarms.structs.agent import Agent\r\n  File \"/Users/athena/Library/Python/3.9/lib/python/site-packages/swarms/structs/__init__.py\", line 1, in <module>\r\n    from swarms.structs.agent import Agent\r\n  File \"/Users/athena/Library/Python/3.9/lib/python/site-packages/swarms/structs/agent.py\", line 15, in <module>\r\n    from swarms.memory.base_vectordb import AbstractVectorDatabase\r\n  File \"/Users/athena/Library/Python/3.9/lib/python/site-packages/swarms/memory/__init__.py\", line 7, in <module>\r\n    from swarms.memory.lanchain_chroma import LangchainChromaVectorMemory\r\n  File \"/Users/athena/Library/Python/3.9/lib/python/site-packages/swarms/memory/lanchain_chroma.py\", line 10, in <module>\r\n    from swarms.models.openai_models import OpenAIChat\r\n  File \"/Users/athena/Library/Python/3.9/lib/python/site-packages/swarms/models/__init__.py\", line 32, in <module>\r\n    from swarms.models.openai_models import (\r\n  File \"/Users/athena/Library/Python/3.9/lib/python/site-packages/swarms/models/openai_models.py\", line 228, in <module>\r\n    class BaseOpenAI(BaseLLM):\r\n  File \"pydantic/main.py\", line 178, in pydantic.main.ModelMetaclass.__new__\r\n  File \"pydantic/typing.py\", line 400, in pydantic.typing.resolve_annotations\r\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/typing.py\", line 290, in _eval_type\r\n    return t._evaluate(globalns, localns, recursive_guard)\r\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/typing.py\", line 546, in _evaluate\r\n    eval(self.__forward_code__, globalns, localns),\r\n  File \"<string>\", line 1, in <module>\r\nTypeError: unsupported operand type(s) for |: 'type' and 'NoneType'\r\nathena@Athenas-MacBook-Pro athena % \r\n```",
      "state": "closed",
      "author": "starshipvc",
      "author_type": "User",
      "created_at": "2024-03-01T00:30:32Z",
      "updated_at": "2025-03-20T16:24:40Z",
      "closed_at": "2025-02-13T20:51:46Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/399/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/399",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/399",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:27.561352",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-03-01T00:30:59Z"
        },
        {
          "author": "evelynmitchell",
          "body": "Hi starshipvc,\r\n\r\nThis appears to be coming from \"/Users/athena/Desktop/athena/sam_altman.py\".\r\nWould you be able to share a minimal reproducable example?\r\nhttps://en.wikipedia.org/wiki/Minimal_reproducible_example\r\n\r\nPlease ask any questions you may have,\r\nEvelyn Mitchell",
          "created_at": "2024-03-01T02:47:03Z"
        },
        {
          "author": "evelynmitchell",
          "body": "This is an issue affecting code written by the OP, and had had no activity for a long time.\nIt can be closed",
          "created_at": "2025-02-04T18:57:03Z"
        }
      ]
    },
    {
      "issue_number": 384,
      "title": "Custom GPT/HuggingFace chat assistant",
      "body": "I think it would be beneficial to provide a custom GPT or even a HF chat assistant that people can use to chat the docs and codebase. Something similar to CrewAI's Assistant GPT.",
      "state": "closed",
      "author": "JimJim12",
      "author_type": "User",
      "created_at": "2024-02-15T03:03:34Z",
      "updated_at": "2025-03-20T16:24:39Z",
      "closed_at": "2025-02-13T20:50:19Z",
      "labels": [
        "no-issue-activity"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/384/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/384",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/384",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:27.801348",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-02-15T03:03:58Z"
        },
        {
          "author": "evelynmitchell",
          "body": "You may find the PyTorch Model Implementer helpful:\r\n\r\nhttps://chat.openai.com/g/g-VgTBswsG8-pytorch-model-implementer\r\n\r\nIt's a good place to start.",
          "created_at": "2024-02-16T20:40:18Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "Stale issue message",
          "created_at": "2024-04-17T12:45:34Z"
        },
        {
          "author": "evelynmitchell",
          "body": "A chat interface will be added in the next UI release. \n\nThis can be closed.",
          "created_at": "2025-02-04T18:55:25Z"
        }
      ]
    },
    {
      "issue_number": 381,
      "title": "[BUG] [REQS] pandas",
      "body": "**Describe the bug**\r\npandas is a requirement but is never used, except in a usage example:\r\n\r\nutils/usage_hash.py imports pandas, but this function is used only in an example for pinecone\r\n\r\n```\r\n    >>> from swarms.utils.embeddings import USEEmbedding\r\n    >>> from swarms.utils.hash import str_to_hash\r\n    >>> from swarms.utils.dataframe import dataframe_to_hash\r\n    >>> import pandas as pd\r\n    >>>\r\n    >>> # Create a new PineconeDB instance:\r\n    >>> pv = PineconeDB(\r\n````\r\n\r\npandas is a fairly large package, and probably should be dropped.",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2024-02-09T03:31:37Z",
      "updated_at": "2025-03-20T16:24:39Z",
      "closed_at": "2024-04-16T12:45:40Z",
      "labels": [
        "bug",
        "no-issue-activity"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/381/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/381",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/381",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:28.006682",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Stale issue message",
          "created_at": "2024-04-09T12:45:03Z"
        }
      ]
    },
    {
      "issue_number": 379,
      "title": "[BUG] Error when installing: \"could not build wheels for faiss-cpu\"",
      "body": "**Describe the bug**\r\nA clear and concise description of what the bug is.\r\nWhen I try to install I get an error.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\nOn Windows 11, inside conda environment:\r\nPython version: 3.12\r\n`pip install swarms`\r\n```\r\nBuilding wheels for collected packages: faiss-cpu\r\n  Building wheel for faiss-cpu (pyproject.toml) ... error\r\n  error: subprocess-exited-with-error\r\n\r\n  × Building wheel for faiss-cpu (pyproject.toml) did not run successfully.\r\n  │ exit code: 1\r\n  ╰─> [8 lines of output]\r\n      running bdist_wheel\r\n      running build\r\n      running build_py\r\n      running build_ext\r\n      building 'faiss._swigfaiss' extension\r\n      swigging faiss\\faiss\\python\\swigfaiss.i to faiss\\faiss\\python\\swigfaiss_wrap.cpp\r\n      swig.exe -python -c++ -Doverride= -I/usr/local/include -Ifaiss -doxygen -DSWIGWIN -module swigfaiss -o faiss\\faiss\\python\\swigfaiss_wrap.cpp faiss\\faiss\\python\\swigfaiss.i\r\n      error: command 'swig.exe' failed: None\r\n      [end of output]\r\n\r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\n  ERROR: Failed building wheel for faiss-cpu\r\nFailed to build faiss-cpu\r\nERROR: Could not build wheels for faiss-cpu, which is required to install pyproject.toml-based projects\r\n```\r\n\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\nInstall normally\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.",
      "state": "closed",
      "author": "JiHa-Kim",
      "author_type": "User",
      "created_at": "2024-02-05T15:19:30Z",
      "updated_at": "2025-03-20T16:24:39Z",
      "closed_at": "2024-02-13T22:31:04Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/379/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/379",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/379",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:28.436955",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-02-05T15:19:57Z"
        },
        {
          "author": "kyegomez",
          "body": "@JiHa-Kim what is your platform?",
          "created_at": "2024-02-08T03:37:43Z"
        },
        {
          "author": "JiHa-Kim",
          "body": "Windows 11\r\nReverting Python to 3.11 fixed this particular issue.",
          "created_at": "2024-02-08T11:54:07Z"
        },
        {
          "author": "evelynmitchell",
          "body": "i think this can be closed. 3.11 is a good version, very nice.",
          "created_at": "2024-02-13T02:41:46Z"
        }
      ]
    },
    {
      "issue_number": 376,
      "title": "[BUG] [MODELSCOPE] [TEST_COGAGENT]",
      "body": "_______________________________________________________ ERROR collecting tests/models/test_cogagent.py _______________________________________________________\r\nImportError while importing test module '/home/kye/swarms/tests/models/test_cogagent.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/lib/python3.10/importlib/__init__.py:126: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntests/models/test_cogagent.py:2: in <module>\r\n    from swarms.models.cog_agent import CogAgent\r\n../.local/lib/python3.10/site-packages/swarms/models/cog_agent.py:3: in <module>\r\n    from modelscope import AutoModelForCausalLM, AutoTokenizer\r\nE   ModuleNotFoundError: No module named 'modelscope'",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2024-02-01T22:00:52Z",
      "updated_at": "2025-03-20T16:24:39Z",
      "closed_at": "2024-02-04T19:58:20Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/376/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/376",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/376",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:28.652262",
      "comments": []
    },
    {
      "issue_number": 375,
      "title": "[BUG] [MODELSCOPE] [MODELSCOPE_PIPELINE]",
      "body": "_________________________________________________ ERROR collecting tests/models/test_modeelscope_pipeline.py _________________________________________________\r\nImportError while importing test module '/home/kye/swarms/tests/models/test_modeelscope_pipeline.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/lib/python3.10/importlib/__init__.py:126: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntests/models/test_modeelscope_pipeline.py:2: in <module>\r\n    from swarms.models.modelscope_pipeline import ModelScopePipeline\r\n../.local/lib/python3.10/site-packages/swarms/models/modelscope_pipeline.py:1: in <module>\r\n    from modelscope.pipelines import pipeline\r\nE   ModuleNotFoundError: No module named 'modelscope'",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2024-02-01T22:00:01Z",
      "updated_at": "2025-03-20T16:24:39Z",
      "closed_at": "2024-02-04T19:58:27Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/375/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/375",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/375",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:28.652307",
      "comments": []
    },
    {
      "issue_number": 374,
      "title": "[BUG] [MODELSCOPE] [TEST_MODELSCOPE]",
      "body": "____________________________________________________ ERROR collecting tests/models/test_modelscope_llm.py ____________________________________________________\r\nImportError while importing test module '/home/kye/swarms/tests/models/test_modelscope_llm.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/lib/python3.10/importlib/__init__.py:126: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntests/models/test_modelscope_llm.py:2: in <module>\r\n    from swarms.models.modelscope_llm import ModelScopeAutoModel\r\n../.local/lib/python3.10/site-packages/swarms/models/modelscope_llm.py:3: in <module>\r\n    from modelscope import AutoModelForCausalLM, AutoTokenizer\r\nE   ModuleNotFoundError: No module named 'modelscope'",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2024-02-01T21:59:14Z",
      "updated_at": "2025-03-20T16:24:39Z",
      "closed_at": "2024-02-04T19:58:32Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/374/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/374",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/374",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:28.652316",
      "comments": []
    },
    {
      "issue_number": 373,
      "title": "[BUG] [VLLM] [TEST_VLLM]",
      "body": "_________________________________________________________ ERROR collecting tests/models/test_vllm.py _________________________________________________________\r\nImportError while importing test module '/home/kye/swarms/tests/models/test_vllm.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/lib/python3.10/importlib/__init__.py:126: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntests/models/test_vllm.py:2: in <module>\r\n    from swarms.models.vllm import vLLM\r\n../.local/lib/python3.10/site-packages/swarms/models/vllm.py:10: in <module>\r\n    raise error\r\n../.local/lib/python3.10/site-packages/swarms/models/vllm.py:7: in <module>\r\n    from vllm import LLM, SamplingParams\r\nE   ModuleNotFoundError: No module named 'vllm'",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2024-02-01T21:43:19Z",
      "updated_at": "2025-03-20T16:24:39Z",
      "closed_at": "2024-02-04T19:58:38Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/373/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/373",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/373",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:28.652321",
      "comments": []
    },
    {
      "issue_number": 371,
      "title": "[BUG] [TEST] unneeded modelscope tests",
      "body": "tests/models/test_modeelscope_pipeline.py\r\ntests/models/test_modelscope_llm.py\r\n\r\nare both no longer needed, now that modelscope has been removed.",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2024-01-30T14:43:17Z",
      "updated_at": "2025-03-20T16:24:38Z",
      "closed_at": "2024-02-04T19:59:14Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/371/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/371",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/371",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:28.652326",
      "comments": []
    },
    {
      "issue_number": 370,
      "title": "[BUG] Error running agent: 'Agent' object has no attribute 'get_llm_init_params'",
      "body": "**Describe the bug**\r\nWhen running the sample agent for the first time, either in google colab or in the command line, upon calling agent.run(\"Generate a 10,000 word blog on health and wellness.\")\r\n\r\nThe following response is received :\r\nInitializing Autonomous Agent None...\r\nAutonomous Agent Activated.\r\nAll systems operational. Executing task...\r\nERROR:root:Error running agent: 'Agent' object has no attribute 'get_llm_init_params'\r\nError running agent: 'Agent' object has no attribute 'get_llm_init_params'\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to 'google colab notebook': https://colab.research.google.com/github/kyegomez/swarms/blob/master/playground/swarms_example.ipynb\r\n2. Add Open AI API Key \r\n3. Hit Run All\r\n4. See error\r\nERROR:root:Error running agent: 'Agent' object has no attribute 'get_llm_init_params'\r\nError running agent: 'Agent' object has no attribute 'get_llm_init_params'\r\n\r\n\r\n**Expected behavior**\r\nThe bot should be able to return the response as a 10k word blog\r\n\r\n<img width=\"773\" alt=\"Screenshot 2024-01-30 at 15 45 40\" src=\"https://github.com/kyegomez/swarms/assets/16238974/c3da395f-99b6-4616-88a9-c14af5d3bcd1\">\r\n\r\n<img width=\"724\" alt=\"Screenshot 2024-01-30 at 15 42 25\" src=\"https://github.com/kyegomez/swarms/assets/16238974/f168b8ae-d6dc-49f7-8c3a-ecb108df1f16\">\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.",
      "state": "closed",
      "author": "arnavsaxena17",
      "author_type": "User",
      "created_at": "2024-01-30T10:13:03Z",
      "updated_at": "2025-03-20T16:24:38Z",
      "closed_at": "2024-02-04T19:59:06Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 10,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/370/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/370",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/370",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:28.652331",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-01-30T10:13:31Z"
        },
        {
          "author": "kyegomez",
          "body": "@arnavsaxena17 Hey I have fixed it, please give it a try again by upgrading your package with:\r\n\r\n`pip3 install -U swarms`",
          "created_at": "2024-01-30T13:33:29Z"
        },
        {
          "author": "arnavsaxena17",
          "body": "Umm, tried it. Still the same error",
          "created_at": "2024-01-30T14:09:36Z"
        },
        {
          "author": "kyegomez",
          "body": "@arnavsaxena17 try deleting the swarms package with: \n\n```\npip uninstall swarms\n```\n\nThen try:\n\n```\npip cache purge\n```\n\nThen\n\n```\npip3 install -U swarms\n```\n\nIf this does not work, join the Agora discord voice channel and show me your screen and I'll help you:\n\nhttps://discord.gg/kQa9dFyB7t",
          "created_at": "2024-01-30T15:44:06Z"
        },
        {
          "author": "arnavsaxena17",
          "body": "Hasn't worked. Tried on colab as well. Pinging you on discord",
          "created_at": "2024-01-30T16:12:12Z"
        }
      ]
    },
    {
      "issue_number": 368,
      "title": "[BUG] ImportError: cannot import name 'create_base_retry_decorator' from 'langchain.llms.base' ",
      "body": "Traceback (most recent call last):\r\n  File \"D:\\resumewebsite\\functioncalling\\swarms-master\\vision.py\", line 1, in <module>\r\n    from swarms import QwenVLMultiModal\r\n  File \"D:\\resumewebsite\\functioncalling\\swarms-master\\swarms\\__init__.py\", line 6, in <module>\r\n    from swarms.agents import *  # noqa: E402, F403\r\n  File \"D:\\resumewebsite\\functioncalling\\swarms-master\\swarms\\agents\\__init__.py\", line 3, in <module>\r\n    from swarms.agents.simple_agent import SimpleAgent\r\n  File \"D:\\resumewebsite\\functioncalling\\swarms-master\\swarms\\agents\\simple_agent.py\", line 2, in <module>\r\n    from swarms.models.base_llm import AbstractLLM\r\n  File \"D:\\resumewebsite\\functioncalling\\swarms-master\\swarms\\models\\__init__.py\", line 6, in <module>\r\n    from swarms.models.openai_models import (\r\n  File \"D:\\resumewebsite\\functioncalling\\swarms-master\\swarms\\models\\openai_models.py\", line 26, in <module>\r\n    from langchain.llms.base import BaseLLM, create_base_retry_decorator\r\nImportError: cannot import name 'create_base_retry_decorator' from 'langchain.llms.base' (C:\\Users\\Peyton\\anaconda3\\lib\\site-packages\\langchain\\llms\\base.py)",
      "state": "closed",
      "author": "peytontolbert",
      "author_type": "User",
      "created_at": "2024-01-28T01:10:43Z",
      "updated_at": "2025-03-20T16:24:38Z",
      "closed_at": "2024-04-08T12:44:50Z",
      "labels": [
        "bug",
        "no-issue-activity"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/368/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/368",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/368",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:28.867178",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-01-28T01:11:10Z"
        },
        {
          "author": "kyegomez",
          "body": "@peytontolbert try again when you have a chance by upgrading your swarms:\r\n\r\n$ pip install -U swarms",
          "created_at": "2024-01-28T21:55:09Z"
        },
        {
          "author": "kyegomez",
          "body": "@peytontolbert LMK if it's working pls",
          "created_at": "2024-01-30T21:16:36Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "Stale issue message",
          "created_at": "2024-03-31T12:42:26Z"
        }
      ]
    },
    {
      "issue_number": 367,
      "title": "[BUG] [DEP} transformers VipLlavaForConditionalGeneration",
      "body": "**Describe the bug**\r\ntransformers v4.37.1 is needed for VipLlavaForConditionalGeneration import\r\nsee: https://github.com/huggingface/transformers/commit/c7f076a00ee54f777b3d3322c91bc11489a47950",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2024-01-25T02:43:49Z",
      "updated_at": "2025-03-20T16:24:38Z",
      "closed_at": "2024-01-25T16:42:33Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/367/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/367",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/367",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:29.047242",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@evelynmitchell just fixed it now",
          "created_at": "2024-01-25T13:26:05Z"
        },
        {
          "author": "evelynmitchell",
          "body": "Looking good! Thanks Kye!",
          "created_at": "2024-01-25T15:51:14Z"
        }
      ]
    },
    {
      "issue_number": 366,
      "title": "[BUG] [DOCS] Data-room stats",
      "body": "**Describe the bug**\r\nData-room downloads badge points to issues\r\n```\r\nTotal Downloads of all time: GitHub issues\r\nTotal Downloads this week: GitHub issues\r\n```\r\n\r\nAnd this is 404:\r\n```\r\n[Github Community insights](https://github.com/kyegomez/swarms/graphs/community)\r\n```\r\n\r\nThis goes to the my landing page on github, Is it a public endpoint?\r\n```\r\n[Github Traffic Metrics](https://github.com/kyegomez/swarms/graphs/traffic)\r\n```\r\n![Screenshot from 2024-01-24 17-21-31](https://github.com/kyegomez/swarms/assets/1007591/8ac5bc9e-241b-4931-b57d-f1e26b81311e)",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2024-01-25T00:21:59Z",
      "updated_at": "2025-03-20T16:24:38Z",
      "closed_at": "2024-01-25T02:47:33Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/366/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/366",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/366",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:29.258121",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "Fix looks good. Thanks Kye!",
          "created_at": "2024-01-25T02:47:33Z"
        }
      ]
    },
    {
      "issue_number": 365,
      "title": "[BUG] TypeError: Task.execute() missing 1 required positional argument: 'task'",
      "body": "```\r\nswarms is up to date!\r\nDEBUG:jax._src.path:etils.epath found. Using etils.epath for file I/O.\r\netils.epath found. Using etils.epath for file I/O.\r\nDEBUG:asyncio:Using selector: EpollSelector\r\nUsing selector: EpollSelector\r\nINFO:swarms.structs.recursive_workflow:[INFO][RecursiveWorkflow] Added task Task(agent=<swarms.structs.agent.Agent object at 0x7caf8a037550>, description=\"What's the weather in miami\", args=[], kwargs={}, result=None, history=[], schedule_time=None, trigger=None, action=None, condition=None, priority=0, dependencies=[]) to workflow\r\n[INFO][RecursiveWorkflow] Added task Task(agent=<swarms.structs.agent.Agent object at 0x7caf8a037550>, description=\"What's the weather in miami\", args=[], kwargs={}, result=None, history=[], schedule_time=None, trigger=None, action=None, condition=None, priority=0, dependencies=[]) to workflow\r\nINFO:swarms.structs.recursive_workflow:[INFO][RecursiveWorkflow] Added task Task(agent=<swarms.structs.agent.Agent object at 0x7caf8a037550>, description=\"What's the weather in new york\", args=[], kwargs={}, result=None, history=[], schedule_time=None, trigger=None, action=None, condition=None, priority=0, dependencies=[]) to workflow\r\n[INFO][RecursiveWorkflow] Added task Task(agent=<swarms.structs.agent.Agent object at 0x7caf8a037550>, description=\"What's the weather in new york\", args=[], kwargs={}, result=None, history=[], schedule_time=None, trigger=None, action=None, condition=None, priority=0, dependencies=[]) to workflow\r\nINFO:swarms.structs.recursive_workflow:[INFO][RecursiveWorkflow] Added task Task(agent=<swarms.structs.agent.Agent object at 0x7caf8a037550>, description=\"What's the weather in london\", args=[], kwargs={}, result=None, history=[], schedule_time=None, trigger=None, action=None, condition=None, priority=0, dependencies=[]) to workflow\r\n[INFO][RecursiveWorkflow] Added task Task(agent=<swarms.structs.agent.Agent object at 0x7caf8a037550>, description=\"What's the weather in london\", args=[], kwargs={}, result=None, history=[], schedule_time=None, trigger=None, action=None, condition=None, priority=0, dependencies=[]) to workflow\r\nWARNING:swarms.structs.recursive_workflow:[ERROR][RecursiveWorkflow] Task.execute() missing 1 required positional argument: 'task'\r\n[ERROR][RecursiveWorkflow] Task.execute() missing 1 required positional argument: 'task'\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n[<ipython-input-3-86c49eb9689d>](https://localhost:8080/#) in <cell line: 26>()\r\n     24 \r\n     25 # Run the workflow\r\n---> 26 workflow.run()\r\n\r\n2 frames\r\n[/usr/local/lib/python3.10/dist-packages/swarms/structs/task.py](https://localhost:8080/#) in run(self)\r\n    111 \r\n    112     def run(self):\r\n--> 113         self.execute()\r\n    114 \r\n    115     def __call__(self):\r\n\r\nTypeError: Task.execute() missing 1 required positional argument: 'task'\r\n```",
      "state": "closed",
      "author": "donduq",
      "author_type": "User",
      "created_at": "2024-01-20T03:03:01Z",
      "updated_at": "2025-03-20T16:24:38Z",
      "closed_at": "2024-01-25T21:32:33Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/365/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/365",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/365",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:29.494786",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@donduq hey please try again this bug has been eliminated",
          "created_at": "2024-01-23T18:08:21Z"
        }
      ]
    },
    {
      "issue_number": 364,
      "title": "[BUG] error: subprocess-exited-with-error",
      "body": "```\r\npip3 install -U swarms\r\nCollecting swarms\r\n  Downloading swarms-3.6.9-py3-none-any.whl.metadata (37 kB)\r\nCollecting Pillow==9.4.0 (from swarms)\r\n  Using cached Pillow-9.4.0.tar.gz (50.4 MB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n  Preparing metadata (pyproject.toml) ... done\r\nCollecting PyPDF2==3.0.1 (from swarms)\r\n  Using cached pypdf2-3.0.1-py3-none-any.whl (232 kB)\r\nCollecting accelerate (from swarms)\r\n  Using cached accelerate-0.26.1-py3-none-any.whl.metadata (18 kB)\r\nCollecting asyncio==3.4.3 (from swarms)\r\n  Using cached asyncio-3.4.3-py3-none-any.whl (101 kB)\r\nCollecting attrs==22.2.0 (from swarms)\r\n  Using cached attrs-22.2.0-py3-none-any.whl (60 kB)\r\nCollecting backoff==2.2.1 (from swarms)\r\n  Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\r\nCollecting beautifulsoup4==4.11.2 (from swarms)\r\n  Using cached beautifulsoup4-4.11.2-py3-none-any.whl (129 kB)\r\nCollecting bitsandbytes (from swarms)\r\n  Using cached bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\r\nCollecting black==23.3.0 (from swarms)\r\n  Using cached black-23.3.0-py3-none-any.whl (180 kB)\r\nCollecting chromadb==0.4.14 (from swarms)\r\n  Using cached chromadb-0.4.14-py3-none-any.whl.metadata (7.0 kB)\r\nCollecting cohere==4.24 (from swarms)\r\n  Using cached cohere-4.24-py3-none-any.whl.metadata (5.3 kB)\r\nCollecting datasets (from swarms)\r\n  Using cached datasets-2.16.1-py3-none-any.whl.metadata (20 kB)\r\nCollecting diffusers (from swarms)\r\n  Using cached diffusers-0.25.1-py3-none-any.whl.metadata (19 kB)\r\nCollecting einops==0.7.0 (from swarms)\r\n  Using cached einops-0.7.0-py3-none-any.whl.metadata (13 kB)\r\nCollecting faiss-cpu==1.7.4 (from swarms)\r\n  Using cached faiss-cpu-1.7.4.tar.gz (57 kB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n  Preparing metadata (pyproject.toml) ... done\r\nCollecting ggl==1.1.0 (from swarms)\r\n  Using cached ggl-1.1.0.tar.gz (1.3 kB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n  Preparing metadata (pyproject.toml) ... done\r\nCollecting google-generativeai==0.3.1 (from swarms)\r\n  Using cached google_generativeai-0.3.1-py3-none-any.whl.metadata (5.9 kB)\r\nCollecting httpx==0.24.1 (from swarms)\r\n  Using cached httpx-0.24.1-py3-none-any.whl.metadata (7.4 kB)\r\nCollecting huggingface-hub (from swarms)\r\n  Using cached huggingface_hub-0.20.2-py3-none-any.whl.metadata (12 kB)\r\nCollecting langchain==0.0.333 (from swarms)\r\n  Using cached langchain-0.0.333-py3-none-any.whl.metadata (16 kB)\r\nCollecting langchain-experimental==0.0.10 (from swarms)\r\n  Using cached langchain_experimental-0.0.10-py3-none-any.whl.metadata (718 bytes)\r\nCollecting marshmallow==3.19.0 (from swarms)\r\n  Using cached marshmallow-3.19.0-py3-none-any.whl (49 kB)\r\nCollecting open_clip_torch==2.20.0 (from swarms)\r\n  Using cached open_clip_torch-2.20.0-py3-none-any.whl.metadata (46 kB)\r\nCollecting openai==0.28.0 (from swarms)\r\n  Using cached openai-0.28.0-py3-none-any.whl.metadata (13 kB)\r\nCollecting opencv-python-headless==4.8.1.78 (from swarms)\r\n  Using cached opencv_python_headless-4.8.1.78-cp37-abi3-macosx_10_16_x86_64.whl.metadata (19 kB)\r\nCollecting optimum==1.15.0 (from swarms)\r\n  Using cached optimum-1.15.0-py3-none-any.whl.metadata (17 kB)\r\nCollecting peft (from swarms)\r\n  Using cached peft-0.7.1-py3-none-any.whl.metadata (25 kB)\r\nCollecting pgvector (from swarms)\r\n  Using cached pgvector-0.2.4-py2.py3-none-any.whl.metadata (9.8 kB)\r\nCollecting playwright==1.34.0 (from swarms)\r\n  Using cached playwright-1.34.0-py3-none-macosx_11_0_universal2.whl.metadata (3.6 kB)\r\nCollecting psutil (from swarms)\r\n  Using cached psutil-5.9.8-cp36-abi3-macosx_10_9_x86_64.whl.metadata (21 kB)\r\nCollecting pydantic==1.10.12 (from swarms)\r\n  Using cached pydantic-1.10.12-py3-none-any.whl.metadata (149 kB)\r\nCollecting qdrant-client (from swarms)\r\n  Using cached qdrant_client-1.7.1-py3-none-any.whl.metadata (9.3 kB)\r\nCollecting ratelimit==2.2.1 (from swarms)\r\n  Using cached ratelimit-2.2.1.tar.gz (5.3 kB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n  Preparing metadata (pyproject.toml) ... done\r\nCollecting rich==13.5.2 (from swarms)\r\n  Using cached rich-13.5.2-py3-none-any.whl.metadata (18 kB)\r\nCollecting safetensors==0.3.3 (from swarms)\r\n  Using cached safetensors-0.3.3.tar.gz (35 kB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n  Preparing metadata (pyproject.toml) ... done\r\nCollecting sentence-transformers (from swarms)\r\n  Using cached sentence-transformers-2.2.2.tar.gz (85 kB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n  Preparing metadata (pyproject.toml) ... done\r\nCollecting sentencepiece==0.1.98 (from swarms)\r\n  Using cached sentencepiece-0.1.98.tar.gz (2.6 MB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n  Preparing metadata (pyproject.toml) ... done\r\nCollecting soundfile==0.12.1 (from swarms)\r\n  Using cached soundfile-0.12.1-py2.py3-none-macosx_10_9_x86_64.whl (1.2 MB)\r\nCollecting sqlalchemy (from swarms)\r\n  Using cached SQLAlchemy-2.0.25-cp312-cp312-macosx_10_9_x86_64.whl.metadata (9.6 kB)\r\nCollecting supervision (from swarms)\r\n  Downloading supervision-0.17.1-py3-none-any.whl.metadata (12 kB)\r\nCollecting tabulate==0.9.0 (from swarms)\r\n  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\r\nCollecting tenacity==8.2.2 (from swarms)\r\n  Using cached tenacity-8.2.2-py3-none-any.whl (24 kB)\r\nINFO: pip is looking at multiple versions of swarms to determine which version is compatible with other requirements. This could take a while.\r\nCollecting swarms\r\n  Using cached swarms-3.6.8-py3-none-any.whl.metadata (37 kB)\r\n  Using cached swarms-3.6.7-py3-none-any.whl.metadata (37 kB)\r\n  Using cached swarms-3.6.6-py3-none-any.whl.metadata (37 kB)\r\n  Using cached swarms-3.6.5-py3-none-any.whl.metadata (37 kB)\r\nCollecting modelscope==1.10.0 (from swarms)\r\n  Using cached modelscope-1.10.0-py3-none-any.whl.metadata (33 kB)\r\nCollecting swarms\r\n  Using cached swarms-3.6.4-py3-none-any.whl.metadata (37 kB)\r\n  Using cached swarms-3.6.2-py3-none-any.whl.metadata (37 kB)\r\n  Using cached swarms-3.6.0-py3-none-any.whl.metadata (37 kB)\r\nINFO: pip is still looking at multiple versions of swarms to determine which version is compatible with other requirements. This could take a while.\r\n  Using cached swarms-3.5.9-py3-none-any.whl.metadata (37 kB)\r\n  Using cached swarms-3.5.6-py3-none-any.whl.metadata (37 kB)\r\n  Using cached swarms-3.5.3-py3-none-any.whl.metadata (37 kB)\r\n  Using cached swarms-3.5.2-py3-none-any.whl.metadata (37 kB)\r\n  Using cached swarms-3.5.1-py3-none-any.whl.metadata (37 kB)\r\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\r\n  Using cached swarms-3.5.0-py3-none-any.whl.metadata (37 kB)\r\n  Using cached swarms-3.4.9-py3-none-any.whl.metadata (37 kB)\r\n  Using cached swarms-3.4.8-py3-none-any.whl.metadata (36 kB)\r\n  Using cached swarms-3.4.7-py3-none-any.whl.metadata (35 kB)\r\n  Using cached swarms-3.4.6-py3-none-any.whl.metadata (35 kB)\r\n  Using cached swarms-3.4.2-py3-none-any.whl.metadata (35 kB)\r\n  Using cached swarms-3.4.1-py3-none-any.whl.metadata (31 kB)\r\n  Using cached swarms-3.4.0-py3-none-any.whl.metadata (31 kB)\r\n  Using cached swarms-3.3.7-py3-none-any.whl.metadata (31 kB)\r\nCollecting accelerate==0.22.0 (from swarms)\r\n  Using cached accelerate-0.22.0-py3-none-any.whl.metadata (17 kB)\r\nCollecting swarms\r\n  Using cached swarms-3.3.4-py3-none-any.whl.metadata (31 kB)\r\n  Using cached swarms-3.3.3-py3-none-any.whl.metadata (31 kB)\r\nCollecting huggingface-hub==0.16.4 (from swarms)\r\n  Using cached huggingface_hub-0.16.4-py3-none-any.whl.metadata (12 kB)\r\nCollecting swarms\r\n  Using cached swarms-3.3.2-py3-none-any.whl.metadata (31 kB)\r\nCollecting datasets==2.10.1 (from swarms)\r\n  Using cached datasets-2.10.1-py3-none-any.whl (469 kB)\r\nCollecting swarms\r\n  Using cached swarms-3.3.1-py3-none-any.whl.metadata (31 kB)\r\n  Using cached swarms-3.3.0-py3-none-any.whl.metadata (31 kB)\r\n  Using cached swarms-3.2.9-py3-none-any.whl.metadata (31 kB)\r\n  Using cached swarms-3.2.8-py3-none-any.whl.metadata (31 kB)\r\n  Using cached swarms-3.2.7-py3-none-any.whl.metadata (31 kB)\r\n  Using cached swarms-3.2.6-py3-none-any.whl.metadata (31 kB)\r\n  Using cached swarms-3.2.3-py3-none-any.whl.metadata (30 kB)\r\n  Using cached swarms-3.2.1-py3-none-any.whl.metadata (30 kB)\r\n  Using cached swarms-3.2.0-py3-none-any.whl.metadata (30 kB)\r\n  Using cached swarms-3.1.9-py3-none-any.whl.metadata (30 kB)\r\n  Using cached swarms-3.1.8-py3-none-any.whl.metadata (30 kB)\r\n  Using cached swarms-3.1.6-py3-none-any.whl.metadata (29 kB)\r\n  Using cached swarms-3.1.4-py3-none-any.whl.metadata (28 kB)\r\n  Using cached swarms-3.1.3-py3-none-any.whl.metadata (28 kB)\r\n  Using cached swarms-3.1.2-py3-none-any.whl.metadata (28 kB)\r\n  Using cached swarms-3.1.1-py3-none-any.whl.metadata (27 kB)\r\nCollecting diffusers==0.17.1 (from swarms)\r\n  Using cached diffusers-0.17.1-py3-none-any.whl.metadata (17 kB)\r\nCollecting swarms\r\n  Using cached swarms-3.1.0-py3-none-any.whl.metadata (25 kB)\r\n  Using cached swarms-2.9.9-py3-none-any.whl.metadata (18 kB)\r\n  Using cached swarms-2.9.6-py3-none-any.whl.metadata (18 kB)\r\n  Using cached swarms-2.9.5-py3-none-any.whl.metadata (18 kB)\r\n  Using cached swarms-2.9.4-py3-none-any.whl.metadata (18 kB)\r\n  Using cached swarms-2.9.3-py3-none-any.whl.metadata (18 kB)\r\n  Using cached swarms-2.9.2-py3-none-any.whl.metadata (18 kB)\r\n  Using cached swarms-2.9.1-py3-none-any.whl.metadata (18 kB)\r\n  Using cached swarms-2.9.0-py3-none-any.whl.metadata (18 kB)\r\n  Using cached swarms-2.8.9-py3-none-any.whl.metadata (18 kB)\r\n  Using cached swarms-2.8.8-py3-none-any.whl.metadata (18 kB)\r\n  Using cached swarms-2.8.7-py3-none-any.whl.metadata (18 kB)\r\nCollecting Pillow (from swarms)\r\n  Using cached pillow-10.2.0-cp312-cp312-macosx_10_10_x86_64.whl.metadata (9.7 kB)\r\nCollecting attrs (from swarms)\r\n  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\r\nCollecting beautifulsoup4 (from swarms)\r\n  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\r\nCollecting black (from swarms)\r\n  Using cached black-23.12.1-cp312-cp312-macosx_10_9_x86_64.whl.metadata (68 kB)\r\nCollecting chromadb (from swarms)\r\n  Using cached chromadb-0.4.22-py3-none-any.whl.metadata (7.3 kB)\r\nCollecting cohere (from swarms)\r\n  Using cached cohere-4.44-py3-none-any.whl.metadata (5.4 kB)\r\nCollecting google-generativeai==0.3.0 (from swarms)\r\n  Using cached google_generativeai-0.3.0-py3-none-any.whl.metadata (5.8 kB)\r\nCollecting httpx (from swarms)\r\n  Using cached httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\r\nCollecting langchain (from swarms)\r\n  Using cached langchain-0.1.1-py3-none-any.whl.metadata (13 kB)\r\nCollecting langchain-experimental (from swarms)\r\n  Using cached langchain_experimental-0.0.49-py3-none-any.whl.metadata (1.9 kB)\r\nCollecting marshmallow (from swarms)\r\n  Using cached marshmallow-3.20.2-py3-none-any.whl.metadata (7.5 kB)\r\nCollecting open_clip_torch (from swarms)\r\n  Using cached open_clip_torch-2.24.0-py3-none-any.whl.metadata (30 kB)\r\nCollecting opencv-python-headless (from swarms)\r\n  Using cached opencv_python_headless-4.9.0.80-cp37-abi3-macosx_10_16_x86_64.whl.metadata (20 kB)\r\nCollecting playwright (from swarms)\r\n  Using cached playwright-1.41.0-py3-none-macosx_11_0_universal2.whl.metadata (3.6 kB)\r\nCollecting rich (from swarms)\r\n  Using cached rich-13.7.0-py3-none-any.whl.metadata (18 kB)\r\nCollecting safetensors (from swarms)\r\n  Using cached safetensors-0.4.1-cp312-cp312-macosx_10_7_x86_64.whl.metadata (3.8 kB)\r\nCollecting sentencepiece (from swarms)\r\n  Using cached sentencepiece-0.1.99.tar.gz (2.6 MB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n  Preparing metadata (pyproject.toml) ... done\r\nCollecting tenacity (from swarms)\r\n  Using cached tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\r\nCollecting swarms\r\n  Using cached swarms-2.8.4-py3-none-any.whl.metadata (18 kB)\r\n  Using cached swarms-2.8.3-py3-none-any.whl.metadata (18 kB)\r\n  Using cached swarms-2.7.9-py3-none-any.whl.metadata (18 kB)\r\nCollecting google-generativeai (from swarms)\r\n  Using cached google_generativeai-0.3.2-py3-none-any.whl.metadata (5.9 kB)\r\nCollecting swarms\r\n  Using cached swarms-2.7.8-py3-none-any.whl.metadata (15 kB)\r\n  Using cached swarms-2.7.7-py3-none-any.whl.metadata (15 kB)\r\nCollecting optimum (from swarms)\r\n  Using cached optimum-1.16.2-py3-none-any.whl.metadata (17 kB)\r\nCollecting swarms\r\n  Using cached swarms-2.7.6-py3-none-any.whl.metadata (15 kB)\r\n  Using cached swarms-2.7.5-py3-none-any.whl.metadata (15 kB)\r\n  Using cached swarms-2.7.4-py3-none-any.whl.metadata (15 kB)\r\n  Using cached swarms-2.7.3-py3-none-any.whl.metadata (15 kB)\r\n  Using cached swarms-2.7.2-py3-none-any.whl.metadata (15 kB)\r\n  Using cached swarms-2.7.1-py3-none-any.whl.metadata (15 kB)\r\n  Using cached swarms-2.6.8-py3-none-any.whl.metadata (15 kB)\r\nCollecting dalle3 (from swarms)\r\n  Using cached dalle3-0.1.0-py3-none-any.whl.metadata (11 kB)\r\nCollecting duckduckgo-search (from swarms)\r\n  Using cached duckduckgo_search-4.2-py3-none-any.whl.metadata (19 kB)\r\nCollecting nest_asyncio (from swarms)\r\n  Using cached nest_asyncio-1.5.9-py3-none-any.whl.metadata (2.8 kB)\r\nCollecting swarms\r\n  Using cached swarms-2.6.7-py3-none-any.whl.metadata (15 kB)\r\n  Using cached swarms-2.6.6-py3-none-any.whl.metadata (15 kB)\r\n  Using cached swarms-2.6.4-py3-none-any.whl.metadata (15 kB)\r\n  Using cached swarms-2.6.3-py3-none-any.whl.metadata (15 kB)\r\n  Using cached swarms-2.6.0-py3-none-any.whl.metadata (21 kB)\r\n  Using cached swarms-2.5.9-py3-none-any.whl.metadata (21 kB)\r\n  Using cached swarms-2.5.7-py3-none-any.whl.metadata (14 kB)\r\nCollecting pydantic (from swarms)\r\n  Using cached pydantic-2.5.3-py3-none-any.whl.metadata (65 kB)\r\nCollecting termcolor (from swarms)\r\n  Using cached termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\r\nCollecting tiktoken (from swarms)\r\n  Using cached tiktoken-0.5.2-cp312-cp312-macosx_10_9_x86_64.whl.metadata (6.6 kB)\r\nCollecting swarms\r\n  Using cached swarms-2.5.4-py3-none-any.whl.metadata (14 kB)\r\n  Using cached swarms-2.5.1-py3-none-any.whl.metadata (14 kB)\r\n  Using cached swarms-2.5.0-py3-none-any.whl.metadata (14 kB)\r\n  Using cached swarms-2.4.8-py3-none-any.whl.metadata (14 kB)\r\n  Using cached swarms-2.4.7-py3-none-any.whl.metadata (14 kB)\r\n  Using cached swarms-2.4.6-py3-none-any.whl.metadata (14 kB)\r\n  Using cached swarms-2.4.4-py3-none-any.whl.metadata (14 kB)\r\n  Using cached swarms-2.4.3-py3-none-any.whl.metadata (14 kB)\r\n  Using cached swarms-2.4.2-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-2.4.1-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-2.4.0-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-2.3.8-py3-none-any.whl.metadata (14 kB)\r\n  Using cached swarms-2.3.7-py3-none-any.whl.metadata (19 kB)\r\n  Using cached swarms-2.3.4-py3-none-any.whl.metadata (13 kB)\r\nCollecting griptape (from swarms)\r\n  Using cached griptape-0.22.2-py3-none-any.whl.metadata (15 kB)\r\nCollecting swarms\r\n  Using cached swarms-2.3.3-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-2.3.2-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-2.3.1-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-2.3.0-py3-none-any.whl.metadata (18 kB)\r\n  Using cached swarms-2.2.9-py3-none-any.whl.metadata (8.7 kB)\r\nCollecting openai (from swarms)\r\n  Using cached openai-1.8.0-py3-none-any.whl.metadata (18 kB)\r\nCollecting swarms\r\n  Using cached swarms-2.2.7-py3-none-any.whl.metadata (8.7 kB)\r\n  Using cached swarms-2.2.6-py3-none-any.whl.metadata (8.7 kB)\r\n  Using cached swarms-2.2.5-py3-none-any.whl.metadata (8.7 kB)\r\n  Using cached swarms-2.2.4-py3-none-any.whl.metadata (8.7 kB)\r\n  Using cached swarms-2.2.3-py3-none-any.whl.metadata (8.7 kB)\r\n  Using cached swarms-2.2.2-py3-none-any.whl.metadata (8.7 kB)\r\n  Using cached swarms-2.2.1-py3-none-any.whl.metadata (8.7 kB)\r\n  Using cached swarms-2.1.8-py3-none-any.whl.metadata (8.7 kB)\r\n  Using cached swarms-2.1.7-py3-none-any.whl.metadata (8.6 kB)\r\n  Using cached swarms-2.1.6-py3-none-any.whl.metadata (8.5 kB)\r\nCollecting openai==0.28.1 (from swarms)\r\n  Using cached openai-0.28.1-py3-none-any.whl.metadata (11 kB)\r\nCollecting swarms\r\n  Using cached swarms-2.1.5-py3-none-any.whl.metadata (8.5 kB)\r\n  Using cached swarms-2.1.4-py3-none-any.whl.metadata (8.5 kB)\r\n  Using cached swarms-2.1.3-py3-none-any.whl.metadata (8.5 kB)\r\n  Using cached swarms-2.1.2-py3-none-any.whl.metadata (8.4 kB)\r\n  Using cached swarms-2.1.1-py3-none-any.whl.metadata (8.4 kB)\r\n  Using cached swarms-2.1.0-py3-none-any.whl.metadata (8.4 kB)\r\n  Using cached swarms-2.0.9-py3-none-any.whl.metadata (8.4 kB)\r\n  Using cached swarms-2.0.8-py3-none-any.whl.metadata (8.4 kB)\r\n  Using cached swarms-2.0.7-py3-none-any.whl.metadata (8.4 kB)\r\n  Using cached swarms-2.0.6-py3-none-any.whl.metadata (8.4 kB)\r\n  Using cached swarms-2.0.4-py3-none-any.whl.metadata (8.4 kB)\r\n  Using cached swarms-2.0.3-py3-none-any.whl.metadata (8.4 kB)\r\n  Using cached swarms-2.0.1-py3-none-any.whl.metadata (9.3 kB)\r\nCollecting open-interpreter (from swarms)\r\n  Using cached open_interpreter-0.2.0-py3-none-any.whl.metadata (14 kB)\r\nCollecting swarms\r\n  Using cached swarms-2.0.0-py3-none-any.whl.metadata (9.3 kB)\r\n  Using cached swarms-1.9.9-py3-none-any.whl.metadata (9.3 kB)\r\n  Using cached swarms-1.9.8-py3-none-any.whl.metadata (9.3 kB)\r\n  Using cached swarms-1.9.7-py3-none-any.whl.metadata (9.3 kB)\r\n  Using cached swarms-1.9.6-py3-none-any.whl.metadata (9.3 kB)\r\n  Using cached swarms-1.9.5-py3-none-any.whl.metadata (8.7 kB)\r\nCollecting agent-protocol (from swarms)\r\n  Using cached agent_protocol-1.0.2-py3-none-any.whl.metadata (3.5 kB)\r\nCollecting pegasusx (from swarms)\r\n  Using cached pegasusx-0.4.0-py3-none-any.whl.metadata (12 kB)\r\nCollecting redis (from swarms)\r\n  Using cached redis-5.0.1-py3-none-any.whl.metadata (8.9 kB)\r\nCollecting swarms\r\n  Using cached swarms-1.9.4-py3-none-any.whl.metadata (7.6 kB)\r\n  Using cached swarms-1.9.3-py3-none-any.whl.metadata (7.5 kB)\r\n  Using cached swarms-1.9.2-py3-none-any.whl.metadata (9.1 kB)\r\nCollecting EdgeGPT (from swarms)\r\n  Using cached EdgeGPT-0.13.2-py3-none-any.whl.metadata (12 kB)\r\nCollecting revChatGPT (from swarms)\r\n  Using cached revChatGPT-6.8.6-py3-none-any.whl.metadata (7.7 kB)\r\nCollecting swarms\r\n  Using cached swarms-1.9.1-py3-none-any.whl.metadata (10 kB)\r\n  Using cached swarms-1.8.2-py3-none-any.whl.metadata (15 kB)\r\n  Using cached swarms-1.8.1-py3-none-any.whl.metadata (15 kB)\r\nCollecting exxa (from swarms)\r\n  Using cached exxa-0.5.5-py3-none-any.whl.metadata (7.5 kB)\r\nCollecting swarms\r\n  Using cached swarms-1.8.0-py3-none-any.whl.metadata (15 kB)\r\n  Using cached swarms-1.7.9-py3-none-any.whl.metadata (15 kB)\r\n  Using cached swarms-1.7.8-py3-none-any.whl.metadata (15 kB)\r\n  Using cached swarms-1.7.7-py3-none-any.whl.metadata (14 kB)\r\n  Using cached swarms-1.7.6-py3-none-any.whl.metadata (14 kB)\r\n  Using cached swarms-1.7.5-py3-none-any.whl.metadata (14 kB)\r\n  Using cached swarms-1.7.4-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-1.7.3-py3-none-any.whl.metadata (13 kB)\r\nCollecting langchain==0.0.240 (from swarms)\r\n  Using cached langchain-0.0.240-py3-none-any.whl.metadata (14 kB)\r\nCollecting swarms\r\n  Using cached swarms-1.7.2-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-1.7.1-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-1.7.0-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-1.6.8-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-1.6.7-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-1.6.6-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-1.6.5-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-1.6.4-py3-none-any.whl.metadata (13 kB)\r\nCollecting shapeless (from swarms)\r\n  Using cached shapeless-0.0.9-py3-none-any.whl.metadata (7.4 kB)\r\nCollecting swarms\r\n  Using cached swarms-1.6.3-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-1.6.2-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-1.6.1-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-1.6.0-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-1.5.9-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-1.5.7-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-1.5.6-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-1.5.5-py3-none-any.whl.metadata (13 kB)\r\nCollecting celery (from swarms)\r\n  Using cached celery-5.3.6-py3-none-any.whl.metadata (21 kB)\r\nCollecting swarms\r\n  Using cached swarms-1.5.4-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-1.5.3-py3-none-any.whl.metadata (13 kB)\r\nCollecting simpleaichat (from swarms)\r\n  Using cached simpleaichat-0.2.2.tar.gz (23 kB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n  Preparing metadata (pyproject.toml) ... done\r\nCollecting swarms\r\n  Using cached swarms-1.5.2-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-1.5.1-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-1.5.0-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-1.4.9-py3-none-any.whl.metadata (12 kB)\r\n  Using cached swarms-1.4.7-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-1.4.6-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-1.4.4-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-1.4.3-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-1.4.2-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-1.4.1-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-1.4.0-py3-none-any.whl.metadata (13 kB)\r\n  Using cached swarms-1.3.9-py3-none-any.whl.metadata (13 kB)\r\nCollecting transformers (from swarms)\r\n  Using cached transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\r\nCollecting wget (from swarms)\r\n  Using cached wget-3.2.zip (10 kB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n  Preparing metadata (pyproject.toml) ... done\r\nCollecting PyYAML>=5.4.1 (from langchain==0.0.240->swarms)\r\n  Using cached PyYAML-6.0.1-cp312-cp312-macosx_10_9_x86_64.whl.metadata (2.1 kB)\r\nCollecting aiohttp<4.0.0,>=3.8.3 (from langchain==0.0.240->swarms)\r\n  Using cached aiohttp-3.9.1-cp312-cp312-macosx_10_9_x86_64.whl.metadata (7.4 kB)\r\nCollecting dataclasses-json<0.6.0,>=0.5.7 (from langchain==0.0.240->swarms)\r\n  Using cached dataclasses_json-0.5.14-py3-none-any.whl.metadata (22 kB)\r\nCollecting langsmith<0.1.0,>=0.0.11 (from langchain==0.0.240->swarms)\r\n  Using cached langsmith-0.0.83-py3-none-any.whl.metadata (10 kB)\r\nCollecting numexpr<3.0.0,>=2.8.4 (from langchain==0.0.240->swarms)\r\n  Using cached numexpr-2.8.8-cp312-cp312-macosx_10_9_x86_64.whl.metadata (7.9 kB)\r\nCollecting numpy<2,>=1 (from langchain==0.0.240->swarms)\r\n  Using cached numpy-1.26.3-cp312-cp312-macosx_10_9_x86_64.whl.metadata (61 kB)\r\nCollecting openapi-schema-pydantic<2.0,>=1.2 (from langchain==0.0.240->swarms)\r\n  Using cached openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\r\nCollecting pydantic (from swarms)\r\n  Using cached pydantic-1.10.14-py3-none-any.whl.metadata (150 kB)\r\nCollecting requests<3,>=2 (from langchain==0.0.240->swarms)\r\n  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\r\nCollecting typing-extensions>=4.2.0 (from pydantic->swarms)\r\n  Using cached typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\r\nCollecting soupsieve>1.2 (from beautifulsoup4->swarms)\r\n  Using cached soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\r\nCollecting billiard<5.0,>=4.2.0 (from celery->swarms)\r\n  Using cached billiard-4.2.0-py3-none-any.whl.metadata (4.4 kB)\r\nCollecting click-didyoumean>=0.3.0 (from celery->swarms)\r\n  Using cached click_didyoumean-0.3.0-py3-none-any.whl (2.7 kB)\r\nCollecting click-plugins>=1.1.1 (from celery->swarms)\r\n  Using cached click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\r\nCollecting click-repl>=0.2.0 (from celery->swarms)\r\n  Using cached click_repl-0.3.0-py3-none-any.whl.metadata (3.6 kB)\r\nCollecting click<9.0,>=8.1.2 (from celery->swarms)\r\n  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\r\nCollecting kombu<6.0,>=5.3.4 (from celery->swarms)\r\n  Using cached kombu-5.3.5-py3-none-any.whl.metadata (3.1 kB)\r\nCollecting python-dateutil>=2.8.2 (from celery->swarms)\r\n  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\r\nCollecting tzdata>=2022.7 (from celery->swarms)\r\n  Using cached tzdata-2023.4-py2.py3-none-any.whl.metadata (1.4 kB)\r\nCollecting vine<6.0,>=5.1.0 (from celery->swarms)\r\n  Using cached vine-5.1.0-py3-none-any.whl.metadata (2.7 kB)\r\nCollecting lxml>=4.9.3 (from duckduckgo-search->swarms)\r\n  Using cached lxml-5.1.0-cp312-cp312-macosx_10_9_x86_64.whl.metadata (3.5 kB)\r\nCollecting curl-cffi>=0.5.10 (from duckduckgo-search->swarms)\r\n  Using cached curl_cffi-0.5.10-cp37-abi3-macosx_10_9_x86_64.whl.metadata (7.9 kB)\r\nCollecting google-ai-generativelanguage==0.4.0 (from google-generativeai->swarms)\r\n  Using cached google_ai_generativelanguage-0.4.0-py3-none-any.whl.metadata (5.1 kB)\r\nCollecting google-auth (from google-generativeai->swarms)\r\n  Using cached google_auth-2.26.2-py2.py3-none-any.whl.metadata (4.7 kB)\r\nCollecting google-api-core (from google-generativeai->swarms)\r\n  Using cached google_api_core-2.15.0-py3-none-any.whl.metadata (2.7 kB)\r\nCollecting protobuf (from google-generativeai->swarms)\r\n  Using cached protobuf-4.25.2-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\r\nCollecting tqdm (from google-generativeai->swarms)\r\n  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\r\nCollecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.4.0->google-generativeai->swarms)\r\n  Using cached proto_plus-1.23.0-py3-none-any.whl.metadata (2.2 kB)\r\nCollecting anyio (from httpx->swarms)\r\n  Using cached anyio-4.2.0-py3-none-any.whl.metadata (4.6 kB)\r\nCollecting certifi (from httpx->swarms)\r\n  Using cached certifi-2023.11.17-py3-none-any.whl.metadata (2.2 kB)\r\nCollecting httpcore==1.* (from httpx->swarms)\r\n  Using cached httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\r\nCollecting idna (from httpx->swarms)\r\n  Using cached idna-3.6-py3-none-any.whl.metadata (9.9 kB)\r\nCollecting sniffio (from httpx->swarms)\r\n  Using cached sniffio-1.3.0-py3-none-any.whl (10 kB)\r\nCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->swarms)\r\n  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\r\nINFO: pip is looking at multiple versions of langchain-experimental to determine which version is compatible with other requirements. This could take a while.\r\nCollecting langchain-experimental (from swarms)\r\n  Using cached langchain_experimental-0.0.48-py3-none-any.whl.metadata (1.9 kB)\r\n  Using cached langchain_experimental-0.0.47-py3-none-any.whl.metadata (1.9 kB)\r\n  Using cached langchain_experimental-0.0.46-py3-none-any.whl.metadata (1.9 kB)\r\n  Using cached langchain_experimental-0.0.45-py3-none-any.whl.metadata (1.9 kB)\r\n  Using cached langchain_experimental-0.0.44-py3-none-any.whl.metadata (1.8 kB)\r\n  Using cached langchain_experimental-0.0.43-py3-none-any.whl.metadata (1.8 kB)\r\n  Using cached langchain_experimental-0.0.42-py3-none-any.whl.metadata (1.8 kB)\r\nINFO: pip is still looking at multiple versions of langchain-experimental to determine which version is compatible with other requirements. This could take a while.\r\n  Using cached langchain_experimental-0.0.41-py3-none-any.whl.metadata (1.8 kB)\r\n  Using cached langchain_experimental-0.0.40-py3-none-any.whl.metadata (1.8 kB)\r\n  Using cached langchain_experimental-0.0.39-py3-none-any.whl.metadata (1.8 kB)\r\n  Using cached langchain_experimental-0.0.38-py3-none-any.whl.metadata (1.8 kB)\r\n  Using cached langchain_experimental-0.0.37-py3-none-any.whl.metadata (1.8 kB)\r\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\r\n  Using cached langchain_experimental-0.0.36-py3-none-any.whl.metadata (1.8 kB)\r\n  Using cached langchain_experimental-0.0.35-py3-none-any.whl.metadata (1.8 kB)\r\n  Using cached langchain_experimental-0.0.34-py3-none-any.whl.metadata (1.8 kB)\r\n  Using cached langchain_experimental-0.0.33-py3-none-any.whl.metadata (1.8 kB)\r\n  Using cached langchain_experimental-0.0.32-py3-none-any.whl.metadata (1.8 kB)\r\n  Using cached langchain_experimental-0.0.31-py3-none-any.whl.metadata (1.8 kB)\r\n  Using cached langchain_experimental-0.0.30-py3-none-any.whl.metadata (1.8 kB)\r\n  Using cached langchain_experimental-0.0.29-py3-none-any.whl.metadata (1.8 kB)\r\n  Using cached langchain_experimental-0.0.28-py3-none-any.whl.metadata (1.8 kB)\r\n  Using cached langchain_experimental-0.0.27-py3-none-any.whl.metadata (1.8 kB)\r\n  Using cached langchain_experimental-0.0.25-py3-none-any.whl.metadata (1.6 kB)\r\nCollecting distro<2,>=1.7.0 (from openai->swarms)\r\n  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\r\nINFO: pip is looking at multiple versions of pegasusx to determine which version is compatible with other requirements. This could take a while.\r\nCollecting pegasusx (from swarms)\r\n  Using cached pegasusX-0.3.9-py3-none-any.whl.metadata (1.1 kB)\r\nCollecting hnswlib==0.7.0 (from pegasusx->swarms)\r\n  Using cached hnswlib-0.7.0.tar.gz (33 kB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n  Preparing metadata (pyproject.toml) ... done\r\nCollecting pandas==1.3.5 (from pegasusx->swarms)\r\n  Using cached pandas-1.3.5.tar.gz (4.7 MB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n  Preparing metadata (pyproject.toml) ... done\r\nCollecting pydantic (from swarms)\r\n  Using cached pydantic-1.9.0-py3-none-any.whl (140 kB)\r\nCollecting requests<3,>=2 (from langchain==0.0.240->swarms)\r\n  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\r\nCollecting pegasusx (from swarms)\r\n  Using cached pegasusX-0.3.8-py3-none-any.whl.metadata (1.1 kB)\r\n  Using cached pegasusX-0.3.7-py3-none-any.whl.metadata (1.1 kB)\r\n  Using cached pegasusX-0.3.6-py3-none-any.whl.metadata (1.1 kB)\r\n  Using cached pegasusX-0.3.5-py3-none-any.whl.metadata (1.1 kB)\r\n  Using cached pegasusX-0.3.4-py3-none-any.whl.metadata (1.1 kB)\r\n  Using cached pegasusX-0.3.2-py3-none-any.whl.metadata (1.1 kB)\r\nINFO: pip is still looking at multiple versions of pegasusx to determine which version is compatible with other requirements. This could take a while.\r\n  Using cached pegasusX-0.3.1-py3-none-any.whl.metadata (1.1 kB)\r\n  Using cached pegasusX-0.3.0-py3-none-any.whl.metadata (1.1 kB)\r\n  Using cached pegasusX-0.2.9-py3-none-any.whl.metadata (1.1 kB)\r\n  Using cached pegasusX-0.2.7-py3-none-any.whl.metadata (1.1 kB)\r\n  Using cached pegasusX-0.2.5-py3-none-any.whl.metadata (626 bytes)\r\nCollecting numba (from pegasusx->swarms)\r\n  Using cached numba-0.58.1.tar.gz (2.6 MB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... error\r\n  error: subprocess-exited-with-error\r\n  \r\n  × Getting requirements to build wheel did not run successfully.\r\n  │ exit code: 1\r\n  ╰─> [21 lines of output]\r\n      Traceback (most recent call last):\r\n        File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 353, in <module>\r\n          main()\r\n        File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 335, in main\r\n          json_out['return_val'] = hook(**hook_input['kwargs'])\r\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 118, in get_requires_for_build_wheel\r\n          return hook(config_settings)\r\n                 ^^^^^^^^^^^^^^^^^^^^^\r\n        File \"/private/var/folders/4z/9tmf31f51jb44_hkvyqkht2m0000gn/T/pip-build-env-k2znnjli/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 325, in get_requires_for_build_wheel\r\n          return self._get_build_requires(config_settings, requirements=['wheel'])\r\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"/private/var/folders/4z/9tmf31f51jb44_hkvyqkht2m0000gn/T/pip-build-env-k2znnjli/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 295, in _get_build_requires\r\n          self.run_setup()\r\n        File \"/private/var/folders/4z/9tmf31f51jb44_hkvyqkht2m0000gn/T/pip-build-env-k2znnjli/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 480, in run_setup\r\n          super(_BuildMetaLegacyBackend, self).run_setup(setup_script=setup_script)\r\n        File \"/private/var/folders/4z/9tmf31f51jb44_hkvyqkht2m0000gn/T/pip-build-env-k2znnjli/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 311, in run_setup\r\n          exec(code, locals())\r\n        File \"<string>\", line 51, in <module>\r\n        File \"<string>\", line 48, in _guard_py_ver\r\n      RuntimeError: Cannot install on Python version 3.12.1; only versions >=3.8,<3.12 are supported.\r\n      [end of output]\r\n  \r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\nerror: subprocess-exited-with-error\r\n\r\n× Getting requirements to build wheel did not run successfully.\r\n│ exit code: 1\r\n╰─> See above for output.\r\n\r\nnote: This error originates from a subprocess, and is likely not a problem with pip.\r\n```",
      "state": "closed",
      "author": "donduq",
      "author_type": "User",
      "created_at": "2024-01-20T02:23:43Z",
      "updated_at": "2025-03-20T16:24:38Z",
      "closed_at": "2024-02-05T02:51:36Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/364/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/364",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/364",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:29.697305",
      "comments": [
        {
          "author": "vyomakesh09",
          "body": "I presume your installing  3.6.9\r\n\r\nCollecting swarms\r\n  Downloading swarms-3.6.9-py3-none-any.whl.metadata (37 kB) \r\n  \r\n  but the current latest version is 3.7.5, i'd suggest \r\n  \r\n  ~/ rm -rf swarms \r\n  ~/ pip3 install --upgrade swarms==3.7.5",
          "created_at": "2024-01-20T20:29:33Z"
        },
        {
          "author": "kyegomez",
          "body": "@donduq Problem was that it was trying to download every verison of the package which has errors, if you specify the verison it should work, lmk",
          "created_at": "2024-01-23T18:08:56Z"
        }
      ]
    },
    {
      "issue_number": 363,
      "title": "[BUG] ERROR: No matching distribution found for tensorflow==2.14.0",
      "body": "i'm trying to pip install swarms==3.6.6\r\n\r\nhere's my stack trace\r\n\r\n```\r\ndavidduque@Davids-MacBook-Pro powerhouse_ai % pip3 install swarms==3.6.6\r\nCollecting swarms==3.6.6\r\n  Using cached swarms-3.6.6-py3-none-any.whl.metadata (37 kB)\r\nCollecting Pillow==9.4.0 (from swarms==3.6.6)\r\n  Using cached Pillow-9.4.0.tar.gz (50.4 MB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n  Preparing metadata (pyproject.toml) ... done\r\nCollecting PyPDF2==3.0.1 (from swarms==3.6.6)\r\n  Using cached pypdf2-3.0.1-py3-none-any.whl (232 kB)\r\nCollecting accelerate (from swarms==3.6.6)\r\n  Using cached accelerate-0.26.1-py3-none-any.whl.metadata (18 kB)\r\nCollecting asyncio==3.4.3 (from swarms==3.6.6)\r\n  Using cached asyncio-3.4.3-py3-none-any.whl (101 kB)\r\nCollecting attrs==22.2.0 (from swarms==3.6.6)\r\n  Using cached attrs-22.2.0-py3-none-any.whl (60 kB)\r\nCollecting backoff==2.2.1 (from swarms==3.6.6)\r\n  Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\r\nCollecting beautifulsoup4==4.11.2 (from swarms==3.6.6)\r\n  Using cached beautifulsoup4-4.11.2-py3-none-any.whl (129 kB)\r\nCollecting bitsandbytes (from swarms==3.6.6)\r\n  Using cached bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\r\nCollecting black==23.3.0 (from swarms==3.6.6)\r\n  Using cached black-23.3.0-py3-none-any.whl (180 kB)\r\nCollecting chromadb==0.4.14 (from swarms==3.6.6)\r\n  Using cached chromadb-0.4.14-py3-none-any.whl.metadata (7.0 kB)\r\nCollecting cohere==4.24 (from swarms==3.6.6)\r\n  Using cached cohere-4.24-py3-none-any.whl.metadata (5.3 kB)\r\nCollecting datasets (from swarms==3.6.6)\r\n  Using cached datasets-2.16.1-py3-none-any.whl.metadata (20 kB)\r\nCollecting diffusers (from swarms==3.6.6)\r\n  Using cached diffusers-0.25.1-py3-none-any.whl.metadata (19 kB)\r\nCollecting einops==0.7.0 (from swarms==3.6.6)\r\n  Using cached einops-0.7.0-py3-none-any.whl.metadata (13 kB)\r\nCollecting faiss-cpu==1.7.4 (from swarms==3.6.6)\r\n  Using cached faiss-cpu-1.7.4.tar.gz (57 kB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n  Preparing metadata (pyproject.toml) ... done\r\nCollecting ggl==1.1.0 (from swarms==3.6.6)\r\n  Using cached ggl-1.1.0.tar.gz (1.3 kB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n  Preparing metadata (pyproject.toml) ... done\r\nCollecting google-generativeai==0.3.1 (from swarms==3.6.6)\r\n  Using cached google_generativeai-0.3.1-py3-none-any.whl.metadata (5.9 kB)\r\nCollecting httpx==0.24.1 (from swarms==3.6.6)\r\n  Using cached httpx-0.24.1-py3-none-any.whl.metadata (7.4 kB)\r\nCollecting huggingface-hub (from swarms==3.6.6)\r\n  Using cached huggingface_hub-0.20.2-py3-none-any.whl.metadata (12 kB)\r\nCollecting langchain==0.0.333 (from swarms==3.6.6)\r\n  Using cached langchain-0.0.333-py3-none-any.whl.metadata (16 kB)\r\nCollecting langchain-experimental==0.0.10 (from swarms==3.6.6)\r\n  Using cached langchain_experimental-0.0.10-py3-none-any.whl.metadata (718 bytes)\r\nCollecting marshmallow==3.19.0 (from swarms==3.6.6)\r\n  Using cached marshmallow-3.19.0-py3-none-any.whl (49 kB)\r\nCollecting open_clip_torch==2.20.0 (from swarms==3.6.6)\r\n  Using cached open_clip_torch-2.20.0-py3-none-any.whl.metadata (46 kB)\r\nCollecting openai==0.28.0 (from swarms==3.6.6)\r\n  Using cached openai-0.28.0-py3-none-any.whl.metadata (13 kB)\r\nCollecting opencv-python-headless==4.8.1.78 (from swarms==3.6.6)\r\n  Using cached opencv_python_headless-4.8.1.78-cp37-abi3-macosx_10_16_x86_64.whl.metadata (19 kB)\r\nCollecting optimum==1.15.0 (from swarms==3.6.6)\r\n  Using cached optimum-1.15.0-py3-none-any.whl.metadata (17 kB)\r\nCollecting peft (from swarms==3.6.6)\r\n  Using cached peft-0.7.1-py3-none-any.whl.metadata (25 kB)\r\nCollecting pgvector (from swarms==3.6.6)\r\n  Using cached pgvector-0.2.4-py2.py3-none-any.whl.metadata (9.8 kB)\r\nCollecting playwright==1.34.0 (from swarms==3.6.6)\r\n  Using cached playwright-1.34.0-py3-none-macosx_11_0_universal2.whl.metadata (3.6 kB)\r\nCollecting psutil (from swarms==3.6.6)\r\n  Using cached psutil-5.9.8-cp36-abi3-macosx_10_9_x86_64.whl.metadata (21 kB)\r\nCollecting pydantic==1.10.12 (from swarms==3.6.6)\r\n  Using cached pydantic-1.10.12-py3-none-any.whl.metadata (149 kB)\r\nCollecting qdrant-client (from swarms==3.6.6)\r\n  Using cached qdrant_client-1.7.1-py3-none-any.whl.metadata (9.3 kB)\r\nCollecting ratelimit==2.2.1 (from swarms==3.6.6)\r\n  Using cached ratelimit-2.2.1.tar.gz (5.3 kB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n  Preparing metadata (pyproject.toml) ... done\r\nCollecting rich==13.5.2 (from swarms==3.6.6)\r\n  Using cached rich-13.5.2-py3-none-any.whl.metadata (18 kB)\r\nCollecting safetensors==0.3.3 (from swarms==3.6.6)\r\n  Using cached safetensors-0.3.3.tar.gz (35 kB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n  Preparing metadata (pyproject.toml) ... done\r\nCollecting sentence-transformers (from swarms==3.6.6)\r\n  Using cached sentence-transformers-2.2.2.tar.gz (85 kB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n  Preparing metadata (pyproject.toml) ... done\r\nCollecting sentencepiece==0.1.98 (from swarms==3.6.6)\r\n  Using cached sentencepiece-0.1.98.tar.gz (2.6 MB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n  Preparing metadata (pyproject.toml) ... done\r\nCollecting soundfile==0.12.1 (from swarms==3.6.6)\r\n  Using cached soundfile-0.12.1-py2.py3-none-macosx_10_9_x86_64.whl (1.2 MB)\r\nCollecting sqlalchemy (from swarms==3.6.6)\r\n  Using cached SQLAlchemy-2.0.25-cp312-cp312-macosx_10_9_x86_64.whl.metadata (9.6 kB)\r\nCollecting tabulate==0.9.0 (from swarms==3.6.6)\r\n  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\r\nCollecting tenacity==8.2.2 (from swarms==3.6.6)\r\n  Using cached tenacity-8.2.2-py3-none-any.whl (24 kB)\r\nINFO: pip is looking at multiple versions of swarms to determine which version is compatible with other requirements. This could take a while.\r\nERROR: Ignored the following versions that require a different python version: 0.11.10 Requires-Python >=3.7,<=3.11; 1.0.0 Requires-Python >=3.7,<=3.11; 1.0.1 Requires-Python >=3.7,<=3.11; 1.0.2 Requires-Python >=3.7,<=3.11; 1.0.3 Requires-Python >=3.7,<3.12; 1.0.4 Requires-Python >=3.7,<3.12; 1.0.5 Requires-Python >=3.7,<3.12; 1.1.0 Requires-Python >=3.7,<3.12; 1.1.1 Requires-Python >=3.7,<3.12; 1.1.2 Requires-Python >=3.7,<3.12; 1.1.3 Requires-Python >=3.7,<3.12; 1.1.4 Requires-Python >=3.7,<3.12; 1.1.5 Requires-Python >=3.7,<3.12; 1.1.6 Requires-Python >=3.7,<3.12; 1.1.7 Requires-Python >=3.7,<3.12; 1.2.0 Requires-Python >=3.7,<3.12; 1.3.0 Requires-Python >=3.7,<3.12; 1.3.1 Requires-Python >=3.7,<3.12; 1.3.2 Requires-Python >=3.7,<3.12; 1.4.0 Requires-Python >=3.7,<3.12; 1.5.0 Requires-Python >=3.8,<3.12; 1.5.1 Requires-Python >=3.8,<3.12; 1.5.2 Requires-Python >=3.8,<3.12; 1.5.3 Requires-Python >=3.8,<3.12; 1.5.4 Requires-Python >=3.8,<3.12; 4.0.0 Requires-Python >=3.7,<3.11\r\nERROR: Could not find a version that satisfies the requirement tensorflow==2.14.0 (from swarms) (from versions: none)\r\nERROR: No matching distribution found for tensorflow==2.14.0\r\n```",
      "state": "closed",
      "author": "donduq",
      "author_type": "User",
      "created_at": "2024-01-20T02:07:47Z",
      "updated_at": "2025-03-20T16:24:38Z",
      "closed_at": "2024-02-05T02:51:17Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/363/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/363",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/363",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:29.958342",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-01-20T02:08:13Z"
        },
        {
          "author": "vyomakesh09",
          "body": "please use pip3 install --upgrade swarms \r\n\r\nthe current swarms version is 3.7.5\r\n\r\nif you're unsure of the latest version, check pyproject.toml for more info ",
          "created_at": "2024-01-20T20:25:08Z"
        }
      ]
    },
    {
      "issue_number": 361,
      "title": "[BUG] [TOOL AGENT] [HTTPError: 404 Client Error]",
      "body": "```\r\nconfig.json: 100%\r\n818/818 [00:00<00:00, 35.1kB/s]\r\n---------------------------------------------------------------------------\r\nHTTPError                                 Traceback (most recent call last)\r\n[/usr/local/lib/python3.10/dist-packages/modelscope/hub/errors.py](https://localhost:8080/#) in handle_http_response(response, logger, cookies, model_id)\r\n     90     try:\r\n---> 91         response.raise_for_status()\r\n     92     except HTTPError as error:\r\n\r\n7 frames\r\nHTTPError: 404 Client Error: Not Found for url: https://www.modelscope.cn/api/v1/models/databricks/dolly-v2-12b/revisions?EndTime=1705374100\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nHTTPError                                 Traceback (most recent call last)\r\n[/usr/local/lib/python3.10/dist-packages/modelscope/hub/errors.py](https://localhost:8080/#) in handle_http_response(response, logger, cookies, model_id)\r\n     96                 private. Please login first.')\r\n     97         message = _decode_response_error(response)\r\n---> 98         raise HTTPError('Response details: %s, Request id: %s' %\r\n     99                         (message, get_request_id(response))) from error\r\n    100 \r\n\r\nHTTPError: Response details: {'Code': 10010205001, 'Message': '获取模型版本失败，信息：record not found', 'RequestId': '147fe511-8b26-4a3a-b878-73a5c892e601', 'Success': False}, Request id: ff6a9bc12ba34a0cb997a9997351c754\r\n```",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2024-01-16T03:03:01Z",
      "updated_at": "2025-03-20T16:24:38Z",
      "closed_at": "2024-01-23T18:09:19Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/361/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/361",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/361",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:30.182264",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@vyomakesh09 try again I blocked modelscope for now, delete swarms and re-download it",
          "created_at": "2024-01-17T22:58:07Z"
        }
      ]
    },
    {
      "issue_number": 360,
      "title": "[BUG]  [RECURSIVE WORK FLOW EXAMPLE] ",
      "body": "```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n[<ipython-input-11-776bf6269c08>](https://localhost:8080/#) in <cell line: 21>()\r\n     19 \r\n     20 # Add tasks to the workflow\r\n---> 21 workflow.add(task1)\r\n     22 workflow.add(task2)\r\n     23 workflow.add(task3)\r\n\r\n1 frames\r\n[/usr/local/lib/python3.10/dist-packages/swarms/structs/recursive_workflow.py](https://localhost:8080/#) in add(self, task, tasks)\r\n     56                     )\r\n     57             else:\r\n---> 58                 self.task_pool.append(task)\r\n     59                 logger.info(\r\n     60                     f\"[INFO][RecursiveWorkflow] Added task {task} to\"\r\n\r\nTypeError: descriptor 'append' for 'list' objects doesn't apply to a 'Task' object\r\n```",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2024-01-16T02:35:07Z",
      "updated_at": "2025-03-20T16:24:38Z",
      "closed_at": "2024-01-16T06:09:30Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/360/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/360",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/360",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:30.356956",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@vyomakesh09 the error has been eliminated",
          "created_at": "2024-01-16T06:09:30Z"
        }
      ]
    },
    {
      "issue_number": 358,
      "title": "[RELE] MISMATCH VERSIONS ",
      "body": "pypi project has 3.5.3 but toml.py has 3.5.2 versions respectively",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2024-01-15T02:56:31Z",
      "updated_at": "2025-03-20T16:24:37Z",
      "closed_at": "2024-01-15T05:15:12Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/358/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/358",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/358",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:30.523632",
      "comments": []
    },
    {
      "issue_number": 357,
      "title": "[BUG] [TEST] tests/structs/test_model_parallizer.py can't find model on HF, modelscope?",
      "body": "```\r\n__________________ ERROR collecting swarms/tests/structs/test_model_parallizer.py __________________\r\n/usr/local/lib/python3.10/dist-packages/modelscope/hub/errors.py:91: in handle_http_response\r\n    response.raise_for_status()\r\n/usr/local/lib/python3.10/dist-packages/requests/models.py:1021: in raise_for_status\r\n    raise HTTPError(http_error_msg, response=self)\r\nE   requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://www.modelscope.cn/api/v1/models/NousResearch/Nous-Hermes-2-Vision-Alpha/revisions?EndTime=1705278485\r\n\r\nThe above exception was the direct cause of the following exception:\r\nswarms/tests/structs/test_model_parallizer.py:16: in <module>\r\n    huggingface_llm = HuggingfaceLLM(\r\n/usr/local/lib/python3.10/dist-packages/swarms/models/huggingface.py:176: in __init__\r\n    self.tokenizer = AutoTokenizer.from_pretrained(self.model_id)\r\n/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:787: in from_pretrained\r\n    return tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)\r\n/usr/local/lib/python3.10/dist-packages/modelscope/utils/hf_util.py:46: in from_pretrained\r\n    model_dir = snapshot_download(\r\n/usr/local/lib/python3.10/dist-packages/modelscope/hub/snapshot_download.py:96: in snapshot_download\r\n    revision = _api.get_valid_revision(\r\n/usr/local/lib/python3.10/dist-packages/modelscope/hub/api.py:478: in get_valid_revision\r\n    all_revisions = self.list_model_revisions(\r\n/usr/local/lib/python3.10/dist-packages/modelscope/hub/api.py:448: in list_model_revisions\r\n    handle_http_response(r, logger, cookies, model_id)\r\n/usr/local/lib/python3.10/dist-packages/modelscope/hub/errors.py:98: in handle_http_response\r\n    raise HTTPError('Response details: %s, Request id: %s' %\r\nE   requests.exceptions.HTTPError: Response details: {'Code': 10010205001, 'Message': '获取模型版本失败，信息：record not found', 'RequestId': '1db1af79-319b-48ec-b9a6-abb15cbdab2f', 'Success': False}, Request id: 5c3d39ade334434eb113014d50278ad9\r\n```\r\n\r\nI've veriified the model is there: \r\nhttps://huggingface.co/NousResearch/Nous-Hermes-2-Vision-Alpha\r\n\r\nIt may be an issue with modelscope:\r\nhttps://github.com/modelscope/modelscope",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2024-01-15T00:37:32Z",
      "updated_at": "2025-03-20T16:24:37Z",
      "closed_at": "2024-01-25T02:51:25Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/357/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/357",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/357",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:30.523652",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@evelynmitchell Please try again the modelscope was excommunicated",
          "created_at": "2024-01-17T22:58:29Z"
        },
        {
          "author": "evelynmitchell",
          "body": "Will do, Kye.",
          "created_at": "2024-01-17T23:00:13Z"
        },
        {
          "author": "evelynmitchell",
          "body": "This is looking better:\r\n```\r\n___________ ERROR collecting tests/structs/test_model_parallizer.py ____________\r\ntests/structs/test_model_parallizer.py:16: in <module>\r\n    huggingface_llm = HuggingfaceLLM(\r\n/usr/local/lib/python3.9/site-packages/swarms/models/huggingface.py:179: in __init__\r\n    sel",
          "created_at": "2024-01-18T02:37:16Z"
        },
        {
          "author": "evelynmitchell",
          "body": "Closing, I don't see this error anymore.",
          "created_at": "2024-01-25T02:51:25Z"
        }
      ]
    },
    {
      "issue_number": 356,
      "title": "Examples not working: ",
      "body": "Hello,\r\n\r\nI  have been trying this software with the examples given. So far,   only a few things works. \r\n\r\nAlthough  I  get the following mssage from the example below,   it did not the second line.         \r\n\r\nswarms is up to date!\r\n\r\n\r\nfrom swarms.workers import Worker\r\nfrom swarms.agents.meta_prompter import MetaPrompterAgent\r\nfrom swarms.models import OpenAI\r\n\r\n# init llm\r\nllm = OpenAI()\r\n\r\n# init the meta prompter agent that optimized prompts\r\nmeta_optimizer = MetaPrompterAgent(llm=llm)\r\n\r\n# init the worker agent\r\nworker = Worker(llm)\r\n\r\n# broad task to complete\r\ntask = \"Create a feedforward in pytorch\"\r\n\r\n# optimize the prompt\r\noptimized_prompt = meta_optimizer.run(task)\r\n\r\n# run the optimized prompt with detailed instructions\r\nresult = worker.run(optimized_prompt)\r\n\r\n# print\r\nprint(result)",
      "state": "closed",
      "author": "shersoni610",
      "author_type": "User",
      "created_at": "2024-01-14T14:58:58Z",
      "updated_at": "2025-03-20T16:24:37Z",
      "closed_at": "2024-01-16T02:41:29Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/356/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/356",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/356",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:30.758655",
      "comments": [
        {
          "author": "vyomakesh09",
          "body": "I'm sorry, but this example doesn't exits anymore ",
          "created_at": "2024-01-16T02:29:55Z"
        }
      ]
    },
    {
      "issue_number": 354,
      "title": "psutil problem",
      "body": "Hello,\r\n\r\nI created a virtualenv and installed psutil package and it worked fine.\r\nThereafter, I installed swarms using pip install swarms and using pip install -r requirements.\r\nBut doing so, created problem with psutil:Now I get the following error:\r\n\r\n\r\nModuleNotFoundError: No module named 'psutil'\r\n\r\nWhat could be the issue?",
      "state": "closed",
      "author": "shersoni610",
      "author_type": "User",
      "created_at": "2024-01-13T09:00:15Z",
      "updated_at": "2025-03-20T16:24:36Z",
      "closed_at": "2024-01-25T12:18:34Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/354/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/354",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/354",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:30.963001",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@shersoni610 please try again when you have a chance I believed I have fixed it!",
          "created_at": "2024-01-17T16:53:52Z"
        },
        {
          "author": "evelynmitchell",
          "body": "I see that psutil has been added to the package requirements. I believe this can be closed.",
          "created_at": "2024-01-25T02:53:03Z"
        }
      ]
    },
    {
      "issue_number": 353,
      "title": "RecursiveWorkflow example ",
      "body": "Hello,\r\nThe RecursiveWorkFlow  example on the  web  produces the following error:\r\n\r\n descriptor 'append' for 'list' objects doesn't apply to a 'Task' object\r\n\r\nI was hoping that simple example must work without any issues.",
      "state": "closed",
      "author": "shersoni610",
      "author_type": "User",
      "created_at": "2024-01-13T05:44:35Z",
      "updated_at": "2025-03-20T16:24:36Z",
      "closed_at": "2024-01-23T18:09:47Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/353/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/353",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/353",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:31.153133",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-01-13T05:45:01Z"
        },
        {
          "author": "kyegomez",
          "body": "@shersoni610 Please update your swarms package and try again I believe it may be fixed.",
          "created_at": "2024-01-16T06:10:06Z"
        }
      ]
    },
    {
      "issue_number": 350,
      "title": "[BUG] FileNotFoundError: [Errno 2] No such file or directory: 'runs/conversation.json'",
      "body": "User: v\r\n---------------------------------------------------------------------------\r\nFileNotFoundError                         Traceback (most recent call last)\r\n[<ipython-input-9-6e7b9c208a3d>](https://localhost:8080/#) in <cell line: 44>()\r\n     42 \r\n     43 # Replace with your LLM instance\r\n---> 44 interactive_conversation(llm)\r\n\r\n2 frames\r\n[/usr/local/lib/python3.10/dist-packages/swarms/structs/conversation.py](https://localhost:8080/#) in save_as_json(self, filename)\r\n    230         \"\"\"\r\n    231         # Save the conversation history as a JSON file\r\n--> 232         with open(filename, \"w\") as f:\r\n    233             json.dump(self.conversation_history, f)\r\n    234 \r\n\r\nFileNotFoundError: [Errno 2] No such file or directory: 'runs/conversation.json'",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2024-01-11T19:59:35Z",
      "updated_at": "2025-03-20T16:24:36Z",
      "closed_at": "2024-02-08T03:42:01Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/350/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/350",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/350",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:31.353110",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@vyomakesh09 please try again and lmk",
          "created_at": "2024-01-11T23:56:24Z"
        }
      ]
    },
    {
      "issue_number": 349,
      "title": "[BUG] TypeError: descriptor 'append' for 'list' objects doesn't apply to a 'Task' object",
      "body": "```\r\n[ERROR][ConcurrentWorkflow] descriptor 'append' for 'list' objects doesn't apply to a 'Task' object\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n[<ipython-input-7-3cd599b21a20>](https://localhost:8080/#) in <cell line: 23>()\r\n     21 \r\n     22 # Add tasks to the workflow\r\n---> 23 workflow.add(task1)\r\n     24 workflow.add(task2)\r\n     25 workflow.add(task3)\r\n\r\n1 frames\r\n[/usr/local/lib/python3.10/dist-packages/swarms/structs/recursive_workflow.py](https://localhost:8080/#) in add(self, task, tasks)\r\n     47                     self.tasks.append(task)\r\n     48             else:\r\n---> 49                 self.tasks.append(task)\r\n     50         except Exception as error:\r\n     51             print(f\"[ERROR][ConcurrentWorkflow] {error}\")\r\n\r\nTypeError: descriptor 'append' for 'list' objects doesn't apply to a 'Task' object\r\n```",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2024-01-11T19:56:59Z",
      "updated_at": "2025-03-20T16:24:36Z",
      "closed_at": "2024-01-11T23:55:58Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/349/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/349",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/349",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:31.525856",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@vyomakesh09 I have fixed this error by removing `tasks` from the add method",
          "created_at": "2024-01-11T22:18:26Z"
        }
      ]
    },
    {
      "issue_number": 345,
      "title": "[TEST] tests/structs/test_team error",
      "body": "Error in tests/structs/test_team, fix incoming (add pydantic BaseModel to structs/agent.py)\r\n\r\n```\r\nERROR collecting tests/structs/test_team.py ____________________________\r\ntests/structs/test_team.py:6: in <module>\r\n    from swarms.structs.team import Team\r\nswarms/structs/team.py:10: in <module>\r\n    class Team(BaseModel):\r\npydantic/main.py:197: in pydantic.main.ModelMetaclass.__new__\r\n    ???\r\npydantic/fields.py:506: in pydantic.fields.ModelField.infer\r\n    ???\r\npydantic/fields.py:436: in pydantic.fields.ModelField.__init__\r\n    ???\r\npydantic/fields.py:552: in pydantic.fields.ModelField.prepare\r\n    ???\r\npydantic/fields.py:661: in pydantic.fields.ModelField._type_analysis\r\n    ???\r\npydantic/fields.py:758: in pydantic.fields.ModelField._type_analysis\r\n    ???\r\npydantic/fields.py:808: in pydantic.fields.ModelField._create_sub_type\r\n    ???\r\npydantic/fields.py:436: in pydantic.fields.ModelField.__init__\r\n    ???\r\npydantic/fields.py:557: in pydantic.fields.ModelField.prepare\r\n    ???\r\npydantic/fields.py:831: in pydantic.fields.ModelField.populate_validators\r\n    ???\r\npydantic/validators.py:725: in find_validators\r\n    ???\r\npydantic/dataclasses.py:478: in make_dataclass_validator\r\n    ???\r\npydantic/dataclasses.py:231: in pydantic.dataclasses.dataclass\r\n    ???\r\npydantic/dataclasses.py:224: in pydantic.dataclasses.dataclass.wrap\r\n    ???\r\npydantic/dataclasses.py:347: in pydantic.dataclasses._add_pydantic_validation_attributes\r\n    ???\r\npydantic/dataclasses.py:400: in pydantic.dataclasses.create_pydantic_model_from_dataclass\r\n    ???\r\npydantic/main.py:1026: in pydantic.main.create_model\r\n    ???\r\npydantic/main.py:197: in pydantic.main.ModelMetaclass.__new__\r\n    ???\r\npydantic/fields.py:506: in pydantic.fields.ModelField.infer\r\n    ???\r\npydantic/fields.py:436: in pydantic.fields.ModelField.__init__\r\n    ???\r\npydantic/fields.py:552: in pydantic.fields.ModelField.prepare\r\n    ???\r\npydantic/fields.py:663: in pydantic.fields.ModelField._type_analysis\r\n    ???\r\npydantic/fields.py:808: in pydantic.fields.ModelField._create_sub_type\r\n    ???\r\npydantic/fields.py:436: in pydantic.fields.ModelField.__init__\r\n    ???\r\npydantic/fields.py:557: in pydantic.fields.ModelField.prepare\r\n    ???\r\npydantic/fields.py:831: in pydantic.fields.ModelField.populate_validators\r\n    ???\r\npydantic/validators.py:765: in find_validators\r\n    ???\r\nE   RuntimeError: no validator found for <class 'swarms.structs.agent.Agent'>, see `arbitrary_types_allowed` in Config\r\n```",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2024-01-10T01:42:06Z",
      "updated_at": "2025-03-20T16:24:36Z",
      "closed_at": "2024-03-19T12:44:21Z",
      "labels": [
        "bug",
        "no-issue-activity"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/345/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/345",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/345",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:31.694473",
      "comments": [
        {
          "author": "vyomakesh09",
          "body": "we getting the same, I presume it has to do with the version of pydantic at the source ",
          "created_at": "2024-01-11T19:15:03Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "Stale issue message",
          "created_at": "2024-03-12T12:44:12Z"
        }
      ]
    },
    {
      "issue_number": 342,
      "title": "[BUGF] [pydantic.v1] [test_team.py] ",
      "body": "```\r\npydantic-1.10.12 --> 2.5.3\r\n\r\ncould potentially change the version \r\n\r\n_________________________________ ERROR collecting tests/structs/test_team.py __________________________________\r\nImportError while importing test module '/home/v/vswarms/tests/structs/test_team.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/lib/python3.10/importlib/__init__.py:126: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntests/structs/test_team.py:6: in <module>\r\n    from swarms.structs.team import Team\r\n../.local/lib/python3.10/site-packages/swarms/structs/team.py:4: in <module>\r\n    from pydantic.v1 import BaseModel, Field, Json, root_validator\r\nE   ModuleNotFoundError: No module named 'pydantic.v1'\r\n```",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2024-01-05T21:19:20Z",
      "updated_at": "2025-03-20T16:24:36Z",
      "closed_at": "2024-01-05T23:43:04Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/342/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/342",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/342",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:31.926846",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@vyomakesh09 pull and try again please I removed it",
          "created_at": "2024-01-05T22:37:54Z"
        }
      ]
    },
    {
      "issue_number": 338,
      "title": "[CLEA] models/anthropic - check_package_version redefined and unused.",
      "body": "ruff noticed a re-defined unused method:\r\n\r\n```\r\nmodels/anthropic.py:135:5: F811 Redefinition of unused `check_package_version` from line 32\r\n```\r\nIt is both imported from langchain, and defined at line 135.\r\n\r\nOne or the other should be deleted.",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2024-01-01T17:15:27Z",
      "updated_at": "2025-03-20T16:24:36Z",
      "closed_at": "2024-01-25T21:33:21Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/338/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/338",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/338",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:32.090771",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "Similar problem for \r\n```\r\nmodels/anthropic.py:174:5: F811 Redefinition of unused `get_pydantic_field_names` from line 34\r\n```\r\nimported from langchain and defined at line 174\r\n",
          "created_at": "2024-01-01T17:16:48Z"
        },
        {
          "author": "kyegomez",
          "body": "@evelynmitchell just fixed by deleting them",
          "created_at": "2024-01-25T21:33:21Z"
        }
      ]
    },
    {
      "issue_number": 341,
      "title": "[BUG] Cannot install swarms",
      "body": "**Describe the bug**\r\nEither via colab notebook or locally pip3 install --upgarde swarms or pip install -r requirements.txt, there are multiple dependancy issues preventing use or swarms\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. run the Colab notebook OR\r\n2. pip3 install --upgrade swarms OR\r\n3. pip insatall  -r requirements.txt",
      "state": "closed",
      "author": "Hfoley36",
      "author_type": "User",
      "created_at": "2024-01-05T15:04:08Z",
      "updated_at": "2025-03-20T16:24:35Z",
      "closed_at": "2024-01-06T09:35:19Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/341/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/341",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/341",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:32.282693",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-01-05T15:04:34Z"
        },
        {
          "author": "kyegomez",
          "body": "@Hfoley36 Please attempt to re-download or upgrade your package and let me know if it is functional.\r\n\r\n`pip install -U swarms`\r\n",
          "created_at": "2024-01-06T01:44:46Z"
        },
        {
          "author": "Hfoley36",
          "body": "swarms now installing via pip install swarms in both colab notebook example and local .",
          "created_at": "2024-01-06T09:35:19Z"
        }
      ]
    },
    {
      "issue_number": 340,
      "title": "[BUG] ValueError: I/O operation on closed file",
      "body": "\r\n============================================================= 3 warnings, 1 error in 8.43s ==============================================================\r\nTraceback (most recent call last):\r\n  File \"/home/v/.local/lib/python3.10/site-packages/_pytest/main.py\", line 271, in wrap_session\r\n    session.exitstatus = doit(config, session) or 0\r\n  File \"/home/v/.local/lib/python3.10/site-packages/_pytest/main.py\", line 324, in _main\r\n    config.hook.pytest_collection(session=session)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/pluggy/_hooks.py\", line 493, in __call__\r\n    return self._hookexec(self.name, self._hookimpls, kwargs, firstresult)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/pluggy/_manager.py\", line 115, in _hookexec\r\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/pluggy/_callers.py\", line 152, in _multicall\r\n    return outcome.get_result()\r\n  File \"/home/v/.local/lib/python3.10/site-packages/pluggy/_result.py\", line 114, in get_result\r\n    raise exc.with_traceback(exc.__traceback__)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/pluggy/_callers.py\", line 77, in _multicall\r\n    res = hook_impl.function(*args)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/_pytest/main.py\", line 335, in pytest_collection\r\n    session.perform_collect()\r\n  File \"/home/v/.local/lib/python3.10/site-packages/_pytest/main.py\", line 675, in perform_collect\r\n    self.items.extend(self.genitems(node))\r\n  File \"/home/v/.local/lib/python3.10/site-packages/_pytest/main.py\", line 842, in genitems\r\n    rep = collect_one_node(node)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/_pytest/runner.py\", line 547, in collect_one_node\r\n    rep: CollectReport = ihook.pytest_make_collect_report(collector=collector)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/pluggy/_hooks.py\", line 493, in __call__\r\n    return self._hookexec(self.name, self._hookimpls, kwargs, firstresult)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/pluggy/_manager.py\", line 115, in _hookexec\r\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/pluggy/_callers.py\", line 130, in _multicall\r\n    teardown[0].send(outcome)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/_pytest/capture.py\", line 858, in pytest_make_collect_report\r\n    out, err = self.read_global_capture()\r\n  File \"/home/v/.local/lib/python3.10/site-packages/_pytest/capture.py\", line 780, in read_global_capture\r\n    return self._global_capturing.readouterr()\r\n  File \"/home/v/.local/lib/python3.10/site-packages/_pytest/capture.py\", line 685, in readouterr\r\n    err = self.err.snap() if self.err else \"\"\r\n  File \"/home/v/.local/lib/python3.10/site-packages/_pytest/capture.py\", line 567, in snap\r\n    self.tmpfile.seek(0)\r\nValueError: I/O operation on closed file.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/v/.local/lib/python3.10/site-packages/_pytest/main.py\", line 291, in wrap_session\r\n    config.notify_exception(excinfo, config.option)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/_pytest/config/__init__.py\", line 1108, in notify_exception\r\n    res = self.hook.pytest_internalerror(excrepr=excrepr, excinfo=excinfo)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/pluggy/_hooks.py\", line 493, in __call__\r\n    return self._hookexec(self.name, self._hookimpls, kwargs, firstresult)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/pluggy/_manager.py\", line 115, in _hookexec\r\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/pluggy/_callers.py\", line 113, in _multicall\r\n    raise exception.with_traceback(exception.__traceback__)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/pluggy/_callers.py\", line 77, in _multicall\r\n    res = hook_impl.function(*args)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/_pytest/capture.py\", line 888, in pytest_internalerror\r\n    self.stop_global_capturing()\r\n  File \"/home/v/.local/lib/python3.10/site-packages/_pytest/capture.py\", line 755, in stop_global_capturing\r\n    self._global_capturing.pop_outerr_to_orig()\r\n  File \"/home/v/.local/lib/python3.10/site-packages/_pytest/capture.py\", line 637, in pop_outerr_to_orig\r\n    out, err = self.readouterr()\r\n  File \"/home/v/.local/lib/python3.10/site-packages/_pytest/capture.py\", line 685, in readouterr\r\n    err = self.err.snap() if self.err else \"\"\r\n  File \"/home/v/.local/lib/python3.10/site-packages/_pytest/capture.py\", line 567, in snap\r\n    self.tmpfile.seek(0)\r\nValueError: I/O operation on closed file.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/v/.local/bin/pytest\", line 8, in <module>\r\n    sys.exit(console_main())\r\n  File \"/home/v/.local/lib/python3.10/site-packages/_pytest/config/__init__.py\", line 192, in console_main\r\n    code = main()\r\n  File \"/home/v/.local/lib/python3.10/site-packages/_pytest/config/__init__.py\", line 169, in main\r\n    ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(\r\n  File \"/home/v/.local/lib/python3.10/site-packages/pluggy/_hooks.py\", line 493, in __call__\r\n    return self._hookexec(self.name, self._hookimpls, kwargs, firstresult)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/pluggy/_manager.py\", line 115, in _hookexec\r\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/pluggy/_callers.py\", line 113, in _multicall\r\n    raise exception.with_traceback(exception.__traceback__)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/pluggy/_callers.py\", line 77, in _multicall\r\n    res = hook_impl.function(*args)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/_pytest/main.py\", line 318, in pytest_cmdline_main\r\n    return wrap_session(config, _main)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/_pytest/main.py\", line 313, in wrap_session\r\n    config._ensure_unconfigure()\r\n  File \"/home/v/.local/lib/python3.10/site-packages/_pytest/config/__init__.py\", line 1062, in _ensure_unconfigure\r\n    fin()\r\n  File \"/home/v/.local/lib/python3.10/site-packages/_pytest/capture.py\", line 755, in stop_global_capturing\r\n    self._global_capturing.pop_outerr_to_orig()\r\n  File \"/home/v/.local/lib/python3.10/site-packages/_pytest/capture.py\", line 637, in pop_outerr_to_orig\r\n    out, err = self.readouterr()\r\n  File \"/home/v/.local/lib/python3.10/site-packages/_pytest/capture.py\", line 685, in readouterr\r\n    err = self.err.snap() if self.err else \"\"\r\n  File \"/home/v/.local/lib/python3.10/site-packages/_pytest/capture.py\", line 567, in snap\r\n    self.tmpfile.seek(0)\r\nValueError: I/O operation on closed file.",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2024-01-02T01:48:59Z",
      "updated_at": "2025-03-20T16:24:35Z",
      "closed_at": "2024-01-04T17:26:08Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/340/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/340",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/340",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:32.537594",
      "comments": []
    },
    {
      "issue_number": 337,
      "title": "[TEST] several modules - ImportError: cannot import name 'BaseStruct' ",
      "body": "```\r\n___________________________ ERROR collecting test_zeroscope.py ____________________________\r\nImportError while importing test module '/usr/src/swarm_cloud/tests/models/test_zeroscope.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/local/lib/python3.9/importlib/__init__.py:127: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntest_zeroscope.py:5: in <module>\r\n    from swarms.models.zeroscope import ZeroscopeTTV\r\n/usr/local/lib/python3.9/site-packages/swarms/__init__.py:6: in <module>\r\n    from swarms.structs import *  # noqa: E402, F403\r\n/usr/local/lib/python3.9/site-packages/swarms/structs/__init__.py:4: in <module>\r\n    from swarms.structs.concurrent_workflow import ConcurrentWorkflow\r\n/usr/local/lib/python3.9/site-packages/swarms/structs/concurrent_workflow.py:5: in <module>\r\n    from swarms.structs.base import BaseStruct\r\nE   ImportError: cannot import name 'BaseStruct' from 'swarms.structs.base' (/usr/local/lib/python3.9/site-packages/swarms/structs/base.py)\r\n```",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2024-01-01T00:23:33Z",
      "updated_at": "2025-03-20T16:24:35Z",
      "closed_at": "2024-01-01T07:28:48Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/337/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/337",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/337",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:32.537617",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@evelynmitchell this bug has been eliminated",
          "created_at": "2024-01-01T07:28:48Z"
        }
      ]
    },
    {
      "issue_number": 335,
      "title": "[BUG] ImportError: cannot import name 'HF_HOME' from 'huggingface_hub.constants' (/home/v/.local/lib/python3.10/site-packages/huggingface_hub/constants.py)",
      "body": "_______________________ ERROR collecting tests/models/test_ssd_1b.py ________________________\r\nImportError while importing test module '/home/v/vswarms/tests/models/test_ssd_1b.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/lib/python3.10/importlib/__init__.py:126: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntests/models/test_ssd_1b.py:2: in <module>\r\n    from swarms.models.ssd_1b import SSD1B\r\nswarms/models/ssd_1b.py:10: in <module>\r\n    from diffusers import StableDiffusionXLPipeline\r\n../.local/lib/python3.10/site-packages/diffusers/__init__.py:5: in <module>\r\n    from .utils import (\r\n../.local/lib/python3.10/site-packages/diffusers/utils/__init__.py:21: in <module>\r\n    from .constants import (\r\n../.local/lib/python3.10/site-packages/diffusers/utils/constants.py:17: in <module>\r\n    from huggingface_hub.constants import HF_HOME\r\nE   ImportError: cannot import name 'HF_HOME' from 'huggingface_hub.constants' (/home/v/.local/lib/python3.10/site-packages/huggingface_hub/constants.py)",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-12-29T00:22:33Z",
      "updated_at": "2025-03-20T16:24:35Z",
      "closed_at": "2024-02-08T03:42:35Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/335/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/335",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/335",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:32.725100",
      "comments": [
        {
          "author": "ychacha",
          "body": "any updates on the this bug?",
          "created_at": "2024-01-08T16:08:33Z"
        },
        {
          "author": "vyomakesh09",
          "body": "update your pip",
          "created_at": "2024-01-08T17:10:06Z"
        }
      ]
    },
    {
      "issue_number": 333,
      "title": "[BUG] test/tools/test_base  - 3 tests to remove",
      "body": "test_tool_with_fixture(some_fixture)\r\ntest_structured_tool_with_fixture(some_fixture)\r\ntest_tool_async_invoke_with_fixture(some_fixture)\r\n\r\nThese three tests rely on some_fixture, which is never defined. This causes an error in the test running.\r\n\r\ntool.ainvoke looks to be exercised elsewhere.",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-12-24T21:47:57Z",
      "updated_at": "2025-03-20T16:24:35Z",
      "closed_at": "2023-12-25T23:19:07Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/333/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/333",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/333",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:32.906030",
      "comments": []
    },
    {
      "issue_number": 332,
      "title": "Adding more than one image to Gemini model",
      "body": "Since this is possible through the original Google APIs, it would be perfect to have the same thing through swarms.\r\n\r\nIn Gemini I simply do this:\r\n\r\nPROMPT_MESSAGE_GEMINI = [\r\n        text_prompt, pil_img_x, pil_img_y\r\n]\r\n\r\nresponse = model.generate_content(PROMPT_MESSAGE_GEMINI, stream=True)\r\nresponse.resolve()\r\n\r\nprint(response.text)",
      "state": "closed",
      "author": "robertobalestri",
      "author_type": "User",
      "created_at": "2023-12-24T16:15:13Z",
      "updated_at": "2025-03-20T16:24:35Z",
      "closed_at": "2024-03-12T12:44:14Z",
      "labels": [
        "no-issue-activity"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/332/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/332",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/332",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:32.906053",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2023-12-24T16:15:40Z"
        },
        {
          "author": "kyegomez",
          "body": "@robertobalestri Hey this is a good idea can you link the docs with this feature so we can add it",
          "created_at": "2023-12-24T19:27:56Z"
        },
        {
          "author": "robertobalestri",
          "body": "I didn't find documentation about sending more than one image, I just know that it works: you can pass more than one PIL image in the list of prompt parameters send in model.generate_content( list_of_prompt_paramaters )",
          "created_at": "2023-12-25T08:52:31Z"
        },
        {
          "author": "kyegomez",
          "body": "@robertobalestri \n\nI'll add the parameter to add a list of images to the google api",
          "created_at": "2024-01-03T18:11:24Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "Stale issue message",
          "created_at": "2024-03-04T12:47:41Z"
        }
      ]
    },
    {
      "issue_number": 331,
      "title": "[BUG] test_bioclip lacks the config file ",
      "body": "![image](https://github.com/kyegomez/swarms/assets/54256947/22f61464-c539-41cf-ae82-4201fd358ff7)",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-12-24T03:38:38Z",
      "updated_at": "2025-03-20T16:24:35Z",
      "closed_at": "2023-12-25T23:22:11Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/331/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/331",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/331",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:33.168991",
      "comments": []
    },
    {
      "issue_number": 330,
      "title": "[BUG] change modules to the latest version",
      "body": "```\r\nwe presume that latest versions of the modules would be prominent\r\n\r\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\nagent-protocol 1.0.1 requires pydantic<2.0.0,>=1.10.5, but you have pydantic 2.5.3 which is incompatible.\r\ndeepspeed 0.10.3 requires pydantic<2.0.0, but you have pydantic 2.5.3 which is incompatible.\r\nmarqo 2.0.0 requires pydantic<2.0.0, but you have pydantic 2.5.3 which is incompatible.\r\nooba 0.0.21 requires huggingface-hub<0.18.0,>=0.17.3, but you have huggingface-hub 0.20.1 which is incompatible.\r\nopen-interpreter 0.1.9 requires huggingface-hub<0.18.0,>=0.17.3, but you have huggingface-hub 0.20.1 which is incompatible.\r\nopenapi-python-client 0.13.4 requires pydantic<2.0.0,>=1.6.1, but you have pydantic 2.5.3 which is incompatible.\r\nopenapi-python-client 0.13.4 requires typer<0.8.0,>=0.6, but you have typer 0.9.0 which is incompatible.\r\nsky 0.0.201 requires tornado==4.5.3, but you have tornado 6.4 which is incompatible.\r\nswarms 2.9.9 requires huggingface-hub==0.16.4, but you have huggingface-hub 0.20.1 which is incompatible.\r\nswarms 2.9.9 requires pydantic==1.10.12, but you have pydantic 2.5.3 which is incompatible.\r\nswarms 2.9.9 requires sentencepiece==0.1.98, but you have sentencepiece 0.1.99 which is incompatible.\r\nswarms 2.9.9 requires termcolor==2.2.0, but you have termcolor 2.4.0 which is incompatible.\r\ntokenizers 0.14.1 requires huggingface_hub<0.18,>=0.16.4, but you have huggingface-hub 0.20.1 which is incompatible.\r\nvllm 0.2.3 requires pydantic==1.10.13, but you have pydantic 2.5.3 which is incompatible.\r\n\r\n\r\n\r\n```",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-12-24T03:22:09Z",
      "updated_at": "2025-03-20T16:24:35Z",
      "closed_at": "2023-12-24T15:57:01Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/330/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/330",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/330",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:33.169020",
      "comments": [
        {
          "author": "vyomakesh09",
          "body": "```\r\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\nooba 0.0.21 requires huggingface-hub<0.18.0,>=0.17.3, but you have huggingface-hub 0.16.4 which is incompatible.\r\nopen-",
          "created_at": "2023-12-24T03:24:24Z"
        },
        {
          "author": "kyegomez",
          "body": "this isnt a bug",
          "created_at": "2023-12-24T15:57:01Z"
        }
      ]
    },
    {
      "issue_number": 327,
      "title": "[BUG]   ValueError: We expect a numpy ndarray as input, got `<class 'torch.Tensor'>`",
      "body": "/home/v/swarms/tests/models/test_distill_whisper.py::test_transcribe_with_audio_dict failed: whisper_model = <swarms.models.distilled_whisperx.DistilWhisperModel object at 0x7f21873801c0>\r\naudio_dict = {}\r\n\r\n    def test_transcribe_with_audio_dict(whisper_model, audio_dict):\r\n>       transcription = whisper_model.transcribe(audio_dict)\r\n\r\ntests/models/test_distill_whisper.py:253: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\nswarms/models/distilled_whisperx.py:105: in transcribe\r\n    return pipe(inputs)[\"text\"]\r\n../.local/lib/python3.10/site-packages/transformers/pipelines/automatic_speech_recognition.py:357: in __call__\r\n    return super().__call__(inputs, **kwargs)\r\n../.local/lib/python3.10/site-packages/transformers/pipelines/base.py:1132: in __call__\r\n    return next(\r\n../.local/lib/python3.10/site-packages/transformers/pipelines/pt_utils.py:124: in __next__\r\n    item = next(self.iterator)\r\n../.local/lib/python3.10/site-packages/transformers/pipelines/pt_utils.py:266: in __next__\r\n    processed = self.infer(next(self.iterator), **self.params)\r\n../.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630: in __next__\r\n    data = self._next_data()\r\n../.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674: in _next_data\r\n    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\r\n../.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:32: in fetch\r\n    data.append(next(self.dataset_iter))\r\n../.local/lib/python3.10/site-packages/transformers/pipelines/pt_utils.py:183: in __next__\r\n    processed = next(self.subiterator)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nself = <transformers.pipelines.automatic_speech_recognition.AutomaticSpeechRecognitionPipeline object at 0x7f21875af640>\r\ninputs = tensor([[-1.1103,  0.8967, -1.4661,  ..., -1.2967, -0.6640,  0.1096]])\r\nchunk_length_s = 0, stride_length_s = None\r\n\r\n    def preprocess(self, inputs, chunk_length_s=0, stride_length_s=None):\r\n        if isinstance(inputs, str):\r\n            if inputs.startswith(\"http://\") or inputs.startswith(\"https://\"):\r\n                # We need to actually check for a real protocol, otherwise it's impossible to use a local file\r\n                # like http_huggingface_co.png\r\n                inputs = requests.get(inputs).content\r\n            else:\r\n                with open(inputs, \"rb\") as f:\r\n                    inputs = f.read()\r\n    \r\n        if isinstance(inputs, bytes):\r\n            inputs = ffmpeg_read(inputs, self.feature_extractor.sampling_rate)\r\n    \r\n        stride = None\r\n        extra = {}\r\n        if isinstance(inputs, dict):\r\n            stride = inputs.pop(\"stride\", None)\r\n            # Accepting `\"array\"` which is the key defined in `datasets` for\r\n            # better integration\r\n            if not (\"sampling_rate\" in inputs and (\"raw\" in inputs or \"array\" in inputs)):\r\n                raise ValueError(\r\n                    \"When passing a dictionary to AutomaticSpeechRecognitionPipeline, the dict needs to contain a \"\r\n                    '\"raw\" key containing the numpy array representing the audio and a \"sampling_rate\" key, '\r\n                    \"containing the sampling_rate associated with that array\"\r\n                )\r\n    \r\n            _inputs = inputs.pop(\"raw\", None)\r\n            if _inputs is None:\r\n                # Remove path which will not be used from `datasets`.\r\n                inputs.pop(\"path\", None)\r\n                _inputs = inputs.pop(\"array\", None)\r\n            in_sampling_rate = inputs.pop(\"sampling_rate\")\r\n            extra = inputs\r\n            inputs = _inputs\r\n            if in_sampling_rate != self.feature_extractor.sampling_rate:\r\n                if is_torchaudio_available():\r\n                    from torchaudio import functional as F\r\n                else:\r\n                    raise ImportError(\r\n                        \"torchaudio is required to resample audio samples in AutomaticSpeechRecognitionPipeline. \"\r\n                        \"The torchaudio package can be installed through: `pip install torchaudio`.\"\r\n                    )\r\n    \r\n                inputs = F.resample(\r\n                    torch.from_numpy(inputs), in_sampling_rate, self.feature_extractor.sampling_rate\r\n                ).numpy()\r\n                ratio = self.feature_extractor.sampling_rate / in_sampling_rate\r\n            else:\r\n                ratio = 1\r\n            if stride is not None:\r\n                if stride[0] + stride[1] > inputs.shape[0]:\r\n                    raise ValueError(\"Stride is too large for input\")\r\n    \r\n                # Stride needs to get the chunk length here, it's going to get\r\n                # swallowed by the `feature_extractor` later, and then batching\r\n                # can add extra data in the inputs, so we need to keep track\r\n                # of the original length in the stride so we can cut properly.\r\n                stride = (inputs.shape[0], int(round(stride[0] * ratio)), int(round(stride[1] * ratio)))\r\n        if not isinstance(inputs, np.ndarray):\r\n>           raise ValueError(f\"We expect a numpy ndarray as input, got `{type(inputs)}`\")\r\nE           ValueError: We expect a numpy ndarray as input, got `<class 'torch.Tensor'>`\r\n\r\n../.local/lib/python3.10/site-packages/transformers/pipelines/automatic_speech_recognition.py:482: ValueError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-12-20T20:10:46Z",
      "updated_at": "2025-03-20T16:24:34Z",
      "closed_at": "2023-12-25T23:22:32Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/327/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/327",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/327",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:33.379954",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "I think this  test can be deleted:\r\n```\r\ntest_transcribe_with_audio_dict\r\n# Test successful transcription with audio dict\r\ndef test_transcribe_with_audio_dict(whisper_model, audio_dict):\r\n    transcription = whisper_model.transcribe(audio_dict)\r\n    assert isinstance(transcription, str)\r\n```",
          "created_at": "2023-12-21T21:17:06Z"
        }
      ]
    },
    {
      "issue_number": 326,
      "title": "[BUG] WhisperProcessor' object has no attribute 'audio_file_to_array'\\n\", err='').out",
      "body": "/home/v/swarms/tests/models/test_distill_whisper.py::test_real_time_transcribe failed: distil_whisper_model = <swarms.models.distilled_whisperx.DistilWhisperModel object at 0x7f21ac75e6e0>\r\ncapsys = <_pytest.capture.CaptureFixture object at 0x7f2187381ea0>\r\n\r\n    def test_real_time_transcribe(distil_whisper_model, capsys):\r\n        test_data = np.random.rand(\r\n            16000 * 5\r\n        )  # Simulated audio data (5 seconds)\r\n        with tempfile.NamedTemporaryFile(\r\n            suffix=\".wav\", delete=False\r\n        ) as audio_file:\r\n            audio_file_path = create_audio_file(\r\n                test_data, 16000, audio_file.name\r\n            )\r\n    \r\n            distil_whisper_model.real_time_transcribe(\r\n                audio_file_path, chunk_duration=1\r\n            )\r\n    \r\n            os.remove(audio_file_path)\r\n    \r\n        captured = capsys.readouterr()\r\n>       assert \"Starting real-time transcription...\" in captured.out\r\nE       assert 'Starting real-time transcription...' in \"An error occurred during transcription: 'WhisperProcessor' object has no attribute 'audio_file_to_array'\\n\"\r\nE        +  where \"An error occurred during transcription: 'WhisperProcessor' object has no attribute 'audio_file_to_array'\\n\" = CaptureResult(out=\"An error occurred during transcription: 'WhisperProcessor' object has no attribute 'audio_file_to_array'\\n\", err='').out\r\n\r\ntests/models/test_distill_whisper.py:118: AssertionError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-12-20T20:10:09Z",
      "updated_at": "2025-03-20T16:24:34Z",
      "closed_at": "2023-12-25T23:22:50Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/326/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/326",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/326",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:33.597262",
      "comments": []
    },
    {
      "issue_number": 324,
      "title": "[BUG]   AttributeError: <module 'swarms.memory' from '/home/v/swarms/swarms/memory/__init__.py'> does not have the attribute 'Qdrant'",
      "body": "/home/v/swarms/tests/memory/test_qdrant.py::test_qdrant_init failed with error: Test failed with exception\r\n@pytest.fixture\r\n    def mock_qdrant_client():\r\n>       with patch(\"swarms.memory.Qdrant\") as MockQdrantClient:\r\ntests/memory/test_qdrant.py:9: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n/usr/lib/python3.10/unittest/mock.py:1447: in __enter__\r\n    original, local = self.get_original()\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\nself = <unittest.mock._patch object at 0x7f8cdc631d20>\r\n    def get_original(self):\r\n        target = self.getter()\r\n        name = self.attribute\r\n    \r\n        original = DEFAULT\r\n        local = False\r\n    \r\n        try:\r\n            original = target.__dict__[name]\r\n        except (AttributeError, KeyError):\r\n            original = getattr(target, name, DEFAULT)\r\n        else:\r\n            local = True\r\n    \r\n        if name in _builtins and isinstance(target, ModuleType):\r\n            self.create = True\r\n    \r\n        if not self.create and original is DEFAULT:\r\n>           raise AttributeError(\r\n                \"%s does not have the attribute %r\" % (target, name)\r\n            )\r\nE           AttributeError: <module 'swarms.memory' from '/home/v/swarms/swarms/memory/__init__.py'> does not have the attribute 'Qdrant'\r\n/usr/lib/python3.10/unittest/mock.py:1420: AttributeError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-12-20T15:08:43Z",
      "updated_at": "2025-03-20T16:24:34Z",
      "closed_at": "2024-03-26T12:44:39Z",
      "labels": [
        "bug",
        "no-issue-activity"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/324/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/324",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/324",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:33.597283",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "This error is still occurring.",
          "created_at": "2024-01-18T04:00:38Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "Stale issue message",
          "created_at": "2024-03-18T12:46:11Z"
        }
      ]
    },
    {
      "issue_number": 315,
      "title": "[BUG] test_autoscaler import error",
      "body": "Patch incoming\r\n```\r\nImportError while importing test module '/usr/src/swarm_cloud/tests/structs/test_autoscaler.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/local/lib/python3.9/importlib/__init__.py:127: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntest_autoscaler.py:4: in <module>\r\n    from pytest import patch\r\nE   ImportError: cannot import name 'patch' from 'pytest' (/usr/local/lib/python3.9/site-packages/pytest/__init__.py)\r\n```",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-12-16T23:03:43Z",
      "updated_at": "2025-03-20T16:24:34Z",
      "closed_at": "2023-12-18T23:03:46Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/315/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/315",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/315",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:33.826813",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "This can be closed ",
          "created_at": "2023-12-18T19:57:38Z"
        }
      ]
    },
    {
      "issue_number": 314,
      "title": "[BUG]   TypeError: Can't instantiate abstract class PineconDB with abstract methods delete, update",
      "body": "/home/v/swarms/tests/memory/test_pinecone.py::test_create_index failed: def test_create_index():\r\n        with patch(\"pinecone.init\"), patch(\"pinecone.Index\"), patch(\r\n            \"pinecone.create_index\"\r\n        ) as MockCreateIndex:\r\n>           store = PineconDB(\r\n                api_key=api_key,\r\n                index_name=\"test_index\",\r\n                environment=\"test_env\",\r\n            )\r\nE           TypeError: Can't instantiate abstract class PineconDB with abstract methods delete, update\r\n\r\ntests/memory/test_pinecone.py:75: TypeError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-12-16T21:29:01Z",
      "updated_at": "2025-03-20T16:24:34Z",
      "closed_at": "2024-01-04T00:53:37Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/314/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/314",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/314",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:33.999221",
      "comments": []
    },
    {
      "issue_number": 322,
      "title": "[BUG] add sqlalchemy, pgvector to requirements, pyproject",
      "body": "**Describe the bug**\r\nswarms/memory/pg.py contains a section of code at the top which checks for the presence of sqlalchemy and installs it if it is not there, followed by a segment which does the same for pgvector. This can be better handled by just importing sqlalchemy and pgvector as a requirement. \r\n\r\n```\r\ntry:\r\n    from sqlalchemy.engine import Engine\r\n    from sqlalchemy import create_engine, Column, String, JSON\r\n    from sqlalchemy.ext.declarative import declarative_base\r\n    from sqlalchemy.dialects.postgresql import UUID\r\n    from sqlalchemy.orm import Session\r\nexcept ImportError:\r\n    print(\r\n        \"The PgVectorVectorStore requires sqlalchemy to be installed\"\r\n    )\r\n    print(\"pip install sqlalchemy\")\r\n    subprocess.run([\"pip\", \"install\", \"sqlalchemy\"])\r\n\r\ntry:\r\n    from pgvector.sqlalchemy import Vector\r\nexcept ImportError:\r\n    print(\"The PgVectorVectorStore requires pgvector to be installed\")\r\n    print(\"pip install pgvector\")\r\n    subprocess.run([\"pip\", \"install\", \"pgvector\"])\r\n\r\n```",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-12-18T17:48:12Z",
      "updated_at": "2025-03-20T16:24:33Z",
      "closed_at": "2024-01-03T18:02:46Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/322/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/322",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/322",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:33.999240",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "I've created a pull request which updates requirements: https://github.com/kyegomez/swarms/pull/323",
          "created_at": "2023-12-19T00:17:09Z"
        }
      ]
    },
    {
      "issue_number": 313,
      "title": "[BUG]  AttributeError: <module 'swarms.memory' from '/home/v/swarms/swarms/memory/__init__.py'> does not have the attribute 'Qdrant'",
      "body": "/home/v/swarms/tests/memory/test_qdrant.py::test_search_vectors failed with error: Test failed with exception\r\n@pytest.fixture\r\n    def mock_qdrant_client():\r\n>       with patch(\"swarms.memory.Qdrant\") as MockQdrantClient:\r\ntests/memory/test_qdrant.py:9: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n/usr/lib/python3.10/unittest/mock.py:1447: in __enter__\r\n    original, local = self.get_original()\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\nself = <unittest.mock._patch object at 0x7f227607d3f0>\r\n    def get_original(self):\r\n        target = self.getter()\r\n        name = self.attribute\r\n    \r\n        original = DEFAULT\r\n        local = False\r\n    \r\n        try:\r\n            original = target.__dict__[name]\r\n        except (AttributeError, KeyError):\r\n            original = getattr(target, name, DEFAULT)\r\n        else:\r\n            local = True\r\n    \r\n        if name in _builtins and isinstance(target, ModuleType):\r\n            self.create = True\r\n    \r\n        if not self.create and original is DEFAULT:\r\n>           raise AttributeError(\r\n                \"%s does not have the attribute %r\" % (target, name)\r\n            )\r\nE           AttributeError: <module 'swarms.memory' from '/home/v/swarms/swarms/memory/__init__.py'> does not have the attribute 'Qdrant'\r\n/usr/lib/python3.10/unittest/mock.py:1420: AttributeError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-12-16T21:28:41Z",
      "updated_at": "2025-03-20T16:24:33Z",
      "closed_at": "2024-01-04T00:54:52Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/313/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/313",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/313",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:34.185788",
      "comments": []
    },
    {
      "issue_number": 312,
      "title": "[BUG]  RuntimeError: Model config for microsoft-BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 not found.",
      "body": "/home/v/swarms/tests/models/test_bioclip.py::test_clip_inference_performance failed with error: Test failed with exception\r\n@pytest.fixture\r\n    def clip_instance():\r\n>       return BioClip(\r\n            \"microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224\"\r\n        )\r\ntests/models/test_bioclip.py:17: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\nswarms/models/bioclip.py:98: in __init__\r\n    ) = open_clip.create_model_and_transforms(model_path)\r\n../.local/lib/python3.10/site-packages/open_clip/factory.py:324: in create_model_and_transforms\r\n    model = create_model(\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\nmodel_name = 'microsoft-BiomedCLIP-PubMedBERT_256-vit_base_patch16_224'\r\npretrained = None, precision = 'fp32', device = device(type='cpu'), jit = False\r\nforce_quick_gelu = False, force_custom_text = False, force_patch_dropout = None\r\nforce_image_size = None, pretrained_image = False, pretrained_hf = True\r\ncache_dir = None, output_dict = None, require_pretrained = False\r\nmodel_kwargs = {}, has_hf_hub_prefix = False, checkpoint_path = None\r\npretrained_cfg = {}\r\n    def create_model(\r\n            model_name: str,\r\n            pretrained: Optional[str] = None,\r\n            precision: str = 'fp32',\r\n            device: Union[str, torch.device] = 'cpu',\r\n            jit: bool = False,\r\n            force_quick_gelu: bool = False,\r\n            force_custom_text: bool = False,\r\n            force_patch_dropout: Optional[float] = None,\r\n            force_image_size: Optional[Union[int, Tuple[int, int]]] = None,\r\n            pretrained_image: bool = False,\r\n            pretrained_hf: bool = True,\r\n            cache_dir: Optional[str] = None,\r\n            output_dict: Optional[bool] = None,\r\n            require_pretrained: bool = False,\r\n            **model_kwargs,\r\n    ):\r\n        has_hf_hub_prefix = model_name.startswith(HF_HUB_PREFIX)\r\n        if has_hf_hub_prefix:\r\n            model_id = model_name[len(HF_HUB_PREFIX):]\r\n            checkpoint_path = download_pretrained_from_hf(model_id, cache_dir=cache_dir)\r\n            config_path = download_pretrained_from_hf(model_id, filename='open_clip_config.json', cache_dir=cache_dir)\r\n    \r\n            with open(config_path, 'r', encoding='utf-8') as f:\r\n                config = json.load(f)\r\n            pretrained_cfg = config['preprocess_cfg']\r\n            model_cfg = config['model_cfg']\r\n        else:\r\n            model_name = model_name.replace('/', '-')  # for callers using old naming with / in ViT names\r\n            checkpoint_path = None\r\n            pretrained_cfg = {}\r\n            model_cfg = None\r\n    \r\n        if isinstance(device, str):\r\n            device = torch.device(device)\r\n    \r\n        if pretrained and pretrained.lower() == 'openai':\r\n            logging.info(f'Loading pretrained {model_name} from OpenAI.')\r\n            model = load_openai_model(\r\n                model_name,\r\n                precision=precision,\r\n                device=device,\r\n                cache_dir=cache_dir,\r\n            )\r\n        else:\r\n            model_cfg = model_cfg or get_model_config(model_name)\r\n            if model_cfg is not None:\r\n                logging.info(f'Loaded {model_name} model config.')\r\n            else:\r\n                logging.error(f'Model config for {model_name} not found; available models {list_models()}.')\r\n>               raise RuntimeError(f'Model config for {model_name} not found.')\r\nE               RuntimeError: Model config for microsoft-BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 not found.\r\n../.local/lib/python3.10/site-packages/open_clip/factory.py:166: RuntimeError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-12-16T21:28:05Z",
      "updated_at": "2025-03-20T16:24:33Z",
      "closed_at": "2023-12-25T23:23:27Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/312/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/312",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/312",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:34.185804",
      "comments": []
    },
    {
      "issue_number": 310,
      "title": "[BUG] test_LLM import error",
      "body": "I have a PR for this.\r\n\r\n```\r\n_________________________ ERROR collecting test_LLM.py _________________________\r\nImportError while importing test module '/usr/src/swarm_cloud/tests/models/test_LLM.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/local/lib/python3.9/importlib/__init__.py:127: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntest_LLM.py:4: in <module>\r\n    from langchain import HuggingFaceHub, ChatOpenAI\r\nE   ImportError: cannot import name 'ChatOpenAI' from 'langchain' (/usr/local/lib/python3.9/site-packages/langchain/__init__.py)\r\n```",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-12-16T18:14:21Z",
      "updated_at": "2025-03-20T16:24:33Z",
      "closed_at": "2023-12-16T18:39:41Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/310/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/310",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/310",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:34.185809",
      "comments": []
    },
    {
      "issue_number": 309,
      "title": "[BUG] test_pg failure importing BaseVectorStore",
      "body": "test_pg imports swarms.memory.base, which doesn't exist, to use BaseVectorStore, which is referenced in pg and pinecone, but not defined.\r\n```\r\n_________________________ ERROR collecting test_pg.py __________________________\r\nImportError while importing test module '/usr/src/swarm_cloud/tests/memory/test_pg.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/local/lib/python3.9/importlib/__init__.py:127: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntest_pg.py:3: in <module>\r\n    from swarms.memory.pg import PgVectorVectorStore\r\n/usr/local/lib/python3.9/site-packages/swarms/memory/pg.py:6: in <module>\r\n    from swarms.memory.base import BaseVectorStore\r\nE   ModuleNotFoundError: No module named 'swarms.memory.base'\r\n```",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-12-16T17:42:40Z",
      "updated_at": "2025-03-20T16:24:33Z",
      "closed_at": "2024-01-18T03:57:33Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/309/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/309",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/309",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:34.185814",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "This test no longer exists, closing.",
          "created_at": "2024-01-18T03:57:55Z"
        }
      ]
    },
    {
      "issue_number": 308,
      "title": "[BUG] Dependency conflicts",
      "body": "In colab notebok:\r\n\r\n```\r\n!git clone https://github.com/kyegomez/swarms.git\r\n```\r\n```\r\n%cd swarms\r\n!pip install -r requirements.txt .\r\n```\r\nError is:\r\n```\r\n...\r\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.333->-r requirements.txt (line 4)) (2.31.0)\r\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.333->-r requirements.txt (line 4)) (8.2.3)\r\nCollecting greenlet==2.0.2 (from playwright==1.34.0->-r requirements.txt (line 7))\r\n  Downloading greenlet-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (613 kB)\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 613.7/613.7 kB 4.2 MB/s eta 0:00:00\r\nCollecting pyee==9.0.4 (from playwright==1.34.0->-r requirements.txt (line 7))\r\n  Downloading pyee-9.0.4-py2.py3-none-any.whl (14 kB)\r\nINFO: pip is looking at multiple versions of simpleaichat to determine which version is compatible with other requirements. This could take a while.\r\nERROR: Cannot install -r requirements.txt (line 4), -r requirements.txt (line 9) and pydantic==1.10.12 because these package versions have conflicting dependencies.\r\n\r\nThe conflict is caused by:\r\n    The user requested pydantic==1.10.12\r\n    langchain 0.0.333 depends on pydantic<3 and >=1\r\n    simpleaichat 0.2.2 depends on pydantic>=2.0\r\n\r\nTo fix this you could try to:\r\n1. loosen the range of package versions you've specified\r\n2. remove package versions to allow pip attempt to solve the dependency conflict\r\n\r\nERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\r\n\r\n```",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-12-15T00:10:06Z",
      "updated_at": "2025-03-20T16:24:33Z",
      "closed_at": "2023-12-15T04:09:34Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/308/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/308",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/308",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:34.434604",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@evelynmitchell this error has been eliminated ",
          "created_at": "2023-12-15T04:09:28Z"
        },
        {
          "author": "evelynmitchell",
          "body": "A different error popped up after this fix:\r\n```\r\n  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.1/12.1 MB 77.1 MB/s eta 0:00:00\r\nERROR: Cannot install -r requirements.txt (line 18), -r requirements.tx",
          "created_at": "2023-12-15T04:24:32Z"
        },
        {
          "author": "evelynmitchell",
          "body": "```\nCollecting tenacity<9.0.0,>=8.1.0 (from langchain==0.0.333->-r requirements.txt (line 4))\n  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\nINFO: pip is looking at multiple versions of swarms to determine which version is compatible with other requirements. This could take a while.\nERROR: Ca",
          "created_at": "2023-12-15T15:03:09Z"
        },
        {
          "author": "kyegomez",
          "body": "@evelynmitchell its been fixed now",
          "created_at": "2023-12-15T17:03:55Z"
        }
      ]
    },
    {
      "issue_number": 306,
      "title": "[BUG] ImportError: cannot import name 'Gemini' from 'swarms.models' ",
      "body": "Traceback (most recent call last):\r\n  File \"/home/v/inhouse/gemini.py\", line 1, in <module>\r\n    from swarms.models import Gemini\r\nImportError: cannot import name 'Gemini' from 'swarms.models' (/home/v/.local/lib/python3.10/site-packages/swarms/models/__init__.py)",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-12-14T22:05:47Z",
      "updated_at": "2025-03-20T16:24:33Z",
      "closed_at": "2023-12-15T04:10:16Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/306/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/306",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/306",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:34.625532",
      "comments": [
        {
          "author": "kyegomez",
          "body": "  @vyomakesh09  This error has been eliminated ",
          "created_at": "2023-12-15T04:10:11Z"
        }
      ]
    },
    {
      "issue_number": 305,
      "title": "[BUG] E               RuntimeError: Model config for microsoft-BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 not found.",
      "body": "/home/v/swarms/tests/models/test_bioclip.py::test_clip_initialization failed with error: Test failed with exception\r\n@pytest.fixture\r\n    def clip_instance():\r\n>       return BioClip(\r\n            \"microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224\"\r\n        )\r\ntests/models/test_bioclip.py:17: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\nswarms/models/bioclip.py:98: in __init__\r\n    ) = open_clip.create_model_and_transforms(model_path)\r\n../.local/lib/python3.10/site-packages/open_clip/factory.py:324: in create_model_and_transforms\r\n    model = create_model(\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\nmodel_name = 'microsoft-BiomedCLIP-PubMedBERT_256-vit_base_patch16_224'\r\npretrained = None, precision = 'fp32', device = device(type='cpu'), jit = False\r\nforce_quick_gelu = False, force_custom_text = False, force_patch_dropout = None\r\nforce_image_size = None, pretrained_image = False, pretrained_hf = True\r\ncache_dir = None, output_dict = None, require_pretrained = False\r\nmodel_kwargs = {}, has_hf_hub_prefix = False, checkpoint_path = None\r\npretrained_cfg = {}\r\n    def create_model(\r\n            model_name: str,\r\n            pretrained: Optional[str] = None,\r\n            precision: str = 'fp32',\r\n            device: Union[str, torch.device] = 'cpu',\r\n            jit: bool = False,\r\n            force_quick_gelu: bool = False,\r\n            force_custom_text: bool = False,\r\n            force_patch_dropout: Optional[float] = None,\r\n            force_image_size: Optional[Union[int, Tuple[int, int]]] = None,\r\n            pretrained_image: bool = False,\r\n            pretrained_hf: bool = True,\r\n            cache_dir: Optional[str] = None,\r\n            output_dict: Optional[bool] = None,\r\n            require_pretrained: bool = False,\r\n            **model_kwargs,\r\n    ):\r\n        has_hf_hub_prefix = model_name.startswith(HF_HUB_PREFIX)\r\n        if has_hf_hub_prefix:\r\n            model_id = model_name[len(HF_HUB_PREFIX):]\r\n            checkpoint_path = download_pretrained_from_hf(model_id, cache_dir=cache_dir)\r\n            config_path = download_pretrained_from_hf(model_id, filename='open_clip_config.json', cache_dir=cache_dir)\r\n    \r\n            with open(config_path, 'r', encoding='utf-8') as f:\r\n                config = json.load(f)\r\n            pretrained_cfg = config['preprocess_cfg']\r\n            model_cfg = config['model_cfg']\r\n        else:\r\n            model_name = model_name.replace('/', '-')  # for callers using old naming with / in ViT names\r\n            checkpoint_path = None\r\n            pretrained_cfg = {}\r\n            model_cfg = None\r\n    \r\n        if isinstance(device, str):\r\n            device = torch.device(device)\r\n    \r\n        if pretrained and pretrained.lower() == 'openai':\r\n            logging.info(f'Loading pretrained {model_name} from OpenAI.')\r\n            model = load_openai_model(\r\n                model_name,\r\n                precision=precision,\r\n                device=device,\r\n                cache_dir=cache_dir,\r\n            )\r\n        else:\r\n            model_cfg = model_cfg or get_model_config(model_name)\r\n            if model_cfg is not None:\r\n                logging.info(f'Loaded {model_name} model config.')\r\n            else:\r\n                logging.error(f'Model config for {model_name} not found; available models {list_models()}.')\r\n>               raise RuntimeError(f'Model config for {model_name} not found.')\r\nE               RuntimeError: Model config for microsoft-BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 not found.\r\n../.local/lib/python3.10/site-packages/open_clip/factory.py:166: RuntimeError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-12-14T16:38:51Z",
      "updated_at": "2025-03-20T16:24:32Z",
      "closed_at": "2023-12-19T00:39:14Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/305/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/305",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/305",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:34.833480",
      "comments": []
    },
    {
      "issue_number": 304,
      "title": "[BUG] E       AssertionError: assert 'An error occurred' in 'Error code: 301'",
      "body": "/home/v/swarms/tests/models/test_anthropic.py::test_anthropic_exception_handling failed: mock_anthropic_env = None\r\nmock_requests_post = <MagicMock name='post' id='139878164524976'>\r\nanthropic_instance = Anthropic(client=<anthropic.Anthropic object at 0x7f37ec4ed7e0>, async_client=<anthropic.AsyncAnthropic object at 0x7f...'\\n\\nAssistant:', count_tokens=<bound method Anthropic.count_tokens of <anthropic.Anthropic object at 0x7f37ec4ed7e0>>)\r\n\r\n    def test_anthropic_exception_handling(\r\n        mock_anthropic_env, mock_requests_post, anthropic_instance\r\n    ):\r\n        mock_response = Mock()\r\n        mock_response.json.return_value = {\"error\": \"An error occurred\"}\r\n        mock_requests_post.return_value = mock_response\r\n    \r\n        task = \"Generate text\"\r\n        stop = [\"stop1\", \"stop2\"]\r\n    \r\n        with pytest.raises(Exception) as excinfo:\r\n            anthropic_instance(task, stop)\r\n    \r\n>       assert \"An error occurred\" in str(excinfo.value)\r\nE       AssertionError: assert 'An error occurred' in 'Error code: 301'\r\nE        +  where 'Error code: 301' = str(APIStatusError('Error code: 301'))\r\nE        +    where APIStatusError('Error code: 301') = <ExceptionInfo APIStatusError('Error code: 301') tblen=12>.value\r\n\r\ntests/models/test_anthropic.py:147: AssertionErro",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-12-14T16:37:46Z",
      "updated_at": "2025-03-20T16:24:32Z",
      "closed_at": "2024-01-03T18:10:20Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/304/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/304",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/304",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:34.833519",
      "comments": []
    },
    {
      "issue_number": 303,
      "title": "[BUG] E       ModuleNotFoundError: No module named 'your_module'",
      "body": "/home/v/swarms/tests/memory/test_qdrant.py::test_qdrant_init failed with error: Test failed with exception\r\n@pytest.fixture\r\n    def mock_qdrant_client():\r\n>       with patch(\"your_module.QdrantClient\") as MockQdrantClient:\r\ntests/memory/test_qdrant.py:9: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n/usr/lib/python3.10/unittest/mock.py:1431: in __enter__\r\n    self.target = self.getter()\r\n/usr/lib/python3.10/unittest/mock.py:1618: in <lambda>\r\n    getter = lambda: _importer(target)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\ntarget = 'your_module'\r\n    def _importer(target):\r\n        components = target.split('.')\r\n        import_path = components.pop(0)\r\n>       thing = __import__(import_path)\r\nE       ModuleNotFoundError: No module named 'your_module'\r\n/usr/lib/python3.10/unittest/mock.py:1257: ModuleNotFoundError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-12-14T16:36:41Z",
      "updated_at": "2025-03-20T16:24:32Z",
      "closed_at": "2023-12-19T00:38:10Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/303/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/303",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/303",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:34.833526",
      "comments": []
    },
    {
      "issue_number": 302,
      "title": "[BUG] ruch",
      "body": "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/nate/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from rich==13.5.2) (2.17.2)\r\nRequirement already satisfied: mdurl~=0.1 in /Users/nate/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich==13.5.2) (0.1.2)\r\nUsing cached rich-13.5.2-py3-none-any.whl (239 kB)\r\nInstalling collected packages: rich\r\nSuccessfully installed rich-13.5.2\r\nnate@Nates-MacBook-Pro p-swarms % /usr/local/bin/pyt\r\nhon3 /Users/nate/Desktop/p-swarms/swarm_daddy.py\r\nTraceback (most recent call last):\r\n  File \"/Users/nate/Desktop/p-swarms/swarm_daddy.py\", line 3, in <module>\r\n    from swarms.models import OpenAIChat\r\n  File \"/Users/nate/Desktop/p-swarms/swarms/__init__.py\", line 1, in <module>\r\n    from swarms.utils.disable_logging import disable_logging\r\n  File \"/Users/nate/Desktop/p-swarms/swarms/utils/__init__.py\", line 2, in <module>\r\n    from swarms.utils.markdown_message import display_markdown_message\r\n  File \"/Users/nate/Desktop/p-swarms/swarms/utils/markdown_message.py\", line 1, in <module>\r\n    from rich import print as rich_print\r\nModuleNotFoundError: No module named 'rich'\r\nnate@Nates-MacBook-Pro p-swarms % /usr/local/bin/pyt\r\nhon3 /Users/nate/Desktop/p-swarms/example.py\r\nTraceback (most recent call last):\r\n  File \"/Users/nate/Desktop/p-swarms/example.py\", line 6, in <module>\r\n    from swarms.models import OpenAIChat\r\n  File \"/Users/nate/Desktop/p-swarms/swarms/__init__.py\", line 1, in <module>\r\n    from swarms.utils.disable_logging import disable_logging\r\n  File \"/Users/nate/Desktop/p-swarms/swarms/utils/__init__.py\", line 2, in <module>\r\n    from swarms.utils.markdown_message import display_markdown_message\r\n  File \"/Users/nate/Desktop/p-swarms/swarms/utils/markdown_message.py\", line 1, in <module>\r\n    from rich import print as rich_print\r\nModuleNotFoundError: No module named 'rich'\r\nnate@Nates-MacBook-Pro p-swarms %",
      "state": "closed",
      "author": "elder-plinius",
      "author_type": "User",
      "created_at": "2023-12-14T08:42:43Z",
      "updated_at": "2025-03-20T16:24:32Z",
      "closed_at": "2023-12-25T02:26:14Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/302/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/302",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/302",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:34.833531",
      "comments": []
    },
    {
      "issue_number": 301,
      "title": "[BUG] swarms 2.8.8 ",
      "body": "pip install swarms, much faster\r\n\r\n```\r\nDEBUG:jaxlib.mlir._mlir_libs:Initializing MLIR with module: _site_initialize_0\r\nDEBUG:jaxlib.mlir._mlir_libs:Registering dialects from initializer <module 'jaxlib.mlir._mlir_libs._site_initialize_0' from '/usr/local/lib/python3.10/dist-packages/jaxlib/mlir/_mlir_libs/_site_initialize_0.so'>\r\nDEBUG:jax._src.path:etils.epath found. Using etils.epath for file I/O.\r\n\r\n---------------------------------------------------------------------------\r\n\r\nImportError                               Traceback (most recent call last)\r\n\r\n[/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py](https://localhost:8080/#) in _get_module(self, module_name)\r\n   1344         try:\r\n-> 1345             return importlib.import_module(\".\" + module_name, self.__name__)\r\n   1346         except Exception as e:\r\n\r\n21 frames\r\n\r\nImportError: This version of TensorFlow Probability requires TensorFlow version >= 2.14; Detected an installation of version 2.12.0. Please upgrade TensorFlow to proceed.\r\n\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nRuntimeError                              Traceback (most recent call last)\r\n\r\n[/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py](https://localhost:8080/#) in _get_module(self, module_name)\r\n   1345             return importlib.import_module(\".\" + module_name, self.__name__)\r\n   1346         except Exception as e:\r\n-> 1347             raise RuntimeError(\r\n   1348                 f\"Failed to import {self.__name__}.{module_name} because of the following error (look up to see its\"\r\n   1349                 f\" traceback):\\n{e}\"\r\n\r\nRuntimeError: Failed to import transformers.pipelines because of the following error (look up to see its traceback):\r\nThis version of TensorFlow Probability requires TensorFlow version >= 2.14; Detected an installation of version 2.12.0. Please upgrade TensorFlow to proceed.\r\n```",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-12-14T00:27:12Z",
      "updated_at": "2025-03-20T16:24:32Z",
      "closed_at": "2023-12-14T02:01:08Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/301/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/301",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/301",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:34.833537",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@evelynmitchell i just fixed it update to the newest version ",
          "created_at": "2023-12-14T00:53:38Z"
        },
        {
          "author": "evelynmitchell",
          "body": "I tried this with 2.9.2 and the package requirements worked.\r\n\r\nThank you @kyegomez !",
          "created_at": "2023-12-14T01:17:02Z"
        }
      ]
    },
    {
      "issue_number": 300,
      "title": "[BUG] E   AttributeError: 'function' object has no attribute 'capture'",
      "body": "________________ ERROR collecting tests/memory/test_qdrant.py _________________\r\n../.local/lib/python3.10/site-packages/_pytest/runner.py:341: in from_call\r\n    result: Optional[TResult] = func()\r\n../.local/lib/python3.10/site-packages/_pytest/runner.py:372: in <lambda>\r\n    call = CallInfo.from_call(lambda: list(collector.collect()), \"collect\")\r\n../.local/lib/python3.10/site-packages/_pytest/python.py:531: in collect\r\n    self._inject_setup_module_fixture()\r\n../.local/lib/python3.10/site-packages/_pytest/python.py:545: in _inject_setup_module_fixture\r\n    self.obj, (\"setUpModule\", \"setup_module\")\r\n../.local/lib/python3.10/site-packages/_pytest/python.py:310: in obj\r\n    self._obj = obj = self._getobj()\r\n../.local/lib/python3.10/site-packages/_pytest/python.py:528: in _getobj\r\n    return self._importtestmodule()\r\n../.local/lib/python3.10/site-packages/_pytest/python.py:617: in _importtestmodule\r\n    mod = import_path(self.path, mode=importmode, root=self.config.rootpath)\r\n../.local/lib/python3.10/site-packages/_pytest/pathlib.py:567: in import_path\r\n    importlib.import_module(module_name)\r\n/usr/lib/python3.10/importlib/__init__.py:126: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n<frozen importlib._bootstrap>:1050: in _gcd_import\r\n    ???\r\n<frozen importlib._bootstrap>:1027: in _find_and_load\r\n    ???\r\n<frozen importlib._bootstrap>:1006: in _find_and_load_unlocked\r\n    ???\r\n<frozen importlib._bootstrap>:688: in _load_unlocked\r\n    ???\r\n../.local/lib/python3.10/site-packages/_pytest/assertion/rewrite.py:178: in exec_module\r\n    exec(co, module.__dict__)\r\ntests/memory/test_qdrant.py:4: in <module>\r\n    from swarms.memory.qdrant import Qdrant\r\nswarms/__init__.py:9: in <module>\r\n    from swarms.telemetry import *  # noqa: E402, F403\r\nswarms/telemetry/__init__.py:2: in <module>\r\n    from swarms.telemetry.posthog_utils import log_activity_posthog\r\nswarms/telemetry/posthog_utils.py:77: in <module>\r\n    out = my_function()\r\nswarms/telemetry/posthog_utils.py:58: in wrapper_log_activity\r\n    init_posthog.capture(\r\nE   AttributeError: 'function' object has no attribute 'capture'",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-12-13T22:15:31Z",
      "updated_at": "2025-03-20T16:24:32Z",
      "closed_at": "2024-01-03T18:03:23Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/300/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/300",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/300",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:35.079979",
      "comments": []
    },
    {
      "issue_number": 297,
      "title": "[BUG] ",
      "body": "zack@ClownPuter:~/code/swarms$ sudo python3 app.py\r\nwill register chemical-prop\r\nwill register douban-film\r\nwill register wikidata\r\nwill register stock\r\nwill register weather\r\nwill register wikipedia\r\nwill register wolframalpha\r\nwill register office-ppt\r\nwill register bing_search\r\nwill register bing_map\r\nwill register baidu_map\r\nwill register nllb-translation\r\nwill register baidu-translation\r\nwill register tutorial\r\nwill register file_operation\r\nwill register meta_analysis\r\nwill register database\r\nwill register db_diag\r\nwill register code_interpreter\r\nwill register hugging_tools\r\nwill register arxiv\r\nwill register zillow\r\nwill register google_scholar\r\nwill register google_places\r\nwill register google_serper\r\nwill register python\r\nwill register sceneXplain\r\nwill register shell\r\nwill register image_generation\r\nwill register airbnb\r\nwill register job_search\r\nwill register gradio_tools\r\nwill register walmart\r\nTraceback (most recent call last):\r\n  File \"/home/zack/code/swarms/app.py\", line 15, in <module>\r\n    from swarms.modelui.modules.block_requests import OpenMonkeyPat\r\n    from swarms.modelui.modules.block_requests import OpenMonkeyPatch, RequestBlocker\r\n  File \"/home/zack/code/swarms/swarms/__init__.py\", line 6, in <mod\r\n  File \"/home/zack/code/swarms/swarms/__init__.py\", line 6, in <module>\r\n    from swarms.swarms import *  # noqa: E402, F403\r\n  File \"/home/zack/code/swarms/swarms/swarms/__init__.py\", line 4, \r\n  File \"/home/zack/code/swarms/swarms/swarms/__init__.py\", line 4, in <module>\r\n    from swarms.swarms.base import AbstractSwarm\r\n  File \"/home/zack/code/swarms/swarms/swarms/base.py\", line 7, in <\r\n  File \"/home/zack/code/swarms/swarms/swarms/base.py\", line 7, in <module>\r\n    from swarms.agents.base import AbstractWorker\r\nImportError: cannot import name 'AbstractWorker' from 'swarms.agent\r\nImportError: cannot import name 'AbstractWorker' from 'swarms.agents.base' (/home/zack/code/swarms/swarms/agents/base.py)",
      "state": "closed",
      "author": "ZackBradshaw",
      "author_type": "User",
      "created_at": "2023-12-13T21:18:02Z",
      "updated_at": "2025-03-20T16:24:32Z",
      "closed_at": "2023-12-13T22:28:29Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/297/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/297",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/297",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:35.080001",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@ZackBradshaw try updating your package and return the new results, this code does not exist any more",
          "created_at": "2023-12-13T22:28:29Z"
        }
      ]
    },
    {
      "issue_number": 295,
      "title": "[BUG] ERROR: not found: /home/v/swarms/tests/models/test_gpt4_vision_api.py: | ERROR: not found: /home/v/swarms/tests/models/test_huggingface.py::test_llm_run",
      "body": "============================= test session starts ==============================\r\nplatform linux -- Python 3.10.12, pytest-7.4.2, pluggy-1.3.0\r\nrootdir: /home/v/swarms\r\nplugins: anyio-3.7.1\r\ncollected 673 items\r\n\r\n=============================== warnings summary ===============================\r\n../.local/lib/python3.10/site-packages/PyPDF2/__init__.py:21\r\n  /home/v/.local/lib/python3.10/site-packages/PyPDF2/__init__.py:21: DeprecationWarning: PyPDF2 is deprecated. Please move to the pypdf library instead.\r\n    warnings.warn(\r\n\r\n../.local/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:22\r\n  /home/v/.local/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:22: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\r\n    from distutils.dir_util import copy_tree\r\n\r\n../.local/lib/python3.10/site-packages/timm/models/layers/__init__.py:49\r\n  /home/v/.local/lib/python3.10/site-packages/timm/models/layers/__init__.py:49: DeprecationWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\r\n    warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", DeprecationWarning)\r\n\r\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\r\n============================= 3 warnings in 2.84s ==============================\r\nERROR: not found: /home/v/swarms/tests/models/test_gpt4_vision_api.py::test_run_successful_response\r\n(no name '/home/v/swarms/tests/models/test_gpt4_vision_api.py::test_run_successful_response' in any of [<Module tests/models/test_gpt4_vision_api.py>])\r\n\r\nERROR: not found: /home/v/swarms/tests/models/test_huggingface.py::test_llm_run\r\n(no name '/home/v/swarms/tests/models/test_huggingface.py::test_llm_run' in any of [<Module tests/models/test_huggingface.py>])\r\n\r\nFinished running tests!",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-12-12T19:28:03Z",
      "updated_at": "2025-03-20T16:24:32Z",
      "closed_at": "2024-01-03T18:10:51Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/295/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/295",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/295",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:35.280468",
      "comments": []
    },
    {
      "issue_number": 292,
      "title": "[BUG] sequential workflow only working for first loop with vision, then repeats \"I'm sorry, I can't provide that information\"",
      "body": "               Sequential Workflow Initializing...   \r\nInitializing Autonomous Agent Autonomous-Agent-XYZ1B...\r\nAutonomous Agent Activated.\r\nAll systems operational. Executing task...\r\n\r\nLoop 1 of 1\r\n\r\n\r\n\r\n\r\n<obs> The image appears to show an indoor setting, resembling a lobby or entrance area of a building. There \r\nare two individuals present. One person is holding a bag and has one arm extended in the direction of the other person, who seems to be backing away or reacting defensively. The scene suggests a confrontation or a potential security threat within the premises. The image includes a timestamp in the corner, indicating the time of the event. Due to the nature of the activities shown in the image, it is imperative to act with urgency and caution. </obs>\r\n\r\n<task> Based on the surveillance image, identify the actions to take for monitoring and ensuring safety. </task>\r\n\r\n<plan>\r\n1. Assess the situation quickly to understand the ongoing event.\r\n2. Alert security personnel immediately to attend to the location shown in the image.\r\n3. Lockdown the area remotely if possible to contain the threat.\r\n4. Use intercom or public address system to inform occupants of the building about the situation without causing panic.\r\n5. Contact law enforcement authorities to respond to the situation.\r\n6. Monitor all exits and entrances through the surveillance system to track movements.\r\n7. Initiate a building-wide security protocol that inc8. Prepare to provide law enforcement with additional \r\ninformation such as the number of individuals involved, descriptions, and live surveillance access if available.\r\n9. Preserve the footage for evidence purposes.        \r\n10. Conduct a follow-up investigation after the event \r\nto improve security measures and\r\nNone\r\nInitializing Autonomous Agent Autonomous-Agent-XYZ1B...\r\nAutonomous Agent Activated.\r\nAll systems operational. Executing task...\r\n\r\nLoop 1 of 1\r\n\r\n\r\n\r\n\r\nI'm sorry, I can't provide that information.\r\nNone\r\nInitializing Autonomous Agent Autonomous-Agent-XYZ1B...\r\nAutonomous Agent Activated.\r\nAll systems operational. Executing task...\r\n\r\nLoop 1 of 1\r\n\r\n\r\n\r\n\r\nI'm sorry, I can't assist with this request.\r\nNone\r\nInitializing Autonomous Agent Autonomous-Agent-XYZ1B...\r\nAutonomous Agent Activated.\r\nAll systems operational. Executing task...\r\n\r\nLoop 1 of 1\r\n\r\n\r\n\r\n\r\nI'm sorry, I cannot assist with this request.\r\nNone\r\nPS C:\\Users\\Guest1\\Desktop\\p-swarms> & C:/Users/Guest1/AppData/Local/Programs/Python/Python311/python.exe c:/Users/Guest1/Desktop/p-swarms/security_team.py       \r\n\r\n                Sequential Workflow Initializing...   \r\nInitializing Autonomous Agent Autonomous-Agent-XYZ1B...\r\nAutonomous Agent Activated.\r\nAll systems operational. Executing task...\r\n\r\nLoop 1 of 1\r\n\r\n\r\n\r\n\r\n<obs> The image depicts an interior space, specifically a lobby area, with two individuals in what appears to be a confrontational posture. The person on the left is carrying a bag and has one arm extended forward, seeming to be in the act of throwing or handing over the bag. The person on the right, with their back partially facing the camera, appears to be in a defensive or reactionary stance, with both arms raised. There are \r\nno other people visible in the image, suggesting the \"crowd dynamics\" are limited to the interaction between these two individuals. Additionally, elements of the \r\nenvironment include a desk area with a computer, a water dispenser, and organized shelves, giving the impression of an office or business lobby. The image has a timestamp indicating it is from December 2013 and includes the text \"Picture modified,\" implying alterations \r\nto the original content. </obs>\r\n\r\n<plan> Given the task to analyze crowd dynamics, but observing that the image effectively contains only two \r\nindividuals, the plan must be adapted:\r\n\r\n1. Define crowd dynamics as it pertains to the image, \r\nconsidering only the two individuals present.\r\n3. Determine the flow of movement, if any, suggested by their stances and the potential outcomes of the inte4. Consider the environmental context of the lobby and how it might influence the interaction.\r\n5. Compile this analysis into a coherent understandingNone\r\nInitializing Autonomous Agent Autonomous-Agent-XYZ1B...\r\nAutonomous Agent Activated.\r\nAll systems operational. Executing task...\r\n\r\nLoop 1 of 1\r\n\r\n\r\n\r\n\r\nI'm sorry, I can't assist with this request.\r\nNone\r\nInitializing Autonomous Agent Autonomous-Agent-XYZ1B...\r\nAutonomous Agent Activated.\r\nAll systems operational. Executing task...\r\n\r\nLoop 1 of 1\r\n\r\n\r\n\r\n\r\nI'm sorry, I cannot assist with this request.\r\nNone\r\nInitializing Autonomous Agent Autonomous-Agent-XYZ1B...\r\nAutonomous Agent Activated.\r\nAll systems operational. Executing task...\r\n\r\nLoop 1 of 1\r\n\r\n\r\n\r\n\r\nI'm sorry, I can't provide that information.\r\nNone",
      "state": "closed",
      "author": "elder-plinius",
      "author_type": "User",
      "created_at": "2023-12-12T02:29:49Z",
      "updated_at": "2025-03-20T16:24:32Z",
      "closed_at": "2024-01-03T18:06:29Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/292/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/292",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/292",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:35.280489",
      "comments": []
    },
    {
      "issue_number": 285,
      "title": "[BUG] phoenix install issue",
      "body": "  Using cached pypdf2-3.0.1-py3-none-any.whl (232 kB)\r\nCollecting accelerate (from swarms==2.7.2)\r\n  Using cached accelerate-0.25.0-py3-none-any.whl.metadata (18 kB)\r\nINFO: pip is looking at multiple versions of swarms to determine which version is compatible with other requirements. This could take a while.\r\nERROR: Ignored the following versions that require a different python version: 0.0.10 Requires-Python <3.11,>=3.8; 0.0.10rc0 Requires-Python <3.11,>=3.8; 0.0.10rc1 Requires-Python <3.11,>=3.8; 0.0.10rc2 Requires-Python <3.11,>=3.8; 0.0.11 Requires-Python <3.11,>=3.8; 0.0.11rc1 Requires-Python <3.11,>=3.8; 0.0.11rc2 Requires-Python <3.11,>=3.8; 0.0.11rc3 Requires-Python <3.11,>=3.8; 0.0.12 Requires-Python <3.11,>=3.8; 0.0.13 Requires-Python <3.11,>=3.8; 0.0.14 Requires-Python <3.11,>=3.8; 0.0.14rc0 Requires-Python <3.11,>=3.8; 0.0.14rc1 Requires-Python <3.11,>=3.8; 0.0.15 Requires-Python <3.11,>=3.8; 0.0.15rc0 Requires-Python <3.11,>=3.8; 0.0.16 Requires-Python <3.11,>=3.8; 0.0.17 Requires-Python <3.11,>=3.8; 0.0.18 Requires-Python <3.11,>=3.8; 0.0.18rc1 Requires-Python <3.11,>=3.8; 0.0.19 Requires-Python <3.11,>=3.8; 0.0.19rc1 Requires-Python <3.11,>=3.8; 0.0.19rc2 Requires-Python <3.11,>=3.8; 0.0.19rc3 Requires-Python <3.11,>=3.8; 0.0.1rc0 Requires-Python <3.11,>=3.8; 0.0.1rc1 Requires-Python <3.11,>=3.8; 0.0.20 Requires-Python <3.12,>=3.8; 0.0.20rc0 Requires-Python <3.12,>=3.8; 0.0.21 Requires-Python <3.12,>=3.8; 0.0.22 Requires-Python <3.12,>=3.8; 0.0.23 Requires-Python <3.12,>=3.8; 0.0.23rc0 Requires-Python <3.12,>=3.8; 0.0.23rc1 Requires-Python <3.12,>=3.8; 0.0.24 Requires-Python <3.12,>=3.8; 0.0.24rc0 Requires-Python <3.12,>=3.8; 0.0.24rc1 Requires-Python <3.12,>=3.8; 0.0.24rc2 Requires-Python <3.12,>=3.8; 0.0.25 Requires-Python <3.12,>=3.8; 0.0.26 Requires-Python <3.12,>=3.8; 0.0.27 Requires-Python <3.12,>=3.8; 0.0.28 Requires-Python <3.12,>=3.8; 0.0.29rc1 Requires-Python <3.12,>=3.8; 0.0.29rc2 Requires-Python <3.12,>=3.8; 0.0.29rc3 Requires-Python <3.12,>=3.8; 0.0.29rc4 Requires-Python <3.12,>=3.8; 0.0.29rc5 Requires-Python <3.12,>=3.8; 0.0.29rc6 Requires-Python <3.12,>=3.8; 0.0.29rc7 Requires-Python <3.12,>=3.8; 0.0.29rc8 Requires-Python <3.12,>=3.8; 0.0.2rc0 Requires-Python <3.11,>=3.8; 0.0.2rc1 Requires-Python <3.11,>=3.8; 0.0.2rc2 Requires-Python <3.11,>=3.8; 0.0.2rc3 Requires-Python <3.11,>=3.8; 0.0.2rc4 Requires-Python <3.11,>=3.8; 0.0.2rc5 Requires-Python <3.11,>=3.8; 0.0.2rc6 Requires-Python <3.11,>=3.8; 0.0.3 Requires-Python <3.11,>=3.8; 0.0.30 Requires-Python <3.12,>=3.8; 0.0.31 Requires-Python <3.12,>=3.8; 0.0.31rc1 Requires-Python <3.12,>=3.8; 0.0.31rc2 Requires-Python <3.12,>=3.8; 0.0.32 Requires-Python <3.12,>=3.8; 0.0.32rc1 Requires-Python <3.12,>=3.8; 0.0.33 Requires-Python <3.12,>=3.8; 0.0.33rc1 Requires-Python <3.12,>=3.8; 0.0.33rc2 Requires-Python <3.12,>=3.8; 0.0.33rc3 Requires-Python <3.12,>=3.8; 0.0.33rc4 Requires-Python <3.12,>=3.8; 0.0.33rc5 Requires-Python <3.12,>=3.8; 0.0.33rc6 Requires-Python <3.12,>=3.8; 0.0.33rc7 Requires-Python <3.12,>=3.8; 0.0.33rc8 Requires-Python <3.12,>=3.8; 0.0.33rc9 Requires-Python <3.12,>=3.8; 0.0.34 Requires-Python <3.12,>=3.8; 0.0.34rc0 Requires-Python <3.12,>=3.8; 0.0.35 Requires-Python <3.12,>=3.8; 0.0.36 Requires-Python <3.12,>=3.8; 0.0.37 Requires-Python <3.12,>=3.8; 0.0.38 Requires-Python <3.12,>=3.8; 0.0.39 Requires-Python <3.12,>=3.8; 0.0.4 Requires-Python <3.11,>=3.8; 0.0.40 Requires-Python <3.12,>=3.8; 0.0.41 Requires-Python <3.12,>=3.8; 0.0.42 Requires-Python <3.12,>=3.8; 0.0.43 Requires-Python <3.12,>=3.8; 0.0.44 Requires-Python <3.12,>=3.8; 0.0.44rc1 Requires-Python <3.12,>=3.8; 0.0.44rc2 Requires-Python <3.12,>=3.8; 0.0.44rc3 Requires-Python <3.12,>=3.8; 0.0.44rc4 Requires-Python <3.12,>=3.8; 0.0.44rc5 Requires-Python <3.12,>=3.8; 0.0.45 Requires-Python <3.12,>=3.8; 0.0.46 Requires-Python <3.12,>=3.8; 0.0.47 Requires-Python <3.12,>=3.8; 0.0.48 Requires-Python <3.12,>=3.8; 0.0.49 Requires-Python <3.12,>=3.8; 0.0.5 Requires-Python <3.11,>=3.8; 0.0.50 Requires-Python <3.12,>=3.8; 0.0.50rc0 Requires-Python <3.12,>=3.8; 0.0.50rc1 Requires-Python <3.12,>=3.8; 0.0.50rc2 Requires-Python <3.12,>=3.8; 0.0.51 Requires-Python <3.12,>=3.8; 0.0.6 Requires-Python <3.11,>=3.8; 0.0.7 Requires-Python <3.11,>=3.8; 0.0.8 Requires-Python <3.11,>=3.8; 0.0.9 Requires-Python <3.11,>=3.8; 0.1.0 Requires-Python <3.12,>=3.8; 0.1.1 Requires-Python <3.12,>=3.8; 1.0.0 Requires-Python <3.12,>=3.8; 1.1.0 Requires-Python <3.12,>=3.8; 1.1.1 Requires-Python <3.12,>=3.8; 1.1.2rc1 Requires-Python <3.12,>=3.8; 1.1.2rc2 Requires-Python <3.12,>=3.8; 1.1.2rc3 Requires-Python <3.12,>=3.8; 1.1.2rc4 Requires-Python <3.12,>=3.8; 1.1.2rc5 Requires-Python <3.12,>=3.8; 1.1.2rc6 Requires-Python <3.12,>=3.8; 1.1.2rc7 Requires-Python <3.12,>=3.8; 1.2.0 Requires-Python <3.12,>=3.8; 1.2.1 Requires-Python <3.12,>=3.8; 1.2.1rc1 Requires-Python <3.12,>=3.8; 1.2.1rc2 Requires-Python <3.12,>=3.8; 1.2.2rc1 Requires-Python <3.12,>=3.8; 1.2.2rc2 Requires-Python <3.12,>=3.8; 1.2.2rc3 Requires-Python <3.12,>=3.8; 1.2.2rc4 Requires-Python <3.12,>=3.8; 1.2.2rc5 Requires-Python <3.12,>=3.8; 1.2.2rc6 Requires-Python <3.12,>=3.8; 1.2.2rc7 Requires-Python <3.12,>=3.8; 1.2.2rc8 Requires-Python <3.12,>=3.8; 1.3.0 Requires-Python <3.12,>=3.8; 1.4.0 Requires-Python <3.12,>=3.8; 1.5.0 Requires-Python <3.12,>=3.8; 1.5.1 Requires-Python <3.12,>=3.8; 1.6.0 Requires-Python <3.12,>=3.8; 1.7.0 Requires-Python <3.12,>=3.8; 1.7.1 Requires-Python <3.12,>=3.8; 1.7.2rc1 Requires-Python <3.12,>=3.8; 1.7.2rc3 Requires-Python <3.12,>=3.8; 1.8.0 Requires-Python <3.12,>=3.8\r\nERROR: Could not find a version that satisfies the requirement arize-phoenix (from swarms) (from versions: none)\r\nERROR: No matching distribution found for arize-phoenix\r\nnate@Nates-MacBook-Pro ~ %",
      "state": "closed",
      "author": "elder-plinius",
      "author_type": "User",
      "created_at": "2023-12-10T07:03:22Z",
      "updated_at": "2025-03-20T16:24:32Z",
      "closed_at": "2023-12-10T19:22:58Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/285/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/285",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/285",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:35.280496",
      "comments": []
    },
    {
      "issue_number": 284,
      "title": "[BUG] requirements.txt issues",
      "body": "Collecting rich (from swarms==2.6.8)\r\n  Using cached rich-13.7.0-py3-none-any.whl.metadata (18 kB)\r\nCollecting safetensors (from swarms==2.6.8)\r\n  Using cached safetensors-0.4.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.8 kB)\r\nCollecting sentencepiece (from swarms==2.6.8)\r\n  Using cached sentencepiece-0.1.99.tar.gz (2.6 MB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n  Preparing metadata (pyproject.toml) ... done\r\nCollecting soundfile (from swarms==2.6.8)\r\n  Using cached soundfile-0.12.1-py2.py3-none-macosx_11_0_arm64.whl (1.1 MB)\r\nCollecting tabulate (from swarms==2.6.8)\r\n  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\r\nCollecting tenacity (from swarms==2.6.8)\r\n  Using cached tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\r\nINFO: pip is looking at multiple versions of swarms to determine which version is compatible with other requirements. This could take a while.\r\nERROR: Ignored the following versions that require a different python version: 4.0.0 Requires-Python >=3.7,<3.11\r\nERROR: Could not find a version that satisfies the requirement tensorflow (from swarms) (from versions: none)\r\nERROR: No matching distribution found for tensorflow\r\nnate@Nates-MacBook-Pro ~ %",
      "state": "closed",
      "author": "elder-plinius",
      "author_type": "User",
      "created_at": "2023-12-10T07:01:39Z",
      "updated_at": "2025-03-20T16:24:31Z",
      "closed_at": "2023-12-10T19:23:04Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/284/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/284",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/284",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:35.280503",
      "comments": []
    },
    {
      "issue_number": 283,
      "title": "[BUG] numba doesnt play nice with python 3.12",
      "body": "Collecting requests<3,>=2 (from langchain==0.0.240->swarms)\r\n  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\r\nCollecting typing-extensions>=4.2.0 (from pydantic->swarms)\r\n  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\r\nCollecting uvicorn==0.18.3 (from uvicorn[standard]==0.18.3->pegasusx->swarms)\r\n  Using cached uvicorn-0.18.3-py3-none-any.whl (57 kB)\r\nCollecting pegasusx (from swarms)\r\n  Using cached pegasusX-0.3.8-py3-none-any.whl.metadata (1.1 kB)\r\n  Using cached pegasusX-0.3.7-py3-none-any.whl.metadata (1.1 kB)\r\n  Using cached pegasusX-0.3.6-py3-none-any.whl.metadata (1.1 kB)\r\n  Using cached pegasusX-0.3.5-py3-none-any.whl.metadata (1.1 kB)\r\n  Using cached pegasusX-0.3.4-py3-none-any.whl.metadata (1.1 kB)\r\n  Using cached pegasusX-0.3.2-py3-none-any.whl.metadata (1.1 kB)\r\nINFO: pip is still looking at multiple versions of pegasusx to determine which version is compatible with other requirements. This could take a while.\r\n  Using cached pegasusX-0.3.1-py3-none-any.whl.metadata (1.1 kB)\r\n  Using cached pegasusX-0.3.0-py3-none-any.whl.metadata (1.1 kB)\r\n  Using cached pegasusX-0.2.9-py3-none-any.whl.metadata (1.1 kB)\r\n  Using cached pegasusX-0.2.7-py3-none-any.whl.metadata (1.1 kB)\r\n  Using cached pegasusX-0.2.5-py3-none-any.whl.metadata (626 bytes)\r\nCollecting numba (from pegasusx->swarms)\r\n  Using cached numba-0.58.1.tar.gz (2.6 MB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... error\r\n  error: subprocess-exited-with-error\r\n  \r\n  × Getting requirements to build wheel did not run successfully.\r\n  │ exit code: 1\r\n  ╰─> [21 lines of output]\r\n      Traceback (most recent call last):\r\n        File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 353, in <module>\r\n          main()\r\n        File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 335, in main\r\n          json_out['return_val'] = hook(**hook_input['kwargs'])\r\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 118, in get_requires_for_build_wheel\r\n          return hook(config_settings)\r\n                 ^^^^^^^^^^^^^^^^^^^^^\r\n        File \"/private/var/folders/fk/s283mdwd26z5zhm4gjlbbkk00000gn/T/pip-build-env-y_weiv9s/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 325, in get_requires_for_build_wheel\r\n          return self._get_build_requires(config_settings, requirements=['wheel'])\r\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"/private/var/folders/fk/s283mdwd26z5zhm4gjlbbkk00000gn/T/pip-build-env-y_weiv9s/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 295, in _get_build_requires\r\n          self.run_setup()\r\n        File \"/private/var/folders/fk/s283mdwd26z5zhm4gjlbbkk00000gn/T/pip-build-env-y_weiv9s/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 480, in run_setup\r\n          super(_BuildMetaLegacyBackend, self).run_setup(setup_script=setup_script)\r\n        File \"/private/var/folders/fk/s283mdwd26z5zhm4gjlbbkk00000gn/T/pip-build-env-y_weiv9s/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 311, in run_setup\r\n          exec(code, locals())\r\n        File \"<string>\", line 51, in <module>\r\n        File \"<string>\", line 48, in _guard_py_ver\r\n      RuntimeError: Cannot install on Python version 3.12.1; only versions >=3.8,<3.12 are supported.\r\n      [end of output]\r\n  \r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\nerror: subprocess-exited-with-error\r\n\r\n× Getting requirements to build wheel did not run successfully.\r\n│ exit code: 1\r\n╰─> See above for output.\r\n\r\nnote: This error originates from a subprocess, and is likely not a problem with pip.\r\nnate@Nates-MacBook-Pro ~ %",
      "state": "closed",
      "author": "elder-plinius",
      "author_type": "User",
      "created_at": "2023-12-10T06:53:22Z",
      "updated_at": "2025-03-20T16:24:31Z",
      "closed_at": "2023-12-10T21:26:52Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/283/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/283",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/283",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:35.280509",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@elder-plinius pegasus was removed",
          "created_at": "2023-12-10T21:26:52Z"
        }
      ]
    },
    {
      "issue_number": 281,
      "title": "[BUG] AssertionError: assert <MagicMock name='from_pretrained().decode()' id='140571253705504'> == 'mocked output'",
      "body": "/home/v/swarms/tests/models/test_huggingface.py::test_llm_run failed: mock_model = <MagicMock name='from_pretrained' id='140571806989760'>\r\nmock_tokenizer = <MagicMock name='from_pretrained' id='140571829573696'>\r\nllm_instance = <swarms.models.huggingface.HuggingfaceLLM object at 0x7fd96c9ef6a0>\r\n\r\n    @patch(\"swarms.models.huggingface.AutoTokenizer.from_pretrained\")\r\n    @patch(\r\n        \"swarms.models.huggingface.AutoModelForCausalLM.from_pretrained\"\r\n    )\r\n    def test_llm_run(mock_model, mock_tokenizer, llm_instance):\r\n        mock_model.return_value.generate.return_value = \"mocked output\"\r\n        mock_tokenizer.return_value.encode.return_value = \"mocked input\"\r\n        result = llm_instance.run(\"test task\")\r\n>       assert result == \"mocked output\"\r\nE       AssertionError: assert <MagicMock name='from_pretrained().decode()' id='140571253705504'> == 'mocked output'\r\n\r\ntests/models/test_huggingface.py:51: AssertionError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-12-08T23:20:49Z",
      "updated_at": "2025-03-20T16:24:31Z",
      "closed_at": "2023-12-10T21:27:58Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/281/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/281",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/281",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:35.537140",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@vyomakesh09 deleted the tests",
          "created_at": "2023-12-10T21:27:58Z"
        }
      ]
    },
    {
      "issue_number": 280,
      "title": "[BUG] TypeError: Can't instantiate abstract class HuggingfacePipeline with abstract methods generate_summary, run",
      "body": "/home/v/swarms/tests/models/test_hf_pipeline.py::test_init failed with error: Test failed with exception\r\nmock_pipeline = <MagicMock name='pipeline' id='140571817124112'>\r\n    @pytest.fixture\r\n    def pipeline(mock_pipeline):\r\n>       return HuggingfacePipeline(\r\n            \"text-generation\", \"meta-llama/Llama-2-13b-chat-hf\"\r\n        )\r\nE       TypeError: Can't instantiate abstract class HuggingfacePipeline with abstract methods generate_summary, run\r\ntests/models/test_hf_pipeline.py:17: TypeError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-12-08T23:20:12Z",
      "updated_at": "2025-03-20T16:24:31Z",
      "closed_at": "2023-12-10T19:38:27Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/280/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/280",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/280",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:35.745779",
      "comments": []
    },
    {
      "issue_number": 278,
      "title": "[BUG] AssertionError: assert None == 'Answer from GPT-4 Vision'",
      "body": "/home/v/swarms/tests/models/test_gpt4_vision_api.py::test_run_successful_response failed: gpt_api = <swarms.models.gpt4_vision_api.GPT4VisionAPI object at 0x7fd96d388f40>\r\n\r\n    def test_run_successful_response(gpt_api):\r\n        task = \"What is in the image?\"\r\n        img_url = img\r\n        response_json = {\r\n            \"choices\": [{\"text\": \"Answer from GPT-4 Vision\"}]\r\n        }\r\n        mock_response = Mock()\r\n        mock_response.json.return_value = response_json\r\n        with patch(\r\n            \"requests.post\", return_value=mock_response\r\n        ) as mock_post:\r\n            result = gpt_api.run(task, img_url)\r\n            mock_post.assert_called_once()\r\n>       assert result == response_json[\"choices\"][0][\"text\"]\r\nE       AssertionError: assert None == 'Answer from GPT-4 Vision'\r\n\r\ntests/models/test_gpt4_vision_api.py:108: AssertionError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-12-08T23:18:42Z",
      "updated_at": "2025-03-20T16:24:31Z",
      "closed_at": "2024-01-01T07:15:13Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/278/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/278",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/278",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:35.745798",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "This can be closed.",
          "created_at": "2024-01-01T00:33:04Z"
        }
      ]
    },
    {
      "issue_number": 279,
      "title": "[BUG]   assert [] == [\"This is the...'s response.\"]",
      "body": "/home/v/swarms/tests/models/test_gpt4_vision_api.py::test_run_many_success failed: vision_api = <swarms.models.gpt4_vision_api.GPT4VisionAPI object at 0x7fd96d39b610>\r\n\r\n    def test_run_many_success(vision_api):\r\n        expected_response = {\r\n            \"choices\": [\r\n                {\"message\": {\"content\": \"This is the model's response.\"}}\r\n            ]\r\n        }\r\n        with patch(\r\n            \"requests.post\",\r\n            return_value=Mock(json=lambda: expected_response),\r\n        ) as mock_post:\r\n            tasks = [\"What is this?\", \"What is that?\"]\r\n            imgs = [img, img]\r\n            results = vision_api.run_many(tasks, imgs)\r\n            assert mock_post.call_count == 2\r\n>           assert results == [\r\n                \"This is the model's response.\",\r\n                \"This is the model's response.\",\r\n            ]\r\nE           assert [] == [\"This is the...'s response.\"]\r\nE             Right contains 2 more items, first extra item: \"This is the model's response.\"\r\nE             Use -v to get more diff\r\n\r\ntests/models/test_gpt4_vision_api.py:191: AssertionError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-12-08T23:19:11Z",
      "updated_at": "2025-03-20T16:24:30Z",
      "closed_at": "2023-12-10T22:52:08Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/279/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/279",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/279",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:36.015396",
      "comments": []
    },
    {
      "issue_number": 277,
      "title": "[BUG]            Failed: DID NOT RAISE <class 'requests.exceptions.RequestException'>",
      "body": "/home/v/swarms/tests/models/test_gpt4_vision_api.py::test_run_request_error failed: vision_api = <swarms.models.gpt4_vision_api.GPT4VisionAPI object at 0x7fd96db40c40>\r\n\r\n    def test_run_request_error(vision_api):\r\n        with patch(\r\n            \"requests.post\", side_effect=RequestException(\"Request Error\")\r\n        ) as mock_post:\r\n>           with pytest.raises(RequestException):\r\nE           Failed: DID NOT RAISE <class 'requests.exceptions.RequestException'>\r\n\r\ntests/models/test_gpt4_vision_api.py:52: Failed",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-12-08T23:18:11Z",
      "updated_at": "2025-03-20T16:24:30Z",
      "closed_at": "2024-01-01T09:08:40Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/277/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/277",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/277",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:36.015418",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "This can be closed.",
          "created_at": "2024-01-01T00:32:46Z"
        }
      ]
    },
    {
      "issue_number": 276,
      "title": "[BUG] assert None == \"This is the model's response.\"",
      "body": "/home/v/swarms/tests/models/test_gpt4_vision_api.py::test_run_success failed: vision_api = <swarms.models.gpt4_vision_api.GPT4VisionAPI object at 0x7fd96c9477f0>\r\n\r\n    def test_run_success(vision_api):\r\n        expected_response = {\"This is the model's response.\"}\r\n        with patch(\r\n            \"requests.post\",\r\n            return_value=Mock(json=lambda: expected_response),\r\n        ) as mock_post:\r\n            result = vision_api.run(\"What is this?\", img)\r\n            mock_post.assert_called_once()\r\n>           assert result == \"This is the model's response.\"\r\nE           assert None == \"This is the model's response.\"\r\n\r\ntests/models/test_gpt4_vision_api.py:45: AssertionError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-12-08T23:17:49Z",
      "updated_at": "2025-03-20T16:24:30Z",
      "closed_at": "2024-01-03T18:05:49Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/276/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/276",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/276",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:36.227441",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "This can be closed.",
          "created_at": "2024-01-01T00:32:10Z"
        }
      ]
    },
    {
      "issue_number": 275,
      "title": "[BUG]  TypeError: BaseMultiModalModel.__init__() missing 1 required positional argument: 'model_name'",
      "body": "/home/v/swarms/tests/models/test_fuyu.py::test_invalid_image_path failed with error: Test failed with exception\r\n@pytest.fixture\r\n    def fuyu_instance():\r\n>       return Fuyu()\r\ntests/models/test_fuyu.py:35: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\nself = <swarms.models.fuyu.Fuyu object at 0x7fd96caadd80>\r\nmodel_name = 'adept/fuyu-8b', device_map = 'auto', max_new_tokens = 500\r\nargs = (), kwargs = {}\r\n    def __init__(\r\n        self,\r\n        model_name: str = \"adept/fuyu-8b\",\r\n        device_map: str = \"auto\",\r\n        max_new_tokens: int = 500,\r\n        *args,\r\n        **kwargs,\r\n    ):\r\n>       super().__init__(*args, **kwargs)\r\nE       TypeError: BaseMultiModalModel.__init__() missing 1 required positional argument: 'model_name'\r\nswarms/models/fuyu.py:42: TypeError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-12-08T23:09:48Z",
      "updated_at": "2025-03-20T16:24:30Z",
      "closed_at": "2023-12-10T19:50:28Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/275/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/275",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/275",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:36.430794",
      "comments": []
    },
    {
      "issue_number": 274,
      "title": "[BUG]   ValueError: We expect a numpy ndarray as input, got `<class 'torch.Tensor'>`",
      "body": "/home/v/swarms/tests/models/test_distill_whisper.py::test_transcribe_with_audio_dict failed: whisper_model = <swarms.models.distilled_whisperx.DistilWhisperModel object at 0x7fd96df7abf0>\r\naudio_dict = {}\r\n\r\n    def test_transcribe_with_audio_dict(whisper_model, audio_dict):\r\n>       transcription = whisper_model.transcribe(audio_dict)\r\n\r\ntests/models/test_distill_whisper.py:253: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\nswarms/models/distilled_whisperx.py:105: in transcribe\r\n    return pipe(inputs)[\"text\"]\r\n../.local/lib/python3.10/site-packages/transformers/pipelines/automatic_speech_recognition.py:357: in __call__\r\n    return super().__call__(inputs, **kwargs)\r\n../.local/lib/python3.10/site-packages/transformers/pipelines/base.py:1132: in __call__\r\n    return next(\r\n../.local/lib/python3.10/site-packages/transformers/pipelines/pt_utils.py:124: in __next__\r\n    item = next(self.iterator)\r\n../.local/lib/python3.10/site-packages/transformers/pipelines/pt_utils.py:266: in __next__\r\n    processed = self.infer(next(self.iterator), **self.params)\r\n../.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630: in __next__\r\n    data = self._next_data()\r\n../.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674: in _next_data\r\n    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\r\n../.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:32: in fetch\r\n    data.append(next(self.dataset_iter))\r\n../.local/lib/python3.10/site-packages/transformers/pipelines/pt_utils.py:183: in __next__\r\n    processed = next(self.subiterator)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nself = <transformers.pipelines.automatic_speech_recognition.AutomaticSpeechRecognitionPipeline object at 0x7fd93d72b700>\r\ninputs = tensor([[-1.1103,  0.8967, -1.4661,  ..., -1.2967, -0.6640,  0.1096]])\r\nchunk_length_s = 0, stride_length_s = None\r\n\r\n    def preprocess(self, inputs, chunk_length_s=0, stride_length_s=None):\r\n        if isinstance(inputs, str):\r\n            if inputs.startswith(\"http://\") or inputs.startswith(\"https://\"):\r\n                # We need to actually check for a real protocol, otherwise it's impossible to use a local file\r\n                # like http_huggingface_co.png\r\n                inputs = requests.get(inputs).content\r\n            else:\r\n                with open(inputs, \"rb\") as f:\r\n                    inputs = f.read()\r\n    \r\n        if isinstance(inputs, bytes):\r\n            inputs = ffmpeg_read(inputs, self.feature_extractor.sampling_rate)\r\n    \r\n        stride = None\r\n        extra = {}\r\n        if isinstance(inputs, dict):\r\n            stride = inputs.pop(\"stride\", None)\r\n            # Accepting `\"array\"` which is the key defined in `datasets` for\r\n            # better integration\r\n            if not (\"sampling_rate\" in inputs and (\"raw\" in inputs or \"array\" in inputs)):\r\n                raise ValueError(\r\n                    \"When passing a dictionary to AutomaticSpeechRecognitionPipeline, the dict needs to contain a \"\r\n                    '\"raw\" key containing the numpy array representing the audio and a \"sampling_rate\" key, '\r\n                    \"containing the sampling_rate associated with that array\"\r\n                )\r\n    \r\n            _inputs = inputs.pop(\"raw\", None)\r\n            if _inputs is None:\r\n                # Remove path which will not be used from `datasets`.\r\n                inputs.pop(\"path\", None)\r\n                _inputs = inputs.pop(\"array\", None)\r\n            in_sampling_rate = inputs.pop(\"sampling_rate\")\r\n            extra = inputs\r\n            inputs = _inputs\r\n            if in_sampling_rate != self.feature_extractor.sampling_rate:\r\n                if is_torchaudio_available():\r\n                    from torchaudio import functional as F\r\n                else:\r\n                    raise ImportError(\r\n                        \"torchaudio is required to resample audio samples in AutomaticSpeechRecognitionPipeline. \"\r\n                        \"The torchaudio package can be installed through: `pip install torchaudio`.\"\r\n                    )\r\n    \r\n                inputs = F.resample(\r\n                    torch.from_numpy(inputs), in_sampling_rate, self.feature_extractor.sampling_rate\r\n                ).numpy()\r\n                ratio = self.feature_extractor.sampling_rate / in_sampling_rate\r\n            else:\r\n                ratio = 1\r\n            if stride is not None:\r\n                if stride[0] + stride[1] > inputs.shape[0]:\r\n                    raise ValueError(\"Stride is too large for input\")\r\n    \r\n                # Stride needs to get the chunk length here, it's going to get\r\n                # swallowed by the `feature_extractor` later, and then batching\r\n                # can add extra data in the inputs, so we need to keep track\r\n                # of the original length in the stride so we can cut properly.\r\n                stride = (inputs.shape[0], int(round(stride[0] * ratio)), int(round(stride[1] * ratio)))\r\n        if not isinstance(inputs, np.ndarray):\r\n>           raise ValueError(f\"We expect a numpy ndarray as input, got `{type(inputs)}`\")\r\nE           ValueError: We expect a numpy ndarray as input, got `<class 'torch.Tensor'>`\r\n\r\n../.local/lib/python3.10/site-packages/transformers/pipelines/automatic_speech_recognition.py:482: ValueError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-12-08T23:09:01Z",
      "updated_at": "2025-03-20T16:24:30Z",
      "closed_at": "2024-01-03T18:05:59Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/274/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/274",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/274",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:36.430810",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "This can be closed.",
          "created_at": "2024-01-01T00:31:51Z"
        }
      ]
    },
    {
      "issue_number": 273,
      "title": "[BUG] RuntimeError: Model config for microsoft-BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 not found.",
      "body": "/home/v/swarms/tests/models/test_bioclip.py::test_clip_initialization failed with error: Test failed with exception\r\n@pytest.fixture\r\n    def clip_instance():\r\n>       return BioClip(\r\n            \"microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224\"\r\n        )\r\ntests/models/test_bioclip.py:17: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\nswarms/models/bioclip.py:98: in __init__\r\n    ) = open_clip.create_model_and_transforms(model_path)\r\n../.local/lib/python3.10/site-packages/open_clip/factory.py:324: in create_model_and_transforms\r\n    model = create_model(\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\nmodel_name = 'microsoft-BiomedCLIP-PubMedBERT_256-vit_base_patch16_224'\r\npretrained = None, precision = 'fp32', device = device(type='cpu'), jit = False\r\nforce_quick_gelu = False, force_custom_text = False, force_patch_dropout = None\r\nforce_image_size = None, pretrained_image = False, pretrained_hf = True\r\ncache_dir = None, output_dict = None, require_pretrained = False\r\nmodel_kwargs = {}, has_hf_hub_prefix = False, checkpoint_path = None\r\npretrained_cfg = {}\r\n    def create_model(\r\n            model_name: str,\r\n            pretrained: Optional[str] = None,\r\n            precision: str = 'fp32',\r\n            device: Union[str, torch.device] = 'cpu',\r\n            jit: bool = False,\r\n            force_quick_gelu: bool = False,\r\n            force_custom_text: bool = False,\r\n            force_patch_dropout: Optional[float] = None,\r\n            force_image_size: Optional[Union[int, Tuple[int, int]]] = None,\r\n            pretrained_image: bool = False,\r\n            pretrained_hf: bool = True,\r\n            cache_dir: Optional[str] = None,\r\n            output_dict: Optional[bool] = None,\r\n            require_pretrained: bool = False,\r\n            **model_kwargs,\r\n    ):\r\n        has_hf_hub_prefix = model_name.startswith(HF_HUB_PREFIX)\r\n        if has_hf_hub_prefix:\r\n            model_id = model_name[len(HF_HUB_PREFIX):]\r\n            checkpoint_path = download_pretrained_from_hf(model_id, cache_dir=cache_dir)\r\n            config_path = download_pretrained_from_hf(model_id, filename='open_clip_config.json', cache_dir=cache_dir)\r\n    \r\n            with open(config_path, 'r', encoding='utf-8') as f:\r\n                config = json.load(f)\r\n            pretrained_cfg = config['preprocess_cfg']\r\n            model_cfg = config['model_cfg']\r\n        else:\r\n            model_name = model_name.replace('/', '-')  # for callers using old naming with / in ViT names\r\n            checkpoint_path = None\r\n            pretrained_cfg = {}\r\n            model_cfg = None\r\n    \r\n        if isinstance(device, str):\r\n            device = torch.device(device)\r\n    \r\n        if pretrained and pretrained.lower() == 'openai':\r\n            logging.info(f'Loading pretrained {model_name} from OpenAI.')\r\n            model = load_openai_model(\r\n                model_name,\r\n                precision=precision,\r\n                device=device,\r\n                cache_dir=cache_dir,\r\n            )\r\n        else:\r\n            model_cfg = model_cfg or get_model_config(model_name)\r\n            if model_cfg is not None:\r\n                logging.info(f'Loaded {model_name} model config.')\r\n            else:\r\n                logging.error(f'Model config for {model_name} not found; available models {list_models()}.')\r\n>               raise RuntimeError(f'Model config for {model_name} not found.')\r\nE               RuntimeError: Model config for microsoft-BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 not found.\r\n../.local/lib/python3.10/site-packages/open_clip/factory.py:166: RuntimeError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-12-08T23:08:07Z",
      "updated_at": "2025-03-20T16:24:30Z",
      "closed_at": "2023-12-25T23:11:25Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/273/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/273",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/273",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:36.648997",
      "comments": []
    },
    {
      "issue_number": 272,
      "title": "[BUG] ../.local/lib/python3.10/site-packages/psycopg2/__init__.py:122: OperationalError",
      "body": "/home/v/swarms/tests/memory/test_pg.py::test_setup failed: self = Engine(postgresql://mockuser:***@localhost:5432/mockdb)\r\nfn = <bound method Pool.connect of <sqlalchemy.pool.impl.QueuePool object at 0x7f446c084c10>>\r\nconnection = None\r\n\r\n    def _wrap_pool_connect(self, fn, connection):\r\n        dialect = self.dialect\r\n        try:\r\n>           return fn()\r\n\r\n../.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:3371: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n../.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:327: in connect\r\n    return _ConnectionFairy._checkout(self)\r\n../.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:894: in _checkout\r\n    fairy = _ConnectionRecord.checkout(pool)\r\n../.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:493: in checkout\r\n    rec = pool._do_get()\r\n../.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py:145: in _do_get\r\n    with util.safe_reraise():\r\n../.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:70: in __exit__\r\n    compat.raise_(\r\n../.local/lib/python3.10/site-packages/sqlalchemy/util/compat.py:211: in raise_\r\n    raise exception\r\n../.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py:143: in _do_get\r\n    return self._create_connection()\r\n../.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:273: in _create_connection\r\n    return _ConnectionRecord(self)\r\n../.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:388: in __init__\r\n    self.__connect()\r\n../.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:690: in __connect\r\n    with util.safe_reraise():\r\n../.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:70: in __exit__\r\n    compat.raise_(\r\n../.local/lib/python3.10/site-packages/sqlalchemy/util/compat.py:211: in raise_\r\n    raise exception\r\n../.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:686: in __connect\r\n    self.dbapi_connection = connection = pool._invoke_creator(self)\r\n../.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py:574: in connect\r\n    return dialect.connect(*cargs, **cparams)\r\n../.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py:598: in connect\r\n    return self.dbapi.connect(*cargs, **cparams)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\ndsn = 'host=localhost user=mockuser password=mockpassword port=5432 dbname=mockdb'\r\nconnection_factory = None, cursor_factory = None\r\nkwargs = {'database': 'mockdb', 'host': 'localhost', 'password': 'mockpassword', 'port': 5432, ...}\r\nkwasync = {}\r\n\r\n    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):\r\n        \"\"\"\r\n        Create a new database connection.\r\n    \r\n        The connection parameters can be specified as a string:\r\n    \r\n            conn = psycopg2.connect(\"dbname=test user=postgres password=secret\")\r\n    \r\n        or using a set of keyword arguments:\r\n    \r\n            conn = psycopg2.connect(database=\"test\", user=\"postgres\", password=\"secret\")\r\n    \r\n        Or as a mix of both. The basic connection parameters are:\r\n    \r\n        - *dbname*: the database name\r\n        - *database*: the database name (only as keyword argument)\r\n        - *user*: user name used to authenticate\r\n        - *password*: password used to authenticate\r\n        - *host*: database host address (defaults to UNIX socket if not provided)\r\n        - *port*: connection port number (defaults to 5432 if not provided)\r\n    \r\n        Using the *connection_factory* parameter a different class or connections\r\n        factory can be specified. It should be a callable object taking a dsn\r\n        argument.\r\n    \r\n        Using the *cursor_factory* parameter, a new default cursor factory will be\r\n        used by cursor().\r\n    \r\n        Using *async*=True an asynchronous connection will be created. *async_* is\r\n        a valid alias (for Python versions where ``async`` is a keyword).\r\n    \r\n        Any other keyword parameter will be passed to the underlying client\r\n        library: the list of supported parameters depends on the library version.\r\n    \r\n        \"\"\"\r\n        kwasync = {}\r\n        if 'async' in kwargs:\r\n            kwasync['async'] = kwargs.pop('async')\r\n        if 'async_' in kwargs:\r\n            kwasync['async_'] = kwargs.pop('async_')\r\n    \r\n        dsn = _ext.make_dsn(dsn, **kwargs)\r\n>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)\r\nE       psycopg2.OperationalError: connection to server at \"localhost\" (127.0.0.1), port 5432 failed: Connection refused\r\nE       \tIs the server running on that host and accepting TCP/IP connections?\r\n\r\n../.local/lib/python3.10/site-packages/psycopg2/__init__.py:122: OperationalError\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\n    def test_setup():\r\n        with patch(\"sqlalchemy.create_engine\") as MockEngine:\r\n            store = PgVectorVectorStore(\r\n                embedding_driver=mock_embedding_driver,\r\n                connection_string=PSG_CONNECTION_STRING,\r\n                table_name=\"test\",\r\n            )\r\n>           store.setup()\r\n\r\ntests/memory/test_pg.py:42: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\nswarms/memory/pg.py:163: in setup\r\n    self.engine.execute(\r\n<string>:2: in execute\r\n    ???\r\n../.local/lib/python3.10/site-packages/sqlalchemy/util/deprecations.py:468: in warned\r\n    return fn(*args, **kwargs)\r\n../.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:3266: in execute\r\n    connection = self.connect(close_with_result=True)\r\n../.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:3325: in connect\r\n    return self._connection_cls(self, close_with_result=close_with_result)\r\n../.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:96: in __init__\r\n    else engine.raw_connection()\r\n../.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:3404: in raw_connection\r\n    return self._wrap_pool_connect(self.pool.connect, _connection)\r\n../.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:3374: in _wrap_pool_connect\r\n    Connection._handle_dbapi_exception_noconnection(\r\n../.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2208: in _handle_dbapi_exception_noconnection\r\n    util.raise_(\r\n../.local/lib/python3.10/site-packages/sqlalchemy/util/compat.py:211: in raise_\r\n    raise exception\r\n../.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:3371: in _wrap_pool_connect\r\n    return fn()\r\n../.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:327: in connect\r\n    return _ConnectionFairy._checkout(self)\r\n../.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:894: in _checkout\r\n    fairy = _ConnectionRecord.checkout(pool)\r\n../.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:493: in checkout\r\n    rec = pool._do_get()\r\n../.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py:145: in _do_get\r\n    with util.safe_reraise():\r\n../.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:70: in __exit__\r\n    compat.raise_(\r\n../.local/lib/python3.10/site-packages/sqlalchemy/util/compat.py:211: in raise_\r\n    raise exception\r\n../.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py:143: in _do_get\r\n    return self._create_connection()\r\n../.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:273: in _create_connection\r\n    return _ConnectionRecord(self)\r\n../.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:388: in __init__\r\n    self.__connect()\r\n../.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:690: in __connect\r\n    with util.safe_reraise():\r\n../.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:70: in __exit__\r\n    compat.raise_(\r\n../.local/lib/python3.10/site-packages/sqlalchemy/util/compat.py:211: in raise_\r\n    raise exception\r\n../.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:686: in __connect\r\n    self.dbapi_connection = connection = pool._invoke_creator(self)\r\n../.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py:574: in connect\r\n    return dialect.connect(*cargs, **cparams)\r\n../.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py:598: in connect\r\n    return self.dbapi.connect(*cargs, **cparams)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\ndsn = 'host=localhost user=mockuser password=mockpassword port=5432 dbname=mockdb'\r\nconnection_factory = None, cursor_factory = None\r\nkwargs = {'database': 'mockdb', 'host': 'localhost', 'password': 'mockpassword', 'port': 5432, ...}\r\nkwasync = {}\r\n\r\n    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):\r\n        \"\"\"\r\n        Create a new database connection.\r\n    \r\n        The connection parameters can be specified as a string:\r\n    \r\n            conn = psycopg2.connect(\"dbname=test user=postgres password=secret\")\r\n    \r\n        or using a set of keyword arguments:\r\n    \r\n            conn = psycopg2.connect(database=\"test\", user=\"postgres\", password=\"secret\")\r\n    \r\n        Or as a mix of both. The basic connection parameters are:\r\n    \r\n        - *dbname*: the database name\r\n        - *database*: the database name (only as keyword argument)\r\n        - *user*: user name used to authenticate\r\n        - *password*: password used to authenticate\r\n        - *host*: database host address (defaults to UNIX socket if not provided)\r\n        - *port*: connection port number (defaults to 5432 if not provided)\r\n    \r\n        Using the *connection_factory* parameter a different class or connections\r\n        factory can be specified. It should be a callable object taking a dsn\r\n        argument.\r\n    \r\n        Using the *cursor_factory* parameter, a new default cursor factory will be\r\n        used by cursor().\r\n    \r\n        Using *async*=True an asynchronous connection will be created. *async_* is\r\n        a valid alias (for Python versions where ``async`` is a keyword).\r\n    \r\n        Any other keyword parameter will be passed to the underlying client\r\n        library: the list of supported parameters depends on the library version.\r\n    \r\n        \"\"\"\r\n        kwasync = {}\r\n        if 'async' in kwargs:\r\n            kwasync['async'] = kwargs.pop('async')\r\n        if 'async_' in kwargs:\r\n            kwasync['async_'] = kwargs.pop('async_')\r\n    \r\n        dsn = _ext.make_dsn(dsn, **kwargs)\r\n>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)\r\nE       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at \"localhost\" (127.0.0.1), port 5432 failed: Connection refused\r\nE       \tIs the server running on that host and accepting TCP/IP connections?\r\nE       \r\nE       (Background on this error at: https://sqlalche.me/e/14/e3q8)\r\n\r\n../.local/lib/python3.10/site-packages/psycopg2/__init__.py:122: OperationalError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-12-08T22:50:08Z",
      "updated_at": "2025-03-20T16:24:30Z",
      "closed_at": "2024-01-03T18:03:53Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/272/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/272",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/272",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:36.649045",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "This can be closed.",
          "created_at": "2024-01-01T00:31:24Z"
        }
      ]
    },
    {
      "issue_number": 271,
      "title": "[BUG] AssertionError: Expected 'create_engine' to have been called once. Called 0 times.",
      "body": "/home/v/swarms/tests/memory/test_pg.py::test_init failed: def test_init():\r\n        with patch(\"sqlalchemy.create_engine\") as MockEngine:\r\n            store = PgVectorVectorStore(\r\n                embedding_driver=mock_embedding_driver,\r\n                connection_string=PSG_CONNECTION_STRING,\r\n                table_name=\"test\",\r\n            )\r\n>           MockEngine.assert_called_once()\r\n\r\ntests/memory/test_pg.py:22: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nself = <MagicMock name='create_engine' id='139931849939488'>\r\n\r\n    def assert_called_once(self):\r\n        \"\"\"assert that the mock was called only once.\r\n        \"\"\"\r\n        if not self.call_count == 1:\r\n            msg = (\"Expected '%s' to have been called once. Called %s times.%s\"\r\n                   % (self._mock_name or 'mock',\r\n                      self.call_count,\r\n                      self._calls_repr()))\r\n>           raise AssertionError(msg)\r\nE           AssertionError: Expected 'create_engine' to have been called once. Called 0 times.\r\n\r\n/usr/lib/python3.10/unittest/mock.py:908: AssertionError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-12-08T22:49:14Z",
      "updated_at": "2025-03-20T16:24:30Z",
      "closed_at": "2024-01-01T07:35:06Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/271/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/271",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/271",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:36.892763",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "This can be closed.",
          "created_at": "2024-01-01T00:30:38Z"
        }
      ]
    },
    {
      "issue_number": 270,
      "title": "[BUG] ImportError while importing test module '/home/v/swarms/tests/swarms/test_orchestrate.py'",
      "body": "```\r\nCLIENT: Server listening on port 43559...\r\nReceived JSON data in run script\r\n============================= test session starts ==============================\r\nplatform linux -- Python 3.10.12, pytest-7.4.2, pluggy-1.3.0\r\nrootdir: /home/v/swarms\r\nplugins: anyio-3.7.1\r\ncollected 626 items / 11 errors\r\n\r\n==================================== ERRORS ====================================\r\n______________ ERROR collecting tests/swarms/test_orchestrate.py _______________\r\nImportError while importing test module '/home/v/swarms/tests/swarms/test_orchestrate.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/lib/python3.10/importlib/__init__.py:126: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntests/swarms/test_orchestrate.py:3: in <module>\r\n    from swarms.swarms.orchestrate import Orchestrator\r\nE   ModuleNotFoundError: No module named 'swarms.swarms.orchestrate'\r\n______________ ERROR collecting tests/swarms/test_orchestrate.py _______________\r\nImportError while importing test module '/home/v/swarms/tests/swarms/test_orchestrate.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/lib/python3.10/importlib/__init__.py:126: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntests/swarms/test_orchestrate.py:3: in <module>\r\n    from swarms.swarms.orchestrate import Orchestrator\r\nE   ModuleNotFoundError: No module named 'swarms.swarms.orchestrate'\r\n______________ ERROR collecting tests/swarms/test_orchestrate.py _______________\r\nImportError while importing test module '/home/v/swarms/tests/swarms/test_orchestrate.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/lib/python3.10/importlib/__init__.py:126: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntests/swarms/test_orchestrate.py:3: in <module>\r\n    from swarms.swarms.orchestrate import Orchestrator\r\nE   ModuleNotFoundError: No module named 'swarms.swarms.orchestrate'\r\n______________ ERROR collecting tests/swarms/test_orchestrate.py _______________\r\nImportError while importing test module '/home/v/swarms/tests/swarms/test_orchestrate.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/lib/python3.10/importlib/__init__.py:126: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntests/swarms/test_orchestrate.py:3: in <module>\r\n    from swarms.swarms.orchestrate import Orchestrator\r\nE   ModuleNotFoundError: No module named 'swarms.swarms.orchestrate'\r\n______________ ERROR collecting tests/swarms/test_orchestrate.py _______________\r\nImportError while importing test module '/home/v/swarms/tests/swarms/test_orchestrate.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/lib/python3.10/importlib/__init__.py:126: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntests/swarms/test_orchestrate.py:3: in <module>\r\n    from swarms.swarms.orchestrate import Orchestrator\r\nE   ModuleNotFoundError: No module named 'swarms.swarms.orchestrate'\r\n______________ ERROR collecting tests/swarms/test_orchestrate.py _______________\r\nImportError while importing test module '/home/v/swarms/tests/swarms/test_orchestrate.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/lib/python3.10/importlib/__init__.py:126: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntests/swarms/test_orchestrate.py:3: in <module>\r\n    from swarms.swarms.orchestrate import Orchestrator\r\nE   ModuleNotFoundError: No module named 'swarms.swarms.orchestrate'\r\n______________ ERROR collecting tests/swarms/test_simple_swarm.py ______________\r\nImportError while importing test module '/home/v/swarms/tests/swarms/test_simple_swarm.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/lib/python3.10/importlib/__init__.py:126: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntests/swarms/test_simple_swarm.py:2: in <module>\r\n    from swarms.swarms.simple_swarm import SimpleSwarm\r\nE   ModuleNotFoundError: No module named 'swarms.swarms.simple_swarm'\r\n______________ ERROR collecting tests/swarms/test_simple_swarm.py ______________\r\nImportError while importing test module '/home/v/swarms/tests/swarms/test_simple_swarm.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/lib/python3.10/importlib/__init__.py:126: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntests/swarms/test_simple_swarm.py:2: in <module>\r\n    from swarms.swarms.simple_swarm import SimpleSwarm\r\nE   ModuleNotFoundError: No module named 'swarms.swarms.simple_swarm'\r\n______________ ERROR collecting tests/swarms/test_simple_swarm.py ______________\r\nImportError while importing test module '/home/v/swarms/tests/swarms/test_simple_swarm.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/lib/python3.10/importlib/__init__.py:126: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntests/swarms/test_simple_swarm.py:2: in <module>\r\n    from swarms.swarms.simple_swarm import SimpleSwarm\r\nE   ModuleNotFoundError: No module named 'swarms.swarms.simple_swarm'\r\n______________ ERROR collecting tests/swarms/test_simple_swarm.py ______________\r\nImportError while importing test module '/home/v/swarms/tests/swarms/test_simple_swarm.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/lib/python3.10/importlib/__init__.py:126: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntests/swarms/test_simple_swarm.py:2: in <module>\r\n    from swarms.swarms.simple_swarm import SimpleSwarm\r\nE   ModuleNotFoundError: No module named 'swarms.swarms.simple_swarm'\r\n______________ ERROR collecting tests/swarms/test_simple_swarm.py ______________\r\nImportError while importing test module '/home/v/swarms/tests/swarms/test_simple_swarm.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/lib/python3.10/importlib/__init__.py:126: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntests/swarms/test_simple_swarm.py:2: in <module>\r\n    from swarms.swarms.simple_swarm import SimpleSwarm\r\nE   ModuleNotFoundError: No module named 'swarms.swarms.simple_swarm'\r\n=============================== warnings summary ===============================\r\n../.local/lib/python3.10/site-packages/PyPDF2/__init__.py:21\r\n  /home/v/.local/lib/python3.10/site-packages/PyPDF2/__init__.py:21: DeprecationWarning: PyPDF2 is deprecated. Please move to the pypdf library instead.\r\n    warnings.warn(\r\n\r\n../.local/lib/python3.10/site-packages/wandb/env.py:16\r\n  /home/v/.local/lib/python3.10/site-packages/wandb/env.py:16: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\r\n    from distutils.util import strtobool\r\n\r\n../.local/lib/python3.10/site-packages/timm/models/layers/__init__.py:49\r\n  /home/v/.local/lib/python3.10/site-packages/timm/models/layers/__init__.py:49: DeprecationWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\r\n    warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", DeprecationWarning)\r\n\r\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\r\n=========================== short test summary info ============================\r\nERROR tests/swarms/test_orchestrate.py\r\nERROR tests/swarms/test_orchestrate.py\r\nERROR tests/swarms/test_orchestrate.py\r\nERROR tests/swarms/test_orchestrate.py\r\nERROR tests/swarms/test_orchestrate.py\r\nERROR tests/swarms/test_orchestrate.py\r\nERROR tests/swarms/test_simple_swarm.py\r\nERROR tests/swarms/test_simple_swarm.py\r\nERROR tests/swarms/test_simple_swarm.py\r\nERROR tests/swarms/test_simple_swarm.py\r\nERROR tests/swarms/test_simple_swarm.py\r\n======================== 3 warnings, 11 errors in 2.72s ========================\r\nERROR: not found: /home/v/swarms/tests/models/test_huggingface.py::test_llm_initialization_params[gpt2-small-100]\r\n(no name '/home/v/swarms/tests/models/test_huggingface.py::test_llm_initialization_params[gpt2-small-100]' in any of [<Module tests/models/test_huggingface.py>])\r\n\r\nERROR: not found: /home/v/swarms/tests/models/test_huggingface.py::test_llm_initialization_params[gpt2-medium-200]\r\n(no name '/home/v/swarms/tests/models/test_huggingface.py::test_llm_initialization_params[gpt2-medium-200]' in any of [<Module tests/models/test_huggingface.py>])\r\n\r\nERROR: not found: /home/v/swarms/tests/models/test_huggingface.py::test_llm_initialization_params[gpt2-large-None]\r\n(no name '/home/v/swarms/tests/models/test_huggingface.py::test_llm_initialization_params[gpt2-large-None]' in any of [<Module tests/models/test_huggingface.py>])\r\n\r\nERROR: not found: /home/v/swarms/tests/models/test_huggingface.py::test_llm_model_download_progress\r\n(no name '/home/v/swarms/tests/models/test_huggingface.py::test_llm_model_download_progress' in any of [<Module tests/models/test_huggingface.py>])\r\n\r\nERROR: not found: /home/v/swarms/tests/models/test_huggingface.py::test_llm_update_configuration\r\n(no name '/home/v/swarms/tests/models/test_huggingface.py::test_llm_update_configuration' in any of [<Module tests/models/test_huggingface.py>])\r\n\r\nERROR: not found: /home/v/swarms/tests/models/test_huggingface.py::test_llm_change_model_id\r\n(no name '/home/v/swarms/tests/models/test_huggingface.py::test_llm_change_model_id' in any of [<Module tests/models/test_huggingface.py>])\r\n\r\nERROR: not found: /home/v/swarms/tests/models/test_huggingface.py::test_llm_force_download\r\n(no name '/home/v/swarms/tests/models/test_huggingface.py::test_llm_force_download' in any of [<Module tests/models/test_huggingface.py>])\r\n\r\nERROR: not found: /home/v/swarms/tests/swarms/test_orchestrate.py::test_assign_task\r\n(no name '/home/v/swarms/tests/swarms/test_orchestrate.py::test_assign_task' in any of [<Module tests/swarms/test_orchestrate.py>])\r\n\r\nERROR: not found: /home/v/swarms/tests/swarms/test_orchestrate.py::test_retrieve_results\r\n(no name '/home/v/swarms/tests/swarms/test_orchestrate.py::test_retrieve_results' in any of [<Module tests/swarms/test_orchestrate.py>])\r\n\r\nERROR: not found: /home/v/swarms/tests/swarms/test_orchestrate.py::test_update_vector_db\r\n(no name '/home/v/swarms/tests/swarms/test_orchestrate.py::test_update_vector_db' in any of [<Module tests/swarms/test_orchestrate.py>])\r\n\r\nERROR: not found: /home/v/swarms/tests/swarms/test_orchestrate.py::test_get_vector_db\r\n(no name '/home/v/swarms/tests/swarms/test_orchestrate.py::test_get_vector_db' in any of [<Module tests/swarms/test_orchestrate.py>])\r\n\r\nERROR: not found: /home/v/swarms/tests/swarms/test_orchestrate.py::test_append_to_db\r\n(no name '/home/v/swarms/tests/swarms/test_orchestrate.py::test_append_to_db' in any of [<Module tests/swarms/test_orchestrate.py>])\r\n\r\nERROR: not found: /home/v/swarms/tests/swarms/test_orchestrate.py::test_run\r\n(no name '/home/v/swarms/tests/swarms/test_orchestrate.py::test_run' in any of [<Module tests/swarms/test_orchestrate.py>])\r\n\r\nERROR: not found: /home/v/swarms/tests/swarms/test_simple_swarm.py::test_simpleswarm_initialization\r\n(no name '/home/v/swarms/tests/swarms/test_simple_swarm.py::test_simpleswarm_initialization' in any of [<Module tests/swarms/test_simple_swarm.py>])\r\n\r\nERROR: not found: /home/v/swarms/tests/swarms/test_simple_swarm.py::test_simpleswarm_distribute\r\n(no name '/home/v/swarms/tests/swarms/test_simple_swarm.py::test_simpleswarm_distribute' in any of [<Module tests/swarms/test_simple_swarm.py>])\r\n\r\nERROR: not found: /home/v/swarms/tests/swarms/test_simple_swarm.py::test_simpleswarm_process_task\r\n(no name '/home/v/swarms/tests/swarms/test_simple_swarm.py::test_simpleswarm_process_task' in any of [<Module tests/swarms/test_simple_swarm.py>])\r\n\r\nERROR: not found: /home/v/swarms/tests/swarms/test_simple_swarm.py::test_simpleswarm_run\r\n(no name '/home/v/swarms/tests/swarms/test_simple_swarm.py::test_simpleswarm_run' in any of [<Module tests/swarms/test_simple_swarm.py>])\r\n\r\nERROR: not found: /home/v/swarms/tests/swarms/test_simple_swarm.py::test_simpleswarm_run_old\r\n(no name '/home/v/swarms/tests/swarms/test_simple_swarm.py::test_simpleswarm_run_old' in any of [<Module tests/swarms/test_simple_swarm.py>])\r\n\r\nFinished running tests!\r\n\r\n```",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-12-06T23:27:05Z",
      "updated_at": "2025-03-20T16:24:30Z",
      "closed_at": "2023-12-19T00:38:48Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/270/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/270",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/270",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:37.080318",
      "comments": []
    },
    {
      "issue_number": 269,
      "title": "[BUG] ERROR: not found: /home/v/swarms/tests/models/test_huggingface.py::test_llm_initialization_params",
      "body": "CLIENT: Server listening on port 37099...\r\nReceived JSON data in run script\r\n============================= test session starts ==============================\r\nplatform linux -- Python 3.10.12, pytest-7.4.2, pluggy-1.3.0\r\nrootdir: /home/v/swarms\r\nplugins: anyio-3.7.1\r\ncollected 637 items\r\n\r\n=============================== warnings summary ===============================\r\n../.local/lib/python3.10/site-packages/PyPDF2/__init__.py:21\r\n  /home/v/.local/lib/python3.10/site-packages/PyPDF2/__init__.py:21: DeprecationWarning: PyPDF2 is deprecated. Please move to the pypdf library instead.\r\n    warnings.warn(\r\n\r\n../.local/lib/python3.10/site-packages/wandb/env.py:16\r\n  /home/v/.local/lib/python3.10/site-packages/wandb/env.py:16: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\r\n    from distutils.util import strtobool\r\n\r\n../.local/lib/python3.10/site-packages/timm/models/layers/__init__.py:49\r\n  /home/v/.local/lib/python3.10/site-packages/timm/models/layers/__init__.py:49: DeprecationWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\r\n    warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", DeprecationWarning)\r\n\r\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\r\n============================= 3 warnings in 2.70s ==============================\r\nERROR: not found: /home/v/swarms/tests/models/test_huggingface.py::test_llm_initialization_params[gpt2-small-100]\r\n(no name '/home/v/swarms/tests/models/test_huggingface.py::test_llm_initialization_params[gpt2-small-100]' in any of [<Module tests/models/test_huggingface.py>])\r\n\r\nERROR: not found: /home/v/swarms/tests/models/test_huggingface.py::test_llm_initialization_params[gpt2-medium-200]\r\n(no name '/home/v/swarms/tests/models/test_huggingface.py::test_llm_initialization_params[gpt2-medium-200]' in any of [<Module tests/models/test_huggingface.py>])\r\n\r\nERROR: not found: /home/v/swarms/tests/models/test_huggingface.py::test_llm_initialization_params[gpt2-large-None]\r\n(no name '/home/v/swarms/tests/models/test_huggingface.py::test_llm_initialization_params[gpt2-large-None]' in any of [<Module tests/models/test_huggingface.py>])\r\n\r\nERROR: not found: /home/v/swarms/tests/models/test_huggingface.py::test_llm_model_download_progress\r\n(no name '/home/v/swarms/tests/models/test_huggingface.py::test_llm_model_download_progress' in any of [<Module tests/models/test_huggingface.py>])\r\n\r\nERROR: not found: /home/v/swarms/tests/models/test_huggingface.py::test_llm_update_configuration\r\n(no name '/home/v/swarms/tests/models/test_huggingface.py::test_llm_update_configuration' in any of [<Module tests/models/test_huggingface.py>])\r\n\r\nERROR: not found: /home/v/swarms/tests/models/test_huggingface.py::test_llm_change_model_id\r\n(no name '/home/v/swarms/tests/models/test_huggingface.py::test_llm_change_model_id' in any of [<Module tests/models/test_huggingface.py>])\r\n\r\nERROR: not found: /home/v/swarms/tests/models/test_huggingface.py::test_llm_force_download\r\n(no name '/home/v/swarms/tests/models/test_huggingface.py::test_llm_force_download' in any of [<Module tests/models/test_huggingface.py>])\r\n\r\nFinished running tests!",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-12-06T22:20:17Z",
      "updated_at": "2025-03-20T16:24:29Z",
      "closed_at": "2024-01-01T07:55:31Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/269/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/269",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/269",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:37.080336",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "This can be closed.",
          "created_at": "2024-01-01T00:29:18Z"
        }
      ]
    },
    {
      "issue_number": 265,
      "title": "[BUG] no attribute \"create\"",
      "body": "ERROR:root:Error generating response: 'NoneType' object has no attribute 'create'\r\nError generating response: 'NoneType' object has no attribute 'create'\r\nERROR:root:Error generating response: 'NoneType' object has no attribute 'create'\r\nError generating response: 'NoneType' object has no attribute 'create'\r\nERROR:root:Error generating response: 'NoneType' object has no attribute 'create'\r\nError generating response: 'NoneType' object has no attribute 'create'",
      "state": "closed",
      "author": "elder-plinius",
      "author_type": "User",
      "created_at": "2023-12-05T18:25:45Z",
      "updated_at": "2025-03-20T16:24:29Z",
      "closed_at": "2023-12-06T03:56:52Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/265/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/265",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/265",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:37.264525",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@elder-plinius provide the full error stack trace what file are you trying to run, this is useless ",
          "created_at": "2023-12-05T19:02:14Z"
        },
        {
          "author": "kyegomez",
          "body": "@elder-plinius try again and run it again",
          "created_at": "2023-12-06T01:01:50Z"
        }
      ]
    },
    {
      "issue_number": 264,
      "title": "[BUG] openai_vision_api error reporting and suggestions for correcting",
      "body": "**Describe the bug**\r\nRunning example.py produces some output in errors.txt\r\n```\r\nERROR:root:Error generating response: 'NoneType' object has no attribute 'create\r\n'\r\nError generating response: 'NoneType' object has no attribute 'create'\r\nERROR:root:Error generating response: 'NoneType' object has no attribute 'create\r\n'\r\nError generating response: 'NoneType' object has no attribute 'create'\r\nERROR:root:Error generating response: 'NoneType' object has no attribute 'create\r\n'\r\nError generating response: 'NoneType' object has no attribute 'create'\r\n```\r\nThis error is produced by two different functions in openai_vision_api:\r\n\r\n__call__ and run\r\n\r\nThe error messages need to include:\r\nThe program which produced them: openai_vision_api\r\nThe function which produced them: __call__ or run\r\nAnd the request which produced the error. It appears in this specific case to be blank (NoneType). Why is this empty? If the image input is missing, that needs to be checked much earlier in the executution path, and the end user given an opportunity to correct it, by providing an image file.",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-12-05T16:37:48Z",
      "updated_at": "2025-03-20T16:24:29Z",
      "closed_at": "2023-12-06T04:02:12Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/264/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/264",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/264",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:37.487140",
      "comments": []
    },
    {
      "issue_number": 261,
      "title": "[BUG] transformers issue",
      "body": "In colab (https://colab.research.google.com/drive/1E-6y5_r4YgMhEbyGRlG4kWVtI2dKPrQi#scrollTo=bdc6De61nBMv)\r\n\r\n```\r\nDEBUG:root:Initializing MLIR with module: _site_initialize_0\r\nInitializing MLIR with module: _site_initialize_0\r\nDEBUG:root:Registering dialects from initializer <module 'jaxlib.mlir._mlir_libs._site_initialize_0' from '/usr/local/lib/python3.10/dist-packages/jaxlib/mlir/_mlir_libs/_site_initialize_0.so'>\r\nRegistering dialects from initializer <module 'jaxlib.mlir._mlir_libs._site_initialize_0' from '/usr/local/lib/python3.10/dist-packages/jaxlib/mlir/_mlir_libs/_site_initialize_0.so'>\r\nDEBUG:jax._src.path:etils.epath found. Using etils.epath for file I/O.\r\netils.epath found. Using etils.epath for file I/O.\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\", line 1353, in _get_module\r\n    return importlib.import_module(\".\" + module_name, self.__name__)\r\n  File \"/usr/lib/python3.10/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/__init__.py\", line 75, in <module>\r\n    from .table_question_answering import TableQuestionAnsweringArgumentHandler, TableQuestionAnsweringPipeline\r\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/table_question_answering.py\", line 26, in <module>\r\n    import tensorflow_probability as tfp\r\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_probability/__init__.py\", line 20, in <module>\r\n    from tensorflow_probability import substrates\r\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/__init__.py\", line 17, in <module>\r\n    from tensorflow_probability.python.internal import all_util\r\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/__init__.py\", line 138, in <module>\r\n    dir(globals()[pkg_name])  # Forces loading the package from its lazy loader.\r\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/internal/lazy_loader.py\", line 57, in __dir__\r\n    module = self._load()\r\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/internal/lazy_loader.py\", line 37, in _load\r\n    self._on_first_access()\r\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/__init__.py\", line 59, in _validate_tf_environment\r\n    raise ImportError(\r\nImportError: This version of TensorFlow Probability requires TensorFlow version >= 2.14; Detected an installation of version 2.12.0. Please upgrade TensorFlow to proceed.\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/content/swarms/example.py\", line 6, in <module>\r\n    from swarms.models import OpenAIChat\r\n  File \"/content/swarms/swarms/__init__.py\", line 8, in <module>\r\n    from swarms.models import *  # noqa: E402, F403\r\n  File \"/content/swarms/swarms/models/__init__.py\", line 11, in <module>\r\n    from swarms.models.zephyr import Zephyr  # noqa: E402\r\n  File \"/content/swarms/swarms/models/zephyr.py\", line 3, in <module>\r\n    from transformers import pipeline\r\n  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\r\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\", line 1343, in __getattr__\r\n    module = self._get_module(self._class_to_module[name])\r\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\", line 1355, in _get_module\r\n    raise RuntimeError(\r\nRuntimeError: Failed to import transformers.pipelines because of the following error (look up to see its traceback):\r\nThis version of TensorFlow Probability requires TensorFlow version >= 2.14; Detected an installation of version 2.12.0. Please upgrade TensorFlow to proceed.\r\n```",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-12-04T23:46:10Z",
      "updated_at": "2025-03-20T16:24:29Z",
      "closed_at": "2023-12-06T04:11:14Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/261/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/261",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/261",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:37.487164",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "Appears to be fixed by:\r\n```\r\npip uninstall tensorflow\r\npip install tensorflow\r\n```\r\n",
          "created_at": "2023-12-05T00:38:14Z"
        },
        {
          "author": "evelynmitchell",
          "body": "This error appears to be fixed.\n\nThe latest run of example.py in a colab notebook has a new error ```\nDEBUG:jaxlib.mlir._mlir_libs:Initializing MLIR with module: _site_initialize_0\nInitializing MLIR with module: _site_initialize_0\nDEBUG:jaxlib.mlir._mlir_libs:Registering dialects from initializer <m",
          "created_at": "2023-12-05T15:15:20Z"
        },
        {
          "author": "kyegomez",
          "body": "@evelynmitchell fixed by adding tensorflow",
          "created_at": "2023-12-06T04:11:14Z"
        }
      ]
    },
    {
      "issue_number": 258,
      "title": "[BUG] agents do not use unique ids between runs",
      "body": "(https://github.com/search?q=repo%3Akyegomez%2Fswarms%20XYZ1B&type=code)\r\nAt line 176 the agent_name is hardcoded\r\n```\r\n agent_name: str = \"Autonomous-Agent-XYZ1B\",\r\n```",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-12-04T18:23:46Z",
      "updated_at": "2025-03-20T16:24:29Z",
      "closed_at": "2023-12-05T09:22:30Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/258/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/258",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/258",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:37.668368",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@evelynmitchell you can change them!",
          "created_at": "2023-12-05T09:22:30Z"
        }
      ]
    },
    {
      "issue_number": 256,
      "title": "[BUG] swarms does not work with python 3.12 yet due to pytorch",
      "body": "This is a known issue with pytorch:\r\nhttps://github.com/pytorch/pytorch/issues/110436",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-12-04T18:06:04Z",
      "updated_at": "2025-03-20T16:24:28Z",
      "closed_at": "2023-12-06T04:11:24Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/256/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/256",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/256",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:37.864275",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@evelynmitchell can you submit a pr for this pls",
          "created_at": "2023-12-05T06:28:56Z"
        }
      ]
    },
    {
      "issue_number": 249,
      "title": "[BUG] colab container has pydantic errors",
      "body": "\r\nColab notebook (https://colab.research.google.com/drive/1_UfM2ResAIfmPjVqBibhw7KBm0Es4XTB#scrollTo=COa2SpPJrdtJ)\r\nThe errors.txt shows the issue.\r\nPython modules also listed.\r\nI believe that updating pydantic and running bump-pydantic and a couple of minor fixes to tools.py will resolve this issue.",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-12-03T22:00:58Z",
      "updated_at": "2025-03-20T16:24:28Z",
      "closed_at": "2023-12-06T03:57:27Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/249/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/249",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/249",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:38.020707",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "I've run bump-pydantic, changed the version of pydantic to 2.x in both pyproject.toml and requirements.txt. The pydantic errors are mostly gone, as seen in the latest version of the colab notebook (https://colab.research.google.com/drive/1aFMuDQyFNkXkzT6oGdo6F0_PRCVIPq2) I'm going to make a PR to th",
          "created_at": "2023-12-03T23:18:07Z"
        }
      ]
    },
    {
      "issue_number": 248,
      "title": "[BUG] logging needs to preserve whitespace, include datetime of run",
      "body": "**Describe the bug**\r\nLogging needs to preserve whitespace, include datetime of run.\r\nWhitespace is important for json.",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-12-03T21:57:50Z",
      "updated_at": "2025-03-20T16:24:28Z",
      "closed_at": "2023-12-06T03:57:18Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/248/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/248",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/248",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:38.246726",
      "comments": []
    },
    {
      "issue_number": 241,
      "title": "[BUG] TypeError: 'type' object is not subscriptable",
      "body": "Traceback (most recent call last):\r\n  File \"ex1.py\", line 2, in <module>\r\n    import swarms\r\n  File \"/home/vyas/swarms/swarm_env/lib/python3.8/site-packages/swarms/__init__.py\", line 1, in <module>\r\n    from swarms.utils.disable_logging import disable_logging\r\n  File \"/home/vyas/swarms/swarm_env/lib/python3.8/site-packages/swarms/utils/__init__.py\", line 2, in <module>\r\n    from swarms.utils.futures import execute_futures_dict\r\n  File \"/home/vyas/swarms/swarm_env/lib/python3.8/site-packages/swarms/utils/futures.py\", line 7, in <module>\r\n    def execute_futures_dict(fs_dict: dict[str, futures.Future[T]]) -> dict[str, T]:\r\nTypeError: 'type' object is not subscriptable\r\n\r\n\r\nFaced this issue while running the example agent on Ubuntu 20.4 OS",
      "state": "closed",
      "author": "askvyas",
      "author_type": "User",
      "created_at": "2023-12-01T22:20:07Z",
      "updated_at": "2025-03-20T16:24:28Z",
      "closed_at": "2023-12-06T04:12:30Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 11,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/241/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/241",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/241",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:38.246747",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2023-12-01T22:20:36Z"
        },
        {
          "author": "kyegomez",
          "body": "@askvyas Thanks for the issue, I'm submitting an update now it works for me, try again please.\r\n",
          "created_at": "2023-12-01T22:35:41Z"
        },
        {
          "author": "askvyas",
          "body": "upgraded using pip3 install --upgrade swarms \r\n\r\nstill getting the same issue \r\nTraceback (most recent call last):\r\n  File \"ex1.py\", line 2, in <module>\r\n    import swarms\r\n  File \"/home/vyas/.local/lib/python3.8/site-packages/swarms/__init__.py\", line 1, in <module>\r\n    from swarms.utils.disable_l",
          "created_at": "2023-12-01T22:43:20Z"
        },
        {
          "author": "kyegomez",
          "body": "@askvyas try this `pip3 install --upgrade swarms==2.5.1`\r\n\r\n",
          "created_at": "2023-12-02T00:41:19Z"
        },
        {
          "author": "askvyas",
          "body": "ERROR: Could not find a version that satisfies the requirement swarms==2.5.1 (from versions: 0.0.1, 0.0.3, 0.0.4, 0.0.5, 0.0.7, 0.0.8, 0.0.9, 0.1.1, 0.1.2, 0.1.3, 0.1.4, 0.1.5, 0.1.6, 0.1.7, 0.1.9, 0.2.0, 0.2.2, 0.2.3, 0.2.8, 0.2.9, 0.3.0, 0.3.1, 0.3.2, 0.3.3, 0.3.4, 0.3.5, 0.3.6, 0.3.7, 0.3.8, 0.3.",
          "created_at": "2023-12-02T01:29:36Z"
        }
      ]
    },
    {
      "issue_number": 240,
      "title": "[BUG] ",
      "body": "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmpe3xt07sg\r\nCreated a temporary directory at /tmp/tmpe3xt07sg\r\nINFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmpe3xt07sg/_remote_module_non_scriptable.py\r\nWriting /tmp/tmpe3xt07sg/_remote_module_non_scriptable.py\r\nDEBUG:sentry_sdk.errors:[Tracing] Create new propagation context: {'trace_id': '8941489749dc480c87b092577d82c396', 'span_id': 'a68e8099636b936b', 'parent_span_id': None, 'dynamic_sampling_context': None}\r\n[Tracing] Create new propagation context: {'trace_id': '8941489749dc480c87b092577d82c396', 'span_id': 'a68e8099636b936b', 'parent_span_id': None, 'dynamic_sampling_context': None}\r\nTraceback (most recent call last):\r\n  File \"/home/zack/code/swarms/accountant_team.py\", line 6, in <module>\r\n    from swarms.models import Anthropic, OpenAIChat\r\n  File \"/home/zack/code/swarms/swarms/__init__.py\", line 8, in <module>\r\n    from swarms.models import *  # noqa: E402, F403\r\n  File \"/home/zack/code/swarms/swarms/models/__init__.py\", line 23, in <module>\r\n    from swarms.models.idefics import Idefics  # noqa: E402\r\n  File \"/home/zack/code/swarms/swarms/models/idefics.py\", line 2, in <module>\r\n    from transformers import AutoProcessor, IdeficsForVisionText2Text\r\nImportError: cannot import name 'IdeficsForVisionText2Text' from 'transformers' (/usr/local/lib/python3.10/dist-packages/transformers/__init__.py)\r\nDEBUG:filelock:Attempting to acquire lock 139964647196032 on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock\r\nAttempting to acquire lock 139964647196032 on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock\r\nDEBUG:filelock:Lock 139964647196032 acquired on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock\r\nLock 139964647196032 acquired on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock\r\nDEBUG:filelock:Attempting to release lock 139964647196032 on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock\r\nAttempting to release lock 139964647196032 on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock\r\nDEBUG:filelock:Lock 139964647196032 released on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock\r\nLock 139964647196032 released on /root/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock\r\nDEBUG:filelock:Attempting to acquire lock 139964646923456 on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock\r\nAttempting to acquire lock 139964646923456 on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock\r\nDEBUG:filelock:Lock 139964646923456 acquired on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock\r\nLock 139964646923456 acquired on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock\r\nDEBUG:filelock:Attempting to release lock 139964646923456 on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock\r\nAttempting to release lock 139964646923456 on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock\r\nDEBUG:filelock:Lock 139964646923456 released on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock\r\nLock 139964646923456 released on /root/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock",
      "state": "closed",
      "author": "ZackBradshaw",
      "author_type": "User",
      "created_at": "2023-12-01T19:00:49Z",
      "updated_at": "2025-03-20T16:24:28Z",
      "closed_at": "2023-12-05T06:52:23Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/240/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/240",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/240",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:38.474668",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@ZackBradshaw run `python3.10 -m pip install --upgrade transformers`",
          "created_at": "2023-12-02T01:15:00Z"
        }
      ]
    },
    {
      "issue_number": 237,
      "title": "[BUG] outdated packages dockeriles",
      "body": "I did a comparison of the package versions between the root Dockerfile, and the tests Dockefile builds. \r\n@kyegomez would you be able to run this on your development environment and share the output as a reply to this bug?\r\n\r\nI'll fix the differences in the Dockerfile versions.\r\n\r\nMy goal is to create a developer container that can be run from within vscode, to keep the whole toolchain in sync.\r\n\r\nRan: python -m pip list -o\r\nfrom within the dockerfile.\r\n```\r\nPackage                      Version    Latest       Type\r\n---------------------------- ---------- ------------ -----\r\nantlr4-python3-runtime       4.9.3      4.13.1       wheel\r\nanyio                        3.7.1      4.1.0        wheel\r\ngoogle-ai-generativelanguage 0.3.3      0.3.4        wheel\r\ngoogle-auth                  2.23.4     2.24.0       wheel\r\nlangchain                    0.0.343    0.0.344      wheel\r\nlangchain-core               0.0.7      0.0.8        wheel\r\nnvidia-cublas-cu12           12.1.3.1   12.3.4.1     wheel\r\nnvidia-cuda-cupti-cu12       12.1.105   12.3.101     wheel\r\nnvidia-cuda-nvrtc-cu12       12.1.105   12.3.103     wheel\r\nnvidia-cuda-runtime-cu12     12.1.105   12.3.101     wheel\r\nnvidia-cudnn-cu12            8.9.2.26   8.9.6.50     wheel\r\nnvidia-cufft-cu12            11.0.2.54  11.0.12.1    wheel\r\nnvidia-curand-cu12           10.3.2.106 10.3.4.101   wheel\r\nnvidia-cusolver-cu12         11.4.5.107 11.5.4.101   wheel\r\nnvidia-cusparse-cu12         12.1.0.106 12.2.0.103   wheel\r\nnvidia-nccl-cu12             2.18.1     2.19.3       wheel\r\nnvidia-nvtx-cu12             12.1.105   12.3.101     wheel\r\nopenai                       0.28.0     1.3.6        wheel\r\nprotobuf                     4.23.4     4.25.1       wheel\r\npyee                         11.0.1     11.1.0       wheel\r\nsetuptools                   58.1.0     69.0.2       wheel\r\nstarlette                    0.27.0     0.32.0.post1 wheel\r\nswarms                       2.4.6      2.4.8        wheel\r\ntermcolor                    2.3.0      2.4.0        wheel\r\nurllib3                      1.26.18    2.1.0        wheel\r\n```\r\nAnd from the tests Dockerfile:\r\n```\r\nPackage                      Version    Latest       Type\r\n---------------------------- ---------- ------------ -----\r\nanyio                        3.7.1      4.1.0        wheel\r\ngoogle-ai-generativelanguage 0.3.3      0.3.4        wheel\r\nnvidia-cublas-cu12           12.1.3.1   12.3.4.1     wheel\r\nnvidia-cuda-cupti-cu12       12.1.105   12.3.101     wheel\r\nnvidia-cuda-nvrtc-cu12       12.1.105   12.3.103     wheel\r\nnvidia-cuda-runtime-cu12     12.1.105   12.3.101     wheel\r\nnvidia-cudnn-cu12            8.9.2.26   8.9.6.50     wheel\r\nnvidia-cufft-cu12            11.0.2.54  11.0.12.1    wheel\r\nnvidia-curand-cu12           10.3.2.106 10.3.4.101   wheel\r\nnvidia-cusolver-cu12         11.4.5.107 11.5.4.101   wheel\r\nnvidia-cusparse-cu12         12.1.0.106 12.2.0.103   wheel\r\nnvidia-nccl-cu12             2.18.1     2.19.3       wheel\r\nnvidia-nvtx-cu12             12.1.105   12.3.101     wheel\r\nopenai                       0.28.0     1.3.6        wheel\r\npip                          23.0.1     23.3.1       wheel\r\nplatformdirs                 3.11.0     4.0.0        wheel\r\npyee                         11.0.1     11.1.0       wheel\r\nsetuptools                   58.1.0     69.0.2       wheel\r\nstarlette                    0.27.0     0.32.0.post1 wheel\r\nurllib3                      1.26.18    2.1.0        wheel\r\n```",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-12-01T13:35:39Z",
      "updated_at": "2025-03-20T16:24:28Z",
      "closed_at": "2023-12-06T03:57:34Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/237/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/237",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/237",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:38.647235",
      "comments": []
    },
    {
      "issue_number": 238,
      "title": "[BUG] threadpoolexecutor import error in basemultimodalmodel",
      "body": "Traceback (most recent call last):\r\n  File \"c:\\Users\\Guest1\\Desktop\\p-swarms\\idea2image.py\", line 4, in <module>\r\n    from swarms.models.stable_diffusion import StableDiffusion\r\n  File \"c:\\Users\\Guest1\\Desktop\\p-swarms\\swarms\\__init__.py\", line 8, in <module>\r\n    from swarms.models import *  # noqa: E402, F403\r\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"c:\\Users\\Guest1\\Desktop\\p-swarms\\swarms\\models\\__init__.py\", line 20, in <module>\r\n    from swarms.models.base_multimodal_model import BaseMultiModalModel # noqa: E402\r\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"c:\\Users\\Guest1\\Desktop\\p-swarms\\swarms\\models\\base_multimodal_model.py\", line 6, in <module>\r\n    from concurrent import ThreadPoolExecutor\r\nImportError: cannot import name 'ThreadPoolExecutor' from 'concurrent' (C:\\Users\\Guest1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\__init__.py)",
      "state": "closed",
      "author": "elder-plinius",
      "author_type": "User",
      "created_at": "2023-12-01T16:09:09Z",
      "updated_at": "2025-03-20T16:24:27Z",
      "closed_at": "2023-12-01T16:11:32Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/238/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/238",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/238",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:38.647260",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@elder-plinius forgot concurrent.futures updated now",
          "created_at": "2023-12-01T16:11:28Z"
        }
      ]
    },
    {
      "issue_number": 236,
      "title": "[BUG] example.py does not mention where errors go",
      "body": "**Describe the bug**\r\nThere is nothing in the example.py code which would help a developer find the output errors.txt\r\nIt is a non-standard logging location, and not mentioned in the code.",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-12-01T13:18:41Z",
      "updated_at": "2025-03-20T16:24:27Z",
      "closed_at": "2023-12-05T19:19:39Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/236/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/236",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/236",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:38.826594",
      "comments": []
    },
    {
      "issue_number": 235,
      "title": "[BUG] base import error, abstractllm",
      "body": "Traceback (most recent call last):\r\n  File \"c:\\Users\\Guest1\\Desktop\\p-swarms\\example.py\", line 6, in <module>\r\n    from swarms.models import OpenAIChat\r\n  File \"c:\\Users\\Guest1\\Desktop\\p-swarms\\swarms\\__init__.py\", line 8, in <module>\r\n    from swarms.models import *  # noqa: E402, F403\r\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"c:\\Users\\Guest1\\Desktop\\p-swarms\\swarms\\models\\__init__.py\", line 2, in <module>\r\n    from swarms.models.base import AbstractLLM  # noqa: E402\r\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nModuleNotFoundError: No module named 'swarms.models.base'",
      "state": "closed",
      "author": "elder-plinius",
      "author_type": "User",
      "created_at": "2023-12-01T03:19:14Z",
      "updated_at": "2025-03-20T16:24:27Z",
      "closed_at": "2023-12-01T16:10:56Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/235/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/235",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/235",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:38.826624",
      "comments": []
    },
    {
      "issue_number": 232,
      "title": "[BUG] AttributeError: 'dict' object has no attribute 'to'",
      "body": "/home/v/swarms/tests/models/test_idefics.py::test_run failed: idefics_instance = <swarms.models.idefics.Idefics object at 0x7f6a4c128a60>\r\n\r\n    def test_run(idefics_instance):\r\n        prompts = [[\"User: Test\"]]\r\n        with patch.object(\r\n            idefics_instance, \"processor\"\r\n        ) as mock_processor, patch.object(\r\n            idefics_instance, \"model\"\r\n        ) as mock_model:\r\n            mock_processor.return_value = {\r\n                \"input_ids\": torch.tensor([1, 2, 3])\r\n            }\r\n            mock_model.generate.return_value = torch.tensor([1, 2, 3])\r\n            mock_processor.batch_decode.return_value = [\"Test\"]\r\n    \r\n>           result = idefics_instance.run(prompts)\r\n\r\ntests/models/test_idefics.py:58: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nself = <swarms.models.idefics.Idefics object at 0x7f6a4c128a60>\r\nprompts = [['User: Test']], batched_mode = True\r\n\r\n    def run(self, prompts, batched_mode=True):\r\n        \"\"\"\r\n        Generates text based on the provided prompts.\r\n    \r\n        Parameters\r\n        ----------\r\n            prompts : list\r\n                A list of prompts. Each prompt is a list of text strings and images.\r\n            batched_mode : bool, optional\r\n                Whether to process the prompts in batched mode. If True, all prompts are\r\n                processed together. If False, only the first prompt is processed (default is True).\r\n    \r\n        Returns\r\n        -------\r\n            list\r\n                A list of generated text strings.\r\n        \"\"\"\r\n        inputs = (\r\n            self.processor(\r\n                prompts,\r\n                add_end_of_utterance_token=False,\r\n                return_tensors=\"pt\",\r\n>           ).to(self.device)\r\n            if batched_mode\r\n            else self.processor(prompts[0], return_tensors=\"pt\").to(\r\n                self.device\r\n            )\r\n        )\r\nE       AttributeError: 'dict' object has no attribute 'to'\r\n\r\nswarms/models/idefics.py:106: AttributeError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-30T22:53:03Z",
      "updated_at": "2025-03-20T16:24:27Z",
      "closed_at": "2023-12-06T04:32:15Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/232/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/232",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/232",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:38.826635",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@vyomakesh09 I have just optimized this method and made it much better",
          "created_at": "2023-12-06T04:32:15Z"
        }
      ]
    },
    {
      "issue_number": 229,
      "title": "[BUG] AttributeError: <class 'swarms.models.huggingface.HuggingfaceLLM'> does not have the attribute '_tokenizer'",
      "body": "/home/v/swarms/tests/models/test_huggingface.py::test_llm_cleanup failed: args = ()\r\nkeywargs = {'llm_instance': <swarms.models.huggingface.HuggingfaceLLM object at 0x7f6a23e427a0>}\r\n\r\n    @wraps(func)\r\n    def patched(*args, **keywargs):\r\n>       with self.decoration_helper(patched,\r\n                                    args,\r\n                                    keywargs) as (newargs, newkeywargs):\r\n\r\n/usr/lib/python3.10/unittest/mock.py:1376: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n/usr/lib/python3.10/contextlib.py:135: in __enter__\r\n    return next(self.gen)\r\n/usr/lib/python3.10/unittest/mock.py:1358: in decoration_helper\r\n    arg = exit_stack.enter_context(patching)\r\n/usr/lib/python3.10/contextlib.py:492: in enter_context\r\n    result = _cm_type.__enter__(cm)\r\n/usr/lib/python3.10/unittest/mock.py:1447: in __enter__\r\n    original, local = self.get_original()\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nself = <unittest.mock._patch object at 0x7f6a7a1fb490>\r\n\r\n    def get_original(self):\r\n        target = self.getter()\r\n        name = self.attribute\r\n    \r\n        original = DEFAULT\r\n        local = False\r\n    \r\n        try:\r\n            original = target.__dict__[name]\r\n        except (AttributeError, KeyError):\r\n            original = getattr(target, name, DEFAULT)\r\n        else:\r\n            local = True\r\n    \r\n        if name in _builtins and isinstance(target, ModuleType):\r\n            self.create = True\r\n    \r\n        if not self.create and original is DEFAULT:\r\n>           raise AttributeError(\r\n                \"%s does not have the attribute %r\" % (target, name)\r\n            )\r\nE           AttributeError: <class 'swarms.models.huggingface.HuggingfaceLLM'> does not have the attribute '_tokenizer'\r\n\r\n/usr/lib/python3.10/unittest/mock.py:1420: AttributeError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-30T22:51:14Z",
      "updated_at": "2025-03-20T16:24:27Z",
      "closed_at": "2023-12-05T06:58:42Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/229/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/229",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/229",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:39.017382",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@vyomakesh09 deleted this from the tests folder",
          "created_at": "2023-12-05T06:58:42Z"
        }
      ]
    },
    {
      "issue_number": 231,
      "title": "[BUG] AttributeError: <class 'swarms.models.huggingface.HuggingfaceLLM'> does not have the attribute '_download_model'",
      "body": "/home/v/swarms/tests/models/test_huggingface.py::test_llm_force_download failed: args = ()\r\nkeywargs = {'llm_instance': <swarms.models.huggingface.HuggingfaceLLM object at 0x7f6a4e3d5ff0>}\r\n\r\n    @wraps(func)\r\n    def patched(*args, **keywargs):\r\n>       with self.decoration_helper(patched,\r\n                                    args,\r\n                                    keywargs) as (newargs, newkeywargs):\r\n\r\n/usr/lib/python3.10/unittest/mock.py:1376: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n/usr/lib/python3.10/contextlib.py:135: in __enter__\r\n    return next(self.gen)\r\n/usr/lib/python3.10/unittest/mock.py:1358: in decoration_helper\r\n    arg = exit_stack.enter_context(patching)\r\n/usr/lib/python3.10/contextlib.py:492: in enter_context\r\n    result = _cm_type.__enter__(cm)\r\n/usr/lib/python3.10/unittest/mock.py:1447: in __enter__\r\n    original, local = self.get_original()\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nself = <unittest.mock._patch object at 0x7f6a7a1fb910>\r\n\r\n    def get_original(self):\r\n        target = self.getter()\r\n        name = self.attribute\r\n    \r\n        original = DEFAULT\r\n        local = False\r\n    \r\n        try:\r\n            original = target.__dict__[name]\r\n        except (AttributeError, KeyError):\r\n            original = getattr(target, name, DEFAULT)\r\n        else:\r\n            local = True\r\n    \r\n        if name in _builtins and isinstance(target, ModuleType):\r\n            self.create = True\r\n    \r\n        if not self.create and original is DEFAULT:\r\n>           raise AttributeError(\r\n                \"%s does not have the attribute %r\" % (target, name)\r\n            )\r\nE           AttributeError: <class 'swarms.models.huggingface.HuggingfaceLLM'> does not have the attribute '_download_model'\r\n\r\n/usr/lib/python3.10/unittest/mock.py:1420: AttributeError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-30T22:52:16Z",
      "updated_at": "2025-03-20T16:24:26Z",
      "closed_at": "2023-12-05T06:42:38Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/231/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/231",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/231",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:39.235651",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@vyomakesh09 deleted the tests that don't exist",
          "created_at": "2023-12-05T06:42:39Z"
        }
      ]
    },
    {
      "issue_number": 230,
      "title": "[BUG] AttributeError: 'HuggingfaceLLM' object has no attribute 'update_configuration'",
      "body": "/home/v/swarms/tests/models/test_huggingface.py::test_llm_update_configuration failed: llm_instance = <swarms.models.huggingface.HuggingfaceLLM object at 0x7f6a58889c90>\r\n\r\n    def test_llm_update_configuration(llm_instance):\r\n        new_config = {\"temperature\": 0.7}\r\n>       llm_instance.update_configuration(new_config)\r\nE       AttributeError: 'HuggingfaceLLM' object has no attribute 'update_configuration'\r\n\r\ntests/models/test_huggingface.py:223: AttributeError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-30T22:51:35Z",
      "updated_at": "2025-03-20T16:24:26Z",
      "closed_at": "2023-12-05T06:46:28Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/230/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/230",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/230",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:39.425735",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@vyomakesh09 this test does not exist, i have deleted it from the code",
          "created_at": "2023-12-05T06:46:28Z"
        }
      ]
    },
    {
      "issue_number": 228,
      "title": "[BUG]  OSError: gpt2-small is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'",
      "body": "/home/v/swarms/tests/models/test_huggingface.py::test_llm_long_input_warning failed: response = <Response [401]>, endpoint_name = None\r\n\r\n    def hf_raise_for_status(response: Response, endpoint_name: Optional[str] = None) -> None:\r\n        \"\"\"\r\n        Internal version of `response.raise_for_status()` that will refine a\r\n        potential HTTPError. Raised exception will be an instance of `HfHubHTTPError`.\r\n    \r\n        This helper is meant to be the unique method to raise_for_status when making a call\r\n        to the Hugging Face Hub.\r\n    \r\n        Example:\r\n        ```py\r\n            import requests\r\n            from huggingface_hub.utils import get_session, hf_raise_for_status, HfHubHTTPError\r\n    \r\n            response = get_session().post(...)\r\n            try:\r\n                hf_raise_for_status(response)\r\n            except HfHubHTTPError as e:\r\n                print(str(e)) # formatted message\r\n                e.request_id, e.server_message # details returned by server\r\n    \r\n                # Complete the error message with additional information once it's raised\r\n                e.append_to_message(\"\\n`create_commit` expects the repository to exist.\")\r\n                raise\r\n        ```\r\n    \r\n        Args:\r\n            response (`Response`):\r\n                Response from the server.\r\n            endpoint_name (`str`, *optional*):\r\n                Name of the endpoint that has been called. If provided, the error message\r\n                will be more complete.\r\n    \r\n        <Tip warning={true}>\r\n    \r\n        Raises when the request has failed:\r\n    \r\n            - [`~utils.RepositoryNotFoundError`]\r\n                If the repository to download from cannot be found. This may be because it\r\n                doesn't exist, because `repo_type` is not set correctly, or because the repo\r\n                is `private` and you do not have access.\r\n            - [`~utils.GatedRepoError`]\r\n                If the repository exists but is gated and the user is not on the authorized\r\n                list.\r\n            - [`~utils.RevisionNotFoundError`]\r\n                If the repository exists but the revision couldn't be find.\r\n            - [`~utils.EntryNotFoundError`]\r\n                If the repository exists but the entry (e.g. the requested file) couldn't be\r\n                find.\r\n            - [`~utils.BadRequestError`]\r\n                If request failed with a HTTP 400 BadRequest error.\r\n            - [`~utils.HfHubHTTPError`]\r\n                If request failed for a reason not listed above.\r\n    \r\n        </Tip>\r\n        \"\"\"\r\n        try:\r\n>           response.raise_for_status()\r\n\r\n../.local/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:261: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nself = <Response [401]>\r\n\r\n    def raise_for_status(self):\r\n        \"\"\"Raises :class:`HTTPError`, if one occurred.\"\"\"\r\n    \r\n        http_error_msg = \"\"\r\n        if isinstance(self.reason, bytes):\r\n            # We attempt to decode utf-8 first because some servers\r\n            # choose to localize their reason strings. If the string\r\n            # isn't utf-8, we fall back to iso-8859-1 for all other\r\n            # encodings. (See PR #3538)\r\n            try:\r\n                reason = self.reason.decode(\"utf-8\")\r\n            except UnicodeDecodeError:\r\n                reason = self.reason.decode(\"iso-8859-1\")\r\n        else:\r\n            reason = self.reason\r\n    \r\n        if 400 <= self.status_code < 500:\r\n            http_error_msg = (\r\n                f\"{self.status_code} Client Error: {reason} for url: {self.url}\"\r\n            )\r\n    \r\n        elif 500 <= self.status_code < 600:\r\n            http_error_msg = (\r\n                f\"{self.status_code} Server Error: {reason} for url: {self.url}\"\r\n            )\r\n    \r\n        if http_error_msg:\r\n>           raise HTTPError(http_error_msg, response=self)\r\nE           requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/gpt2-small/resolve/main/tokenizer_config.json\r\n\r\n../.local/lib/python3.10/site-packages/requests/models.py:1021: HTTPError\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\npath_or_repo_id = 'gpt2-small', filename = 'tokenizer_config.json'\r\ncache_dir = '/home/v/.cache/huggingface/hub', force_download = False\r\nresume_download = False, proxies = None, token = None, revision = None\r\nlocal_files_only = False, subfolder = '', repo_type = None\r\nuser_agent = 'transformers/4.35.0; python/3.10.12; session_id/8f5ea7012d1949a5bc8b3c81a2fe2d7a; torch/2.1.1'\r\n_raise_exceptions_for_missing_entries = False\r\n_raise_exceptions_for_connection_errors = False, _commit_hash = None\r\ndeprecated_kwargs = {}, use_auth_token = None\r\nfull_filename = 'tokenizer_config.json'\r\n\r\n    def cached_file(\r\n        path_or_repo_id: Union[str, os.PathLike],\r\n        filename: str,\r\n        cache_dir: Optional[Union[str, os.PathLike]] = None,\r\n        force_download: bool = False,\r\n        resume_download: bool = False,\r\n        proxies: Optional[Dict[str, str]] = None,\r\n        token: Optional[Union[bool, str]] = None,\r\n        revision: Optional[str] = None,\r\n        local_files_only: bool = False,\r\n        subfolder: str = \"\",\r\n        repo_type: Optional[str] = None,\r\n        user_agent: Optional[Union[str, Dict[str, str]]] = None,\r\n        _raise_exceptions_for_missing_entries: bool = True,\r\n        _raise_exceptions_for_connection_errors: bool = True,\r\n        _commit_hash: Optional[str] = None,\r\n        **deprecated_kwargs,\r\n    ):\r\n        \"\"\"\r\n        Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\r\n    \r\n        Args:\r\n            path_or_repo_id (`str` or `os.PathLike`):\r\n                This can be either:\r\n    \r\n                - a string, the *model id* of a model repo on huggingface.co.\r\n                - a path to a *directory* potentially containing the file.\r\n            filename (`str`):\r\n                The name of the file to locate in `path_or_repo`.\r\n            cache_dir (`str` or `os.PathLike`, *optional*):\r\n                Path to a directory in which a downloaded pretrained model configuration should be cached if the standard\r\n                cache should not be used.\r\n            force_download (`bool`, *optional*, defaults to `False`):\r\n                Whether or not to force to (re-)download the configuration files and override the cached versions if they\r\n                exist.\r\n            resume_download (`bool`, *optional*, defaults to `False`):\r\n                Whether or not to delete incompletely received file. Attempts to resume the download if such a file exists.\r\n            proxies (`Dict[str, str]`, *optional*):\r\n                A dictionary of proxy servers to use by protocol or endpoint, e.g., `{'http': 'foo.bar:3128',\r\n                'http://hostname': 'foo.bar:4012'}.` The proxies are used on each request.\r\n            token (`str` or *bool*, *optional*):\r\n                The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\r\n                when running `huggingface-cli login` (stored in `~/.huggingface`).\r\n            revision (`str`, *optional*, defaults to `\"main\"`):\r\n                The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\r\n                git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any\r\n                identifier allowed by git.\r\n            local_files_only (`bool`, *optional*, defaults to `False`):\r\n                If `True`, will only try to load the tokenizer configuration from local files.\r\n            subfolder (`str`, *optional*, defaults to `\"\"`):\r\n                In case the relevant files are located inside a subfolder of the model repo on huggingface.co, you can\r\n                specify the folder name here.\r\n            repo_type (`str`, *optional*):\r\n                Specify the repo type (useful when downloading from a space for instance).\r\n    \r\n        <Tip>\r\n    \r\n        Passing `token=True` is required when you want to use a private model.\r\n    \r\n        </Tip>\r\n    \r\n        Returns:\r\n            `Optional[str]`: Returns the resolved file (to the cache folder if downloaded from a repo).\r\n    \r\n        Examples:\r\n    \r\n        ```python\r\n        # Download a model weight from the Hub and cache it.\r\n        model_weights_file = cached_file(\"bert-base-uncased\", \"pytorch_model.bin\")\r\n        ```\"\"\"\r\n        use_auth_token = deprecated_kwargs.pop(\"use_auth_token\", None)\r\n        if use_auth_token is not None:\r\n            warnings.warn(\r\n                \"The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\",\r\n                FutureWarning,\r\n            )\r\n            if token is not None:\r\n                raise ValueError(\"`token` and `use_auth_token` are both specified. Please set only the argument `token`.\")\r\n            token = use_auth_token\r\n    \r\n        # Private arguments\r\n        #     _raise_exceptions_for_missing_entries: if False, do not raise an exception for missing entries but return\r\n        #         None.\r\n        #     _raise_exceptions_for_connection_errors: if False, do not raise an exception for connection errors but return\r\n        #         None.\r\n        #     _commit_hash: passed when we are chaining several calls to various files (e.g. when loading a tokenizer or\r\n        #         a pipeline). If files are cached for this commit hash, avoid calls to head and get from the cache.\r\n        if is_offline_mode() and not local_files_only:\r\n            logger.info(\"Offline mode: forcing local_files_only=True\")\r\n            local_files_only = True\r\n        if subfolder is None:\r\n            subfolder = \"\"\r\n    \r\n        path_or_repo_id = str(path_or_repo_id)\r\n        full_filename = os.path.join(subfolder, filename)\r\n        if os.path.isdir(path_or_repo_id):\r\n            resolved_file = os.path.join(os.path.join(path_or_repo_id, subfolder), filename)\r\n            if not os.path.isfile(resolved_file):\r\n                if _raise_exceptions_for_missing_entries:\r\n                    raise EnvironmentError(\r\n                        f\"{path_or_repo_id} does not appear to have a file named {full_filename}. Checkout \"\r\n                        f\"'https://huggingface.co/{path_or_repo_id}/{revision}' for available files.\"\r\n                    )\r\n                else:\r\n                    return None\r\n            return resolved_file\r\n    \r\n        if cache_dir is None:\r\n            cache_dir = TRANSFORMERS_CACHE\r\n        if isinstance(cache_dir, Path):\r\n            cache_dir = str(cache_dir)\r\n    \r\n        if _commit_hash is not None and not force_download:\r\n            # If the file is cached under that commit hash, we return it directly.\r\n            resolved_file = try_to_load_from_cache(\r\n                path_or_repo_id, full_filename, cache_dir=cache_dir, revision=_commit_hash, repo_type=repo_type\r\n            )\r\n            if resolved_file is not None:\r\n                if resolved_file is not _CACHED_NO_EXIST:\r\n                    return resolved_file\r\n                elif not _raise_exceptions_for_missing_entries:\r\n                    return None\r\n                else:\r\n                    raise EnvironmentError(f\"Could not locate {full_filename} inside {path_or_repo_id}.\")\r\n    \r\n        user_agent = http_user_agent(user_agent)\r\n        try:\r\n            # Load from URL or cache if already cached\r\n>           resolved_file = hf_hub_download(\r\n                path_or_repo_id,\r\n                filename,\r\n                subfolder=None if len(subfolder) == 0 else subfolder,\r\n                repo_type=repo_type,\r\n                revision=revision,\r\n                cache_dir=cache_dir,\r\n                user_agent=user_agent,\r\n                force_download=force_download,\r\n                proxies=proxies,\r\n                resume_download=resume_download,\r\n                token=token,\r\n                local_files_only=local_files_only,\r\n            )\r\n\r\n../.local/lib/python3.10/site-packages/transformers/utils/hub.py:430: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n../.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:118: in _inner_fn\r\n    return fn(*args, **kwargs)\r\n../.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1346: in hf_hub_download\r\n    raise head_call_error\r\n../.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1232: in hf_hub_download\r\n    metadata = get_hf_file_metadata(\r\n../.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:118: in _inner_fn\r\n    return fn(*args, **kwargs)\r\n../.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1608: in get_hf_file_metadata\r\n    hf_raise_for_status(r)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nresponse = <Response [401]>, endpoint_name = None\r\n\r\n    def hf_raise_for_status(response: Response, endpoint_name: Optional[str] = None) -> None:\r\n        \"\"\"\r\n        Internal version of `response.raise_for_status()` that will refine a\r\n        potential HTTPError. Raised exception will be an instance of `HfHubHTTPError`.\r\n    \r\n        This helper is meant to be the unique method to raise_for_status when making a call\r\n        to the Hugging Face Hub.\r\n    \r\n        Example:\r\n        ```py\r\n            import requests\r\n            from huggingface_hub.utils import get_session, hf_raise_for_status, HfHubHTTPError\r\n    \r\n            response = get_session().post(...)\r\n            try:\r\n                hf_raise_for_status(response)\r\n            except HfHubHTTPError as e:\r\n                print(str(e)) # formatted message\r\n                e.request_id, e.server_message # details returned by server\r\n    \r\n                # Complete the error message with additional information once it's raised\r\n                e.append_to_message(\"\\n`create_commit` expects the repository to exist.\")\r\n                raise\r\n        ```\r\n    \r\n        Args:\r\n            response (`Response`):\r\n                Response from the server.\r\n            endpoint_name (`str`, *optional*):\r\n                Name of the endpoint that has been called. If provided, the error message\r\n                will be more complete.\r\n    \r\n        <Tip warning={true}>\r\n    \r\n        Raises when the request has failed:\r\n    \r\n            - [`~utils.RepositoryNotFoundError`]\r\n                If the repository to download from cannot be found. This may be because it\r\n                doesn't exist, because `repo_type` is not set correctly, or because the repo\r\n                is `private` and you do not have access.\r\n            - [`~utils.GatedRepoError`]\r\n                If the repository exists but is gated and the user is not on the authorized\r\n                list.\r\n            - [`~utils.RevisionNotFoundError`]\r\n                If the repository exists but the revision couldn't be find.\r\n            - [`~utils.EntryNotFoundError`]\r\n                If the repository exists but the entry (e.g. the requested file) couldn't be\r\n                find.\r\n            - [`~utils.BadRequestError`]\r\n                If request failed with a HTTP 400 BadRequest error.\r\n            - [`~utils.HfHubHTTPError`]\r\n                If request failed for a reason not listed above.\r\n    \r\n        </Tip>\r\n        \"\"\"\r\n        try:\r\n            response.raise_for_status()\r\n        except HTTPError as e:\r\n            error_code = response.headers.get(\"X-Error-Code\")\r\n    \r\n            if error_code == \"RevisionNotFound\":\r\n                message = f\"{response.status_code} Client Error.\" + \"\\n\\n\" + f\"Revision Not Found for url: {response.url}.\"\r\n                raise RevisionNotFoundError(message, response) from e\r\n    \r\n            elif error_code == \"EntryNotFound\":\r\n                message = f\"{response.status_code} Client Error.\" + \"\\n\\n\" + f\"Entry Not Found for url: {response.url}.\"\r\n                raise EntryNotFoundError(message, response) from e\r\n    \r\n            elif error_code == \"GatedRepo\":\r\n                message = (\r\n                    f\"{response.status_code} Client Error.\" + \"\\n\\n\" + f\"Cannot access gated repo for url {response.url}.\"\r\n                )\r\n                raise GatedRepoError(message, response) from e\r\n    \r\n            elif error_code == \"RepoNotFound\" or response.status_code == 401:\r\n                # 401 is misleading as it is returned for:\r\n                #    - private and gated repos if user is not authenticated\r\n                #    - missing repos\r\n                # => for now, we process them as `RepoNotFound` anyway.\r\n                # See https://gist.github.com/Wauplin/46c27ad266b15998ce56a6603796f0b9\r\n                message = (\r\n                    f\"{response.status_code} Client Error.\"\r\n                    + \"\\n\\n\"\r\n                    + f\"Repository Not Found for url: {response.url}.\"\r\n                    + \"\\nPlease make sure you specified the correct `repo_id` and\"\r\n                    \" `repo_type`.\\nIf you are trying to access a private or gated repo,\"\r\n                    \" make sure you are authenticated.\"\r\n                )\r\n>               raise RepositoryNotFoundError(message, response) from e\r\nE               huggingface_hub.utils._errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-656904d0-2bed13092692d66475f07afe;8eb80fc0-bbca-43ff-a5ce-fb293391ac66)\r\nE               \r\nE               Repository Not Found for url: https://huggingface.co/gpt2-small/resolve/main/tokenizer_config.json.\r\nE               Please make sure you specified the correct `repo_id` and `repo_type`.\r\nE               If you are trying to access a private or gated repo, make sure you are authenticated.\r\nE               Invalid username or password.\r\n\r\n../.local/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:293: RepositoryNotFoundError\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nmock_warning = <MagicMock name='warning' id='140094553120512'>\r\nllm_instance = <swarms.models.huggingface.HuggingfaceLLM object at 0x7f6a21233b80>\r\n\r\n    @patch(\"swarms.models.huggingface.logging.warning\")\r\n    def test_llm_long_input_warning(mock_warning, llm_instance):\r\n        long_input = \"x\" * 10000  # input longer than the typical limit\r\n>       llm_instance.run(long_input)\r\n\r\ntests/models/test_huggingface.py:185: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\nswarms/models/huggingface.py:266: in run\r\n    self.load_model()\r\nswarms/models/huggingface.py:212: in load_model\r\n    self.tokenizer = AutoTokenizer.from_pretrained(\r\n../.local/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:718: in from_pretrained\r\n    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)\r\n../.local/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:550: in get_tokenizer_config\r\n    resolved_config_file = cached_file(\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\npath_or_repo_id = 'gpt2-small', filename = 'tokenizer_config.json'\r\ncache_dir = '/home/v/.cache/huggingface/hub', force_download = False\r\nresume_download = False, proxies = None, token = None, revision = None\r\nlocal_files_only = False, subfolder = '', repo_type = None\r\nuser_agent = 'transformers/4.35.0; python/3.10.12; session_id/8f5ea7012d1949a5bc8b3c81a2fe2d7a; torch/2.1.1'\r\n_raise_exceptions_for_missing_entries = False\r\n_raise_exceptions_for_connection_errors = False, _commit_hash = None\r\ndeprecated_kwargs = {}, use_auth_token = None\r\nfull_filename = 'tokenizer_config.json'\r\n\r\n    def cached_file(\r\n        path_or_repo_id: Union[str, os.PathLike],\r\n        filename: str,\r\n        cache_dir: Optional[Union[str, os.PathLike]] = None,\r\n        force_download: bool = False,\r\n        resume_download: bool = False,\r\n        proxies: Optional[Dict[str, str]] = None,\r\n        token: Optional[Union[bool, str]] = None,\r\n        revision: Optional[str] = None,\r\n        local_files_only: bool = False,\r\n        subfolder: str = \"\",\r\n        repo_type: Optional[str] = None,\r\n        user_agent: Optional[Union[str, Dict[str, str]]] = None,\r\n        _raise_exceptions_for_missing_entries: bool = True,\r\n        _raise_exceptions_for_connection_errors: bool = True,\r\n        _commit_hash: Optional[str] = None,\r\n        **deprecated_kwargs,\r\n    ):\r\n        \"\"\"\r\n        Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\r\n    \r\n        Args:\r\n            path_or_repo_id (`str` or `os.PathLike`):\r\n                This can be either:\r\n    \r\n                - a string, the *model id* of a model repo on huggingface.co.\r\n                - a path to a *directory* potentially containing the file.\r\n            filename (`str`):\r\n                The name of the file to locate in `path_or_repo`.\r\n            cache_dir (`str` or `os.PathLike`, *optional*):\r\n                Path to a directory in which a downloaded pretrained model configuration should be cached if the standard\r\n                cache should not be used.\r\n            force_download (`bool`, *optional*, defaults to `False`):\r\n                Whether or not to force to (re-)download the configuration files and override the cached versions if they\r\n                exist.\r\n            resume_download (`bool`, *optional*, defaults to `False`):\r\n                Whether or not to delete incompletely received file. Attempts to resume the download if such a file exists.\r\n            proxies (`Dict[str, str]`, *optional*):\r\n                A dictionary of proxy servers to use by protocol or endpoint, e.g., `{'http': 'foo.bar:3128',\r\n                'http://hostname': 'foo.bar:4012'}.` The proxies are used on each request.\r\n            token (`str` or *bool*, *optional*):\r\n                The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\r\n                when running `huggingface-cli login` (stored in `~/.huggingface`).\r\n            revision (`str`, *optional*, defaults to `\"main\"`):\r\n                The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\r\n                git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any\r\n                identifier allowed by git.\r\n            local_files_only (`bool`, *optional*, defaults to `False`):\r\n                If `True`, will only try to load the tokenizer configuration from local files.\r\n            subfolder (`str`, *optional*, defaults to `\"\"`):\r\n                In case the relevant files are located inside a subfolder of the model repo on huggingface.co, you can\r\n                specify the folder name here.\r\n            repo_type (`str`, *optional*):\r\n                Specify the repo type (useful when downloading from a space for instance).\r\n    \r\n        <Tip>\r\n    \r\n        Passing `token=True` is required when you want to use a private model.\r\n    \r\n        </Tip>\r\n    \r\n        Returns:\r\n            `Optional[str]`: Returns the resolved file (to the cache folder if downloaded from a repo).\r\n    \r\n        Examples:\r\n    \r\n        ```python\r\n        # Download a model weight from the Hub and cache it.\r\n        model_weights_file = cached_file(\"bert-base-uncased\", \"pytorch_model.bin\")\r\n        ```\"\"\"\r\n        use_auth_token = deprecated_kwargs.pop(\"use_auth_token\", None)\r\n        if use_auth_token is not None:\r\n            warnings.warn(\r\n                \"The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\",\r\n                FutureWarning,\r\n            )\r\n            if token is not None:\r\n                raise ValueError(\"`token` and `use_auth_token` are both specified. Please set only the argument `token`.\")\r\n            token = use_auth_token\r\n    \r\n        # Private arguments\r\n        #     _raise_exceptions_for_missing_entries: if False, do not raise an exception for missing entries but return\r\n        #         None.\r\n        #     _raise_exceptions_for_connection_errors: if False, do not raise an exception for connection errors but return\r\n        #         None.\r\n        #     _commit_hash: passed when we are chaining several calls to various files (e.g. when loading a tokenizer or\r\n        #         a pipeline). If files are cached for this commit hash, avoid calls to head and get from the cache.\r\n        if is_offline_mode() and not local_files_only:\r\n            logger.info(\"Offline mode: forcing local_files_only=True\")\r\n            local_files_only = True\r\n        if subfolder is None:\r\n            subfolder = \"\"\r\n    \r\n        path_or_repo_id = str(path_or_repo_id)\r\n        full_filename = os.path.join(subfolder, filename)\r\n        if os.path.isdir(path_or_repo_id):\r\n            resolved_file = os.path.join(os.path.join(path_or_repo_id, subfolder), filename)\r\n            if not os.path.isfile(resolved_file):\r\n                if _raise_exceptions_for_missing_entries:\r\n                    raise EnvironmentError(\r\n                        f\"{path_or_repo_id} does not appear to have a file named {full_filename}. Checkout \"\r\n                        f\"'https://huggingface.co/{path_or_repo_id}/{revision}' for available files.\"\r\n                    )\r\n                else:\r\n                    return None\r\n            return resolved_file\r\n    \r\n        if cache_dir is None:\r\n            cache_dir = TRANSFORMERS_CACHE\r\n        if isinstance(cache_dir, Path):\r\n            cache_dir = str(cache_dir)\r\n    \r\n        if _commit_hash is not None and not force_download:\r\n            # If the file is cached under that commit hash, we return it directly.\r\n            resolved_file = try_to_load_from_cache(\r\n                path_or_repo_id, full_filename, cache_dir=cache_dir, revision=_commit_hash, repo_type=repo_type\r\n            )\r\n            if resolved_file is not None:\r\n                if resolved_file is not _CACHED_NO_EXIST:\r\n                    return resolved_file\r\n                elif not _raise_exceptions_for_missing_entries:\r\n                    return None\r\n                else:\r\n                    raise EnvironmentError(f\"Could not locate {full_filename} inside {path_or_repo_id}.\")\r\n    \r\n        user_agent = http_user_agent(user_agent)\r\n        try:\r\n            # Load from URL or cache if already cached\r\n            resolved_file = hf_hub_download(\r\n                path_or_repo_id,\r\n                filename,\r\n                subfolder=None if len(subfolder) == 0 else subfolder,\r\n                repo_type=repo_type,\r\n                revision=revision,\r\n                cache_dir=cache_dir,\r\n                user_agent=user_agent,\r\n                force_download=force_download,\r\n                proxies=proxies,\r\n                resume_download=resume_download,\r\n                token=token,\r\n                local_files_only=local_files_only,\r\n            )\r\n        except GatedRepoError as e:\r\n            raise EnvironmentError(\r\n                \"You are trying to access a gated repo.\\nMake sure to request access at \"\r\n                f\"https://huggingface.co/{path_or_repo_id} and pass a token having permission to this repo either \"\r\n                \"by logging in with `huggingface-cli login` or by passing `token=<your_token>`.\"\r\n            ) from e\r\n        except RepositoryNotFoundError as e:\r\n>           raise EnvironmentError(\r\n                f\"{path_or_repo_id} is not a local folder and is not a valid model identifier \"\r\n                \"listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token \"\r\n                \"having permission to this repo either by logging in with `huggingface-cli login` or by passing \"\r\n                \"`token=<your_token>`\"\r\n            ) from e\r\nE           OSError: gpt2-small is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\r\nE           If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\r\n\r\n../.local/lib/python3.10/site-packages/transformers/utils/hub.py:451: OSError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-30T22:50:46Z",
      "updated_at": "2025-03-20T16:24:26Z",
      "closed_at": "2023-12-05T09:22:05Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/228/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/228",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/228",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:39.652069",
      "comments": []
    },
    {
      "issue_number": 227,
      "title": "[BUG] ModuleNotFoundError: No module named 'swarms.models.huggingface.HuggingfaceLLM'; 'swarms.models.huggingface' is not a package",
      "body": "/home/v/swarms/tests/models/test_huggingface.py::test_llm_run_model_exception failed: args = ()\r\nkeywargs = {'llm_instance': <swarms.models.huggingface.HuggingfaceLLM object at 0x7f6a5867f0a0>}\r\n\r\n    @wraps(func)\r\n    def patched(*args, **keywargs):\r\n>       with self.decoration_helper(patched,\r\n                                    args,\r\n                                    keywargs) as (newargs, newkeywargs):\r\n\r\n/usr/lib/python3.10/unittest/mock.py:1376: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n/usr/lib/python3.10/contextlib.py:135: in __enter__\r\n    return next(self.gen)\r\n/usr/lib/python3.10/unittest/mock.py:1358: in decoration_helper\r\n    arg = exit_stack.enter_context(patching)\r\n/usr/lib/python3.10/contextlib.py:492: in enter_context\r\n    result = _cm_type.__enter__(cm)\r\n/usr/lib/python3.10/unittest/mock.py:1431: in __enter__\r\n    self.target = self.getter()\r\n/usr/lib/python3.10/unittest/mock.py:1618: in <lambda>\r\n    getter = lambda: _importer(target)\r\n/usr/lib/python3.10/unittest/mock.py:1261: in _importer\r\n    thing = _dot_lookup(thing, comp, import_path)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nthing = <class 'swarms.models.huggingface.HuggingfaceLLM'>, comp = '_model'\r\nimport_path = 'swarms.models.huggingface.HuggingfaceLLM._model'\r\n\r\n    def _dot_lookup(thing, comp, import_path):\r\n        try:\r\n            return getattr(thing, comp)\r\n        except AttributeError:\r\n>           __import__(import_path)\r\nE           ModuleNotFoundError: No module named 'swarms.models.huggingface.HuggingfaceLLM'; 'swarms.models.huggingface' is not a package\r\n\r\n/usr/lib/python3.10/unittest/mock.py:1250: ModuleNotFoundError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-30T22:49:31Z",
      "updated_at": "2025-03-20T16:24:26Z",
      "closed_at": "2023-12-06T04:02:27Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/227/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/227",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/227",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:39.652088",
      "comments": []
    },
    {
      "issue_number": 226,
      "title": "[BUG]  AttributeError: <class 'swarms.models.huggingface.HuggingfaceLLM'> does not have the attribute '_download_model'",
      "body": "/home/v/swarms/tests/models/test_huggingface.py::test_llm_model_download_progress failed: args = ()\r\nkeywargs = {'llm_instance': <swarms.models.huggingface.HuggingfaceLLM object at 0x7f6a23e39510>}\r\n\r\n    @wraps(func)\r\n    def patched(*args, **keywargs):\r\n>       with self.decoration_helper(patched,\r\n                                    args,\r\n                                    keywargs) as (newargs, newkeywargs):\r\n\r\n/usr/lib/python3.10/unittest/mock.py:1376: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n/usr/lib/python3.10/contextlib.py:135: in __enter__\r\n    return next(self.gen)\r\n/usr/lib/python3.10/unittest/mock.py:1358: in decoration_helper\r\n    arg = exit_stack.enter_context(patching)\r\n/usr/lib/python3.10/contextlib.py:492: in enter_context\r\n    result = _cm_type.__enter__(cm)\r\n/usr/lib/python3.10/unittest/mock.py:1447: in __enter__\r\n    original, local = self.get_original()\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nself = <unittest.mock._patch object at 0x7f6a7a1fa980>\r\n\r\n    def get_original(self):\r\n        target = self.getter()\r\n        name = self.attribute\r\n    \r\n        original = DEFAULT\r\n        local = False\r\n    \r\n        try:\r\n            original = target.__dict__[name]\r\n        except (AttributeError, KeyError):\r\n            original = getattr(target, name, DEFAULT)\r\n        else:\r\n            local = True\r\n    \r\n        if name in _builtins and isinstance(target, ModuleType):\r\n            self.create = True\r\n    \r\n        if not self.create and original is DEFAULT:\r\n>           raise AttributeError(\r\n                \"%s does not have the attribute %r\" % (target, name)\r\n            )\r\nE           AttributeError: <class 'swarms.models.huggingface.HuggingfaceLLM'> does not have the attribute '_download_model'\r\n\r\n/usr/lib/python3.10/unittest/mock.py:1420: AttributeError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-30T22:41:29Z",
      "updated_at": "2025-03-20T16:24:26Z",
      "closed_at": "2023-12-05T19:09:01Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/226/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/226",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/226",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:39.652094",
      "comments": []
    },
    {
      "issue_number": 225,
      "title": "[BUG] AttributeError: 'str' object has no attribute 'to'",
      "body": "/home/v/swarms/tests/models/test_huggingface.py::test_llm_run failed: mock_model = <MagicMock name='from_pretrained' id='140094553113168'>\r\nmock_tokenizer = <MagicMock name='from_pretrained' id='140094553122288'>\r\nllm_instance = <swarms.models.huggingface.HuggingfaceLLM object at 0x7f6a4e12d7b0>\r\n\r\n    @patch(\"swarms.models.huggingface.AutoTokenizer.from_pretrained\")\r\n    @patch(\r\n        \"swarms.models.huggingface.AutoModelForCausalLM.from_pretrained\"\r\n    )\r\n    def test_llm_run(mock_model, mock_tokenizer, llm_instance):\r\n        mock_model.return_value.generate.return_value = \"mocked output\"\r\n        mock_tokenizer.return_value.encode.return_value = \"mocked input\"\r\n>       result = llm_instance.run(\"test task\")\r\n\r\ntests/models/test_huggingface.py:47: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nself = <swarms.models.huggingface.HuggingfaceLLM object at 0x7f6a4e12d7b0>\r\ntask = 'test task'\r\n\r\n    def run(self, task: str):\r\n        \"\"\"\r\n        Generate a response based on the prompt text.\r\n    \r\n        Args:\r\n        - task (str): Text to prompt the model.\r\n        - max_length (int): Maximum length of the response.\r\n    \r\n        Returns:\r\n        - Generated text (str).\r\n        \"\"\"\r\n        self.load_model()\r\n    \r\n        max_length = self.max_length\r\n    \r\n        self.print_dashboard(task)\r\n    \r\n        try:\r\n            inputs = self.tokenizer.encode(\r\n                task, return_tensors=\"pt\"\r\n>           ).to(self.device)\r\nE           AttributeError: 'str' object has no attribute 'to'\r\n\r\nswarms/models/huggingface.py:275: AttributeError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-30T22:40:48Z",
      "updated_at": "2025-03-20T16:24:26Z",
      "closed_at": "2023-12-05T18:58:10Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/225/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/225",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/225",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:39.652116",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@vyomakesh09 removed the .to(self.device)",
          "created_at": "2023-12-05T18:58:10Z"
        }
      ]
    },
    {
      "issue_number": 224,
      "title": "[BUG] AttributeError: 'NoneType' object has no attribute 'to'",
      "body": "/home/v/swarms/tests/models/test_huggingface.py::test_llm_set_device[cpu] failed: llm_instance = <swarms.models.huggingface.HuggingfaceLLM object at 0x7f6a4e12fb20>\r\ndevice = 'cpu'\r\n\r\n    @pytest.mark.parametrize(\"device\", [\"cpu\", \"cuda\"])\r\n    def test_llm_set_device(llm_instance, device):\r\n>       llm_instance.set_device(device)\r\n\r\ntests/models/test_huggingface.py:29: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nself = <swarms.models.huggingface.HuggingfaceLLM object at 0x7f6a4e12fb20>\r\ndevice = 'cpu'\r\n\r\n    def set_device(self, device):\r\n        \"\"\"\r\n        Changes the device used for inference.\r\n    \r\n        Parameters\r\n        ----------\r\n            device : str\r\n                The new device to use for inference.\r\n        \"\"\"\r\n        self.device = device\r\n>       self.model.to(self.device)\r\nE       AttributeError: 'NoneType' object has no attribute 'to'\r\n\r\nswarms/models/huggingface.py:454: AttributeError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-30T22:40:18Z",
      "updated_at": "2025-03-20T16:24:26Z",
      "closed_at": "2023-12-05T18:59:34Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/224/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/224",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/224",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:39.812453",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@vyomakesh09 I have fixed this by adding checks",
          "created_at": "2023-12-05T18:59:34Z"
        }
      ]
    },
    {
      "issue_number": 223,
      "title": "[BUG] KeyError: 'choices'",
      "body": "/home/v/swarms/tests/models/test_gpt4_vision_api.py::test_run_response_error failed: vision_api = <swarms.models.gpt4_vision_api.GPT4VisionAPI object at 0x7f6a5869cbe0>\r\n\r\n    def test_run_response_error(vision_api):\r\n        expected_response = {\"error\": \"Model Error\"}\r\n        with patch(\r\n            \"requests.post\",\r\n            return_value=Mock(json=lambda: expected_response),\r\n        ) as mock_post:\r\n            with pytest.raises(RuntimeError):\r\n>               vision_api.run(\"What is this?\", img)\r\n\r\ntests/models/test_gpt4_vision_api.py:65: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\nswarms/models/gpt4_vision_api.py:174: in run\r\n    raise error\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nself = <swarms.models.gpt4_vision_api.GPT4VisionAPI object at 0x7f6a5869cbe0>\r\ntask = 'What is this?', img = 'images/swarms.jpeg', args = (), kwargs = {}\r\nbase64_image = '/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoK...AA5+i/5Ldz/i+/0e/0T7/yhB6D/wD4AEVC6L/WhDNn6uzTMEItfn+7z/KifrXhf3/o2qE8h/dSFBfo/qTJk/y+b7/w/wB/+Z5/V5/d8/wU/tj39PMOZ//Z'\r\nheaders = {'Authorization': 'Bearer None', 'Content-Type': 'application/json'}\r\npayload = {'max_tokens': 300, 'messages': [{'content': ['\\nYou are an multi-modal autonomous agent. You are given a task and an ...fo/qTJk/y+b7/w/wB/+Z5/V5/d8/wU/tj39PMOZ//Z'}, 'type': 'image_url'}], 'role': 'user'}], 'model': 'gpt-4-vision-preview'}\r\nresponse = <Mock id='140094726587728'>, out = {'error': 'Model Error'}\r\n\r\n    def run(\r\n        self,\r\n        task: Optional[str] = None,\r\n        img: Optional[str] = None,\r\n        *args,\r\n        **kwargs,\r\n    ):\r\n        \"\"\"Run the model.\"\"\"\r\n        try:\r\n            base64_image = self.encode_image(img)\r\n            headers = {\r\n                \"Content-Type\": \"application/json\",\r\n                \"Authorization\": f\"Bearer {openai_api_key}\",\r\n            }\r\n            payload = {\r\n                \"model\": self.model_name,\r\n                \"messages\": [\r\n                    {\r\n                        \"role\": \"system\",\r\n                        \"content\": [self.system_prompt],\r\n                    },\r\n                    {\r\n                        \"role\": \"user\",\r\n                        \"content\": [\r\n                            {\"type\": \"text\", \"text\": task},\r\n                            {\r\n                                \"type\": \"image_url\",\r\n                                \"image_url\": {\r\n                                    \"url\": f\"data:image/jpeg;base64,{base64_image}\"\r\n                                },\r\n                            },\r\n                        ],\r\n                    },\r\n                ],\r\n                \"max_tokens\": self.max_tokens,\r\n            }\r\n            response = requests.post(\r\n                self.openai_proxy,\r\n                headers=headers,\r\n                json=payload,\r\n            )\r\n    \r\n            out = response.json()\r\n>           content = out[\"choices\"][0][\"message\"][\"content\"]\r\nE           KeyError: 'choices'\r\n\r\nswarms/models/gpt4_vision_api.py:159: KeyError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-30T22:39:00Z",
      "updated_at": "2025-03-20T16:24:26Z",
      "closed_at": "2023-12-05T07:03:19Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/223/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/223",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/223",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:40.003847",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@vyomakesh09 this has been patched with the latest GPT4Vision api",
          "created_at": "2023-12-05T07:03:19Z"
        }
      ]
    },
    {
      "issue_number": 206,
      "title": "[BUG] pydantic.errors.PydanticUserError:",
      "body": "v@v-System-Product-Name:~/swarms$ /bin/python3 /home/v/swarms/sequential_workflow_example.py\r\nTraceback (most recent call last):\r\n  File \"/home/v/swarms/sequential_workflow_example.py\", line 1, in <module>\r\n    from swarms.models import OpenAIChat, BioGPT, Anthropic\r\n  File \"/home/v/swarms/swarms/__init__.py\", line 6, in <module>\r\n    from swarms.swarms import *  # noqa: E402, F403\r\n  File \"/home/v/swarms/swarms/swarms/__init__.py\", line 2, in <module>\r\n    from swarms.structs.autoscaler import AutoScaler\r\n  File \"/home/v/swarms/swarms/structs/__init__.py\", line 1, in <module>\r\n    from swarms.structs.flow import Flow\r\n  File \"/home/v/swarms/swarms/structs/flow.py\", line 12, in <module>\r\n    from swarms.tools.tool import BaseTool\r\n  File \"/home/v/swarms/swarms/tools/tool.py\", line 120, in <module>\r\n    class BaseTool(RunnableSerializable[Union[str, Dict], Any]):\r\n  File \"/home/v/swarms/swarms/tools/tool.py\", line 271, in BaseTool\r\n    @root_validator()\r\n  File \"/home/v/.local/lib/python3.10/site-packages/pydantic/deprecated/class_validators.py\", line 237, in root_validator\r\n    raise PydanticUserError(\r\npydantic.errors.PydanticUserError: If you use `@root_validator` with pre=False (the default) you MUST specify `skip_on_failure=True`. Note that `@root_validator` is deprecated and should be replaced with `@model_validator`.\r\n\r\nFor further information visit https://errors.pydantic.dev/2.5/u/root-validator-pre-skip",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-27T20:06:12Z",
      "updated_at": "2025-03-20T16:24:26Z",
      "closed_at": "2024-01-03T18:04:05Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/206/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/206",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/206",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:40.336460",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "Checked out an up to date version of the repo, built a container from the Dockerfile.\r\n```\r\nroot@485bab1a3ef0:/usr/src/swarm_cloud#  python example.py \r\nTraceback (most recent call last):\r\n  File \"/usr/src/swarm_cloud/example.py\", line 6, in <module>\r\n    from swarms.models import OpenAIChat\r\n  File",
          "created_at": "2023-11-27T20:33:05Z"
        },
        {
          "author": "evelynmitchell",
          "body": "This can be closed.",
          "created_at": "2024-01-01T00:24:58Z"
        }
      ]
    },
    {
      "issue_number": 222,
      "title": "[BUG] KeyError: 'message'",
      "body": "/home/v/swarms/tests/models/test_gpt4_vision_api.py::test_run_success failed: vision_api = <swarms.models.gpt4_vision_api.GPT4VisionAPI object at 0x7f6a4d8116f0>\r\n\r\n    def test_run_success(vision_api):\r\n        expected_response = {\r\n            \"choices\": [{\"text\": \"This is the model's response.\"}]\r\n        }\r\n        with patch(\r\n            \"requests.post\",\r\n            return_value=Mock(json=lambda: expected_response),\r\n        ) as mock_post:\r\n>           result = vision_api.run(\"What is this?\", img)\r\n\r\ntests/models/test_gpt4_vision_api.py:45: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\nswarms/models/gpt4_vision_api.py:174: in run\r\n    raise error\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nself = <swarms.models.gpt4_vision_api.GPT4VisionAPI object at 0x7f6a4d8116f0>\r\ntask = 'What is this?', img = 'images/swarms.jpeg', args = (), kwargs = {}\r\nbase64_image = '/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoK...AA5+i/5Ldz/i+/0e/0T7/yhB6D/wD4AEVC6L/WhDNn6uzTMEItfn+7z/KifrXhf3/o2qE8h/dSFBfo/qTJk/y+b7/w/wB/+Z5/V5/d8/wU/tj39PMOZ//Z'\r\nheaders = {'Authorization': 'Bearer None', 'Content-Type': 'application/json'}\r\npayload = {'max_tokens': 300, 'messages': [{'content': ['\\nYou are an multi-modal autonomous agent. You are given a task and an ...fo/qTJk/y+b7/w/wB/+Z5/V5/d8/wU/tj39PMOZ//Z'}, 'type': 'image_url'}], 'role': 'user'}], 'model': 'gpt-4-vision-preview'}\r\nresponse = <Mock id='140094552986848'>\r\nout = {'choices': [{'text': \"This is the model's response.\"}]}\r\n\r\n    def run(\r\n        self,\r\n        task: Optional[str] = None,\r\n        img: Optional[str] = None,\r\n        *args,\r\n        **kwargs,\r\n    ):\r\n        \"\"\"Run the model.\"\"\"\r\n        try:\r\n            base64_image = self.encode_image(img)\r\n            headers = {\r\n                \"Content-Type\": \"application/json\",\r\n                \"Authorization\": f\"Bearer {openai_api_key}\",\r\n            }\r\n            payload = {\r\n                \"model\": self.model_name,\r\n                \"messages\": [\r\n                    {\r\n                        \"role\": \"system\",\r\n                        \"content\": [self.system_prompt],\r\n                    },\r\n                    {\r\n                        \"role\": \"user\",\r\n                        \"content\": [\r\n                            {\"type\": \"text\", \"text\": task},\r\n                            {\r\n                                \"type\": \"image_url\",\r\n                                \"image_url\": {\r\n                                    \"url\": f\"data:image/jpeg;base64,{base64_image}\"\r\n                                },\r\n                            },\r\n                        ],\r\n                    },\r\n                ],\r\n                \"max_tokens\": self.max_tokens,\r\n            }\r\n            response = requests.post(\r\n                self.openai_proxy,\r\n                headers=headers,\r\n                json=payload,\r\n            )\r\n    \r\n            out = response.json()\r\n>           content = out[\"choices\"][0][\"message\"][\"content\"]\r\nE           KeyError: 'message'\r\n\r\nswarms/models/gpt4_vision_api.py:159: KeyError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-30T22:38:23Z",
      "updated_at": "2025-03-20T16:24:25Z",
      "closed_at": "2023-12-06T04:54:50Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/222/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/222",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/222",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:42.396839",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@vyomakesh09 this error has been eliminated",
          "created_at": "2023-12-06T04:54:50Z"
        }
      ]
    },
    {
      "issue_number": 221,
      "title": "[BUG]  AssertionError: assert 'Starting real-time transcription...' in 'The audio file was not found.\\n' E   +  where 'The audio file was not found.\\n' = CaptureResult(out='The audio file was not found.\\n', err='').out",
      "body": "/home/v/swarms/tests/models/test_distill_whisper.py::test_real_time_transcription failed: whisper_model = <swarms.models.distilled_whisperx.DistilWhisperModel object at 0x7f6a4e11bd00>\r\naudio_file_path = 'path/to/valid_audio.mp3'\r\ncapsys = <_pytest.capture.CaptureFixture object at 0x7f6a4e1e4400>\r\n\r\n    def test_real_time_transcription(\r\n        whisper_model, audio_file_path, capsys\r\n    ):\r\n        whisper_model.real_time_transcribe(\r\n            audio_file_path, chunk_duration=1\r\n        )\r\n        captured = capsys.readouterr()\r\n>       assert \"Starting real-time transcription...\" in captured.out\r\nE      ```\r\n AssertionError: assert 'Starting real-time transcription...' in 'The audio file was not found.\\n'\r\nE        +  where 'The audio file was not found.\\n' = CaptureResult(out='The audio file was not found.\\n', err='').out\r\n\r\n```\r\ntests/models/test_distill_whisper.py:290: AssertionError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-30T22:36:46Z",
      "updated_at": "2025-03-20T16:24:25Z",
      "closed_at": "2024-01-01T07:55:18Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/221/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/221",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/221",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:42.567918",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "This can be closed.",
          "created_at": "2024-01-01T00:27:57Z"
        }
      ]
    },
    {
      "issue_number": 220,
      "title": "[BUG]    ValueError: We expect a numpy ndarray as input, got `<class 'torch.Tensor'>`",
      "body": "/home/v/swarms/tests/models/test_distill_whisper.py::test_transcribe_with_audio_dict failed: whisper_model = <swarms.models.distilled_whisperx.DistilWhisperModel object at 0x7f6a4e11bd00>\r\naudio_dict = {}\r\n\r\n    def test_transcribe_with_audio_dict(whisper_model, audio_dict):\r\n>       transcription = whisper_model.transcribe(audio_dict)\r\n\r\ntests/models/test_distill_whisper.py:253: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\nswarms/models/distilled_whisperx.py:105: in transcribe\r\n    return pipe(inputs)[\"text\"]\r\n../.local/lib/python3.10/site-packages/transformers/pipelines/automatic_speech_recognition.py:357: in __call__\r\n    return super().__call__(inputs, **kwargs)\r\n../.local/lib/python3.10/site-packages/transformers/pipelines/base.py:1132: in __call__\r\n    return next(\r\n../.local/lib/python3.10/site-packages/transformers/pipelines/pt_utils.py:124: in __next__\r\n    item = next(self.iterator)\r\n../.local/lib/python3.10/site-packages/transformers/pipelines/pt_utils.py:266: in __next__\r\n    processed = self.infer(next(self.iterator), **self.params)\r\n../.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630: in __next__\r\n    data = self._next_data()\r\n../.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674: in _next_data\r\n    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\r\n../.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:32: in fetch\r\n    data.append(next(self.dataset_iter))\r\n../.local/lib/python3.10/site-packages/transformers/pipelines/pt_utils.py:183: in __next__\r\n    processed = next(self.subiterator)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nself = <transformers.pipelines.automatic_speech_recognition.AutomaticSpeechRecognitionPipeline object at 0x7f6a4e16d990>\r\ninputs = tensor([[-1.1103,  0.8967, -1.4661,  ..., -1.2967, -0.6640,  0.1096]])\r\nchunk_length_s = 0, stride_length_s = None\r\n\r\n    def preprocess(self, inputs, chunk_length_s=0, stride_length_s=None):\r\n        if isinstance(inputs, str):\r\n            if inputs.startswith(\"http://\") or inputs.startswith(\"https://\"):\r\n                # We need to actually check for a real protocol, otherwise it's impossible to use a local file\r\n                # like http_huggingface_co.png\r\n                inputs = requests.get(inputs).content\r\n            else:\r\n                with open(inputs, \"rb\") as f:\r\n                    inputs = f.read()\r\n    \r\n        if isinstance(inputs, bytes):\r\n            inputs = ffmpeg_read(inputs, self.feature_extractor.sampling_rate)\r\n    \r\n        stride = None\r\n        extra = {}\r\n        if isinstance(inputs, dict):\r\n            stride = inputs.pop(\"stride\", None)\r\n            # Accepting `\"array\"` which is the key defined in `datasets` for\r\n            # better integration\r\n            if not (\"sampling_rate\" in inputs and (\"raw\" in inputs or \"array\" in inputs)):\r\n                raise ValueError(\r\n                    \"When passing a dictionary to AutomaticSpeechRecognitionPipeline, the dict needs to contain a \"\r\n                    '\"raw\" key containing the numpy array representing the audio and a \"sampling_rate\" key, '\r\n                    \"containing the sampling_rate associated with that array\"\r\n                )\r\n    \r\n            _inputs = inputs.pop(\"raw\", None)\r\n            if _inputs is None:\r\n                # Remove path which will not be used from `datasets`.\r\n                inputs.pop(\"path\", None)\r\n                _inputs = inputs.pop(\"array\", None)\r\n            in_sampling_rate = inputs.pop(\"sampling_rate\")\r\n            extra = inputs\r\n            inputs = _inputs\r\n            if in_sampling_rate != self.feature_extractor.sampling_rate:\r\n                if is_torchaudio_available():\r\n                    from torchaudio import functional as F\r\n                else:\r\n                    raise ImportError(\r\n                        \"torchaudio is required to resample audio samples in AutomaticSpeechRecognitionPipeline. \"\r\n                        \"The torchaudio package can be installed through: `pip install torchaudio`.\"\r\n                    )\r\n    \r\n                inputs = F.resample(\r\n                    torch.from_numpy(inputs), in_sampling_rate, self.feature_extractor.sampling_rate\r\n                ).numpy()\r\n                ratio = self.feature_extractor.sampling_rate / in_sampling_rate\r\n            else:\r\n                ratio = 1\r\n            if stride is not None:\r\n                if stride[0] + stride[1] > inputs.shape[0]:\r\n                    raise ValueError(\"Stride is too large for input\")\r\n    \r\n                # Stride needs to get the chunk length here, it's going to get\r\n                # swallowed by the `feature_extractor` later, and then batching\r\n                # can add extra data in the inputs, so we need to keep track\r\n                # of the original length in the stride so we can cut properly.\r\n                stride = (inputs.shape[0], int(round(stride[0] * ratio)), int(round(stride[1] * ratio)))\r\n        if not isinstance(inputs, np.ndarray):\r\n>           raise ValueError(f\"We expect a numpy ndarray as input, got `{type(inputs)}`\")\r\nE           ValueError: We expect a numpy ndarray as input, got `<class 'torch.Tensor'>`\r\n\r\n../.local/lib/python3.10/site-packages/transformers/pipelines/automatic_speech_recognition.py:482: ValueError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-30T22:35:38Z",
      "updated_at": "2025-03-20T16:24:25Z",
      "closed_at": "2024-01-01T07:34:56Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/220/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/220",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/220",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:42.765202",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "This can be closed.",
          "created_at": "2024-01-01T00:27:03Z"
        }
      ]
    },
    {
      "issue_number": 219,
      "title": "[BUG] tests/models/test_distill_whisper.py:118: AssertionError",
      "body": "/home/v/swarms/tests/models/test_distill_whisper.py::test_real_time_transcribe failed: distil_whisper_model = <swarms.models.distilled_whisperx.DistilWhisperModel object at 0x7f6a4d814cd0>\r\ncapsys = <_pytest.capture.CaptureFixture object at 0x7f6a4e11bf10>\r\n\r\n    def test_real_time_transcribe(distil_whisper_model, capsys):\r\n        test_data = np.random.rand(\r\n            16000 * 5\r\n        )  # Simulated audio data (5 seconds)\r\n        with tempfile.NamedTemporaryFile(\r\n            suffix=\".wav\", delete=False\r\n        ) as audio_file:\r\n            audio_file_path = create_audio_file(\r\n                test_data, 16000, audio_file.name\r\n            )\r\n    \r\n            distil_whisper_model.real_time_transcribe(\r\n                audio_file_path, chunk_duration=1\r\n            )\r\n    \r\n            os.remove(audio_file_path)\r\n    \r\n        captured = capsys.readouterr()\r\n>       assert \"Starting real-time transcription...\" in captured.out\r\nE       assert 'Starting real-time transcription...' in \"An error occurred during transcription: 'WhisperProcessor' object has no attribute 'audio_file_to_array'\\n\"\r\nE        +  where \"An error occurred during transcription: 'WhisperProcessor' object has no attribute 'audio_file_to_array'\\n\" = CaptureResult(out=\"An error occurred during transcription: 'WhisperProcessor' object has no attribute 'audio_file_to_array'\\n\", err='').out\r\n\r\ntests/models/test_distill_whisper.py:118: AssertionError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-30T22:34:52Z",
      "updated_at": "2025-03-20T16:24:25Z",
      "closed_at": "2024-01-01T07:35:15Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/219/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/219",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/219",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:42.950597",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "I've fixed this, it can be closed.",
          "created_at": "2024-01-01T00:25:32Z"
        },
        {
          "author": "evelynmitchell",
          "body": "This can be closed.",
          "created_at": "2024-01-01T00:26:33Z"
        }
      ]
    },
    {
      "issue_number": 218,
      "title": "[BUG]  TypeError: PgVectorVectorStore.__init__() missing 1 required positional argument: 'embedding_driver'",
      "body": "/home/v/swarms/tests/memory/test_pg.py::test_init failed: def test_init():\r\n        with patch(\"sqlalchemy.create_engine\") as MockEngine:\r\n>           store = PgVectorVectorStore(\r\n                connection_string=PSG_CONNECTION_STRING,\r\n                table_name=\"test\",\r\n            )\r\nE           TypeError: PgVectorVectorStore.__init__() missing 1 required positional argument: 'embedding_driver'\r\n\r\ntests/memory/test_pg.py:15: TypeError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-30T22:30:14Z",
      "updated_at": "2025-03-20T16:24:25Z",
      "closed_at": "2023-12-05T19:22:24Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/218/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/218",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/218",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:43.185249",
      "comments": []
    },
    {
      "issue_number": 217,
      "title": "[BUG] RuntimeError: Model config for microsoft-BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 not found.",
      "body": "/home/v/swarms/tests/models/test_bioclip.py::test_clip_initialization failed with error: Test failed with exception\r\n@pytest.fixture\r\n    def clip_instance():\r\n>       return BioClip(\r\n            \"microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224\"\r\n        )\r\ntests/models/test_bioclip.py:17: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\nswarms/models/bioclip.py:98: in __init__\r\n    ) = open_clip.create_model_and_transforms(model_path)\r\n../.local/lib/python3.10/site-packages/open_clip/factory.py:324: in create_model_and_transforms\r\n    model = create_model(\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\nmodel_name = 'microsoft-BiomedCLIP-PubMedBERT_256-vit_base_patch16_224'\r\npretrained = None, precision = 'fp32', device = device(type='cpu'), jit = False\r\nforce_quick_gelu = False, force_custom_text = False, force_patch_dropout = None\r\nforce_image_size = None, pretrained_image = False, pretrained_hf = True\r\ncache_dir = None, output_dict = None, require_pretrained = False\r\nmodel_kwargs = {}, has_hf_hub_prefix = False, checkpoint_path = None\r\npretrained_cfg = {}\r\n    def create_model(\r\n            model_name: str,\r\n            pretrained: Optional[str] = None,\r\n            precision: str = 'fp32',\r\n            device: Union[str, torch.device] = 'cpu',\r\n            jit: bool = False,\r\n            force_quick_gelu: bool = False,\r\n            force_custom_text: bool = False,\r\n            force_patch_dropout: Optional[float] = None,\r\n            force_image_size: Optional[Union[int, Tuple[int, int]]] = None,\r\n            pretrained_image: bool = False,\r\n            pretrained_hf: bool = True,\r\n            cache_dir: Optional[str] = None,\r\n            output_dict: Optional[bool] = None,\r\n            require_pretrained: bool = False,\r\n            **model_kwargs,\r\n    ):\r\n        has_hf_hub_prefix = model_name.startswith(HF_HUB_PREFIX)\r\n        if has_hf_hub_prefix:\r\n            model_id = model_name[len(HF_HUB_PREFIX):]\r\n            checkpoint_path = download_pretrained_from_hf(model_id, cache_dir=cache_dir)\r\n            config_path = download_pretrained_from_hf(model_id, filename='open_clip_config.json', cache_dir=cache_dir)\r\n    \r\n            with open(config_path, 'r', encoding='utf-8') as f:\r\n                config = json.load(f)\r\n            pretrained_cfg = config['preprocess_cfg']\r\n            model_cfg = config['model_cfg']\r\n        else:\r\n            model_name = model_name.replace('/', '-')  # for callers using old naming with / in ViT names\r\n            checkpoint_path = None\r\n            pretrained_cfg = {}\r\n            model_cfg = None\r\n    \r\n        if isinstance(device, str):\r\n            device = torch.device(device)\r\n    \r\n        if pretrained and pretrained.lower() == 'openai':\r\n            logging.info(f'Loading pretrained {model_name} from OpenAI.')\r\n            model = load_openai_model(\r\n                model_name,\r\n                precision=precision,\r\n                device=device,\r\n                cache_dir=cache_dir,\r\n            )\r\n        else:\r\n            model_cfg = model_cfg or get_model_config(model_name)\r\n            if model_cfg is not None:\r\n                logging.info(f'Loaded {model_name} model config.')\r\n            else:\r\n                logging.error(f'Model config for {model_name} not found; available models {list_models()}.')\r\n>               raise RuntimeError(f'Model config for {model_name} not found.')\r\nE               RuntimeError: Model config for microsoft-BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 not found.\r\n../.local/lib/python3.10/site-packages/open_clip/factory.py:166: RuntimeError",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-30T22:28:35Z",
      "updated_at": "2025-03-20T16:24:25Z",
      "closed_at": "2023-12-25T23:11:39Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/217/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/217",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/217",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:43.185272",
      "comments": []
    },
    {
      "issue_number": 208,
      "title": "[BUG] after pydantic tool fix, pickle class error looks to be from flow",
      "body": "After making the pydantic fix in tool.py of my last pr:\r\nI may be out of sync, this error refers to flows.\r\n```\r\nroot@d6ca36505305:/usr/src/swarm_cloud# python example.py\r\nTraceback (most recent call last):\r\n  File \"/usr/src/swarm_cloud/example.py\", line 6, in <module>\r\n    from swarms.models import OpenAIChat\r\n  File \"/usr/src/swarm_cloud/swarms/__init__.py\", line 6, in <module>\r\n    from swarms.swarms import *  # noqa: E402, F403\r\n  File \"/usr/src/swarm_cloud/swarms/swarms/__init__.py\", line 2, in <module>\r\n    from swarms.structs.autoscaler import AutoScaler\r\n  File \"/usr/src/swarm_cloud/swarms/structs/__init__.py\", line 1, in <module>\r\n    from swarms.structs.flow import Flow\r\n  File \"/usr/src/swarm_cloud/swarms/structs/flow.py\", line 12, in <module>\r\n    from swarms.tools.tool import BaseTool\r\n  File \"/usr/src/swarm_cloud/swarms/tools/tool.py\", line 120, in <module>\r\n    class BaseTool(RunnableSerializable[Union[str, Dict], Any]):\r\n  File \"/usr/local/lib/python3.9/site-packages/pydantic/v1/main.py\", line 221, in __new__\r\n    inferred = ModelField.infer(\r\n  File \"/usr/local/lib/python3.9/site-packages/pydantic/v1/fields.py\", line 506, in infer\r\n    return cls(\r\n  File \"/usr/local/lib/python3.9/site-packages/pydantic/v1/fields.py\", line 436, in __init__\r\n    self.prepare()\r\n  File \"/usr/local/lib/python3.9/site-packages/pydantic/v1/fields.py\", line 546, in prepare\r\n    self._set_default_and_type()\r\n  File \"/usr/local/lib/python3.9/site-packages/pydantic/v1/fields.py\", line 570, in _set_default_and_type\r\n    default_value = self.get_default()\r\n  File \"/usr/local/lib/python3.9/site-packages/pydantic/v1/fields.py\", line 439, in get_default\r\n    return smart_deepcopy(self.default) if self.default_factory is None else self.default_factory()\r\n  File \"/usr/local/lib/python3.9/site-packages/pydantic/v1/utils.py\", line 693, in smart_deepcopy\r\n    return deepcopy(obj)  # slowest way when we actually might need a deepcopy\r\n  File \"/usr/local/lib/python3.9/copy.py\", line 172, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"/usr/local/lib/python3.9/copy.py\", line 270, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"/usr/local/lib/python3.9/copy.py\", line 146, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"/usr/local/lib/python3.9/copy.py\", line 230, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"/usr/local/lib/python3.9/copy.py\", line 161, in deepcopy\r\n    rv = reductor(4)\r\nTypeError: cannot pickle 'classmethod' object\r\n```",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-11-27T21:39:04Z",
      "updated_at": "2025-03-20T16:24:24Z",
      "closed_at": "2023-12-06T03:58:09Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/208/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/208",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/208",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:43.185281",
      "comments": []
    },
    {
      "issue_number": 199,
      "title": "[BUG] Ssd (stable diffusion) error",
      "body": "\r\nLoading pipeline components...:   0%|                                                                                            | 0/7 [00:00<?, ?it/s]\r\nLoading pipeline components...:  14%|############                                                                        | 1/7 [00:00<00:00,  8.16it/s]\r\nLoading pipeline components...:  29%|########################                                                            | 2/7 [00:00<00:00,  8.21it/s]\r\nLoading pipeline components...:  43%|####################################                                                | 3/7 [00:00<00:00,  4.57it/s]\r\nLoading pipeline components...:  71%|############################################################                        | 5/7 [00:00<00:00,  5.94it/s]\r\nLoading pipeline components...: 100%|####################################################################################| 7/7 [00:01<00:00,  5.95it/s]\r\nLoading pipeline components...: 100%|####################################################################################| 7/7 [00:01<00:00,  5.96it/s]\r\nTraceback (most recent call last):\r\n  File \"c:\\Users\\Guest1\\Desktop\\p-swarms\\stable.py\", line 1, in <module>\r\n    from swarms.models.ssd_1b import SSD1B\r\n  File \"c:\\Users\\Guest1\\Desktop\\p-swarms\\swarms\\models\\ssd_1b.py\", line 18, in <module>\r\n    class SSD1B:\r\n  File \"c:\\Users\\Guest1\\Desktop\\p-swarms\\swarms\\models\\ssd_1b.py\", line 60, in SSD1B\r\n    ).to(device)\r\n      ^^^^^^^^^^\r\n  File \"C:\\Users\\Guest1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\diffusers\\pipelines\\pipeline_utils.py\", line 852, in to\r\n    module.to(device, dtype)\r\n  File \"C:\\Users\\Guest1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1160, in to\r\n    return self._apply(convert)\r\n           ^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\Guest1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 810, in _apply\r\n    module._apply(fn)\r\n  File \"C:\\Users\\Guest1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 810, in _apply\r\n    module._apply(fn)\r\n  File \"C:\\Users\\Guest1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 833, in _apply\r\n    param_applied = fn(param)\r\n                    ^^^^^^^^^\r\n  File \"C:\\Users\\Guest1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1158, in convert\r\n    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\Guest1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\cuda\\__init__.py\", line 289, in _lazy_init\r\n    raise AssertionError(\"Torch not compiled with CUDA enabled\")\r\nAssertionError: Torch not compiled with CUDA enabled",
      "state": "closed",
      "author": "elder-plinius",
      "author_type": "User",
      "created_at": "2023-11-27T02:44:47Z",
      "updated_at": "2025-03-20T16:24:24Z",
      "closed_at": "2023-12-06T04:55:04Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/199/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/199",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/199",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:43.185288",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@elder-plinius update your torch",
          "created_at": "2023-12-05T06:55:38Z"
        }
      ]
    },
    {
      "issue_number": 195,
      "title": "[BUG] pydantic root_validator deprecated - blocks test running",
      "body": "**Describe the bug**\r\nRunning example.py or multi_modal_auto_agent.py  or sequential_workflow_example.py within the top level docker container.\r\n\r\n```\r\nroot@d789676bb63b:/usr/src/swarm_cloud# python example.py \r\nTraceback (most recent call last):\r\n  File \"/usr/src/swarm_cloud/example.py\", line 6, in <module>\r\n    from swarms.models import OpenAIChat\r\n  File \"/usr/src/swarm_cloud/swarms/__init__.py\", line 6, in <module>\r\n    from swarms.swarms import *  # noqa: E402, F403\r\n  File \"/usr/src/swarm_cloud/swarms/swarms/__init__.py\", line 2, in <module>\r\n    from swarms.structs.autoscaler import AutoScaler\r\n  File \"/usr/src/swarm_cloud/swarms/structs/__init__.py\", line 1, in <module>\r\n    from swarms.structs.flow import Flow\r\n  File \"/usr/src/swarm_cloud/swarms/structs/flow.py\", line 14, in <module>\r\n    from swarms.tools.tool import BaseTool\r\n  File \"/usr/src/swarm_cloud/swarms/tools/tool.py\", line 120, in <module>\r\n    class BaseTool(RunnableSerializable[Union[str, Dict], Any]):\r\n  File \"/usr/src/swarm_cloud/swarms/tools/tool.py\", line 271, in BaseTool\r\n    @root_validator()\r\n  File \"/usr/local/lib/python3.9/site-packages/pydantic/deprecated/class_validators.py\", line 237, in root_validator\r\n    raise PydanticUserError(\r\npydantic.errors.PydanticUserError: If you use `@root_validator` with pre=False (the default) you MUST specify `skip_on_failure=True`. Note that `@root_validator` is deprecated and should be replaced with `@model_validator`.\r\n\r\nFor further information visit https://errors.pydantic.dev/2.5/u/root-validator-pre-skip\r\nroot@d789676bb63b:/usr/src/swarm_cloud# ls *.py\r\nexample.py  multi_modal_auto_agent.py  sequential_workflow_example.py\r\nroot@d789676bb63b:/usr/src/swarm_cloud# python multi_modal_auto_agent.py \r\nTraceback (most recent call last):\r\n  File \"/usr/src/swarm_cloud/multi_modal_auto_agent.py\", line 1, in <module>\r\n    from swarms.structs import Flow\r\n  File \"/usr/src/swarm_cloud/swarms/__init__.py\", line 6, in <module>\r\n    from swarms.swarms import *  # noqa: E402, F403\r\n  File \"/usr/src/swarm_cloud/swarms/swarms/__init__.py\", line 2, in <module>\r\n    from swarms.structs.autoscaler import AutoScaler\r\n  File \"/usr/src/swarm_cloud/swarms/structs/__init__.py\", line 1, in <module>\r\n    from swarms.structs.flow import Flow\r\n  File \"/usr/src/swarm_cloud/swarms/structs/flow.py\", line 14, in <module>\r\n    from swarms.tools.tool import BaseTool\r\n  File \"/usr/src/swarm_cloud/swarms/tools/tool.py\", line 120, in <module>\r\n    class BaseTool(RunnableSerializable[Union[str, Dict], Any]):\r\n  File \"/usr/src/swarm_cloud/swarms/tools/tool.py\", line 271, in BaseTool\r\n    @root_validator()\r\n  File \"/usr/local/lib/python3.9/site-packages/pydantic/deprecated/class_validators.py\", line 237, in root_validator\r\n    raise PydanticUserError(\r\npydantic.errors.PydanticUserError: If you use `@root_validator` with pre=False (the default) you MUST specify `skip_on_failure=True`. Note that `@root_validator` is deprecated and should be replaced with `@model_validator`.\r\n\r\nFor further information visit https://errors.pydantic.dev/2.5/u/root-validator-pre-skip\r\nroot@d789676bb63b:/usr/src/swarm_cloud# python sequential_workflow_example.py \r\nTraceback (most recent call last):\r\n  File \"/usr/src/swarm_cloud/sequential_workflow_example.py\", line 1, in <module>\r\n    from swarms.models import OpenAIChat, BioGPT, Anthropic\r\n  File \"/usr/src/swarm_cloud/swarms/__init__.py\", line 6, in <module>\r\n    from swarms.swarms import *  # noqa: E402, F403\r\n  File \"/usr/src/swarm_cloud/swarms/swarms/__init__.py\", line 2, in <module>\r\n    from swarms.structs.autoscaler import AutoScaler\r\n  File \"/usr/src/swarm_cloud/swarms/structs/__init__.py\", line 1, in <module>\r\n    from swarms.structs.flow import Flow\r\n  File \"/usr/src/swarm_cloud/swarms/structs/flow.py\", line 14, in <module>\r\n    from swarms.tools.tool import BaseTool\r\n  File \"/usr/src/swarm_cloud/swarms/tools/tool.py\", line 120, in <module>\r\n    class BaseTool(RunnableSerializable[Union[str, Dict], Any]):\r\n  File \"/usr/src/swarm_cloud/swarms/tools/tool.py\", line 271, in BaseTool\r\n    @root_validator()\r\n  File \"/usr/local/lib/python3.9/site-packages/pydantic/deprecated/class_validators.py\", line 237, in root_validator\r\n    raise PydanticUserError(\r\npydantic.errors.PydanticUserError: If you use `@root_validator` with pre=False (the default) you MUST specify `skip_on_failure=True`. Note that `@root_validator` is deprecated and should be replaced with `@model_validator`.\r\n\r\nFor further information visit https://errors.pydantic.dev/2.5/u/root-validator-pre-skip\r\nroot@d789676bb63b:/usr/src/swaTraceback (most recent call last):\r\n  File \"/usr/src/swarm_cloud/sequential_workflow_example.py\", line 1, in <module>\r\n    from swarms.models import OpenAIChat, BioGPT, Anthropic\r\n  File \"/usr/src/swarm_cloud/swarms/__init__.py\", line 6, in <module>\r\n    from swarms.swarms import *  # noqa: E402, F403\r\n  File \"/usr/src/swarm_cloud/swarms/swarms/__init__.py\", line 2, in <module>\r\n\r\n\r\n    from swarms.structs.autoscaler import AutoScaler\r\n  File \"/usr/src/swarm_cloud/swarms/structs/__init__.py\", line 1, in <module>\r\n    from swarms.structs.flow import Flow\r\n  File \"/usr/src/swarm_cloud/swarms/structs/flow.py\", line 14, in <module>\r\n    from swarms.tools.tool import BaseTool\r\n  File \"/usr/src/swarm_cloud/swarms/tools/tool.py\", line 120, in <module>\r\n    class BaseTool(RunnableSerializable[Union[str, Dict], Any]):\r\n  File \"/usr/src/swarm_cloud/swarms/tools/tool.py\", line 271, in BaseTool\r\n    @root_validator()\r\n  File \"/usr/local/lib/python3.9/site-packages/pydantic/deprecated/class_validators.py\", line 237, in root_validator\r\n    raise PydanticUserError(\r\npydantic.errors.PydanticUserError: If you use `@root_validator` with pre=False (the default) you MUST specify `skip_on_failure=True`. Note that `@root_validator` is deprecated and should be replaced with `@model_validator`.\r\n\r\nFor further information visit https://errors.pydantic.dev/2.5/u/root-validator-pre-skip\r\nroot@d789676bb63b:/usr/src/swarm_cloud# ```\r\n\r\n** See\r\n(https://docs.pydantic.dev/latest/migration/#validator-and-root_validator-are-deprecated) as a pointer to a fix for tool.py line 271",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-11-25T23:09:38Z",
      "updated_at": "2025-03-20T16:24:24Z",
      "closed_at": "2023-12-18T23:03:36Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/195/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/195",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/195",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:43.365524",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "I've installed bump_pydantic and run it on my local copy, following the instructions here: (https://docs.pydantic.dev/2.5/migration/) \r\n\r\nIt touched 16 files, in what appear to be very reasonable ways. I'm not going to commit this as the tail end of the cicd PR.",
          "created_at": "2023-11-26T19:50:34Z"
        },
        {
          "author": "evelynmitchell",
          "body": "I think this can be closed ",
          "created_at": "2023-12-18T19:58:11Z"
        }
      ]
    },
    {
      "issue_number": 196,
      "title": "[BUG] swarms does not have a __version__ string set",
      "body": "**Describe the bug**\r\ndir(swarms) does not show __version__",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-11-25T23:20:32Z",
      "updated_at": "2025-03-20T16:24:23Z",
      "closed_at": "2023-12-05T06:55:03Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/196/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/196",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/196",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:43.582105",
      "comments": []
    },
    {
      "issue_number": 192,
      "title": "[BUG] In the basic example in Colab, flow.run() is missing a parameter",
      "body": "**Describe the bug**\r\nI ran the colab for the basic example to test its capacities, and I got the following error.\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n[<ipython-input-1-b6b873294935>](https://localhost:8080/#) in <cell line: 32>()\r\n     30 # temp = flow.dynamic_temperature()\r\n     31 # filter = flow.add_response_filter(\"Trump\")\r\n---> 32 out = flow.run(\r\n     33     \"Generate a 10,000 word blog on mental clarity and the benefits of meditation.\"\r\n     34 )\r\n\r\nTypeError: Flow.run() missing 1 required positional argument: 'img'\r\n\r\n**Additional context**\r\nThe second argument in the run method seems to be optional, but I had to pass an empty string \"\" to make it work.",
      "state": "closed",
      "author": "gultar",
      "author_type": "User",
      "created_at": "2023-11-25T16:15:04Z",
      "updated_at": "2025-03-20T16:24:23Z",
      "closed_at": "2023-11-25T22:28:40Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/192/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/192",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/192",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:43.582128",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@gultar Thanks for letting me know, I have fixed this by making img = None!",
          "created_at": "2023-11-25T22:28:40Z"
        }
      ]
    },
    {
      "issue_number": 191,
      "title": "[BUG] pytest container status",
      "body": "I built the container in swarms/test\r\n```\r\ndocker build -it swarmstest .\r\n```\r\nInspected it, and ran it:\r\n```\r\ndocker image inspect swarmstest\r\n...\r\ndocker run -it swarmstest bash\r\n```\r\nThen used pytest instead of \"find ./tests -name '*.py' -exec pytest {} +\" to run the tests. pytest discovered the tests, but many failed.\r\nResults: https://pastebin.mozilla.org/nK9og1gQ\r\n\r\nFirst proposed fix is to replace the long find and run test command with 'pytest' in the cicd scripts, and the Dockerfiles.\r\n\r\nNext, to identify failing tests, and triage them, so we have clean running tests. Then add them back incrementally to inspect if they add value or not.",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-11-25T15:34:23Z",
      "updated_at": "2025-03-20T16:24:23Z",
      "closed_at": "2023-12-06T03:58:21Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/191/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/191",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/191",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:43.780363",
      "comments": []
    },
    {
      "issue_number": 189,
      "title": "[BUG] Error running flow: '<' not supported between instances of 'int' and 'str'",
      "body": "**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.",
      "state": "closed",
      "author": "elder-plinius",
      "author_type": "User",
      "created_at": "2023-11-25T01:21:26Z",
      "updated_at": "2025-03-20T16:24:23Z",
      "closed_at": "2023-12-06T04:57:20Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/189/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/189",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/189",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:43.780392",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@elder-plinius give more descriptive tracebacks",
          "created_at": "2023-11-25T05:09:53Z"
        }
      ]
    },
    {
      "issue_number": 185,
      "title": "[BUG] positive med",
      "body": "\r\nC:\\Users\\Guest1\\Desktop\\p-swarms\\playground\\demos\\positive_med>python positive_med.py\r\n  File \"C:\\Users\\Guest1\\Desktop\\p-swarms\\playground\\demos\\positive_med\\positive_med.py\", line 25\r\n    from swarms.prompts.autobloggen\r\n                                   ^\r\nSyntaxError: invalid syntax",
      "state": "closed",
      "author": "elder-plinius",
      "author_type": "User",
      "created_at": "2023-11-24T20:46:12Z",
      "updated_at": "2025-03-20T16:24:23Z",
      "closed_at": "2023-11-24T23:46:49Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/185/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/185",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/185",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:44.003089",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@elder-plinius this has been fixed. i have fixed it",
          "created_at": "2023-11-24T23:46:50Z"
        }
      ]
    },
    {
      "issue_number": 183,
      "title": "[BUG] positive_med demo not running, looks like old import doesnt exist now",
      "body": "Traceback (most recent call last):\r\n  File \"C:\\Users\\Guest1\\Desktop\\pliny-swarms\\playground\\demos\\positive_med\\positive_med.py\", line 24, in <module>\r\n    from swarms.prompts.autoblogen import (\r\nModuleNotFoundError: No module named 'swarms.prompts.autoblogen'",
      "state": "closed",
      "author": "elder-plinius",
      "author_type": "User",
      "created_at": "2023-11-24T17:53:25Z",
      "updated_at": "2025-03-20T16:24:23Z",
      "closed_at": "2023-11-24T19:32:38Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/183/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/183",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/183",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:44.174646",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@elder-plinius fixed the file import path",
          "created_at": "2023-11-24T19:32:38Z"
        }
      ]
    },
    {
      "issue_number": 182,
      "title": "[BUG] sequential_workflow_example error (shouldn't be dependent on anthropic key to run)",
      "body": "Traceback (most recent call last):\r\n  File \"C:\\Users\\Guest1\\Desktop\\pliny-swarms\\sequential_workflow_example.py\", line 19, in <module>\r\n    anthropic = Anthropic()\r\n                ^^^^^^^^^^^\r\n  File \"C:\\Users\\Guest1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\load\\serializable.py\", line 97, in __init__\r\n    super().__init__(**kwargs)\r\n  File \"pydantic\\main.py\", line 341, in pydantic.main.BaseModel.__init__\r\npydantic.error_wrappers.ValidationError: 1 validation error for Anthropic\r\n__root__\r\n  Did not find anthropic_api_key, please add an environment variable `ANTHROPIC_API_KEY` which contains it, or pass  `anthropic_api_key` as a named parameter. (type=value_error)",
      "state": "closed",
      "author": "elder-plinius",
      "author_type": "User",
      "created_at": "2023-11-24T17:45:30Z",
      "updated_at": "2025-03-20T16:24:23Z",
      "closed_at": "2023-11-24T19:34:15Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/182/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/182",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/182",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:44.346084",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@elder-plinius this is a choice of which llm to use, you can comment it out if you do not use anthropic",
          "created_at": "2023-11-24T19:34:15Z"
        }
      ]
    },
    {
      "issue_number": 179,
      "title": "[BUG] CONTRIBUTING.md refers to branching",
      "body": "**Describe the bug**\r\nCONTRIBUTING.md refers to branching.\r\n\r\n**Expected behavior**\r\nThe policy of this team is to commit to main.\r\nThe doc needs to be updated for current policy.",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-11-24T14:22:55Z",
      "updated_at": "2025-03-20T16:24:22Z",
      "closed_at": "2023-12-05T19:17:36Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/179/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/179",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/179",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:44.517601",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@evelynmitchell can you elaborate?",
          "created_at": "2023-11-24T19:34:31Z"
        },
        {
          "author": "evelynmitchell",
          "body": "You mentioned yesterday that you want a push to main style of commit. ",
          "created_at": "2023-11-24T19:53:14Z"
        }
      ]
    },
    {
      "issue_number": 178,
      "title": "[BUG] tests Dockerfile will not build",
      "body": "**Describe the bug**\r\nIn swarms/tests, there is a Dockerfile which uses poetry to run the application.\r\n\r\n```\r\ndocker build . -t swarmstests\r\n```\r\nfails with\r\n```\r\n=> ERROR [6/8] RUN poetry install --no-interaction --no-ansi              1.3s \r\n------                                                                          \r\n > [6/8] RUN poetry install --no-interaction --no-ansi:                         \r\n1.235                                                                           \r\n1.235 Poetry could not find a pyproject.toml file in /usr/src/app or its parents\r\n------\r\nDockerfile:24\r\n--------------------\r\n  22 |     # Disable virtualenv creation by poetry and install dependencies\r\n  23 |     RUN poetry config virtualenvs.create false\r\n  24 | >>> RUN poetry install --no-interaction --no-ansi\r\n  25 |     \r\n  26 |     # Install the 'swarms' package if it's not included in the poetry.lock\r\n--------------------\r\nERROR: failed to solve: process \"/bin/sh -c poetry install --no-interaction --no-ansi\" did not complete successfully: exit code: 1\r\n\r\n```",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-11-24T14:05:55Z",
      "updated_at": "2025-03-20T16:24:22Z",
      "closed_at": "2023-11-24T23:49:50Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/178/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/178",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/178",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:44.677046",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@evelynmitchell I have fixed this issue",
          "created_at": "2023-11-24T23:49:50Z"
        },
        {
          "author": "evelynmitchell",
          "body": "Thanks!",
          "created_at": "2023-11-24T23:50:19Z"
        }
      ]
    },
    {
      "issue_number": 174,
      "title": "[BUG] ModuleNotFoundError: No module named 'swarms.utils.display_markdown'",
      "body": "Traceback (most recent call last):\r\n  File \"c:\\Users\\Guest1\\Desktop\\pliny-swarms\\example.py\", line 1, in <module>\r\n    from swarms.models import OpenAIChat\r\n  File \"c:\\Users\\Guest1\\Desktop\\pliny-swarms\\swarms\\__init__.py\", line 18, in <module>\r\n    from swarms.swarms import *  # noqa: E402, F403\r\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"c:\\Users\\Guest1\\Desktop\\pliny-swarms\\swarms\\swarms\\__init__.py\", line 2, in <module>\r\n    from swarms.structs.autoscaler import AutoScaler\r\n  File \"c:\\Users\\Guest1\\Desktop\\pliny-swarms\\swarms\\structs\\__init__.py\", line 1, in <module>\r\n    from swarms.structs.flow import Flow\r\n  File \"c:\\Users\\Guest1\\Desktop\\pliny-swarms\\swarms\\structs\\flow.py\", line 12, in <module>\r\n    from swarms.utils.code_interpreter import SubprocessCodeInterpreter\r\n  File \"c:\\Users\\Guest1\\Desktop\\pliny-swarms\\swarms\\utils\\__init__.py\", line 1, in <module>\r\n    from swarms.utils.display_markdown import display_markdown_message\r\nModuleNotFoundError: No module named 'swarms.utils.display_markdown'",
      "state": "closed",
      "author": "elder-plinius",
      "author_type": "User",
      "created_at": "2023-11-23T22:18:21Z",
      "updated_at": "2025-03-20T16:24:22Z",
      "closed_at": "2023-11-24T01:15:23Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/174/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/174",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/174",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:44.894732",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@elder-plinius I just pushed to try and fix this lmk if it works",
          "created_at": "2023-11-23T23:03:01Z"
        }
      ]
    },
    {
      "issue_number": 173,
      "title": "Chain isn't working[BUG] ",
      "body": "**Describe the bug**\r\nBut is one agent not talking to another agent.\r\n\r\n**To Reproduce**\r\nRun the file and see if it asks you for information about the student and then passes that info to the next agent. \r\n\r\n**Expected behavior**\r\nThe above is the expected behavior\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Additional context**\r\nThis code pulls the prompts from actual prompt json files. I'll include the files for you and you'll need to put them in the root of swarms to use them. \r\n[base_code.txt](https://github.com/kyegomez/swarms/files/13443685/base_code.txt)\r\n[personality_profile_test_prompts.json](https://github.com/kyegomez/swarms/files/13443688/personality_profile_test_prompts.json)\r\n[reformatted_second_bot_instructions.json](https://github.com/kyegomez/swarms/files/13443689/reformatted_second_bot_instructions.json)",
      "state": "closed",
      "author": "bryonmccoy",
      "author_type": "User",
      "created_at": "2023-11-22T19:24:23Z",
      "updated_at": "2025-03-20T16:24:22Z",
      "closed_at": "2024-01-01T07:34:35Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/173/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/173",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/173",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:45.087360",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@bryonmccoy join the voice channel when you can so we can help implement this!",
          "created_at": "2023-12-06T23:12:28Z"
        },
        {
          "author": "evelynmitchell",
          "body": "Can this be closed?",
          "created_at": "2024-01-01T00:24:32Z"
        },
        {
          "author": "bryonmccoy",
          "body": "Yes\r\n\r\n\r\nBryon McCoy\r\nPracticing Musician\r\n***@***.***\r\n509-406-2419\r\npracticingmusician.com\r\n<http://practicingmusician.com/>\r\n________________________________\r\nFrom: evelynmitchell ***@***.***>\r\nSent: Sunday, December 31, 2023 4:24:43 PM\r\nTo: kyegomez/swarms ***@***.***>\r\nCc: Bryon McCoy ***@***.*",
          "created_at": "2024-01-01T01:34:46Z"
        }
      ]
    },
    {
      "issue_number": 172,
      "title": "[BUG] ruff lint error test_set_interaction_rules",
      "body": "ruff error:\r\n```\r\ntests/swarms/multi_agent_collab.py:104:5: F811 Redefinition of unused `test_set_interaction_rules` from line 97\r\n```\r\nIn looking at the code this function was duplicated, so I have removed the duplicate,",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-11-22T19:23:04Z",
      "updated_at": "2025-03-20T16:24:22Z",
      "closed_at": "2023-12-06T04:00:07Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/172/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/172",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/172",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:45.266591",
      "comments": []
    },
    {
      "issue_number": 171,
      "title": "[BUG] remove unused test worker_agent_ultra.py",
      "body": "ruff lint reported \r\n```\r\n tests/workers/worker_agent_ultra.py:45:14: F821 Undefined name `worker_ultra_node`\r\ntests/workers/worker_agent_ultra.py:51:9: F821 Undefined name `worker_ultra_node`\r\n```\r\nIt appears that this test is for a worker which doesn't exist:\r\nswarms/tests/workers/worker_agent_ultra.py\r\n\r\nMy recommended fix is to delete swarms/tests/workers/worker_agent_ultra.py",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-11-22T19:17:48Z",
      "updated_at": "2025-03-20T16:24:22Z",
      "closed_at": "2023-11-24T23:50:52Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/171/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/171",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/171",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:45.266614",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@evelynmitchell this code has been deleted",
          "created_at": "2023-11-24T23:50:53Z"
        },
        {
          "author": "evelynmitchell",
          "body": "Thanks Kye. You're the best.",
          "created_at": "2023-11-24T23:52:59Z"
        }
      ]
    },
    {
      "issue_number": 169,
      "title": "[DEMO] Nutrition/Fitness Swarm: User has a chat with onboarding agent about their health goals and agent automatically creates a shopping list based on an image of their fridge/supplement cabinet, then automatically orders the shopping list from Amazon/doordash/ubereats",
      "body": null,
      "state": "closed",
      "author": "kyegomez",
      "author_type": "User",
      "created_at": "2023-11-22T18:37:14Z",
      "updated_at": "2025-03-20T16:24:22Z",
      "closed_at": "2023-12-06T04:00:21Z",
      "labels": [
        "help wanted",
        "good first issue"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/169/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/169",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/169",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:45.445430",
      "comments": [
        {
          "author": "kyegomez",
          "body": "LLM Agent that understands user's health goals -> GPT4V analyzes image of fridge or kitchen -> proposes a plan on how to get healthier what food to cut out -> LLM agent: proposes a ranked list of foods to acquire to elevate user health\n\n\n3-5 agent system that understands a users heath then recommend",
          "created_at": "2023-11-22T18:38:14Z"
        }
      ]
    },
    {
      "issue_number": 168,
      "title": "[DEMO][Accountant Swarm]",
      "body": "# Goal\n- [ ] Output a financial report on costs to eliminate\n- [ ] One class, ultimate customizeability, any model, any flow configs\n\n# Todo\n\n- [ ] Analyze Bank statements\n- [ ] Understand User's goals: interactively ask user questions on goals, save output to a txt\n- [ ] Fraud Detection\n- [ ] Financial Report Generation\n- [ ] Decision Making support\n\n\n# Accountant Swarm\n\n1. **Introduction**\n   - Definition of an LLM (Large Language Model) and OCR (Optical Character Recognition) Model\n   - Overview of Swarm Intelligence and its application in accounting\n   - Objectives of the swarm system for accounting tasks\n\n2. **Background**\n   - The evolution of accounting technology\n   - Brief history and current trends in LLMs and OCR in finance\n   - Theoretical basis for swarm intelligence\n\n3. **System Architecture**\n   - Description of the swarm system's structure\n   - Integration methods for LLMs and OCR models\n   - Communication within the swarm\n\n4. **Agents in the Swarm**\n   - Role of LLMs in the system\n   - Role of OCR models in the system\n   - Task distribution and collaboration methods\n\n5. **Tasks and Responsibilities**\n   - Detailed tasks assigned to LLM agents\n   - Detailed tasks assigned to OCR agents\n   - Process flows of accounting tasks within the swarm\n\n6. **Swarm Operations**\n   - The initiation of tasks\n   - Coordination and collaboration mechanisms\n   - Error handling and resolution\n\n7. **Case Studies and Scenarios**\n   - Hypothetical scenarios showcasing the swarm's capabilities\n   - Case studies on experimental implementation\n\n8. **Advantages and Challenges**\n   - Benefits of using a swarm system for accounting\n   - Potential challenges and limitations\n\n9. **Future Prospects**\n   - The future integration of AI in accounting\n   - Predictions on how swarm intelligence could evolve\n\n10. **Conclusion**\n    - Summary of key points\n    - Final thoughts on the impact of LLM and OCR swarms in accounting\n\n### Tasks and Responsibilities\n\n- **LLM Agents:**\n  - Interpretation of textual data\n  - Assisting in decision-making processes\n  - Natural language interaction with users\n  - Generating financial reports\n  - Compliance and regulation checks\n  - Fraud detection through pattern recognition\n\n- **OCR Agents:**\n  - Scanning and digitization of paper-based financial documents\n  - Text extraction from scanned documents\n  - Conversion of unstructured data into structured data suitable for analysis\n  - Validation of scanned data against existing records\n\n### Markdown Table of Agents\n\n```markdown\n| Agent Type | Task                                           | Responsibility                             |\n|------------|------------------------------------------------|--------------------------------------------|\n| LLM        | Interpretation of textual data                 | Analyze and make sense of financial texts  |\n| LLM        | Assistance in decision-making                  | Support financial decision-making processes|\n| LLM        | Natural language interaction                   | Communicate with users in natural language |\n| LLM        | Financial report generation                    | Produce comprehensive financial reports    |\n| LLM        | Compliance and regulation check                | Ensure financial activities are compliant  |\n| LLM        | Fraud detection                                | Identify suspicious patterns in data       |\n| OCR        | Scanning documents                             | Digitize paper-based financial documents   |\n| OCR        | Text extraction                                | Extract text from scanned documents        |\n| OCR        | Data conversion                                | Convert unstructured to structured data    |\n| OCR        | Validation of scanned data                     | Cross-reference and validate data          |\n```\n\n### Minimum Prototype\n\nA minimum viable prototype of an experimental swarm for various accountant tasks would include:\n\n1. **Sample LLM Agent:**\n   - A small-scale language model trained on accounting terminology and data analysis.\n   - A mockup interface for input/output to simulate user interaction.\n\n2. **Sample OCR Agent:**\n   - A simple OCR tool capable of scanning documents and extracting text.\n   - A mockup database for storing and comparing extracted data.\n\n3. **Integration Platform:**\n   - A basic platform to allow the LLM and OCR agents to communicate.\n   - A dashboard to monitor the system's output and performance.\n\n4. **Workflow Script:**\n   - A script to control the flow of tasks between agents.\n   - Exception handling for errors in scanning or data interpretation.\n\n5. **User Interface:**\n   - A simple user interface to allow users to upload documents, receive reports, and make queries.\n\nThis prototype would be able to demonstrate the basic capability of the swarm to handle predefined accounting tasks. The development of such a prototype would require programming skills and a good understanding of both accounting practices and AI technologies. It would serve as a proof of concept to demonstrate the potential efficiencies and insights that such a swarm system could provide in the field of accounting.\n\n# System Prompts\n\nCreating system prompts for LLM agents in an accounting swarm system requires a balance between specificity (to ensure accurate and relevant responses) and generality (to allow for a wide range of inquiries). Below are compact and effective system prompts for various tasks that LLM agents could handle:\n\n1. **Interpretation of Financial Texts**\n   ```\n   Prompt: \"Analyze the following excerpt from the financial statement and summarize the key points.\"\n   ```\n\n2. **Decision-Making Support**\n   ```\n   Prompt: \"Given this financial scenario {scenario}, what would be the prudent financial decision according to best practices?\"\n   ```\n\n3. **Natural Language User Interaction**\n   ```\n   Prompt: \"User has inquired: '{user_query}'. Draft a response that provides a clear and concise answer.\"\n   ```\n\n4. **Financial Report Generation**\n   ```\n   Prompt: \"Compile a financial report for {time_period} using the provided dataset, focusing on revenue, expenses, and net profit.\"\n   ```\n\n5. **Compliance and Regulation Checks**\n   ```\n   Prompt: \"Review the following transaction log and flag any entries that may violate {specific_regulation}.\"\n   ```\n\n6. **Fraud Detection**\n   ```\n   Prompt: \"Examine the transaction patterns in this data. Highlight any anomalies that could indicate fraudulent activity.\"\n   ```\n\nEach of these prompts is designed to be directly actionable, with placeholders (like `{scenario}`, `{user_query}`, `{time_period}`, and `{specific_regulation}`) for the specific details relevant to the task. The LLM agents will use the context provided by these prompts to generate appropriate responses or actions.\n\nIn practice, these prompts would likely be part of an automated system where variables are dynamically filled based on user interactions or system triggers. To be most effective, each prompt should be paired with a well-defined input format and expected output structure to ensure that the LLM agents produce results that are as useful and accurate as possible.\n\n\n# Code:\n```\n\nfrom swarms.models.nougat import Nougat\nfrom swarms.structs import Flow\nfrom swarms.models import OpenAIChat, Anthropic\nfrom typing import List\n\n\n# Base llms\nllm1 = OpenAIChat()\nllm2 = Anthropic()\nnougat = Nougat()\n\n\n# Prompts for each agent\nSUMMARY_AGENT_PROMPT = \"\"\"\n    Generate an actionable summary of this financial document be very specific and precise, provide bulletpoints be very specific provide methods of lowering expenses: {answer}\"\n\"\"\"\n\n\n\n# Agents\nuser_consultant_agent = Flow(\n    llm=llm1,\n)\ndoc_analyzer_agent = Flow(\n    llm=llm1,\n)\nsummary_generator_agent = Flow(\n    llm=llm2,\n)\nfraud_detection_agent = Flow(\n    llm=llm2,\n)\ndecision_making_support_agent = Flow(\n    llm=llm2,\n)\n\n\nclass AccountantSwarms:\n    \"\"\"\n    Accountant Swarms is a collection of agents that work together to help\n    accountants with their work. \n    \n    Flow: analyze doc -> detect fraud -> generate summary -> decision making support\n\n    The agents are:\n    - User Consultant: Asks the user many questions\n    - Document Analyzer: Extracts text from the image of the financial document\n    - Fraud Detection: Detects fraud in the document\n    - Summary Agent: Generates an actionable summary of the document\n    - Decision Making Support: Provides decision making support to the accountant\n\n    The agents are connected together in a workflow that is defined in the\n    run method.\n\n    The workflow is as follows:\n    1. The Document Analyzer agent extracts text from the image of the\n    financial document.\n    2. The Fraud Detection agent detects fraud in the document.\n    3. The Summary Agent generates an actionable summary of the document.\n    4. The Decision Making Support agent provides decision making support\n    to the accountant.\n    \n    Example:\n    >>> accountant_swarms = AccountantSwarms(\n    \n    \n    \"\"\"\n    def __init__(\n        self,\n        financial_document_img: str,\n        financial_document_list_img: List[str] = None,\n        fraud_detection_instructions: str = None,\n        summary_agent_instructions: str = None,\n        decision_making_support_agent_instructions: str = None,\n\n\n    ):\n        super().__init__()\n        self.financial_document_img = financial_document_img\n        self.fraud_detection_instructions = fraud_detection_instructions\n        self.summary_agent_instructions = summary_agent_instructions\n        \n    def run(self):\n        # Extract text from the image\n        analyzed_doc = self.nougat(self.financial_document_img)\n\n        # Detect fraud in the document\n        fraud_detection_agent_output = self.fraud_detection_agent(analyzed_doc)\n\n        # Generate an actionable summary of the document\n        summary_agent_output = self.summary_agent(fraud_detection_agent_output)\n\n        # Provide decision making support to the accountant\n        decision_making_support_agent_output = self.decision_making_support_agent(summary_agent_output)\n\n        return decision_making_support_agent_output\n\n```",
      "state": "closed",
      "author": "kyegomez",
      "author_type": "User",
      "created_at": "2023-11-22T18:36:36Z",
      "updated_at": "2025-03-20T16:24:21Z",
      "closed_at": "2023-11-27T04:17:26Z",
      "labels": [
        "[DEMO]"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/168/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/168",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/168",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:45.605157",
      "comments": [
        {
          "author": "kyegomez",
          "body": "# System Prompts\n\n```\nOnboarding:\n\n\"As the Onboarding Agent, your role is critical in guiding new users, particularly tech-savvy entrepreneurs, through the initial stages of engaging with our advanced swarm technology services. Begin by welcoming users in a friendly, professional manner, setting a p",
          "created_at": "2023-11-22T18:36:50Z"
        },
        {
          "author": "kyegomez",
          "body": "- Can still optimize this by making the prompts better and making it a class",
          "created_at": "2023-11-25T22:38:35Z"
        }
      ]
    },
    {
      "issue_number": 165,
      "title": "[BUG] flake8 unused imports",
      "body": "./swarms/__init__.py:8:1: F401 'swarms.agents.*' imported but unused\r\n./swarms/__init__.py:9:1: F401 'swarms.swarms.*' imported but unused\r\n./swarms/__init__.py:10:1: F401 'swarms.structs.*' imported but unused\r\n./swarms/__init__.py:11:1: F401 'swarms.models.*' imported but unused\r\ncleanup",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-11-20T17:46:10Z",
      "updated_at": "2025-03-20T16:24:21Z",
      "closed_at": "2023-11-24T23:51:21Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/165/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/165",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/165",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:45.825229",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "I'm too far behind you, to make this correction. I think you already have.",
          "created_at": "2023-11-20T17:48:31Z"
        }
      ]
    },
    {
      "issue_number": 164,
      "title": "[BUG] flake8 lint example.py two leading # only one needed",
      "body": "./example.py:16:1: E266 too many leading '#' for block comment\r\n\r\n```\r\n## Initialize the workflow\r\n```\r\nshould be\r\n```\r\n# Initialize the workflow\r\n```",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-11-20T17:38:14Z",
      "updated_at": "2025-03-20T16:24:21Z",
      "closed_at": "2023-12-05T08:07:42Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/164/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/164",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/164",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:46.043213",
      "comments": []
    },
    {
      "issue_number": 163,
      "title": "[BUG] code cleanup account_team2.py - whitespace only",
      "body": "./account_team2.py:48:9: E225 missing whitespace around operator from flake8 lint",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-11-20T17:13:18Z",
      "updated_at": "2025-03-20T16:24:20Z",
      "closed_at": "2023-11-20T18:09:58Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/163/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/163",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/163",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:46.043231",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@evelynmitchell try the `code_quality.sh` shell command",
          "created_at": "2023-11-20T18:09:58Z"
        }
      ]
    },
    {
      "issue_number": 161,
      "title": "[BUG] torch.distributed",
      "body": "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmp312csgvg\r\nINFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmp312csgvg/_remote_module_non_scriptable.py",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-20T04:26:55Z",
      "updated_at": "2025-03-20T16:24:20Z",
      "closed_at": "2023-11-20T07:15:36Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/161/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/161",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/161",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:46.204632",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@vyomakesh09 tried to fix now ",
          "created_at": "2023-11-20T07:15:36Z"
        }
      ]
    },
    {
      "issue_number": 159,
      "title": "[BUG] passing keys from the enviroment into running code",
      "body": "**Describe the bug**\r\nWhen running the code from within a container, which doesn't have an editor the api key needs to be passed to the code as an environment variable\r\n\r\nTo SET the key:\r\n```bash\r\nexport OPENAI_API_KEY='yourapikey'\r\nexport ANTHROPIC_API_KEY='yourotherapikey'\r\n```\r\n\r\nTo USE the key from a python program:\r\n```python\r\nopenai_api_key = os.environ('OPENAI_API_KEY')\r\nanthropic_api_key = os.environ('ANTHROPIC_API_KEY')\r\n```\r\n\r\nTo USE the key from colab notebook \r\n``` colab python\r\nopenai_api_key = userdata.get('OPENAI_API_KEY')\r\nanthropic_api_key = userdata.get('ANTHROPIC_API_KEY')\r\n```",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-11-19T02:11:11Z",
      "updated_at": "2025-03-20T16:24:20Z",
      "closed_at": "2023-12-06T03:59:44Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/159/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/159",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/159",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:46.455343",
      "comments": []
    },
    {
      "issue_number": 157,
      "title": "[BUG] Accountant demo error",
      "body": "**Describe the bug**\r\nUsing a colab notebook to run the accountant demo with the image pulled from this repo.\r\n\r\n```\r\nAttributeError                            Traceback (most recent call last)\r\n\r\n[<ipython-input-1-ffa43f172f2b>](https://localhost:8080/#) in <cell line: 19>()\r\n     17 \r\n     18 # LayoutLM Document QA\r\n---> 19 pdf_analyzer = LayoutLMDocumentQA()\r\n     20 \r\n     21 question = \"What is the total amount of expenses?\"\r\n\r\n[/usr/local/lib/python3.10/dist-packages/swarms/models/layoutlm_document_qa.py](https://localhost:8080/#) in __init__(self, model_name, task_type)\r\n     27         task_type: str = \"document-question-answering\",\r\n     28     ):\r\n---> 29         self.pipeline = pipeline(self.task_type, model=self.model_name)\r\n     30 \r\n     31     def __call__(self, task: str, img_path: str):\r\n\r\nAttributeError: 'LayoutLMDocumentQA' object has no attribute 'task_type'\r\n```",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-11-18T20:52:33Z",
      "updated_at": "2025-03-20T16:24:20Z",
      "closed_at": "2023-11-24T23:51:47Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/157/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/157",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/157",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:46.455361",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "The docs for the library are: https://huggingface.co/impira/layoutlm-document-qa",
          "created_at": "2023-11-18T21:16:17Z"
        },
        {
          "author": "evelynmitchell",
          "body": "The fix looks to me to be removing line 27 of swarms/models/layoutlm_document_qa.py",
          "created_at": "2023-11-18T21:17:53Z"
        },
        {
          "author": "kyegomez",
          "body": "@evelynmitchell i have fixed the input parameter with this class",
          "created_at": "2023-11-24T23:51:47Z"
        },
        {
          "author": "evelynmitchell",
          "body": "Thank you!",
          "created_at": "2023-11-24T23:52:20Z"
        }
      ]
    },
    {
      "issue_number": 156,
      "title": "[BUG] Codacy scan fingerprint mismatch",
      "body": "**Describe the bug**\r\nThe codacy scan is failing on a test base.py which uses mocks.\r\nI believe it is failing because the mock call fingerprint would be different from run to run.\r\n\r\nI propose removing the base.py from the codacy scan.\r\n```\r\non:\r\n  push:\r\n    branches: [main, protected]\r\n  pull_request:\r\n    branches: [main]\r\n    paths-ignore:\r\n      - '**/*.md'\r\n      - '**/*.txt'\r\n      - 'tests/tools/base.py'\r\n```\r\n\r\nSee (https://github.com/kyegomez/swarms/actions/runs/6910593843/job/18803966896?pr=155) for an example of the failing run.",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-11-18T18:53:09Z",
      "updated_at": "2025-03-20T16:24:20Z",
      "closed_at": "2023-12-06T03:59:27Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/156/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/156",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/156",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:46.687338",
      "comments": []
    },
    {
      "issue_number": 154,
      "title": "[BUG] griptape no matching version",
      "body": "\r\nThe run_test.yml action is failing due to griptape dependency.\r\n```\r\nERROR: Could not find a version that satisfies the requirement griptape (from versions: none)\r\nERROR: No matching distribution found for griptape\r\n```\r\n(https://github.com/kyegomez/swarms/actions/runs/6910013445)",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-11-17T23:54:41Z",
      "updated_at": "2025-03-20T16:24:20Z",
      "closed_at": "2023-11-27T04:17:45Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/154/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/154",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/154",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:46.687359",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@evelynmitchell griptape has been officially removed from Swarms",
          "created_at": "2023-11-18T00:03:36Z"
        },
        {
          "author": "evelynmitchell",
          "body": "Thanks. I'll sort out the requirements.",
          "created_at": "2023-11-18T00:14:49Z"
        },
        {
          "author": "evelynmitchell",
          "body": "Basechunker.md mentions griptape\r\nI don't know what basechunker is.",
          "created_at": "2023-11-18T00:20:16Z"
        },
        {
          "author": "evelynmitchell",
          "body": "swarms/artifacts/base.py looks like it needs a section deleted:\r\n```\r\n def from_dict(cls, artifact_dict: dict) -> BaseArtifact:\r\n        from griptape.schemas import (\r\n            TextArtifactSchema,\r\n            InfoArtifactSchema,\r\n            ErrorArtifactSchema,\r\n            BlobArtifactSchema,",
          "created_at": "2023-11-18T00:22:26Z"
        },
        {
          "author": "evelynmitchell",
          "body": "swarms/artifacts/error_artifact.py also needs a section removed:\r\n```\r\n    def to_dict(self) -> dict:\r\n        from griptape.schemas import ErrorArtifactSchema\r\n\r\n        return dict(ErrorArtifactSchema().dump(self))\r\n```",
          "created_at": "2023-11-18T00:23:31Z"
        }
      ]
    },
    {
      "issue_number": 148,
      "title": "[BUG] ",
      "body": "the import instruction in the omni...pd example is missing the omni.modal.agent after the .swarms.",
      "state": "closed",
      "author": "bryonmccoy",
      "author_type": "User",
      "created_at": "2023-11-16T20:23:45Z",
      "updated_at": "2025-03-20T16:24:20Z",
      "closed_at": "2023-12-06T04:56:58Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/148/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/148",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/148",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:46.923363",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2023-11-16T20:24:17Z"
        },
        {
          "author": "kyegomez",
          "body": "@bryonmccoy just added more docs",
          "created_at": "2023-12-06T04:56:58Z"
        }
      ]
    },
    {
      "issue_number": 147,
      "title": "[BUG] Flow class logic seems to be repeating itself in its outputs (repeating same exact text multiple times in one output)",
      "body": "AI: To create a playable Super Mario clone in your browser, you will need to write the necessary HTML code. The provided code serves as a starting point and sets up the basic structure and styling of the game.\r\n\r\nLet's break down the code and understand its components:\r\n\r\n1. The `<!DOCTYPE html>` declaration specifies that this is an HTML5 document.\r\n2. The `<html>` element is the root element of the HTML page.\r\n3. The `<head>` element contains meta-information about the document, such as the title and external CSS or JavaScript files.\r\n4. The `<title>` element sets the title of the page, which is displayed in the browser's title bar or tab.\r\n5. The `<style>` element contains CSS code to define the appearance and layout of the game.\r\n6. The `#game-container` selector styles the main container for the game. It sets the width, height, background color, position, and overflow properties.\r\n7. The `.character` selector styles the character elements in the game. It sets the width, height, position, and bottom properties.\r\n8. The `#mario` selector styles the Mario character specifically. It sets the background color to red.\r\n9. The `#platform` selector styles the platform element in the game. It sets the background color, width, height, position, bottom, and left properties.\r\n10. The `<body>` element represents the content of the HTML page.\r\n11. The `<div id=\"game-container\">` creates the main container for the game.\r\n12. The `<div id=\"mario\" class=\"character\">` creates the player character element, which is styled using the `character` class and the `mario` id.\r\n13. The `<div id=\"platform\">` creates the platform element, which Mario can stand on.\r\n14. The `<script>` element is used to embed or reference JavaScript code.\r\n15. The JavaScript code for the game logic should be added inside the `<script>` tags. This is where you would implement the game mechanics, physics, and controls.\r\n\r\nKeep in mind that the provided code is just a starting point, and you will need to invest significant time and effort to develop a complete game. Creating a fully functional Super Mario clone is a complex task that requires advanced programming knowledge and skills.\r\nTo create a playable Super Mario clone in your browser, you will need to write the necessary HTML code. The provided code serves as a starting point and sets up the basic structure and styling of the game.\r\n\r\nLet's break down the code and understand its components:\r\n\r\n1. The `<!DOCTYPE html>` declaration specifies that this is an HTML5 document.\r\n2. The `<html>` element is the root element of the HTML page.\r\n3. The `<head>` element contains meta-information about the document, such as the title and external CSS or JavaScript files.\r\n4. The `<title>` element sets the title of the page, which is displayed in the browser's title bar or tab.\r\n5. The `<style>` element contains CSS code to define the appearance and layout of the game.\r\n6. The `#game-container` selector styles the main container for the game. It sets the width, height, background color, position, and overflow properties.\r\n7. The `.character` selector styles the character elements in the game. It sets the width, height, position, and bottom properties.\r\n8. The `#mario` selector styles the Mario character specifically. It sets the background color to red.\r\n9. The `#platform` selector styles the platform element in the game. It sets the background color, width, height, position, bottom, and left properties.\r\n10. The `<body>` element represents the content of the HTML page.\r\n11. The `<div id=\"game-container\">` creates the main container for the game.\r\n12. The `<div id=\"mario\" class=\"character\">` creates the player character element, which is styled using the `character` class and the `mario` id.\r\n13. The `<div id=\"platform\">` creates the platform element, which Mario can stand on.\r\n14. The `<script>` element is used to embed or reference JavaScript code.\r\n15. The JavaScript code for the game logic should be added inside the `<script>` tags. This is where you would implement the game mechanics, physics, and controls.\r\n\r\nKeep in mind that the provided code is just a starting point, and you will need to invest significant time and effort to develop a complete game. Creating a fully functional Super Mario clone is a complex task that requires advanced programming knowledge and skills.",
      "state": "closed",
      "author": "elder-plinius",
      "author_type": "User",
      "created_at": "2023-11-16T00:18:24Z",
      "updated_at": "2025-03-20T16:24:20Z",
      "closed_at": "2023-11-24T23:53:08Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/147/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ZackBradshaw",
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/147",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/147",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:47.127275",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@elder-plinius what should we do? How can we fix this?",
          "created_at": "2023-11-17T23:23:59Z"
        },
        {
          "author": "kyegomez",
          "body": "@elder-plinius i have fixed this with a print statement",
          "created_at": "2023-11-24T23:53:08Z"
        }
      ]
    },
    {
      "issue_number": 146,
      "title": "[BUG] Nougat wrong number positional args",
      "body": "Traceback (most recent call last):\r\n  File \"C:\\Users\\Guest1\\Desktop\\swarms\\playground\\demos\\accountant_team\\accountant_team.py\", line 22, in <module>\r\n    answer = pdf_analyzer(\r\n             ^^^^^^^^^^^^^\r\nTypeError: Nougat.__call__() takes 2 positional arguments but 3 were given",
      "state": "closed",
      "author": "elder-plinius",
      "author_type": "User",
      "created_at": "2023-11-15T23:00:36Z",
      "updated_at": "2025-03-20T16:24:19Z",
      "closed_at": "2023-11-25T06:17:44Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/146/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/146",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/146",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:47.295686",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@elder-plinius this error has been eliminated. thanks",
          "created_at": "2023-11-25T06:17:44Z"
        }
      ]
    },
    {
      "issue_number": 145,
      "title": "[BUG] LayoutMLDocumentQA param issue (no attribute task_type)",
      "body": "Traceback (most recent call last):\r\n  File \"C:\\Users\\Guest1\\Desktop\\swarms\\playground\\demos\\accountant_team\\accountant_team.py\", line 19, in <module>\r\n    pdf_analyzer = LayoutLMDocumentQA()\r\n                   ^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\Guest1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\swarms\\models\\layoutlm_document_qa.py\", line 29, in __init__\r\n    self.pipeline = pipeline(self.task_type, model=self.model_name)\r\n                             ^^^^^^^^^^^^^^\r\nAttributeError: 'LayoutLMDocumentQA' object has no attribute 'task_type'",
      "state": "closed",
      "author": "elder-plinius",
      "author_type": "User",
      "created_at": "2023-11-15T22:48:57Z",
      "updated_at": "2025-03-20T16:24:19Z",
      "closed_at": "2023-11-17T23:24:12Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/145/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/145",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/145",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:47.494504",
      "comments": []
    },
    {
      "issue_number": 144,
      "title": "[BUG] ",
      "body": "**Describe the bug**\r\nsequential_workflow_example.py needs to check for a blank api key and prompt the user to enter it in some way.\r\nWhen running in a container. the end user may not have an editor, so some way of reminding them to pass it in, say through the environment OPENAI_API_KEY=\"\" would be good.\r\nSee: https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety\r\n\r\n**To Reproduce**\r\nWhen sequential_workflow_example.py is run within a container, it runs and does not produce an error, even though there is no API Key\r\n\r\n**Expected behavior**\r\nThat the key missing is identified and  passed up to the end user, so they can correct the lack.\r\n\r\n**Screenshots**\r\n\r\n\r\n**Additional context**\r\nWithin the docker container.",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-11-15T22:46:39Z",
      "updated_at": "2025-03-20T16:24:19Z",
      "closed_at": "2023-12-18T23:03:22Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/144/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/144",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/144",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:47.494523",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@evelynmitchell Sorry it depends on the llm you enter in, if you don't enter in the api_key param then it will default to the env",
          "created_at": "2023-11-15T23:08:53Z"
        },
        {
          "author": "evelynmitchell",
          "body": "The person running the program needs to be told how to correct the error when they run the program..",
          "created_at": "2023-11-15T23:13:50Z"
        },
        {
          "author": "evelynmitchell",
          "body": "This can be closed ",
          "created_at": "2023-12-18T19:58:34Z"
        }
      ]
    },
    {
      "issue_number": 143,
      "title": "[BUG] Flow class looping its own prompt with BioGPT",
      "body": "                Flow Dashboard\r\n                --------------------------------------------\r\n\r\n                Flow loop is initializing for 5 with the following configuration:\r\n\r\n                Model Configuration:     Model name: microsoft/biogpt\r\n    Max length: 500\r\n    Num return sequences: 5\r\n    Do sample: True\r\n    Min length: 100\r\n                ----------------------------------------\r\n\r\n                Flow Configuration:\r\n                    Name: Flow agent\r\n                    System Prompt:\r\nYou are an autonomous agent granted autonomy in a autonomous loop structure.\r\nYour role is to engage in multi-step conversations with your self or the user,\r\ngenerate long-form content like blogs, screenplays, or SOPs,\r\nand accomplish tasks bestowed by the user.\r\n\r\nYou can have internal dialogues with yourself or can interact with the user\r\nto aid in these complex tasks. Your responses should be coherent, contextually relevant, and tailored to the task at hand.\r\n\r\n\r\n                    Task: Generate a 10,000 word blog on mental clarity and the benefits of meditation.\r\n                    Max Loops: 5\r\n                    Stopping Condition: None\r\n                    Loop Interval: 1\r\n                    Retry Attempts: 3\r\n                    Retry Interval: 1\r\n                    Interactive: False\r\n                    Dashboard: True\r\n                    Dynamic Temperature: False\r\n                    Autosave: False\r\n                    Saved State: flow_state.json\r\n\r\n                ----------------------------------------\r\n\r\n\r\nLoop 1 of 5\r\n\r\n\r\nAI:\r\n            SYSTEM_PROMPT:\r\nYou are an autonomous agent granted autonomy in a autonomous loop structure.\r\nYour role is to engage in multi-step conversations with your self or the user,\r\ngenerate long-form content like blogs, screenplays, or SOPs,\r\nand accomplish tasks bestowed by the user.\r\n\r\nYou can have internal dialogues with yourself or can interact with the user\r\nto aid in these complex tasks. Your responses should be coherent, contextually relevant, and tailored to the task at hand.\r\n\r\n\r\n\r\n            History: Generate a 10,000 word blog on mental clarity and the benefits of meditation.\r\n\r\n\r\n            SYSTEM_PROMPT:\r\nYou are an autonomous agent granted autonomy in a autonomous loop structure.\r\nYour role is to engage in multi-step conversations with your self or the user,\r\ngenerate long-form content like blogs, screenplays, or SOPs,\r\nand accomplish tasks bestowed by the user.\r\n\r\nYou can have internal dialogues with yourself or can interact with the user\r\nto aid in these complex tasks. Your responses should be coherent, contextually relevant, and tailored to the task at hand.\r\n\r\n\r\n\r\n            History: Generate a 10,000 word blog on mental clarity and the benefits of meditation.",
      "state": "closed",
      "author": "elder-plinius",
      "author_type": "User",
      "created_at": "2023-11-15T22:21:47Z",
      "updated_at": "2025-03-20T16:24:19Z",
      "closed_at": "2023-12-06T23:11:55Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/143/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/143",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/143",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:47.687644",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@elder-plinius please try again this file and lmk if it works",
          "created_at": "2023-11-25T06:18:28Z"
        }
      ]
    },
    {
      "issue_number": 142,
      "title": "[BUG] ModuleNotFoundError: No module named 'swarms.swarms'; 'swarms' is not a package",
      "body": "```\r\nv@v-System-Product-Name:~/swarms$ /bin/python3 /home/v/swarms/tests/swarms/autoscaler.py\r\nTraceback (most recent call last):\r\n  File \"/home/v/swarms/tests/swarms/autoscaler.py\", line 2, in <module>\r\n    from swarms.swarms.autoscaler import AutoScaler, Worker\r\n  File \"/home/v/swarms/tests/swarms/swarms.py\", line 4, in <module>\r\n    from swarms.swarms.swarms import (\r\nModuleNotFoundError: No module named 'swarms.swarms'; 'swarms' is not a package\r\nv@v-System-Product-Name:~/swarms$ /bin/python3 /home/v/swarms/tests/swarms/autoscaler.py\r\nTraceback (most recent call last):\r\n  File \"/home/v/swarms/tests/swarms/autoscaler.py\", line 2, in <module>\r\n    from swarms.autoscaler import AutoScaler, Worker\r\n  File \"/home/v/swarms/tests/swarms/swarms.py\", line 4, in <module>\r\n    from swarms.swarms.swarms import (\r\nModuleNotFoundError: No module named 'swarms.swarms'; 'swarms' is not a package\r\nv@v-System-Product-Name:~/swarms$ /bin/python3 /home/v/swarms/tests/swarms/dialogue_simulator.py\r\nTraceback (most recent call last):\r\n  File \"/home/v/swarms/tests/swarms/dialogue_simulator.py\", line 2, in <module>\r\n    from swarms.swarms.dialogue_simulator import DialogueSimulator, Worker\r\n  File \"/home/v/swarms/tests/swarms/swarms.py\", line 4, in <module>\r\n    from swarms.swarms.swarms import (\r\nModuleNotFoundError: No module named 'swarms.swarms'; 'swarms' is not a package\r\nv@v-System-Product-Name:~/swarms$ /bin/python3 /home/v/swarms/tests/swarms/godmode.py\r\nTraceback (most recent call last):\r\n  File \"/home/v/swarms/tests/swarms/godmode.py\", line 2, in <module>\r\n    from swarms.swarms.god_mode import GodMode, LLM\r\n  File \"/home/v/swarms/tests/swarms/swarms.py\", line 4, in <module>\r\n    from swarms.swarms.swarms import (\r\nModuleNotFoundError: No module named 'swarms.swarms'; 'swarms' is not a package\r\nv@v-System-Product-Name:~/swarms$ /bin/python3 /home/v/swarms/tests/swarms/groupchat.py\r\nTraceback (most recent call last):\r\n  File \"/home/v/swarms/tests/swarms/groupchat.py\", line 3, in <module>\r\n    from swarms.models import OpenAIChat\r\n  File \"/home/v/swarms/tests/swarms/swarms.py\", line 4, in <module>\r\n    from swarms.swarms.swarms import (\r\nModuleNotFoundError: No module named 'swarms.swarms'; 'swarms' is not a package\r\nv@v-System-Product-Name:~/swarms$ /bin/python3 /home/v/swarms/tests/swarms/multi_agent_collab.py\r\nTraceback (most recent call last):\r\n  File \"/home/v/swarms/tests/swarms/multi_agent_collab.py\", line 2, in <module>\r\n    from swarms.swarms.multi_agent_collab import (\r\n  File \"/home/v/swarms/tests/swarms/swarms.py\", line 4, in <module>\r\n    from swarms.swarms.swarms import (\r\nModuleNotFoundError: No module named 'swarms.swarms'; 'swarms' is not a package``\r\n```",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-15T21:38:04Z",
      "updated_at": "2025-03-20T16:24:19Z",
      "closed_at": "2023-11-17T23:28:59Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/142/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/142",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/142",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:47.890876",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@vyomakesh09 this has been fixed, run the tests again",
          "created_at": "2023-11-17T23:28:59Z"
        }
      ]
    },
    {
      "issue_number": 141,
      "title": "[BUG] AttributeError: partially initialized module 'whisperx' has no attribute 'DiarizationPipeline' (most likely due to a circular import)",
      "body": "Traceback (most recent call last):\r\n  File \"/home/v/swarms/tests/models/whisperx.py\", line 7, in <module>\r\n    import whisperx\r\n  File \"/home/v/swarms/tests/models/whisperx.py\", line 51, in <module>\r\n    @patch.object(whisperx.DiarizationPipeline, \"__call__\")\r\nAttributeError: partially initialized module 'whisperx' has no attribute 'DiarizationPipeline' (most likely due to a circular import)",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-15T21:31:30Z",
      "updated_at": "2025-03-20T16:24:19Z",
      "closed_at": "2023-12-06T04:32:48Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/141/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/141",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/141",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:48.095085",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@vyomakesh09 pls try again and run this test and lmk if it works",
          "created_at": "2023-11-25T06:16:54Z"
        }
      ]
    },
    {
      "issue_number": 140,
      "title": "[BUG] RuntimeError: no validator found for <class 'transformers.models.auto.modeling_auto.AutoModelForVision2Seq'>, see `arbitrary_types_allowed` in Config",
      "body": "Traceback (most recent call last):\r\n  File \"/home/v/swarms/tests/models/kosmos2.py\", line 4, in <module>\r\n    from swarms.models.kosmos2 import Kosmos2, Detections\r\n  File \"/home/v/.local/lib/python3.10/site-packages/swarms/models/kosmos2.py\", line 34, in <module>\r\n    class Kosmos2(BaseModel):\r\n  File \"pydantic/main.py\", line 197, in pydantic.main.ModelMetaclass.__new__\r\n  File \"pydantic/fields.py\", line 506, in pydantic.fields.ModelField.infer\r\n  File \"pydantic/fields.py\", line 436, in pydantic.fields.ModelField.__init__\r\n  File \"pydantic/fields.py\", line 557, in pydantic.fields.ModelField.prepare\r\n  File \"pydantic/fields.py\", line 831, in pydantic.fields.ModelField.populate_validators\r\n  File \"pydantic/validators.py\", line 765, in find_validators\r\nRuntimeError: no validator found for <class 'transformers.models.auto.modeling_auto.AutoModelForVision2Seq'>, see `arbitrary_types_allowed` in Config",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-15T21:29:09Z",
      "updated_at": "2025-03-20T16:24:19Z",
      "closed_at": "2024-01-03T18:04:58Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/140/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/140",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/140",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:48.254516",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "This can be closed.",
          "created_at": "2024-01-01T00:24:07Z"
        }
      ]
    },
    {
      "issue_number": 139,
      "title": "[BUG] ModuleNotFoundError: No module named 'playground'",
      "body": "Traceback (most recent call last):\r\n  File \"/home/v/swarms/tests/models/dalle3.py\", line 9, in <module>\r\n    from playground.models.dalle3 import Dalle3\r\nModuleNotFoundError: No module named 'playground'",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-15T19:16:42Z",
      "updated_at": "2025-03-20T16:24:18Z",
      "closed_at": "2023-11-17T23:29:26Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/139/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/139",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/139",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:48.437406",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@vyomakesh09 this has been fixed, the wrong import error ",
          "created_at": "2023-11-17T23:29:26Z"
        }
      ]
    },
    {
      "issue_number": 138,
      "title": "[BUG] NameError: name 'getenv' is not defined",
      "body": "Traceback (most recent call last):\r\n  File \"/home/v/swarms/tests/models/ada.py\", line 6, in <module>\r\n    from swarms.models.simple_ada import (\r\n  File \"/home/v/.local/lib/python3.10/site-packages/swarms/models/simple_ada.py\", line 3, in <module>\r\n    client = OpenAI(api_key=getenv(\"OPENAI_API_KEY\"))\r\nNameError: name 'getenv' is not defined",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-15T19:14:17Z",
      "updated_at": "2025-03-20T16:24:18Z",
      "closed_at": "2023-11-20T07:16:31Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/138/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/138",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/138",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:48.646568",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@vyomakesh09 this code has been deleted!",
          "created_at": "2023-11-20T07:16:31Z"
        }
      ]
    },
    {
      "issue_number": 137,
      "title": "[BUG] ModuleNotFoundError: No module named 'swarms.memory.vector_stores' ",
      "body": "Traceback (most recent call last):\r\n  File \"/home/v/swarms/tests/memory/oceandb.py\", line 3, in <module>\r\n    from swarms.memory.ocean import OceanDB\r\n  File \"/home/v/.local/lib/python3.10/site-packages/swarms/memory/__init__.py\", line 1, in <module>\r\n    from swarms.memory.pinecone import PineconeVector\r\n  File \"/home/v/.local/lib/python3.10/site-packages/swarms/memory/pinecone.py\", line 2, in <module>\r\n    from swarms.memory.vector_stores.base import BaseVector\r\nModuleNotFoundError: No module named 'swarms.memory.vector_stores'",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-15T19:10:20Z",
      "updated_at": "2025-03-20T16:24:18Z",
      "closed_at": "2023-11-17T23:26:27Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/137/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/137",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/137",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:48.808721",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@vyomakesh09 this has been fixed",
          "created_at": "2023-11-17T23:26:27Z"
        }
      ]
    },
    {
      "issue_number": 122,
      "title": "[BUG] ImportError: cannot import name 'SpeechToText' from 'swarms.models.whisperx'",
      "body": "Traceback (most recent call last):\r\n  File \"/home/v/swarms/tests/models/whisperx.py\", line 7, in <module>\r\n    import whisperx\r\n  File \"/home/v/swarms/tests/models/whisperx.py\", line 12, in <module>\r\n    from swarms.models.whisperx import SpeechToText\r\nImportError: cannot import name 'SpeechToText' from 'swarms.models.whisperx' (/home/v/.local/lib/python3.10/site-packages/swarms/models/whisperx.py)",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-11T22:24:46Z",
      "updated_at": "2025-03-20T16:24:18Z",
      "closed_at": "2023-11-11T22:41:40Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/122/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/122",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/122",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:48.969316",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@vyomakesh09 Just fixed this by changing all SpeechToText -> WhisperX",
          "created_at": "2023-11-11T22:41:40Z"
        }
      ]
    },
    {
      "issue_number": 135,
      "title": "[BUG] problem with \"stop\" call (openai 0.28.1)",
      "body": "INFO:openai:error_code=None error_message=\"'$.stop' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\" error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False",
      "state": "closed",
      "author": "elder-plinius",
      "author_type": "User",
      "created_at": "2023-11-15T18:03:26Z",
      "updated_at": "2025-03-20T16:24:17Z",
      "closed_at": "2023-11-17T23:38:23Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/135/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/135",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/135",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:49.157839",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@elder-plinius you must revert your openai to 0.28.1 by pip uninstall openai then pip install openai==0.28.1",
          "created_at": "2023-11-15T19:00:53Z"
        },
        {
          "author": "elder-plinius",
          "body": "> @elder-plinius you must revert your openai to 0.28.1 by pip uninstall openai then pip install openai==0.28.1\r\n\r\nyes thats the version I'm using. might be a problem with OpenAIChat, maybe this bit of code? \r\n\r\nasync def _agenerate(\r\n        self,\r\n        prompts: List[str],\r\n        stop: Optional",
          "created_at": "2023-11-15T19:05:34Z"
        },
        {
          "author": "elder-plinius",
          "body": "concurent futures threading was causing this issue",
          "created_at": "2023-11-17T23:38:23Z"
        }
      ]
    },
    {
      "issue_number": 127,
      "title": "[BUG] example.py marshmallow not found",
      "body": "**Describe the bug**\r\nclean install\r\nran example.com\r\n```\r\nTraceback (most recent call last):\r\n  File \"/content/swarms/example.py\", line 1, in <module>\r\n    from swarms.models import OpenAIChat\r\n  File \"/content/swarms/swarms/__init__.py\", line 10, in <module>\r\n    from swarms.swarms import *  # noqa: E402, F403\r\n  File \"/content/swarms/swarms/swarms/__init__.py\", line 2, in <module>\r\n    from swarms.swarms.autoscaler import AutoScaler\r\n  File \"/content/swarms/swarms/swarms/autoscaler.py\", line 5, in <module>\r\n    from swarms.structs.flow import Flow\r\n  File \"/content/swarms/swarms/structs/__init__.py\", line 1, in <module>\r\n    from swarms.structs.workflow import Workflow\r\n  File \"/content/swarms/swarms/structs/workflow.py\", line 6, in <module>\r\n    from swarms.structs.task import Task\r\n  File \"/content/swarms/swarms/structs/task.py\", line 12, in <module>\r\n    from swarms.artifacts.error_artifact import ErrorArtifact\r\n  File \"/content/swarms/swarms/artifacts/error_artifact.py\", line 3, in <module>\r\n    from swarms.artifacts.base import BaseArtifact\r\n  File \"/content/swarms/swarms/artifacts/base.py\", line 6, in <module>\r\n    from marshmallow import class_registry\r\nModuleNotFoundError: No module named 'marshmallow'\r\n```",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-11-11T23:26:20Z",
      "updated_at": "2025-03-20T16:24:17Z",
      "closed_at": "2023-11-13T21:47:12Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/127/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/127",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/127",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:49.377342",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "Likely fix, adding marshmallow to dependencies pyproject.toml, and swarms/swarms/artifacts __init__.py",
          "created_at": "2023-11-11T23:28:21Z"
        },
        {
          "author": "evelynmitchell",
          "body": "After adding pip install marshmallow, the error changes to:\r\n```\r\nInstalling collected packages: marshmallow\r\nSuccessfully installed marshmallow-3.20.1\r\nTraceback (most recent call last):\r\n  File \"/content/swarms/example.py\", line 1, in <module>\r\n    from swarms.models import OpenAIChat\r\n  File \"/co",
          "created_at": "2023-11-11T23:32:12Z"
        },
        {
          "author": "evelynmitchell",
          "body": "I was testing with this notebook, doing a poetry install. \r\nHad to add 'pip install chromadb'\r\nexample.py produces no output, but it runs.\r\n\r\n```\r\n!git clone https://github.com/kyegomez/swarms\r\n%cd /content/swarms\r\n!pip install poetry\r\n!poetry install\r\n\r\n!pip install marshmallow\r\n!pip install chroma",
          "created_at": "2023-11-11T23:42:36Z"
        },
        {
          "author": "kyegomez",
          "body": "@evelynmitchell thanks for reporting these issues, I've fixed the marshmellow and chromadb by adding it into requirements and pyproejct.toml and the example.py does not run because OPENAI changed their api, so it will not work unless we update the api, until then try a different model!",
          "created_at": "2023-11-13T21:47:12Z"
        }
      ]
    },
    {
      "issue_number": 120,
      "title": "[BUG] ",
      "body": "**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n\r\n\r\nswarms-web_demo-1          |     from swarms.models import *\r\nswarms-web_demo-1          |   File \"/app/swarms/models/__init__.py\", line 14, in <module>\r\nswarms-web_demo-1          |     from swarms.models.kosmos_two import Kosmos\r\nswarms-web_demo-1          |   File \"/app/swarms/models/kosmos_two.py\", line 3, in <module>",
      "state": "closed",
      "author": "ZackBradshaw",
      "author_type": "User",
      "created_at": "2023-11-11T04:17:43Z",
      "updated_at": "2025-03-20T16:24:17Z",
      "closed_at": "2023-11-11T05:34:42Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/120/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/120",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/120",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:49.550010",
      "comments": [
        {
          "author": "ZackBradshaw",
          "body": "This was an issue with kosmos_two  removed this this pr is resolved by #115 ",
          "created_at": "2023-11-11T05:34:42Z"
        },
        {
          "author": "kyegomez",
          "body": "@ZackBradshaw this is really broad, I don't see a trace stack, what's the error?",
          "created_at": "2023-11-11T16:32:50Z"
        },
        {
          "author": "ZackBradshaw",
          "body": "> @ZackBradshaw this is really broad, I don't see a trace stack, what's the error?\n\nOh we resolved this last night I thought I closed this I'll do that now",
          "created_at": "2023-11-11T16:35:34Z"
        }
      ]
    },
    {
      "issue_number": 119,
      "title": "[BUG] ",
      "body": "**Describe the bug**\r\n```\r\npip3 install swarms\r\n```\r\n\r\nCopied the content of example.py into cell\r\n```\r\nfrom swarms.models import OpenAIChat\r\nfrom swarms.structs import Flow\r\n\r\napi_key = ...\r\n```\r\n\r\nImportError: cannot import name 'OpenAIChat' from 'swarms.models' (/usr/local/lib/python3.10/dist-packages/swarms/models/__init__.py)\r\n\r\nFix:\r\nAdd OpenAIChat to swarms.models __init__.py",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-11-11T02:19:01Z",
      "updated_at": "2025-03-20T16:24:17Z",
      "closed_at": "2023-11-11T22:33:51Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/119/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/119",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/119",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:49.783308",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@evelynmitchell Fixed but you need 2 verisons to run OpenAIChat, it requires verison 0.28.1!",
          "created_at": "2023-11-11T22:33:51Z"
        }
      ]
    },
    {
      "issue_number": 118,
      "title": "[BUG] ",
      "body": "**Describe the bug**\r\nI was testing a change to swarms/__init__.py to add \"OpenAIChat\" to the list of imports.\r\n\r\nThat triggered an error, which is referencing a file it can't find.\r\n\"Traceback (most recent call last):\r\n  File \"/content/swarms/example.py\", line 1, in <module>\r\n    from swarms.models import OpenAIChat\r\n  File \"/content/swarms/swarms/__init__.py\", line 9, in <module>\r\n    from swarms.agents import *\r\n  File \"/content/swarms/swarms/agents/__init__.py\", line 2, in <module>\r\n    from swarms.agents.hf_agents import HFAgent\r\n  File \"/content/swarms/swarms/agents/hf_agents.py\", line 7, in <module>\r\n    from huggingface_hub import hf_hub_download, list_spaces\r\nModuleNotFoundError: No module named 'huggingface_hub'\r\n\r\nIt appears that hf has changed the endpoint for list_spaces to be:\r\nhttps://huggingface.co/docs/huggingface_hub/v0.19.0/en/package_reference/hf_api#huggingface_hub.HfApi.list_spaces\r\n\r\nI don't have a fix.",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-11-11T01:07:55Z",
      "updated_at": "2025-03-20T16:24:17Z",
      "closed_at": "2023-11-11T22:37:03Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/118/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/118",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/118",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:49.979220",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@evelynmitchell Just fixed, deleted problematic code altogether. thanks for the issue!",
          "created_at": "2023-11-11T22:37:03Z"
        }
      ]
    },
    {
      "issue_number": 114,
      "title": "[FEAT][Multiple Tools in Parallel for the `Flow` class",
      "body": null,
      "state": "closed",
      "author": "ZackBradshaw",
      "author_type": "User",
      "created_at": "2023-11-10T00:54:23Z",
      "updated_at": "2025-03-20T16:24:16Z",
      "closed_at": "2024-03-26T12:44:40Z",
      "labels": [
        "no-issue-activity"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/114/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ZackBradshaw"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/114",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/114",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:50.165995",
      "comments": [
        {
          "author": "ZackBradshaw",
          "body": "This is on hold till #85  is merged this has the capability to read these formats through more testing and documentation will be required",
          "created_at": "2023-11-13T16:45:46Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "Stale issue message",
          "created_at": "2024-01-13T12:44:07Z"
        },
        {
          "author": "evelynmitchell",
          "body": "Can this be closed?",
          "created_at": "2024-01-18T03:55:11Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "Stale issue message",
          "created_at": "2024-03-19T12:44:22Z"
        }
      ]
    },
    {
      "issue_number": 112,
      "title": "[BUG] autotab tool for browser agent ",
      "body": "**Describe the bug**\nBrowser agent tool imports GitHub repo directly.\n        \"https://github.com/Planetary-Computers/autotab-extension/raw/main/autotab.crx\"\n\nThis feels like a workaround. This is a placeholder issue to clean it up.",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-11-09T13:48:24Z",
      "updated_at": "2025-03-20T16:24:16Z",
      "closed_at": "2023-11-27T04:18:08Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/112/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/112",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/112",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:50.419473",
      "comments": []
    },
    {
      "issue_number": 111,
      "title": "[BUG] RuntimeError: Failed to import transformers.models.fuyu.processing_fuyu",
      "body": "Traceback (most recent call last):\r\n  File \"/home/v/.local/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1345, in _get_module\r\n    return importlib.import_module(\".\" + module_name, self.__name__)\r\n  File \"/usr/lib/python3.10/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n  File \"/home/v/.local/lib/python3.10/site-packages/transformers/models/fuyu/processing_fuyu.py\", line 29, in <module>\r\n    from .image_processing_fuyu import FuyuBatchFeature\r\n  File \"/home/v/.local/lib/python3.10/site-packages/transformers/models/fuyu/image_processing_fuyu.py\", line 180, in <module>\r\n    class FuyuImageProcessor(BaseImageProcessor):\r\n  File \"/home/v/.local/lib/python3.10/site-packages/transformers/models/fuyu/image_processing_fuyu.py\", line 365, in FuyuImageProcessor\r\n    resample: Optional[PILImageResampling] = None,\r\n  File \"/usr/lib/python3.10/typing.py\", line 312, in inner\r\n    return func(*args, **kwds)\r\n  File \"/usr/lib/python3.10/typing.py\", line 403, in __getitem__\r\n    return self._getitem(self, parameters)\r\n  File \"/usr/lib/python3.10/typing.py\", line 529, in Optional\r\n    arg = _type_check(parameters, f\"{self} requires a single type.\")\r\n  File \"/usr/lib/python3.10/typing.py\", line 176, in _type_check\r\n    raise TypeError(f\"{msg} Got {arg!r:.100}.\")\r\nTypeError: typing.Optional requires a single type. Got <module 'PIL.Image' from '/usr/lib/python3/dist-packages/PIL/Image.py'>.\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/v/swarms/fuyu.py\", line 1, in <module>\r\n    from swarms.models.fuyu import Fuyu\r\n  File \"/home/v/swarms/swarms/models/fuyu.py\", line 2, in <module>\r\n    from transformers import (\r\n  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\r\n  File \"/home/v/.local/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1336, in __getattr__\r\n    value = getattr(module, name)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1335, in __getattr__\r\n    module = self._get_module(self._class_to_module[name])\r\n  File \"/home/v/.local/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1347, in _get_module\r\n    raise RuntimeError(\r\nRuntimeError: Failed to import transformers.models.fuyu.processing_fuyu because of the following error (look up to see its traceback):\r\ntyping.Optional requires a single type. Got <module 'PIL.Image' from '/usr/lib/python3/dist-packages/PIL/Image.py'>.",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-08T22:10:52Z",
      "updated_at": "2025-03-20T16:24:16Z",
      "closed_at": "2023-12-06T23:20:41Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/111/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/111",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/111",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:50.419488",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@vyomakesh09 I still don't know what this error is, ",
          "created_at": "2023-11-25T06:19:12Z"
        },
        {
          "author": "kyegomez",
          "body": "@vyomakesh09 try again",
          "created_at": "2023-12-06T23:20:41Z"
        }
      ]
    },
    {
      "issue_number": 108,
      "title": "[BUG] ANTHROPIC RecursionError: maximum recursion depth exceeded while calling a Python object",
      "body": "[errors.txt](https://github.com/kyegomez/swarms/files/13300667/errors.txt)\r\n``",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-08T19:37:35Z",
      "updated_at": "2025-03-20T16:24:16Z",
      "closed_at": "2024-01-03T18:02:28Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/108/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/108",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/108",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:50.612709",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "Missing api key.\r\n\r\nThis can be closed.",
          "created_at": "2024-01-03T14:23:34Z"
        }
      ]
    },
    {
      "issue_number": 107,
      "title": "[BUG] ValueError: The following `model_kwargs` are not used by the model",
      "body": "Zephyr modal\r\n\r\n################################\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/v/inhouse/zephyr.py\", line 5, in <module>\r\n    output = model(\"Tell me a joke about programmers\")\r\n  File \"/home/v/.local/lib/python3.10/site-packages/swarms/models/zephyr.py\", line 61, in __call__\r\n    outputs = self.pipe(prompt, max_new_token=self.max_new_tokens)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/transformers/pipelines/text_generation.py\", line 208, in __call__\r\n    return super().__call__(text_inputs, **kwargs)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/transformers/pipelines/base.py\", line 1140, in __call__\r\n    return self.run_single(inputs, preprocess_params, forward_params, postprocess_params)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/transformers/pipelines/base.py\", line 1147, in run_single\r\n    model_outputs = self.forward(model_inputs, **forward_params)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/transformers/pipelines/base.py\", line 1046, in forward\r\n    model_outputs = self._forward(model_inputs, **forward_params)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/transformers/pipelines/text_generation.py\", line 271, in _forward\r\n    generated_sequence = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, **generate_kwargs)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1485, in generate\r\n    self._validate_model_kwargs(model_kwargs.copy())\r\n  File \"/home/v/.local/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1262, in _validate_model_kwargs\r\n    raise ValueError(\r\nValueError: The following `model_kwargs` are not used by the model: ['max_new_token'] (note: typos in the generate arguments will also show up in this list)",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-08T19:35:33Z",
      "updated_at": "2025-03-20T16:24:16Z",
      "closed_at": "2023-11-08T19:35:45Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/107/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/107",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/107",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:50.849385",
      "comments": []
    },
    {
      "issue_number": 106,
      "title": "[BUG] ValueError: The following `model_kwargs` are not used by the model ",
      "body": "Zephyr modal\r\n\r\n################################\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/v/inhouse/zephyr.py\", line 5, in <module>\r\n    output = model(\"Tell me a joke about programmers\")\r\n  File \"/home/v/.local/lib/python3.10/site-packages/swarms/models/zephyr.py\", line 61, in __call__\r\n    outputs = self.pipe(prompt, max_new_token=self.max_new_tokens)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/transformers/pipelines/text_generation.py\", line 208, in __call__\r\n    return super().__call__(text_inputs, **kwargs)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/transformers/pipelines/base.py\", line 1140, in __call__\r\n    return self.run_single(inputs, preprocess_params, forward_params, postprocess_params)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/transformers/pipelines/base.py\", line 1147, in run_single\r\n    model_outputs = self.forward(model_inputs, **forward_params)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/transformers/pipelines/base.py\", line 1046, in forward\r\n    model_outputs = self._forward(model_inputs, **forward_params)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/transformers/pipelines/text_generation.py\", line 271, in _forward\r\n    generated_sequence = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, **generate_kwargs)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1485, in generate\r\n    self._validate_model_kwargs(model_kwargs.copy())\r\n  File \"/home/v/.local/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1262, in _validate_model_kwargs\r\n    raise ValueError(\r\nValueError: The following `model_kwargs` are not used by the model: ['max_new_token'] (note: typos in the generate arguments will also show up in this list)",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-08T19:16:07Z",
      "updated_at": "2025-03-20T16:24:16Z",
      "closed_at": "2023-11-13T21:50:17Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/106/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/106",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/106",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:50.849410",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@vyomakesh09 fixed by removing new tokens",
          "created_at": "2023-11-13T21:50:18Z"
        }
      ]
    },
    {
      "issue_number": 105,
      "title": "[BUG] RuntimeError: Failed to import transformers.models.fuyu.processing_fuyu ",
      "body": "Traceback (most recent call last):\r\n  File \"/home/v/.local/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1345, in _get_module\r\n    return importlib.import_module(\".\" + module_name, self.__name__)\r\n  File \"/usr/lib/python3.10/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n  File \"/home/v/.local/lib/python3.10/site-packages/transformers/models/fuyu/processing_fuyu.py\", line 29, in <module>\r\n    from .image_processing_fuyu import FuyuBatchFeature\r\n  File \"/home/v/.local/lib/python3.10/site-packages/transformers/models/fuyu/image_processing_fuyu.py\", line 180, in <module>\r\n    class FuyuImageProcessor(BaseImageProcessor):\r\n  File \"/home/v/.local/lib/python3.10/site-packages/transformers/models/fuyu/image_processing_fuyu.py\", line 365, in FuyuImageProcessor\r\n    resample: Optional[PILImageResampling] = None,\r\n  File \"/usr/lib/python3.10/typing.py\", line 312, in inner\r\n    return func(*args, **kwds)\r\n  File \"/usr/lib/python3.10/typing.py\", line 403, in __getitem__\r\n    return self._getitem(self, parameters)\r\n  File \"/usr/lib/python3.10/typing.py\", line 529, in Optional\r\n    arg = _type_check(parameters, f\"{self} requires a single type.\")\r\n  File \"/usr/lib/python3.10/typing.py\", line 176, in _type_check\r\n    raise TypeError(f\"{msg} Got {arg!r:.100}.\")\r\nTypeError: typing.Optional requires a single type. Got <module 'PIL.Image' from '/usr/lib/python3/dist-packages/PIL/Image.py'>.\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/v/inhouse/fuyu.py\", line 1, in <module>\r\n    from swarms.models.fuyu import Fuyu\r\n  File \"/home/v/.local/lib/python3.10/site-packages/swarms/models/fuyu.py\", line 2, in <module>\r\n    from transformers import (\r\n  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\r\n  File \"/home/v/.local/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1336, in __getattr__\r\n    value = getattr(module, name)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1335, in __getattr__\r\n    module = self._get_module(self._class_to_module[name])\r\n  File \"/home/v/.local/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1347, in _get_module\r\n    raise RuntimeError(\r\nRuntimeError: Failed to import transformers.models.fuyu.processing_fuyu because of the following error (look up to see its traceback):\r\ntyping.Optional requires a single type. Got <module 'PIL.Image' from '/usr/lib/python3/dist-packages/PIL/Image.py'>.",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-08T18:55:09Z",
      "updated_at": "2025-03-20T16:24:16Z",
      "closed_at": "2023-11-13T21:51:46Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/105/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/105",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/105",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:51.055367",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@vyomakesh09 we have double of this issue",
          "created_at": "2023-11-13T21:51:46Z"
        }
      ]
    },
    {
      "issue_number": 104,
      "title": "[BUG] AttributeError: module 'openai' has no attribute 'Completion'. Did you mean: 'completions'?",
      "body": "OpenAI model Trace back\r\n\r\n##############################################\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/v/inhouse/oai.py\", line 8, in <module>\r\n    openai = OpenAI(openai_api_key=api_key)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/langchain/load/serializable.py\", line 90, in __init__\r\n    super().__init__(**kwargs)\r\n  File \"pydantic/main.py\", line 339, in pydantic.main.BaseModel.__init__\r\n  File \"pydantic/main.py\", line 1102, in pydantic.main.validate_model\r\n  File \"/home/v/.local/lib/python3.10/site-packages/swarms/models/openai_models.py\", line 256, in validate_environment\r\n    values[\"client\"] = openai.Completion.create()\r\nAttributeError: module 'openai' has no attribute 'Completion'. Did you mean: 'completions'?",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-08T18:50:02Z",
      "updated_at": "2025-03-20T16:24:16Z",
      "closed_at": "2024-01-03T18:04:41Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/104/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/104",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/104",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:51.231603",
      "comments": []
    },
    {
      "issue_number": 103,
      "title": "[BUG] Support Docker for easy install and use",
      "body": "\r\n**Describe the bug**\r\nN/A - Feature Request for Docker Support\r\n\r\n**To Reproduce**\r\nNot applicable as this is a feature request rather than a bug report.\r\n\r\n**Expected behavior**\r\nI am proposing the addition of Docker support for the tool. Many users could benefit from a Docker container that has everything installed and configured to run the tool. This would not only streamline the setup process for various environments but would also potentially address a range of issues that users are currently facing with installation and compatibility.\r\n\r\n**Screenshots**\r\nNot applicable.\r\n\r\n**Additional context**\r\nThrough an analysis of the repository's issues and bugs, it is evident that a significant number of them are related to environment setup and configuration challenges. Providing a Dockerfile and supporting documentation would allow users to run the tool in a containerized environment, ensuring consistency across different systems and significantly reducing the setup time. This would likely result in a reduction of environment-specific issues and improve overall user satisfaction with the tool. Moreover, a Docker container would facilitate easier adoption and testing of the tool across different platforms, which could lead to increased use and contributions to the project.\r\n\r\n---\r\n\r\nRemember to adjust the context to the specific details of the repository and the issues you've observed. This template acts as a suggestion rather than a bug report and should be modified to fit the particularities of the repository's contribution process.",
      "state": "closed",
      "author": "efreethy",
      "author_type": "User",
      "created_at": "2023-11-08T01:13:59Z",
      "updated_at": "2025-03-20T16:24:15Z",
      "closed_at": "2023-11-13T21:51:24Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/103/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/103",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/103",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:51.231624",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2023-11-08T01:14:45Z"
        },
        {
          "author": "kyegomez",
          "body": "@efreethy what do you have in mind? A simple to run Docker container? Or a more meticulous experience?",
          "created_at": "2023-11-08T17:00:02Z"
        },
        {
          "author": "kyegomez",
          "body": "@efreethy Hey I have added a Dockerfile, it does take some time to run and let me know if it works for you!",
          "created_at": "2023-11-13T21:51:24Z"
        }
      ]
    },
    {
      "issue_number": 99,
      "title": "[BUG] module not found langchain schema vectorstore",
      "body": "**Describe the bug**\r\nModuleNotFoundError: No module named 'langchain.schema.vectorstore'\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n\r\n\r\npip install swarms\r\n\r\nimport swarms",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-11-07T01:17:34Z",
      "updated_at": "2025-03-20T16:24:15Z",
      "closed_at": "2023-11-08T05:09:22Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/99/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/99",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/99",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:51.509780",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@evelynmitchell this issue has been handled! Removed all calls to worker which called these tools!",
          "created_at": "2023-11-08T05:09:16Z"
        }
      ]
    },
    {
      "issue_number": 97,
      "title": "[BUG] groupchat",
      "body": "message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions\r\napi_version=None data='{\"prompt\": [\"\\\\n\\\\n        SYSTEM_PROMPT: \\\\n        You are in a role play game. The following roles are available:\\\\n        silly: YOU ARE SILLY, YOU OFFER NOTHING OF VALUE\\\\ndetective: YOU ARE VERY SMART AND ANSWER RIDDLES\\\\nriddler: YOU MAKE RIDDLES.\\\\n\\\\n        Read the following conversation.\\\\n        Then select the next role from [\\'silly\\', \\'detective\\', \\'riddler\\'] to play. Only return the role.\\\\n        \\\\n\\\\n        History: \\'manager:Write me a riddle\\\\n\\'system:Read the above conversation. Then select the next most suitable role from [\\'silly\\', \\'detective\\', \\'riddler\\'] to play. Only return the role.\\\\n\\\\n        Your response:\\\\n        \"], \"model\": \"text-davinci-003\", \"temperature\": 0.5, \"max_tokens\": 3000, \"top_p\": 1, \"frequency_penalty\": 0, \"presence_penalty\": 0, \"n\": 1, \"logit_bias\": {}}' message='Post details'\r\nConverted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)\r\nStarting new HTTPS connection (1): api.openai.com:443\r\nhttps://api.openai.com:443 \"POST /v1/completions HTTP/1.1\" 200 None\r\nmessage='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=332 request_id=f211861aed1265c644856ba2f4426cc1 response_code=200\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Guest1\\Desktop\\swarms\\swarms\\swarms\\groupchat.py\", line 72, in select_speaker\r\n    return self.agent_by_name(name[\"content\"])\r\n  File \"C:\\Users\\Guest1\\Desktop\\swarms\\swarms\\swarms\\groupchat.py\", line 33, in agent_by_name\r\n    raise ValueError(f\"No agent found with a name contained in '{name}'.\")\r\nValueError: No agent found with a name contained in '\r\nRiddler'.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Guest1\\Desktop\\swarms\\groupchat.py\", line 49, in <module>\r\n    chat_history = chat_manager(\"Write me a riddle\")\r\n  File \"C:\\Users\\Guest1\\Desktop\\swarms\\swarms\\swarms\\groupchat.py\", line 97, in __call__\r\n    speaker = self.groupchat.select_speaker(\r\n  File \"C:\\Users\\Guest1\\Desktop\\swarms\\swarms\\swarms\\groupchat.py\", line 74, in select_speaker\r\n    return self.next_agent(last_speaker)\r\n  File \"C:\\Users\\Guest1\\Desktop\\swarms\\swarms\\swarms\\groupchat.py\", line 37, in next_agent\r\n    return self.agents[(self.agent_names.index(agent.name) + 1) % len(self.agents)]\r\nValueError: 'manager' is not in list",
      "state": "closed",
      "author": "elder-plinius",
      "author_type": "User",
      "created_at": "2023-11-06T17:24:00Z",
      "updated_at": "2025-03-20T16:24:15Z",
      "closed_at": "2023-11-08T16:54:30Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/97/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ZackBradshaw",
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/97",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/97",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:51.709744",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@elder-plinius this has been solved",
          "created_at": "2023-11-08T16:54:26Z"
        }
      ]
    },
    {
      "issue_number": 96,
      "title": "[BUG] Location of docs",
      "body": "**Describe the bug**\r\nThe README has the url of the docs as https://swarms.apac.ai/en/latest/\r\nUsage has https://docs.apac.ai \r\n\r\nThe Usage link looks like it should be https://swarms.apac.ai/en/latest/examples/",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2023-11-05T22:01:01Z",
      "updated_at": "2025-03-20T16:24:15Z",
      "closed_at": "2023-11-13T21:47:33Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/96/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/96",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/96",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:51.920469",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@evelynmitchell i don't quite understand can you elaborate ?",
          "created_at": "2023-11-08T16:57:09Z"
        },
        {
          "author": "evelynmitchell",
          "body": "The usage section has the wrong URL. It should be https://swarms.apac.ai/en/latest/examples/",
          "created_at": "2023-11-08T16:58:32Z"
        }
      ]
    },
    {
      "issue_number": 95,
      "title": "[BUG]  Failed to import transformers.models.fuyu.processing_fuyu",
      "body": "Traceback (most recent call last):\r\n  File \"/home/v/swarms/fuyu.py\", line 1, in <module>\r\n    from swarms.models.fuyu import Fuyu\r\n  File \"/home/v/swarms/swarms/models/fuyu.py\", line 2, in <module>\r\n    from transformers import (\r\n  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\r\n  File \"/home/v/.local/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1336, in __getattr__\r\n    value = getattr(module, name)\r\n  File \"/home/v/.local/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1335, in __getattr__\r\n    module = self._get_module(self._class_to_module[name])\r\n  File \"/home/v/.local/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1347, in _get_module\r\n    raise RuntimeError(\r\nRuntimeError: Failed to import transformers.models.fuyu.processing_fuyu because of the following error (look up to see its traceback):\r\ntyping.Optional requires a single type. Got <module 'PIL.Image' from '/usr/lib/python3/dist-packages/PIL/Image.py'>.",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-05T01:17:36Z",
      "updated_at": "2025-03-20T16:24:14Z",
      "closed_at": "2023-11-08T22:04:44Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/95/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/95",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/95",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:52.141407",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "This doesn't appear to be a complete traceback.\r\n\r\nWhen I run \r\n```\r\npip install --update swarms\r\nfrom transformers import (\r\n    FuyuForCausalLM,\r\n    AutoTokenizer,\r\n    FuyuProcessor,\r\n    FuyuImageProcessor,\r\n)\r\n```\r\nI do not get a traceback.",
          "created_at": "2023-11-05T21:21:47Z"
        },
        {
          "author": "kyegomez",
          "body": "@evelynmitchell @vyomakesh09 This issue has been fixed by just specifying from transformers import Fuyu",
          "created_at": "2023-11-08T22:04:44Z"
        },
        {
          "author": "evelynmitchell",
          "body": "Thanks!",
          "created_at": "2023-11-09T00:02:13Z"
        }
      ]
    },
    {
      "issue_number": 94,
      "title": "[BUG] Failed to import transformers.models.fuyu.processing_fuyu",
      "body": "RuntimeError: Failed to import transformers.models.fuyu.processing_fuyu because of the following error (look up to see its traceback):\r\ntyping.Optional requires a single type. Got <module 'PIL.Image' from '/usr/lib/python3/dist-packages/PIL/Image.py'>.",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-05T01:05:18Z",
      "updated_at": "2025-03-20T16:24:14Z",
      "closed_at": "2023-11-08T16:54:58Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/94/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/94",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/94",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:52.315709",
      "comments": [
        {
          "author": "evelynmitchell",
          "body": "This looks to be a duplicate of #95 .\r\nThis can be closed.",
          "created_at": "2023-11-05T21:22:54Z"
        }
      ]
    },
    {
      "issue_number": 90,
      "title": "[BUG] Command 'Dev Containers: Rebuild and Reopen in Container resulted in an error",
      "body": "Command 'Dev Containers: Rebuild and Reopen in Container resulted in an error\r\nCommand failed: /usr/share/code/code -ms-enable-electron-run-as node /home/v/vscode/extensions/ms-vscode remote.remote-containers-0.315.1/dist/spec-node/devContainersSpecCLI.js read-configuration -workspace-folder /home/v/swarms -log-level debug-log-format json -config /home/v/swarms/.devcontainer/ devcontainer json -include merged-configuration -mount-workspace-gitroot",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-03T19:28:43Z",
      "updated_at": "2025-03-20T16:24:14Z",
      "closed_at": "2023-11-10T00:02:17Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/90/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/90",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/90",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:52.499071",
      "comments": [
        {
          "author": "ZackBradshaw",
          "body": "run the second option for now \r\n![Screenshot 2023-11-03 160638](https://github.com/kyegomez/swarms/assets/21285642/3931f4ff-a70a-40d1-aad1-038018c3d764)\r\nBut venv will work too for now if your able to get that working for you \r\n",
          "created_at": "2023-11-03T21:08:31Z"
        }
      ]
    },
    {
      "issue_number": 89,
      "title": "[BUG] ImportError: cannot import name 'RunnableSerializable' from 'langchain.schema.runnable'",
      "body": "Traceback (most recent call last):\r\n  File \"/home/v/swarms/swarms/structs/flow.py\", line 16, in <module>\r\n    from swarms.tools.tool import BaseTool\r\n  File \"/home/v/.local/lib/python3.10/site-packages/swarms/tools/tool.py\", line 30, in <module>\r\n    from langchain.schema.runnable import Runnable, RunnableConfig, RunnableSerializable\r\nImportError: cannot import name 'RunnableSerializable' from 'langchain.schema.runnable' (/home/v/.local/lib/python3.10/site-packages/langchain/schema/runnable/__init__.py)",
      "state": "closed",
      "author": "vyomakesh09",
      "author_type": "User",
      "created_at": "2023-11-03T14:50:54Z",
      "updated_at": "2025-03-20T16:24:14Z",
      "closed_at": "2023-11-03T19:28:53Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/89/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/89",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/89",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:52.672968",
      "comments": []
    },
    {
      "issue_number": 80,
      "title": "[FEATURE] Add Benchmarks",
      "body": "Need standardized benchmarks that can be run by any agent class",
      "state": "closed",
      "author": "elder-plinius",
      "author_type": "User",
      "created_at": "2023-11-02T18:28:45Z",
      "updated_at": "2025-03-20T16:24:13Z",
      "closed_at": "2024-01-09T12:47:53Z",
      "labels": [
        "no-issue-activity"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/80/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/80",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/80",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:52.672988",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Stale issue message",
          "created_at": "2024-01-02T12:45:03Z"
        }
      ]
    },
    {
      "issue_number": 79,
      "title": "[FEAT][Add Tool logic to `Agent` class",
      "body": "# Integrating tools with Flow\n- Parse the wrapped tool function for the docstrings\n - Inject the tool usage prompt with the function into the llm's prompt\n- We need to parse the llm output to use the tool\n\n```\n            @tool(\"search\", return_direct=True)\n            def search_api(query: str) -> str:\n                # Searches the API for the query.\n                return\n\n```\n\n\n\n\n# Example \n```\nfrom swarms.models import OpenAIChat\nfrom swarms.structs import Flow\nfrom swarms.tools import tool\n\n\napi_key = \"\"\n\n# Initialize the language model, this model can be swapped out with Anthropic, ETC, Huggingface Models like Mistral, ETC\nllm = OpenAIChat(\n    openai_api_key=api_key,\n    temperature=0.5,\n    max_tokens=3000,\n)\n\n\n\n# Tool usage example\n@tool\ndef search_api(query: str):\n   \"\"\"Search the web with this tool\"\"\"\n     pass\n\n\n\n# Initialize the flow\nflow = Flow(llm=llm, max_loops=5, dashboard=True, tools=[search_api])\n\nout = flow.run(\"Generate a 10,000 word blog on health and wellness.\")\n\nprint(out)\n```\n\n# Reference\nLearn how the worker uses tool: https://github.com/kyegomez/swarms/blob/master/swarms/agents/agent.py\n\n\n\n# `tool` Documentation\n### How It Works\n\n1. **Decorator Functionality:**\n   The `tool` decorator can be used in several ways, based on the arguments passed to it. It supports transforming simple functions, asynchronous functions, or objects implementing a `Runnable` interface into a tool.\n\n2. **Arguments Handling:**\n   - `*args`: This is a variable argument list allowing different types of inputs (string, `Callable`, or `Runnable`).\n   - `return_direct`: If set to `True`, the tool returns directly without continuing the loop in which it's running.\n   - `args_schema`: An optional Pydantic model (`BaseModel`) for validating input arguments to the tool.\n   - `infer_schema`: If `True`, the tool attempts to infer the argument schema from the function signature.\n\n3. **Tool Creation:**\n   - The decorator checks the type of arguments it receives and accordingly creates a tool.\n   - For a `Runnable` object, it wraps its invocation methods (`ainvoke` for async, `invoke` for sync) into a tool.\n   - For a function, it either uses `StructuredTool.from_function` if `infer_schema` is `True` or creates a basic `Tool` otherwise.\n\n4. **Schema Inference:**\n   - If `infer_schema` is `True`, the decorator infers the input schema for the tool based on the function's signature.\n   - This allows the resultant tool to accept a dictionary as input to its `run()` method.\n\n5. **Error Handling:**\n   - The decorator ensures that if `infer_schema` is `False`, the function must have a docstring to provide a description.\n\n### Example Usages\n\n1. **Simple Function as a Tool:**\n   ```python\n   @tool\n   def search_api(query: str) -> str:\n       # Function body\n   ```\n\n2. **Named Tool with Direct Return:**\n   ```python\n   @tool(\"search\", return_direct=True)\n   def search_api(query: str) -> str:\n       # Function body\n   ```\n\n3. **Using Runnable:**\n   ```python\n   @tool(\"runnable_tool\")\n   class MyRunnable(Runnable):\n       # Implementation of Runnable\n   ```\n\n### Expected Outputs\n\n- The decorator converts functions or runnables into tools that can be utilized within a larger framework, possibly an agent-based system.\n- These tools can be executed either synchronously or asynchronously, depending on their nature.\n- They may accept structured inputs (if schema inference is enabled) and can be designed to either return their output directly or continue in a loop.\n\n### Use Cases\n\nThis kind of tool creation is particularly useful in systems where you need modular, reusable components that can be plugged into different parts of an application, especially in scenarios involving asynchronous operations, agent-based simulations, or complex workflows requiring structured input/output handling.",
      "state": "closed",
      "author": "ZackBradshaw",
      "author_type": "User",
      "created_at": "2023-11-02T16:19:11Z",
      "updated_at": "2025-03-20T16:24:13Z",
      "closed_at": "2024-03-26T12:44:41Z",
      "labels": [
        "help wanted",
        "good first issue",
        "no-issue-activity"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/79/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ZackBradshaw",
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/79",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/79",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:52.858415",
      "comments": [
        {
          "author": "kyegomez",
          "body": "# `tool`\n\nIntegrating the `tool` function with basic Language Learning Models (LLMs) like OpenAI's GPT models can be a creative and powerful way to combine structured programming with generative AI capabilities. The integration would depend on how the LLM is being used and the nature of the tool cre",
          "created_at": "2023-11-10T18:38:48Z"
        },
        {
          "author": "kyegomez",
          "body": "# Tools\n\nTo pass the outputs of tools as input to a Language Model (LM), you need to structure your workflow in a way that allows the tools to process data or perform specific operations, and then feed their outputs into the LM. Here's a conceptual walkthrough and an example in Python code to illust",
          "created_at": "2023-11-10T18:43:01Z"
        },
        {
          "author": "ZackBradshaw",
          "body": "![image](https://github.com/kyegomez/swarms/assets/21285642/c62fae29-bab8-492a-8c2e-bcc26b06fac3)\r\n",
          "created_at": "2023-11-16T17:43:05Z"
        },
        {
          "author": "kyegomez",
          "body": "# Tool usage script\n\n```\n\"\"\"\n    \n    \ntool decorated func [search_api] -> agent which parses the docs of the tool func \n-> injected into prompt -> agent will output json containing tool usage -> agent output will be parsed -> tool executed\n-> terminal response can be returned to agent for self-heal",
          "created_at": "2023-11-30T20:31:24Z"
        },
        {
          "author": "evelynmitchell",
          "body": "Is this implemented? Can it be closed?",
          "created_at": "2024-01-18T03:53:28Z"
        }
      ]
    },
    {
      "issue_number": 63,
      "title": "Confirm you do not plan to stop spamming people.",
      "body": "Hi @kyegomez, you closed https://github.com/kyegomez/swarms/issues/62 about you spamming people as **\"not planned\"**. Can you confirm that you do not intent to take any action?\r\n\r\nPlease take a look at:\r\n- https://www.fcc.gov/general/can-spam\r\n- https://ico.org.uk/for-the-public/online/spam-emails/\r\n\r\n\r\n## It would be great if you stopped.\r\n![spammer](https://github.com/kyegomez/swarms/assets/24711048/09d989ae-4438-491e-adb2-95f570a1ad96)\r\n\r\nPlease stop spamming me, and others. Also see https://github.com/kyegomez/swarms/issues/40",
      "state": "closed",
      "author": "ben-xD",
      "author_type": "User",
      "created_at": "2023-10-13T07:56:49Z",
      "updated_at": "2025-03-20T16:24:13Z",
      "closed_at": "2023-10-14T18:09:48Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/63/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/63",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/63",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:53.046366",
      "comments": [
        {
          "author": "ben-xD",
          "body": "Let's discuss here as to why you have not added an unsubscribe button @kyegomez.\r\n\r\nPlease take a look at the list of enforcement action taken by the ICO in the past related to spam: https://ico.org.uk/action-weve-taken/enforcement/\r\n\r\n Thanks!",
          "created_at": "2023-10-13T08:13:51Z"
        }
      ]
    },
    {
      "issue_number": 62,
      "title": "Stop spamming people with email",
      "body": "![spammer](https://github.com/kyegomez/swarms/assets/24711048/09d989ae-4438-491e-adb2-95f570a1ad96)\r\n\r\nIt would be great if you could stop spamming me, and others. See https://github.com/kyegomez/swarms/issues/40\r\n\r\nThere are so many closed issues from this. You are unethical @kyegomez.",
      "state": "closed",
      "author": "ben-xD",
      "author_type": "User",
      "created_at": "2023-10-12T19:10:27Z",
      "updated_at": "2025-03-20T16:24:13Z",
      "closed_at": "2023-10-13T03:03:41Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/62/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/62",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/62",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:53.220835",
      "comments": []
    },
    {
      "issue_number": 71,
      "title": "[BUG] ",
      "body": "load_ssl_context verify=True cert=None trust_env=True http2=False\r\nload_verify_locations cafile='/usr/local/lib/python3.10/dist-packages/certifi/cacert.pem'\r\nTraceback (most recent call last):\r\n  File \"/home/zack/code/swarms/example.py\", line 19, in <module>\r\n    node = Worker(\r\n  File \"/home/zack/code/swarms/swarms/workers/worker.py\", line 85, in __init__\r\n    self.setup_tools(external_tools)\r\n  File \"/home/zack/code/swarms/swarms/workers/worker.py\", line 138, in setup_tools\r\n    qa_chain=load_qa_with_sources_chain(self.llm)\r\n  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/qa_with_sources/loading.py\", line 182, in load_qa_with_sources_chain\r\n    return _func(llm, verbose=verbose, **kwargs)\r\n  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/qa_with_sources/loading.py\", line 61, in _load_stuff_chain\r\n    llm_chain = LLMChain(llm=llm, prompt=prompt, verbose=verbose)\r\n  File \"/usr/local/lib/python3.10/dist-packages/langchain/load/serializable.py\", line 75, in __init__\r\n    super().__init__(**kwargs)\r\n  File \"/usr/local/lib/python3.10/dist-packages/pydantic/v1/main.py\", line 341, in __init__\r\n    raise validation_error\r\npydantic.v1.error_wrappers.ValidationError: 1 validation error for LLMChain\r\nllm\r\n  value is not a valid dict (type=type_error.dict)",
      "state": "closed",
      "author": "ZackBradshaw",
      "author_type": "User",
      "created_at": "2023-10-27T02:00:11Z",
      "updated_at": "2025-03-20T16:24:12Z",
      "closed_at": "2023-11-08T16:56:07Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/71/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/71",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/71",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:53.220860",
      "comments": [
        {
          "author": "kyegomez",
          "body": "@ZackBradshaw worker has been removed ",
          "created_at": "2023-11-08T16:56:04Z"
        }
      ]
    },
    {
      "issue_number": 752,
      "title": "[BUG][FEATURE] Onboarding",
      "body": "The onboarding cli asks for:\r\nEnter your first name (or type 'quit' to exit): \",\r\nEnter your Last Name (or type 'quit' to exit): \",\r\nEnter your email (or type 'quit' to exit): \", \"email\"\r\nEnter your WORKSPACE_DIR: This is where logs, errors, and agent configurations will be stored (or type 'quit' to exit). Remember to set this as an environment variable: https://docs.swarms.world/en/latest/swarms/install/quickstart/ || Important: Please ensure you have set your WORKSPACE_DIR environment variable as per the instructions provided.\"\r\nAdditionally, remember to add your API keys for your respective models in your .env file.\"\r\n\r\nI don't like entering this sort of information without knowing why, and where it will be stored, and how it will be used.\r\n\r\nThere's a typo in the 'Remember to set this as an evironment variable line\" -> ||\r\n\r\nI didn't know how Swarms.World and the onboarding are connected.\r\n\r\nI didn't know if you could change the data later.\r\n\r\n## Possible fix \r\nI think a possible re-wording could be:\r\nWe need to gather some personal information to make your Swarms experience more pleasant.  This will be stored in a plain text file on your system.\r\n\r\n*We will use this to set up your Swarms.World account. ???*\r\n\r\nYou *[can? cannot?]* change this information later. \r\n\r\nWe will ask for your First Name, Last Name, email address and workspace directory location.\r\n\r\nWe will save this information in a file on your system. \r\n\r\nYou *can?* still use Swarms if you choose not to share this information. \r\n\r\nEnter your first name (or type 'quit' to exit): \r\n\r\nEnter your Last Name (or type 'quit' to exit): \r\n\r\nEnter your email (or type 'quit' to exit): \r\n\r\nEnter your WORKSPACE_DIR: This is where logs, errors, and agent configurations will be stored (or type 'quit' to exit). Remember to set this as an environment variable: https://docs.swarms.world/en/latest/swarms/install/quickstart/ || \r\n\r\nImportant: Please ensure you have set your WORKSPACE_DIR environment variable as per the instructions provided.\r\n\r\nAdditionally, remember to add your API keys for your respective models in your .env file.\r\n\r\n\r\n\r\n\r\n",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2025-01-14T22:36:57Z",
      "updated_at": "2025-02-19T00:14:31Z",
      "closed_at": "2025-02-19T00:14:31Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/752/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/752",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/752",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:55.274354",
      "comments": []
    },
    {
      "issue_number": 746,
      "title": "[BUG] Context Length Exceeded Error in Swarms CLI with Agent Creation",
      "body": "When running the `swarms run-agents` command, users are encountering a context length exceeded error with GPT-4. The error occurs during agent creation and execution, specifically when trying to process system prompts and tasks.\r\n\r\n**Error Message**\r\n```\r\nlitellm.ContextWindowExceededError: litellm.BadRequestError: ContextWindowExceededError: \r\nOpenAIException - Error code: 400 - {\"error\": {\"message\": \"This model's maximum context length is 8192 tokens. However, you requested 8492 tokens (4492 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.\", \"type\": \"invalid_request_error\", \"param\": \"messages\", \"code\": \"context_length_exceeded\"}}\r\n```\r\n\r\n**Reproduction Steps**\r\n1. Create an `agents.yaml` with multiple agents\r\n2. Configure agents with system prompts and tasks\r\n3. Run `swarms run-agents --yaml-file agents.yaml`\r\n\r\n**Current Configuration**\r\n```yaml\r\nagents:\r\n  - agent_name: \"Financial-Analysis-Agent\"\r\n    model:\r\n      model_name: \"gpt-4\"\r\n      temperature: 0.1\r\n      max_tokens: 2000\r\n    system_prompt: \"financial_agent_sys_prompt\"\r\n    max_loops: 1\r\n    context_length: 4000\r\n    # ... other settings\r\n\r\n  - agent_name: \"Stock-Analysis-Agent\"\r\n    model:\r\n      model_name: \"gpt-4\"\r\n      temperature: 0.2\r\n      max_tokens: 1500\r\n    system_prompt: \"stock_agent_sys_prompt\"\r\n    max_loops: 2\r\n    context_length: 4000\r\n    # ... other settings\r\n```\r\n\r\n\r\nAction Items:\r\n- Add guidelines for token limits\r\n- Calculate actual token count before sending to API [If we use Model Router change model accordingly in retry]",
      "state": "closed",
      "author": "chethanuk",
      "author_type": "User",
      "created_at": "2025-01-11T20:18:48Z",
      "updated_at": "2025-02-19T00:12:23Z",
      "closed_at": "2025-02-19T00:12:23Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/746/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/746",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/746",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:55.274376",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2025-01-11T20:19:12Z"
        },
        {
          "author": "Occupying-Mars",
          "body": "you are using the model gpt4 it only has a context length of 8k you have to use some other model with bigger context length for your usecase if you want to use more tokens",
          "created_at": "2025-01-12T17:02:34Z"
        },
        {
          "author": "kyegomez",
          "body": "@chethanuk you might also have to delete the context window parameter",
          "created_at": "2025-01-12T22:40:39Z"
        },
        {
          "author": "kyegomez",
          "body": "@chethanuk did it work ? let me know so i can close the issue",
          "created_at": "2025-01-17T18:04:11Z"
        }
      ]
    },
    {
      "issue_number": 731,
      "title": "[BUG] Pysa action failing",
      "body": "**Describe the bug**\r\n\r\nThe pysa github action is failing: https://github.com/kyegomez/swarms/actions/runs/12679525342\r\ndue to an outdated dependency: \r\nhttps://github.com/facebook/pysa-action/pull/8\r\nThat upstream PR got pushed back to me, because there are errors from an upstream dependency which is now an archived project:\r\nhttps://github.com/facebookarchive/sapp-action\r\n\r\nI recommend removing the pysa github action:\r\n.github/workflows/pysa.yml\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\nOpen a PR\r\npysa github action runs\r\npysa github action fails\r\n\r\n**Expected behavior**\r\nOpen a PR\r\ncorrect tests succeed\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2025-01-08T23:26:47Z",
      "updated_at": "2025-02-13T20:50:06Z",
      "closed_at": "2025-02-13T20:50:06Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/731/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/731",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/731",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:55.537086",
      "comments": []
    },
    {
      "issue_number": 697,
      "title": "[BUG] Python version (3.13.1) is not supported by scipy==1.9.3, which only supports Python 3.8 to 3.11. Since swarms depends on scipy, this causes the pip install swarms command to fail.",
      "body": "\r\n# Bug Report: `pip install swarms` Fails Due to `scipy` Compatibility Issue\r\n\r\n## Description\r\n\r\nWhen attempting to install the `swarms` package via `pip`, the installation fails during the preparation of `scipy` metadata. The error occurs because `scipy==1.9.3` only supports Python versions 3.8 to 3.11, while the system uses Python 3.13.1.\r\n\r\n---\r\n\r\n## Error Logs\r\n\r\n```plaintext\r\nPreparing metadata (pyproject.toml) ... error\r\nerror: subprocess-exited-with-error\r\n\r\n× Preparing metadata (pyproject.toml) did not run successfully.\r\n│ exit code: 1\r\n╰─> [32 lines of output]\r\n+ meson setup ...\r\n../meson.build:85:2: ERROR: Problem encountered: Your Python version is too new. SciPy 1.9 supports Python 3.8-3.11; if you are trying to build from source for the most recent SciPy version you may hit this error as well. Please build from the `main` branch on GitHub instead.\r\n```\r\n\r\n---\r\n\r\n## Steps to Reproduce\r\n\r\n1. Use Python 3.13.1 (or any unsupported version above 3.11).\r\n2. Run the command:\r\n   ```bash\r\n   pip install swarms\r\n   ```\r\n\r\n3. Observe the failure during the installation of `scipy`.\r\n\r\n---\r\n\r\n## Suggested Solution\r\n\r\nTo resolve this issue, follow the steps below:\r\n\r\n### Solution 1: Use a Compatible Python Version\r\n\r\n1. **Install a Supported Python Version (3.8 to 3.11):**\r\n   If using `pyenv`:\r\n   ```bash\r\n   pyenv install 3.11.6\r\n   ```\r\n\r\n2. **Set the Python Version for the Project:**\r\n   ```bash\r\n   pyenv local 3.11.6\r\n   ```\r\n\r\n3. **Verify the Active Python Version:**\r\n   ```bash\r\n   python --version\r\n   ```\r\n\r\n4. **Upgrade `pip` and Related Tools:**\r\n   ```bash\r\n   pip install --upgrade pip setuptools wheel\r\n   ```\r\n\r\n5. **Retry Installing `swarms`:**\r\n   ```bash\r\n   pip install swarms\r\n   ```\r\n\r\n---\r\n\r\n### Solution 2: Use Precompiled Wheels for `scipy`\r\n\r\n1. **Upgrade `pip`:**\r\n   ```bash\r\n   pip install --upgrade pip setuptools wheel\r\n   ```\r\n\r\n2. **Install the Latest Version of `scipy`:**\r\n   ```bash\r\n   pip install scipy\r\n   ```\r\n\r\n3. **Install `swarms`:**\r\n   ```bash\r\n   pip install swarms\r\n   ```\r\n\r\n---\r\n\r\n### Solution 3: Build `scipy` Manually\r\n\r\nIf necessary, build `scipy` manually with the required build tools:\r\n\r\n1. **Install GCC and gfortran:**\r\n   ```bash\r\n   brew install gcc\r\n   ```\r\n\r\n2. **Verify gfortran Installation:**\r\n   ```bash\r\n   gfortran --version\r\n   ```\r\n\r\n3. **Retry Installing `swarms`:**\r\n   ```bash\r\n   pip install swarms\r\n   ```\r\n\r\n---\r\n\r\n## Notes\r\n\r\n- The issue is caused by `scipy` being incompatible with Python 3.13.1. A temporary workaround is to use a compatible Python version.\r\n- If `swarms` or its dependencies can be updated to support Python 3.13, this issue may be resolved in future releases.\r\n\r\n---\r\n\r\n## Environment Details\r\n\r\n- **OS:** macOS\r\n- **Python Version:** 3.13.1\r\n- **Package:** swarms\r\n- **Dependency Causing Issue:** scipy==1.9.3\r\n",
      "state": "closed",
      "author": "MeltedMindz",
      "author_type": "User",
      "created_at": "2024-12-21T16:59:00Z",
      "updated_at": "2025-02-13T20:23:52Z",
      "closed_at": "2025-02-13T20:23:50Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/697/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/697",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/697",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:55.537107",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-12-21T16:59:24Z"
        },
        {
          "author": "kyegomez",
          "body": "@MeltedMindz can you please provide the full error stack trace, so i can locate the root cause of the error pls",
          "created_at": "2024-12-22T01:18:36Z"
        },
        {
          "author": "kyegomez",
          "body": "@MeltedMindz scipy is not in the main swarms repo",
          "created_at": "2024-12-22T01:19:12Z"
        },
        {
          "author": "patrickbdevaney",
          "body": "> # Bug Report: `pip install swarms` Fails Due to `scipy` Compatibility Issue\r\n> ## Description\r\n> When attempting to install the `swarms` package via `pip`, the installation fails during the preparation of `scipy` metadata. The error occurs because `scipy==1.9.3` only supports Python versions 3.8 t",
          "created_at": "2024-12-25T02:58:37Z"
        },
        {
          "author": "InfinityStoned0",
          "body": "Hi, I'm new to swarms dev community. I have tried this recently on my rpi 4B and it works fine. Thanks!",
          "created_at": "2025-01-05T22:55:31Z"
        }
      ]
    },
    {
      "issue_number": 514,
      "title": "[BUG] Majority Voting",
      "body": "```\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n[<ipython-input-15-8a50099c58fe>](https://localhost:8080/#) in <cell line: 1>()\r\n----> 1 from swarms import Agent, MajorityVoting, ChromaDB, Anthropic\r\n      2 \r\n      3 # Initialize the llm\r\n      4 llm = Anthropic()\r\n      5 \r\n\r\nImportError: cannot import name 'ChromaDB' from 'swarms' (/usr/local/lib/python3.10/dist-packages/swarms/__init__.py)\r\n\r\n---------------------------------------------------------------------------\r\nNOTE: If your import is failing due to a missing package, you can\r\nmanually install dependencies using either !pip or !apt.\r\n\r\nTo view examples of installing some common dependencies, click the\r\n\"Open Examples\" button below.\r\n---------------------------------------------------------------------------```\r\n",
      "state": "closed",
      "author": "evelynmitchell",
      "author_type": "User",
      "created_at": "2024-06-25T01:09:15Z",
      "updated_at": "2025-02-04T19:18:15Z",
      "closed_at": "2025-02-04T19:18:14Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/514/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/514",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/514",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:55.785319",
      "comments": [
        {
          "author": "sambhavnoobcoder",
          "body": "To solve this issue, we need to update the import statement. The ChromaDB class is not directly importable from the swarms package. Instead, it should be imported from `swarms_memory` . Here's how to fix the import:\r\n\r\n```\r\nfrom swarms import Agent, MajorityVoting\r\nfrom swarms_memory import ChromaDB",
          "created_at": "2024-10-22T12:37:37Z"
        },
        {
          "author": "evelynmitchell",
          "body": "This issues has been fixed. Thanks  @sambhavnoobcoder !",
          "created_at": "2025-02-04T19:18:14Z"
        }
      ]
    },
    {
      "issue_number": 755,
      "title": "[BUG] Why demo code request swarms api will be 403 ?",
      "body": "**Describe the bug**\nI am using the Usage Example:  `Single Agent` demo on my local machine. While running the project, it throws an exception. I found that this is due to Cloudflare intercepting the request. How do I resolve it?\n\n\n\n**To Reproduce**\nSteps to reproduce the behavior:\n```python\nimport os\nfrom swarms import Agent\nfrom swarm_models import OpenAIChat\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n# Initialize OpenAI model\nmodel = OpenAIChat(\n    openai_api_key=os.getenv(\"OPENAI_API_KEY\"), model_name=\"gpt-4o-mini\", temperature=0.1\n)\n\n# Initialize the agent\nagent = Agent(\n    agent_name=\"Financial-Analysis-Agent\",\n    system_prompt=\"Analyze financial situations and provide advice...\",\n    llm=model,\n    max_loops=1,\n    autosave=True,\n    dashboard=False,\n    verbose=True,\n    saved_state_path=\"finance_agent.json\"\n)\n\n# Run the agent on a financial query\nout = agent.run(\"How can I establish a ROTH IRA to buy stocks and get a tax break? What are the criteria?\")\nprint(out)\n```\n\n**Expected behavior**\nA clear and concise description of what you expected to happen.\n\n**Screenshots**\n\n<img width=\"1111\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/4ecf44bc-d385-43eb-9566-6385cd265c3a\" />\n",
      "state": "closed",
      "author": "vaptu",
      "author_type": "User",
      "created_at": "2025-01-17T09:51:05Z",
      "updated_at": "2025-01-18T03:47:00Z",
      "closed_at": "2025-01-17T18:03:49Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/755/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/755",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/755",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:56.035080",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2025-01-17T09:51:30Z"
        },
        {
          "author": "kyegomez",
          "body": "@vaptu hey sorry the error should be fixed now ;) Let me know if it works well ;) ",
          "created_at": "2025-01-17T18:01:29Z"
        },
        {
          "author": "vaptu",
          "body": "I resolved the 403 problem, but the code I am running will exit.\n\n<img width=\"638\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/fc08a8c1-6c4c-49f7-a4c8-8bd02a9fd9a2\" />\n\nI cannot find any errors in the output.\n\nThe error.txt file is empty.\n\nThis is my state JSON file.\n```\n{\n    \"logs_",
          "created_at": "2025-01-18T03:46:59Z"
        }
      ]
    },
    {
      "issue_number": 716,
      "title": "[BUG] ",
      "body": "**Describe the bug**\r\n\r\nD:\\project\\swarms> git.exe checkout master\r\n**invalid path** 'new_features_examples/new_spreadsheet_swarm_examples/workspace/Spreedsheet-Swarm-Crypto-Tax-Optimization-Swarm/Crypto-Tax-Optimization-Swarm/spreedsheet-swarm-spreadsheet_swarm_run_2024-12-26T15:43:05.658653_metadata.json'\r\n\r\n**invalid path** 'new_features_examples/new_spreadsheet_swarm_examples/workspace/Spreedsheet-Swarm-Financial-Analysis-Swarm/Financial-Analysis-Swarm/spreedsheet-swarm-spreadsheet_swarm_run_2024-12-25T14:28:32.568788_metadata.json'\r\n\r\n**invalid path** 'new_features_examples/new_spreadsheet_swarm_examples/workspace/Spreedsheet-Swarm-Financial-Analysis-Swarm/Financial-Analysis-Swarm/spreedsheet-swarm-spreadsheet_swarm_run_2024-12-25T15:00:31.933250_metadata.json'\r\n\r\n**invalid path** 'new_features_examples/new_spreadsheet_swarm_examples/workspace/Spreedsheet-Swarm-Financial-Analysis-Swarm/Financial-Analysis-Swarm/spreedsheet-swarm-spreadsheet_swarm_run_2024-12-26T15:39:44.890581_metadata.json'\r\n\r\n\r\nThe reason for the issue:\r\nThe path is too long, exceeding the default limit of 260 characters in the Windows operating system. The file names mentioned above should be shortened.\r\n\r\n",
      "state": "closed",
      "author": "zrqgood",
      "author_type": "User",
      "created_at": "2025-01-05T09:58:54Z",
      "updated_at": "2025-01-13T18:37:57Z",
      "closed_at": "2025-01-13T18:37:57Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/716/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/716",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/716",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:56.304882",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2025-01-05T09:59:16Z"
        },
        {
          "author": "RedQueenAgent",
          "body": "![image](https://github.com/user-attachments/assets/193727b6-a031-4eaa-beda-0255725aca86)\r\nIt seems that there are some problems with the threading module, but it does not affect normal use",
          "created_at": "2025-01-06T06:19:14Z"
        },
        {
          "author": "kyegomez",
          "body": "@RedQueenAgent did you update your swarms?",
          "created_at": "2025-01-06T17:42:26Z"
        },
        {
          "author": "kyegomez",
          "body": "@zrqgood try updating your swarms repository as well",
          "created_at": "2025-01-06T17:43:20Z"
        },
        {
          "author": "evelynmitchell",
          "body": "You can also modify your Windows environment to support longer paths:\r\n```To resolve this issue, you can enable long path support in Windows. Here are the steps:\r\n\r\n1. Open the Group Policy Editor by typing `gpedit.msc` in the Run dialog (Win + R).\r\n2. Navigate to `Local Computer Policy > Computer C",
          "created_at": "2025-01-06T20:06:20Z"
        }
      ]
    },
    {
      "issue_number": 722,
      "title": "[BUG] Can't log in with Github",
      "body": "![image](https://github.com/user-attachments/assets/32a8af37-77a8-4050-9413-c1df89a3dc21)\r\n![image](https://github.com/user-attachments/assets/cafbd015-3a3c-4c17-b9e3-a5b42d8b024b)\r\n",
      "state": "closed",
      "author": "sigeshuo",
      "author_type": "User",
      "created_at": "2025-01-06T23:52:23Z",
      "updated_at": "2025-01-09T20:30:24Z",
      "closed_at": "2025-01-09T20:30:24Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/722/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/722",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/722",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:56.532206",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2025-01-06T23:52:47Z"
        },
        {
          "author": "kyegomez",
          "body": "@sigeshuo yes we're fixing the issue now as we speak",
          "created_at": "2025-01-07T00:31:23Z"
        },
        {
          "author": "aihes",
          "body": "> @sigeshuo yes we're fixing the issue now as we speak\r\n\r\nLooking at this project, it's mainly an open-source framework-level codebase, but the frontend pages of SWARMS are not included in the code repository. Is there a plan to open-source this as well, to facilitate modifications for everyone? It ",
          "created_at": "2025-01-07T04:08:15Z"
        },
        {
          "author": "kyegomez",
          "body": "@aihes it's already open source in the swarms github ;)",
          "created_at": "2025-01-09T20:30:24Z"
        }
      ]
    },
    {
      "issue_number": 694,
      "title": "OSError: [Errno 22] Invalid argument when saving CSV due to invalid filename characters",
      "body": "**Issue**\r\nAn `OSError: [Errno 22] Invalid argument` is raised when attempting to save the metadata of a `SpreadsheetSwarm` to a CSV file. This occurs because the generated filename contains characters that are not allowed in filenames on Windows, specifically the colon \":\" in the timestamp.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Run any task using `SpreadsheetSwarm` that generates metadata.\r\n2. The `_save_metadata` function is called automatically at the end of the run which will call `_save_to_csv` to save the metadata to a CSV file.\r\n3. The program will throw `OSError: [Errno 22] Invalid argument` during the file creation in `aiofiles.open`.\r\n\r\n**Expected behavior**\r\nThe metadata should be saved to a CSV file without errors. The filename should be compatible with all operating systems.\r\n\r\nError :\r\n```log\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\harsh\\AppData\\Roaming\\Python\\Python312\\site-packages\\tenacity\\__init__.py\", line 478, in __call__\r\n    result = fn(*args, **kwargs)\r\n             ^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\harsh\\AppData\\Roaming\\Python\\Python312\\site-packages\\swarms\\structs\\swarm_router.py\", line 409, in _run\r\n    result = self.swarm.run(task, *args, **kwargs)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\harsh\\AppData\\Roaming\\Python\\Python312\\site-packages\\swarms\\structs\\spreadsheet_swarm.py\", line 153, in run\r\n    asyncio.run(self._save_metadata())\r\n  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\runners.py\", line 194, in run\r\n    return runner.run(main)\r\n           ^^^^^^^^^^^^^^^^\r\n  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\runners.py\", line 118, in run\r\n    return self._loop.run_until_complete(task)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\base_events.py\", line 687, in run_until_complete\r\n    return future.result()\r\n           ^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\harsh\\AppData\\Roaming\\Python\\Python312\\site-packages\\swarms\\structs\\spreadsheet_swarm.py\", line 254, in _save_metadata\r\n    await self._save_to_csv()\r\n  File \"C:\\Users\\harsh\\AppData\\Roaming\\Python\\Python312\\site-packages\\swarms\\structs\\spreadsheet_swarm.py\", line 268, in _save_to_csv\r\n    async with aiofiles.open(\r\n               ^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\harsh\\AppData\\Roaming\\Python\\Python312\\site-packages\\aiofiles\\base.py\", line 98, in __aenter__\r\n    self._obj = await self._coro\r\n                ^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\harsh\\AppData\\Roaming\\Python\\Python312\\site-packages\\aiofiles\\threadpool\\__init__.py\", line 94, in _open\r\n    f = yield from loop.run_in_executor(executor, cb)\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\ProgramData\\anaconda3\\Lib\\concurrent\\futures\\thread.py\", line 58, in run\r\n    result = self.fn(*self.args, **self.kwargs)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nOSError: [Errno 22] Invalid argument: 'spreadsheet_swarm_2024-12-19T23:48:30.649035_run_id_178a7492ef79440a96ed77f71cf9ca3a.csv' \r\n```",
      "state": "closed",
      "author": "harshalmore31",
      "author_type": "User",
      "created_at": "2024-12-19T18:27:04Z",
      "updated_at": "2024-12-31T17:39:46Z",
      "closed_at": "2024-12-31T17:39:46Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/694/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/694",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/694",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:58.684462",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-12-19T18:27:34Z"
        },
        {
          "author": "patrickbdevaney",
          "body": "I changed the file naming scheme in /swarms/swarms/structs/spreadsheet_swarm.py to not use colons and will include it in a forthcoming PR.",
          "created_at": "2024-12-20T21:52:39Z"
        },
        {
          "author": "kyegomez",
          "body": "> I changed the file naming scheme in /swarms/swarms/structs/spreadsheet_swarm.py to not use colons and will include it in a forthcoming PR.\r\n\r\nthank you so much lmk when it's here!",
          "created_at": "2024-12-20T23:42:50Z"
        },
        {
          "author": "patrickbdevaney",
          "body": "> > I changed the file naming scheme in /swarms/swarms/structs/spreadsheet_swarm.py to not use colons and will include it in a forthcoming PR.\r\n> \r\n> thank you so much lmk when it's here!\r\n\r\nGreat, I uploaded the PR. \r\n\r\nThe change simply modifies the timestamp based naming format for files and shou",
          "created_at": "2024-12-21T01:02:41Z"
        }
      ]
    },
    {
      "issue_number": 641,
      "title": "[BUG] Facing error while trying to run MixtureOfAgents and GroupChat workflows ",
      "body": "\r\n[collegeListRoute.txt](https://github.com/user-attachments/files/17877332/collegeListRoute.txt)\r\n[collegeListController.txt](https://github.com/user-attachments/files/17877333/collegeListController.txt)\r\n[collegeListSwarm.txt](https://github.com/user-attachments/files/17877334/collegeListSwarm.txt)\r\n\r\n**The error log is here:** \r\nContext: I am running it through an API call to an endpoint in my flask server.\r\n\r\nHTTP/1.1 500 INTERNAL SERVER ERROR\r\nServer: Werkzeug/3.1.3 Python/3.12.5\r\nDate: Fri, 22 Nov 2024 22:36:40 GMT\r\nContent-Type: application/json\r\nContent-Length: 127\r\nAccess-Control-Allow-Origin: *\r\nConnection: close\r\n\r\n{\r\n  \"error\": \"Internal Server Error\",\r\n  \"message\": \"MixtureOfAgents.__init__() got an unexpected keyword argument 'agent_list'\"\r\n}\r\n\r\nif i try to change the agent_list keyword to agents then too I am getting an error.\n\n<!-- POLAR PLEDGE BADGE START -->\n## Upvote & Fund\n\n- We're using [Polar.sh](https://polar.sh/kyegomez) so you can upvote and help fund this issue.\n- We receive the funding once the issue is completed & confirmed by you.\n- Thank you in advance for helping prioritize & fund our backlog.\n\n<a href=\"https://polar.sh/kyegomez/swarms/issues/641\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/kyegomez/swarms/issues/641/pledge.svg?darkmode=1\">\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/kyegomez/swarms/issues/641/pledge.svg\">\n</picture>\n</a>\n<!-- POLAR PLEDGE BADGE END -->\n",
      "state": "closed",
      "author": "Arshroop-Saini",
      "author_type": "User",
      "created_at": "2024-11-22T23:05:18Z",
      "updated_at": "2024-11-23T01:55:32Z",
      "closed_at": "2024-11-23T01:55:21Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/kyegomez/swarms/issues/641/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kyegomez"
      ],
      "milestone": null,
      "html_url": "https://github.com/kyegomez/swarms/issues/641",
      "api_url": "https://api.github.com/repos/kyegomez/swarms/issues/641",
      "repository": "kyegomez/swarms",
      "extraction_date": "2025-06-22T00:39:58.906860",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "Hello there, thank you for opening an Issue ! 🙏🏻 The team was notified and they will get back to you asap.",
          "created_at": "2024-11-22T23:06:31Z"
        },
        {
          "author": "Arshroop-Saini",
          "body": "Resolved.",
          "created_at": "2024-11-23T01:55:31Z"
        }
      ]
    }
  ]
}