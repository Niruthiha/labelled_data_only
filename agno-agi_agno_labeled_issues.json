{
  "repository": "agno-agi/agno",
  "repository_info": {
    "repo": "agno-agi/agno",
    "stars": 28603,
    "language": "Python",
    "description": "Full-stack framework for building Multi-Agent Systems with memory, knowledge and reasoning.",
    "url": "https://github.com/agno-agi/agno",
    "topics": [
      "agents",
      "agi",
      "ai",
      "developer-tools",
      "framework",
      "python"
    ],
    "created_at": "2022-05-04T15:23:02Z",
    "updated_at": "2025-06-22T02:22:19Z",
    "search_query": "ai agent language:python stars:>3 -framework",
    "total_issues_estimate": 84,
    "labeled_issues_estimate": 84,
    "labeling_rate": 100.0,
    "sample_labeled": 27,
    "sample_total": 27,
    "has_issues": true,
    "repo_id": 488641606,
    "default_branch": "main",
    "size": 207783
  },
  "extraction_date": "2025-06-21T23:28:08.408753",
  "extraction_type": "LABELED_ISSUES_ONLY",
  "total_labeled_issues": 500,
  "issues": [
    {
      "issue_number": 3196,
      "title": "[Bug] MCP server async causes loosing history of the messages",
      "body": "### Description\n\nWhen I create an agent with mcp seems like I cannot decouple agent decleration and message processing.\nThis causes loosing context in a chat history (every time agent reinitialized).\n\nI couldn't find any example which can support add_history_to_messages=True together with mcpserver with successful context keeping.\n\n\nexample:\nclass myAgent:\n    def __init__(self, config=None, knowledge_base=None):\n        \"\"\"Initialize configuration for DBT connection.\"\"\"\n        self.config = config or {}\n        self.knowledge_base = knowledge_base\n        \n        # Configuration for connecting to the server\n        self.server_port = int(os.getenv(\"MCP_PORT\", \"8766\"))\n        self.server_host = os.getenv(\"MCP_HOST\", \"127.0.0.1\")\n        \n    \n\n    def process_message(self, message):\n        \"\"\"Process message synchronously by delegating to async method.\"\"\"\n        import asyncio\n        print(f\"Processing message synchronously: {message[:50]}...\")\n        \n        try:\n            # Create a new event loop for this request\n            loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(loop)\n            \n            # Run the async method and get the result\n            result = loop.run_until_complete(self._process_message_async(message))\n            return result\n        except Exception as e:\n            print(f\"ERROR in DBTAgent.process_message: {e}\")\n            import traceback\n            traceback.print_exc()\n            return f\"Error processing message: {str(e)}\"\n        finally:\n            # Clean up\n            loop.close()\n            \n    async def _process_message_async(self, message):\n        \"\"\"Internal async method to process messages with MCPTools.\"\"\"\n        print(f\"Starting async message processing: {message[:50]}...\")\n     \n        \n        try:\n            # Define the URL for connecting to the already running MCP server\n            base_url = f\"http://{self.server_host}:{self.server_port}\"\n            sse_url = f\"{base_url}/sse\"\n            print(f\"Attempting to connect to MCP server at {sse_url}\")\n            \n            try:\n                # Create MCP server parameters to connect to the remote server\n                mcp_server_params = StdioServerParameters(\n                    command=\"npx\",\n                    args=[\n                        \"-y\",\n                        \"mcp-remote\",\n                        sse_url\n                    ]\n                )\n                async with MCPTools(server_params=mcp_server_params) as mcp_tools:\n                    print(\"Successfully connected to MCP server via MCPTools\")\n                    \n                    # Get model instance based on configuration\n                    model = get_model_instance(self.config)\n                    \n                    # Create a fresh agent for each request\n                    print(\"Creating agent instance...\")\n                    self.agent = Agent(\n                        tools=[mcp_tools],\n                        model=model,\n                        instructions=dedent(\"\"\"\\\n                            instructions....\"\"\"),\n                        markdown=True,\n                        add_history_to_messages=True,\n                        show_tool_calls=True,\n                        knowledge=self.knowledge_base\n                    )\n                    print(\"agent created successfully\")\n                    \n                    # Run the agent with the message\n                    print(\"Running agent with message...\")\n                    try:\n                        response = await asyncio.wait_for(self.agent.arun(message), timeout=60)\n                        print(\"Agent response received!\")\n                        \n                        # Extract response content\n                        if hasattr(response, 'content'):\n                            print(f\"Response length: {len(response.content)} chars\")\n                            return response.content\n                        else:\n                            print(\"Response has no content attribute\")\n                            return str(response)\n                    except asyncio.TimeoutError:\n                        return \"The agent's response timed out after 60 seconds. This could indicate the server is running slowly.\"\n                    except Exception as e:\n                        print(f\"ERROR during agent run: {e}\")\n                        import traceback\n                        traceback.print_exc()\n                        return f\"Error generating response: {str(e)}\"\n                    \n            except Exception as conn_error:\n                print(f\"Error establishing MCPTools connection: {conn_error}\")\n                import traceback\n                traceback.print_exc()\n                return f\"Error connecting to MCP server: {str(conn_error)}\"\n                \n        except Exception as e:\n            print(f\"Error during agent execution: {e}\")\n            import traceback\n            traceback.print_exc()\n            return f\"Error processing your request: {str(e)}\"\n    \n\n### Steps to Reproduce\n\n1. create an agent with mcp server\n2. start a chat interface and check if it can remember previous messages\n\n### Agent Configuration (if applicable)\n\nself.agent = Agent(\n                        tools=[mcp_tools],\n                        model=model,\n                        instructions=dedent(\"\"\"\\\n                            instructions....\"\"\"),\n                        markdown=True,\n                        add_history_to_messages=True,\n                        show_tool_calls=True,\n                        knowledge=self.knowledge_base\n                    )\n\n### Expected Behavior\n\nI expect agent to remember previous messages so it can have a continous conversation with the user.\n\n### Actual Behavior\n\nforgets previous messages and asks the same details over and over again loosing context.\n\n### Screenshots or Logs (if applicable)\n\n\nexample:\nclass myAgent:\n    def __init__(self, config=None, knowledge_base=None):\n        \"\"\"Initialize configuration for DBT connection.\"\"\"\n        self.config = config or {}\n        self.knowledge_base = knowledge_base\n        \n        # Configuration for connecting to the server\n        self.server_port = int(os.getenv(\"MCP_PORT\", \"8766\"))\n        self.server_host = os.getenv(\"MCP_HOST\", \"127.0.0.1\")\n        \n    \n\n    def process_message(self, message):\n        \"\"\"Process message synchronously by delegating to async method.\"\"\"\n        import asyncio\n        print(f\"Processing message synchronously: {message[:50]}...\")\n        \n        try:\n            # Create a new event loop for this request\n            loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(loop)\n            \n            # Run the async method and get the result\n            result = loop.run_until_complete(self._process_message_async(message))\n            return result\n        except Exception as e:\n            print(f\"ERROR in DBTAgent.process_message: {e}\")\n            import traceback\n            traceback.print_exc()\n            return f\"Error processing message: {str(e)}\"\n        finally:\n            # Clean up\n            loop.close()\n            \n    async def _process_message_async(self, message):\n        \"\"\"Internal async method to process messages with MCPTools.\"\"\"\n        print(f\"Starting async message processing: {message[:50]}...\")\n     \n        \n        try:\n            # Define the URL for connecting to the already running MCP server\n            base_url = f\"http://{self.server_host}:{self.server_port}\"\n            sse_url = f\"{base_url}/sse\"\n            print(f\"Attempting to connect to MCP server at {sse_url}\")\n            \n            try:\n                # Create MCP server parameters to connect to the remote server\n                mcp_server_params = StdioServerParameters(\n                    command=\"npx\",\n                    args=[\n                        \"-y\",\n                        \"mcp-remote\",\n                        sse_url\n                    ]\n                )\n                async with MCPTools(server_params=mcp_server_params) as mcp_tools:\n                    print(\"Successfully connected to MCP server via MCPTools\")\n                    \n                    # Get model instance based on configuration\n                    model = get_model_instance(self.config)\n                    \n                    # Create a fresh agent for each request\n                    print(\"Creating agent instance...\")\n                    self.agent = Agent(\n                        tools=[mcp_tools],\n                        model=model,\n                        instructions=dedent(\"\"\"\\\n                            instructions....\"\"\"),\n                        markdown=True,\n                        add_history_to_messages=True,\n                        show_tool_calls=True,\n                        knowledge=self.knowledge_base\n                    )\n                    print(\"agent created successfully\")\n                    \n                    # Run the agent with the message\n                    print(\"Running agent with message...\")\n                    try:\n                        response = await asyncio.wait_for(self.agent.arun(message), timeout=60)\n                        print(\"Agent response received!\")\n                        \n                        # Extract response content\n                        if hasattr(response, 'content'):\n                            print(f\"Response length: {len(response.content)} chars\")\n                            return response.content\n                        else:\n                            print(\"Response has no content attribute\")\n                            return str(response)\n                    except asyncio.TimeoutError:\n                        return \"The agent's response timed out after 60 seconds. This could indicate the server is running slowly.\"\n                    except Exception as e:\n                        print(f\"ERROR during agent run: {e}\")\n                        import traceback\n                        traceback.print_exc()\n                        return f\"Error generating response: {str(e)}\"\n                    \n            except Exception as conn_error:\n                print(f\"Error establishing MCPTools connection: {conn_error}\")\n                import traceback\n                traceback.print_exc()\n                return f\"Error connecting to MCP server: {str(conn_error)}\"\n                \n        except Exception as e:\n            print(f\"Error during agent execution: {e}\")\n            import traceback\n            traceback.print_exc()\n            return f\"Error processing your request: {str(e)}\"\n    \n\n### Environment\n\n```markdown\nmacos\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "samkaradag",
      "author_type": "User",
      "created_at": "2025-05-14T17:41:42Z",
      "updated_at": "2025-06-22T00:39:05Z",
      "closed_at": null,
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3196/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3196",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3196",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:19.251993",
      "comments": [
        {
          "author": "rpvitrux",
          "body": "I'm facing a similar problem that I don't yet know how to solve. The root of the issue is that some tasks cannot be completed in a single run. If you find a solution or have any feedback on my issue, I would greatly appreciate it.\n\nhttps://github.com/agno-agi/agno/issues/2732",
          "created_at": "2025-05-16T13:50:35Z"
        },
        {
          "author": "manuhortet",
          "body": "Hey @samkaradag, the `add_history_to_messages` param will indeed not work across execution cycles by default. You have to also use storage. You can see a practical example here: https://docs.agno.com/agents/memory#session-storage\n\nThe agent initialization will then look similar to this:\n```python\nag",
          "created_at": "2025-05-22T08:08:43Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-06-22T00:39:05Z"
        }
      ]
    },
    {
      "issue_number": 3523,
      "title": "[Bug] AttributeError: 'SyncHttpxClientWrapper' object has no attribute '_state'",
      "body": "### Description\n\nPerforming web search...\nException ignored in: <function SyncHttpxClientWrapper.__del__ at 0x758043ee4720>\nTraceback (most recent call last):\n  File \".venv/lib/python3.11/site-packages/openai/_base_client.py\", line 801, in __del__\n    if self.is_closed:\n       ^^^^^^^^^^^^^^\n  File \".venv/lib/python3.11/site-packages/httpx/_client.py\", line 202, in is_closed\n    return self._state == ClientState.CLOSED\n           ^^^^^^^^^^^\nAttributeError: 'SyncHttpxClientWrapper' object has no attribute '_state'\nException ignored in: <function SyncHttpxClientWrapper.__del__ at 0x758043ee4720>\nTraceback (most recent call last):\n  File \".venv/lib/python3.11/site-packages/openai/_base_client.py\", line 801, in __del__\n    if self.is_closed:\n       ^^^^^^^^^^^^^^\n  File \".venv/lib/python3.11/site-packages/httpx/_client.py\", line 202, in is_closed\n    return self._state == ClientState.CLOSED\n           ^^^^^^^^^^^\n\n\n### Steps to Reproduce\n\nrun this code in notbook or code more than 4 time \n\nfrom agno.tools.googlesearch import GoogleSearchTools\nfrom agno.tools.duckduckgo import DuckDuckGoTools\nfrom agno.knowledge.text import TextKnowledgeBase\nfrom agno.vectordb.pgvector import PgVector\n\nknowledge = TextKnowledgeBase(\n    path=Path(documents_folder),\n    chunking_strategy=AgenticChunking(model=model),\n    vector_db=vector_db,\n)\nagent = Agent(\n        model=model,\n        knowledge=knowledge, \n        add_references=True,\n        tools = [GoogleSearchTools()],\n        search_knowledge=True,\n        show_tool_calls=True,\n        markdown=True,\n        instructions=instruction,\n        # debug_mode=True,\n        )\nresponse = agent.run(question)\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nThis error pops up even for a 2 runs of code it s persistent in notebook and python script \n\n### Actual Behavior\n\nThis error should not appear\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\npython 3.11\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "basanthsk",
      "author_type": "User",
      "created_at": "2025-06-10T10:26:06Z",
      "updated_at": "2025-06-21T19:18:27Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3523/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3523",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3523",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:19.441531",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-459/bug\">SUPPORT-459 [Bug]</a></p>",
          "created_at": "2025-06-10T10:26:10Z"
        },
        {
          "author": "Mustafa-Esoofally",
          "body": "Hey @basanthsk ! Thanks for bringing this up.\n\nCould you try upgrading the openai package version using ```pip install -U \"openai>=1.55.3\"```. If you still continue facing issues let us know",
          "created_at": "2025-06-10T18:46:44Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@basanthsk I have observed this issue with OpenAI in async before when wrapping my agent in context manager. \n",
          "created_at": "2025-06-10T20:11:39Z"
        },
        {
          "author": "basanthsk",
          "body": "> Hey [@basanthsk](https://github.com/basanthsk) ! Thanks for bringing this up.\n> \n> Could you try upgrading the openai package version using `pip install -U \"openai>=1.55.3\"`. If you still continue facing issues let us know\n\nI did update the openai package as suggested, still the issue persists\n",
          "created_at": "2025-06-11T10:28:27Z"
        },
        {
          "author": "askarbozcan",
          "body": "Getting the same error with Anthropic (Bedrock) client as well. (Paths redacted for privacy)\n\n```\nException ignored in: <function SyncHttpxClientWrapper.__del__ at 0x10441ede0>\nTraceback (most recent call last):\n  File \".venv/lib/python3.12/site-packages/anthropic/_base_client.py\", line 866, in __de",
          "created_at": "2025-06-12T16:00:29Z"
        }
      ]
    },
    {
      "issue_number": 3296,
      "title": "[Bug] The Using MCP in Agno playground example does not work",
      "body": "### Description\n\nThis doesn't work if copy/pasted https://docs.agno.com/tools/mcp/mcp#using-mcp-in-agno-playground\n\nError in the playground server logs is:\n\nINFO:     ::1:58774 - \"GET /v1/playground/agents HTTP/1.1\" 500 Internal Server Error\n\nNot really helping, also setting DEBUG logging won't help.\n\nCalling the endpoint manually (http://localhost:7777/v1/playground/agents) gets you to the issues, though:\n\n{\"detail\":\"Async tool MCPTools can't be used with synchronous agent.run() or agent.print_response(). Use agent.arun() or agent.aprint_response() instead to use this tool.\"}\n\n### Steps to Reproduce\n\nJust run this:\n\nhttps://docs.agno.com/tools/mcp/mcp#using-mcp-in-agno-playground\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nRunning the Agno UI on top of agents with MCP deployed in the Playground should work.\n\n### Actual Behavior\n\nRunning the Agno UI on top of agents with MCP deployed in the Playground fails with HTTP 500 error code:\n\n{\"detail\":\"Async tool MCPTools can't be used with synchronous agent.run() or agent.print_response(). Use agent.arun() or agent.aprint_response() instead to use this tool.\"}\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nMacOS, Python 3.13, Agno v. 1.5.3\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "dvaida",
      "author_type": "User",
      "created_at": "2025-05-22T13:25:19Z",
      "updated_at": "2025-06-21T17:23:11Z",
      "closed_at": "2025-06-21T17:23:11Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3296/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3296",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3296",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:19.636615",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-268/bug-the-using-mcp-in-agno-playground-example-does-not-work\">SUPPORT-268 [Bug] The Using MCP in Agno playground example does not work</a></p>",
          "created_at": "2025-05-22T13:25:22Z"
        },
        {
          "author": "dvaida",
          "body": "Also, starting development with everything async (especially with a robust agent team and a lot of tools) produces unreadable code (you can't really demo that as all people see is handling async constructs) and forces you to shape your entire system around async MCP tooling. I would suggest keeping ",
          "created_at": "2025-05-22T13:38:44Z"
        },
        {
          "author": "manuhortet",
          "body": "Hey @dvaida, thank you for reporting this. The example was not working because of a bug with how we handle async agent tools in the playground. I opened a PR with a fix (https://github.com/agno-agi/agno/pull/3356) and we will try to merge it asap!\n\nApart from that, you are right, I agree that using ",
          "created_at": "2025-05-26T10:06:27Z"
        },
        {
          "author": "furkanc",
          "body": "Hey @manuhortet, thanks a lot for your fix 🙏\nThis should also be fixed for teams. I was planning to open a PR, but we can include it with your current fix.\n\nIn addition, async_mode=True should also be passed [here](https://github.com/agno-agi/agno/blob/6bd719af9abf6113653ae6a06ef2309d43141bda/libs/a",
          "created_at": "2025-05-26T10:25:24Z"
        },
        {
          "author": "manuhortet",
          "body": "Great, thanks for noticing @furkanc, I'll make it work for teams too! \n\nBetter to always pass `async_mode=True`, as these agents will indeed be always be invoked async in this context, and the flag could be used for more stuff in the future. But thanks for the recommendation, I appreciate the suppor",
          "created_at": "2025-05-26T11:06:22Z"
        }
      ]
    },
    {
      "issue_number": 3616,
      "title": "[Bug] Visualisation tool not showing images in playground",
      "body": "### Description\n\nAgno's new Visualisation tool creates the bar chart locally but faild to load it into the chat context.\n\n<img width=\"920\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/b6315ba3-c1fd-46c5-bdc0-f6556c728f8d\" />\n\n### Steps to Reproduce\n\n1. Set up an agent using the visualisation tool\n2. Run the Agno Playground app\n3. Open the playground app at `app.agno.com` or use the local `agent-ui`\n4. Ask the agent to generate a simple chart\n5. See results.\n\n### Agent Configuration (if applicable)\n\n```\nAgent(\n            tools=[VisualizationTools(output_dir=\"./assets/charts\", enable_all=True)],\n            name=\"Viz Agent\",\n            model=OpenAIChat(id=\"gpt-4o-mini\"),\n            description=dedent(AGENT_DESC),\n            instructions=AGENT_INSTRUCTIONS,\n            debug_mode=True if os.environ.get(\"DEBUG\") else False,\n            show_tool_calls=True if os.environ.get(\"DEBUG\") else False,\n        )\n```\n\n### Expected Behavior\n\nI want the playground UIs to return the image in the chat.\n\n### Actual Behavior\n\nIt doenst load the image \n\n<img width=\"920\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/691e96c9-3907-4ac0-8c82-2667cf6f3b43\" />\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n- Mac\n- agno>=1.6.3\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "sebastian-montero",
      "author_type": "User",
      "created_at": "2025-06-21T16:32:39Z",
      "updated_at": "2025-06-21T16:32:39Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3616/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3616",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3616",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:19.837173",
      "comments": []
    },
    {
      "issue_number": 3597,
      "title": "[Bug] The tool \"list_repositories\" for agno.tools.github.GithubTools is not completely implemented",
      "body": "### Description\n\n\nThe tool is written but cannot be added/enabled (simply missing implementation in the code),\n it is not provided as a boolean choice at the top, to enable the feature, and it is not added as tool.\n\n### Steps to Reproduce\n\ncheck the file agno.tools.github.GithubTools.\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\ntool to be available.\n\n### Actual Behavior\n\ntool not available\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nNA\n```\n\n### Possible Solutions (optional)\n\nI will provide a PR with the simple fix\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "Siete-F",
      "author_type": "User",
      "created_at": "2025-06-19T20:32:57Z",
      "updated_at": "2025-06-21T15:48:17Z",
      "closed_at": "2025-06-21T15:48:17Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3597/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3597",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3597",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:19.837195",
      "comments": [
        {
          "author": "kausmeows",
          "body": "@Siete-F PR merged! This will be out with the next release thanks for the contribution! 🚀",
          "created_at": "2025-06-21T11:10:50Z"
        }
      ]
    },
    {
      "issue_number": 3615,
      "title": "[Bug] team_session_state 에러",
      "body": "### Description\n\n\nHi team,\n\nI was following the example from the [Shared State documentation](https://docs.agno.com/teams/shared-state), specifically using the team_session_state.py example.\n\nHowever, when I tried to run the code, I encountered the following error:\n\n```\n  File \"/Users/sungeunmyung/Desktop/astin/role_play/test_play_weight/dd.py\", line 40, in remove_all_items\n    agent.team_session_state[\"shopping_list\"] = []\nTypeError: 'NoneType' object does not support item assignment\n```\n\nIt seems like agent.team_session_state is None, and thus cannot be used like a dictionary. Based on the documentation, I expected it to be an initialized dictionary-like object.\n\nCould you clarify if this is a bug or if there’s an initialization step missing from the documentation?\n\nThanks!\n\n### Steps to Reproduce\n\n1. go to 'https://docs.agno.com/teams/shared-state '\n2. just run 'team_session_state.py'\n\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nExample work without error\n\n### Actual Behavior\n\nI can't use it team agent with team_state\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n- mac os\n- agno==1.6.3\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "astin75",
      "author_type": "User",
      "created_at": "2025-06-21T14:00:51Z",
      "updated_at": "2025-06-21T14:00:51Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3615/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3615",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3615",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:20.071750",
      "comments": []
    },
    {
      "issue_number": 3595,
      "title": "[Bug] error when rename session_name of team",
      "body": "### Description\n\n## 🐞 Bug Report\n\n**Describe the bug**  \nCalling `team.rename_session(...)` raises an `AttributeError` because the `AgentSession` object does not have the `team_data` attribute.\n\n**Traceback**\napi-1 | File \"/app/api/routes/v1/conversation.py\", line 212, in rename_team_session\napi-1 | team.rename_session(session_name='hihi')\napi-1 | File \"/usr/local/lib/python3.11/site-packages/agno/team/team.py\", line 6490, in rename_session\napi-1 | self.read_from_storage(session_id=session_id) # type: ignore\napi-1 | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\napi-1 | File \"/usr/local/lib/python3.11/site-packages/agno/team/team.py\", line 6464, in read_from_storage\napi-1 | self.load_team_session(session=self.team_session)\napi-1 | File \"/usr/local/lib/python3.11/site-packages/agno/team/team.py\", line 6516, in load_team_session\napi-1 | if session.team_data is not None:\napi-1 | ^^^^^^^^^^^^^^^^^\napi-1 | AttributeError: 'AgentSession' object has no attribute 'team_data'\n**Expected behavior**  \nThe `rename_session` method should not throw an exception. Either `team_data` should exist on the session object, or a type/attribute check should be performed before accessing it.\n\n**To Reproduce**\n1. Call `team.rename_session(session_name='...')` on a `Team` instance.\n2. Internally, `read_from_storage()` is invoked and attempts to load the session.\n3. `load_team_session()` accesses `session.team_data`, which does not exist on `AgentSession`.\n\n### Steps to Reproduce\n\nCall team.rename_session(session_name='...') on a Team instance.\n\nObserve crash when load_team_session() is called.\n\nThe crash occurs due to missing team_data attribute on AgentSession.\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nThe method rename_session should not raise an exception. team_data should either exist on AgentSession, or proper validation should be done before accessing it.\n\n### Actual Behavior\n\nThis happens because `load_team_session()` assumes the session object has a `team_data` attribute, but it doesn't exist on the `AgentSession` instance.\n\n### Screenshots or Logs (if applicable)\n\n![Image](https://github.com/user-attachments/assets/aeacd978-2e2b-40a0-8dd0-a1645220d52e)\n\n### Environment\n\n```markdown\n- Agno version: 1.6.3\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "iawtk2302",
      "author_type": "User",
      "created_at": "2025-06-19T03:05:01Z",
      "updated_at": "2025-06-21T13:55:33Z",
      "closed_at": "2025-06-21T13:55:33Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3595/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3595",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3595",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:20.071777",
      "comments": [
        {
          "author": "amMistic",
          "body": "Hey @iawtk2302,\nare you passing the session id manually while creating the instance of team and agent?\n",
          "created_at": "2025-06-20T09:36:10Z"
        },
        {
          "author": "kausmeows",
          "body": "hi @iawtk2302  thanks for raising this!\nfixed here- https://github.com/agno-agi/agno/pull/3614\n\nwould be released in the next version!\n",
          "created_at": "2025-06-21T12:33:19Z"
        }
      ]
    },
    {
      "issue_number": 3515,
      "title": "[Bug] Mongodb knowledge is not taking into account knowledge_filters when search is Hybrid",
      "body": "### Description\n\nHybrid search call doesn't pass the filters in Mongodb KnowledgeBase \n![Image](https://github.com/user-attachments/assets/ed4a74a1-a589-4870-9c80-574edfd6ae32)\n\n### Steps to Reproduce\n\n1. Create a mongodb knowledgebase with search_type=SearchType.hybrid,\n2. Create an agent that queries the data with knowledge_filters \n3. call agent.run \n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nfilters should be taken into account, i.e injected into the aggregation pipeline \n\n### Actual Behavior\n\nSearch ignores filters\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nmacOS\nAgno version 1.5.10\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "Zuttam",
      "author_type": "User",
      "created_at": "2025-06-09T15:05:39Z",
      "updated_at": "2025-06-21T13:54:07Z",
      "closed_at": "2025-06-21T13:54:07Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3515/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kausmeows"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3515",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3515",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:20.359665",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-455/bug-mongodb-knowledge-is-not-taking-into-account-knowledge-filters\">SUPPORT-455 [Bug] Mongodb knowledge is not taking into account knowledge_filters when search is Hybrid</a></p>",
          "created_at": "2025-06-09T15:05:42Z"
        },
        {
          "author": "Zuttam",
          "body": "@ysolanky any chance to get an update on this one? ",
          "created_at": "2025-06-15T08:03:29Z"
        },
        {
          "author": "kausmeows",
          "body": "Hey @Zuttam thanks for raising and reminding on this, I’ll work on this and keep you posted. Thanks!",
          "created_at": "2025-06-15T08:26:38Z"
        },
        {
          "author": "Zuttam",
          "body": "Thanks @kausmeows while you guys are on it, can you also improve the \"delete\" function to accept custom filters (currently it deletes the entire collection)",
          "created_at": "2025-06-15T09:19:36Z"
        },
        {
          "author": "kausmeows",
          "body": "> Thanks [@kausmeows](https://github.com/kausmeows) while you guys are on it, can you also improve the \"delete\" function to accept custom filters (currently it deletes the entire collection)\n\nYes @Zuttam this has been requested before, having delete on the vector db level for individual docs (youre ",
          "created_at": "2025-06-15T09:22:08Z"
        }
      ]
    },
    {
      "issue_number": 3577,
      "title": "[Bug] in lance_db.py, function `upsert` doesn't use the parameter `filters`",
      "body": "### Description\n\n    def upsert(self, documents: List[Document], filters: Optional[Dict[str, Any]] = None) -> None:\n        \"\"\"\n        Upsert documents into the database.\n\n        Args:\n            documents (List[Document]): List of documents to upsert\n            filters (Optional[Dict[str, Any]]): Filters to apply while upserting\n        \"\"\"\n        self.insert(documents)\n\n### Steps to Reproduce\n\nNone\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nEffect\n\n### Actual Behavior\n\nNo effect\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nAgno\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "YilingLiang",
      "author_type": "User",
      "created_at": "2025-06-17T07:43:08Z",
      "updated_at": "2025-06-21T13:53:28Z",
      "closed_at": "2025-06-21T13:53:28Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3577/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3577",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3577",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:20.550066",
      "comments": [
        {
          "author": "kausmeows",
          "body": "Thanks for raising, we'll fix asap!",
          "created_at": "2025-06-17T18:05:05Z"
        },
        {
          "author": "kausmeows",
          "body": "fix PR: https://github.com/agno-agi/agno/pull/3612\n\nwill be released in the next version. Thanks for raising this! ",
          "created_at": "2025-06-21T11:23:11Z"
        }
      ]
    },
    {
      "issue_number": 3121,
      "title": "[Bug] When agent configured with Llama, it does not respond.",
      "body": "# Description\nAgent works with openAI, Gemini and other models but when Llama is configured, it does not respond. I think the issue is specific to v1.4.5. In below log, note that `assistant` does not respond with anything.\n\n## Agent run log\n```\nagno-copilotkit-integration/backend on  main [!] via 🐍 v3.12.4 (.venv-backend) \n❯ python sample_agent.py \nDEBUG ******************************************************* Agent ID: ace9e158-53f4-41b1-8ffe-cf56b0a737a7 ******************************************************              \nDEBUG ****************************************************** Session ID: 117a7cf8-c6ac-468d-a050-ce8e9f2e00ca *****************************************************              \nDEBUG *************************************************** Agent Run Start: 3e9d59af-bb4e-4e08-9fd2-daa30f9d86ef ***************************************************              \nDEBUG Processing tools for model                                                                                                                                                 \nDEBUG Added tool google_search from googlesearch                                                                                                                                 \nDEBUG Added tool get_current_stock_price from yfinance_tools                                                                                                                     \nDEBUG Added tool get_company_info from yfinance_tools                                                                                                                            \nDEBUG Added tool get_stock_fundamentals from yfinance_tools                                                                                                                      \nDEBUG Added tool get_income_statements from yfinance_tools                                                                                                                       \nDEBUG Added tool get_key_financial_ratios from yfinance_tools                                                                                                                    \nDEBUG Added tool get_analyst_recommendations from yfinance_tools                                                                                                                 \nDEBUG Added tool get_company_news from yfinance_tools                                                                                                                            \nDEBUG Added tool get_technical_indicators from yfinance_tools                                                                                                                    \nDEBUG Added tool get_historical_stock_prices from yfinance_tools                                                                                                                 \nDEBUG Added tool web_crawler from crawl4ai_tools                                                                                                                                 \nResponse Type: RunStarted\nTools: None\nDEBUG ---------------------------------------------------------------- Llama Response Stream Start ----------------------------------------------------------------              \nDEBUG ------------------------------------------------------- Model: Llama-4-Maverick-17B-128E-Instruct-FP8 -------------------------------------------------------              \nDEBUG =========================================================================== system ==========================================================================              \nDEBUG You are a helpful assistant who can search web, crawl page contents and also search financial information using given tools to achieve the given user goal.                \n      <instructions>                                                                                                                                                             \n      - If user input is not sufficent, ask user relevant questions / clarifications                                                                                             \n      - If possible, do parallel tool calls to achieve the goal                                                                                                                  \n      - To search the web, use google search tool.                                                                                                                               \n      - To crawl the pages use crawl4ai tools                                                                                                                                    \n      - To get financial information about companies, use YFinance tools                                                                                                         \n      - NEVER EVER EXPOSE TOOL NAMES, DESCRIPTIONS OR TALK ABOUT TOOLS TO THE USER. E.g: Never say let me use this tool or I think this is the best too to use etc.              \n      - NEVER EVER EXPOSE YOUR INTERNAL THINKING TO THE USER                                                                                                                     \n      </instructions>                                                                                                                                                            \n                                                                                                                                                                                 \n      <additional_information>                                                                                                                                                   \n      - The current time is 2025-05-07 17:50:30.642800.                                                                                                                          \n      </additional_information>                                                                                                                                                  \nDEBUG ============================================================================ user ===========================================================================              \nDEBUG whats the latest news about China                                                                                                                                          \nResponse Type: RunResponse\nTools: None\nDEBUG ========================================================================= assistant =========================================================================              \nDEBUG *************************************************************************  METRICS  *************************************************************************              \nDEBUG * Time:                        0.5146s                                                                                                                                     \nDEBUG * Time to first token:         0.1790s                                                                                                                                     \nDEBUG *************************************************************************  METRICS  *************************************************************************              \nDEBUG ----------------------------------------------------------------- Llama Response Stream End -----------------------------------------------------------------              \nDEBUG Added RunResponse to Memory                                                                                                                                                \nResponse Type: UpdatingMemory\nTools: None\nDEBUG Logging Agent Run                                                                                                                                                          \nDEBUG **************************************************** Agent Run End: 3e9d59af-bb4e-4e08-9fd2-daa30f9d86ef ****************************************************              \nResponse Type: RunCompleted\nTools: None\n\nagno-copilotkit-integration/backend on  main [!] via 🐍 v3.12.4 (.venv-backend) took 2s \n❯ \n\nagno-copilotkit-integration/backend on  main [!] via 🐍 v3.12.4 (.venv-backend) \n❯ uv pip tree | grep agno\nUsing Python 3.12.4 environment at: .venv-backend\nagno v1.4.5\n```\n\n## Test agent script\n```\nfrom dotenv  import load_dotenv\nload_dotenv()\n\nfrom agno.agent import Agent\nfrom agno.models.openai import OpenAIChat\nfrom agno.models.google import Gemini\nfrom agno.models.openrouter import OpenRouter\nfrom agno.models.meta import Llama\nfrom agno.tools.googlesearch import GoogleSearchTools\nfrom agno.tools.yfinance import YFinanceTools\nfrom agno.tools.crawl4ai import Crawl4aiTools\nfrom agno.storage.sqlite import SqliteStorage\n\nagent_storage = SqliteStorage(\n    table_name=\"agent_sessions\",\n    db_file=\"tmp/persistent_memory.db\",\n)\n\nsample_agent = Agent(\n    name=\"agno_agent\",\n    description=\"You are a helpful assistant who can search web, crawl page contents and also search financial information using given tools to achieve the given user goal.\",\n    # model=OpenAIChat(id=\"gpt-4o\"),\n    # model=Gemini(id=\"gemini-2.5-flash-preview-04-17\"),\n    model=Llama(id=\"Llama-4-Maverick-17B-128E-Instruct-FP8\"),\n    # model=OpenRouter(id=\"deepseek/deepseek-chat-v3-0324\"),\n    # model=OpenRouter(id=\"qwen/qwen3-235b-a22b\"),\n    # model=Groq(id=\"llama-3.3-70b-versatile\"),\n    instructions=[\n        \"If user input is not sufficent, ask user relevant questions / clarifications\",\n        \"If possible, do parallel tool calls to achieve the goal\",\n        \"To search the web, use google search tool.\",\n        \"To crawl the pages use crawl4ai tools\",\n        \"To get financial information about companies, use YFinance tools\",\n        \"NEVER EVER EXPOSE TOOL NAMES, DESCRIPTIONS OR TALK ABOUT TOOLS TO THE USER. E.g: Never say let me use this tool or I think this is the best too to use etc.\",\n        \"NEVER EVER EXPOSE YOUR INTERNAL THINKING TO THE USER\",\n    ],\n    storage=agent_storage,\n    # add_history_to_messages=True,\n    # num_history_responses=5,\n    tools=[\n        GoogleSearchTools(),\n        YFinanceTools(enable_all=True),\n        Crawl4aiTools(max_length=5000)\n    ],\n    # reasoning=True,\n    stream_intermediate_steps=True,\n    add_datetime_to_instructions=True,\n    debug_mode=True\n)\n\nuser_prompt = \"whats the latest news about China\"\nfor res in sample_agent.run(user_prompt, stream=True):\n    print(f\"Response Type: {res.event}\")\n    print(f\"Tools: {res.tools}\")\n#     # print(f\"Messages: {res.messages}\")\n```",
      "state": "closed",
      "author": "gauravdhiman",
      "author_type": "User",
      "created_at": "2025-05-08T00:54:48Z",
      "updated_at": "2025-06-21T10:57:36Z",
      "closed_at": "2025-06-21T10:57:36Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3121/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3121",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3121",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:20.747742",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-06-08T00:38:52Z"
        },
        {
          "author": "gauravdhiman",
          "body": "Pls check this",
          "created_at": "2025-06-08T08:02:57Z"
        },
        {
          "author": "jhowrez",
          "body": "Also having this problem, both with maverick and scout.\nSeems related to their <|header_start|>ipython<|header_end|>... <|eot|> format",
          "created_at": "2025-06-18T09:50:40Z"
        },
        {
          "author": "Mustafa-Esoofally",
          "body": "Hey @gauravdhiman ! Could you trying updating to the latest Agno version and try again? Are you still facing the same issue",
          "created_at": "2025-06-19T02:52:13Z"
        },
        {
          "author": "kausmeows",
          "body": "This should now be fixed. \nIt was an issue from the llama's sdk side, See here- https://github.com/meta-llama/llama-api-python/issues/31\n\n<img width=\"755\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/b4b27527-6173-4f61-a38a-11a9b87d9741\" />",
          "created_at": "2025-06-21T10:57:31Z"
        }
      ]
    },
    {
      "issue_number": 3387,
      "title": "[Feature Request]  The vector library supports Elasticsearch",
      "body": "### Problem Description\n\nProject requirements, work requirements\n\n### Proposed Solution\n\nElasticsearch should support vector retrieval and jieba word segmentation retrieval\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.",
      "state": "open",
      "author": "yqher",
      "author_type": "User",
      "created_at": "2025-05-28T09:09:32Z",
      "updated_at": "2025-06-21T06:02:09Z",
      "closed_at": null,
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3387/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3387",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3387",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:20.970603",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-332/feature-request-the-vector-library-supports-elasticsearch\">SUPPORT-332 [Feature Request] The vector library supports Elasticsearch</a></p>",
          "created_at": "2025-05-28T09:09:35Z"
        },
        {
          "author": "anhphong22",
          "body": "Hi @yqher I am implementing to support opensearch and will support elasticsearch later on.",
          "created_at": "2025-06-04T02:52:45Z"
        },
        {
          "author": "monali7-d",
          "body": "@anhphong22 great to hear this. Looking forward to your contribution.\n",
          "created_at": "2025-06-17T12:36:11Z"
        },
        {
          "author": "Mustafa-Esoofally",
          "body": "Hey @anhphong22 ! Do you have a open PR we can review? Let us know if you need help ",
          "created_at": "2025-06-19T13:57:20Z"
        },
        {
          "author": "anhphong22",
          "body": "> Hey [@anhphong22](https://github.com/anhphong22) ! Do you have a open PR we can review? Let us know if you need help\n\nHey @Mustafa-Esoofally I have a PR to need reviewing before continuing support elasticsearch as both dbs have the same arch and functionality.\nhttps://github.com/agno-agi/agno/pull",
          "created_at": "2025-06-21T06:02:09Z"
        }
      ]
    },
    {
      "issue_number": 2608,
      "title": "[Bug] Unable to either disable SSL or provide SSL path to certification",
      "body": "## Description\nThe Agno library's Gemini model implementation fails with SSL certificate verification errors when attempting to stream responses. This occurs at the model's invocation level, not at the image loading level, indicating a fundamental SSL verification issue within the Agno-Gemini integration.\n\n## Steps to Reproduce\nCreate a basic Agno agent with Gemini model:\n```python\nagent = Agent(\n    model=Gemini(id=\"gemini-2.0-flash\"),\n    tools=[],\n    markdown=True\n)\n\nagent.print_response(\n    \"Tell me about AI.\",\n    stream=True,\n)\n```\n\n## Expected Behavior\nThe agent should establish a secure connection to the Gemini API and stream the response without SSL verification issues. There is an issue with my SSL certificate so it should give me an option to disable SSL verification using `verify=False` flag.\n\n## Actual Behavior\nThe code fails immediately with an SSL certificate verification error in the model's stream invocation:\n\n``` \nFile \"...agno/models/base.py\", line 472, in process_response_stream\n    for response_delta in self.invoke_stream(messages=messages):\nFile \"...agno/models/google/gemini.py\", line 382, in invoke_stream\n    raise ModelProviderError(message=str(e), model_name=self.name, model_id=self.id) from e\nagno.exceptions.ModelProviderError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1028)\n```\n\n## Screenshots or Logs (if applicable)\n\n```\nraise mapped_exc(message) from exc\nhttpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1028)\n```\n\n\n## Environment\n\n```\nRun the code\nAgent Configuration\nModel: Gemini (gemini-2.0-flash)\nTools: None\nMarkdown: True\nStream: True\n```\n\n## Expected Behavior\n```\nThe agent should establish a secure connection to the Gemini API and stream the response without SSL verification issues.\n```\n\n## Actual Behavior\n```\nThe code fails immediately with an SSL certificate verification error in the model's stream invocation:\n```\n\n## Environment\n\n```\nOS: Windows\nPython Version: 3.13.2\nAgno Version: Latest\nDependencies:\ngoogle-genai\nhttpx\nurllib3\nagno\n```\n\n## Possible Solutions\n* Implement SSL verification configuration options in Agno Agent and other classes\n* Update the Agno implementation to use proper SSL certificates or handle self-signed certificates or turn off SSL\n* Add SSL verification configuration options to the base model class in Agno\n* Provide a way to configure SSL settings at the Agent initialization level\n\n## Additional Context\n* The error occurs during the model's `invoke_stream` method, suggesting the issue is with the Gemini API connection\n* This is not related to image loading or processing, as the error occurs with basic text prompts\n* The error suggests there might be a proxy or network security setup causing certificate validation issues\n* Standard SSL verification workarounds (urllib3, ssl context) don't affect the internal connection used by the Gemini model\n```",
      "state": "open",
      "author": "tapas-joshi",
      "author_type": "User",
      "created_at": "2025-03-29T17:34:20Z",
      "updated_at": "2025-06-21T00:34:48Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 12,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2608/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "willemcdejongh"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2608",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2608",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:21.149291",
      "comments": [
        {
          "author": "tapas-joshi",
          "body": "Any help would be appreciated by the Agno team. It is a very big blocker for me since I cannot use Agno without this. ",
          "created_at": "2025-03-31T00:22:39Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @tapas-joshi, Sorry for the delay - Our team was taking a breather over the weekend, We had massive release week\n\nTagging engineers on this, we will get back to asap",
          "created_at": "2025-03-31T07:25:53Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @tapas-joshi \nI am unable to replicate this issue. It could be a red herring possibly, are you sure you are exporting `GOOGLE_API_KEY` for the API key? \nI also looked through their SDK and there is no ability to disable their internal SSL verification. ",
          "created_at": "2025-03-31T15:21:03Z"
        },
        {
          "author": "lowlandghost",
          "body": "Are you behind an enterprise proxy? You may need to patch your certifi bundle to include the root CAs for the proxy. You can get the bundle path with this:\n\n```python\nimport certifi\nprint(certifi.where())\n```",
          "created_at": "2025-04-10T20:27:20Z"
        },
        {
          "author": "tapas-joshi",
          "body": "Correct @lowlandghost, I am behind the enterprise proxy and I cannot access any SSL websites through code. I tried the certifi library and provided the root certificate but it did not work. Any way to bypass SSL with verify=False flag?",
          "created_at": "2025-04-11T19:07:09Z"
        }
      ]
    },
    {
      "issue_number": 2826,
      "title": "[Usage] Returning additional objects other than the tool response",
      "body": "First, thank you for your work in this great library! I had a quick set of questions, I checked the documentation but was not able to find something similar\n\nLets say I have a tool\n\n```python\ndef custom_tool(query: str) -> str:\n    # do whatever\n    result = some_function(query)\n    return result\n```\n\nIn agno, this `result` is passed to the LLM internally and agent responds but I want to be able to \n\n\n```python\nfrom pydantic import BaseModel\nfrom typing import List\n\nclass ToolCallResult(BaseModel):\n    query: str\n    to_use_in_application: List\n\ndef custom_tool(query: str) -> ToolCallResult:\n    # do whatever\n    result = some_other_function(query)\n    return result\n```\n\n```python\nasync for resp in await agent.arun(\n       query,\n        stream=True,\n        stream_intermediate_steps=True,\n    ):\n    # match resp event with the specific tool call\n    # use the respective output in the application\n```\n\nAre there any objects or anything in agno that can help me with this?\n\n\nMoreover, I want to confirm something else when I create a tool,\n\n```python\nasync def general_run(query, agent: Agent) -> str:\n    return await some_function(\n        query=query,\n        some_params=agent.context[\"some_params\"],  # type: ignore\n        ...\n    )\n\ngeneral_tool = Function(\n        name=\"general_tool\",\n        entrypoint=general_run,\n        description=\"Tool to run for general questions about EPAM\",\n    )\n```\n\nI tried this and it works but is this an alright usage, I want to be able to give external parameters to tools, I assume I can update agent's context within the tool call but I want to pass parameters from outside like some configs\n",
      "state": "open",
      "author": "aliozts",
      "author_type": "User",
      "created_at": "2025-04-14T13:59:36Z",
      "updated_at": "2025-06-21T00:34:46Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2826/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2826",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2826",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:21.383604",
      "comments": [
        {
          "author": "Mustafa-Esoofally",
          "body": "Hi @aliozts ! Thanks for reaching out! The agent you suggested is exactly how I would go about doing this. \n\nYou can also maybe try baking. your config in at tool-creation time, a simple functools.partial or a closure will do:\n\n`from functools import partial\n\ndef make_general_tool(cfg: MyConfig):\n  ",
          "created_at": "2025-04-26T21:19:28Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-06-18T00:34:55Z"
        },
        {
          "author": "Mustafa-Esoofally",
          "body": "Hey @aliozts ! Could you confirm that you still need help?",
          "created_at": "2025-06-19T13:34:53Z"
        }
      ]
    },
    {
      "issue_number": 2928,
      "title": "[Bug] Input question not being saved in workflow memory db",
      "body": "# Description\nI don't see input question being saved anywhere in db when using workflows, i see you have added memory 2.0 update might need to fix something over there.\n\n## Steps to Reproduce\nI'm using cookbook/workflows/workflows_playground.py and using BlogPostGenerator\nI've tried others workflows aswell, same is happening\n\n## Agent Configuration (if applicable)\nI had even added auto_upgrade_schema and mode aswell\n```\nblog_post_generator = BlogPostGenerator(\n    workflow_id=\"generate-blog-post\",\n    storage=SqliteStorage(\n        table_name=\"generate_blog_post_workflows\",\n        db_file=\"tmp/agno_workflows.db\",\n        auto_upgrade_schema=True,\n        mode='workflow'\n    ),\n)\n```\n\n## Expected Behaviour\nI want to see their input question being saved\n\n## Actual Behaviour\nthis is the sample memory from column 'memory'\n```\n{\n  \"summaries\": {},\n  \"memories\": {},\n  \"runs\": {\n    \"605f9d4d-fdac-4c61-b6f8-e20ad131b7db\": [\n      {\n        \"content\": \"content....\",\n        \"content_type\": \"str\",\n        \"event\": \"RunResponse\",\n        \"run_id\": \"9bcd9b34-b9d3-4eaf-bf6e-3c9d7e13f587\",\n        \"session_id\": \"605f9d4d-fdac-4c61-b6f8-e20ad131b7db\",\n        \"workflow_id\": \"generate-blog-post\",\n        \"created_at\": 1745335830\n      }\n    ]\n  }\n}\n```\n\nearlier it used to be like this\n```\n{\n  \"runs\": [\n    {\n      \"input\": {\n        \"question\": \"why is sky blue?\"\n      },\n      \"response\": {\n        \"content\": content....\",\n        \"content_type\": \"str\",\n        \"event\": \"RunResponse\",\n        \"run_id\": \"42004086-7d6a-418b-a8eb-fae5756fabd1\",\n        \"session_id\": \"05571f4b-6d41-4995-a2ea-72c78e889cde\",\n        \"workflow_id\": \"generate-blog-post\",\n        \"created_at\": 1743151477\n      }\n    }\n  ]\n}\n```\n\n\n## Environment\n- OS: Ubuntu 20.04\n- Browser Chrome\n- Agno Version: v1.3.5\n- Additional Environment Details: Python 3.10\n\n",
      "state": "open",
      "author": "AjayVarmaK",
      "author_type": "User",
      "created_at": "2025-04-22T15:49:57Z",
      "updated_at": "2025-06-21T00:34:45Z",
      "closed_at": null,
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2928/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2928",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2928",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:21.617765",
      "comments": [
        {
          "author": "alaap001",
          "body": "+1",
          "created_at": "2025-04-24T10:33:13Z"
        },
        {
          "author": "linuxhackr",
          "body": "In workflow.py\n\n```python\nself.memory.runs = [WorkflowRun(**m) for m in session.memory[\"runs\"]]\n```\n\nWhile loading session, I can see runs are `dict` in the database(I use mongo in my case) but here it's being read as `list`. Due to this we are getting error:\n`\nFailed to load runs from memory: agno.",
          "created_at": "2025-04-25T12:56:56Z"
        },
        {
          "author": "AjayVarmaK",
          "body": "Any update regarding the bug?",
          "created_at": "2025-04-30T14:19:25Z"
        },
        {
          "author": "Mustafa-Esoofally",
          "body": "Hi @AjayVarmaK and @linuxhackr ! We are looking into this and will be back with an update soon. Thanks for bringing this up",
          "created_at": "2025-05-08T14:27:00Z"
        },
        {
          "author": "AjayVarmaK",
          "body": "Hey @Mustafa-Esoofally, any update on the fix?",
          "created_at": "2025-05-19T09:51:55Z"
        }
      ]
    },
    {
      "issue_number": 3134,
      "title": "[Bug] error in streaming mode if llm call tool does not require parameters",
      "body": "# Description\nCommunicate with qwen3-32b via streaming, when need to call a tool without arguments, if the model returns the argument as '', wait until the completion of the tool call and then return to the model will report an error.\nI think there are 3 main reasons for this problem:\n1. the ability of the model itself (no such phenomenon when using deepseek-chat API, but it will be triggered when using locally deployed qwen3-32b)\n2. the use of streaming (not triggered when stream=False)\n3. tool does not require parameters\n\n## Steps to Reproduce\n1. select qwen3-32b as model\n2. use stream=True\n3. selec a tool does not require parameters\n\n## Agent Configuration (if applicable)\nMinimum Implementation Code:\n```py\nimport random\n\nfrom agno.agent import Agent\nfrom agno.models.openai.like import OpenAILike\nfrom agno.tools import tool\n\n\n@tool(show_result=True)\ndef get_number() -> str:\n    \"\"\"Get the number.\"\"\"\n    # In a real implementation, this would call a number API\n    random_number = random.randint(1, 100)\n\n    return f\"The number is {random_number}.\"\n\n\nmodel = OpenAILike(\n    id=\"qwen3-32b\", base_url=\"http://127.0.0.1:8080, api_key=\"sk-xxxxx\"\n)\n\nagent = Agent(model=model, tools=[get_number], debug_mode=True)\nagent.print_response(\"Give me a random number.\", stream=True)\n```\n\n## Expected Behavior\nCall the tool and output the results\n\n## Actual Behavior\n```powershell\nPS D:\\Code\\agent\\agno_bug> & D:/Code/agent/agno_bug/.venv/Scripts/python.exe d:/Code/agent/agno_bug/main.py\nDEBUG ******************************************* Agent ID: d70c8231-afc4-4770-8ff7-812fc329179d *******************************************\nDEBUG ****************************************** Session ID: 4a93145c-b17e-4f0a-aace-08780e3fe147 ******************************************\nDEBUG *************************************** Agent Run Start: 4d03b13d-f073-4f03-b938-ffa1b1a242e9 ****************************************\nDEBUG Processing tools for model\nDEBUG Added tool get_number\nDEBUG ---------------------------------------------------- OpenAI Response Stream Start ----------------------------------------------------\nDEBUG ---------------------------------------------------------- Model: qwen3-32b ----------------------------------------------------------\nDEBUG ================================================================ user ================================================================\nDEBUG Give me a random number.\nDEBUG messages in stream: [{'role': 'user', 'content': 'Give me a random number.'}]\nDEBUG ============================================================= assistant ==============================================================\nDEBUG <think>\n      Okay, the user is asking for a random number. Let me check the tools available. There's a function called get_number with no parameters required.   \n      Since the user wants a random number, I should call that function. But wait, the function's description just says \"Get the number.\" Does it generate\n      a random one or return a fixed value? The parameters are empty, so maybe it's designed to return a random number by default. I'll proceed to call   \n      get_number without any arguments. I need to make sure the tool call is correctly formatted in JSON within the XML tags. Alright, that should do it. \n      </think>\n\n\nDEBUG Tool Calls:                                                                                                                                         \n        - ID: 'chatcmpl-tool-1077bda4db6941d1936130b9f9d57102'                                                                                            \n          Name: 'get_number'                                                                                                                              \nDEBUG *************************************************************  METRICS  **************************************************************              \nDEBUG * Tokens:                      input=139, output=144, total=283                                                                                     \nDEBUG * Time:                        3.3514s                                                                                                              \nDEBUG * Tokens per second:           42.9673 tokens/s                                                                                                     \nDEBUG * Time to first token:         0.9840s                                                                                                              \nDEBUG *************************************************************  METRICS  **************************************************************              \nDEBUG Getting function get_number                                                                                                                         \nDEBUG Running: get_number()                                                                                                                               \nDEBUG ================================================================ tool ================================================================              \nDEBUG Tool call Id: chatcmpl-tool-1077bda4db6941d1936130b9f9d57102\nDEBUG The number is 67.                                                                                                                                   \nDEBUG ***********************************************************  TOOL METRICS  ***********************************************************              \nDEBUG * Time:                        0.0022s                                                                                                              \nDEBUG ***********************************************************  TOOL METRICS  ***********************************************************              \nDEBUG messages in stream: [{'role': 'user', 'content': 'Give me a random number.'}, {'role': 'assistant', 'content': '<think>\\nOkay, the user is asking   \n      for a random number. Let me check the tools available. There\\'s a function called get_number with no parameters required. Since the user wants a    \n      random number, I should call that function. But wait, the function\\'s description just says \"Get the number.\" Does it generate a random one or      \n      return a fixed value? The parameters are empty, so maybe it\\'s designed to return a random number by default. I\\'ll proceed to call get_number      \n      without any arguments. I need to make sure the tool call is correctly formatted in JSON within the XML tags. Alright, that should do                \n      it.\\n</think>\\n\\n', 'tool_calls': [{'id': 'chatcmpl-tool-1077bda4db6941d1936130b9f9d57102', 'type': 'function', 'function': {'name': 'get_number',  \n      'arguments': ''}}]}, {'role': 'tool', 'content': 'The number is 67.', 'tool_call_id': 'chatcmpl-tool-1077bda4db6941d1936130b9f9d57102'}]            \nERROR    API status error from OpenAI API: Error code: 400 - {'object': 'error', 'message': 'Expecting value: line 1 column 1 (char 0)', 'type':\n         'BadRequestError', 'param': None, 'code': 400}\n▰▱▱▱▱▱▱ Thinking...\n┏━ Message ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                                                                                                        ┃\n┃ Give me a random number.                                                                                                                               ┃\n┃                                                                                                                                                        ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n┏━ Tool Calls ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                                                                                                        ┃\n┃ • get_number()                                                                                                                                         ┃\n┃                                                                                                                                                        ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n┏━ Response (3.4s) ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                                                                                                        ┃\n┃ <think>                                                                                                                                                ┃\n┃ Okay, the user is asking for a random number. Let me check the tools available. There's a function called get_number with no parameters required.      ┃\n┃ Since the user wants a random number, I should call that function. But wait, the function's description just says \"Get the number.\" Does it generate a ┃\n┃ random one or return a fixed value? The parameters are empty, so maybe it's designed to return a random number by default. I'll proceed to call        ┃\n┃ get_number without any arguments. I need to make sure the tool call is correctly formatted in JSON within the XML tags. Alright, that should do it.    ┃\n┃ </think>                                                                                                                                               ┃\n┃                                                                                                                                                        ┃\n┃ The number is 67.                                                                                                                                      ┃\n┃                                                                                                                                                        ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\nTraceback (most recent call last):\n  File \"D:\\Code\\agent\\agno_bug\\.venv\\Lib\\site-packages\\agno\\models\\openai\\chat.py\", line 455, in invoke_stream\n    yield from self.get_client().chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Code\\agent\\agno_bug\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 287, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Code\\agent\\agno_bug\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 925, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"D:\\Code\\agent\\agno_bug\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1239, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Code\\agent\\agno_bug\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1034, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'object': 'error', 'message': 'Expecting value: line 1 column 1 (char 0)', 'type': 'BadRequestError', 'param': None, 'code': 400}\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"d:\\Code\\agent\\agno_bug\\main.py\", line 24, in <module>\n    agent.print_response(\"Give me a random number.\", stream=True)\n  File \"D:\\Code\\agent\\agno_bug\\.venv\\Lib\\site-packages\\agno\\agent\\agent.py\", line 4545, in print_response\n    for resp in self.run(\n                ^^^^^^^^^\n  File \"D:\\Code\\agent\\agno_bug\\.venv\\Lib\\site-packages\\agno\\agent\\agent.py\", line 655, in _run\n    for model_response_chunk in self.model.response_stream(messages=run_messages.messages):\n                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Code\\agent\\agno_bug\\.venv\\Lib\\site-packages\\agno\\models\\base.py\", line 520, in response_stream\n    yield from self.process_response_stream(\n  File \"D:\\Code\\agent\\agno_bug\\.venv\\Lib\\site-packages\\agno\\models\\base.py\", line 492, in process_response_stream\n    for response_delta in self.invoke_stream(messages=messages):\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Code\\agent\\agno_bug\\.venv\\Lib\\site-packages\\agno\\models\\openai\\chat.py\", line 490, in invoke_stream\n    raise ModelProviderError(\nagno.exceptions.ModelProviderError: Unknown model error\n```\n\n## Screenshots or Logs (if applicable)\n\n![Image](https://github.com/user-attachments/assets/1967c253-d5a9-4622-84bd-2964203e86a8)\n\n## Environment\n- OS: Windows 11\n- Agno Version: v1.4.5\n- External Dependency Versions: openai-v1.78.0\n- Additional Environment Details: Python 3.12.8\n\n## Possible Solutions (optional)\n```py\n# add code at _format_messages in agno.model.opnai.chat.OpenAIChat\nif \"tool_calls\" in message_dict:\n            for tool in message_dict[\"tool_calls\"]:\n                if tool[\"type\"] == \"function\":\n                    if not tool[\"function\"][\"arguments\"]:\n                        tool[\"function\"][\"arguments\"] = '{}'\n```\n\n![Image](https://github.com/user-attachments/assets/e951b756-d80c-475b-858d-ca21e5e7d898)\n\n## Additional Context\nA similar [problem](https://github.com/pydantic/pydantic-ai/issues/1654) arises in pydantic-ai, and they think should fix in agent framework.\n",
      "state": "open",
      "author": "wusskk",
      "author_type": "User",
      "created_at": "2025-05-09T05:58:23Z",
      "updated_at": "2025-06-21T00:34:44Z",
      "closed_at": null,
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3134/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3134",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3134",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:21.818660",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @wusskk ! Looks like what is happening here is an incompatibility between the model `qwen3-32b` and the OpenAI spec for function calling. \n\nOpenAI expects the arguments for a tool call with no params to be `{}` whereas `qwen3-32b` returns `''` resulting in the error. Your suggestion works but ",
          "created_at": "2025-05-20T15:42:28Z"
        },
        {
          "author": "wusskk",
          "body": "Hi @ysolanky , I am using the model qwen3-32b, but it is an API provided by others. As far as I know, they use vllm for deployment, and I am not clear about the specific commands.\nNow I have switched to other API providers (siliconflow and Aliyun), using the qwen3 series models for testing, and foun",
          "created_at": "2025-05-21T03:12:53Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-06-21T00:34:43Z"
        }
      ]
    },
    {
      "issue_number": 3610,
      "title": "[Bug] ERROR    Reasoning error: 'NoneType' object has no attribute 'replace'",
      "body": "### Description\n\nAfter installing the arize-phoenix package getting below error \nReasoning error: 'NoneType' object has no attribute 'replace'                                                      \n\nReasoning is not working when enable observability with arize-phoenix\n\n### Steps to Reproduce\n\nInstall below packages \n\narize-phoenix\nopeninference-instrumentation-agno\nopentelemetry-sdk\nopentelemetry-exporter-otlp\n\nWhen I enable my agent with Reasoning=True\n\nIts not returning reasoning throwing below error \n\nReasoning error: 'NoneType' object has no attribute 'replace'                                                      \n\n\n\n### Agent Configuration (if applicable)\n\nTeam(\n        name=\"Sequential Scheduling Team\",\n        mode=\"coordinate\",\n        model=AzureOpenAI(id=os.environ.get(\"COMPLETION_DEPLOYMENT_NAME\")),\n        members=[case_agent, slot_agent, appointment_agent],\n        show_tool_calls=True,\n        instructions=SCHEDULING_AGENT_INSTRUCTIONS,\n        description=\"Sequential Scheduling Team responsible for scheduling appointments call the tools always with proper arguments without skipping any arguments\",\n        markdown=True,\n        reasoning=True,\n        debug_mode=True,\n        show_members_responses=True,\n        enable_agentic_context=True,\n        add_datetime_to_instructions=True,\n        success_criteria=\"The team has successfully processed the scheduling request sequentially, maintaining context and requirements throughout the process.\",\n    )\n\n### Expected Behavior\n\nReasoning should work with arize phoenix\n\n### Actual Behavior\n\nReasoning not working work with arize phoenix\n\n### Screenshots or Logs (if applicable)\n\n<img width=\"875\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/7fc6cd48-0245-4c3a-b9c7-42206b40ffad\" />\n\n### Environment\n\n```markdown\nMacOS\nImplemented with fast api\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "mahesh52",
      "author_type": "User",
      "created_at": "2025-06-20T19:39:12Z",
      "updated_at": "2025-06-20T19:39:12Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3610/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3610",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3610",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:22.055363",
      "comments": []
    },
    {
      "issue_number": 3607,
      "title": "[Bug] knowledge_filters not working in run/print_response",
      "body": "### Description\n\nFor this example: https://docs.agno.com/examples/concepts/knowledge/filters/pdf_url/filtering_on_load\nThe knowledge_filters is not working for `Option 2: Filters on the run/print_response`. It does not restrict the knowledge to the metadata specified in the filter.\n\n![Image](https://github.com/user-attachments/assets/5fb61b6a-7c2b-4194-8934-6efabfb19379)\n\n### Steps to Reproduce\n\nRun this example:  https://docs.agno.com/examples/concepts/knowledge/filters/pdf_url/filtering_on_load\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nThe filter should be working in run/print_response\n\n### Actual Behavior\n\nThe filter is not working in run/print_response\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nmacOS\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "tl6c",
      "author_type": "User",
      "created_at": "2025-06-20T13:11:07Z",
      "updated_at": "2025-06-20T15:19:36Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3607/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3607",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3607",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:22.055400",
      "comments": [
        {
          "author": "kausmeows",
          "body": "Hi @tl6c unable to replicate this, i ran the option 2 and it worked for me. Did you use the `load_document` or not?\n\n<img width=\"796\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/74900fb5-48e3-41f3-a1fc-b3521fe1f7e4\" />",
          "created_at": "2025-06-20T15:19:36Z"
        }
      ]
    },
    {
      "issue_number": 3606,
      "title": "[Bug] ImportError: cannot import name 'ToolExecution' from 'agno.models.response' (/usr/local/lib/python3.12/site-packages/agno/models/response.py)",
      "body": "### Description\n\nImportError: cannot import name 'ToolExecution' from 'agno.models.response' (/usr/local/lib/python3.12/site-packages/agno/models/response.py)\nTraceback:\nFile \"/app/ui/Home.py\", line 8, in <module>\n    from ui.utils import about_agno, footer\nFile \"/app/ui/utils.py\", line 12, in <module>\n    from agno.models.response import ToolExecution\n\n### Steps to Reproduce\n\nI followed the official setup instructions step by step from the documentation: https://docs.agno.com/workspaces/agent-app/local\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nNo error message\n\n### Actual Behavior\n\nAn error occurred after opening http://localhost:8501/\nImportError: cannot import name 'ToolExecution' from 'agno.models.response' (/usr/local/lib/python3.12/site-packages/agno/models/response.py)\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n# This file was autogenerated by uv via the following command:\n#    ./scripts/generate_requirements.sh\nagno==1.5.5\nagno-aws==0.0.1\nagno-docker==0.0.1\naiofiles==24.1.0\nalembic==1.15.2\naltair==5.5.0\nannotated-types==0.7.0\nanyio==4.9.0\nattrs==25.3.0\nbeautifulsoup4==4.13.4\nblinker==1.9.0\nboto3==1.38.15\nbotocore==1.38.15\ncachetools==5.5.2\ncertifi==2025.4.26\ncffi==1.17.1\ncharset-normalizer==3.4.2\nclick==8.2.0\ncurl-cffi==0.11.0\ndistro==1.9.0\ndnspython==2.7.0\ndocker==7.1.0\ndocstring-parser==0.16\nduckduckgo-search==8.0.1\nemail-validator==2.2.0\nexa-py==1.13.1\nfastapi==0.115.12\nfastapi-cli==0.0.7\nfeedparser==6.0.11\nfilelock==3.18.0\nfrozendict==2.4.6\ngitdb==4.0.12\ngitpython==3.1.44\nh11==0.16.0\nhttpcore==1.0.9\nhttptools==0.6.4\nhttpx==0.28.1\nidna==3.10\niniconfig==2.1.0\njinja2==3.1.6\njiter==0.9.0\njmespath==1.0.1\njoblib==1.5.1\njsonschema==4.23.0\njsonschema-specifications==2025.4.1\nlxml==5.4.0\nlxml-html-clean==0.4.2\nmako==1.3.10\nmarkdown-it-py==3.0.0\nmarkupsafe==3.0.2\nmdurl==0.1.2\nmultitasking==0.0.11\nnarwhals==1.39.0\nnest-asyncio==1.6.0\nnewspaper4k==0.9.3.1\nnltk==3.9.1\nnumpy==2.2.5\nopenai==1.78.1\npackaging==24.2\npandas==2.2.3\npeewee==3.18.1\npgvector==0.4.1\npillow==11.2.1\nplatformdirs==4.3.8\npluggy==1.5.0\nprimp==0.15.0\nprotobuf==6.30.2\npsycopg==3.2.9\npsycopg-binary==3.2.9\npyarrow==20.0.0\npycparser==2.22\npydantic==2.11.4\npydantic-core==2.33.2\npydantic-settings==2.9.1\npydeck==0.9.1\npygments==2.19.1\npypdf==5.5.0\npytest==8.3.5\npytest-mock==3.14.0\npython-dateutil==2.9.0.post0\npython-docx==1.1.2\npython-dotenv==1.1.0\npython-multipart==0.0.20\npytz==2025.2\npyyaml==6.0.2\nreferencing==0.36.2\nregex==2024.11.6\nrequests==2.32.3\nrequests-file==2.1.0\nrich==14.0.0\nrich-toolkit==0.14.6\nrpds-py==0.24.0\ns3transfer==0.12.0\nsgmllib3k==1.0.0\nshellingham==1.5.4\nsix==1.17.0\nsmmap==5.0.2\nsniffio==1.3.1\nsoupsieve==2.7\nsqlalchemy==2.0.40\nstarlette==0.46.2\nstreamlit==1.45.1\ntenacity==9.1.2\ntiktoken==0.9.0\ntldextract==5.3.0\ntoml==0.10.2\ntomli==2.2.1\ntornado==6.4.2\ntqdm==4.67.1\ntyper==0.15.3\ntyping-extensions==4.13.2\ntyping-inspection==0.4.0\ntzdata==2025.2\nurllib3==2.4.0\nuvicorn==0.34.2\nuvloop==0.21.0\nwatchfiles==1.0.5\nwebsockets==15.0.1\nyfinance==0.2.61\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "154192",
      "author_type": "User",
      "created_at": "2025-06-20T12:28:52Z",
      "updated_at": "2025-06-20T12:28:52Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3606/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3606",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3606",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:22.238828",
      "comments": []
    },
    {
      "issue_number": 3569,
      "title": "[Bug] ERROR Failed to create Container: agent-app-ui",
      "body": "### Description\n\nERROR    Failed to create Container: agent-app-ui\n\n### Steps to Reproduce\n\nPS C:\\Users\\Admin\\Desktop\\M&A\\M&A network\\agent-app> ag ws up dev:docker\nStarting workspace: agent-app\n\n--**-- Confirm resources to create:\n  -+-> Network: agent-app\n  -+-> Container: agent-app-db\n  -+-> Container: agent-app-ui\n  -+-> Container: agent-app-api\n\nNetwork: agent-app\nTotal 4 resources\n\nConfirm deploy [Y/n]: y\n\n-==+==- Network: agent-app\nNetwork: agent-app already exists\n\n-==+==- Container: agent-app-db\nStarting container: agent-app-db\nContainer Status: running\nContainer: agent-app-db created\n\n-==+==- Container: agent-app-ui\nStarting container: agent-app-ui\nContainer Status: exited\nERROR    Failed to create Container: agent-app-ui\n\n--**-- ResourceGroups deployed: 1/1\n\nERROR    Some resources failed to create, please check logs\nPS C:\\Users\\Admin\\Desktop\\M&A\\M&A network\\agent-app> docker logs agent-app-ui\nexec /app/scripts/entrypoint.sh: no such file or directory\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\ncreate Container: agent-app-ui\n\n### Actual Behavior\n\n Failed to create Container: agent-app-ui\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n# This file was autogenerated by uv via the following command:\n#    ./scripts/generate_requirements.sh\nagno==1.5.5\nagno-aws==0.0.1\nagno-docker==0.0.1\naiofiles==24.1.0\nalembic==1.15.2\naltair==5.5.0\nannotated-types==0.7.0\nanyio==4.9.0\nattrs==25.3.0\nbeautifulsoup4==4.13.4\nblinker==1.9.0\nboto3==1.38.15\nbotocore==1.38.15\ncachetools==5.5.2\ncertifi==2025.4.26\ncffi==1.17.1\ncharset-normalizer==3.4.2\nclick==8.2.0\ncurl-cffi==0.11.0\ndistro==1.9.0\ndnspython==2.7.0\ndocker==7.1.0\ndocstring-parser==0.16\nduckduckgo-search==8.0.1\nemail-validator==2.2.0\nexa-py==1.13.1\nfastapi==0.115.12\nfastapi-cli==0.0.7\nfeedparser==6.0.11\nfilelock==3.18.0\nfrozendict==2.4.6\ngitdb==4.0.12\ngitpython==3.1.44\nh11==0.16.0\nhttpcore==1.0.9\nhttptools==0.6.4\nhttpx==0.28.1\nidna==3.10\niniconfig==2.1.0\njinja2==3.1.6\njiter==0.9.0\njmespath==1.0.1\njoblib==1.5.1\njsonschema==4.23.0\njsonschema-specifications==2025.4.1\nlxml==5.4.0\nlxml-html-clean==0.4.2\nmako==1.3.10\nmarkdown-it-py==3.0.0\nmarkupsafe==3.0.2\nmdurl==0.1.2\nmultitasking==0.0.11\nnarwhals==1.39.0\nnest-asyncio==1.6.0\nnewspaper4k==0.9.3.1\nnltk==3.9.1\nnumpy==2.2.5\nopenai==1.78.1\npackaging==24.2\npandas==2.2.3\npeewee==3.18.1\npgvector==0.4.1\npillow==11.2.1\nplatformdirs==4.3.8\npluggy==1.5.0\nprimp==0.15.0\nprotobuf==6.30.2\npsycopg==3.2.9\npsycopg-binary==3.2.9\npyarrow==20.0.0\npycparser==2.22\npydantic==2.11.4\npydantic-core==2.33.2\npydantic-settings==2.9.1\npydeck==0.9.1\npygments==2.19.1\npypdf==5.5.0\npytest==8.3.5\npytest-mock==3.14.0\npython-dateutil==2.9.0.post0\npython-docx==1.1.2\npython-dotenv==1.1.0\npython-multipart==0.0.20\npytz==2025.2\npyyaml==6.0.2\nreferencing==0.36.2\nregex==2024.11.6\nrequests==2.32.3\nrequests-file==2.1.0\nrich==14.0.0\nrich-toolkit==0.14.6\nrpds-py==0.24.0\ns3transfer==0.12.0\nsgmllib3k==1.0.0\nshellingham==1.5.4\nsix==1.17.0\nsmmap==5.0.2\nsniffio==1.3.1\nsoupsieve==2.7\nsqlalchemy==2.0.40\nstarlette==0.46.2\nstreamlit==1.45.1\ntenacity==9.1.2\ntiktoken==0.9.0\ntldextract==5.3.0\ntoml==0.10.2\ntomli==2.2.1\ntornado==6.4.2\ntqdm==4.67.1\ntyper==0.15.3\ntyping-extensions==4.13.2\ntyping-inspection==0.4.0\ntzdata==2025.2\nurllib3==2.4.0\nuvicorn==0.34.2\nuvloop==0.21.0\nwatchfiles==1.0.5\nwebsockets==15.0.1\nyfinance==0.2.61\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "154192",
      "author_type": "User",
      "created_at": "2025-06-15T02:12:19Z",
      "updated_at": "2025-06-20T12:22:29Z",
      "closed_at": "2025-06-20T12:22:29Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3569/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3569",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3569",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:22.238851",
      "comments": [
        {
          "author": "isikepalaku",
          "body": "i think you not run agno app ui, instead agno demo app, and you should run it on linux or wsl if you using windows",
          "created_at": "2025-06-15T04:14:40Z"
        },
        {
          "author": "154192",
          "body": "> i think you not run agno app ui, instead agno demo app, and you should run it on linux or wsl if you using windows\n\nI ran the agno demo app following the official documentation, and I’m running it on Windows.\n\nHowever, I'm not sure what the issue is and how to resolve it.",
          "created_at": "2025-06-15T04:32:48Z"
        },
        {
          "author": "isikepalaku",
          "body": "run it on linux or use wsl ubuntu if you using windows, then install the workspace fisrt \"sh ./scripts/install.sh\" then activate environtment \"source .venv\\bin\\activate\" \n\nthen run \"ag ws up dev\" it should run the fast api app at localhost:8000\n\n\nyou must run it on linux os or wsl",
          "created_at": "2025-06-15T04:41:33Z"
        },
        {
          "author": "Ayush0054",
          "body": "hey @154192 these are some steps \n for windows select LF instead of CRLF in YOUR IDE (AT BOTTOM).\nand run this script\n```\n@echo off\nSETLOCAL\n\nSET \"CURR_DIR=%~dp0\"\nSET \"CURR_DIR=%CURR_DIR:~0,-1%\"\nSET \"REPO_ROOT=%CURR_DIR%..\"\nSET \"VENV_DIR=%REPO_ROOT%.venv\"\n\nCALL :print_heading \"Development setup...\"\n",
          "created_at": "2025-06-16T19:33:33Z"
        }
      ]
    },
    {
      "issue_number": 3594,
      "title": "[Bug] content: None raises errors in local LLM frameworks",
      "body": "### Description\n\n**Description**\n\nIn `agno/models/openai/chat.py` on line 307, the code currently sets `message_dict[\"content\"] = None` if the input `content` is `None`.\n\n```python\n# agno/models/openai/chat.py:307\nif message.content is None:\n    message_dict[\"content\"] = None\n```\n\nThis behavior causes errors when interacting with various local LLM frameworks (e.g., Vllm, Llama.cpp) which expect the `content` field to always be a string, even if it's empty.\n\nFurthermore, according to the official OpenAI API documentation for the chat completions endpoint, the `content` field within a message object is **required** and must be a string or an array of content parts. A `null` (or `None`) value is not permissible.\n\n**Reference:** [[OpenAI API Documentation - Chat](https://platform.openai.com/docs/api-reference/chat/create)]\n\n**Proposed Solution**\n\nTo align with the OpenAI API specification and improve compatibility with other frameworks, I suggest changing the behavior to set `message_dict[\"content\"]` to an empty string (`\"\"`) when the input `content` is `None`.\n\n**Suggested Change:**\n\n```python\n# agno/models/openai/chat.py:307\nif message.content is None:\n    # Change from None to an empty string for compatibility.\n    message_dict[\"content\"] = \"\"\n```\n\nThis small change would prevent errors and make the integration with different LLM backends much smoother.\n\nThank you for your consideration!\n\n### Steps to Reproduce\n\nwhen interacting with various local LLM frameworks\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\n```python\n# agno/models/openai/chat.py:307\nif message.content is None:\n    # Change from None to an empty string for compatibility.\n    message_dict[\"content\"] = \"\"\n```\n\n### Actual Behavior\n\n```python\n# agno/models/openai/chat.py:307\nif message.content is None:\n    message_dict[\"content\"] = None\n```\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nlocal LLM (Vllm, Sglang, llama.cpp)\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "garam-kim1",
      "author_type": "User",
      "created_at": "2025-06-19T01:39:58Z",
      "updated_at": "2025-06-20T09:17:32Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3594/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3594",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3594",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:22.469280",
      "comments": [
        {
          "author": "willemcdejongh",
          "body": "Hey @garam-kim1 \nThanks for raising the issue. We have made the updates and they will be included in the next release.",
          "created_at": "2025-06-20T09:17:32Z"
        }
      ]
    },
    {
      "issue_number": 3462,
      "title": "[Bug] qwen3 no think",
      "body": "### Description\n\nagno not have extra_body set  \"chat_template_kwargs\": {\"enable_thinking\": false}\n\n### Steps to Reproduce\n\n\"chat_template_kwargs\": {\"enable_thinking\": false}\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\n\"chat_template_kwargs\": {\"enable_thinking\": false}\n\n### Actual Behavior\n\n\"chat_template_kwargs\": {\"enable_thinking\": false}\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n\"chat_template_kwargs\": {\"enable_thinking\": false}\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "uid10086",
      "author_type": "User",
      "created_at": "2025-06-04T06:42:12Z",
      "updated_at": "2025-06-20T02:48:56Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3462/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3462",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3462",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:22.652669",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-403/bug-qwen3-no-think\">SUPPORT-403 [Bug] qwen3 no think</a></p>",
          "created_at": "2025-06-04T06:42:15Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @uid10086 do you want this functionality with Ollama? ",
          "created_at": "2025-06-05T19:03:33Z"
        },
        {
          "author": "uid10086",
          "body": "> 你好[@uid10086](https://github.com/uid10086)您想要 Ollama 的这个功能吗？\n\nvllm qwen3 no thinking，i already know use this。show you  request_params={\"extra_body\":{\"chat_template_kwargs\": {\"enable_thinking\": False}}}",
          "created_at": "2025-06-06T08:00:52Z"
        },
        {
          "author": "phanxuanphucnd",
          "body": "How to set no_think with qwen3 use from Ollama \n\nExample: model=Ollama(id=\"qwen3-4b-gguf:Q8_0\")\n\nHow to setup params to open mode nothink?\n\ni used the following:\n\n```\nmodel=Ollama(id=\"qwen3-4b-gguf:Q8_0\", request_params={\"extra_body\":{\"chat_template_kwargs\": {\"enable_thinking\": False}}}),\n```\n\nBUT E",
          "created_at": "2025-06-15T17:04:14Z"
        },
        {
          "author": "Mustafa-Esoofally",
          "body": "Hi @uid10086  do you want this functionality with Ollama?",
          "created_at": "2025-06-19T13:43:55Z"
        }
      ]
    },
    {
      "issue_number": 2931,
      "title": "[Bug] Repeated calls to add_memory when using Gemini with memory and message history",
      "body": "# Description\nWhen using an agent defined with Gemini, memory, message history, and other options, I get lots and lots of repeated memory additions (especially with longer input prompts). This causes the agent to take a very long time to respond (1-3 minutes), and it runs up the LLM costs due to an LLM query every time a memory is summarized to be added.\n\n## Steps to Reproduce\n\nBuild an agent with memory and message history, e.g., https://docs.agno.com/agents/memory.\n\n## Agent Configuration (if applicable)\n\n```python\nmodel = Gemini(\n    id=\"gemini-2.5-pro-preview-03-25\",\n    vertexai=True,\n    project_id=\"...\",\n    location=\"us-central1\",\n)\n\nstorage = PostgresAgentStorage(table_name=\"chat_history\", db_url=db_url)\n\nmemory = AgentMemory(\n    db=PgMemoryDb(table_name=\"agent_memory\", db_url=db_url),\n    create_user_memories=True,\n    create_session_summary=True,\n    manager=MemoryManager(model=model),\n    summarizer=MemorySummarizer(model=model),\n    classifier=MemoryClassifier(model=model),\n)\n\nagent = Agent(\n    add_context=True,\n    add_datetime_to_instructions=True,\n    add_history_to_messages=True,\n    debug_mode=True,\n    delay_between_retries=2,\n    exponential_backoff=True,\n    goal=goal,\n    instructions=instructions,\n    knowledge=knowledge_base,\n    markdown=True,\n    memory=memory,\n    model=model,\n    num_history_responses=20,\n    session_id=session_id,\n    storage=storage,\n    read_chat_history=True,\n    read_tool_call_history=True,\n    retries=30,\n    telemetry=False,\n    tools=tools,\n)\n```\n\nModel: \n\n## Expected Behavior\n\nI expect the agent to update memory one or a few times for each query.\n\n## Actual Behavior\n\nThe agent updated memories with 10 or 50 times with variants of the same \"message\" for the memory.\n\n## Screenshots or Logs (if applicable)\n\n```\nDEBUG **********************  TOOL METRICS  **********************\nDEBUG ======================== assistant =========================\nDEBUG Tool Calls:\n          Name: 'add_memory'\n          Arguments: 'memory: The user is asking about research'\nDEBUG ************************  METRICS  *************************\nDEBUG * Tokens:                      input=226886, output=38, total=227250\nDEBUG * Time:                        10.5332s\nDEBUG * Tokens per second:           3.6076 tokens/s\nDEBUG ************************  METRICS  *************************\nDEBUG Getting function add_memory\nDEBUG Running: add_memory(memory=...)\nDEBUG =========================== tool ===========================\nDEBUG Memory added successfully\nDEBUG **********************  TOOL METRICS  **********************\nDEBUG * Time:                        0.0079s\nDEBUG **********************  TOOL METRICS  **********************\nDEBUG ======================== assistant =========================\nDEBUG Tool Calls:\n          Name: 'add_memory'\n          Arguments: 'memory: The user is curious about research'\nDEBUG ************************  METRICS  *************************\nDEBUG * Tokens:                      input=226931, output=37, total=227234\nDEBUG * Time:                        9.4867s\nDEBUG * Tokens per second:           3.9002 tokens/s\nDEBUG ************************  METRICS  *************************\nDEBUG Getting function add_memory\nDEBUG Running: add_memory(memory=...)\nDEBUG =========================== tool ===========================\nDEBUG Memory added successfully\nDEBUG **********************  TOOL METRICS  **********************\nDEBUG * Time:                        0.0080s\nDEBUG **********************  TOOL METRICS  **********************\nDEBUG ======================== assistant =========================\nDEBUG Tool Calls:\n          Name: 'add_memory'\n          Arguments: 'memory: The user is wants to perform research'\nDEBUG ************************  METRICS  *************************\nDEBUG * Tokens:                      input=226975, output=37, total=227178\nDEBUG * Time:                        8.6251s\nDEBUG * Tokens per second:           4.2898 tokens/s\nDEBUG ************************  METRICS  *************************\nDEBUG Getting function add_memory\nDEBUG Running: add_memory(memory=...)\nDEBUG =========================== tool ===========================\nDEBUG Memory added successfully\nDEBUG **********************  TOOL METRICS  **********************\nDEBUG * Time:                        0.0078s\nDEBUG **********************  TOOL METRICS  **********************\nDEBUG ======================== assistant =========================\nDEBUG Tool Calls:\n          Name: 'add_memory'\n          Arguments: 'memory: The user is researching scientific facts'\nDEBUG ************************  METRICS  *************************\nDEBUG * Tokens:                      input=227019, output=37, total=227612\nDEBUG * Time:                        10.6457s\nDEBUG * Tokens per second:           3.4756 tokens/s\nDEBUG ************************  METRICS  *************************\nDEBUG Getting function add_memory\nDEBUG Running: add_memory(memory=...)\nDEBUG =========================== tool ===========================\nDEBUG Memory added successfully\n[...]\n[Repeats ~50 more times]\n```\n\n## Environment\n- OS: macOS\n- Agno Version: 1.3.5\n- Additional Environment Details: Python 3.12\n\n## Possible Solutions (optional)\n\nI'm not sure if I'm not supposed to be using those options (or other conflicting options) together, but I didn't see any warnings or notes in the docs that stated otherwise. So I'm trying to figure out if it's a bug or conflicting options or something else.",
      "state": "open",
      "author": "koverholt",
      "author_type": "User",
      "created_at": "2025-04-22T18:53:29Z",
      "updated_at": "2025-06-20T00:35:10Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2931/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2931",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2931",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:22.891629",
      "comments": [
        {
          "author": "pritipsingh",
          "body": "Hey @koverholt — one quick thing you can try is passing an additional_instructions ref (as mentioned here: [docs](https://docs.agno.com/reference/memory/memory#memory-manager)) to guide the model to be more selective about what it stores in memory. That might help reduce the frequency of memory addi",
          "created_at": "2025-04-24T18:30:03Z"
        },
        {
          "author": "koverholt",
          "body": "This is great, thanks for those links! I was so focused on all of the other agent settings that I was not even aware of those `additional_instructions` and agentic memory, that sounds awesome.\n\nI will try agentic memory first, then I'll need to work on a simpler reproducible case before I start twea",
          "created_at": "2025-04-26T01:50:41Z"
        },
        {
          "author": "koverholt",
          "body": "I've been using `agentic_memory` for the past few days. It does help with better cleanup after making lots and lots of repeated memory calls that are very similar, so thanks for that tip! But it doesn't fix the underlying \"why is Agno making so many calls to add_memory for a given conversation turn\"",
          "created_at": "2025-04-28T18:28:41Z"
        },
        {
          "author": "isikepalaku",
          "body": "I think i have same issue, in my case, my agent behaviour is running same task multiple time, more often when using vertex, i think there is some issue with gemini, i dont know is it model issue or from agno itself, when agent done doing task it not stop and do same task again\n\nI attach my agno moni",
          "created_at": "2025-04-29T22:11:18Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-05-30T00:34:15Z"
        }
      ]
    },
    {
      "issue_number": 2988,
      "title": "[Bug] Message token number increased quickly to very high levels ( 100k+), causing API errors",
      "body": "# Description\nI've run \nblog_post_generator.py\ncode example available at:\nhttps://docs.agno.com/workflows/introduction\nI found OpenAI API sent back error, referring to above 100k token message token numbers as the cause!\nI think something unwanted is added to the message ( log, debug info, ... ) in loops\nI used these 2 LLMs:\n```\ncheap_llm = OpenAIChat(\n    id=\"gpt-4o-mini\",\n    temperature=0.1,\n    max_tokens=8000\n)\nexpensive_llm = OpenAIChat(\n    id=\"o3-mini-2025-01-31\",\n    temperature=0.3,\n    max_tokens=16000\n)\n```\ncheap_llm is used by all agents except Writer.\n\n## Steps to Reproduce\nTry it with the example code referred to, with the LLMs I shared\n\n## Agent Configuration (if applicable)\nProvide relevant agent configuration.\n\n## Expected Behavior\nThe example code runs properly.\n\n## Actual Behavior\nWhen running the code, I got rate limited by DDGo Search Tool very soon.\nWhen trying to tweak the code and add retry logic, additional logging and error handling, doing it in Cursor with Gemini 2.5 Pro and investigating the issue by checking the logs, I found that huge message size, which cause unnecessary cost increases and may cause improper LLM responses.\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- Agno: 1.4.2\n- OS: Win 10\n- Python 3.12.7\n\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "open",
      "author": "vanetreg",
      "author_type": "User",
      "created_at": "2025-04-25T13:37:26Z",
      "updated_at": "2025-06-20T00:35:09Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2988/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2988",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2988",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:23.142509",
      "comments": [
        {
          "author": "mishramonalisha76",
          "body": "Hi @vanetreg,  DuckduckGo sometimes has this problem of rate limiting very quickly. You can use ExaTools instead. But apart from that I was able to run the workflow. Can you please share your tweaked code, so that i can replicate the issue ?",
          "created_at": "2025-04-26T09:51:00Z"
        },
        {
          "author": "vanetreg",
          "body": "Hi @mishramonalisha76 \n\ntoday I tested it again.\nFortunately DDG rate limits were not an issue.\nI found the code doesn't run with this LLM:\n```\nexpensive_llm = OpenAIChat(\n    id=\"o3-mini-2025-01-31\",\n    # temperature=0.3,\n    # max_tokens=16000\n)\n```\nwhen either temp or max_tokens are used.\n\nI did",
          "created_at": "2025-04-26T10:58:42Z"
        },
        {
          "author": "mishramonalisha76",
          "body": "Hi @vanetreg , thanks for testing it and finding warnings and errors . \nIt must be a model issue but  we will also keep testing it from our side too . \nMeanwhile you can try other workflow examples to see if you are facing the same issue.\n",
          "created_at": "2025-04-28T05:20:36Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-05-29T00:34:26Z"
        },
        {
          "author": "Mustafa-Esoofally",
          "body": "Hey @vanetreg ! Do you still continue to face this issue? I recommend updating to latest version of Agno and trying again",
          "created_at": "2025-06-19T13:39:58Z"
        }
      ]
    },
    {
      "issue_number": 3129,
      "title": "[Bug] Not add context to the system message",
      "body": "# Description\nI tried running your example about Agent Context, which fetches top Hacker News stories and provides them to the user. However, when I ran it, the placeholder {top_hackernews_stories} in the instruction did not get replaced with the context value\n\n## Steps to Reproduce\nRun example https://docs.agno.com/agents/context and check instructions in system_message \n",
      "state": "open",
      "author": "TranTien201",
      "author_type": "User",
      "created_at": "2025-05-09T02:48:41Z",
      "updated_at": "2025-06-20T00:35:08Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3129/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3129",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3129",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:23.451074",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @TranTien201 ! I ran the example [here](https://docs.agno.com/agents/context) and the system message did get populated as expected. Can you please try updating to the latest Agno version and then retrying?\n\n![Image](https://github.com/user-attachments/assets/56837996-9d35-4ca2-b989-d74a9cf4a7d",
          "created_at": "2025-05-19T18:34:32Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-06-19T00:35:20Z"
        },
        {
          "author": "Mustafa-Esoofally",
          "body": "Hey @TranTien201 ! Could you confirm that you still continue to face this issue? I recommend upgrading to the latest version before you test",
          "created_at": "2025-06-19T13:42:11Z"
        }
      ]
    },
    {
      "issue_number": 3183,
      "title": "[Bug] why arun back a coroutine？stream=true, arun must back a AsyncIterator.",
      "body": "### Description\n\n![Image](https://github.com/user-attachments/assets/dab70c64-fbb1-466e-856a-58efb1ec90f1)\n\n![Image](https://github.com/user-attachments/assets/c52e114a-6208-496a-ad99-580282eaf767)\n\n### Steps to Reproduce\n\n![Image](https://github.com/user-attachments/assets/034390bd-3e69-44f7-aaf4-3f1ea40175eb)\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nwhy arun back a coroutine？stream=true, arun must back a AsyncIterator. \n\n### Actual Behavior\n\nwhy arun back a coroutine？stream=true, arun must back a AsyncIterator. \n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nmac os\n```\n\n### Possible Solutions (optional)\n\nwhy arun back a coroutine？stream=true, arun must back a AsyncIterator. \n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "uid10086",
      "author_type": "User",
      "created_at": "2025-05-14T02:15:29Z",
      "updated_at": "2025-06-20T00:35:07Z",
      "closed_at": null,
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3183/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3183",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3183",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:23.687005",
      "comments": [
        {
          "author": "Hakstar",
          "body": "have same problem",
          "created_at": "2025-05-20T01:52:27Z"
        },
        {
          "author": "dirkbrnd",
          "body": "We are discussing internally! <br>In the mean time it should work fine to change to `await agent.arun(…)`",
          "created_at": "2025-05-20T15:06:02Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-06-20T00:35:06Z"
        }
      ]
    },
    {
      "issue_number": 3220,
      "title": "[Bug] \"Failed to detach context\" error when async generators are garbage collected with active OpenTelemetry spans in Agno",
      "body": "### Description\n\nWhen using Agno with OpenInference instrumentation in async generators, a \"Failed to detach context\" error occurs when the generator is garbage collected with active OpenTelemetry spans. This happens specifically when iteration over the generator is interrupted early (via break, return, or exception).\nThe error indicates that OpenTelemetry's context management has issues with context tokens created in one async context being detached in another during garbage collection. This is a common issue with OpenTelemetry's context management in async code, particularly when generators don't complete normally.\n\n\n### Steps to Reproduce\n\n1. Create an async generator function that uses Agno with OpenInference instrumentation\n2. Call the function and iterate with async for, but break or return early from the iteration\n3. Wait for garbage collection to occur (this may happen automatically)\n4. The error occurs during garbage collection when the suspended generator with active spans is destroyed\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nThe application should gracefully handle async generator cleanup even when iteration is interrupted before completion. No errors should be logged, and OpenTelemetry spans should be properly closed or safely abandoned.\n\n### Actual Behavior\n\nWhen the async generator with an active OpenTelemetry span is garbage collected before completion, the following error occurs:\n\n```\nFailed to detach context\nTraceback (most recent call last):\n  File \"/Users/saitharun/Documents/agi/.venv/lib/python3.12/site-packages/opentelemetry/trace/__init__.py\", line 587, in use_span\n    yield span\n  File \"/Users/saitharun/Documents/agi/.venv/lib/python3.12/site-packages/openinference/instrumentation/_tracers.py\", line 140, in start_as_current_span\n    yield cast(OpenInferenceSpan, current_span)\n  File \"/Users/saitharun/Documents/agi/.venv/lib/python3.12/site-packages/openinference/instrumentation/agno/_wrappers.py\", line 219, in arun\n    yield run_response\nGeneratorExit\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/saitharun/Documents/agi/.venv/lib/python3.12/site-packages/opentelemetry/context/__init__.py\", line 155, in detach\n    _RUNTIME_CONTEXT.detach(token)\n  File \"/Users/saitharun/Documents/agi/.venv/lib/python3.12/site-packages/opentelemetry/context/contextvars_context.py\", line 53, in detach\n    self._current_context.reset(token)\nValueError: <Token var=<ContextVar name='current_context' default={} at 0x105204a40> at 0x33bcd4240> was created in a different Context\n2025-05-16T10:22:08.697636Z [info     ] request_completed    \n```\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n- OS: M4 Air macOS Ventura (darwin 24.3.0)\n- Python Version: 3.12\n- Agno Version: 1.5.0\n- OpenInference Version: openinference-instrumentation-agno 0.1.3\n- OpenTelemetry SDK: 1.31.0\n- OpenTelemetry Exporter: opentelemetry-exporter-otlp-proto-http 1.31.0\n- Additional Dependencies: redis 5.2.1+, FastAPI, ARQ workers\n- Environment: Async application with FastAPI and ARQ workers processing async generator functions\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "saitharunsai",
      "author_type": "User",
      "created_at": "2025-05-16T10:33:46Z",
      "updated_at": "2025-06-20T00:35:05Z",
      "closed_at": null,
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3220/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3220",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3220",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:23.882114",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-179/bug-failed-to-detach-context-error-when-async-generators-are-garbage\">SUPPORT-179 [Bug] \"Failed to detach context\" error when async generators are garbage collected with active OpenTelemetry spans in Agno</a></p>",
          "created_at": "2025-05-16T10:33:49Z"
        },
        {
          "author": "willemcdejongh",
          "body": "Hi @saitharunsai \nThank you for raising and the detailed description. Mind sharing the exact code snippet you used when first seeing this error?",
          "created_at": "2025-05-20T14:12:14Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-06-20T00:35:05Z"
        }
      ]
    },
    {
      "issue_number": 3229,
      "title": "[Bug] Gemini model does not handle multiple text parts",
      "body": "### Description\n\nThe Gemini's [parse_provider_response](https://github.com/agno-agi/agno/blob/1c4b0f4206269f2172e46ef9ad4482955c18efb5/libs/agno/agno/models/google/gemini.py#L666) method does not handle multiple text parts. Now, I do not know why on earth the genapi/API returns multiple parts only containing \"text\" to begin with, but it does..\n\nExample of a response as seen from HTTP logs:\n\n```\n\"candidates\": [\n  {\n    \"content\": {\n      \"parts\": [\n        {\n          \"text\": \"Well here's one line\\n\"\n        },\n        {\n          \"text\": \"and another..\\n\"\n        },\n        {\n          \"text\": \"and it goes on.. :(\"\n        }\n      ]\n    }\n  }\n]     \n```\n\nThe current implementation goes through each part and assigns a part with \"text\" as the content, actually only assigning the last part as the message. As said I don't know why the response would be like this, but the current assumption of there being only one text part is clearly wrong.\n\n### Steps to Reproduce\n\nGet the model to generate a response like this and check the incoming data.\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nText parts should be concatenated and returned as the response's content.\n\n### Actual Behavior\n\nOnly the last part is reported as the response's content.\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nAnything capable of using the library\n```\n\n### Possible Solutions (optional)\n\nSee above.\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "nilnor",
      "author_type": "User",
      "created_at": "2025-05-17T19:47:05Z",
      "updated_at": "2025-06-20T00:35:04Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3229/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "Mustafa-Esoofally"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3229",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3229",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:24.129433",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-180/bug-gemini-model-does-not-handle-multiple-text-parts\">SUPPORT-180 [Bug] Gemini model does not handle multiple text parts</a></p>",
          "created_at": "2025-05-17T19:47:08Z"
        },
        {
          "author": "nilnor",
          "body": "Some additional info: This is with Gemini 2.5 pro (gemini-2.5-pro-preview-05-06). AI being what it is it now happens only irregularly.. Still, handling this case in the code would account for it.",
          "created_at": "2025-05-17T20:40:11Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-06-17T00:34:53Z"
        },
        {
          "author": "Mustafa-Esoofally",
          "body": "Hi @nilnor ! Could you confirm is your are still facing this issue? I recommend updating Agno to the latest version and testing",
          "created_at": "2025-06-19T15:09:32Z"
        }
      ]
    },
    {
      "issue_number": 3239,
      "title": "[Feature Request] Support Passing Dynamically-Generated Images into Multimodal Models (e.g. GPT-4o)",
      "body": "### Problem Description\n\n### Description\n\nI’ve built a set of custom tools that analyze stock data and generate charts, then return Markdown links to those images. What I’d like to do is feed those images directly into a multimodal model (e.g. GPT-4o), not just reference static, pre-uploaded files.\n\nRight now, Agno’s examples (such as [image\\_agent\\_local\\_file.py](https://github.com/agno-agi/agno/blob/main/cookbook/models/cohere/[image_agent_local_file.py](https://github.com/agno-agi/agno/blob/main/cookbook/models/cohere/image_agent_local_file.py))) only demonstrate chatting with a fixed set of images. I need a way to:\n\n1. Run my “plot” tool\n2. Fetch or capture the resulting image object\n3. Pass that image buffer into the model in the same turn\n\nIf this is already possible, pointing me to a minimal example or a cookbook recipe would be awesome—I’m writing a public tutorial + article on stock analysis with Agno, and want to cover this workflow.\n\n---\n\n### Reproduction\n\n1. **Tool definition**\n   My tools run Python code, save plots to a local path.\n\n2. **Agent call**\n\n   ```python\n   agent.run(\"Show me a 30-day moving average of TSLA\")\n   ```\n\n3. **Current output**\n\n   > “Here’s your chart: ```![MA chart](data/chart.png)”```\n\n4. **Limitation**\n   GPT-4o (or any multimodal endpoint) sees only the Markdown link, not the image bytes themselves.\n\n5. **Example environment**\n   Colab notebook:\n   [https://colab.research.google.com/drive/1GkcDJIOcvGXKEb5xe5rwpBzKPU0Xoa-g?usp=sharing](https://colab.research.google.com/drive/1GkcDJIOcvGXKEb5xe5rwpBzKPU0Xoa-g?usp=sharing)\n\n---\n\n### Expected Behavior\n\n* After generating the plot, the agent should attach the raw image (or its in-memory buffer) as an input to the multimodal model in the same API call.\n* The model can then “see” the chart and answer follow-up questions like “What was the sharpest drop?” or “Add a 7-day Bollinger Band overlay.”\n\n---\n\n### Actual Behavior\n\n* The agent only emits a Markdown link, which GPT-4o can’t fetch or display.\n* I have to manually download or re-upload the chart to show it to the model.\n\n---\n\n### Environment\n\n* **Agno version:** `main` Version: 1.5.1\n* **Notebook:** Colab (linked above)\n\n---\n\n### References\n\n* Related: #3238\n* Agno example: `cookbook/models/cohere/image_agent_local_file.py`\n\n---\n\n### Request\n\n1. Is there an existing Agno feature or recipe to stream a dynamically-generated image buffer into `agent.run()`?\n2. If not, what would be the best way to extend Agno’s tool architecture to support it?\n\nThanks in advance! I’ll incorporate any pointers into my public tutorial.\n\n### Proposed Solution\n\nYou can add Images instead of just text in a tool:\n \nreturn {\n  image: 'link to image or local file'\n}\n\n\n### Alternatives Considered\n\nI've thought about using another model to turn that chart into text first, but that's not ideal\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [x] No, I’m just sharing the idea.",
      "state": "open",
      "author": "mrmps",
      "author_type": "User",
      "created_at": "2025-05-19T09:25:19Z",
      "updated_at": "2025-06-20T00:35:03Z",
      "closed_at": null,
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3239/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3239",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3239",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:24.346540",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-206/feature-request-support-passing-dynamically-generated-images-into\">SUPPORT-206 [Feature Request] Support Passing Dynamically-Generated Images into Multimodal Models (e.g. GPT-4o)</a></p>",
          "created_at": "2025-05-19T09:25:23Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-06-19T00:35:16Z"
        },
        {
          "author": "Mustafa-Esoofally",
          "body": "Hey @mrmps ! You can use OpenAI / Gemini image generator tools for creating plots. When a plot is generated via tools the agent will store it in context automatically and use it.\n\nHere's how to get started: [OpenAI toolkit](https://docs.agno.com/tools/toolkits/models/openai#openai).\n\nIf you'd like t",
          "created_at": "2025-06-19T14:33:01Z"
        }
      ]
    },
    {
      "issue_number": 3527,
      "title": "[Bug] Complex Issue: 'ImportError: ToolExecution' initially, then 'no such file or directory' for entrypoint.sh, expecting return to ImportError",
      "body": "### Description\n\nThis report details a complex and persistent issue encountered while deploying an Agno workspace. The initial problem was a `ImportError: cannot import name 'ToolExecution' from 'agno.models.response'`. During troubleshooting, a new error emerged: `exec /app/scripts/entrypoint.sh: no such file or directory`. While the `entrypoint.sh` error has been diagnosed as a line ending (`CRLF` vs `LF`) issue, fixing it is expected to lead back to the original `ImportError` as the core `agno` package version problem remains unaddressed by standard means.\n\n\n### Steps to Reproduce\n\nThe problem manifests in a chronological sequence of errors:\n\n1.  **Initial Setup & First Error:**\n    * Create a new Agno workspace (e.g., using `ag ws create`).\n    * Modify `requirements.txt` to include `agno==1.5.10`.\n    * Attempt to start the workspace using: `ag ws up -e dev -i docker -f`.\n    * **Result:** The `agent-app-ui` container fails to start, displaying logs with `ImportError: cannot import name 'ToolExecution'`.\n\n2.  **Emergence of Second Error (after initial troubleshooting attempts):**\n    * After multiple attempts to fix the `ImportError` (including Docker cleanups and `ag ws up -f`), the `ag ws up` command output shifts to show `Container Status: exited` for `agent-app-ui`.\n    * Upon checking `docker logs agent-app-ui`, the error is now `exec /app/scripts/entrypoint.sh: no such file or directory`.\n\n3.  **Fixing Second Error (and anticipating return to first error):**\n    * Modify `scripts/entrypoint.sh` on the host to convert line endings from `CRLF` to `LF`.\n    * Perform a targeted Docker cleanup (`docker stop agent-app-ui`, `docker rm -f agent-app-ui`).\n    * Execute `ag ws up -e dev -i docker -f` again.\n    * **Expected Result:** The `entrypoint.sh` error should be resolved, allowing the container to proceed further, at which point the original `ImportError: cannot import name 'ToolExecution'` is anticipated to reappear, as the underlying `agno` version issue has not been solved by direct means.\n\n\n### Agent Configuration (if applicable)\n\nThis issue occurs with a newly created Agno workspace, using the default `Dockerfile` (with minor modifications for aggressive `agno` installation) and `requirements.txt` specifying `agno==1.5.10`.\n\n## Agent Configuration\nThis issue occurs with a newly created Agno workspace, using the default `Dockerfile` (with minor modifications for aggressive `agno` installation) and `requirements.txt` specifying `agno==1.5.5`.\n\n**`requirements.txt` content:**\n```\n# This file was autogenerated by uv via the following command:\n#    ./scripts/generate_requirements.sh\nagno==1.5.5\nagno-aws==0.0.1\nagno-docker==0.0.1\naiofiles==24.1.0\nalembic==1.15.2\naltair==5.5.0\nannotated-types==0.7.0\nanyio==4.9.0\nattrs==25.3.0\nbeautifulsoup4==4.13.4\nblinker==1.9.0\nboto3==1.38.15\nbotocore==1.38.15\ncachetools==5.5.2\ncertifi==2025.4.26\ncffi==1.17.1\ncharset-normalizer==3.4.2\nclick==8.2.0\ncurl-cffi==0.11.0\ndistro==1.9.0\ndnspython==2.7.0\ndocker==7.1.0\ndocstring-parser==0.16\nduckduckgo-search==8.0.1\nemail-validator==2.2.0\nexa-py==1.13.1\nfastapi==0.115.12\nfastapi-cli==0.0.7\nfeedparser==6.0.11\nfilelock==3.18.0\nfrozendict==2.4.6\ngitdb==4.0.12\ngitpython==3.1.44\nh11==0.16.0\nhttpcore==1.0.9\nhttptools==0.6.4\nhttpx==0.28.1\nidna==3.10\niniconfig==2.1.0\njinja2==3.1.6\njiter==0.9.0\njmespath==1.0.1\njoblib==1.5.1\njsonschema==4.23.0\njsonschema-specifications==2025.4.1\nlxml==5.4.0\nlxml-html-clean==0.4.2\nmako==1.3.10\nmarkdown-it-py==3.0.0\nmarkupsafe==3.0.2\nmdurl==0.1.2\nmultitasking==0.0.11\nnarwhals==1.39.0\nnest-asyncio==1.6.0\nnewspaper4k==0.9.3.1\nnltk==3.9.1\nnumpy==2.2.5\nopenai==1.78.1\npackaging==24.2\npandas==2.2.3\npeewee==3.18.1\npgvector==0.4.1\npillow==11.2.1\nplatformdirs==4.3.8\npluggy==1.5.0\nprimp==0.15.0\nprotobuf==6.30.2\npsycopg==3.2.9\npsycopg-binary==3.2.9\npyarrow==20.0.0\npycparser==2.22\npydantic==2.11.4\npydantic-core==2.33.2\npydantic-settings==2.9.1\npydeck==0.9.1\npygments==2.19.1\npypdf==5.5.0\npytest==8.3.5\npytest-mock==3.14.0\npython-dateutil==2.9.0.post0\npython-docx==1.1.2\npython-dotenv==1.1.0\npython-multipart==0.0.20\npytz==2025.2\npyyaml==6.0.2\nreferencing==0.36.2\nregex==2024.11.6\nrequests==2.32.3\nrequests-file==2.1.0\nrich==14.0.0\nrich-toolkit==0.14.6\nrpds-py==0.24.0\ns3transfer==0.12.0\nsgmllib3k==1.0.0\nshellingham==1.5.4\nsix==1.17.0\nsmmap==5.0.2\nsniffio==1.3.1\nsoupsieve==2.7\nsqlalchemy==2.0.40\nstarlette==0.46.2\nstreamlit==1.45.1\ntenacity==9.1.2\ntiktoken==0.9.0\ntldextract==5.3.0\ntoml==0.10.2\ntomli==2.2.1\ntornado==6.4.2\ntqdm==4.67.1\ntyper==0.15.3\ntyping-extensions==4.13.2\ntyping-inspection==0.4.0\ntzdata==2025.2\nurllib3==2.4.0\nuvicorn==0.34.2\nuvloop==0.21.0\nwatchfiles==1.0.5\nwebsockets==15.0.1\nyfinance==0.2.61\n\n```\n\n**`Dockerfile` content (including aggressive `agno` uninstall/install attempt):**\n\n```dockerfile\nFROM agnohq/python:3.12\n\nARG USER=app\nARG APP_DIR=/app\nENV APP_DIR=${APP_DIR}\n\n# Create user and home directory\nRUN groupadd -g 61000 ${USER} \\\n  && useradd -g 61000 -u 61000 -ms /bin/bash -d ${APP_DIR} ${USER}\n\nWORKDIR ${APP_DIR}\n\n# Copy requirements.txt\nCOPY requirements.txt ./\n\n# Force uninstall agno before syncing to ensure a fresh install\nRUN uv pip uninstall agno || true # '|| true' ensures build doesn't fail if agno isn't found\n\n# Install requirements\nRUN uv pip sync requirements.txt --system --cache-dir /tmp/uv_cache\n\n# Copy project files\nCOPY . .\n\n# Ensure entrypoint.sh is executable\nRUN chmod +x ${APP_DIR}/scripts/entrypoint.sh\n\n# Set permissions for the /app directory\nRUN chown -R <span class=\"math-inline\">\\{USER\\}\\:</span>{USER} ${APP_DIR}\n\n# Switch to non-root user\nUSER ${USER}\n\nENTRYPOINT [\"/app/scripts/entrypoint.sh\"]\nCMD [\"chill\"]\n\n### Expected Behavior\n\nExpected Behavior\n1-The agent-app-ui container should start without an exec /app/scripts/entrypoint.sh error (after fixing line endings).\n2- The agno library within the container (agno/models/response.py) should match the version specified in requirements.txt (1.5.10), which includes the ToolExecution class, allowing the application to run correctly without ImportError.\n\n### Actual Behavior\n\nThe problem is observed in stages:\n\nStage 1: Initial ImportError: ToolExecution\nWhen first attempting to run the workspace, the agent-app-ui container would fail to start with the following traceback in its logs:\n\n```\nImportError: cannot import name 'ToolExecution' from 'agno.models.response' (/usr/local/lib/python3.12/site-packages/agno/models/response.py)\n\nTraceback:\nFile \"/app/ui/Home.py\", line 9, in <module>\n    from ui.utils import about_agno, footer\nFile \"/app/ui/utils.py\", line 13, in <module>\n    from agno.models.response import ToolExecution\n```\n\nContent of /usr/local/lib/python3.12/site-packages/agno/models/response.py inside the Docker container (during Stage 1/expected after Stage 2 fix):\n\n```\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nfrom time import time\nfrom typing import Any, Dict, List, Optional\n\nfrom agno.media import AudioResponse\nfrom agno.models.message import Citations\n\n\nclass ModelResponseEvent(str, Enum):\n    \"\"\"Events that can be sent by the model provider\"\"\"\n\n    tool_call_started = \"ToolCallStarted\"\n    tool_call_completed = \"ToolCallCompleted\"\n    assistant_response = \"AssistantResponse\"\n\n\n@dataclass\nclass ModelResponse:\n    \"\"\"Response from the model provider\"\"\"\n\n    role: Optional[str] = None\n\n    content: Optional[str] = None\n    parsed: Optional[Any] = None\n    audio: Optional[AudioResponse] = None\n    tool_calls: List[Dict[str, Any]] = field(default_factory=list)\n    event: str = ModelResponseEvent.assistant_response.value\n\n    provider_data: Optional[Dict[str, Any]] = None\n\n    thinking: Optional[str] = None\n    redacted_thinking: Optional[str] = None\n    reasoning_content: Optional[str] = None\n\n    citations: Optional[Citations] = None\n\n    response_usage: Optional[Any] = None\n\n    created_at: int = int(time())\n\n    extra: Optional[Dict[str, Any]] = None\n\n\nclass FileType(str, Enum):\n    MP4 = \"mp4\"\n    GIF = \"gif\"\n    MP3 = \"mp3\"](url)\n```\n\n(Note: ToolExecution class is missing from this content, confirming an outdated agno version despite requirements.txt.)\n\nStage 2: exec /app/scripts/entrypoint.sh: no such file or directory\nAfter repeated ag ws up -f attempts and Docker cleanups, the ag ws up command started reporting:\n\n```\nContainer Status: exited\nERROR    Failed to create Container: agent-app-ui\n--**-- ResourceGroups deployed: 1/1\nERROR    Some resources failed to create, please check logs\n```\n\nChecking docker logs agent-app-ui revealed the new error:\n`exec /app/scripts/entrypoint.sh: no such file or directory\n`This error indicates a problem with the execution of the entrypoint script itself, identified as likely due to CRLF line endings from the Windows host environment being interpreted incorrectly in the Linux container.\n\n\n\n### Screenshots or Logs (if applicable)\n\nLogs are embedded directly in the \"Actual Behavior\" section for clarity.\n\n### Environment\n\n```markdown\nHost Operating System: Windows [Your Windows version, e.g., Windows 11 Home]\nDocker Desktop Version: [Your Docker Desktop version, e.g., 4.29.0]\nAgno CLI Version: [Run ag --version in your terminal and paste the result here]\nCurrent Date & Time (for context): Tuesday, June 10, 2025 at 10:55:09 AM -03\n```\n\n### Possible Solutions (optional)\n\nExtensive troubleshooting has been performed, involving various Docker and Agno CLI commands, suggesting this may be an internal issue with the Agno CLI, its Docker base images, or uv's package resolution within the Agno build process that prevents the correct agno version from being used.\n\nThe entrypoint.sh issue highlights a sensitivity to line endings that should potentially be handled more robustly by the build process or documented prominently.\n\n### Additional Context\n\nProblem Persistence: Both errors (Python ImportError and shell exec error) have shown extreme persistence across multiple attempts to clean Docker caches (containers, images, networks, volumes) and force rebuilds using ag ws up -f.\ndocker exec verification: Direct inspection of the agno library within the container (cat /usr/local/lib/python3.12/site-packages/agno/models/response.py) consistently confirms the presence of an outdated response.py file lacking ToolExecution.\nDockerfile modifications: Attempts were made to explicitly uv pip uninstall agno before uv pip sync within the Dockerfile to force a fresh install, but this hasn't yet resolved the core ImportError.\n--build-arg attempt: An attempt was made to add a CACHE_BUST ARG to the Dockerfile and pass it via --build-arg with ag ws up, but the ag CLI does not support the --build-arg option.\nHost OS vs. Container Environment: It's understood that Docker containers are isolated. The issue is with the agno version within the container's environment.\nPC Restart: A full PC restart was performed to clear any potential lingering Docker daemon states, but the problem still reoccurred.",
      "state": "open",
      "author": "CENFARG",
      "author_type": "User",
      "created_at": "2025-06-10T14:02:35Z",
      "updated_at": "2025-06-19T20:31:28Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3527/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3527",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3527",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:24.558967",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-460/bug-complex-issue-importerror-toolexecution-initially-then-no-such\">SUPPORT-460 [Bug] Complex Issue: 'ImportError: ToolExecution' initially, then 'no such file or directory' for entrypoint.sh, expecting return to ImportError</a></p>",
          "created_at": "2025-06-10T14:02:39Z"
        },
        {
          "author": "CENFARG",
          "body": "Adicionaly y try to  read  response.py \n`cat /usr/local/lib/python3.12/site-packages/agno/models/response.py\n`an result in:\n\n```\nWorkspace-agno\\Prueba_001> docker exec -it agent-app-ui bash\napp@d30f7830d0fd:~$ cat /usr/local/lib/python3.12/site-packages/agno/models/response.py\nfrom dataclasses impor",
          "created_at": "2025-06-10T14:09:38Z"
        },
        {
          "author": "apat183",
          "body": "Any solutions to this problem? Fresh install my end also confirms issue, without even making any changes. ",
          "created_at": "2025-06-12T07:15:16Z"
        },
        {
          "author": "glarione",
          "body": "yes, just set to build from local and set repo to \"local\", then it will build from source. The problem is an outdated image in dockerhub.\nAlso you can set the latest version of agno in pyproject.toml.",
          "created_at": "2025-06-15T23:58:49Z"
        }
      ]
    },
    {
      "issue_number": 3518,
      "title": "[Bug] PostgreSQL Version Comparison Bug Report",
      "body": "### Description\n\nAgno's PgVector implementation fails during table existence checks with a type comparison error when connecting to PostgreSQL databases.\n\n**Root Cause Hypothesis**\nThe bug appears to be in Agno's PostgreSQL version parsing logic where:\n1. PostgreSQL server returns version as a string (e.g., \"14.9\")\n2. Agno's code attempts to compare this string with an integer\n3. Python raises TypeError: '>=' not supported between instances of 'int' and 'str'\n\n### Steps to Reproduce\n\n ## Reproduction Steps\n1. Create a PgVector instance with a Supabase PostgreSQL connection\n2. Initialize a TextKnowledgeBase with the PgVector\n3. Call `knowledge_base.load()` or let the startup process initialize\n4. Error occurs during table existence check    \n\n```\nlocal_kb = TextKnowledgeBase(\n    path=\"caregiver_kb\",\n    vector_db=PgVector(\n        table_name=\"caregiver_text_documents\",\n        db_url=os.getenv(\"DATABASE_URL\"),\n        embedder=AzureOpenAIEmbedder(\n            id=os.getenv(\"OPENAI_EMBEDDING_DEPLOYMENT_NAME\"),\n            api_key=os.getenv(\"OPENAI_API_KEY\"),\n            azure_endpoint=os.getenv(\"OPENAI_ENDPOINT\"),\n            api_version=os.getenv(\"OPENAI_EMBEDDING_API_VERSION\"),\n        ),\n    ),\n)\n```\n\n# Error occurs during this call:\nlocal_kb.load()\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\n- PgVector.table_exists() should correctly parse the PostgreSQL server version, perform the comparison without type errors, and either find the table or create it.\n\n- TextKnowledgeBase.load() should complete without exceptions, leaving the caregiver_text_documents table ready for inserts and retrievals.\n\n- The application should start with full vector-storage functionality enabled, allowing subsequent upsert() and similarity-search calls to work.\n\n### Actual Behavior\n\n- During PgVector.table_exists() the code receives a version string (e.g., \"14.9\") from the server, then compares it to an integer constant (>=), triggering\n` TypeError: '>=' not supported between instances of 'int' and 'str'`\n\n- The check aborts; Agno logs Error checking if table exists …, retries, and ultimately leaves the knowledge-base uninitialized.\n\n- Any downstream attempt to load or query the KB either raises the same error loop or proceeds with local_kb is None, disabling all vector operations.\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nEnvironment                                                                          Agno Version: 1.5.9 (and persists in 1.5.10+)                                     PostgreSQL Driver: psycopg[binary]==3.2.9                                         Database: Supabase PostgreSQL (pooler connection)                                 Python: 3.12                                                                      OS: macOS\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "amadad",
      "author_type": "User",
      "created_at": "2025-06-09T18:44:05Z",
      "updated_at": "2025-06-19T20:05:59Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3518/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3518",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3518",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:24.745839",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-457/bug-postgresql-version-comparison-bug-report\">SUPPORT-457 [Bug] PostgreSQL Version Comparison Bug Report</a></p>",
          "created_at": "2025-06-09T18:44:08Z"
        },
        {
          "author": "ysolanky",
          "body": "Hi @amadad ! The `table_exists` function required `schema` which is a string, not `schema_version` which is an int and is used as an internal parameter - not in the `table_exists` fn. Can you please share the error that you faced? I believe the root cause may be different \n\n```python\n    def table_e",
          "created_at": "2025-06-10T04:36:56Z"
        },
        {
          "author": "Mustafa-Esoofally",
          "body": "Hey @amadad ! Could you share the exact error that you faced?",
          "created_at": "2025-06-19T20:05:59Z"
        }
      ]
    },
    {
      "issue_number": 3534,
      "title": "[Bug] Agno 1.6.0: Critical regressions in team routing - inconsistent IDs, duplicate streams, breaking changes",
      "body": "### Description\n\nAfter upgrading to Agno 1.6.0, team routing produces inconsistent `run_id`/`session_id` across events and duplicates content streaming.\n\n\n### Steps to Reproduce\n\n1. Create a Team with route mode and multiple agents\n2. Send a message that triggers `forward_task_to_member`\n3. Monitor the event stream\n4. Observe ID inconsistency and content duplication\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\n- All events in the same conversation should have the same `run_id` and `session_id`\n- Content should be streamed once, not duplicated\n- Tool names should remain consistent (`aforward_task_to_member`)\n\n### Actual Behavior\n\n- `TeamRunResponseContent` and `RunResponseContent` have different IDs:\n  ```\n  TeamRunResponseContent: run_id='c9193db4-951b-485b-84a9-89759320eaa1'\n  RunResponseContent: run_id='b100393e-978f-456c-968b-32c200a1f3bc'\n  ```\n- Same content is duplicated across both event types\n- Tool name changed from `aforward_task_to_member` to `forward_task_to_member`\n\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n- **Agno version**: 1.6.0\n- **Python version**: 3.13\n- **OS**: macOS\n- **Team mode**: route\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n**Full log excerpt:**\nchunk: ToolCallStartedEvent(..., tool_name='forward_task_to_member', ...)\nchunk: RunResponseContentEvent(..., event='TeamRunResponseContent', run_id='c9193db4-951b-485b-84a9-89759320eaa1', content='Hello', ...)\nchunk: RunResponseContentEvent(..., event='RunResponseContent', run_id='b100393e-978f-456c-968b-32c200a1f3bc', content='Hello', ...)",
      "state": "closed",
      "author": "zhuayi",
      "author_type": "User",
      "created_at": "2025-06-11T03:29:18Z",
      "updated_at": "2025-06-19T15:40:41Z",
      "closed_at": "2025-06-13T12:52:43Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 20,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3534/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3534",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3534",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:24.978894",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-461/bug-agno-160-critical-regressions-in-team-routing-inconsistent-ids\">SUPPORT-461 [Bug] Agno 1.6.0: Critical regressions in team routing - inconsistent IDs, duplicate streams, breaking changes</a></p>",
          "created_at": "2025-06-11T03:32:21Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Thanks for raising. I'll deal with it immediately.\n",
          "created_at": "2025-06-11T06:13:57Z"
        },
        {
          "author": "dirkbrnd",
          "body": "On the run and session ID, the members have different runs and sessions, but have the same team_session_id. We'll look into what is the best solution here.\n\nI'll include team session ID on the events of members. But also add a flag allowing member events not to be yielded if you so choose",
          "created_at": "2025-06-11T06:20:03Z"
        },
        {
          "author": "zhuayi",
          "body": "Thank you for the clarification on the team_session_id approach! That makes perfect sense for tracking the overall team context.\n\nRegarding the member events and output control, I'd like to share my thoughts on the multi-agent architecture design:\n\n## Core Principle: Exclusive Output Responsibility\n",
          "created_at": "2025-06-11T07:25:24Z"
        },
        {
          "author": "dirkbrnd",
          "body": "1. **Clear task delegation** -> Agreed. This is how we model it today.\n2. **Avoid Information Redundancy** -> So they don't output responses at the same time, but rather we stream the events as they happen. But I can see how some use-cases won't work with this, so I am adding a field to disable this",
          "created_at": "2025-06-11T13:17:05Z"
        }
      ]
    },
    {
      "issue_number": 2907,
      "title": "[Bug] Pydantic Missing required argument in ReasoningTools.analyze",
      "body": "# Description\n```\nDEBUG 2 validation errors for ReasoningTools.analyze                                                                            \n      title                                                                                                                     \n        Missing required argument [type=missing_argument, input_value=ArgsKwargs((), {'agent': ...a detailed itinerary.'}),     \n      input_type=ArgsKwargs]                                                                                                    \n          For further information visit https://errors.pydantic.dev/2.11/v/missing_argument                                     \n      result                                                                                                                    \n        Missing required argument [type=missing_argument, input_value=ArgsKwargs((), {'agent': ...a detailed itinerary.'}),     \n      input_type=ArgsKwargs]                                                                                                    \n          For further information visit https://errors.pydantic.dev/2.11/v/missing_argument\n```\n\nIt seems like I am getting Pydantic validation error when the model (Gemini-2.0-Flash-001) calls the \"analyze\" tool in ReasoningTools. I can see that in system prompt, the ReasoningTool instruction is attached to let model understand how to use reasoning tool, but seems like it is not working as it is. Would this error from analyze tool affect the model behaviour (performance) since analyze tool returns error instead of the actual analysis of previous thinking step?\n\nMake title and result optional will easily solve the error but not sure those are necessary for this analyze tool.\n\n\n## Steps to Reproduce\nList the steps needed to encounter this bug or issue.\n\nAdd ReasoningTools() in tools\n```\ntools=[\n  ReasoningTools(add_instructions=True),\n  ...\n],\n```\n\n## Agent Configuration (if applicable)\nProvide relevant agent configuration.\nModel: Gemini-2.0-Flash-001\n\n## Expected Behavior\nWhat did you expect to happen?\nAnalysis of previous thinking step.\n\n## Actual Behavior\nWhat actually happened instead?\nPydantic Error.\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n<img width=\"701\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/f995042b-f701-430a-99f3-5b0b26fac343\" />\n\n## Environment\nWSL Ubuntu with Python 3.10.12, agno version 1.3.1\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "hanjihun2000",
      "author_type": "User",
      "created_at": "2025-04-21T07:22:21Z",
      "updated_at": "2025-06-19T15:23:56Z",
      "closed_at": "2025-06-19T15:23:56Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2907/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2907",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2907",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:25.207385",
      "comments": [
        {
          "author": "manuhortet",
          "body": "Hey @hanjihun2000 \n\nI'm struggling to recreate this. Some examples with ReasoningTools and Gemini work fine on my side. If you can provide more information about how you are setting up and calling your agent I'd be happy to take a deeper look!",
          "created_at": "2025-04-30T14:14:37Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-05-31T00:33:33Z"
        },
        {
          "author": "Mustafa-Esoofally",
          "body": "Hey @hanjihun2000 ! Could you confirm if this is still an issue?",
          "created_at": "2025-06-19T13:37:08Z"
        },
        {
          "author": "hanjihun2000",
          "body": "Hi @Mustafa-Esoofally, thanks for the reminder. I tried to run again and it seemed to be fixed. I think it is okay to close this issue and I will keep trying Agno framework and raise issue if anything found.",
          "created_at": "2025-06-19T15:13:03Z"
        },
        {
          "author": "Mustafa-Esoofally",
          "body": "Hey @hanjihun2000 ! Great to hear that. Pretty excited to see what you build!!",
          "created_at": "2025-06-19T15:23:56Z"
        }
      ]
    },
    {
      "issue_number": 3132,
      "title": "[Bug] agno.exceptions.ModelProviderError: {\"error\":{\"message\":\"Not Found\"}}",
      "body": "# Description\n\nI don't know what went wrong\n\n## Agent Configuration (if applicable)\n```\nfrom os import getenv\nfrom agno.agent import Agent, RunResponse\nfrom agno.models.openai.like import OpenAILike\nfrom agno.models.groq import Groq\n\nagent = Agent(\n    model=Groq(\n        id=\"llama-3.1-8b-instant\",\n        base_url='https://api.groq.com/openai/v1/chat/completions',\n        api_key='***',\n    )\nagent.print_response(\"Share a 2 sentence horror story.\")\n)\n```\n\n## Expected Behavior\nWhat did you expect to happen?\n\n## Actual Behavior\nERROR    Error calling Groq API: Error code: 404 - {'error': {'message': 'Not Found'}}                                                                                          \nWARNING  Attempt 1/1 failed: {\"error\":{\"message\":\"Not Found\"}}                                                                                                                  \nERROR    Failed after 1 attempts. Last error using Groq(llama-3.1-8b-instant)                                                                                                   \n▰▱▱▱▱▱▱ Thinking...\n┏━ Message ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                                                                                                                              ┃\n┃ Share a 2 sentence horror story.                                                                                                                                             ┃\n┃                                                                                                                                                                              ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\nTraceback (most recent call last):\n  File \"/home/sun/miniconda3/envs/agno/lib/python3.12/site-packages/agno/models/groq/groq.py\", line 256, in invoke\n    return self.get_client().chat.completions.create(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/sun/miniconda3/envs/agno/lib/python3.12/site-packages/groq/resources/chat/completions.py\", line 355, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/sun/miniconda3/envs/agno/lib/python3.12/site-packages/groq/_base_client.py\", line 1222, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/sun/miniconda3/envs/agno/lib/python3.12/site-packages/groq/_base_client.py\", line 1031, in request\n    raise self._make_status_error_from_response(err.response) from None\ngroq.NotFoundError: Error code: 404 - {'error': {'message': 'Not Found'}}\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/sun/agent/models/groq/test.py\", line 34, in <module>\n    agent.print_response(\"Share a 2 sentence horror story.\")\n  File \"/home/sun/miniconda3/envs/agno/lib/python3.12/site-packages/agno/agent/agent.py\", line 4725, in print_response\n    run_response = self.run(\n                   ^^^^^^^^^\n  File \"/home/sun/miniconda3/envs/agno/lib/python3.12/site-packages/agno/agent/agent.py\", line 1204, in run\n    raise last_exception\n  File \"/home/sun/miniconda3/envs/agno/lib/python3.12/site-packages/agno/agent/agent.py\", line 1174, in run\n    return next(resp)\n           ^^^^^^^^^^\n  File \"/home/sun/miniconda3/envs/agno/lib/python3.12/site-packages/agno/agent/agent.py\", line 811, in _run\n    model_response = self.model.response(messages=run_messages.messages)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/sun/miniconda3/envs/agno/lib/python3.12/site-packages/agno/models/base.py\", line 187, in response\n    assistant_message, has_tool_calls = self._process_model_response(\n                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/sun/miniconda3/envs/agno/lib/python3.12/site-packages/agno/models/base.py\", line 323, in _process_model_response\n    response = self.invoke(messages=messages)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/sun/miniconda3/envs/agno/lib/python3.12/site-packages/agno/models/groq/groq.py\", line 263, in invoke\n    raise ModelProviderError(\nagno.exceptions.ModelProviderError: {\"error\":{\"message\":\"Not Found\"}}\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- OS: ubuntu22\n- Agno Version: 1.4.5\n- Python 3.12.9\n\n",
      "state": "closed",
      "author": "Shulin-Sun",
      "author_type": "User",
      "created_at": "2025-05-09T03:33:55Z",
      "updated_at": "2025-06-19T15:13:04Z",
      "closed_at": "2025-06-19T15:12:55Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3132/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3132",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3132",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:25.381954",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @Shulin-Sun !\n\nCan you please rearrange your Agent to:\n\n```python\nfrom os import getenv\nfrom agno.agent import Agent, RunResponse\nfrom agno.models.openai.like import OpenAILike\nfrom agno.models.groq import Groq\n\nagent = Agent(\n    model=Groq(\n        id=\"llama-3.1-8b-instant\",\n        base_url",
          "created_at": "2025-05-19T18:22:00Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-06-19T00:35:18Z"
        },
        {
          "author": "Mustafa-Esoofally",
          "body": "Hey @Shulin-Sun ! I believe the issue should be resolved. Feel free to reopen this if you still continue to face issues",
          "created_at": "2025-06-19T15:12:55Z"
        }
      ]
    },
    {
      "issue_number": 3218,
      "title": "[Bug] ShellTools fails to run commands due to incorrect cd usage in argument list",
      "body": "### Description\n\nThe ShellTools.run_shell_command method attempts to change the working directory by prepending [\"cd\", <dir>, \";\"] to the command when building the argument list passed to subprocess.run(). This approach is invalid and leads to silent command failures.\n\nRoot Cause\n- subprocess.run() does not interpret shell syntax (like cd and ;) when arguments are passed as a list.\n- cd is a shell built-in and does not apply outside the shell context.\n- Without a proper working directory or use of shell=True with a full string, the command does not execute as expected.\n\n\n### Steps to Reproduce\n\ntool = ShellTools(\"/some/path\")\ntool.run_shell_command([\"grep\", \"-i\", \"text\", \"file.txt\"])\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nThe command should be executed in the desired working directory and return actual results, e.g., running grep on a file in that directory.\n\n### Actual Behavior\n\n- The tool executes subprocess.run() with an invalid command list, resulting in no output or misleading results.\n- No error is thrown, which can lead to silent debugging issues.\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n- OS: MAcOS\n```\n\n### Possible Solutions (optional)\n\nhttps://github.com/agno-agi/agno/pull/3217\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "shlomobamberger",
      "author_type": "User",
      "created_at": "2025-05-16T08:57:33Z",
      "updated_at": "2025-06-19T15:11:56Z",
      "closed_at": "2025-06-19T15:11:55Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3218/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3218",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3218",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:25.576194",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-178/bug-shelltools-fails-to-run-commands-due-to-incorrect-cd-usage-in\">SUPPORT-178 [Bug] ShellTools fails to run commands due to incorrect cd usage in argument list</a></p>",
          "created_at": "2025-05-16T08:57:37Z"
        },
        {
          "author": "willemcdejongh",
          "body": "Hi @shlomobamberger \n\nI was able to successfully get the correct response from `tool.run_shell_command([\"grep\", \"-i\", \"text\", \"file.txt\"])`\nusing the current implementation.\nWould you like to share your exact test snippet and dir tree where your file.txt is located so we can investigate this further",
          "created_at": "2025-05-20T15:24:00Z"
        },
        {
          "author": "Mustafa-Esoofally",
          "body": "Hey @shlomobamberger ! The fix for this #3217 was merged. Closing this. Let us know if you still face issues",
          "created_at": "2025-06-19T15:11:55Z"
        }
      ]
    },
    {
      "issue_number": 3320,
      "title": "[Bug] When using ClickHouse as the vector library, there is an error when generating OPENAI vector embeddings.",
      "body": "### Description\n\nExecuting the following code will result in an error:\nknowledge_base = TextKnowledgeBase(\n    path=Path(r\"E:\\xinyun\\doc\\test_doc\\1.txt\"),\n    # Table name: ai.text_documents\n    vector_db=Clickhouse(\n            table_name=\"recipe_documents\",\n            database_name=\"ai\",\n        ),\n\n)\n\nagent = Agent(\n    knowledge=knowledge_base,\n    # Show tool calls in the response\n    # show_tool_calls=True,\n    # Enable the agent to search the knowledge base\n    search_knowledge=True,\n    # Enable the agent to read the chat history\n    # read_chat_history=True,\n)\n# Comment out after first run\nagent.knowledge.load(upsert=True)  # type: ignore\n\nagent.print_response(\"小米24年收入多少?\")\n\nError message:\nINFO Loading knowledge base                                                    \nINFO Reading: E:\\xinyun\\doc\\test_doc\\1.txt                              \nTraceback (most recent call last):\n  File \"E:\\xinyun\\code\\mycode\\AgnoProject\\agno_test\\knowledge\\agent_with_knowledge.py\", line 36, in <module>\n    agent.knowledge.load(upsert=True)  # type: ignore\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\xinyun\\code\\mycode\\AgnoProject\\.venv\\Lib\\site-packages\\agno\\knowledge\\agent.py\", line 126, in load\n    self.vector_db.upsert(documents=document_list, filters=doc.meta_data)\n  File \"E:\\xinyun\\code\\mycode\\AgnoProject\\.venv\\Lib\\site-packages\\agno\\vectordb\\clickhouse\\clickhousedb.py\", line 387, in upsert\n    self.insert(documents=documents, filters=filters)\n  File \"E:\\xinyun\\code\\mycode\\AgnoProject\\.venv\\Lib\\site-packages\\agno\\vectordb\\clickhouse\\clickhousedb.py\", line 297, in insert\n    document.embed(embedder=self.embedder)\n  File \"E:\\xinyun\\code\\mycode\\AgnoProject\\.venv\\Lib\\site-packages\\agno\\document\\base.py\", line 27, in embed\n    self.embedding, self.usage = _embedder.get_embedding_and_usage(self.content)\n                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\xinyun\\code\\mycode\\AgnoProject\\.venv\\Lib\\site-packages\\agno\\embedder\\openai.py\", line 70, in get_embedding_and_usage\n    embedding = response.data[0].embedding\n                ^^^^^^^^^^^^^\nAttributeError: 'str' object has no attribute 'data'\n\n### Steps to Reproduce\n\n1 、Executing the following code will result in an error:\nknowledge_base = TextKnowledgeBase(\n    path=Path(r\"E:\\xinyun\\doc\\test_doc\\1.txt\"),\n    # Table name: ai.text_documents\n    vector_db=Clickhouse(\n            table_name=\"recipe_documents\",\n            database_name=\"ai\",\n        ),\n\n)\n\nagent = Agent(\n    knowledge=knowledge_base,\n    # Show tool calls in the response\n    # show_tool_calls=True,\n    # Enable the agent to search the knowledge base\n    search_knowledge=True,\n    # Enable the agent to read the chat history\n    # read_chat_history=True,\n)\n# Comment out after first run\nagent.knowledge.load(upsert=True)  # type: ignore\n\nagent.print_response(\"小米24年收入多少?\")\n\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nHope it can be carried out normally\n\n### Actual Behavior\n\nAn error actually occurred.\n  File \"E:\\xinyun\\code\\mycode\\AgnoProject\\.venv\\Lib\\site-packages\\agno\\embedder\\openai.py\", line 70, in get_embedding_and_usage\n    embedding = response.data[0].embedding\n                ^^^^^^^^^^^^^\nAttributeError: 'str' object has no attribute 'data'\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nOS:WINDOW10\nAGNO :1.5.3\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "yqher",
      "author_type": "User",
      "created_at": "2025-05-23T08:34:52Z",
      "updated_at": "2025-06-19T14:28:22Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3320/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3320",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3320",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:25.776282",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-291/bug-when-using-clickhouse-as-the-vector-library-there-is-an-error-when\">SUPPORT-291 [Bug] When using ClickHouse as the vector library, there is an error when generating OPENAI vector embeddings.</a></p>",
          "created_at": "2025-05-23T08:34:55Z"
        },
        {
          "author": "Mustafa-Esoofally",
          "body": "Hey @yqher ! Could you try updating to the latest Agno version and confirm if this still an issue?",
          "created_at": "2025-06-19T14:28:14Z"
        }
      ]
    },
    {
      "issue_number": 3314,
      "title": "[Bug] Chunking is not working in AWS EC2 server, but it is working in local with same code, openapi key and same file.",
      "body": "### Description\n\nBelow is the error we are getting when trying in server even if the file size is 501B\n\nINFO Embedder not provided, using OpenAIEmbedder as default.\nDEBUG Initialized PgVector with table 'ai.swagger_knowledge'\nINFO Dropping collection\nDEBUG Checking if table 'ai.swagger_knowledge' exists.\nDEBUG Dropping table 'ai.swagger_knowledge'.\nINFO Table 'ai.swagger_knowledge' dropped successfully.\nDEBUG Checking if table 'ai.swagger_knowledge' exists.\nINFO Creating collection\nDEBUG Checking if table 'ai.swagger_knowledge' exists.\nDEBUG Creating extension: vector\nDEBUG Creating schema: ai\nDEBUG Creating table: swagger_knowledge\nINFO Loading knowledge base\nINFO Reading: /tmp/openapi.json\nDEBUG Filtering out existing documents before insertion.\nDEBUG Processing batch starting at index 0, size: 1\nERROR Error processing document 'openapi': Error code: 400 - {'error':\n{'message': \"This model's maximum context length is 8192 tokens,\nhowever you requested 49105 tokens (49105 in your prompt; 0 for the\ncompletion). Please reduce your prompt; or completion length.\", 'type':\n'invalid_request_error', 'param': None, 'code': None}}\nERROR Error with batch starting at index 0: (psycopg.errors.NotNullViolation)\nnull value in column \"id\" of relation \"swagger_knowledge\" violates\nnot-null constraint\nDETAIL: Failing row contains (null, null, {}, {}, null, null, null,\n2025-05-23 03:50:32.425328+00, null, null).\n[SQL: INSERT INTO ai.swagger_knowledge DEFAULT VALUES]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)\nERROR Error inserting documents: (psycopg.errors.NotNullViolation) null value\nin column \"id\" of relation \"swagger_knowledge\" violates not-null\nconstraint\nDETAIL: Failing row contains (null, null, {}, {}, null, null, null,\n2025-05-23 03:50:32.425328+00, null, null).\n[SQL: INSERT INTO ai.swagger_knowledge DEFAULT VALUES]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)\nINFO: 203.192.244.115:15390 - \"POST /v1/knowledge_base/create HTTP/1.1\" 200 OK\n\n### Steps to Reproduce\n\nWhen I tried to create knowledge base I'm getting above error for all types of files.\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nNeed to chunk it based on the default size that is mentioned in the packages\n\n### Actual Behavior\n\nWhether it is a small file or big file getting you are sending 49105 tokens but the limit is 8192 only.\n\nThis is the server logs\n![Image](https://github.com/user-attachments/assets/5e84d852-3143-49f6-bb72-e66be3cbcbd5)\n\nThis is the local logs\n![Image](https://github.com/user-attachments/assets/d97d638e-e05a-4800-be7c-91869198ad2e)\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nlocal is Ubuntu 24.04\nServer is Amazon Linux 2023\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "JanardhanDumpa",
      "author_type": "User",
      "created_at": "2025-05-23T04:10:29Z",
      "updated_at": "2025-06-19T14:14:05Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3314/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3314",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3314",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:26.003994",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-273/bug-chunking-is-not-working-in-aws-ec2-server-but-it-is-working-in\">SUPPORT-273 [Bug] Chunking is not working in AWS EC2 server, but it is working in local with same code, openapi key and same file.</a></p>",
          "created_at": "2025-05-23T04:10:33Z"
        },
        {
          "author": "Diveyam-Mishra",
          "body": "Try hosting it through docker maybe?",
          "created_at": "2025-05-23T08:31:13Z"
        },
        {
          "author": "JanardhanDumpa",
          "body": "> Try hosting it through docker maybe?\n\nI'm using docker only",
          "created_at": "2025-05-27T03:40:43Z"
        },
        {
          "author": "Mustafa-Esoofally",
          "body": "Hey @JanardhanDumpa ! Could you share an agent config that I could use to reproduce this error?",
          "created_at": "2025-06-19T14:14:05Z"
        }
      ]
    },
    {
      "issue_number": 3326,
      "title": "[Bug] Reasoning error When running Team Multi-Agents async",
      "body": "### Description\n\nI'm running my team asynchronously as follows :  \n```python\n run_response = await agent_team.arun(\n                message=request_json,\n                stream=True,\n                stream_intermediate_steps=False\n            )\n```\nWhen enabling `reasoning=True` to the team like this : \n\n```python\nagent_team = Team(\n    mode=\"collaborate\",\n    knowledge=knowledge_base,\n    reasoning=True,\n)\n```\nI get the following error throughout the run, in logs : \n```bash\nERROR    Reasoning error: 'NoneType' object has no attribute 'replace'                                                                \nERROR    Reasoning error: 'NoneType' object has no attribute 'replace' \n```\nAlthough the Run does not crash, it seems like it acts without reasoning for the team.\nand it gives a final output Normally\n\n\n### Steps to Reproduce\n\n1. run the team with arun\n```python\n run_response = await agent_team.arun(\n                message=request_json,\n                stream=True,\n                stream_intermediate_steps=False\n            )\n```\n\n\n\n### Agent Configuration (if applicable)\n\n2. enable reasoning for the team : \n```python\nagent_team = Team(\n    mode=\"collaborate\",\n    knowledge=knowledge_base,\n    reasoning=True,\n)\n```\n\n### Expected Behavior\n\nThe expected behavior is to have an async run with reasoning, just like with sync\n\n### Actual Behavior\n\n Yet a an error is thrown thoughout the run instead\n```bash\nERROR    Reasoning error: 'NoneType' object has no attribute 'replace'                                                                \nERROR    Reasoning error: 'NoneType' object has no attribute 'replace'  \n```\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nagno==1.5.2\nOS: Linux Mint 22.1 x86_64\nlangchain-openai==0.2.14\nopenai==1.75.0\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "amine759",
      "author_type": "User",
      "created_at": "2025-05-23T10:51:03Z",
      "updated_at": "2025-06-19T14:06:02Z",
      "closed_at": "2025-06-19T14:06:02Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3326/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3326",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3326",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:26.185713",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-293/bug-reasoning-error-when-running-team-multi-agents-async\">SUPPORT-293 [Bug] Reasoning error When running Team Multi-Agents async</a></p>",
          "created_at": "2025-05-23T10:51:05Z"
        },
        {
          "author": "Ayush0054",
          "body": "Hey @amine759,\nCould you please share more detailed config or any error logs? We’re currently unable to replicate the issue on our end.\n\nAlso, make sure you’ve updated to the latest Agno version , we’ve released some fixes .\n\nThanks! 🙌\n",
          "created_at": "2025-05-26T09:36:14Z"
        },
        {
          "author": "amine759",
          "body": "@Ayush0054 Hi there, looks like it's fixed in the latest upgrade.\n\nThanks 🚀",
          "created_at": "2025-05-29T13:43:48Z"
        },
        {
          "author": "oza-c",
          "body": "Hello, in version 1.58 I still get the error, both team run and via a ‘normal’ agent run\n\nSpecs: Azure OpenAI - o3-mini\n\nDEBUG =================== Starting OpenAI Reasoning =================== \nWARNING  Reasoning error: 'NoneType' object has no attribute 'replace'               \nWARNING  Reasoning e",
          "created_at": "2025-06-03T17:14:35Z"
        },
        {
          "author": "amine759",
          "body": "@oza-c Hi, I'm using `1.5.5`",
          "created_at": "2025-06-04T10:45:20Z"
        }
      ]
    },
    {
      "issue_number": 3343,
      "title": "[Bug] ValidateCallWrapper for next tool calls",
      "body": "### Description\n\nIn the first tool call there is no problem and it will run with no problem but in the next calls it will warn into:\n```\n_generate_schema.py:355: UserWarning: ValidateCallWrapper(ValidateCallWrapper(<function search_product_tool_hybrid_sync at 0x72ea3a8b37e0>)) is not a Python type \n```\nand the tool will not executed.\nThe tool code:\n```python\n@tool(\n\tname=\"search_product_tool_hybrid_sync\",\n\tdescription=\"\"\"Search for products with a **hybrid** strategy (REST + vector) - fully synchronous version.\nReturns a stringified JSON object; processes searches sequentially.\"\"\",\n\tshow_result=False,\n)\ndef search_product_tool_hybrid_sync(\n\tquery: str = \"Beauty products\",\n\tpage: int = 10,\n\tpage_size: int = 10,\n\tvector_search_limit: int = 10,\n) -> str:\n\t\"\"\"\n\tSearch for products using a hybrid approach combining REST API and vector search.\n\tThis is a fully synchronous version that processes searches sequentially.\n\n\tArgs:\n\t\tquery: The search query string to find relevant products\n\t\tpage: Page number for API search (default: 10)\n\t\tpage_size: Number of items per page for API search (default: 10)\n\t\tvector_search_limit: Maximum number of vector search results (default: 10)\n\t\t\n\tReturns:\n\t\tJSON string containing combined and enriched search results with:\n\t\t\t- count: Total number of results\n\t\t\t- results: List of products with full details\n\t\t\t- vector_search_available: Boolean indicating if vector search was available\n\t\t\t\n\t\"\"\"\n\tprint(\"Starting hybrid search (sync)\", {\"query\": query})\n        return \"Sample text\"\n\n```\nAdding it to the agent:\n```python\nagent = Agent(\n                    model=OpenAIChat(id=config.get('model', settings.OPENAI_MODEL)),\n                    description=config.get('description', base_config['description']),\n                    instructions=config.get('instructions', base_config['instructions']),\n                    tools=[search_product_tool_hybrid_sync]\n,...\n)\n```\nKeep in mind that the agent is created by a factory and `cls._instance`\n\n\n### Steps to Reproduce\n\nYou can simply add the code\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nEach time the tool should be executed\n\n### Actual Behavior\n\nOnly in first execution the tool executed\n\n### Screenshots or Logs (if applicable)\n\nThe log of first execution:\n```log\nDEBUG ********** Agent ID: 132728390_132728390_telegram **********              \nDEBUG ***** Session ID: 3cb7ba2f-29e9-4692-8f07-67762a06fe94 *****              \nDEBUG  Async Agent Run Start: 2483cf24-b78b-441f-a74b-a86d96c695f0              \nDEBUG Processing tools for model                                                \nDEBUG Added tool search_product_tool_hybrid_sync                                \nDEBUG --------------- OpenAI Async Response Start ----------------              \nDEBUG ------------------- Model: gpt-4.1-mini --------------------              \nDEBUG ========================== system ==========================              \n...\nDEBUG ======================== assistant =========================              \nDEBUG Tool Calls:                                                               \n        - ID: 'call_YrboWyt56bmDBt3sY52mqxhN'                                   \n          Name: 'search_product_tool_hybrid_sync'                               \n          Arguments: 'query: ضدآفتاب, page_size: 5'                             \nDEBUG ************************  METRICS  *************************              \nDEBUG * Tokens:                      input=818, output=27, total=845            \nDEBUG * Prompt tokens details:       {'audio_tokens': 0, 'cached_tokens': 0}    \nDEBUG * Completion tokens details:   {'accepted_prediction_tokens': 0,          \n      'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}\nDEBUG * Time:                        1.7321s                                    \nDEBUG * Tokens per second:           15.5884 tokens/s                           \nDEBUG ************************  METRICS  *************************              \nDEBUG Getting function search_product_tool_hybrid_sync                          \nDEBUG Running: search_product_tool_hybrid_sync(query=ضدآفتاب, page_size=5)      \n```\nnext execution logs:\n```log\nDEBUG ********** Agent ID: 132728390_132728390_telegram **********              \nDEBUG ***** Session ID: 1b9ed924-1bc6-4285-bab8-14d2ab208e28 *****              \nDEBUG  Async Agent Run Start: b11f5c6b-dd57-4f59-8515-12c256bbe4cf              \nDEBUG Processing tools for model                                                \n/root/.local/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:355: UserWarning: ValidateCallWrapper(<function search_product_tool_hybrid_sync at 0x7f696b19e480>) is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n  warn(\nDEBUG Added tool search_product_tool_hybrid_sync                                \nDEBUG --------------- OpenAI Async Response Start ----------------              \nDEBUG ------------------- Model: gpt-4.1-mini --------------------              \nDEBUG ========================== system ==========================              \n...\nDEBUG ======================== assistant =========================              \nDEBUG Tool Calls:                                                               \n        - ID: 'call_SwfNx3jyQuUGQIJ2KxvZEHzD'                                   \n          Name: 'search_product_tool_hybrid_sync'                               \n          Arguments: 'query: ضدآفتاب'                                           \nDEBUG ************************  METRICS  *************************              \nDEBUG * Tokens:                      input=823, output=22, total=845            \nDEBUG * Prompt tokens details:       {'audio_tokens': 0, 'cached_tokens': 0}    \nDEBUG * Completion tokens details:   {'accepted_prediction_tokens': 0,          \n      'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}\nDEBUG * Time:                        1.0170s                                    \nDEBUG * Tokens per second:           21.6332 tokens/s                           \nDEBUG ************************  METRICS  *************************              \nDEBUG Getting function search_product_tool_hybrid_sync                          \nDEBUG Running: search_product_tool_hybrid_sync(query=ضدآفتاب)                   \nDEBUG =========================== tool ===========================              \nDEBUG Tool call Id: call_SwfNx3jyQuUGQIJ2KxvZEHzD                               \nDEBUG ArgsKwargs((), {'query': 'ضدآفتاب'})                                      \nDEBUG **********************  TOOL METRICS  **********************              \nDEBUG * Time:                        0.0039s                                    \nDEBUG **********************  TOOL METRICS  **********************              \n```\nThe first execution will return the result but the second and next executions will not even executed!\n\n### Environment\n\n```markdown\nWindows 11\nand Docker python 3.11\nPython 3.11\nLatest version of agno\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "artaasd95",
      "author_type": "User",
      "created_at": "2025-05-25T08:27:10Z",
      "updated_at": "2025-06-19T14:01:16Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 21,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3343/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3343",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3343",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:26.460085",
      "comments": []
    },
    {
      "issue_number": 2861,
      "title": "[Bug] Model Input exceeds max tokens when using Playwright MCP with Claude Bedrock based agent",
      "body": "# Description\nI am trying to do browser automation using agno agents. I am using playwright-mcp tool. The max token for the model is 200k, still it gets exhausted in a few calls and the task doesnt complete.\n\n## Steps to Reproduce\nThis is the code to produce the eeror -\n`import asyncio\nimport os\n\nfrom agno.agent import Agent\nfrom agno.models.anthropic import Claude\nfrom agno.tools.mcp import MCPTools\n\nfrom mcp import StdioServerParameters\n\nasync def run_agent(message: str) -> None:\n    \"\"\"Run the Playwright agent with the given message.\"\"\"\n\n    server_params = StdioServerParameters(\n        command=\"npx\",\n        args=[\n            \"@playwright/mcp@latest\",\n        ],\n    )\n\n    async with MCPTools(server_params=server_params) as mcp_tools:\n        agent = Agent(\n            model=Claude(id=CLAUDE_SONNET_MODEL_ID, api_key=ANTHROPIC_API_KEY),\n            tools=[mcp_tools],\n            role=\"Your task is to use your web browsing capabilities to find information and take actions on the web.\",\n            markdown=True,\n            show_tool_calls=True,\n        )\n\n        await agent.aprint_response(message=message, stream=True)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(\n        run_agent(\n            \"Look for a personality test on the web and take it. Then, summarize the results of the test and provide a link to the test you took.\",\n        )\n    )`\n\n\n\n## Expected Behavior\nThe steps are completed .\n\n## Actual Behavior\nAfter a few steps, it overflows max context length.\n\n## Screenshots or Logs (if applicable)\n\n> ERROR    Unexpected error calling Claude API: Bad response code, expected 200: {'status_code': 400, 'headers':   \n         {':exception-type': 'validationException', ':content-type': 'application/json', ':message-type':        \n         'exception'}, 'body': b'{\"message\":\"Input is too long for requested model.\"}'}\n▰▰▰▰▰▰▰ Thinking...\n┏━ Message ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                                                               ┃\n┃ Go to https://www.sec.gov/ and find the 10-K for NVIDIA. Then, download the 10-K and provide a link to the    ┃\n┃ file you downloaded.                                                                                          ┃\n┃                                                                                                               ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n┏━ Tool Calls ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                                                               ┃\n┃ • browser_navigate(url=https://www.sec.gov/)                                                                  ┃\n┃ • browser_click(element=link \"Search EDGAR\", ref=s1e126)                                                      ┃\n┃ • browser_type(element=textbox \"Search by keyword, ticker, company name, CIK number or individual's name\",    ┃\n┃ ref=s1e25, text=NVIDIA 10-K, submit=True, slowly=False)                                                       ┃\n┃ • browser_wait(time=3)                                                                                        ┃\n┃ • browser_snapshot()                                                                                          ┃\n┃ • browser_click(element=cell \"10-K (Annual report)\" \"2024-02-21\" \"2024-01-28\" \"NVIDIA CORP (NVDA)\",           ┃\n┃ ref=s3e175)                                                                                                   ┃\n┃                                                                                                               ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n┏━ Response (49.2s) ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                                                               ┃\n┃ I'll help you navigate to the SEC website and find NVIDIA's 10-K filing.                                      ┃\n┃                                                                                                               ┃\n┃ Now I'll navigate to the EDGAR search to find NVIDIA's 10-K filing.                                           ┃\n┃                                                                                                               ┃\n┃ I'll search for NVIDIA's 10-K.                                                                                ┃\n┃                                                                                                               ┃\n┃ Let me wait for the search results to load.                                                                   ┃\n┃                                                                                                               ┃\n┃ I can see NVIDIA's latest 10-K filing in the search results. Let me navigate to it.                           ┃\n┃                                                                                                               ┃\n┃ Let me try clicking the 10-K link again with a different reference.                                           ┃\n┃                                                                                                               ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\nan error occurred during closing of asynchronous generator <async_generator object stdio_client at 0x0000025869E38F40>\nasyncgen: <async_generator object stdio_client at 0x0000025869E38F40>\n  + Exception Group Traceback (most recent call last):\n  |   File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 772, in __aexit__\n  |     raise BaseExceptionGroup(\n  | BaseExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\site-packages\\mcp\\client\\stdio\\__init__.py\", line 173, in stdio_client\n    |     yield read_stream, write_stream\n    | GeneratorExit\n    +------------------------------------\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\site-packages\\mcp\\client\\stdio\\__init__.py\", line 167, in stdio_client\n    anyio.create_task_group() as tg,\n    ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 778, in __aexit__\n    if self.cancel_scope.__exit__(type(exc), exc, exc.__traceback__):\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 457, in __exit__\n    raise RuntimeError(\nRuntimeError: Attempted to exit cancel scope in a different task than it was entered in\n  + Exception Group Traceback (most recent call last):\n  |   File \"C:\\Users\\pandsan\\OneDrive - acuitykp\\codes\\agno-agents\\agno_mcp.py\", line 57, in <module>\n  |     asyncio.run(\n  |   File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\asyncio\\runners.py\", line 195, in run   \n  |     return runner.run(main)\n  |            ^^^^^^^^^^^^^^^^\n  |   File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\asyncio\\runners.py\", line 118, in run   \n  |     return self._loop.run_until_complete(task)\n  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  |   File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\asyncio\\base_events.py\", line 691, in run_until_complete\n  |     return future.result()\n  |            ^^^^^^^^^^^^^^^\n  |   File \"C:\\Users\\pandsan\\OneDrive - acuitykp\\codes\\agno-agents\\agno_mcp.py\", line 34, in run_agent\n  |     async with MCPTools(server_params=server_params) as mcp_tools:\n  |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  |   File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\site-packages\\agno\\tools\\mcp.py\", line 114, in __aexit__\n  |     await self._session_context.__aexit__(exc_type, exc_val, exc_tb)\n  |   File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\site-packages\\mcp\\shared\\session.py\", line 210, in __aexit__\n  |     return await self._task_group.__aexit__(exc_type, exc_val, exc_tb)\n  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  |   File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 772, in __aexit__\n  |     raise BaseExceptionGroup(\n  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\site-packages\\agno\\models\\aws\\claude.py\", line 449, in ainvoke_stream\n    |     async for chunk in stream:\n    |   File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\site-packages\\anthropic\\lib\\streaming\\_messages.py\", line 192, in __aiter__\n    |     async for item in self._iterator:\n    |   File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\site-packages\\anthropic\\lib\\streaming\\_messages.py\", line 252, in __stream__\n    |     async for sse_event in self._raw_stream:\n    |   File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\site-packages\\anthropic\\_streaming.py\", line 185, in __aiter__\n    |     async for item in self._iterator:\n    |   File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\site-packages\\anthropic\\_streaming.py\", line 198, in __stream__\n    |     async for sse in iterator:\n    |   File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\site-packages\\anthropic\\_streaming.py\", line 189, in _iter_events\n    |     async for sse in self._decoder.aiter_bytes(self.response.aiter_bytes()):\n    |   File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\site-packages\\anthropic\\lib\\bedrock\\_stream_decoder.py\", line 50, in aiter_bytes\n    |     message = self._parse_message_from_event(event)\n    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\site-packages\\anthropic\\lib\\bedrock\\_stream_decoder.py\", line 58, in _parse_message_from_event\n    |     raise ValueError(f\"Bad response code, expected 200: {response_dict}\")\n    | ValueError: Bad response code, expected 200: {'status_code': 400, 'headers': {':exception-type': 'validationException', ':content-type': 'application/json', ':message-type': 'exception'}, 'body': b'{\"message\":\"Input is too long for requested model.\"}'}\n    |\n    | The above exception was the direct cause of the following exception:\n    |\n    | Traceback (most recent call last):\n    |   File \"C:\\Users\\pandsan\\OneDrive - acuitykp\\codes\\agno-agents\\agno_mcp.py\", line 48, in run_agent\n    |     await agent.aprint_response(message=message, stream=True)\n    |   File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\site-packages\\agno\\agent\\agent.py\", line 4660, in aprint_response\n    |     async for resp in await self.arun(\n    |   File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\site-packages\\agno\\agent\\agent.py\", line 1213, in _arun\n    |     async for model_response_chunk in model_response_stream:  # type: ignore\n    |   File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\site-packages\\agno\\models\\base.py\", line 609, in aresponse_stream\n    |     async for response in self.aprocess_response_stream(\n    |   File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\site-packages\\agno\\models\\base.py\", line 580, in aprocess_response_stream\n    |     async for response_delta in self.ainvoke_stream(messages=messages):  # type: ignore\n    |   File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\site-packages\\agno\\models\\aws\\claude.py\", line 464, in ainvoke_stream\n    |     raise ModelProviderError(message=str(e), model_name=self.name, model_id=self.id) from e\n    | agno.exceptions.ModelProviderError: Bad response code, expected 200: {'status_code': 400, 'headers': {':exception-type': 'validationException', ':content-type': 'application/json', ':message-type': 'exception'}, 'body': b'{\"message\":\"Input is too long for requested model.\"}'}\n    +------------------------------------\nException ignored in: <function BaseSubprocessTransport.__del__ at 0x0000025865FC9800>\nTraceback (most recent call last):\n  File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\asyncio\\base_subprocess.py\", line 126, in __del__\n    self.close()\n  File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\asyncio\\base_subprocess.py\", line 104, in close\n    proto.pipe.close()\n  File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\asyncio\\proactor_events.py\", line 109, in close\n    self._loop.call_soon(self._call_connection_lost, None)\n  File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\asyncio\\base_events.py\", line 799, in call_soon\n    self._check_closed()\n  File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\asyncio\\base_events.py\", line 545, in _check_closed\n    raise RuntimeError('Event loop is closed')\nRuntimeError: Event loop is closed\nException ignored in: <function _ProactorBasePipeTransport.__del__ at 0x0000025865FCB060>\nTraceback (most recent call last):\n  File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\asyncio\\proactor_events.py\", line 116, in __del__\n    _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n                               ^^^^^^^^\n  File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\asyncio\\proactor_events.py\", line 80, in __repr__\n    info.append(f'fd={self._sock.fileno()}')\n                      ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\pandsan\\AppData\\Local\\anaconda3\\envs\\agno-agent\\Lib\\asyncio\\windows_utils.py\", line 102, in fileno\n    raise ValueError(\"I/O operation on closed pipe\")\nValueError: I/O operation on closed pipe\n\n## Environment\n- OS:Windows 11\n- Browser (if relevant): Chrome \n\n\n\n\n",
      "state": "closed",
      "author": "sandeep-acuity",
      "author_type": "User",
      "created_at": "2025-04-17T09:21:15Z",
      "updated_at": "2025-06-19T13:54:18Z",
      "closed_at": "2025-06-19T13:54:18Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2861/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2861",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2861",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:26.460110",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Hi @sandeep-acuity \nSo the Playwright MCP adds 27 tools to the agent. Now this is not usually a problem, but it is important to consider that each tool adds to the context of the model in most cases (it is considered the same as system messages).  This is sent on each request to the model. Also each",
          "created_at": "2025-04-18T13:15:29Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-05-19T00:36:25Z"
        }
      ]
    },
    {
      "issue_number": 2966,
      "title": "[Bug] PostgresStorage for Teams seems to not work",
      "body": "# Description\nI have created a bunch of agents with persistent storage using the PostgresStorage class. Everything works as expected. However, when I created a first team, with some dummy members of the agents I created and also gave it storage=PostgresStorage(...), it correctly creates the table and its columns, but when talking to the team, it does not remember anything (neither in session nor after restarting the app completely).\n\n## Steps to Reproduce\nCreate a Team like so:\nmyteam = Team(\n    name=\"Base_Team\",\n    mode=\"collaborate\",\n    model=OpenAIChat(\"gpt-4o\"),\n    members=[get_base_agent(), get_base_agent2()],\n    show_tool_calls=True,\n    markdown=True,\n    description=_systemprompt_base_team,\n    storage=PostgresStorage(\n            table_name=\"base_team_memory\",\n            db_url=memory_db_uri,\n            auto_upgrade_schema=True,\n            mode=\"team\"\n            ),\n    show_members_responses=False,\n)\nCall it with myteam.run(\"I am HappyPants!\")\nand then\nmyteam.run(\"Whats my name?\")\n\n## Expected Behavior\nIt should be able to remember the messages (like the agents do).\n\n## Actual Behavior\nEach message is new to the agent and neither persistent nor in session memory / storage happens.\n\n## Environment\n- OS: Ubuntu\n- Browser Brave\n- Agno Version: 1.3.4\n- Additional Environment Details: (e.g., Python 3.12.7)\n\n## Context\nI am building a webapp with flask (which is why persistent DB storage of the message history is important). Agents work perfectly with the PostgresStorage.\n\nI saw in the source code, that you can set the \"mode\" in the PostgresStorage class, which I did as you can see above, however, this did not help.\nThe \"enable_team_history\" lets my team remember the messages (with num_of_interactions_from_history being the amount of messages it does), but this is only in session and I also feel like the storage is actually more what is intended for my usecase.\n\nIf you have any more questions or if I can provide any more information please let me know!\n",
      "state": "open",
      "author": "joelbolz",
      "author_type": "User",
      "created_at": "2025-04-24T12:10:00Z",
      "updated_at": "2025-06-19T13:38:25Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2966/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 1
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2966",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2966",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:26.686732",
      "comments": [
        {
          "author": "zizake",
          "body": "Same here. Sometimes it works, sometimes it doesnt keep all messages, just the last one even the number of interactions is set to a higher numner.",
          "created_at": "2025-04-26T19:13:13Z"
        },
        {
          "author": "RaveEx12",
          "body": "Check the logs if it gives you same issues as this: [ModelProviderError with add_memory: Missing 'type' in 'topics' schema](https://community.agno.com/t/modelprovidererror-with-add-memory-missing-type-in-topics-schema/1035) this is the problem i had. i am trying to use only team to manage storage an",
          "created_at": "2025-04-29T23:49:10Z"
        },
        {
          "author": "mishramonalisha76",
          "body": "Hi @joelbolz , For storage and memory with teams , you can refer to the below cookbook  and docs on memory. \nAlso make sure you are using the latest Agno sdk [version](https://github.com/agno-agi/agno/releases/tag/v1.5.4).\n[https://github.com/agno-agi/agno/blob/main/cookbook/teams/team_with_storage.",
          "created_at": "2025-05-26T11:13:31Z"
        },
        {
          "author": "Mustafa-Esoofally",
          "body": "Hey @joelbolz @zizake and @RaveEx12 ! Do you still continue to face this issue?",
          "created_at": "2025-06-19T13:38:25Z"
        }
      ]
    },
    {
      "issue_number": 2689,
      "title": "Having tools with \"stop_after_tool_call\" does not work with streaming",
      "body": "# Description\nWhen I do streaming and have a tool that has \"stop_after_tool_call\" set, I get no chunks returned by the agent. \n\n## Steps to Reproduce\n\n![Image](https://github.com/user-attachments/assets/b4000a63-013c-4a15-8ae7-b8565c4c5de1)\n\n## Agent Configuration (if applicable)\nN/A\n\n## Expected Behavior\nThe messages should still be returned by response_iterator until the agent stops. \n\n## Actual Behavior\nNo messages are returned at all by the iterator. \n\n## Steps to reproduce\nA placeholder is created where tools shouldn't really be called but rather control should be returned to the user code. \n\n![Image](https://github.com/user-attachments/assets/9e7dde4c-3fb6-4e30-837f-00ec7e5f7bbf)\n\nThis approach works in non-streaming mode but fails in streaming mode. ",
      "state": "open",
      "author": "mkschreder",
      "author_type": "User",
      "created_at": "2025-04-05T11:23:31Z",
      "updated_at": "2025-06-19T13:29:29Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2689/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "Ayush0054"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2689",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2689",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:26.913858",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-22T00:33:14Z"
        },
        {
          "author": "Ayush0054",
          "body": "Hey @mkschreder,\nReally sorry for the late reply!\n\nCould you please share more details and the debug logs? We’re currently unable to replicate the issue on our side.\n\nAlso, here are the docs for stop_after_tool_call:\nhttps://docs.agno.com/tools/tools\nhttps://github.com/agno-agi/agno/blob/main/cookbo",
          "created_at": "2025-04-26T20:07:04Z"
        },
        {
          "author": "Antriksh-Narang",
          "body": "@Ayush0054, I guess he means, that the tools response or intermediate results are not streamed, rather the agno agent's result is streamed.",
          "created_at": "2025-05-20T08:03:25Z"
        },
        {
          "author": "Mustafa-Esoofally",
          "body": "Hey @mkschreder and @Antriksh-Narang! Could you try using the latest version of Agno and confirm if this is still an issue?",
          "created_at": "2025-06-19T13:29:29Z"
        }
      ]
    },
    {
      "issue_number": 2792,
      "title": "[Feature Request] Paved detailed logging for API request/response",
      "body": "## Problem Description\nWhen debugging https://github.com/agno-agi/agno/issues/2791 I wanted to inspect the full request/response Agno was making to the LLM provider. There does not seem to be any documented way to do so. There should be.\n\n## Proposed Solution\nI eventually got enough logging by bashing these things in my app:\n\n```\n    from agno.debug import enable_debug_mode\n    enable_debug_mode()\n    import logging\n    logging.basicConfig(level=logging.DEBUG)\n    logging.getLogger(\"httpx\").setLevel(logging.DEBUG)  # For HTTP logging\n    logging.getLogger(\"anthropic\").setLevel(logging.DEBUG)\n```\n\nYou could take this as is, I guess. Probably better to do something native though. BTW, enable_debug_mode didn't work by itself, I needed the logging bits too. I didn't run an ablation.\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[ ] Yes, I’d love to work on it!**\n**[X] I’m open to collaborating but need guidance.**\n**[ ] No, I’m just sharing the idea.**\n",
      "state": "open",
      "author": "ezyang",
      "author_type": "User",
      "created_at": "2025-04-12T14:11:48Z",
      "updated_at": "2025-06-19T13:28:07Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2792/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2792",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2792",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:27.131280",
      "comments": [
        {
          "author": "kausmeows",
          "body": "Hi @ezyang did you try `debug_mode=True` ??? \n\nhttps://docs.agno.com/introduction/agents#debugging\n\nshould give enough logs i think?",
          "created_at": "2025-04-17T08:38:17Z"
        },
        {
          "author": "nilnor",
          "body": "@kausmeows I believe the request is to see the actual raw HTTP requests and responses, not debug logging from agno. This is unlikely to be anything easy to to provide in a generic fashion, but could be achieved for specified models at least.\n\nE.g. for Gemini, given this httpx issue for background in",
          "created_at": "2025-05-16T18:58:06Z"
        },
        {
          "author": "Mustafa-Esoofally",
          "body": "Hi @nilnor and @ezyang ! Could you try using the below mentioned utility? Let us know if you still need more help\n\n```\nfrom agno.utils.log import set_log_level_to_debug\n\n set_log_level_to_debug()\n```",
          "created_at": "2025-06-19T13:28:07Z"
        }
      ]
    },
    {
      "issue_number": 3125,
      "title": "[Feature Request] Async postgres storage",
      "body": "## Problem Description\nCurrently, Agno's PostgreSQL storage solutions primarily offer synchronous operations. When integrating Agno agents and their session management into asynchronous Python frameworks like FastAPI, using synchronous database calls for session storage becomes a bottleneck.\n\n\n## Proposed Solution\nWe propose the introduction of an `AsyncPostgresStorage` class within Agno. This class would provide an asynchronous interface for persisting and retrieving Agno agent, team, or workflow sessions in a PostgreSQL database.\n\n**Key features would include:**\n\n1.  **Asynchronous Operations:** All database interaction methods (`read`, `upsert`, `delete_session`, `get_all_session_ids`, `get_all_sessions`, etc.) should be `async` methods, returning awaitables.\n2.  **Async Database Driver:** It should leverage an asynchronous PostgreSQL driver like `asyncpg` through SQLAlchemy's asynchronous interface (e.g., `create_async_engine`, `AsyncSession`).\n3.  **API Parity:** The API should closely mirror the existing synchronous storage solutions or the provided `PostgresStorage` for ease of migration and consistency. This includes parameters for `table_name`, `mode` (`agent`, `team`, `workflow`), etc.\n5.  **Configuration:** Initialization should accept a database URL suitable for async connections and potentially an existing `AsyncEngine` instance.\n\n**Example (Conceptual):**\n```python\nfrom agno.storage.base import Storage # (or a new async base class)\nfrom sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\n# ... other imports\n\nclass AsyncPostgresStorage(Storage): # Or AsyncStorageBase\n    def __init__(self, table_name: str, tenant_id: str, db_url: str, mode: str = \"agent\", ...):\n        super().__init__(mode)\n        self.table_name = table_name\n        self.engine = create_async_engine(db_url)\n        # ... define self.table using SQLAlchemy Table object\n        # ... sessionmaker with AsyncSession\n\n    async def read(self, session_id: str, user_id: Optional[str] = None) -> Optional[Session]:\n        async with self.Session() as sess: # self.Session() being an async session factory\n            # ... async query execution ...\n            pass\n\n    async def upsert(self, session: Session) -> Optional[Session]:\n        async with self.Session() as sess:\n            # ... async insert/update and commit ...\n            pass\n\n    # ... other async methods ...\n```\n\n## Alternatives Considered\n1.  **Wrapping Sync Calls in `asyncio.to_thread`:** We've considered using `asyncio.to_thread` to run synchronous storage operations in a separate thread pool. While this prevents blocking the main event loop, it introduces overhead and isn't as efficient as native async database operations.\n2.  **Implementing Custom Async Logic:** We could build a completely custom async storage solution outside of Agno's abstractions. However, this would mean losing the benefits of Agno's standardized session objects and storage interface, and would require more effort to maintain.\n\n## Additional context\n*   **Use Case:** The primary motivation is for use within a FastAPI backend, where non-blocking I/O is critical for achieving good performance and scalability when managing agent sessions.\n*   **Agno Documentation:** Agno's documentation already features `PostgresStorage` for agent, team, and workflow examples. An `AsyncPostgresStorage` would be a valuable addition, specifically catering to modern async Python applications requiring multi-tenancy.\n*   **SQLAlchemy Version:** Development should consider compatibility with recent versions of SQLAlchemy that provide robust async support (e.g., SQLAlchemy 1.4+ or 2.x).\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[X] Yes, I’d love to work on it!**\n**[ ] I’m open to collaborating but need guidance.**\n**[ ] No, I’m just sharing the idea.**",
      "state": "closed",
      "author": "diefergil",
      "author_type": "User",
      "created_at": "2025-05-08T14:38:32Z",
      "updated_at": "2025-06-19T11:16:00Z",
      "closed_at": "2025-05-12T13:28:58Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3125/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3125",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3125",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:27.366500",
      "comments": [
        {
          "author": "alec-drw",
          "body": "Would love this!",
          "created_at": "2025-05-11T22:55:07Z"
        },
        {
          "author": "RocketDonald",
          "body": "I was just wondering why Agno does not support Async Postgres. Great request! I am totally supporting it as I need it in my FastApi project.",
          "created_at": "2025-05-12T07:11:39Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey Folks 😊\n\nThank you so much for reaching out and for your support for Agno — it truly means a lot to us. We’ve added your suggestion to our roadmap! \nLooking forward to building together!",
          "created_at": "2025-05-12T13:28:58Z"
        },
        {
          "author": "tumbarumba",
          "body": "This is marked as \"completed\", but I don't see any commits to implement. Was that a mistake?",
          "created_at": "2025-05-29T05:35:28Z"
        },
        {
          "author": "samim23",
          "body": "would love for this to work!",
          "created_at": "2025-06-19T11:16:00Z"
        }
      ]
    },
    {
      "issue_number": 2632,
      "title": "[Bug] Memory leak when making multiple queries one after another",
      "body": "# Description\nI was testing my agno application for resource consumption and found out that the memory usage keeps increasing for each agent call. I am using Gemini LLM with sentence transformers embedded (all-mpnet-base-v2: 768 dimensions). The initial memory usage when the app starts stands at 700 MBs and keeps increasing by ~300 MBs per query.\n\nI am using below -\n- Milvus vector DB (Cloud)\n- Gemini LLM (flash-2.0)\n- Sentence Transformer embedder\n- Chat history enabled (SQLite storage) agno agent\n\nI used `memory_profiler` (python library) to profile the memory usage increase along with the `bpytop` resources monitor. I tried finding the root cause but could not find any as this memory profiler does not work well with functions that use yield keywords inside them. \n\nEDIT:\nI am making same query again and again in this example, but same things happens with the different queries as well.\n\nAdditionally, please inform me if I am incorrectly setting up something against its intended use. Thank you.\n\n## Steps to Reproduce\nProviding code that I used.\n\n```python\n\nimport os\nimport time\nfrom agno.embedder.sentence_transformer import SentenceTransformerEmbedder\nfrom agno.embedder.google import GeminiEmbedder\nfrom agno.knowledge.agent import AgentKnowledge\nfrom agno.vectordb.milvus import Milvus\nfrom memory_profiler import profile\n\nLLM_API_KEY = \"<LLM_API_KEY>\"\nLLM_MODEL_NAME = \"gemini-2.0-flash-exp\"\n\n\nEMBEDDING_MODEL = \"sentence-transformers/all-mpnet-base-v2\"\nTEXT_COLLECTION_NAME = \"test_collection\"\nVECTOR_DB_NAME = \"test\"\nVECTOR_DB_URI = \"<VECTOR_DB_URI>\"\nVECTOR_DB_TOKEN = \"<VECTOR_DB_TOKEN>\"\n\nVECTOR_DIMENSIONS = 768\n\nos.environ[\"GOOGLE_API_KEY\"] = LLM_API_KEY\n\n# VectorDB / Knowledge Base Client for Text based Agent\ntext_knowledge_base = AgentKnowledge(\n    vector_db=Milvus(\n        uri=VECTOR_DB_URI,\n        token=VECTOR_DB_TOKEN,\n        collection=TEXT_COLLECTION_NAME,\n        # embedder=GeminiEmbedder()\n        embedder=SentenceTransformerEmbedder(\n            id=EMBEDDING_MODEL, dimensions=VECTOR_DIMENSIONS\n        ),\n    )\n)\n\nfrom agno.models.google import Gemini as AgentLLM\n\nagent_llm = AgentLLM(id=LLM_MODEL_NAME, api_key=LLM_API_KEY)\n\nfrom agno.agent import Agent, RunResponse\nfrom agno.storage.agent.sqlite import SqliteAgentStorage\n\nagent = Agent(\n    name=\"Some agent name\",\n    description=AGENT_PROMPT,\n    instructions=AGENT_INSTRUCTIONS,\n    model=agent_llm,\n    markdown=True,\n    retries=3,\n    read_chat_history=True,\n    add_history_to_messages=True,\n    knowledge=text_knowledge_base,\n    search_knowledge=True,\n    storage=SqliteAgentStorage(\n        db_file=\"./data/db.sqlite\", table_name=\"general-kb-agent\"\n    ),\n    user_id=\"common user\",\n)\n\n\n@profile\ndef llm_call():\n    print(\"llm_call...\")\n    resp = agent.run(\"what are these docs about?\")\n    del resp\n\n\n@profile\ndef wait_5_sec():\n    print(\"sleeping for 5 seconds...\")\n    time.sleep(5)\n\n\ndef func():\n    while True:\n        llm_call()\n        wait_5_sec()\n\nfunc()\n```\n\n\n## Agent Configuration (if applicable)\n```python\nagent = Agent(\n    name=\"Some agent name\",\n    description=AGENT_PROMPT,\n    instructions=AGENT_INSTRUCTIONS,\n    model=agent_llm,\n    markdown=True,\n    retries=3,\n    read_chat_history=True,\n    add_history_to_messages=True,\n    knowledge=text_knowledge_base,\n    search_knowledge=True,\n    storage=SqliteAgentStorage(\n        db_file=\"./data/db.sqlite\", table_name=\"general-kb-agent\"\n    ),\n    user_id=\"common user\",\n)\n```\n\n## Expected Behavior\nConsistent and steady memory usage. \n\n## Actual Behavior\nIncreasing memory consumption with each query made to the agent.\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- OS: Ubuntu 24.10\n- Browser (if relevant): (e.g. Chrome 108, Firefox 107)\n- Agno Version: 1.2.6\n- Additional Environment Details: Python 3.12.7\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nTerminal output of the above code\n\n```bash\nllm_call...\n\nLine #    Mem usage    Increment  Occurrences   Line Contents\n=============================================================\n   108    739.9 MiB    739.9 MiB           1   @profile\n   109                                         def llm_call():\n   110    739.9 MiB      0.0 MiB           1       print(\"llm_call...\")\n   111   1114.7 MiB    374.8 MiB           1       resp = agent.run(\"what are these docs about?\")\n   112   1114.7 MiB      0.0 MiB           1       del resp\n\n\nsleeping for 5 seconds...\n\nLine #    Mem usage    Increment  Occurrences   Line Contents\n=============================================================\n   115   1114.7 MiB   1114.7 MiB           1   @profile\n   116                                         def wait_5_sec():\n   117   1114.7 MiB      0.0 MiB           1       print(\"sleeping for 5 seconds...\")\n   118   1114.7 MiB      0.0 MiB           1       time.sleep(5)\n\n\nllm_call...\n\nLine #    Mem usage    Increment  Occurrences   Line Contents\n=============================================================\n   108   1114.7 MiB   1114.7 MiB           1   @profile\n   109                                         def llm_call():\n   110   1114.7 MiB      0.0 MiB           1       print(\"llm_call...\")\n   111   1453.0 MiB    338.3 MiB           1       resp = agent.run(\"what are these docs about?\")\n   112   1453.0 MiB      0.0 MiB           1       del resp\n\n\nsleeping for 5 seconds...\n\nLine #    Mem usage    Increment  Occurrences   Line Contents\n=============================================================\n   115   1453.0 MiB   1453.0 MiB           1   @profile\n   116                                         def wait_5_sec():\n   117   1453.0 MiB      0.0 MiB           1       print(\"sleeping for 5 seconds...\")\n   118   1453.0 MiB      0.0 MiB           1       time.sleep(5)\n\n\nllm_call...\n\nLine #    Mem usage    Increment  Occurrences   Line Contents\n=============================================================\n   108   1453.0 MiB   1453.0 MiB           1   @profile\n   109                                         def llm_call():\n   110   1453.0 MiB      0.0 MiB           1       print(\"llm_call...\")\n   111   1790.3 MiB    337.3 MiB           1       resp = agent.run(\"what are these docs about?\")\n   112   1790.3 MiB      0.0 MiB           1       del resp\n\n\nsleeping for 5 seconds...\n\nLine #    Mem usage    Increment  Occurrences   Line Contents\n=============================================================\n   115   1790.3 MiB   1790.3 MiB           1   @profile\n   116                                         def wait_5_sec():\n   117   1790.3 MiB      0.0 MiB           1       print(\"sleeping for 5 seconds...\")\n   118   1790.3 MiB      0.0 MiB           1       time.sleep(5)\n\n\nllm_call...\n\nLine #    Mem usage    Increment  Occurrences   Line Contents\n=============================================================\n   108   1790.3 MiB   1790.3 MiB           1   @profile\n   109                                         def llm_call():\n   110   1790.3 MiB      0.0 MiB           1       print(\"llm_call...\")\n   111   2127.9 MiB    337.7 MiB           1       resp = agent.run(\"what are these docs about?\")\n   112   2127.9 MiB      0.0 MiB           1       del resp\n\n\nsleeping for 5 seconds...\n\nLine #    Mem usage    Increment  Occurrences   Line Contents\n=============================================================\n   115   2127.9 MiB   2127.9 MiB           1   @profile\n   116                                         def wait_5_sec():\n   117   2127.9 MiB      0.0 MiB           1       print(\"sleeping for 5 seconds...\")\n   118   2127.9 MiB      0.0 MiB           1       time.sleep(5)\n\n\nllm_call...\n\nLine #    Mem usage    Increment  Occurrences   Line Contents\n=============================================================\n   108   2127.9 MiB   2127.9 MiB           1   @profile\n   109                                         def llm_call():\n   110   2127.9 MiB      0.0 MiB           1       print(\"llm_call...\")\n   111   2133.1 MiB      5.1 MiB           1       resp = agent.run(\"what are these docs about?\")\n   112   2133.1 MiB      0.0 MiB           1       del resp\n\n\nsleeping for 5 seconds...\n\nLine #    Mem usage    Increment  Occurrences   Line Contents\n=============================================================\n   115   2133.1 MiB   2133.1 MiB           1   @profile\n   116                                         def wait_5_sec():\n   117   2133.1 MiB      0.0 MiB           1       print(\"sleeping for 5 seconds...\")\n   118   2133.1 MiB      0.0 MiB           1       time.sleep(5)\n\n\nllm_call...\n\nLine #    Mem usage    Increment  Occurrences   Line Contents\n=============================================================\n   108   2133.1 MiB   2133.1 MiB           1   @profile\n   109                                         def llm_call():\n   110   2133.1 MiB      0.0 MiB           1       print(\"llm_call...\")\n   111   2144.9 MiB     11.9 MiB           1       resp = agent.run(\"what are these docs about?\")\n   112   2144.9 MiB      0.0 MiB           1       del resp\n\n\nsleeping for 5 seconds...\n\nLine #    Mem usage    Increment  Occurrences   Line Contents\n=============================================================\n   115   2144.9 MiB   2144.9 MiB           1   @profile\n   116                                         def wait_5_sec():\n   117   2144.9 MiB      0.0 MiB           1       print(\"sleeping for 5 seconds...\")\n   118   2144.9 MiB      0.0 MiB           1       time.sleep(5)\n\n\nllm_call...\n\nLine #    Mem usage    Increment  Occurrences   Line Contents\n=============================================================\n   108   2144.9 MiB   2144.9 MiB           1   @profile\n   109                                         def llm_call():\n   110   2144.9 MiB      0.0 MiB           1       print(\"llm_call...\")\n   111   2158.7 MiB     13.8 MiB           1       resp = agent.run(\"what are these docs about?\")\n   112   2158.7 MiB      0.0 MiB           1       del resp\n\n\nsleeping for 5 seconds...\n\nLine #    Mem usage    Increment  Occurrences   Line Contents\n=============================================================\n   115   2158.7 MiB   2158.7 MiB           1   @profile\n   116                                         def wait_5_sec():\n   117   2158.7 MiB      0.0 MiB           1       print(\"sleeping for 5 seconds...\")\n   118   2158.7 MiB      0.0 MiB           1       time.sleep(5)\n\n\nllm_call...\n\nLine #    Mem usage    Increment  Occurrences   Line Contents\n=============================================================\n   108   2158.7 MiB   2158.7 MiB           1   @profile\n   109                                         def llm_call():\n   110   2158.7 MiB      0.0 MiB           1       print(\"llm_call...\")\n   111   2166.5 MiB      7.8 MiB           1       resp = agent.run(\"what are these docs about?\")\n   112   2166.5 MiB      0.0 MiB           1       del resp\n\n\nsleeping for 5 seconds...\n\nLine #    Mem usage    Increment  Occurrences   Line Contents\n=============================================================\n   115   2166.5 MiB   2166.5 MiB           1   @profile\n   116                                         def wait_5_sec():\n   117   2166.5 MiB      0.0 MiB           1       print(\"sleeping for 5 seconds...\")\n   118   2166.5 MiB      0.0 MiB           1       time.sleep(5)\n\n\nllm_call...\n\nLine #    Mem usage    Increment  Occurrences   Line Contents\n=============================================================\n   108   2166.5 MiB   2166.5 MiB           1   @profile\n   109                                         def llm_call():\n   110   2166.5 MiB      0.0 MiB           1       print(\"llm_call...\")\n   111   2500.7 MiB    334.2 MiB           1       resp = agent.run(\"what are these docs about?\")\n   112   2500.7 MiB      0.0 MiB           1       del resp\n\n\nsleeping for 5 seconds...\n\nLine #    Mem usage    Increment  Occurrences   Line Contents\n=============================================================\n   115   2500.7 MiB   2500.7 MiB           1   @profile\n   116                                         def wait_5_sec():\n   117   2500.7 MiB      0.0 MiB           1       print(\"sleeping for 5 seconds...\")\n   118   2500.7 MiB      0.0 MiB           1       time.sleep(5)\n\n\nllm_call...\n\nLine #    Mem usage    Increment  Occurrences   Line Contents\n=============================================================\n   108   2500.7 MiB   2500.7 MiB           1   @profile\n   109                                         def llm_call():\n   110   2500.7 MiB      0.0 MiB           1       print(\"llm_call...\")\n   111   2835.4 MiB    334.7 MiB           1       resp = agent.run(\"what are these docs about?\")\n   112   2835.4 MiB      0.0 MiB           1       del resp\n\n......\n```\n",
      "state": "closed",
      "author": "pratikGhodke1",
      "author_type": "User",
      "created_at": "2025-04-01T18:14:22Z",
      "updated_at": "2025-06-19T08:45:41Z",
      "closed_at": "2025-06-19T02:44:30Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2632/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2632",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2632",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:27.677514",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Thanks for raising. This is most likely related to memory keeping the chat history and runs history.\nWe are investigating.",
          "created_at": "2025-04-05T12:38:51Z"
        },
        {
          "author": "pratikGhodke1",
          "body": "Just adding, **manually invoking the garbage collector** (gc.collect()) at the end of each run releases some memory. The memory increase happens when we iterate on the LLM response.\n\n```python\n...\n# Line 584-589 agno/agent/agent/Agent._run()\n\n        self.model = cast(Model, self.model)\n        if s",
          "created_at": "2025-04-06T05:01:18Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@pratikGhodke1 Do you have an existing texts collection in Milvus that you are using here? \n\nI'm wondering if the responses that come from Milvus is really big? ",
          "created_at": "2025-04-10T13:15:04Z"
        },
        {
          "author": "pratikGhodke1",
          "body": "@dirkbrnd That is a possibility. I do have data into the Milvus. Each document contains a vector (768 dimensions), content (max 5000 chars), id and metadata (around 100 chars). I fetch 5 records in the RAG system. I cannot share the data though.\n\nThe issue is - that memory not being released in time",
          "created_at": "2025-04-10T15:57:46Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @pratikGhodke1 We have released Memory 2.0. Please give it a try and let us know if it works for you.\nPlease feel free to tag us in case of doubts - we are here to help",
          "created_at": "2025-05-05T08:34:01Z"
        }
      ]
    },
    {
      "issue_number": 3596,
      "title": "[Bug] When I use mode=collaborate, an error occurs, but it works fine with mode=coordinate.",
      "body": "pass",
      "state": "closed",
      "author": "wood02",
      "author_type": "User",
      "created_at": "2025-06-19T07:32:54Z",
      "updated_at": "2025-06-19T08:09:56Z",
      "closed_at": "2025-06-19T08:09:56Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3596/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3596",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3596",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:27.926614",
      "comments": [
        {
          "author": "wood02",
          "body": "pass",
          "created_at": "2025-06-19T08:09:56Z"
        }
      ]
    },
    {
      "issue_number": 3591,
      "title": "[Bug] Problem with tools calling using GhidraMCP",
      "body": "### Description\n\nHello, good afternoon. I’m having an issue using Agno for the Ghidra MCP server created by LaurieWired. The tools seem to load correctly according to the debugger, but when the model tries to recognize the tools, it fails. I have to specify the exact tool I want to use and indicate that it belongs to MCPTools. Additionally, it doesn’t recognize the open Ghidra binary (it should, based on how GhidraMCP works).\n\nAny help you could provide would be greatly appreciated.\n\n### Steps to Reproduce\n\nGenerate the agent as is shown in Agent Configuration\nRun it\n\n\n### Agent Configuration (if applicable)\n\n\n\n\n\n\n    \n    async with MCPTools(server_params=sse_params, transport=\"sse\", timeout_seconds=300) as mcp_ghidra:\n        agent = Agent(\n            model=Gemini(id=\"gemini-2.0-flash\", search=True, api_key=API_KEY),\n            tools=[mcp_ghidra],\n            instructions=dedent(\"\"\"\\\n                You are an expert in reverse engeniering.\n                                You will use the tools provided to analyze a binary file.\n                                You will be precise and concise in your answers.\n                                You will explain the steps you take to analyze the binary.\n\n### Expected Behavior\n\nUse the Ghidra tools to change things in the binary opened\n\n### Actual Behavior\n\nTools added\n![Image](https://github.com/user-attachments/assets/152a5248-4221-4247-8414-042f4b3169c6)\n\nProgram behavior\n![Image](https://github.com/user-attachments/assets/7cd4968f-dcbe-477b-9580-10c163252887)\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n- OS: [Windows 10]\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "ChemaElDeAida",
      "author_type": "User",
      "created_at": "2025-06-18T17:56:36Z",
      "updated_at": "2025-06-19T07:33:19Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3591/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3591",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3591",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:28.103142",
      "comments": [
        {
          "author": "manuhortet",
          "body": "Hey @ChemaElDeAida \n\n- The model indeed won't know which tools come from the MCPTools class, just which tools in general it has access to\n- Based on those debug logs, the agent here is correctly connecting to the MCP server and correctly fetching and ingesting the available tools from the server\n- Y",
          "created_at": "2025-06-19T07:33:19Z"
        }
      ]
    },
    {
      "issue_number": 3167,
      "title": "[Bug] audio_conversation_agent.py --- audio_conversation_agent does not exist",
      "body": "### Description\n\ncookbook/playground/audio_conversation_agent.py --- audio_conversation_agent does not exist\n\nTrying to run the audio demo and an agent does not exist. I can't find it in the codebase.\n\n### Steps to Reproduce\n\n1) try and run the cookbook/playground/audio_conversation_agent.py file\n\n### Agent Configuration (if applicable)\n\nN/A\n\n### Expected Behavior\n\nExpect it to run.\n\n### Actual Behavior\n\npython3 voice.py                \nDEBUG ************************ Agent ID: audio-text-agent ************************              \nDEBUG --**-- Creating Playground Endpoint                                                       \nINFO Starting playground on http://localhost:7777                                               \n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ Agent Playground ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                             ┃\n┃                                                                             ┃\n┃  Playground URL: https://app.agno.com/playground?endpoint=localhost%3A7777  ┃\n┃                                                                             ┃\n┃                                                                             ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\nINFO:     Will watch for changes in these directories: ['/***']\nINFO:     Uvicorn running on http://localhost:7777 (Press CTRL+C to quit)\nINFO:     Started reloader process [47941] using WatchFiles\nDEBUG ************************ Agent ID: audio-text-agent ************************              \nERROR:    Error loading ASGI app. Could not import module \"audio_conversation_agent\".\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n- MacOS\n- Python3\n- venv\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "h55nick",
      "author_type": "User",
      "created_at": "2025-05-12T14:19:09Z",
      "updated_at": "2025-06-19T03:01:31Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3167/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3167",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3167",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:28.302858",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Hi @h55nick \nI ran it locally and it worked for me? Are you testing it from the Agno playground?",
          "created_at": "2025-05-13T15:25:28Z"
        },
        {
          "author": "h55nick",
          "body": "@dirkbrnd I was running it locally in a pip env. Admittedly not sure how to run it in the agno playground - my impression was that I should be able to run the script locally if I have the pip env and LLM creds setup?",
          "created_at": "2025-05-13T16:26:34Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@h55nick I am still unable to reproduce this. Are you on the latest version of Agno? ",
          "created_at": "2025-05-20T14:51:19Z"
        },
        {
          "author": "Mustafa-Esoofally",
          "body": "Hey @h55nick Could you try updating to latest version of Agno and try again?",
          "created_at": "2025-06-19T03:01:31Z"
        }
      ]
    },
    {
      "issue_number": 2848,
      "title": "[Bug] MCP - schema error from OpenAI",
      "body": "# Description\nI want to create mcp servers from an OpenAPI documentation. I am using [mcp-link](https://github.com/automation-ai-labs/mcp-link). The tool schema provided by mcp-link is indeed more complex, but it does the job as i can access and call the tools manually. However, the schema is incompatible with OpenAI. I have seen that in Agno \"inputSchema\" is replaced by \"parameter\" and while this might work for most cases, here it fails.\n\nI believe we should have some schema validation as some MCPs might break the schema. I have found this behavior only when working with mcp-link as other MCP servers I have tested work, but this doesn't assure me that this isn't the only case.\n\n## Steps to Reproduce\nGo to https://mcp-link.vercel.app/links/duckduckgo and generate an url for the DuckDuckGo MCP using mcp-link and use it in the code.\nI used mcp-remote to connect to the url, as SSE is not yet available.\n\n## Agent Configuration (if applicable)\n`import asyncio\nfrom os import getenv\nfrom textwrap import dedent\n\nimport nest_asyncio\nfrom agno.agent import Agent\nfrom agno.models.openai import OpenAIChat\nfrom agno.playground import Playground, serve_playground_app\nfrom agno.tools.mcp import MCPTools\nfrom mcp import StdioServerParameters\n\nnest_asyncio.apply()\nmodel = OpenAIChat(id='gpt-4o', api_key=\"dummy\")\n\nasync def run_server() -> None:\n    \"\"\"Run the GitHub agent server.\"\"\"\n    # Initialize the MCP server\n    server_params = StdioServerParameters(\n        command=\"npx\",\n        args=[\n            \"-y\",\n            \"mcp-remote\",\n            \"https://mcp-openapi-to-mcp-adapter.onrender.com/sse?s=https%3A%2F%2Fgithub.com%2Fautomation-ai-labs%2Fmcp-link%2Fraw%2Frefs%2Fheads%2Fmain%2Fexamples%2Fduckduckgo.yaml&u=https%3A%2F%2Fapi.duckduckgo.com&f=%2B%2F**\"\n        ]\n    )\n\n    # Create a client session to connect to the MCP server\n    async with MCPTools(server_params=server_params) as mcp_tools:\n        agent = Agent(\n            name=\"DuckDuckGo Agent\",\n            model=model,\n            tools=[mcp_tools],\n            instructions=dedent(\"\"\"\\\n                You are a AI assistant that has a tool to search the web to answer the user's question.\n            \"\"\"),\n            markdown=True,\n            add_history_to_messages=True,\n            num_history_responses=3,\n            add_datetime_to_instructions=True,\n            show_tool_calls=True,\n        )\n\n        playground = Playground(agents=[agent])\n        app = playground.get_app()\n\n        serve_playground_app(app)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(run_server())`\n\n## Expected Behavior\nI expected Agno to call the MCP.\n\n## Actual Behavior\nAgno tried to call the MCP, but got \n`openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for function 'mcplink_duckduckgo_search_api_get': True is not of type 'array'.\", 'type': 'invalid_request_error', 'param': 'tools[0].function.parameters', 'code': 'invalid_function_parameters'}}`\n\n## Environment\n- OS: Ubuntu 24.04\n- Agno Version:  v1.3.1\n- Additional Environment Details: Python 3.12\n",
      "state": "closed",
      "author": "anionescubd",
      "author_type": "User",
      "created_at": "2025-04-16T10:14:08Z",
      "updated_at": "2025-06-19T03:00:36Z",
      "closed_at": "2025-06-19T03:00:36Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2848/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2848",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2848",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:28.471378",
      "comments": [
        {
          "author": "shankarbhavani",
          "body": "I am running into same issue when I am using camel framework for agent development and MCP tools.",
          "created_at": "2025-04-18T02:29:31Z"
        },
        {
          "author": "manuhortet",
          "body": "@anionescubd  I can recreate and indeed think we should add some validation to avoid this scenario. We will work on this soon, thanks for reporting!\n\n> I used mcp-remote to connect to the url, as SSE is not yet available.\n\nAnd good news, we added support for SSE already!",
          "created_at": "2025-04-28T08:18:21Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-06-14T00:33:54Z"
        },
        {
          "author": "Mustafa-Esoofally",
          "body": "Hey @anionescubd ! I believe the issue should be resolved. Closing this for now. Feel free to create a new issue if continue facing issues",
          "created_at": "2025-06-19T03:00:36Z"
        }
      ]
    },
    {
      "issue_number": 3151,
      "title": "csv_tools.py not working",
      "body": "# Description\n(agno) ➜  tools git:(main) ✗ python csv_tools.py\nRank,Title,Genre,Description,Director,Actors,Year,Runtime (Minutes),Rating,Votes,Revenue (Millions),Metascore\n▰▱▱▱▱▱▱ Thinking...\n┏━ Message ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                ┃\n┃ What is the average rating of movies?                          ┃\n┃                                                                ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\nTraceback (most recent call last):\n  File \"/root/git/agno/cookbook/tools/csv_tools.py\", line 28, in <module>\n    agent.print_response(\"What is the average rating of movies?\", markdown=True)\n  File \"/root/git/agno/.venv/lib/python3.12/site-packages/agno/agent/agent.py\", line 4725, in print_response\n    run_response = self.run(\n                   ^^^^^^^^^\n  File \"/root/git/agno/.venv/lib/python3.12/site-packages/agno/agent/agent.py\", line 1174, in run\n    return next(resp)\n           ^^^^^^^^^^\n  File \"/root/git/agno/.venv/lib/python3.12/site-packages/agno/agent/agent.py\", line 605, in _run\n    self.update_model(async_mode=False, user_id=user_id, session_id=session_id)\n  File \"/root/git/agno/.venv/lib/python3.12/site-packages/agno/agent/agent.py\", line 2094, in update_model\n    self.model.response_format = None\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'list' object has no attribute 'response_format'\n(agno) ➜  tools git:(main) ✗\n(agno) ➜  tools git:(main) ✗\n",
      "state": "closed",
      "author": "mrprohack",
      "author_type": "User",
      "created_at": "2025-05-10T15:26:43Z",
      "updated_at": "2025-06-19T02:59:31Z",
      "closed_at": "2025-06-19T02:59:31Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3151/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3151",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3151",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:28.675657",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "@mrprohack what version of agno do you have? I just ran on latest with your prompt and it worked for me.",
          "created_at": "2025-05-10T20:49:47Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-06-10T00:34:52Z"
        },
        {
          "author": "Mustafa-Esoofally",
          "body": "Hey @mrprohack I believe the latest version of Agno should solve this issue. Feel free to create a new issue with still face issues",
          "created_at": "2025-06-19T02:59:31Z"
        }
      ]
    },
    {
      "issue_number": 3541,
      "title": "[Bug] Error with o3 pro",
      "body": "### Description\n\nUsing o3 pro, I get this error:\n```\nTraceback (most recent call last):\n  File \"\\venv_new\\Lib\\site-packages\\agno\\models\\openai\\chat.py\", line 328, in invoke\n    return self.get_client().chat.completions.create(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"\\venv_new\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 279, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"\\venv_new\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 914, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"\\venv_new\\Lib\\site-packages\\openai\\_base_client.py\", line 1242, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"\\venv_new\\Lib\\site-packages\\openai\\_base_client.py\", line 919, in request\n    return self._request(\n           ^^^^^^^^^^^^^^\n  File \"\\venv_new\\Lib\\site-packages\\openai\\_base_client.py\", line 1023, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.NotFoundError: Error code: 404 - {'error': {'message': 'This is not a chat model and thus not supported in the v1/chat/completions endpoint. Did you mean to use v1/completions?', 'type': 'invalid_request_error', 'param': 'model', 'code': None}}\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"\\main.py\", line 103, in <module>\n    main()\n  File \"\\main.py\", line 91, in main\n    run_next_migration()\n  File \"\\main.py\", line 86, in run_next_migration\n    _run_migration(next_migration)\n  File \"\\main.py\", line 45, in _run_migration\n    spec.loader.exec_module(module)\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"\\migrations\\model_mocker_fix.py\", line 28, in <module>\n    fix_python_test_errors(path, test, model=model, notes=prompt)\n  File \"\\migration_workflows\\testing_workflows.py\", line 119, in fix_python_test_errors\n    run_code_migration_pipeline(\"error_fix\", prompt, root_path,\n  File \"code_task_pipelines.py\", line 68, in run_code_migration_pipeline\n    output = create_code_migration_guide(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"tools\\code_researcher.py\", line 371, in create_code_migration_guide\n    response: RunResponse = agent.run(prompt, images=images)\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"\\venv_new\\Lib\\site-packages\\agno\\agent\\agent.py\", line 1095, in run\n    raise last_exception\n  File \"\\venv_new\\Lib\\site-packages\\agno\\agent\\agent.py\", line 1053, in run\n    response = self._run(\n               ^^^^^^^^^^\n  File \"\\venv_new\\Lib\\site-packages\\agno\\agent\\agent.py\", line 676, in _run\n    model_response: ModelResponse = self.model.response(\n                                    ^^^^^^^^^^^^^^^^^^^^\n  File \"\\venv_new\\Lib\\site-packages\\agno\\models\\base.py\", line 337, in response\n    assistant_message, has_tool_calls = self._process_model_response(\n                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"\\venv_new\\Lib\\site-packages\\agno\\models\\base.py\", line 539, in _process_model_response\n    response = self.invoke(\n               ^^^^^^^^^^^^\n  File \"\\venv_new\\Lib\\site-packages\\agno\\models\\openai\\chat.py\", line 361, in invoke\n    raise ModelProviderError(\nagno.exceptions.ModelProviderError: This is not a chat model and thus not supported in the v1/chat/completions endpoint. Did you mean to use v1/completions?\n```\n\n### Steps to Reproduce\n\n1. set the model to \"o3-pro-2025-06-10\"\n2. run any prompt\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\no3 pro should be supported\n\n### Actual Behavior\n\no3 pro is not supported\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nwindows\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "SethTurin",
      "author_type": "User",
      "created_at": "2025-06-12T05:54:17Z",
      "updated_at": "2025-06-19T02:57:49Z",
      "closed_at": "2025-06-19T02:57:49Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3541/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3541",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3541",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:28.890097",
      "comments": [
        {
          "author": "Mustafa-Esoofally",
          "body": "Hey @SethTurin ! o3-pro is not supported via the chat endpoint. Could you try using OpenAIResponses?\n\n```\nfrom agno.models.openai import OpenAIResponses\n\nagent = Agent(model=OpenAIResponses(id=\"o3-pro\"), markdown=True)\n```\n\n\nHere's the docs for this: [OpenAI developer docs](https://platform.openai.c",
          "created_at": "2025-06-19T02:57:49Z"
        }
      ]
    },
    {
      "issue_number": 2944,
      "title": "There is a conflict between the implementation of the MCPTools class and the Team Agent pattern.",
      "body": "Nested call issue:\nWhen Team A includes Agent B and Agent B uses MCPTools\nThe contextual lifecycle of MCPTools spans across different asynchronous task boundaries\nCan cause the error 'Attempted to exit cancel scope in a different task than it was focused in'\nWhen an MCPTools instance is shared among multiple agents, it can lead to confusion in asynchronous state management\n\nOf course, I haven't upgraded to the latest version of Team yet. I will gradually update it in the future. I would like to know if this is a bug or if there is a problem with my usage?\n\n![Image](https://github.com/user-attachments/assets/023c8ddc-45c8-4e7f-9997-995b94b04bbd)\n",
      "state": "closed",
      "author": "xuqingwei001",
      "author_type": "User",
      "created_at": "2025-04-23T11:27:02Z",
      "updated_at": "2025-06-19T02:49:23Z",
      "closed_at": "2025-06-19T02:49:23Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2944/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2944",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2944",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:29.063557",
      "comments": [
        {
          "author": "Mustafa-Esoofally",
          "body": "HI @xuqingwei001! You are correct to same this issue. IDeally MCP server should be not shared. Here's what you could try:\n\n1. Give each Agent its own toolkit via \"async with MCPTools(…) as mcp_tools\"\n2. Try leveraging MultiMCPTools if you really want to multiplex a single Python object across multip",
          "created_at": "2025-04-28T13:39:13Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-06-06T00:34:40Z"
        },
        {
          "author": "Mustafa-Esoofally",
          "body": "Hi @xuqingwei001 ! I believe using MultiMCPTools should solve this issue. I am closing this issue for now. Feel free to create a new one if you need help",
          "created_at": "2025-06-19T02:49:23Z"
        }
      ]
    },
    {
      "issue_number": 2937,
      "title": "[Bug] Pass video input into a gemini model from vertext-ai raises an exception",
      "body": "# Description\nPass video input into a gemini model from vertext-ai fails when using the provided video input api from agno.\n\n## Steps to Reproduce\n1. Make an agent using the vertex-ai google models\n  ```\n  model=Gemini(id=\"gemini-2.0-flash\", vertexai=True),\n  ```\n2. Try to pass in a video\n```\nresponse: RunResponse = tool_agent.run(question, videos=[Video(filepath=current_video_segment_path)])\n```\n\n\n## Expected Behavior\nModel should receive video and question and respond correctly.\n\n## Actual Behavior\nAn exception is raised:\n```\nError getting file files/file-name: This method is only supported in the Gemini Developer client.  \n```\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- OS: macOS\n- Agno Version: (agno==1.3.4)\n\n\n## Possible Solutions (optional)\nLoading the byte content from the local file and passing it to the agent works!!.\n\n```\ndef read_video_bytes_from_local_file(path: str) -> bytes:\n    \"\"\"Reads and returns the byte content of a video file.\"\"\"\n    file_path = Path(path)\n    if file_path.is_file():\n        return file_path.read_bytes()\n    else:\n        raise FileNotFoundError(f\"Video file not found at: {path}\")\n\nlocal_content = Path(\"tmp/segment-129846-to-137959.mp4\")\n\nresponse: RunResponse = vertex_ai_agent.run(question, videos=[Video(content=read_video_bytes_from_local_file(local_content))])\npprint_run_response(response, markdown=True)\n```\n\n## Additional Context\n```\nDEBUG Videos added: 1                                                                                             \nINFO Using Vertex AI API                                                                                          \nWARNING  Error getting file files/segment-120-to-10419: This method is only supported in the Gemini Developer     \n         client.                                                                                                  \nTraceback (most recent call last):\n  File \n\"/Users/untilhamza/Developer/bebridge-b2b/test-agno-agent/.venv/lib/python3.12/site-packages/agno/models/google/ge\nmini.py\", line 391, in _format_messages\n    video_file = self._format_video_for_message(video)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \n\"/Users/untilhamza/Developer/bebridge-b2b/test-agno-agent/.venv/lib/python3.12/site-packages/agno/models/google/ge\nmini.py\", line 517, in _format_video_for_message\n    video_file = self.get_client().files.upload(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \n\"/Users/untilhamza/Developer/bebridge-b2b/test-agno-agent/.venv/lib/python3.12/site-packages/google/genai/files.py\n\", line 613, in upload\n    raise ValueError(\nValueError: This method is only supported in the Gemini Developer client.\nWARNING  Failed to load video from                                                                                \n         [Video(filepath='/Users/untilhamza/Developer/bebridge-b2b/test-agno-agent/segment-120-to-10419.mp4',     \n         content=None, format=None)]: This method is only supported in the Gemini Developer client.               \nERROR    Unknown error from Gemini API: contents are required.   \n\n```\n",
      "state": "open",
      "author": "untilhamza",
      "author_type": "User",
      "created_at": "2025-04-23T05:12:20Z",
      "updated_at": "2025-06-19T02:47:36Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2937/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2937",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2937",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:34.243558",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @untilhamza !\n\nVertex AI does not support upload of video files. Though it does allow you to provide a URL of a video. [Read more here](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/video-understanding#gemini-send-multimodal-samples-video-python_genai_sdk)\n\nI just posted a [",
          "created_at": "2025-04-25T04:11:08Z"
        },
        {
          "author": "untilhamza",
          "body": "@ysolanky , thanks for the PR.\n\nI have looked at it.\n\nI disagree with the statement:\n> Vertex AI does not support upload of video files.\n\nAs you can see here:\n```\ndef read_video_bytes_from_local_file(path: str) -> bytes:\n    \"\"\"Reads and returns the byte content of a video file.\"\"\"\n    file_path = P",
          "created_at": "2025-04-26T11:19:03Z"
        },
        {
          "author": "ysolanky",
          "body": "Hello @untilhamza ! You are right that Vertex AI supports video input via bytes, but it sill does not support \"upload\" for videos like it does for Gemini through Google AI Studio, in which the video gets uploaded to the client. \n\nA better fix for this would be to have a custom video upload function ",
          "created_at": "2025-04-28T08:44:10Z"
        },
        {
          "author": "vishalsahab",
          "body": "[Code To Upload Local Video in Vertex AI.txt](https://github.com/user-attachments/files/20462598/Code.To.Upload.Local.Video.in.Vertex.AI.txt)\n\nHello @untilhamza !\n\n\nHere's the code that will solve your problem with uploading local video to Vertex AI.\n\n`def generate():\n    client = genai.Client(\n    ",
          "created_at": "2025-05-27T15:44:53Z"
        },
        {
          "author": "vishalsahab",
          "body": "Local Video Upload in Vertex AI ",
          "created_at": "2025-05-27T15:51:31Z"
        }
      ]
    },
    {
      "issue_number": 2805,
      "title": "[Bug] Unable to use MCPTools with Gemini",
      "body": "# Description\nAsking a Gemini Agent to use an MCP Tool returns [400 Bad Request]\n\n## Steps to Reproduce\nRun the code provided below\n\n## Agent Configuration (if applicable)\n```python\nfrom agno.agent import Agent\nfrom agno.models.google import Gemini\nfrom agno.tools.mcp import MCPTools\nimport asyncio\nfrom dotenv import load_dotenv\nload_dotenv()\n\nasync def run_agent(message: str) -> None:\n    async with MCPTools(\"npx -y @sinco-lab/mcp-youtube-transcript\") as mcp_tools:\n        agent = Agent(\n            model=Gemini(id=\"gemini-2.5-pro-exp-03-25\"),\n            tools=[mcp_tools],\n            instructions=\"Given a video url, fetch the transcript and return it in the structure of MovieScript.\",\n            markdown=True,\n            show_tool_calls=True,\n        )\n\n        await agent.aprint_response(message, stream=True)\n\nif __name__ == \"__main__\":\n    asyncio.run(run_agent(\"https://youtu.be/g6tlNyr5sl8?si=W93SzrkyRBS0ol_3\"))\n```\n```python\nfrom agno.agent import Agent\nfrom agno.models.google import Gemini\nfrom agno.tools.mcp import MultiMCPTools\nimport asyncio\nfrom dotenv import load_dotenv\nload_dotenv()\n\nasync def run_agent(message: str) -> None:\n    async with MultiMCPTools(\n        [\n            \"uvx mcp-server-fetch\",\n            \"npx -y @sinco-lab/mcp-youtube-transcript\",\n        ]\n    ) as mcp_tools:\n        agent = Agent(\n            tools=[mcp_tools],\n            model=Gemini(id=\"gemini-2.5-pro-exp-03-25\"),\n            markdown=True,\n            show_tool_calls=True,\n            use_json_mode=True,\n        )\n\n        await agent.aprint_response(message, stream=True)\n\nif __name__ == \"__main__\":\n    asyncio.run(run_agent(\"https://youtu.be/g6tlNyr5sl8?si=W93SzrkyRBS0ol_3\"))\n```\n## Expected Behavior\nAgent uses tool to get youtube transcript\n\n## Actual Behavior\nReturns [400 Bad Request]\n\n## Screenshots or Logs (if applicable)\n```\nERROR    Error from Gemini API: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Invalid JSON payload   \n         received. Unknown name \"default\" at\n         \\'tools[0].function_declarations[0].parameters.properties[1].value\\': Cannot find field.\\nInvalid JSON  \n         payload received. Unknown name \"default\" at\n         \\'tools[0].function_declarations[0].parameters.properties[2].value\\': Cannot find field.', 'status':    \n         'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.BadRequest',\n         'fieldViolations': [{'field': 'tools[0].function_declarations[0].parameters.properties[1].value',       \n         'description': 'Invalid JSON payload received. Unknown name \"default\" at\n         \\'tools[0].function_declarations[0].parameters.properties[1].value\\': Cannot find field.'}, {'field':   \n         'tools[0].function_declarations[0].parameters.properties[2].value', 'description': 'Invalid JSON payload\n         received. Unknown name \"default\" at\n         \\'tools[0].function_declarations[0].parameters.properties[2].value\\': Cannot find field.'}]}]}}\n▰▱▱▱▱▱▱ Thinking...\n┏━ Message ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                                                               ┃\n┃ https://youtu.be/g6tlNyr5sl8?si=W93SzrkyRBS0ol_3                                                              ┃\n┃                                                                                                               ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\nan error occurred during closing of asynchronous generator <async_generator object stdio_client at 0x000001FA5562DE40>\nasyncgen: <async_generator object stdio_client at 0x000001FA5562DE40>\n  + Exception Group Traceback (most recent call last):\n  |   File \"C:\\Users\\Jason\\pythonAI\\agno-test\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 772, in __aexit__\n  |     raise BaseExceptionGroup(\n  | BaseExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"C:\\Users\\Jason\\pythonAI\\agno-test\\.venv\\Lib\\site-packages\\mcp\\client\\stdio\\__init__.py\", line 173, in stdio_client\n    |     yield read_stream, write_stream\n    | GeneratorExit\n    +------------------------------------\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Jason\\pythonAI\\agno-test\\.venv\\Lib\\site-packages\\mcp\\client\\stdio\\__init__.py\", line 166, in stdio_client\n    async with (\n  File \"C:\\Users\\Jason\\pythonAI\\agno-test\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 778, in __aexit__\n    if self.cancel_scope.__exit__(type(exc), exc, exc.__traceback__):\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Jason\\pythonAI\\agno-test\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 457, in __exit__\n    raise RuntimeError(\nRuntimeError: Attempted to exit cancel scope in a different task than it was entered in\n  + Exception Group Traceback (most recent call last):\n  |   File \"C:\\Users\\Jason\\pythonAI\\agno-test\\main.py\", line 137, in <module>\n  |     asyncio.run(run_agent(\"https://youtu.be/g6tlNyr5sl8?si=W93SzrkyRBS0ol_3\"))\n  |   File \"C:\\Users\\Jason\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\runners.py\", line 190, in run     \n  |     return runner.run(main)\n  |            ^^^^^^^^^^^^^^^^\n  |   File \"C:\\Users\\Jason\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\runners.py\", line 118, in run     \n  |     return self._loop.run_until_complete(task)\n  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  |   File \"C:\\Users\\Jason\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 653, in run_until_complete\n  |     return future.result()\n  |            ^^^^^^^^^^^^^^^\n  |   File \"C:\\Users\\Jason\\pythonAI\\agno-test\\main.py\", line 119, in run_agent\n  |     async with MCPTools(\"npx -y @sinco-lab/mcp-youtube-transcript\") as mcp_tools:\n  |   File \"C:\\Users\\Jason\\pythonAI\\agno-test\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 772, in __aexit__\n  |     raise BaseExceptionGroup(\n  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"C:\\Users\\Jason\\pythonAI\\agno-test\\.venv\\Lib\\site-packages\\agno\\models\\google\\gemini.py\", line 315, in ainvoke_stream\n    |     async for chunk in async_stream:\n    |   File \"C:\\Users\\Jason\\pythonAI\\agno-test\\.venv\\Lib\\site-packages\\google\\genai\\models.py\", line 6558, in async_generator\n    |     response = await self._generate_content_stream(\n    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"C:\\Users\\Jason\\pythonAI\\agno-test\\.venv\\Lib\\site-packages\\google\\genai\\models.py\", line 5504, in _generate_content_stream\n    |     response_stream = await self._api_client.async_request_streamed(\n    |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"C:\\Users\\Jason\\pythonAI\\agno-test\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py\", line 725, in async_request_streamed\n    |     response = await self._async_request(http_request=http_request, stream=True)\n    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"C:\\Users\\Jason\\pythonAI\\agno-test\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py\", line 640, in _async_request\n    |     await errors.APIError.raise_for_async_response(response)\n    |   File \"C:\\Users\\Jason\\pythonAI\\agno-test\\.venv\\Lib\\site-packages\\google\\genai\\errors.py\", line 129, in raise_for_async_response\n    |     raise ClientError(status_code, response_json, response)\n    | google.genai.errors.ClientError: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Invalid JSON payload received. Unknown name \"default\" at \\'tools[0].function_declarations[0].parameters.properties[1].value\\': Cannot find field.\\nInvalid JSON payload received. Unknown name \"default\" at \\'tools[0].function_declarations[0].parameters.properties[2].value\\': Cannot find field.', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.BadRequest', 'fieldViolations': [{'field': 'tools[0].function_declarations[0].parameters.properties[1].value', 'description': 'Invalid JSON payload received. Unknown name \"default\" at \\'tools[0].function_declarations[0].parameters.properties[1].value\\': Cannot find field.'}, {'field': 'tools[0].function_declarations[0].parameters.properties[2].value', 'description': 'Invalid JSON payload received. Unknown name \"default\" at \\'tools[0].function_declarations[0].parameters.properties[2].value\\': Cannot find field.'}]}]}}\n    |\n    | The above exception was the direct cause of the following exception:\n    |\n    | Traceback (most recent call last):\n    |   File \"C:\\Users\\Jason\\pythonAI\\agno-test\\main.py\", line 129, in run_agent\n    |     await agent.aprint_response(message, stream=True)\n    |   File \"C:\\Users\\Jason\\pythonAI\\agno-test\\.venv\\Lib\\site-packages\\agno\\agent\\agent.py\", line 4201, in aprint_response\n    |     async for resp in await self.arun(\n    |   File \"C:\\Users\\Jason\\pythonAI\\agno-test\\.venv\\Lib\\site-packages\\agno\\agent\\agent.py\", line 1114, in _arun\n    |     async for model_response_chunk in model_response_stream:  # type: ignore\n    |   File \"C:\\Users\\Jason\\pythonAI\\agno-test\\.venv\\Lib\\site-packages\\agno\\models\\base.py\", line 605, in aresponse_stream\n    |     async for response in self.aprocess_response_stream(\n    |   File \"C:\\Users\\Jason\\pythonAI\\agno-test\\.venv\\Lib\\site-packages\\agno\\models\\base.py\", line 576, in aprocess_response_stream\n    |     async for response_delta in self.ainvoke_stream(messages=messages):  # type: ignore\n    |   File \"C:\\Users\\Jason\\pythonAI\\agno-test\\.venv\\Lib\\site-packages\\agno\\models\\google\\gemini.py\", line 319, in ainvoke_stream\n    |     raise ModelProviderError(\n    | agno.exceptions.ModelProviderError: <Response [400 Bad Request]>\n    +------------------------------------\n\n## Environment\n- OS: Windows 11\n- Agno Version: 1.2.16\n- Additional Environment Details: Python 3.11\n```",
      "state": "closed",
      "author": "thismart595",
      "author_type": "User",
      "created_at": "2025-04-13T13:22:39Z",
      "updated_at": "2025-06-19T02:45:56Z",
      "closed_at": "2025-06-19T02:45:56Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2805/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "willemcdejongh"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2805",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2805",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:34.439817",
      "comments": [
        {
          "author": "MrJStyle",
          "body": "I got the same issue too. \n\n```\nagno==1.3.1\ngoogle-genai==1.10.0\n```\n\n<img width=\"2179\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/4fd1584f-5581-4a3b-b6b9-ec64088b8360\" />\n\n\n",
          "created_at": "2025-04-16T08:38:53Z"
        },
        {
          "author": "MischaPanch",
          "body": "This might be an upstream issue, I am getting the same with another framework (openhands) but for the preview model `gemini-2.5-pro-preview-03-25`, for the experimental it works. Just wanted to mention, maybe it's relevant here",
          "created_at": "2025-04-18T14:38:10Z"
        },
        {
          "author": "MischaPanch",
          "body": "I fixed this in openhands by just removing the default field\n\nhttps://github.com/All-Hands-AI/OpenHands/pull/7964",
          "created_at": "2025-04-20T21:52:56Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-05-21T00:34:35Z"
        },
        {
          "author": "Mustafa-Esoofally",
          "body": "Hi @thismart595 ! Is this still an issue? Could you try updating Agno to the latest version and try again? \n\nClosing this for now as we have tons of updates to Agno and this be resolved. Feel free to create a new issue if you continue facing issue with the new Agno version",
          "created_at": "2025-06-19T02:43:01Z"
        }
      ]
    },
    {
      "issue_number": 3091,
      "title": "Cookbook Workflows Not Saving Inputs Correctly & Playground Issues | Clarification on Memory 2.0 in Workflows",
      "body": "## Problem Description\nI've been testing the workflows provided in the cookbook and ran into a few problems:\n\n- Input questions are not being saved correctly in the database.\n[https://github.com/agno-agi/agno/issues/2928](url)\n- The playground doesn't seem to function as expected with the current workflow examples. (I don't see the previous chats as input is not being properly saved look for above linked issue for reproducing the steps)\n- However, using agents in cookbook seem to be working fine.\n\nIt would be helpful if the cookbook examples could be updated to reflect the latest working setup.\nAdditionally, I’d like some clarification on how Memory 2.0 should be used within workflows:\n\n- Should each agent inside a workflow have its own instance of Memory 2.0?\n- Or is there support for sharing a single memory context across all agents in a workflow?\n\nThanks in advance, and let me know if I can provide any logs or reproduction steps.\n",
      "state": "open",
      "author": "AjayVarmaK",
      "author_type": "User",
      "created_at": "2025-05-06T06:35:48Z",
      "updated_at": "2025-06-19T00:35:21Z",
      "closed_at": null,
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3091/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3091",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3091",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:34.679484",
      "comments": [
        {
          "author": "Ansub",
          "body": "Hey @AjayVarmaK \n\nCould you let us know which specific cookbook workflow example you used? That’ll help us reproduce the issue on our end. Thanks!",
          "created_at": "2025-05-16T04:23:09Z"
        },
        {
          "author": "AjayVarmaK",
          "body": "Hey @Ansub,  i was using cookbook/workflows/blog_post_generator.py, but i tried 2 others as well, All of em failed.",
          "created_at": "2025-05-19T09:51:14Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-06-19T00:35:21Z"
        }
      ]
    },
    {
      "issue_number": 2703,
      "title": "[Feature Request] MCP in Playground",
      "body": "## Problem Description\n\nIn the context of using Playground, what is the procedure for creating multiple agents that utilize MCP within it?\n```\napp = Playground(\n        agents=agents\n    )\n```\n\n## Proposed Solution\n/\n\n## Alternatives Considered\n/\n\n## Additional context\n/\n\n## Would you like to work on this?\n/\n",
      "state": "closed",
      "author": "lmh87883819",
      "author_type": "User",
      "created_at": "2025-04-06T16:18:45Z",
      "updated_at": "2025-06-18T20:06:05Z",
      "closed_at": "2025-05-13T15:14:44Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 10,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2703/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2703",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2703",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:34.916132",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hey @lmh87883819,\nThank you for using Agno and for reaching out to us!\nWe appreciate you taking the time to raise this feature request. We'll discuss it internally and get back to you shortly.",
          "created_at": "2025-04-07T06:23:02Z"
        },
        {
          "author": "lmh87883819",
          "body": "Thank you for your reply and look forward to your team's discussion @monali7-d ",
          "created_at": "2025-04-07T11:02:07Z"
        },
        {
          "author": "ezyang",
          "body": "This is also a problem for me. An easy way to unblock people is to give up on auto reload functionality and let people call the async endpoint directly to run the playground endpoint.\n\nhttps://github.com/oraios/serena seems to have worked around the problem by just not plugging their MCP into agno a",
          "created_at": "2025-04-12T12:28:41Z"
        },
        {
          "author": "ezyang",
          "body": "So for example, this works:\n\n```\nimport asyncio\nfrom pathlib import Path\nfrom textwrap import dedent\n\nfrom agno.agent import Agent\nfrom agno.playground import Playground\nfrom agno.models.anthropic import Claude\nfrom agno.tools.mcp import MCPTools\nfrom mcp import StdioServerParameters\n\nfrom typing im",
          "created_at": "2025-04-12T14:17:08Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @lmh87883819,\nThank you for reaching out and for using Agno!\n\nWe’ve recently added an example that might be helpful for you:\nhttps://github.com/agno-agi/agno/blob/main/cookbook/playground/mcp_demo.py\n\nFeel free to check it out, and let us know if you have any questions or need further clarificat",
          "created_at": "2025-04-22T12:32:07Z"
        }
      ]
    },
    {
      "issue_number": 3590,
      "title": "[Feature Request] Up to Date llms.txt and llms_full.txt",
      "body": "### Problem Description\n\nI want to feed your docs into an llm to aid with development. Some issues I've come across --\n\n1) docs.agno.com/llms.txt is out of date. For example, it does not have a listing for your pages on the new Teams approach. It only contains the deprecated teams approach.\n\n2) There is no llms_full.txt that I can find. Pydantic AI for example publishes a version that has their full docs in a single markdown file. Your llms.txt only includes links to each section.\n\n3) But, those links to sections are failing to browse (Gemini). I point it at your llms.txt and it reports the browser requests are being blocked and its not able to parse your docs. So the stubs file is useless in this context. Gemini would be the most popular choice for this activity to leverage its 1MM context window. But even then, the quality of response I'd get from asking Gemini to browse 30+ pages one-at-a-time to answer a Q is different than if I can put the whole docs in context all at once.\n\nSo this morning I just ended up rolling my own by scraping the docs site with BS4....\n\n... But, I think it would aid in adoption if folks could more quickly have a full set of your docs to feed into an LLM. And/or if your docs site was accessible to Gemini.\n\nThank you!!\n\n### Proposed Solution\n\n- Script out a refreshed llms.txt and llms_full.txt that do a full build/refresh regularly.\n- Adjust site settings to allow consumer LLMs to browse your docs site.\n\n### Alternatives Considered\n\n- I scraped it myself\n- I could point LLMs at your public git repo, but, I think docs site adds useful context and use patterns vs only the raw code.\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "keithkmyers",
      "author_type": "User",
      "created_at": "2025-06-18T14:33:14Z",
      "updated_at": "2025-06-18T17:45:49Z",
      "closed_at": "2025-06-18T17:45:49Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3590/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3590",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3590",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:35.654455",
      "comments": [
        {
          "author": "keithkmyers",
          "body": "FYI Here is the extractor script, and I am maintaining a copy of the markdown docs within this folder:\nhttps://github.com/keithkmyers/agnostick/tree/main/docs",
          "created_at": "2025-06-18T17:14:45Z"
        },
        {
          "author": "keithkmyers",
          "body": "It looks like this might be better over in the agno-docs repo. I'll move it there. Thanks!",
          "created_at": "2025-06-18T17:45:49Z"
        }
      ]
    },
    {
      "issue_number": 3551,
      "title": "[Bug] V1.60 An error occurred when a team agent used an asynchronous tool",
      "body": "### Description\n\nWhen I used an asynchronous tool in one of my agents, and then the team used this agent, an error occurred during execution in the playground.\nHere is the error message：\n`Traceback (most recent call last): File \"/home/fs-user/project/mutil-agent/.venv/lib/python3.12/site-packages/agno/app/playground/async_router.py\", line 108, in team_chat_response_streamer async for run_response_chunk in run_response: File \"/home/fs-user/project/mutil-agent/.venv/lib/python3.12/site-packages/agno/team/team.py\", line 1372, in _arun_stream async for event in self._ahandle_model_response_stream( File \"/home/fs-user/project/mutil-agent/.venv/lib/python3.12/site-packages/agno/team/team.py\", line 1685, in _ahandle_model_response_stream async for model_response_event in model_stream: File \"/home/fs-user/project/mutil-agent/.venv/lib/python3.12/site-packages/agno/models/base.py\", line 937, in aresponse_stream async for function_call_response in self.arun_function_calls( File \"/home/fs-user/project/mutil-agent/.venv/lib/python3.12/site-packages/agno/models/base.py\", line 1535, in arun_function_calls for item in fc.result: File \"/home/fs-user/project/mutil-agent/.venv/lib/python3.12/site-packages/agno/team/team.py\", line 6063, in forward_task_to_member member_agent_run_response_stream = member_agent.run( ^^^^^^^^^^^^^^^^^ File \"/home/fs-user/project/mutil-agent/.venv/lib/python3.12/site-packages/agno/agent/agent.py\", line 979, in run self.determine_tools_for_model( File \"/home/fs-user/project/mutil-agent/.venv/lib/python3.12/site-packages/agno/agent/agent.py\", line 3588, in determine_tools_for_model agent_tools = self.get_tools( ^^^^^^^^^^^^^^^ File \"/home/fs-user/project/mutil-agent/.venv/lib/python3.12/site-packages/agno/agent/agent.py\", line 3517, in get_tools self._raise_if_async_tools() File \"/home/fs-user/project/mutil-agent/.venv/lib/python3.12/site-packages/agno/agent/agent.py\", line 3493, in _raise_if_async_tools raise Exception( Exception: Async function chat_data can't be used with synchronous agent.run() or agent.print_response(). Use agent.arun() or agent.aprint_response() instead to use this tool.`\n\nI set a breakpoint for debugging and found that a variable in team.py is always False, as shown in the figure below:\n\n![Image](https://github.com/user-attachments/assets/2523d9e2-4129-4dec-9a6e-cb24f11e6a3b)\n\nUpon reviewing the source code, I found that async_mode is a parameter that is hard-coded to False. As a result, the agent within the team consistently executes using the synchronous run method, which causes errors when executing asynchronous tools\n\n\n### Steps to Reproduce\n\n1、Define a tool as an asynchronous tool, for example, name it atool.\n2、Define an agent, for example, name it testagent, and use the tool atool.\n3、Define a team with testagent as its member.\n4、Run the team.\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nfix bug\n\n### Actual Behavior\n\nno\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\ndeepin\npython3.12\nagno v1.60\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "tom1978",
      "author_type": "User",
      "created_at": "2025-06-12T15:36:28Z",
      "updated_at": "2025-06-18T15:09:46Z",
      "closed_at": "2025-06-18T15:09:46Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3551/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3551",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3551",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:35.839038",
      "comments": [
        {
          "author": "monoatomix",
          "body": "@tom1978 this was fixed in latest release",
          "created_at": "2025-06-16T11:10:31Z"
        },
        {
          "author": "tom1978",
          "body": "thanks",
          "created_at": "2025-06-18T15:09:46Z"
        }
      ]
    },
    {
      "issue_number": 3578,
      "title": "[Feature Request] Can it work with Qwen LLM ？",
      "body": "### Problem Description\n\nI'm really struggling to get Qwen LLM to work with Agno when building an agent. I tried using OpenAIChat to use Qwen3, but it's not working right at all. And I couldn’t find any clear steps in the official docs on how to make it happen. Would it be possible to add support for Qwen LLM?\n\n### Proposed Solution\n\nIf possible, could you add support for Qwen LLM?\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [x] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.",
      "state": "open",
      "author": "SCYtelils",
      "author_type": "User",
      "created_at": "2025-06-17T08:11:53Z",
      "updated_at": "2025-06-18T14:35:08Z",
      "closed_at": null,
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3578/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3578",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3578",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:36.075887",
      "comments": [
        {
          "author": "anuragshas",
          "body": "Which inference provider are you using? Alibaba dashscope, ollama, vllm, huggingface endpoints or any other inference provider?",
          "created_at": "2025-06-17T14:52:10Z"
        },
        {
          "author": "Mustafa-Esoofally",
          "body": "Hey @SCYtelils ! Which inference provider are you using for Qwen models? We recommend using Qwen via Together or Groq for easy access. Also you could set it up locally via Ollama / vLLM.\n\nLet us know if you need more help here",
          "created_at": "2025-06-18T14:11:07Z"
        }
      ]
    },
    {
      "issue_number": 3275,
      "title": "[Feature Request] Sequential Team based Agents",
      "body": "### Problem Description\n\nCurrently there's three mode: route, coordinate, and collaborate\n\nHaving Sequential mode for the Team, to allow invoking member by order. Invoke subsequent Agent only after current Agent has completed the tasks and updated team_context.\n\n### Proposed Solution\n\nTeam(\n    mode=\"sequential\"\n)\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [x] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "KageyamaJie",
      "author_type": "User",
      "created_at": "2025-05-21T12:52:42Z",
      "updated_at": "2025-06-18T11:36:56Z",
      "closed_at": "2025-06-18T11:36:56Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3275/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3275",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3275",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:36.273453",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-250/feature-request-sequential-team-based-agents\">SUPPORT-250 [Feature Request] Sequential Team based Agents</a></p>",
          "created_at": "2025-05-21T12:52:45Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @KageyamaJie,\nThank you for reaching out!\n\nWe currently support workflows (sequential flows) within teams. You can check out the docs here for more details:\nhttps://docs.agno.com/examples/workflows/team-workflow#team-workflow\n\nFeel free to reach out if you have any questions — happy to help!",
          "created_at": "2025-06-17T12:38:17Z"
        },
        {
          "author": "KageyamaJie",
          "body": "> Hey [@KageyamaJie](https://github.com/KageyamaJie), Thank you for reaching out!\n> \n> We currently support workflows (sequential flows) within teams. You can check out the docs here for more details: https://docs.agno.com/examples/workflows/team-workflow#team-workflow\n> \n> Feel free to reach out if",
          "created_at": "2025-06-18T11:36:56Z"
        }
      ]
    },
    {
      "issue_number": 3588,
      "title": "[Bug] Unexpected tool timing when upgrading agno from 1.5.6 to any version >=1.6.0, not in debug mode",
      "body": "### Description\n\nThe agent response now include chat messages like:\n\"_select_results(...) completed in 0.0490s.\"\n\n### Steps to Reproduce\n\nRun any team with any tool.\narun(message, stream=True, stream_intermediate_steps=False)\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nNo unexpected messages\n\n### Actual Behavior\n\n\"_select_results(...) completed in 0.0490s.\"\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n- Os: MacOS\n- Agno: 1.6.2\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "onesecurity-app",
      "author_type": "User",
      "created_at": "2025-06-18T09:33:30Z",
      "updated_at": "2025-06-18T10:10:52Z",
      "closed_at": "2025-06-18T10:10:52Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3588/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3588",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3588",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:36.491225",
      "comments": [
        {
          "author": "onesecurity-app",
          "body": "Resolved it by adding filtering to chunks being sent:\n\n```\nasync for chunk in await agent_instance.arun(message, stream=True, stream_intermediate_steps=False):\n          if chunk.content:\n              if chunk.event == \"TeamToolCallCompleted\":\n                  continue\n              await websocke",
          "created_at": "2025-06-18T10:10:39Z"
        }
      ]
    },
    {
      "issue_number": 3562,
      "title": "[Bug] Message history not fully loading on new agent instances",
      "body": "### Description\n\nMessage history using storage is not fully loading old messages on new agent instances when using the same user_id and session_id.\n\n### Steps to Reproduce\n\n```python\nimport os\n\nfrom agno.agent import Agent\nfrom agno.models.openai import OpenAIChat\nfrom agno.storage.sqlite import SqliteStorage\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n\ndef get_agent(user_id, session_id):\n    return Agent(\n        model=OpenAIChat(id=\"gpt-4.1-nano\", api_key=os.getenv(\"OPENAI_API_KEY\")),\n        storage=storage,\n        add_history_to_messages=True,\n        num_history_runs=5,\n        user_id=user_id,\n        session_id=session_id,\n    )\n\n\nuser_id = \"123\"\nsession_id = \"123\"\n\nstorage = SqliteStorage(\n    table_name=\"agent_sessions\",\n    db_file=\"tmp/ai.db\",\n)\n\n# Clear session\nstorage.delete_session(session_id=session_id)\n\nr = get_agent(user_id, session_id).run(\"this is my first message\")\n[print(m.content) for m in r.messages]\n\nprint(\"-\" * 100)\n\nr = get_agent(user_id, session_id).run(\"what was my first message?\")\n[print(m.content) for m in r.messages]\n\n```\n\nRunning this code on v1.6.0 prints:\n```\nthis is my first message\nHello! Welcome! How can I assist you today?\n----------------------------------------------------------------------------------------------------\nthis is my first message\nHello! Welcome! How can I assist you today?\nwhat was my first message?\nYour first message was: \"this is my first message.\"\n```\n^ This is right. On the second run the entire history is passed to the LLM.\n\nBut on v1.6.1 and v1.6.2, this is the output:\n```\nthis is my first message\nHello! Welcome to the chat. How can I assist you today?\n----------------------------------------------------------------------------------------------------\nwhat was my first message?\nYour first message was: \"what was my first message?\"\n```\n\nthe second run is not fully loaded.\n\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\n```\nthis is my first message\nHello! Welcome! How can I assist you today?\n----------------------------------------------------------------------------------------------------\nthis is my first message\nHello! Welcome! How can I assist you today?\nwhat was my first message?\nYour first message was: \"this is my first message.\"\n```\n\n### Actual Behavior\n\n```\nthis is my first message\nHello! Welcome to the chat. How can I assist you today?\n----------------------------------------------------------------------------------------------------\nwhat was my first message?\nYour first message was: \"what was my first message?\"\n```\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nOS: Windows\nPython 3.13.1\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "renanmoretto",
      "author_type": "User",
      "created_at": "2025-06-13T19:50:02Z",
      "updated_at": "2025-06-18T10:08:09Z",
      "closed_at": "2025-06-18T10:08:09Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3562/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3562",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3562",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:36.652655",
      "comments": [
        {
          "author": "renanmoretto",
          "body": "This was introduced here https://github.com/agno-agi/agno/commit/73bc4b4ce65c277de55ec582fa48d2e183aeb1e4\nFile `libs/agno/agno/agent/agent.py`\n```python\nhistory = self.memory.get_messages_from_last_n_runs(\n    session_id=session_id, last_n=self.num_history_runs, skip_role=self.system_message_role\n  ",
          "created_at": "2025-06-13T20:09:19Z"
        },
        {
          "author": "ppsid24",
          "body": "+1\n\nI'm working on a chatbot, and I'm using mongodb as storage for my use case. In version 1.6.0, when I look at the document's content, `doc[\"memory\"][\"runs\"]` is a list which contains all the runs for a given session. The last run in this list, i.e, `doc[\"memory\"][\"runs\"][-1][\"messages\"]`, contain",
          "created_at": "2025-06-16T11:41:23Z"
        },
        {
          "author": "dirkbrnd",
          "body": "We are fixing this asap!",
          "created_at": "2025-06-16T21:41:30Z"
        },
        {
          "author": "celobusana",
          "body": "> +1\n> \n> I'm working on a chatbot, and I'm using mongodb as storage for my use case. In version 1.6.0, when I look at the document's content, `doc[\"memory\"][\"runs\"]` is a list which contains all the runs for a given session. The last run in this list, i.e, `doc[\"memory\"][\"runs\"][-1][\"messages\"]`, c",
          "created_at": "2025-06-17T00:02:46Z"
        },
        {
          "author": "elvizlai",
          "body": "agno==1.6.0 works, but not 1.6.2",
          "created_at": "2025-06-17T09:44:12Z"
        }
      ]
    },
    {
      "issue_number": 3555,
      "title": "[Bug] '_tool_instructions' repeated N times in system prompt",
      "body": "### Description\n\nThere's a bug in the implementation related to `_tool_instructions` attribute of the `Agent` class. New `_tool_instructions` are appended to the existing ones every time `determine_tools_for_model()` is called, but they're never cleared between runs.\n\nIn this way, after every run the system prompt will keep growing in size, with duplicated instructions. The number of repetition will be equal to the number of times `determine_tools_for_model()` is called.\n\nThe code resets `self._tools_for_model` and `self._functions_for_model` at the start of the method, but it doesn't reset `self._tool_instructions`. This means that every time `run()` or `arun()` is called, it appends to the existing tool instructions, causing the instructions to be duplicated in the system prompt.\n\n### Steps to Reproduce\n\n1. See the provided code at the section Agent Configuration\n\n### Agent Configuration (if applicable)\n\n```python\nfrom agno.agent import Agent\nfrom agno.tools import Toolkit\nfrom textwrap import dedent\nimport os\nfrom agno.models.azure import AzureOpenAI\nfrom rich import print as rprint\n\nAZURE_OPENAI_MODEL = AzureOpenAI(\n    id=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_ID\"),\n    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n    temperature=0.0,\n)\n\nclass CoolToolkit(Toolkit):\n    def __init__(self, **kwargs):\n        super().__init__(name=\"CoolToolkit\", tools=[self.cool_tool], **kwargs)\n        self.instructions = dedent(\n            \"\"\"\n        <toolkit_instructions>\n        This is a placeholder toolkit for demonstration purposes.\n        </toolkit_instructions>\n        \"\"\"\n        )\n\n    def cool_tool(self, input_data):\n        return f\"Cool tool processed: {input_data}\"\n\nagent = Agent(\n    name=\"CoolAgent\",\n    tools=[CoolToolkit(add_instructions=True)],\n    model=AZURE_OPENAI_MODEL,\n)\n\nN_ITER = 5\nfor _ in range(N_ITER):\n    response = agent.run(\"Hello :)\", stream=False)\n    rprint(response.content)\n\"\"\"\nHello! 😊 How can I help you today?\nHello! 😊 How can I help you today?\nHello! 😊 How can I help you today?\nHello! 😊 How can I help you today?\nHello! 😊 How can I help you today?\n\"\"\"\n\nassert len(agent._tool_instructions) == N_ITER, f\"Expected {N_ITER} tool instructions, got {len(agent._tool_instructions)}\"\n\nfor instruction in agent._tool_instructions:\n    print(instruction)\n\n\"\"\"\n<toolkit_instructions>\nThis is a placeholder toolkit for demonstration purposes.\n</toolkit_instructions>\n\n<toolkit_instructions>\nThis is a placeholder toolkit for demonstration purposes.\n</toolkit_instructions>\n\n(...)\n\"\"\"\n```\n\n### Expected Behavior\n\nThe toolkits descriptions should be added to the system prompt of the agents only once.\n\n### Actual Behavior\n\nThe toolkits descriptions should are added to the system prompt N times, where N is the number of times `determine_tools_for_model()` got called.\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n- OS: 20.04.1-Ubuntu\n- Agno version: 1.5.10 | 1.6.0\n- Python 3.11.11\n```\n\n### Possible Solutions (optional)\n\n\n```python\n# Proposed fix (the actual fix requires to update the determine_tools_for_model both for the Agent and the Team class\nclass FixedAgent(Agent):\n    def determine_tools_for_model(\n        self,\n        *args,\n        **kwargs\n    ) -> None:\n        self._tool_instructions = None\n        super().determine_tools_for_model(*args, **kwargs)\n\nfixed_agent = FixedAgent(\n    name=\"FixedAgent\",\n    tools=[CoolToolkit(add_instructions=True)],\n    model=AZURE_OPENAI_MODEL,\n)\n\nfor _ in range(N_ITER):\n    response = fixed_agent.run(\"Hello :)\", stream=False)\n    rprint(response.content)\n\"\"\"\nHello! 😊 How can I help you today?\nHello! 😊 How can I help you today?\nHello! 😊 How can I help you today?\nHello! 😊 How can I help you today?\nHello! 😊 How can I help you today?\n\"\"\"\n\nassert len(fixed_agent._tool_instructions) == 1, f\"Expected 1 tool instructions, got {len(agent._tool_instructions)}\"\n\nfor instruction in fixed_agent._tool_instructions:\n    print(instruction)\n\"\"\"\n<toolkit_instructions>\nThis is a placeholder toolkit for demonstration purposes.\n</toolkit_instructions>\n\"\"\"\n```\n\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "GitMarco27",
      "author_type": "User",
      "created_at": "2025-06-13T09:22:56Z",
      "updated_at": "2025-06-18T10:08:03Z",
      "closed_at": "2025-06-18T10:08:03Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3555/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3555",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3555",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:36.842371",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Thanks for fixing. \nReleasing asap!\n",
          "created_at": "2025-06-16T22:04:31Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Released with [1.6.3](https://github.com/agno-agi/agno/releases/tag/v1.6.3)!",
          "created_at": "2025-06-18T10:08:03Z"
        }
      ]
    },
    {
      "issue_number": 3376,
      "title": "[Bug] Agent response to Team contains too much information",
      "body": "### Description\n\nIn agno version 1.5.0, when the agent responded to the team coordinator it answered with a response that encapsulated the information obtained from the tools.\n\nIn agno 1.5.1, I have seen that the agent returns to the coordinator a concatenated string with the answers from the tools and the final answer. If the tool returns a large string, then it will be concatenated to the answer that basically summarizes it at the end. This issue is further amplified if I use reasoning tools. Every thought of the agent is further concatenated to the response to the coordinator.\n\nThis is not good as we basically have duplicated information and the context starts to fill up pretty quickly.\n\n### Steps to Reproduce\n\nIf you have a team with any agent, you can see this issue.\n\n### Agent Configuration (if applicable)\n\n```import asyncio\nfrom os import getenv\nfrom textwrap import dedent\n\nimport nest_asyncio\nfrom agno.agent import Agent\nfrom agno.models.openai import OpenAIChat\nfrom agno.team.team import Team\nfrom agno.playground import Playground, serve_playground_app\nfrom agno.storage.agent.sqlite import SqliteAgentStorage\nfrom agno.tools.mcp import MCPTools\n\n# Allow nested event loops\nnest_asyncio.apply()\n\n\nasync def run_server() -> None:\n    \"\"\"Run the GitHub agent server.\"\"\"\n\n    # Create a client session to connect to the MCP server\n    async with MCPTools(\"npx -y exa-mcp-server --tools=web_search_exa,research_paper_search,company_research,crawling,competitor_finder,linkedin_search,wikipedia_search_exa,github_search\", env={\"EXA_API_KEY\": \"api_key\"}) as mcp_tools:\n        agent = Agent(\n            name=\"MCP Exa tools\",\n            tools=[mcp_tools],\n            instructions=dedent(\"\"\"\\\n               You are an agent.\n            \"\"\"),\n            model=OpenAIChat(id=\"gpt-4o\", api_key=\"api_key\"),\n            add_history_to_messages=True,\n            num_history_responses=3,\n            add_datetime_to_instructions=True,\n            markdown=True,\n        )\n        \n        team = Team(\n            name=\"MCP Exa Tools Team\",\n            members=[agent],\n            model=OpenAIChat(id=\"gpt-4o\", api_key=\"api_key\"),\n            instructions=dedent(\"\"\"\\\n                You are a team of agents that can use the MCP Exa tools.\n                You can use the tools to search the web, find research papers, and more.\n                Use the tools to answer questions and solve problems.\n            \"\"\"),\n        )\n\n        playground = Playground(agents=[agent], teams=[team])\n        app = playground.get_app()\n\n        # Serve the app while keeping the MCPTools context manager alive\n        serve_playground_app(app)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(run_server())```\n\n### Expected Behavior\n\nI would like the agent to return only the answer to the task it was supposed to do, not a full breakdown with the outputs of all the tools and steps it has taken. This was the case in Agno version 1.5.0.\n\n### Actual Behavior\n\nThe team coordinator recieves too much information which causes the context to fill up. Furthermore, this is basically duplicated information that would have also been sent regardless in the final answer. This seems to have been caused in version 1.5.1, as in 1.5.0 it was working ok.\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nAgno: 1.5.1\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "andreiionut1411",
      "author_type": "User",
      "created_at": "2025-05-27T15:09:23Z",
      "updated_at": "2025-06-18T10:01:13Z",
      "closed_at": "2025-06-18T10:01:13Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3376/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3376",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3376",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:37.023485",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-329/bug-agent-response-to-team-contains-too-much-information\">SUPPORT-329 [Bug] Agent response to Team contains too much information</a></p>",
          "created_at": "2025-05-27T15:09:26Z"
        },
        {
          "author": "andreiionut1411",
          "body": "I can provide an example of what the agent returns if you need it, in case I explained poorly in the description above.",
          "created_at": "2025-05-27T15:19:15Z"
        },
        {
          "author": "andreiionut1411",
          "body": "After a bit of digging I have identified the cause of this. In the atransfer_task_to_member function there is this line:\n`yield \",\".join([tool.result for tool in member_agent_run_response_chunk.tools if tool.result])`\n\nThe line concatenates all the tools responses which is not ideal, especially when",
          "created_at": "2025-05-29T09:58:17Z"
        },
        {
          "author": "andreiionut1411",
          "body": "It seems that this issue was solved in version 1.6.2, so I am closing this.",
          "created_at": "2025-06-18T10:01:13Z"
        }
      ]
    },
    {
      "issue_number": 3585,
      "title": "[Feature Request] Monitoring Track Session ID",
      "body": "### Problem Description\n\nWhen monitoring the sessions created for the team have the text that was sent to the team/agent which makes it difficult to trace which session it is.\n\n<img width=\"590\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/bfed671c-0d10-4876-99b4-fb3efc3a1238\" />\n\n\n\n### Proposed Solution\n\nCan we add the session id to the UI or allow customization of how the session is displayed on the UI session dashboard.\n\n\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [x] I’m open to collaborating but need guidance.\n- [x] No, I’m just sharing the idea.",
      "state": "open",
      "author": "tmuzanenhamo",
      "author_type": "User",
      "created_at": "2025-06-18T08:13:37Z",
      "updated_at": "2025-06-18T08:14:34Z",
      "closed_at": null,
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3585/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3585",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3585",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:38.819666",
      "comments": []
    },
    {
      "issue_number": 3434,
      "title": "[Feature Request]  nebius embedder model integration",
      "body": "### Problem Description\n\nadd  nebuis embedder model integration\nhttps://discord.com/channels/965734768803192842/965734768803192845/1378378793693216790\n\n### Proposed Solution\n\nhttps://docs.nebius.com/studio/inference/models/embedding\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "Ayush0054",
      "author_type": "User",
      "created_at": "2025-05-31T16:07:40Z",
      "updated_at": "2025-06-18T04:09:25Z",
      "closed_at": "2025-06-17T12:47:24Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3434/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3434",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3434",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:38.819694",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-354/feature-request-nebius-embedder-model-integration\">SUPPORT-354 [Feature Request] nebius embedder model integration</a></p>",
          "created_at": "2025-05-31T16:07:43Z"
        },
        {
          "author": "dirkbrnd",
          "body": "This was released!",
          "created_at": "2025-06-18T04:09:25Z"
        }
      ]
    },
    {
      "issue_number": 3566,
      "title": "[Bug]  How to ensure atomic operations for concurrent modifications",
      "body": "### Description\n\nHow to ensure the atomic operation of concurrent modification when calling the Team arun method by modifying the placeholders in instructions through variables in the context.\n\n### Steps to Reproduce\n\ndef create_social_team(\n    model=Gemini(id=\"gemini-2.5-flash-preview-05-20\"),\n    debug_mode=True,\n    monitor=True,\n    reasoning=True,\n):\n    return Team(\n        name=\"Social Media Content Creation Team\",\n        mode=\"coordinate\", #coordination\n        model=model,\n        team_id=\"1\",\n        context={\"role_info\":get_role_info,\"back_ground\":get_back_ground,\"account_target\":get_account_target},\n        team_session_state={},\n        add_state_in_messages=True,\n        members=[\n            trend_with_grok_agent(\n                debug_mode = debug_mode,\n                monitor=monitor,\n                reasoning=reasoning\n            ),\n\n            create_content_creation_agent(\n                model=model,\n                debug_mode=debug_mode,\n                monitor=monitor,\n                reasoning=reasoning\n            )\n        ],\n\n        description=dedent(\"\"\"\\\n        This is a streamlined tweet creation team consisting of a trend analyst and a content creator.\n        The team will create high-quality, impactful tweets based on the specified role positioning and target audience.\n        Each team member will focus on their core expertise to deliver the best results.\n        \"\"\"),\n\n        instructions=dedent(\"\"\"\\\n        Team Collaboration Process:\n\n        1. Trend Analyst (Grok Agent) Responsibilities:\n           - Analyze current market trends and hot topics based on {back_ground}\n           - Identify emerging patterns and opportunities\n           - Evaluate market dynamics and audience interests\n           - Provide actionable trend insights\n           - All analysis must be in English\n           - Output: A structured trend report with key insights\n\n        2. Content Creator Responsibilities:\n           - Receive and analyze trend insights from Trend Analyst\n           - Create engaging tweets aligned with {account_target}\n           - Ensure content matches {role_info} positioning\n           - Maintain 280 character limit\n           - Focus on engagement and shareability\n           - All content must be in English\n           - Output: Final tweet content with creation rationale\n\n        Collaboration Flow:\n        1. Trend Analyst initiates with market analysis\n        2. Content Creator reviews insights and creates content\n        3. Both agents collaborate to refine the final output\n\n        Quality Standards:\n        - Professional and engaging content\n        - Timely and relevant topics\n        - Strict 280 character limit\n        - All communication in English\n        - Clear alignment with target audience\n        - Consistent brand voice\n        \"\"\"),\n\n        success_criteria=dedent(\"\"\"\\\n        1. Content Quality: The tweet is professional and engaging\n        2. Audience Match: The tweet aligns with {account_target} interests\n        3. Brand Consistency: The tweet style matches {role_info} positioning\n        4. Length Control: The tweet content is within 280 characters\n        5. Language Requirement: All content must be in English\n        \"\"\"),\n\n        expected_output=dedent(\"\"\"\\\n        1. Complete tweet content (in English):\n           - Main content (within 280 characters)\n        2. Creation process (in English):\n           - Trend analysis insights\n           - Content creation strategy\n        3. Brief explanation (in English):\n           - Target audience analysis\n           - Expected engagement effects\n        \"\"\"),\n\n        add_datetime_to_instructions=True,\n        debug_mode=debug_mode,\n        monitoring=monitor,\n        reasoning=reasoning,\n        add_member_tools_to_system_message=False,\n        enable_agentic_context=True,\n        share_member_interactions=True,\n        show_members_responses=True,\n        markdown=True,\n        storage=get_team_storage(),\n        memory=get_team_memory(),\n        enable_user_memories=True,\n        enable_session_summaries=True,\n    )\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nCustomize the system prompt word modification to achieve atomic operations\n\n### Actual Behavior\n\nConcurrent requests to modify the placeholders of instructions will result in confusion\n\n### Screenshots or Logs (if applicable)\n\nConcurrent requests to modify the placeholders of instructions will result in confusion\n\n### Environment\n\n```markdown\nv1.6.0\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "jiafuzeng",
      "author_type": "User",
      "created_at": "2025-06-14T12:44:42Z",
      "updated_at": "2025-06-18T01:55:28Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3566/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3566",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3566",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:39.045940",
      "comments": [
        {
          "author": "Mustafa-Esoofally",
          "body": "Hi @jiafuzeng ! I am little confused here. Could you elaborate more on the use case and what exactly is expected behaviour",
          "created_at": "2025-06-18T01:55:28Z"
        }
      ]
    },
    {
      "issue_number": 3197,
      "title": "[Feature Request]",
      "body": "### Problem Description\n\n Want support for 2 features using local LLMs\n- create_user_memories\n- create_session_summary\n\n### Proposed Solution\n\nAccording to me there should be some changes to the update_model() function present in the classifier.py, manager.py and summarizer.py to allow local models.\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\nEveryone cannot afford to use an OpenAI model due to cost constraints. So, please provide support for local LLMs.\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [x] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "Kartikeya-Sinha",
      "author_type": "User",
      "created_at": "2025-05-14T18:07:19Z",
      "updated_at": "2025-06-17T12:51:06Z",
      "closed_at": "2025-06-17T12:51:06Z",
      "labels": [
        "enhancement",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3197/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3197",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3197",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:39.205783",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-06-15T00:39:17Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @Kartikeya-Sinha \nThanks for sharing this — I’ve forwarded it to our team for discussion.\n\nWhile we don’t have a timeline to commit to just yet due to other priorities, if we decide to pursue this, we’ll be sure to keep you updated and add it to our roadmap.\n\nAppreciate your input!",
          "created_at": "2025-06-17T12:51:06Z"
        }
      ]
    },
    {
      "issue_number": 3433,
      "title": "[Bug] Clarify Usage of progress_callback in MCP Tool Calls",
      "body": "### Description\n\nThe `progress_callback` parameter in MCP tool calls lacks clear documentation and implementation examples, making it difficult to implement progress tracking for long-running operations.\n\n\n### Steps to Reproduce\n\n## Steps to Reproduce\n1. Create a session with MCP client\n2. Attempt to use progress_callback in a tool call:\n```python\nasync def progress_handler(progress, status, data):\n    print(f\"Progress: {progress}\")\n\nresult = await session.call_tool(\n    name=\"long_running_tool\",\n    arguments={\"param\": \"value\"},\n    progress_callback=progress_handler\n)\n```\n3. Observe lack of documentation on callback parameters and usage\n\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\n- Clear documentation on callback function signature\n- Examples of proper implementation\n- Type definitions for callback parameters\n- Guidelines for handling progress updates\n\n### Actual Behavior\n\n- No clear documentation on callback implementation\n- Unclear parameter types and usage\n- No examples provided\n- Difficult to implement progress tracking\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n- MCP client version: latest\n- Python version: 3.13\n- OS: macOS 24.5.0\n- agno: 1.5.5\n```\n\n### Possible Solutions (optional)\n\n1. Add comprehensive documentation for progress_callback\n2. Provide type definitions:\n```python\nclass ProgressCallback(Protocol):\n    async def __call__(\n        self,\n        progress: float,  # 0.0 to 1.0\n        status: str,      # Current status message\n        data: dict | None # Additional progress data\n    ) -> None:\n        ...\n```\n3. Include usage examples\n4. Add best practices for implementation\n\n### Additional Context\n\nCommon use cases for progress callbacks:\n- File uploads/downloads\n- Data processing\n- Long-running API calls\n- Batch operations",
      "state": "closed",
      "author": "zhuayi",
      "author_type": "User",
      "created_at": "2025-05-31T11:12:47Z",
      "updated_at": "2025-06-17T12:46:42Z",
      "closed_at": "2025-06-17T12:46:42Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3433/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3433",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3433",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:39.416249",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-353/bug-clarify-usage-of-progress-callback-in-mcp-tool-calls\">SUPPORT-353 [Bug] Clarify Usage of progress_callback in MCP Tool Calls</a></p>",
          "created_at": "2025-05-31T11:12:50Z"
        },
        {
          "author": "manuhortet",
          "body": "Hey @zhuayi, thanks for the request! Please help me understand it better.\n\nOur MCP integration (the MCPTools and MultiMCPTools classes) is focused on serving the tools available in an MCP server to Agno Agents and Teams. That means running the MCP server if needed, setting up the MCP client, and pro",
          "created_at": "2025-06-03T08:28:01Z"
        },
        {
          "author": "zhuayi",
          "body": "yes!\nI have modified the source code of AGNO's `./agno/utils/mcp.py` and it is now running. \n I look forward to the support of the agno framework.\nThe modifications are as follows\n\n<img width=\"1004\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/4a037218-6f26-4694-89ee-034b2719d937\" />\n",
          "created_at": "2025-06-03T09:41:39Z"
        },
        {
          "author": "manuhortet",
          "body": "This looks fantastic @zhuayi, thanks for going ahead and working on this.\n\nYou can open a pull request with the change if you want! Else let me know and I'll get to it myself.",
          "created_at": "2025-06-04T10:48:26Z"
        },
        {
          "author": "zhuayi",
          "body": "I hope you handle it more elegantly, THK! @manuhortet ",
          "created_at": "2025-06-05T10:03:01Z"
        }
      ]
    },
    {
      "issue_number": 3288,
      "title": "[Bug] `logprobs` not accessible",
      "body": "### Description\n\nThe logprobs (for openai returned in `response.choices[0].logprobs`) are currently not accessible. `ModelResponse` and `Message` should include them as a field\n\n### Steps to Reproduce\n\nAny agent setup that includes logprobs\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\n`run.messages[0].logprobs` should provide a `openai.types.chat.chat_completion.ChoiceLogprobs` object if it is returned by the provider client\n\n### Actual Behavior\n\nInformation is discarded\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n- agno v1.5.3\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "ValeKnappich",
      "author_type": "User",
      "created_at": "2025-05-22T09:22:09Z",
      "updated_at": "2025-06-17T12:32:06Z",
      "closed_at": "2025-06-17T12:32:06Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3288/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3288",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3288",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:39.630101",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-264/bug-logprobs-not-accessible\">SUPPORT-264 [Bug] `logprobs` not accessible</a></p>",
          "created_at": "2025-05-22T09:22:13Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Thanks for raising! We have made this a feature request",
          "created_at": "2025-05-26T10:57:10Z"
        }
      ]
    },
    {
      "issue_number": 3306,
      "title": "Thinking Summaries - Gemini 2.5 pro",
      "body": "### Problem Description\n\nAre there plans to support: [https://ai.google.dev/gemini-api/docs/thinking?hl=pt-br#summaries](https://ai.google.dev/gemini-api/docs/thinking?hl=pt-br#summaries) ?\n\n### Proposed Solution\n\nOnly Feature Request\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "waynermaia",
      "author_type": "User",
      "created_at": "2025-05-22T19:53:14Z",
      "updated_at": "2025-06-17T12:30:57Z",
      "closed_at": "2025-06-17T12:30:57Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3306/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3306",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3306",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:39.847413",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-271/thinking-summaries-gemini-25-pro\">SUPPORT-271 Thinking Summaries - Gemini 2.5 pro</a></p>",
          "created_at": "2025-05-22T19:53:17Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @waynermaia \nThanks so much for reaching out!\n\nAt the moment, **Gemini 2.5 Pro’s thinking summaries** are considered experimental, so we haven’t prioritised them just yet. That said, we’ll definitely revisit this request in the future once we’re through our current priorities.\n\nAppreciate you fl",
          "created_at": "2025-06-17T12:30:57Z"
        }
      ]
    },
    {
      "issue_number": 3139,
      "title": "[Feature Request] Allow Configuration of ensure_ascii for JSON Serialization to Support Non-ASCII Characters",
      "body": "## Problem Description\nI'm working with agno in french and I frequently encounter encoding issues with the model response. As an exemple, I get \" l'ann\\u0000e9e \" instead of \" l'année \". After some digging, I think the issue is related to the json library functions. \n\n## Proposed Solution\nI think the option to choose the ensure_ascii parameter should be given at agent creation. This would improve the quality of results with languages that use characters outside the ascii table, such as french.\n\n## Alternatives Considered\n\n## Additional context\nI had similar issues with other tools I use, which I fixed by adding ensure_ascii=False as an additional parameter for the json functions\nExemple : json.dumps(text) to json.dumps(text, ensure_ascii=False)\n\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[ ] Yes, I’d love to work on it!**\n**[ ] I’m open to collaborating but need guidance.**\n**[X] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "Magma3X",
      "author_type": "User",
      "created_at": "2025-05-09T13:35:10Z",
      "updated_at": "2025-06-17T12:21:55Z",
      "closed_at": "2025-06-17T12:21:55Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3139/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3139",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3139",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:40.057705",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hey there! 😊\n\nThank you so much for reaching out and for your support for Agno — it truly means a lot to us. We’ve added your suggestion to our roadmap! Since Agno is open source, you’re more than welcome to take a stab at it yourself — and we’d be more than happy to support you along the way.\n\nLook",
          "created_at": "2025-05-12T13:28:30Z"
        },
        {
          "author": "KinonoChen",
          "body": "这个问题我在某个方法里修复过，也提交了pr，但是貌似有太多地方需要修改ensure_ascii=False",
          "created_at": "2025-05-15T02:01:32Z"
        },
        {
          "author": "lironesamoun",
          "body": "hi @KinonoChen , I don't see your PR ?",
          "created_at": "2025-05-15T09:53:43Z"
        },
        {
          "author": "Eimis",
          "body": "@monali7-d why was this closed as completed? As far as I understand, it's not yet possible to make sure the the non-ASCII characters are embedded properly?\n\nExample of my embeddings is here. The Lithuanian characters ą, č, ę, ė, į etc. are escaped in the \"content\" column for embeddings.\n\n```json\n{\"P",
          "created_at": "2025-05-15T20:20:39Z"
        },
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-236/feature-request-allow-configuration-of-ensure-ascii-for-json\">SUPPORT-236 [Feature Request] Allow Configuration of ensure_ascii for JSON Serialization to Support Non-ASCII Characters</a></p>",
          "created_at": "2025-05-20T15:30:56Z"
        }
      ]
    },
    {
      "issue_number": 3021,
      "title": "Predefined welcome message",
      "body": "Hello, \nIs there a way to make a Team or an Agent to say an welcome message in the Playground app when the session starts?\n\nThanks.",
      "state": "closed",
      "author": "zizake",
      "author_type": "User",
      "created_at": "2025-04-29T15:44:48Z",
      "updated_at": "2025-06-17T12:18:58Z",
      "closed_at": "2025-06-17T12:18:58Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3021/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3021",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3021",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:40.278904",
      "comments": [
        {
          "author": "Ayush0054",
          "body": "hey @zizake  You can add custom instructions to your agent to send a greeting when a session starts. Check out docs : https://docs.agno.com/agents/prompts\n\nLet me know if you need any help \nthanks 🙌 ",
          "created_at": "2025-05-01T13:54:46Z"
        },
        {
          "author": "dirkbrnd",
          "body": "This is a great idea for a feature we could work on. I assume you want the playground app chat to start with a welcome message regardless of the agent the user is interacting with? ",
          "created_at": "2025-05-04T14:33:37Z"
        },
        {
          "author": "zizake",
          "body": "Exactly. At the beginning of the session, it would be helpful for the agent or team to provide a welcome message along with a brief guide on how to ask questions or make requests.",
          "created_at": "2025-05-04T14:53:17Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-06-04T00:35:08Z"
        },
        {
          "author": "zizake",
          "body": "Hi guys, no updates on this matter?",
          "created_at": "2025-06-04T01:00:07Z"
        }
      ]
    },
    {
      "issue_number": 2644,
      "title": "[Feature Request] Get intermediate tool calling and run response while working with Team",
      "body": "## Problem Description\nI like to be able to get intermediate tool calling, and agent process while using Team mode. For example, I have agent like this.\n\n```python\nimport time\n\nfrom agno.agent import Agent\nfrom agno.team import Team\nfrom agno.tools.newspaper4k import Newspaper4kTools\nfrom agno.models.openrouter import OpenRouter\n\nmodel = OpenRouter('anthropic/claude-3.7-sonnet')\n\ndef demo_tool_1(query: str) -> str:\n    time.sleep(2)\n    return \"Finished demo_tool_1 call\"\n\ndef demo_tool_2(query: str) -> str:\n    time.sleep(2)\n    return \"Finished demo_tool_2 call\"\n\nsearcher = Agent(\n    name=\"A\",\n    model=model,\n    role=\"Worker A\",\n    instructions=[\n        \"When ask you to run, call the `demo_tool_1` 2 time, then return the result.\"\n    ],\n    tools=[demo_tool_1],\n    add_datetime_to_instructions=True,\n)\nwriter = Agent(\n    name=\"B\",\n    model=model,\n    role=\"Writes a high-quality article\",\n    description=(\n        \"When ask you to run, call the `demo_tool_2` 1 time, then return the result.\"\n    ),\n    tools=[Newspaper4kTools()],\n    add_datetime_to_instructions=True,\n)\n\neditor = Team(\n    name=\"Coordinator\",\n    mode=\"coordinate\",\n    model=model,\n    members=[searcher, writer],\n    description=\"You are debugger, run the team, first call A, then B, then A.\",\n    instructions=[\n\n    ],\n    add_datetime_to_instructions=True,\n    show_members_responses=True,\n    show_tool_calls=True,\n    markdown=True,\n)\n\n\nif __name__ == \"__main__\":\n    r = editor.run(\"Hi, run test\", stream=True, stream_intermediate_steps=True)\n    for i in r:\n        tools = i.tools or []\n        print(f\"[Event: {i.event}], Tools: {[t['tool_name'] for t in tools]}, content: {i.content}\")\n```\n\nWhen execution the result I got.\n\n```\n[Event: RunStarted], Tools: [], content: Run started\n[Event: RunResponse], Tools: [], content:\n[Event: RunResponse], Tools: [], content:\n[Event: RunResponse], Tools: [], content: #\n[Event: RunResponse], Tools: [], content:  Testing Team Workflow\n\nI'll run a test of\n[Event: RunResponse], Tools: [], content:  our agent workflow by sequentially calling Agent A,\n[Event: RunResponse], Tools: [], content:  then Agent B, and then Agent A again, as\n[Event: RunResponse], Tools: [], content:  requested.\n[Event: RunResponse], Tools: [], content:\n[Event: RunResponse], Tools: [], content:\n[Event: ToolCallStarted], Tools: ['transfer_task_to_member'], content: None\n[Event: ToolCallCompleted], Tools: ['transfer_task_to_member'], content: None\n[Event: RunResponse], Tools: [], content:\n[Event: RunResponse], Tools: [], content:\n[Event: RunResponse], Tools: [], content: Great\n[Event: RunResponse], Tools: [], content: ! Agent A has confirmed receipt of the test task.\n[Event: RunResponse], Tools: [], content:  Now I'll transfer a task to Agent B:\n[Event: RunResponse], Tools: [], content:\n[Event: RunResponse], Tools: [], content:\n```\n\nI hope to get a result like.\n\n```diff\n[Event: RunStarted], Tools: [], content: Run started\n[Event: RunResponse], Tools: [], content:\n[Event: RunResponse], Tools: [], content:\n[Event: RunResponse], Tools: [], content: #\n[Event: RunResponse], Tools: [], content:  Testing Team Workflow\n\nI'll run a test of\n[Event: RunResponse], Tools: [], content:  our agent workflow by sequentially calling Agent A,\n[Event: RunResponse], Tools: [], content:  then Agent B, and then Agent A again, as\n[Event: RunResponse], Tools: [], content:  requested.\n[Event: RunResponse], Tools: [], content:\n[Event: RunResponse], Tools: [], content:\n[Event: ToolCallStarted], Tools: ['transfer_task_to_member'], content: None\n+ [Event: ToolCallStarted], Tools: ['A.demo_tool_1], content: None                 # THIS IS MISSING.\n+ [Event: ToolCallCompleted], Tools: ['A.demo_tool_1], content: None               # THIS IS MISSING.\n+ [Event: ToolCallStarted], Tools: ['A.demo_tool_1], content: None                 # THIS IS MISSING.\n+ [Event: ToolCallCompleted], Tools: ['A.demo_tool_1], content: None               # THIS IS MISSING.\n[Event: ToolCallCompleted], Tools: ['transfer_task_to_member'], content: None\n[Event: RunResponse], Tools: [], content:\n[Event: RunResponse], Tools: [], content:\n[Event: RunResponse], Tools: [], content: Great\n[Event: RunResponse], Tools: [], content: ! Agent A has confirmed receipt of the test task.\n[Event: RunResponse], Tools: [], content:  Now I'll transfer a task to Agent B:\n[Event: RunResponse], Tools: [], content:\n[Event: RunResponse], Tools: [], content:\n[Event: ToolCallStarted], Tools: ['transfer_task_to_member'], content: None\n+ [Event: ToolCallStarted], Tools: ['B.demo_tool_2], content: None                 # THIS IS MISSING.\n+ [Event: ToolCallCompleted], Tools: ['B.demo_tool_2], content: None               # THIS IS MISSING.\n[Event: ToolCallCompleted], Tools: ['transfer_task_to_member'], content: None\n```\n\n## Proposed Solution\n\nI have two option in mind,\n- Add AgentRunResponse, AgentToolCallStarted, AgentToolCallCompleted event for Team use case.\n- Add a param called agent to all RunResponse, which can indicate is that from team leader, or sub-agents.\n\n## Alternatives Considered\n\nI tried to manually yield my Run Response inside agent tools, which is not working.\n\n## Would you like to work on this?\n\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n\n- [ ] Yes, I’d love to work on it!\n- [x] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.\n",
      "state": "closed",
      "author": "BrikerMan",
      "author_type": "User",
      "created_at": "2025-04-02T13:38:01Z",
      "updated_at": "2025-06-17T12:16:48Z",
      "closed_at": "2025-06-17T12:16:48Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2644/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "dirkbrnd"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2644",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2644",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:40.499455",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hey @BrikerMan,\n\nThank you for reaching out and using Agno!\nWe've added this to our community wishlist, and our team will be discussing it internally. We'll make sure to keep you updated.\n\nAppreciate your support and feedback!",
          "created_at": "2025-04-03T06:14:06Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-18T00:32:13Z"
        },
        {
          "author": "s-aravindh",
          "body": "this would be really required, as we want to show the intermediate tool calls to user. \n\nis there any other alternative way we can achieve this??",
          "created_at": "2025-04-19T13:20:07Z"
        },
        {
          "author": "Lockeysama",
          "body": "Yes, this feature is indeed quite important. I also need this feature in my current development. However, at present, I can only implement it temporarily by means of a patch. With such an implementation, the code is not conducive to subsequent maintenance and keeping up with Agno's updates.🤦🏻‍♀️",
          "created_at": "2025-04-21T12:05:11Z"
        },
        {
          "author": "s-aravindh",
          "body": "would it be possible to share the patch code? we can utilise that and see how we can raise a merge request",
          "created_at": "2025-04-21T13:07:59Z"
        }
      ]
    },
    {
      "issue_number": 2997,
      "title": "[Feature Request] Support Non-Localhost Weaviate Servers",
      "body": "## Problem Description\n\nCurrently only Weaviate Cloud or a Weaviate server listening on `localhost` is supported by https://github.com/agno-agi/agno/blob/main/libs/agno/agno/vectordb/weaviate/weaviate.py \n\nThis does not work\n\n```\nWeaviate(wcd_url=os.environ.get('WEAVIATE_HOST'), wcd_api_key=\"\", local=False, collection=kb_name,\n        search_type=SearchType.hybrid, vector_index=VectorIndex.HNSW, distance=Distance.COSINE)\n```\n\nand it falls back to connect to local \n\n```\n2025-04-26 08:51:12,265 - httpcore.connection - DEBUG - connect_tcp.started host='localhost' port=8080 local_address=None timeout=5.0 socket_options=None\n2025-04-26 08:51:12,265 - httpcore.connection - DEBUG - connect_tcp.failed exception=ConnectError(ConnectionRefusedError(111, 'Connection refused'))\n2025-04-26 08:52:57,744 - httpcore.connection - DEBUG - connect_tcp.started host='localhost' port=8080 local_address=None timeout=5.0 socket_options=None\n2025-04-26 08:52:57,745 - httpcore.connection - DEBUG - connect_tcp.failed exception=ConnectError(ConnectionRefusedError(111, 'Connection refused'))\n2025-04-26 08:53:29,455 - httpcore.connection - DEBUG - connect_tcp.started host='localhost' port=8080 local_address=None timeout=5.0 socket_options=None\n2025-04-26 08:53:29,456 - httpcore.connection - DEBUG - connect_tcp.failed exception=ConnectError(ConnectionRefusedError(111, 'Connection refused'))\n```\n\nand \n\n```\nTraceback (most recent call last):\n  File \"/home/mfranz/github/ai-tomfoolery/agno/./combo_ollama_pdf.py\", line 83, in <module>\n    kb = create_kb(vdb, urls)\n         ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/mfranz/github/ai-tomfoolery/agno/./combo_ollama_pdf.py\", line 65, in create_kb\n    kb.load(recreate=recreate)\n  File \"/home/mfranz/github/ai-tomfoolery/agno/.venv/lib/python3.12/site-packages/agno/knowledge/agent.py\", line 108, in load\n    self.vector_db.drop()\n  File \"/home/mfranz/github/ai-tomfoolery/agno/.venv/lib/python3.12/site-packages/agno/vectordb/weaviate/weaviate.py\", line 643, in drop\n    if self.exists():\n       ^^^^^^^^^^^^^\n  File \"/home/mfranz/github/ai-tomfoolery/agno/.venv/lib/python3.12/site-packages/agno/vectordb/weaviate/weaviate.py\", line 631, in exists\n    return self.get_client().collections.exists(self.collection)\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/mfranz/github/ai-tomfoolery/agno/.venv/lib/python3.12/site-packages/agno/vectordb/weaviate/weaviate.py\", line 96, in get_client\n    self.client = weaviate.connect_to_local()\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/mfranz/github/ai-tomfoolery/agno/.venv/lib/python3.12/site-packages/weaviate/connect/helpers.py\", line 161, in connect_to_local\n    return __connect(\n           ^^^^^^^^^^\n  File \"/home/mfranz/github/ai-tomfoolery/agno/.venv/lib/python3.12/site-packages/weaviate/connect/helpers.py\", line 339, in __connect\n    raise e\n  File \"/home/mfranz/github/ai-tomfoolery/agno/.venv/lib/python3.12/site-packages/weaviate/connect/helpers.py\", line 335, in __connect\n    client.connect()\n  File \"/home/mfranz/github/ai-tomfoolery/agno/.venv/lib/python3.12/site-packages/weaviate/client_executor.py\", line 153, in connect\n    return executor.execute(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/mfranz/github/ai-tomfoolery/agno/.venv/lib/python3.12/site-packages/weaviate/connect/executor.py\", line 87, in execute\n    return cast(T, exception_callback(e))\n                   ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/mfranz/github/ai-tomfoolery/agno/.venv/lib/python3.12/site-packages/weaviate/connect/executor.py\", line 26, in raise_exception\n    raise e\n  File \"/home/mfranz/github/ai-tomfoolery/agno/.venv/lib/python3.12/site-packages/weaviate/connect/executor.py\", line 68, in execute\n    call = method(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/mfranz/github/ai-tomfoolery/agno/.venv/lib/python3.12/site-packages/weaviate/connect/v4.py\", line 898, in connect\n    self._open_connections_rest(self._auth, \"sync\")\n  File \"/home/mfranz/github/ai-tomfoolery/agno/.venv/lib/python3.12/site-packages/weaviate/connect/v4.py\", line 424, in _open_connections_rest\n    raise WeaviateConnectionError(\nweaviate.exceptions.WeaviateConnectionError: Connection to Weaviate failed. Details: Error: [Errno 111] Connection refused. \nIs Weaviate running and reachable at http://localhost:8080?\n```\n\n## Proposed Solution\n \n- At least support wcd_url and possibly additional wcd_grpc_url given these might be different depending on the infrastructure. \n- Support API authentication or anonymous usage\n\n## Additional context\n\nSee https://weaviate.io/developers/weaviate/connections/connect-custom for examples of how to use the v4 API \n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[ ] Yes, I’d love to work on it!**\n**[X ] I’m open to collaborating but need guidance.**\n**[ ] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "mdfranz",
      "author_type": "User",
      "created_at": "2025-04-26T13:05:11Z",
      "updated_at": "2025-06-17T12:13:38Z",
      "closed_at": "2025-06-17T12:13:38Z",
      "labels": [
        "enhancement",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2997/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2997",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2997",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:40.709737",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @mdfranz ! Thanks for this feature request! We should definitely add a `wcd_grpc_url` param. In the meantime, to make Weaviate work with your custom endpoint, you could initialize that Client and pass it to the client param of Agno's `Weaviate` vector db class. ",
          "created_at": "2025-04-28T09:09:53Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-05-29T00:34:25Z"
        }
      ]
    },
    {
      "issue_number": 2983,
      "title": "How to Handle Exceeding Model Input Length",
      "body": "My model have 8192 context length , how to limit the input of the agent < 8192 ?",
      "state": "closed",
      "author": "AnhLD2610",
      "author_type": "User",
      "created_at": "2025-04-25T07:13:25Z",
      "updated_at": "2025-06-17T12:13:25Z",
      "closed_at": "2025-06-17T12:13:25Z",
      "labels": [
        "enhancement",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2983/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2983",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2983",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:40.899793",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "This is a very good request that we will look into! We'll add something to our roadmap",
          "created_at": "2025-05-13T15:27:27Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-06-13T00:35:15Z"
        }
      ]
    },
    {
      "issue_number": 2982,
      "title": "Help required",
      "body": "I'm just trying with agno framework, how to add the MCP server running with sse transport and also with custom headers for the request because it requires a authorization bearer token.",
      "state": "closed",
      "author": "th3sanjai",
      "author_type": "User",
      "created_at": "2025-04-25T04:28:04Z",
      "updated_at": "2025-06-17T12:13:08Z",
      "closed_at": "2025-06-17T12:13:08Z",
      "labels": [
        "stale"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2982/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2982",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2982",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:41.126867",
      "comments": [
        {
          "author": "Ansub",
          "body": "Hey @th3sanjai, SSE transport is now supported in the latest release. You can have a look at this [PR description](https://github.com/agno-agi/agno/pull/2892) for more context. \n\nHope that helps!",
          "created_at": "2025-04-25T11:47:44Z"
        },
        {
          "author": "th3sanjai",
          "body": "Hi @Ansub ,\nThanks for  the help, also I want know that agno also support interact shell like Fast-Agent, to make continuous prompts , switch agents?",
          "created_at": "2025-04-25T14:40:58Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@th3sanjai That isn't planned, but could you elaborate which features you like of Fast-Agent and we can add to our roadmap? ",
          "created_at": "2025-05-13T15:09:43Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-06-13T00:35:16Z"
        }
      ]
    },
    {
      "issue_number": 2978,
      "title": "[Feature Request] Support for Vercel AI SDK stream protocol",
      "body": "## Problem Description\n\nAgno has its own streaming implementation for LLM content generation, but this makes it difficult to integrate with frontend frameworks that use Vercel's AI SDK (https://sdk.vercel.ai/).\n\nVercel's AI SDK uses a specific stream protocol that's becoming a standard for many frontend developers. The protocol defines how data is streamed to the frontend on top of HTTP, with specific formats for different types of content (text, reasoning, tool calls, etc.).\n\n## Proposed Solution\n\nAdd support for Vercel's AI SDK stream protocol to Agno, so that frontend applications using `@ai-sdk/react` components like `useChat` can seamlessly work with Agno agents as the backend.\n\nAnd there will be lots of benifits:\n\n- Allow Agno to be used with popular frontend frameworks that use Vercel's AI SDK\n- Enable seamless integration with existing frontends built with Vercel's AI SDK\n\n## Alternatives Considered\n\nCreating a custom adapter layer between Agno and Vercel AI SDK.\n\n## Additional context\n\nAccording to the Vercel AI SDK documentation (https://sdk.vercel.ai/docs/ai-sdk-ui/stream-protocol), the stream protocol is designed to be implementation-agnostic and can be implemented by any backend, including those written in Python.\n\n## Would you like to work on this?\n\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n\n- [x] Yes, I’d love to work on it!\n- [x] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.\n",
      "state": "closed",
      "author": "arkohut",
      "author_type": "User",
      "created_at": "2025-04-25T01:40:11Z",
      "updated_at": "2025-06-17T12:11:59Z",
      "closed_at": "2025-06-17T12:11:59Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2978/reactions",
        "total_count": 7,
        "+1": 7,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2978",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2978",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:41.343126",
      "comments": [
        {
          "author": "Ansub",
          "body": "Thanks for the feedback, Really appreciate you taking the time to surface this. We’ll definitely be exploring support for the Vercel AI SDK stream protocol!",
          "created_at": "2025-04-25T11:41:26Z"
        },
        {
          "author": "gauravdhiman",
          "body": "Hi @arkohut I did this integration, its not part of agno, but as a separate repo. You can have a look at [this github repo](https://github.com/gauravdhiman/vercel-agno-integration) to know how I integrated Agno with Vercel AI SDK UI.\n\nLook at the [adapter file](https://github.com/gauravdhiman/vercel",
          "created_at": "2025-05-25T21:15:21Z"
        }
      ]
    },
    {
      "issue_number": 2894,
      "title": "[Feature Request] Better to provide utils for wrap openai compatible apis in app",
      "body": "## Problem Description\nWhen creating app using agno, serving as an api server, it's better to give some utils to convert the api request and response to openai compatible schemas.\n\n",
      "state": "closed",
      "author": "fwang2002",
      "author_type": "User",
      "created_at": "2025-04-20T08:07:00Z",
      "updated_at": "2025-06-17T12:11:33Z",
      "closed_at": "2025-06-17T12:11:10Z",
      "labels": [
        "enhancement",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2894/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2894",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2894",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:41.585164",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hey @fwang2002 Thank you for reaching out and using Agno.\n\nAdding this to our community wishlist. We will take some time to discuss this internally and get back to you.\n\nThank you again for your inputs",
          "created_at": "2025-04-21T06:02:38Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @fwang2002 \nCould you provide an example? Do you have an API and you want utils to convert it for giving to an Agno agent? \n",
          "created_at": "2025-04-23T10:32:36Z"
        },
        {
          "author": "fwang2002",
          "body": "Yes, just like if I use openai compatible sdk, it can communicate with agno agent, without concerning the protocol transformation.",
          "created_at": "2025-04-24T03:53:00Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Ah I see. Would you like to have an OpenAI compatible API layer that you can host as an API? This makes sense! We will add this to our roadmap.\n",
          "created_at": "2025-04-24T09:22:03Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-05-25T00:38:09Z"
        }
      ]
    },
    {
      "issue_number": 2790,
      "title": "Let's agree on Open Agent API Schema!",
      "body": "# Open Agent API Proposal\n\nLink to official repo: https://github.com/swedishembedded/open-agent-api\n\nLet's agree on the open agent API schema for agent communication over the internet! I have prepared a comprehensive proposal for a standardized API that enables secure, multi-tenant access to intelligent agent capabilities.\n\nThis is still very much in draft stage but **it is extremely urgent and extremely important that we lead the way here with Agno**! \n\nHaving a standardized API will allow us to have agents that communicate with other people's agents over the internet. In the API api we need to sort out solutions to things like authentication, agent discovery, streaming to agents (not just models), streaming to teams (not just agents), exposing MCP tools to other agents, creating teams etc. \n\nWe want a server to be able to implement this API and be compatible with everybody else's agents. We want to be able to build teams that span the internet and not just teams that run in a local terminal. \n\n## Overview\n\nThe **Open Agent API** is designed as a web protocol for connecting intelligent agents across the internet. This protocol supports clients generated in any language that OpenAPI generators support, making it widely accessible and adaptable.\n\nKey features of this proposed API schema include:\n\n- **Authentication**: Supports both magic link email flow and OAuth2 flow (compatible with Clerk or any OAuth provider)\n- **Extensibility**: Designed to be extended as agent capabilities evolve\n- **Multi-tenant**: Secure access control for multiple users and organizations\n- **Streaming Support**: Real-time interaction with agents via server-sent events\n- **Teams Architecture**: Enables coordination between multiple specialized agents\n- **Knowledge Integration**: Built-in RAG capabilities via a Knowledge Search API\n- **OpenAI Compatibility**: Includes Chat Completion endpoints compatible with OpenAI's API\n\n## API Components\n\n### Authentication\n\nTwo primary flows:\n\n1. **Magic Link (Email)**: Passwordless login via email\n   - `POST /auth/link`: Request magic login link\n   - `GET /auth/link/verify`: Validate the token from the link\n\n2. **OAuth2**: Third-party authentication\n   - Integration with providers like Google, GitHub, etc.\n   - `GET /auth/oauth/{provider}/callback`: Handle OAuth redirects\n\nBoth flows result in a bearer token or API key for subsequent authenticated requests.\n\n### Chat Completion API\n\nOpenAI-compatible endpoints for direct model access:\n\n- `GET /v1/models`: List available models\n- `POST /v1/chat/completions`: Generate chat completions\n- `POST /v1/embeddings`: Generate embeddings\n- `POST /v1/completions`: Generate text completions\n\n### Agents API\n\nEndpoints for creating and interacting with intelligent agents:\n\n- `POST /agents`: Create a new agent with specific tools and capabilities\n- `GET /agents`: List available agents\n- `GET /agents/{agentId}`: Get detailed information about an agent\n- `POST /agents/{agentId}/chat`: Chat with a specific agent\n\nThe agent chat supports streaming via server-sent events with defined event types:\n- **RunStarted**: Signals the beginning of agent processing\n- **RunResponse**: Intermediate outputs as the agent thinks\n- **ToolRequest**: Agent requests to use a specific tool\n- **RunCompleted**: Final answer when the agent completes its task\n\n### Teams API\n\nEnables coordination among multiple specialized agents:\n\n- `POST /teams`: Create a team with a leader and member agents\n- `GET /teams/{teamId}`: Get team information\n- `POST /teams/{teamId}/chat`: Interact with the entire team\n\nThe team leader orchestrates tasks, delegating to specialized agents as needed - this can potentially include delegating to remote agents which the server knows about. \n\n### Knowledge Search API\n\nProvides semantic search capabilities for RAG workflows:\n\n- `POST /knowledge/search`: Search domain-specific knowledge\n- Future extensions will include CRUD operations for knowledge management\n\nI'm not entirely sure what we want to expose here. \n\n## Monetization (Optional)\n\nThe API includes optional integration with Stripe for subscription management:\n\n- Multiple subscription tiers (Free, Pro, Enterprise)\n- Usage tracking and limits\n- Webhook integration for billing events (`POST /stripe/webhook`)\n\nThis is important because running any agent has a cost. We must standardize the process of how we subcribe to agent services so that a CLI tool or cursor or another agent can easily implement this flow to make it seamless for the user. \n\n## Next Steps\n\n1. Review this proposal and provide feedback\n2. Discuss implementation details and potential extensions\n3. Clean up the draft and release first official version\n\n## Technical Details\n\nThe complete OpenAPI schema is defined in [`open-agent-api.yaml` ](https://github.com/swedishembedded/open-agent-api/blob/main/open-agent-api.yaml) and covers all endpoints and data structures.\n\nWould love to hear the community's thoughts on this proposal and how we can collaborate to create a truly robust, concise and easy to use open standard for agent communication! ",
      "state": "closed",
      "author": "mkschreder",
      "author_type": "User",
      "created_at": "2025-04-12T09:13:24Z",
      "updated_at": "2025-06-17T12:07:21Z",
      "closed_at": "2025-06-17T12:07:21Z",
      "labels": [
        "enhancement",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2790/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2790",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2790",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:41.878842",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "@mkschreder This looks great to us. Would you imagine this being a server that we allow users to quickly spin up as a standard API for agents/teams? \nWe have a `PlaygroundApp` today with endpoints for connecting agents to our Agno Playground, but I can imagine that we can make a similar `OpenAgentAP",
          "created_at": "2025-04-14T09:32:27Z"
        },
        {
          "author": "mkschreder",
          "body": "@dirkbrnd \n\nI would imagine this being a standard for creating teams of connected agents where an agent doesn't have to be local to be part of the team. Thus we should be able to create a team like this:\n\n```\ncoding_agent = RemoteAgent(\n    url=\"https://supplier.com/agents/coder\"\n    tools=[FileTool",
          "created_at": "2025-04-16T16:17:13Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Ok! Yes now it makes sense to me. The idea of a remote agent makes a lot of sense. \n\nIt could be a nice way to make our agents available to other languages, since it is just an API. \n\nWe do love the idea. We are a very small team so we would appreciate collaboration. \n\n1. Why do you need endpoints t",
          "created_at": "2025-04-23T08:55:48Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-05-24T00:32:49Z"
        }
      ]
    },
    {
      "issue_number": 3570,
      "title": "Addition of Dockerfile",
      "body": "### Problem Description\n\nHi Team,\n\nI've reviewed the repository and noticed that there's currently no Dockerfile present. I would love to contribute by creating a Dockerfile to containerize the application, which could help streamline local development and deployment.\n\nIf this aligns with the goals of the project, I’d appreciate it if you could assign me this task. Looking forward to your guidance on any specific requirements or preferences you might have.\n\nThanks!\n\nBest regards,\nNikhil Kumar\n\n### Proposed Solution\n\nAddition of Dockerfile\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [x] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.",
      "state": "open",
      "author": "Nick1200000",
      "author_type": "User",
      "created_at": "2025-06-15T14:09:09Z",
      "updated_at": "2025-06-17T06:25:55Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3570/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3570",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3570",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:42.162049",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Hi @Nick1200000 \nDo you mean for the `agno` project? We do have Dockerfiles with our API and App templates.\nFor the SDK itself it could make sense to have an example dockerfile, especially with the examples in `/cookbook/apps`\n",
          "created_at": "2025-06-15T18:51:01Z"
        }
      ]
    },
    {
      "issue_number": 3573,
      "title": "[Feature Request] Do you support aihubmix?",
      "body": "### Problem Description\n\nDo you support [aihubmix](https://aihubmix.com)? It's a platform similar to OpenRouter, designed primarily for users in China.  \n\n### Proposed Solution\n\nIt's a platform similar to OpenRouter.\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [x] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "0xfnzero",
      "author_type": "User",
      "created_at": "2025-06-16T12:00:04Z",
      "updated_at": "2025-06-17T06:20:55Z",
      "closed_at": "2025-06-17T06:20:55Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3573/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3573",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3573",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:42.368635",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hey @0xfnzero,\nThank you for sharing this with us. We currently don’t support [aihubmix](https://aihubmix.com/) and it’s not on our roadmap at the moment, but I’ll definitely pass this along to the team for discussion.\n\nAppreciate you flagging it!",
          "created_at": "2025-06-17T06:20:55Z"
        }
      ]
    },
    {
      "issue_number": 3575,
      "title": "[Feature Request] Anthropic on Vertex AI",
      "body": "### Problem Description\n\nSimilar to AWS Bedrock Claude, organizations frequently leverage Vertex AI to access Claude rather than the first-party Anthropic API.\n\n### Proposed Solution\n\nAdd support for Anthropic models to the existing Vertex AI solution\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\nanthropic[vertex] for python library supporting vertex AI\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [x] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "therealpaulgg",
      "author_type": "User",
      "created_at": "2025-06-16T18:27:08Z",
      "updated_at": "2025-06-17T06:19:04Z",
      "closed_at": "2025-06-17T06:19:04Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3575/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3575",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3575",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:42.552149",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hey @therealpaulgg,\nThank you for raising this. This is part of our roadmap.\n\nIn the meantime, feel free to contribute to our open source if you're interested. We always appreciate community contributions and are happy to support you along the way.",
          "created_at": "2025-06-17T06:19:01Z"
        }
      ]
    },
    {
      "issue_number": 3348,
      "title": "[Feature Request] VertexAI model garden/claude support",
      "body": "### Problem Description\n\nVertexAI supports inference for claude models, but there's only support for gemini models in Agno.\n\n### Proposed Solution\n\nHave an implementation similar to how AWS bedrock is handled.\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [x] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "FireMasterK",
      "author_type": "User",
      "created_at": "2025-05-25T16:35:52Z",
      "updated_at": "2025-06-16T18:01:06Z",
      "closed_at": "2025-05-26T10:41:39Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3348/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3348",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3348",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:42.744076",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-302/feature-request-vertexai-model-gardenclaude-support\">SUPPORT-302 [Feature Request] VertexAI model garden/claude support</a></p>",
          "created_at": "2025-05-25T16:35:54Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Thanks for the request! We have added it to our [roadmap](https://github.com/orgs/agno-agi/projects/6/views/1)",
          "created_at": "2025-05-26T10:41:39Z"
        },
        {
          "author": "byteground",
          "body": "Hi. Any chance this is getting picked soon?",
          "created_at": "2025-06-16T18:01:06Z"
        }
      ]
    },
    {
      "issue_number": 2274,
      "title": "Is there a plan to support TypeScript?",
      "body": "Is there a plan to support TypeScript?",
      "state": "closed",
      "author": "phpmac",
      "author_type": "User",
      "created_at": "2025-03-03T15:43:22Z",
      "updated_at": "2025-06-16T11:10:00Z",
      "closed_at": "2025-03-08T03:43:16Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2274/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2274",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2274",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:42.951355",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Hi @phpmac \nWe plan to support more languages in future. At the moment we are focusing on making the current SDK as strong as possible with a small team, so we don't have Typescript on our immediate roadmap. But watch this space later this year!",
          "created_at": "2025-03-03T18:55:51Z"
        },
        {
          "author": "thegreatestcompany",
          "body": "In the meantime it would be great to have a tutorial on how to build a production ready simple app with agno backend and nextjs frontend! I have a lot of multi-agents systems ready, but struggle to deploy it with a nice UI",
          "created_at": "2025-06-16T09:47:59Z"
        },
        {
          "author": "phpmac",
          "body": "Mastra\n\n2025 年 6 月 16 日星期一 17:48, thegreatestcompany ***@***.***(mailto:2025 年 6 月 16 日星期一 17:48, thegreatestcompany <<a href=)> 来信：\n\n> thegreatestcompany left a comment [(agno-agi/agno#2274)](https://github.com/agno-agi/agno/issues/2274#issuecomment-2975858946)\n>\n> In the meantime it would be great",
          "created_at": "2025-06-16T11:10:00Z"
        }
      ]
    },
    {
      "issue_number": 3391,
      "title": "[Bug] Error on using knowledge filters with Agent Knowledge",
      "body": "### Description\n\nWe get a Not Implemented error when running knowledge filtering using PGVector on our existing table.\n\n\n```\nDEBUG AgentSessionsRequest: 66c4ff66-fc1d-4024-8d7a-bf55f17024e6 ravish_c18a                                                           \nINFO:     127.0.0.1:55272 - \"GET /v1/playground/agents/66c4ff66-fc1d-4024-8d7a-bf55f17024e6/sessions?user_id=ravish_c18a HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:55261 - \"OPTIONS /v1/playground/agents/66c4ff66-fc1d-4024-8d7a-bf55f17024e6/memories?user_id=ravish_c18a HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:55272 - \"GET /v1/playground/agents/66c4ff66-fc1d-4024-8d7a-bf55f17024e6/memories?user_id=ravish_c18a HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:55261 - \"OPTIONS /v1/playground/agents/66c4ff66-fc1d-4024-8d7a-bf55f17024e6/runs HTTP/1.1\" 200 OK\nDEBUG AgentRunRequest: hi  ravish_c18a 66c4ff66-fc1d-4024-8d7a-bf55f17024e6                                                            \nDEBUG Creating new session                                                                                                             \nDEBUG ********************************** Agent ID: 66c4ff66-fc1d-4024-8d7a-bf55f17024e6 *********************************              \nTraceback (most recent call last):\n  File \"/Users/ropes/Library/Caches/pypoetry/virtualenvs/data-platform-api-oh-T_uCf-py3.13/lib/python3.13/site-packages/agno/app/playground/async_router.py\", line 60, in chat_response_streamer\n    run_response = await agent.arun(\n                   ^^^^^^^^^^^^^^^^^\n    ...<8 lines>...\n    )\n    ^\n  File \"/Users/ropes/Library/Caches/pypoetry/virtualenvs/data-platform-api-oh-T_uCf-py3.13/lib/python3.13/site-packages/agno/agent/agent.py\", line 1243, in arun\n    self.knowledge.initialize_valid_filters()  # type: ignore\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n  File \"/Users/ropes/Library/Caches/pypoetry/virtualenvs/data-platform-api-oh-T_uCf-py3.13/lib/python3.13/site-packages/agno/knowledge/agent.py\", line 484, in initialize_valid_filters\n    for doc_list in self.document_lists:\n                    ^^^^^^^^^^^^^^^^^^^\nNotImplementedError\n```\n\n### Steps to Reproduce\n\n1. Create a PGVector knowledge base using AgentKnowledge\n2. add knowledge filters\n3. run\n\n### Agent Configuration (if applicable)\n\n```python\nvector_db = PgVector(\n    table_name=\"regulatory_document_chunks\",  # use the existing table\n    db_url=get_db_url(),\n    embedder=OpenAIEmbedder(),  # only needed for query‑time embeddings\n    auto_upgrade_schema=False,  # keep Agno from altering your table\n    reranker=CohereReranker(model=\"rerank-v3.5\"),\n    search_type=SearchType.hybrid,\n)\n\n# Create a knowledge base, loaded with documents from a URL\nknowledge_base = AgentKnowledge(vector_db=vector_db)\n\n# setup memory & storage\nmemory_db = PostgresMemoryDb(table_name=\"agent_history\", db_url=get_db_url())\n\nmemory = Memory(model=Gemini(id=\"gemini-2.0-flash\"), db=memory_db)\n\nstorage = PostgresStorage(\n    # store sessions in the ai.sessions table\n    table_name=\"agent_sessions\",\n    # db_url: Postgres database URL\n    db_url=get_db_url(),\n)\n\n\ndef load_agent(\n    user_id: Optional[str],\n    session_id: Optional[str],\n    regulations_selected: Optional[list[str]] = [],\n    tool_call_limit: Optional[int] = 10,\n    memory=memory,\n):\n    return Agent(\n        name=\"Legal Expert\",\n        role=\"Legal Expert\",\n        model=OpenAIChat(id=\"o4-mini-2025-04-16\"),\n        knowledge=knowledge_base,\n        knowledge_filters={\"state\": \"California\"},\n        search_knowledge=True,\n        tools=[ReasoningTools(add_instructions=True), get_date_time],\n        session_id=session_id,\n        user_id=user_id,\n        monitoring=True,\n        show_tool_calls=True,\n        markdown=True,\n        session_state={\"sources\": [], \"user_id\": user_id},\n        add_state_in_messages=True,\n        storage=storage,\n        memory=memory,\n        enable_agentic_memory=True,\n        read_chat_history=True,\n        add_history_to_messages=True,\n        instructions=[\n            \"You are an expert... \",\n        ],\n        tool_call_limit=tool_call_limit,\n        debug_mode=True\n    )\n```\n\n### Expected Behavior\n\nFilter knowledge base using metadata filters\n\n### Actual Behavior\n\nNot Implemented Error \n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nAgno 1.5.5\n```\n\n### Possible Solutions (optional)\n\nIt's a quick implementation - it would really help us use Agno to launch our product!\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "ravishrawal",
      "author_type": "User",
      "created_at": "2025-05-28T09:50:19Z",
      "updated_at": "2025-06-16T10:14:46Z",
      "closed_at": "2025-06-16T10:14:46Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3391/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3391",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3391",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:43.139771",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-334/bug-error-on-using-knowledge-filters-with-agent-knowledge\">SUPPORT-334 [Bug] Error on using knowledge filters with Agent Knowledge</a></p>",
          "created_at": "2025-05-28T09:50:22Z"
        },
        {
          "author": "jesalg",
          "body": "+1 I had to use a wrapper class around `AgentKnowledge` with this to get it to work:\n\n```py\n  @property\n  def document_lists(self) -> Iterator[List[Document]]:\n      \"\"\"Iterate over all sources and yield their document lists.\n      This enables metadata tracking and filtering capabilities.\n      \"\"\"",
          "created_at": "2025-05-28T18:27:10Z"
        },
        {
          "author": "jesalg",
          "body": "Also related: https://github.com/agno-agi/agno/issues/3384",
          "created_at": "2025-05-28T18:27:26Z"
        },
        {
          "author": "kausmeows",
          "body": "Hey @ravishrawal You're using `AgentKnowlede` class right, that is the base class, we havent put metadata attaching part in base knowledge class like we have in Text, Markdown etc in the `document_lists` function. In the short term you'll have to inherit from that class and override the `document_li",
          "created_at": "2025-06-07T06:27:21Z"
        }
      ]
    },
    {
      "issue_number": 3556,
      "title": "[Bug] \"RuntimeError: Attempted to exit cancel scope....\" using mcp tool streamable-http and playground",
      "body": "### Description\n\nHello!\n\nI have an agno agent with mcp streamable-http and I want to be served in the playground. \nMy code is using https://github.com/agno-agi/agno/blob/c88fa24d06db9bd56105bf8cc7a85cec9b1bfa15/cookbook/apps/playground/mcp_demo.py and https://github.com/agno-agi/agno/blob/c88fa24d06db9bd56105bf8cc7a85cec9b1bfa15/cookbook/tools/mcp/streamable_http_transport/client.py\n\nWhen I start the agent or I call a tool from mcp server, I receive the following stack:\n```\nException ignored in: <async_generator object HTTP11ConnectionByteStream.__aiter__ at 0x109808a40>\nTraceback (most recent call last):\n  File \"/Users/work/karma/repo/ml/venvs/agno/venv/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 404, in __aiter__\n    yield part\nRuntimeError: async generator ignored GeneratorExit\nException ignored in: <coroutine object HTTP11ConnectionByteStream.aclose at 0x1097cfa00>\nTraceback (most recent call last):\n  File \"/Users/work/karma/repo/ml/venvs/agno/venv/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 348, in aclose\n    await self._connection._response_closed()\n  File \"/Users/work/karma/repo/ml/venvs/agno/venv/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 239, in _response_closed\n    async with self._state_lock:\n  File \"/Users/work/karma/repo/ml/venvs/agno/venv/lib/python3.11/site-packages/httpcore/_synchronization.py\", line 77, in __aenter__\n    await self._anyio_lock.acquire()\n  File \"/Users/work/karma/repo/ml/venvs/agno/venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 1799, in acquire\n    await AsyncIOBackend.cancel_shielded_checkpoint()\n  File \"/Users/work/karma/repo/ml/venvs/agno/venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 2349, in cancel_shielded_checkpoint\n    with CancelScope(shield=True):\n  File \"/Users/work/karma/repo/ml/venvs/agno/venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 457, in __exit__\n    raise RuntimeError(\nRuntimeError: Attempted to exit cancel scope in a different task than it was entered in\n```\n\nThe agent works fine, the tool calling from the mcp-server works, the only think is that it throws the above errors in terminal.\n\n### Steps to Reproduce\n\n1. Start mcp-server from https://github.com/agno-agi/agno/blob/c88fa24d06db9bd56105bf8cc7a85cec9b1bfa15/cookbook/tools/mcp/streamable_http_transport/server.py\n2. Start agno agent\n3. Call a tool from agno agent\n\nAt step 2 and step 3, the above errors are shown in terminal, but the agent works ok.\n\n### Agent Configuration (if applicable)\n\n```\n\"\"\"This example shows how to run an Agent using our MCP integration in the Agno Playground.\n\"\"\"\n\nimport asyncio\nfrom textwrap import dedent\n\nimport nest_asyncio\nfrom agno.playground.settings import PlaygroundSettings\n\nfrom agno.agent import Agent\nfrom agno.models.openai import OpenAIChat\nfrom agno.playground import Playground, serve_playground_app\nfrom agno.tools.mcp import MCPTools\nfrom agno.tools.reasoning import ReasoningTools\n\n# Allow nested event loops\nnest_asyncio.apply()\n\nasync def run_server() -> None:\n\n    # Create a client session to connect to the MCP server\n    server_url=\"http://localhost:8000/mcp\"\n    async with MCPTools(transport=\"streamable-http\", url=server_url, timeout_seconds=3000) as mcp_tools:\n        agent = Agent(\n            name=\"MCP Agent\",\n            tools=[ReasoningTools(add_instructions=True),mcp_tools],\n            instructions=dedent(\"\"\"\\\n                You are an agent \n            \"\"\"),\n            model=OpenAIChat(id=\"gpt-4o\"),\n            add_datetime_to_instructions=True,\n            add_history_to_messages=True,\n            num_history_responses=5,\n            markdown=True,\n            show_tool_calls=True,\n        )\n\n        settings = PlaygroundSettings()\n        settings.cors_origin_list = [\n            \"https://app.agno.com\",\n        ]\n\n        \n\n        playground = Playground(agents=[agent],settings=settings)\n        app = playground.get_app()\n\n        # Serve the app while keeping the MCPTools context manager alive\n        serve_playground_app(app)\n\n\n\nif __name__ == \"__main__\":\n    asyncio.run(run_server())\n\n```\n\n### Expected Behavior\n\nNot throw any error\n\n### Actual Behavior\n\nEvery time when a tool from the mcp server (streamable-http) is called, the above error is thrown in terminal, but the tool actually is ran successfully. \n\nThis happens only with streamable-http mcp server. With stdio or sse mcp servers, the error is not thrown.\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n* python 3.11\n* agno: 1.6.0 (I used 1.5.1, 1.5.8 or 1.6.0, it is the same of all versions)\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "orinciog",
      "author_type": "User",
      "created_at": "2025-06-13T10:22:41Z",
      "updated_at": "2025-06-16T08:00:42Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3556/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3556",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3556",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:43.349845",
      "comments": [
        {
          "author": "manuhortet",
          "body": "Hey @orinciog, it looks like after some recent changes the MCP integration is not longer working with the Playground. \nWe will dive into this as soon as possible to find a fix - thanks for reporting this.",
          "created_at": "2025-06-16T07:29:48Z"
        },
        {
          "author": "orinciog",
          "body": "Hy! Thank you for responding.  \nThe above error happens only with streamable-http mcp. With sse or stdio, playground+mcp works ok ",
          "created_at": "2025-06-16T07:44:05Z"
        },
        {
          "author": "manuhortet",
          "body": "Hey @orinciog that's good to know, thanks for the correction! ",
          "created_at": "2025-06-16T08:00:42Z"
        }
      ]
    },
    {
      "issue_number": 3563,
      "title": "[Bug] Playground not working?",
      "body": "### Description\n\nI have been trying to sell my team on using agno.  However i have been attempting to wire my localhost:8000 into the playground.   My agno-api app has a /v1 in the path but the playground does not look to v1/playground, its just /playground.\n\nIn addition, im not sure if I should be authenticating some way because all of the document links for authenticating seem to not work.  Example found here.\nhttps://docs.agno.com/introduction/playground\n\nI also attempted to try the agno app that is documented in workspaces documentation.  However try as i might, I cannot get it to install python deps in the docker container. \n\nI really want to have our team use this but today was a setback.  Im hoping im just doing something horribly wrong and can  find a work around\n\n### Steps to Reproduce\n\nagno-api\n1. I followed the steps in agno workspace documentation for agno-api\n2. attempted to plug in localhost:8000 to app.agno playground.    agno-api uses http://localhost:8000/v1/playground but app.agno playground wants \nhttp://localhost:8000/playground \n\nagno-app\n1. Followed all steps on doc.agno in worspaces for agno-app\n2. followed readme\n3.  Docker container constantly crashes out on missing yfinance module\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nI expect to be able to show my agno-api app in app.agno playground. \n\nI expect to be able to run agno=app without errors about yfinance and other missing modules.\n\n### Actual Behavior\n\napp.agno playground tries to hit the wrong path for agno-api\n\ndocker container for agno-app never runs correctly. always has an error about missing requirements. \n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nMac: Sequoia 15.5\nLatest agno.\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "MFD3000",
      "author_type": "User",
      "created_at": "2025-06-13T20:32:48Z",
      "updated_at": "2025-06-16T07:37:23Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3563/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3563",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3563",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:43.542498",
      "comments": [
        {
          "author": "codingFTW",
          "body": "I also encountered the same issues, please refer my screenshot below\n\n<img width=\"675\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/482022ce-3bf8-432e-955d-ec0bff7e2190\" />",
          "created_at": "2025-06-14T16:13:37Z"
        },
        {
          "author": "Ayush0054",
          "body": "hey @MFD3000 @codingFTW we have updated app to take prefix directly from endpoint , \nyou can add your endpoint like this now `http://localhost:8000/v1` directly and use it.\n we will update the docs asap.\napologies for the inconvenience \nthanks 🙌 ",
          "created_at": "2025-06-16T07:29:03Z"
        }
      ]
    },
    {
      "issue_number": 3571,
      "title": "[Bug] LightRAG Client Import of textract Causes Unnecessary Dependency Conflicts",
      "body": "### Description\n\nWhen using the agno.knowledge.light_rag module as a client to connect to a running LightRAG server (e.g., via Docker), the module attempts to import textract at the top level. \n\nThis causes dependency version conflict as LightRAG requires a different version of extract to my execution tool (a part of a custom tool).\n\nWould appreciate it if anyone could verify this, thanks!\n\nMore info:\nI'm currently using:\nbeautifulsoup4 >=4.12.2,<5.0.0 (very recent)\n\nDocker side textract requires:\nbeautifulsoup4 >=4.8.0,<4.9.0 (much older)\n\n### Steps to Reproduce\n\n1. install agno (with something requiring a newer version of textract, such as bs4\n2.docker compose and run lightrag (which requires an older version of textract)\n3. execute agno script, and the version conflict should appear\n\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nscript should execute, and docker side dependency should not affect agno execution \n\n### Actual Behavior\n\nTerminal log:\nTraceback (most recent call last):\n  File \"/Users/work/Desktop/AI4Biotech/supplement-development-agent/src/resume.py\", line 15, in <module>\n    from execution import run_supplement_research_pipeline\n  File \"/Users/work/Desktop/AI4Biotech/supplement-development-agent/src/execution.py\", line 20, in <module>\n    from agno.knowledge.light_rag import LightRagKnowledgeBase, lightrag_retriever\n  File \"/Users/work/Library/Caches/pypoetry/virtualenvs/supplement-development-agent-w_m6wbs3-py3.11/lib/python3.11/site-packages/agno/knowledge/light_rag.py\", line 6, in <module>\n    import textract\nModuleNotFoundError: No module named 'textract'\n\nWhen trying to resolve:\nUpdating dependencies\nResolving dependencies... (0.2s)\n\nBecause no versions of textract match >1.6.5,<2.0.0\n and textract (1.6.5) depends on beautifulsoup4 (>=4.8.0,<4.9.0), textract (>=1.6.5,<2.0.0) requires beautifulsoup4 (>=4.8.0,<4.9.0).\nSo, because supplement-development-agent depends on both beautifulsoup4 (>=4.12.2,<5.0.0) and textract (^1.6.5), version solving failed.\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nmacOS 14.6.1\nAgno 1.6.2\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "chicco4life",
      "author_type": "User",
      "created_at": "2025-06-16T04:29:05Z",
      "updated_at": "2025-06-16T05:12:02Z",
      "closed_at": "2025-06-16T05:12:02Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3571/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3571",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3571",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:43.768020",
      "comments": []
    },
    {
      "issue_number": 3187,
      "title": "[Bug] ValidationError when serializing Team with class-based response_model in API",
      "body": "### Description\n\ni run agno on fastapi based on [https://github.com/agno-agi/agno-demo-app](url)\n\nWhen a `agno.Team` is defined with its `response_model` attribute set to a Pydantic class object (e.g., `response_model=MyPydanticModel`), the Agno playground API endpoint responsible for displaying team details (likely interacting with `agno.playground.schemas.TeamGetResponse`) throws a `pydantic_core._pydantic_core.ValidationError`.\n\nThe error message typically indicates an input type mismatch, for example:\n`Input should be a valid string [type=string_type, input_value=<class 'your_module.MyPydanticModel'>, input_type=ModelMetaclass]`\n\nThis occurs because `TeamGetResponse` (or a similar schema) expects the `response_model` field to be a string representation of the model's name (e.g., `\"MyPydanticModel\"`), rather than the class object itself.\n\nWhile defining `response_model` as a class is crucial for the `Team`'s internal operations (like validating the output structure), this conflicts with the API serialization schema.\n\n### Steps to Reproduce\n\n1.  Define a Pydantic model:\n    ```python\n    from pydantic import BaseModel\n\n    class MyCustomResponse(BaseModel):\n        result: str\n    ```\n2.  Create a `Team` instance with this model as `response_model`:\n    ```python\n    from agno.team import Team\n    # ... other necessary imports\n\n    my_team = Team(\n        team_id=\"my-custom-team\",\n        name=\"My Custom Team\",\n        # ... other team parameters\n        response_model=MyCustomResponse # Using the class object\n    )\n    ```\n3.  Add this team to the `Playground`:\n    ```python\n    from agno.playground import Playground\n\n    playground = Playground(\n        # ... other agents/workflows\n        teams=[my_team]\n    )\n    ```\n4.  Run the application and attempt to access the API endpoint that lists or provides details for teams (e.g., `/teams` or `/teams/{team_id}`).\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nThe API endpoint should be able to serialize the team details without error, correctly representing the `response_model`. It could, for instance, use `team.response_model.__name__` to get the string representation if needed for the API response, while the `Team` object itself retains the class reference for its internal logic.\n\n### Actual Behavior\n\nA `pydantic_core._pydantic_core.ValidationError` is raised, preventing the API from successfully returning the details of such teams.\n\n**Impact**\n\n- The API endpoint for viewing team details is broken for teams defined with a class-based `response_model`.\n- The core functionality of the `Team` itself (execution, response validation using the Pydantic model) is likely unaffected, as it correctly uses the class-based `response_model`. The issue is confined to the API's presentation layer.\n\n### Screenshots or Logs (if applicable)\n\n![Image](https://github.com/user-attachments/assets/d7297e0f-5dd9-4495-964b-796164b054fe)\n\n### Environment\n\n```markdown\n*   Agno version: 1.5.0\n*   Pydantic version: 2.11.4\n```\n\n### Possible Solutions (optional)\n\nModify the `TeamGetResponse` schema (or equivalent) in `agno/playground/schemas.py` to intelligently handle the `response_model` attribute. If it's a class, it could serialize its `__name__` attribute for the API response.\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "isikepalaku",
      "author_type": "User",
      "created_at": "2025-05-14T09:46:55Z",
      "updated_at": "2025-06-15T00:39:19Z",
      "closed_at": null,
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3187/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3187",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3187",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:43.768034",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-06-15T00:39:18Z"
        }
      ]
    },
    {
      "issue_number": 3065,
      "title": "Better Method for JSON WebSocket/Event Stream Output Instead of Console Printing",
      "body": "\"Agno, is there a better method that could support outputting JSON through websocket, or using event streams to output to an interface? Currently, most outputs are printed to the console, which isn't very suitable for application development. It requires developers to further process the Run Response from arun, which isn't very user-friendly. I'm wondering if this request is reasonable. Thank you.\"",
      "state": "closed",
      "author": "liujianglc",
      "author_type": "User",
      "created_at": "2025-05-03T07:21:45Z",
      "updated_at": "2025-06-14T23:38:21Z",
      "closed_at": "2025-06-14T23:38:21Z",
      "labels": [
        "enhancement",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3065/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3065",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3065",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:43.977448",
      "comments": [
        {
          "author": "pritipsingh",
          "body": "Hey @liujianglc , can you help me with more details? All we need to do is:\n```\nresponse = await agent.arun(message)\nreturn response.content\n```\n\nHow can we help with better ?",
          "created_at": "2025-05-05T16:31:25Z"
        },
        {
          "author": "liujianglc",
          "body": "> Hey [@liujianglc](https://github.com/liujianglc) , can you help me with more details? All we need to do is:\n> \n> ```\n> response = await agent.arun(message)\n> return response.content\n> ```\n> \n> How can we help with better ?\n\n```\nasync with MCPTools(f\"npx -y @valuprosys/mysql-mcp-server\", env=MYSQL_",
          "created_at": "2025-05-06T00:46:39Z"
        },
        {
          "author": "pritipsingh",
          "body": "Hey @liujianglc  - yes you're right but Just a quick heads-up: in your current implementation,\n\n```\nrun_response = await agent.arun(query, stream=True, stream_intermediate_steps=True)\nreturn run_response.content\n```\n\nyou're trying to access .content directly on run_response, but agent.arun(..., stre",
          "created_at": "2025-05-06T06:57:44Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-06-06T00:34:38Z"
        }
      ]
    },
    {
      "issue_number": 2382,
      "title": "Selenium tooling",
      "body": "## Problem Description\nHaving the agent being able to use a full browser would be powerful, It would allow to do complex tasks such as automating repetitive tasks or scrape informations\n\n## Proposed Solution\nA tool that allows the agent to use selenium\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[ ] Yes, I’d love to work on it!**\n**[x ] I’m open to collaborating but need guidance.**\n**[ ] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "riccardodivirgilio",
      "author_type": "User",
      "created_at": "2025-03-13T05:39:48Z",
      "updated_at": "2025-06-14T22:27:39Z",
      "closed_at": "2025-03-31T00:34:13Z",
      "labels": [
        "enhancement",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2382/reactions",
        "total_count": 3,
        "+1": 3,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2382",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2382",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:44.189642",
      "comments": [
        {
          "author": "riccardodivirgilio",
          "body": "Another reason why this is useful is that it would allow the agent to execute arbitrary Javascript code, since it would run in the browser there would be no harm done on the user machine. So very useful to do generic computations",
          "created_at": "2025-03-13T05:42:40Z"
        },
        {
          "author": "manthanguptaa",
          "body": "Hey @riccardodivirgilio! We would love to have this tool in our SDK. We can guide you along the way! I look forward to your PR. Don't hesitate to reach out for help ",
          "created_at": "2025-03-13T08:25:37Z"
        },
        {
          "author": "ashpreetbedi",
          "body": "@riccardodivirgilio this is awesome and we're here to help! Happy to offer a $500 bounty if you can take it all the way",
          "created_at": "2025-03-13T10:47:57Z"
        },
        {
          "author": "evan31415926",
          "body": "why not use brower-use tool ? this is a great tool used by manus.",
          "created_at": "2025-03-16T03:35:30Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-03-31T00:34:12Z"
        }
      ]
    },
    {
      "issue_number": 3568,
      "title": "[Bug] Streaming not working with AzureAIFoundry",
      "body": "### Description\n\nHaving an agent with model AzureAIFoundry, when using agent.print_response with stream=True I get the following error: AttributeError: 'NoneType' object has no attribute 'content'\nWithout streaming it works correctly\n\n### Steps to Reproduce\n\nuse print_response with stream=True\n\n### Agent Configuration (if applicable)\n\nfrom typing import Iterator  # noqa\n\nfrom agno.agent import Agent, RunResponse  # noqa\nfrom agno.models.azure import AzureAIFoundry\n\nmodel = AzureAIFoundry(\n    id=\"gpt-4o-mini\",  api_key=\"******\",\n    azure_endpoint=\"*****\",\n)\n\nagent = Agent(model=model, markdown=True)\n\nagent.print_response(\"Share a 2 sentence horror story\", stream=True)\n\n\n### Expected Behavior\n\nGet a complete response\n\n### Actual Behavior\n\nGet an error\n\n### Screenshots or Logs (if applicable)\n\nPS C:\\Python\\prova> uv run main.py\nERROR    Error parsing Azure AI response delta: 'NoneType' object has no attribute 'content'\n▰▰▰▰▰▰▰ Thinking...\n┏━ Message ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                                                                      ┃\n┃ Share a 2 sentence horror story                                                                                      ┃\n┃                                                                                                                      ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n┏━ Response (1.4s) ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                                                                      ┃\n┃ As she tucked her daughter into bed, the little girl whispered, \"Mommy, there's someone in my closet.\" The mother    ┃\n┃ smiled and said, \"Don't worry, honey; I'll check,\" but when she opened the closet, she found her daughter crying in  ┃\n┃ the corner, saying, \"Mommy, there's someone in my bed.\"                                                              ┃\n┃                                                                                                                      ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\nTraceback (most recent call last):\n  File \"C:\\Python\\prova\\.venv\\Lib\\site-packages\\agno\\models\\azure\\ai_foundry.py\", line 395, in parse_provider_response_delta\n    if delta.content is not None:\n       ^^^^^^^^^^^^^\nAttributeError: 'NoneType' object has no attribute 'content'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Python\\prova\\main.py\", line 19, in <module>\n    agent.print_response(\"Share a 2 sentence horror story\", stream=True)\n  File \"C:\\Python\\prova\\.venv\\Lib\\site-packages\\agno\\agent\\agent.py\", line 6615, in print_response\n    for resp in self.run(\n                ^^^^^^^^^\n  File \"C:\\Python\\prova\\.venv\\Lib\\site-packages\\agno\\agent\\agent.py\", line 790, in _run_stream\n    for event in self._handle_model_response_stream(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python\\prova\\.venv\\Lib\\site-packages\\agno\\agent\\agent.py\", line 2988, in _handle_model_response_stream\n    for model_response_event in self.model.response_stream(\n                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python\\prova\\.venv\\Lib\\site-packages\\agno\\models\\base.py\", line 764, in response_stream\n    yield from self.process_response_stream(\n  File \"C:\\Python\\prova\\.venv\\Lib\\site-packages\\agno\\models\\base.py\", line 733, in process_response_stream\n    model_response_delta = self.parse_provider_response_delta(response_delta)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python\\prova\\.venv\\Lib\\site-packages\\agno\\models\\azure\\ai_foundry.py\", line 411, in parse_provider_response_delta\n    raise ModelProviderError(message=str(e), model_name=self.name, model_id=self.id) from e\nagno.exceptions.ModelProviderError: 'NoneType' object has no attribute 'content'\n\n### Environment\n\n```markdown\nOS: Windows 11\nAgno Version: 1.6.2\n\n[project]\nname = \"prova\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nreadme = \"README.md\"\nrequires-python = \">=3.12\"\ndependencies = [\n    \"agno>=1.6.0\",\n    \"azure-ai-inference>=1.0.0b9\",\n    \"azure-identity>=1.23.0\",\n    \"azure-keyvault-secrets>=4.9.0\",\n    \"openai>=1.86.0\",\n]\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "dariorucci",
      "author_type": "User",
      "created_at": "2025-06-14T17:56:38Z",
      "updated_at": "2025-06-14T17:56:38Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3568/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3568",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3568",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:44.386311",
      "comments": []
    },
    {
      "issue_number": 3502,
      "title": "[Feature Request] ability to pass version to FastAPIApp",
      "body": "### Problem Description\n\ncurrently we can pass version  FastAPI like this:\n```py\n    # Create FastAPI App\n    app: FastAPI = FastAPI(\n        title=api_settings.title,\n        version=api_settings.version,\n        docs_url=\"/docs\" if api_settings.docs_enabled else None,\n        redoc_url=\"/redoc\" if api_settings.docs_enabled else None,\n        openapi_url=\"/openapi.json\" if api_settings.docs_enabled else None,\n    )\n```\nwonder if can do same with new `FastAPIApp` ?\n\nI am thinking to set app version matching to git tag\n\n### Proposed Solution\n\nexample \n```py\nfastapi_app = FastAPIApp(\n    agents=[web_agent, agno_assist, finance_agent, recipe_agent, reasoning_agent],\n    teams=[finance_researcher_team, multi_language_team],\n    workflows=[blog_post_generator, investment_report_generator],\n    name=api_settings.title,\n    version=api_settings.version, \n    app_id=\"advanced-app\",\n    description=\"A FastAPI app for advanced agents\",\n)\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "xmlking",
      "author_type": "User",
      "created_at": "2025-06-07T19:15:27Z",
      "updated_at": "2025-06-14T16:57:00Z",
      "closed_at": "2025-06-13T15:27:50Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3502/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3502",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3502",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:44.386331",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-426/feature-request-ability-to-pass-version-to-fastapiapp\">SUPPORT-426 [Feature Request] ability to pass version to FastAPIApp</a></p>",
          "created_at": "2025-06-07T19:15:30Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Released with 1.6.1!",
          "created_at": "2025-06-13T15:27:50Z"
        },
        {
          "author": "xmlking",
          "body": "it would be nice to add version for other apps, e,g: playground, agui etc",
          "created_at": "2025-06-14T16:57:00Z"
        }
      ]
    },
    {
      "issue_number": 3507,
      "title": "[Bug] LightRAG with authentication",
      "body": "### Description\n\n```python\n2025-06-10 00:00:53 DEBUG ************************  METRICS  *************************              \n2025-06-10 00:00:53 DEBUG * Tokens:                      input=971, output=23, total=994            \n2025-06-10 00:00:53 DEBUG * Time:                        1.2990s                                    \n2025-06-10 00:00:53 DEBUG * Tokens per second:           17.7057 tokens/s                           \n2025-06-10 00:00:53 DEBUG * Time to first token:         1.2940s                                    \n2025-06-10 00:00:53 DEBUG ************************  METRICS  *************************              \n2025-06-10 00:00:53 DEBUG Running: asearch_knowledge_base(query=...)                                \n2025-06-10 00:00:53 ERROR    HTTP Request Error: ConnectError: All connection attempts failed       \n2025-06-10 00:00:53 DEBUG Time to get references: 0.0204s                                           \n2025-06-10 00:00:53 DEBUG =========================== tool ===========================              \n2025-06-10 00:00:53 DEBUG Tool call Id: b9b78639-2e49-4891-ad17-0d0664f06a04                        \n2025-06-10 00:00:53 DEBUG No documents found                                                        \n2025-06-10 00:00:53 DEBUG **********************  TOOL METRICS  **********************  \n```\n\n### Steps to Reproduce\n\nfollowing the documentation [https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/agentic_search/lightrag/agentic_rag_with_lightrag.py](url)\n\nmy lightrag deployment has api enable\n\n```python\nknowledge_base = LightRagKnowledgeBase(\n    lightrag_server_url=\"http://localhost:9621\",  # URL server LightRAG\n    path=\"data/kuhap\", \n    api_key=os.getenv(\"LIGHTRAG_API_KEY\"), \n)\n```\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nshould be doing query\n\n### Actual Behavior\n\n```markdown\n2025-06-10 00:00:53 DEBUG ************************  METRICS  *************************              \n2025-06-10 00:00:53 DEBUG * Tokens:                      input=971, output=23, total=994            \n2025-06-10 00:00:53 DEBUG * Time:                        1.2990s                                    \n2025-06-10 00:00:53 DEBUG * Tokens per second:           17.7057 tokens/s                           \n2025-06-10 00:00:53 DEBUG * Time to first token:         1.2940s                                    \n2025-06-10 00:00:53 DEBUG ************************  METRICS  *************************              \n2025-06-10 00:00:53 DEBUG Running: asearch_knowledge_base(query=...)                                \n2025-06-10 00:00:53 ERROR    HTTP Request Error: ConnectError: All connection attempts failed       \n2025-06-10 00:00:53 DEBUG Time to get references: 0.0204s                                           \n2025-06-10 00:00:53 DEBUG =========================== tool ===========================              \n2025-06-10 00:00:53 DEBUG Tool call Id: b9b78639-2e49-4891-ad17-0d0664f06a04                        \n2025-06-10 00:00:53 DEBUG No documents found                                                        \n2025-06-10 00:00:53 DEBUG **********************  TOOL METRICS  **********************  \n```\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nagno==1.5.10\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "isikepalaku",
      "author_type": "User",
      "created_at": "2025-06-08T18:29:05Z",
      "updated_at": "2025-06-14T06:13:20Z",
      "closed_at": "2025-06-14T06:13:20Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3507/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "willemcdejongh"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3507",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3507",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:44.636908",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-431/bug\">SUPPORT-431 [Bug]</a></p>",
          "created_at": "2025-06-08T18:29:08Z"
        },
        {
          "author": "isikepalaku",
          "body": "lightrag log\n\n```python\n2025-06-09 22:54:47 ✨ Server starting up...\n2025-06-09 22:54:47 \n2025-06-09 22:54:47 \n2025-06-09 22:54:47 🌐 Server Access Information:\n2025-06-09 22:54:47     ├─ WebUI (local): http://localhost:9621\n2025-06-09 22:54:47     ├─ Remote Access: http://<your-ip-address>:9621\n2025-",
          "created_at": "2025-06-09T16:17:34Z"
        },
        {
          "author": "leviethung2103",
          "body": "Could you please provide the .env file for running LightRAG server ?\n\nI think you should comment out the authentication and api_key",
          "created_at": "2025-06-13T16:09:17Z"
        },
        {
          "author": "isikepalaku",
          "body": "> Could you please provide the .env file for running LightRAG server ?\n> \n> I think you should comment out the authentication and api_key\n\nhere's my .env on my lightrag server\n\n\n```python\n### Server ###\nHOST=0.0.0.0\nPORT=9621\nWEBUI_TITLE='LightRAG Demo'\nWEBUI_DESCRIPTION='Knowledge-base RAG playgrou",
          "created_at": "2025-06-13T16:36:27Z"
        },
        {
          "author": "isikepalaku",
          "body": "The connection and “incorrect arguments” errors reported earlier are now **fixed**.  \nKey points:\n\n- **Server endpoint & auth header**  \n  - The default `LightRagKnowledgeBase` and `lightrag_retriever` targets were still set to `http://localhost:9621`, and no `X-API-Key` was being sent.  \n  - I over",
          "created_at": "2025-06-14T06:13:16Z"
        }
      ]
    },
    {
      "issue_number": 3552,
      "title": "[Feature Request] Agent param to hide tool calls from history while using storage",
      "body": "### Problem Description\n\nI have few chat bot agents with storage and some tools that returns massive content. Like 50~100k tokens each tool usage.\n\nSince I'm using the storage with 20 messages history. All those tool calls are being passed into the LLM as history, but I actually dont need the tool calls history, just the LLM response.\n\nOne option is to build a storage/session history manager myself and exclude tool calls from the history.\n\n### Proposed Solution\n\nI wonder if this is a feature worth implementing.\n\nSomething like this:\n```python\nagent = Agent(\n    model=...,\n    tools=[tool_one, tool_two],\n    storage=storage,\n    add_history_to_messages=True,\n    num_history_runs=20,\n    hide_tool_calls_from_history=True,\n)\n```\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [x] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.",
      "state": "open",
      "author": "renanmoretto",
      "author_type": "User",
      "created_at": "2025-06-12T21:05:28Z",
      "updated_at": "2025-06-13T17:18:44Z",
      "closed_at": null,
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3552/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3552",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3552",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:44.867597",
      "comments": [
        {
          "author": "renanmoretto",
          "body": "Actually maybe something like this makes more sense\n```python\nagent = Agent(\n    model=...,\n    tools=[tool_one, tool_two],\n    storage=storage,\n    add_history_to_messages=True,\n    num_history_runs=20,\n    history_roles=['user', 'assistant'], # defaults to ['user', 'assistant', 'tool']\n)\n```",
          "created_at": "2025-06-12T22:57:30Z"
        }
      ]
    },
    {
      "issue_number": 3554,
      "title": "[Bug] AGUIApp fails to emit TEXT_MESSAGE_CONTENT events during streaming - UI shows empty responses",
      "body": "### Description\n\nI was trying to use and develop with ag-ui protocol with Agno.  \n\nThe AGUIApp successfully receives OpenAI streaming responses but fails to convert them into proper AG-UI protocol events. Specifically, TEXT_MESSAGE_CONTENT events are never emitted, resulting in empty message containers in the frontend UI while the agent appears to be \"responding.\"\n\nThe issue occurs in the streaming response conversion layer within AGUIApp. OpenAI API calls work correctly and return streaming content, but the AGUIApp doesn't properly emit the content chunks as TEXT_MESSAGE_CONTENT events.\n\nYou can find the details below, am I missing something?\n\n### Steps to Reproduce\n\n1. Create a basic AGUIApp with OpenAI chat model:\n\n```python\nfrom agno.agent.agent import Agent\nfrom agno.app.agui.app import AGUIApp\nfrom agno.models.openai import OpenAIChat\n\nchat_agent = Agent(\n    name=\"Assistant\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    instructions=\"You are a helpful AI assistant.\",\n)\n\nagui_app = AGUIApp(\n    agent=chat_agent,\n    name=\"Basic AG-UI Agent\",\n    app_id=\"basic_agui_agent\",\n    description=\"A basic agent that demonstrates AG-UI protocol integration.\",\n)\n\napp = agui_app.get_app()\n\nif __name__ == \"__main__\":\n    agui_app.serve(app=\"main:app\", port=8000, reload=True)\n```\n\n2. Run the application: `python main.py`\n3. Connect AG-UI frontend (e.g., Dojo) to http://localhost:8000/agui\n4. Send any message through the UI\n5. Observe that no response content appears in the UI\n\nAlternative test with curl:\n```bash\ncurl -X POST http://localhost:8000/agui \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Accept: text/event-stream\" \\\n  -d '{\"threadId\":\"test\",\"runId\":\"test\",\"state\":{},\"messages\":[{\"id\":\"msg-1\",\"role\":\"user\",\"content\":\"Hello\"}],\"tools\":[],\"context\":[],\"forwardedProps\":{}}'\n```\n\n### Agent Configuration (if applicable)\n\n```python\nfrom agno.agent.agent import Agent\nfrom agno.app.agui.app import AGUIApp\nfrom agno.models.openai import OpenAIChat\n\nchat_agent = Agent(\n    name=\"Assistant\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    instructions=\"You are a helpful AI assistant.\",\n)\n\nagui_app = AGUIApp(\n    agent=chat_agent,\n    name=\"Basic AG-UI Agent\", \n    app_id=\"basic_agui_agent\",\n    description=\"A basic agent that demonstrates AG-UI protocol integration.\",\n)\n```\n\n### Expected Behavior\n\nThe AGUIApp should emit a complete sequence of AG-UI protocol events:\n\ndata: {\"type\":\"RUN_STARTED\",\"threadId\":\"test\",\"runId\":\"test\"}\ndata: {\"type\":\"TEXT_MESSAGE_START\",\"messageId\":\"xxx\",\"role\":\"assistant\"}\ndata: {\"type\":\"TEXT_MESSAGE_CONTENT\",\"messageId\":\"xxx\",\"content\":\"Hello! How can I help you today?\"}\ndata: {\"type\":\"TEXT_MESSAGE_END\",\"messageId\":\"xxx\"}\ndata: {\"type\":\"RUN_FINISHED\",\"threadId\":\"test\",\"runId\":\"test\"}\n\n### Actual Behavior\n\nAGUIApp curl response shows missing TEXT_MESSAGE_CONTENT:\n\ndata: {\"type\":\"RUN_STARTED\",\"threadId\":\"test\",\"runId\":\"test\"}\ndata: {\"type\":\"TEXT_MESSAGE_START\",\"messageId\":\"993bf9b3-ab64-427a-92eb-e8cea3455399\",\"role\":\"assistant\"}\ndata: {\"type\":\"TEXT_MESSAGE_END\",\"messageId\":\"993bf9b3-ab64-427a-92eb-e8cea3455399\"}\ndata: {\"type\":\"RUN_FINISHED\",\"threadId\":\"test\",\"runId\":\"test\"}\n\n### Screenshots or Logs (if applicable)\n\n![Image](https://github.com/user-attachments/assets/21d8cebb-a310-46c6-8d83-7a0c5856c1b1)\n\n**Debug logs show OpenAI streaming works correctly:**\nDEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'text/event-stream; charset=utf-8')])\nINFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\nDEBUG:httpcore.http11:receive_response_body.complete\n\n**But AGUIApp curl response shows missing TEXT_MESSAGE_CONTENT:**\ndata: {\"type\":\"RUN_STARTED\",\"threadId\":\"test\",\"runId\":\"test\"}\ndata: {\"type\":\"TEXT_MESSAGE_START\",\"messageId\":\"993bf9b3-ab64-427a-92eb-e8cea3455399\",\"role\":\"assistant\"}\ndata: {\"type\":\"TEXT_MESSAGE_END\",\"messageId\":\"993bf9b3-ab64-427a-92eb-e8cea3455399\"}\ndata: {\"type\":\"RUN_FINISHED\",\"threadId\":\"test\",\"runId\":\"test\"}\n\n### Environment\n\n```markdown\n- Browser: Chrome/Safari/Firefox (issue occurs in all)\n- Agno Version: 1.6.0\n- ag-ui-protocol Version: 0.1.5\n- Python Version: 3.12\n- OpenAI API: Working correctly with valid API key\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "ozbekburak",
      "author_type": "User",
      "created_at": "2025-06-13T08:30:31Z",
      "updated_at": "2025-06-13T16:07:51Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3554/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3554",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3554",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:45.082684",
      "comments": [
        {
          "author": "manuhortet",
          "body": "Hey @ozbekburak, thank you so much for reporting this! We have found the problem. A recent update partly broke this AG-UI integration. We have a working fix [here](https://github.com/agno-agi/agno/pull/3560) already, we will merge and release soon. \n\nThanks for using Agno and let us know if we can h",
          "created_at": "2025-06-13T16:07:51Z"
        }
      ]
    },
    {
      "issue_number": 3542,
      "title": "[Feature Request] Technical support request for integrating on-premises DeepSeek models in Agno",
      "body": "### Problem Description\n\nI am using the Agno tool for development, but I found that I cannot directly call the local DeepSeek model provided by the company. We have obtained the base_url and api-key of the model and hope to call the model in Agno. Since Agno does not seem to support the configuration or extension of custom APIs at present, the development team is needed to assist in evaluation and provide possible solutions or adaptation methods.\n\nPlease help the development team to confirm the following points:\n\nDoes Agno support calling external models through custom API configuration;\n\nIf supported, please provide relevant configuration instructions or documents;\nIf not supported, can this feature be considered in subsequent versions, or are there other alternatives.\n\nThank you!\n\n### Proposed Solution\n\nNone\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "KeplerrC",
      "author_type": "User",
      "created_at": "2025-06-12T07:24:38Z",
      "updated_at": "2025-06-13T15:28:36Z",
      "closed_at": "2025-06-13T15:28:36Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3542/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3542",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3542",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:45.257993",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Have you tried to use the Deepseek model with a custom base_url and api_key? \n\n```\nagent = Agent(\n    model=DeepSeek(id=\"deepseek-chat\", base_url=\"https://localhost:8080\", api_key=\"<KEY>\"),\n)\n```",
          "created_at": "2025-06-12T13:14:10Z"
        },
        {
          "author": "KeplerrC",
          "body": "Thank you very much for your answer. Calling the company's API requires some other parameters, but I have solved my problem. Thank you again.",
          "created_at": "2025-06-13T02:24:03Z"
        }
      ]
    },
    {
      "issue_number": 3510,
      "title": "[Bug] Whatapp API's Image Artficat sends only one image",
      "body": "### Description\n\nAlthough the Image Artifacts that whatsapp api uses is a List, It's able to send only one image at a time.\n\nExample :\n\n`image_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"), # Ensure OPENAI_API_KEY is set\n    tools=[OpenAITools(image_model=\"gpt-image-1\")],\n    markdown=True,\n    show_tool_calls=True,\n    debug_mode=True,\n    add_history_to_messages=True,\n)\n\n# Async router by default (use_async=True)\nwhatsapp_app = WhatsappAPI(\n    agent=image_agent,\n    name=\"Image Generation Tools\",\n    app_id=\"image_generation_tools\",\n    description=\"A tool that generates images using the OpenAI API.\",\n)\n`\n\nIf we ask for 2 images, Although the agent calls the tools twice and generates two images, the whatsapp api is sending only one image.\n\n### Steps to Reproduce\n\nRun the above code or https://docs.agno.com/applications/whatsapp/introduction.\n\nAsk for 2 images.  example: generate 2 images of dogs.\n\nThe agent will create 2 images but the whatsapp api will send only one image\n\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nShould have sent the 2 generate images.\n\n### Actual Behavior\n\nSent only one Image\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nmacOS, latest agno version\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "AkashS0510",
      "author_type": "User",
      "created_at": "2025-06-09T08:36:22Z",
      "updated_at": "2025-06-13T15:28:08Z",
      "closed_at": "2025-06-13T15:28:08Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3510/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3510",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3510",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:45.443440",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-451/bug-whatapp-apis-image-artficat-sends-only-one-image\">SUPPORT-451 [Bug] Whatapp API's Image Artficat sends only one image</a></p>",
          "created_at": "2025-06-09T08:36:25Z"
        },
        {
          "author": "AkashS0510",
          "body": "@dirkbrnd ",
          "created_at": "2025-06-09T08:36:50Z"
        },
        {
          "author": "VirusDumb",
          "body": "Looking into it 👋",
          "created_at": "2025-06-11T06:22:30Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Released with 1.6.1!",
          "created_at": "2025-06-13T15:28:08Z"
        }
      ]
    },
    {
      "issue_number": 3516,
      "title": "[Bug] DocumentKnowledgeBase not implementing async_document_lists",
      "body": "### Description\n\nDocumentKnowledgeBase doesn't implement async_document_lists which results in an error when running knowledgebase.aload with exception  \"async for' requires an object with __aiter__ method, got coroutine\"\n\n\n### Steps to Reproduce\n\n- Create DocumentKnowledgeBase with documents\n- run `await knowledgebase.aload()`\n- see error\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nrun aload should run as expected with DocumentKnowledgeBase\n\n### Actual Behavior\n\narun fails\n\n### Screenshots or Logs (if applicable)\n\n\n![Image](https://github.com/user-attachments/assets/735f8db1-8801-4eb3-85bb-f2872b5618f7)\n\n![Image](https://github.com/user-attachments/assets/185cde1b-b4b2-4995-9846-2e34d77eb939)\n\n### Environment\n\n```markdown\nmacOS\nAgno 1.5.10\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "Zuttam",
      "author_type": "User",
      "created_at": "2025-06-09T15:43:30Z",
      "updated_at": "2025-06-13T15:27:40Z",
      "closed_at": "2025-06-13T15:27:40Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3516/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kausmeows"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3516",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3516",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:45.659692",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-456/bug-documentknowledgebase-not-implementing-async-document-lists\">SUPPORT-456 [Bug] DocumentKnowledgeBase not implementing async_document_lists</a></p>",
          "created_at": "2025-06-09T15:43:34Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Thanks for raising! Fix incoming",
          "created_at": "2025-06-12T14:49:52Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Released with 1.6.1!",
          "created_at": "2025-06-13T15:27:40Z"
        }
      ]
    },
    {
      "issue_number": 2322,
      "title": "[Bug] Agent not found in Playground after a few queries",
      "body": "# Description\nAgent not found issue in playground after a few queries\n\n## Steps to Reproduce\nCreate a RAG Agent using local PDF Knowledge base\nSetup a playground\nAsk a few queries\nAfter a few queries you should see the error Agent not found\n\n## Agent Configuration (if applicable)\nProvide relevant agent configuration.\n\n## Expected Behavior\nThe behaviour should not change and we should not see this error, it is resolved once I refresh the page.\n\n## Actual Behavior\nWhat actually happened instead?\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- OS: (e.g. macOS, Windows 11)\n- Browser (if relevant): (e.g. Chrome 108, Firefox 107)\n- Agno Version: (e.g. v1.0.0)\n- External Dependency Versions: (e.g., yfinance 0.2.52)\n- Additional Environment Details: (e.g., Python 3.10)\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\n\n<img width=\"701\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/ba6bd2e5-2359-466d-818e-41deffbed82b\" />",
      "state": "closed",
      "author": "adtyavrdhn",
      "author_type": "User",
      "created_at": "2025-03-07T16:18:17Z",
      "updated_at": "2025-06-13T13:21:57Z",
      "closed_at": "2025-03-26T07:01:52Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2322/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2322",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2322",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:45.892240",
      "comments": [
        {
          "author": "anuragts",
          "body": "Hey @adtyavrdhn ,\nCan you share your agent config code, so we can replicate the issue.",
          "created_at": "2025-03-10T08:00:41Z"
        },
        {
          "author": "adtyavrdhn",
          "body": "\nHi @anuragts,\n\nAttaching a snippet below\n```\nagent_config = {\n                # Azure OpenAI model doesn't work as expected, we are seeing error from OpenAi about some user parameters\n                # I'll raise a bug with agno or see if we can fix it ourselves, given it is open source\n           ",
          "created_at": "2025-03-13T05:18:32Z"
        },
        {
          "author": "anuragts",
          "body": "Hey @adtyavrdhn can you try this code, its similar to your code. I have tested it and  it should work as expected. If you run into any issues, feel free to reach out—I’d be happy to help\n\n```python\nfrom agno.agent import Agent\nfrom agno.tools.googlesearch import GoogleSearchTools\nfrom agno.models.az",
          "created_at": "2025-03-15T15:56:19Z"
        },
        {
          "author": "monali7-d",
          "body": "Hi @adtyavrdhn,\nclosing this issue due to inactivity\n",
          "created_at": "2025-03-26T07:01:52Z"
        },
        {
          "author": "adtyavrdhn",
          "body": "Hi, yeah that's okay I haven't tried it in a while. Thank you!",
          "created_at": "2025-06-13T13:21:57Z"
        }
      ]
    },
    {
      "issue_number": 2812,
      "title": "Streaming structured output in Agent Teams",
      "body": "## Problem Description\nI'm encountering an iteration error when using the Team class from the agno library. Specifically, when I try to stream the response from a team.run() call, I get a TypeError indicating that 'RunResponse' object is not iterable, despite using the stream=True parameter.\n## Proposed Solution\nThe Team.run() method should properly support streaming when stream=True is specified. The RunResponse object returned when streaming is enabled should implement the iterator protocol so that it can be consumed in a for loop as expected.\nThe fix would likely involve:\n\nEnsuring the RunResponse class has proper __iter__ and __next__ methods\nMaking sure the streaming functionality correctly returns an iterable response\n\n\n<img width=\"1252\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/b9db1aab-f91d-410b-8b93-e8dc02a1b9ed\" />\n\n```\nresponse = team.run(\"What is the current stock price of NVDA?\", stream=True)\nfor chunk in response:\n    print(chunk)\n```",
      "state": "closed",
      "author": "igorwang",
      "author_type": "User",
      "created_at": "2025-04-14T03:15:47Z",
      "updated_at": "2025-06-13T02:02:30Z",
      "closed_at": "2025-06-13T02:02:30Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2812/reactions",
        "total_count": 3,
        "+1": 3,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2812",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2812",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:46.052912",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hey @igorwang ,\nThank you so much for raising this — really appreciate you taking the time to share your thoughts! This is on our roadmap.\n\nAlso, since Agno is open source, if you feel excited about it, feel free to tag a GO and take a crack at building it! We’d absolutely love to see your contribut",
          "created_at": "2025-04-15T06:30:08Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-05-16T00:34:30Z"
        },
        {
          "author": "siddythings",
          "body": "Cannot reproduce the issue.\n\nTested the reported scenario using the latest version of `agno`, and the `RunResponse` object returned by `team.run(..., stream=True)` is iterable as expected. No `TypeError` was raised during iteration:\n\n```python\nfrom agno.team.team import Team\nfrom agno.models.openai ",
          "created_at": "2025-05-22T08:59:15Z"
        }
      ]
    },
    {
      "issue_number": 3106,
      "title": "How do I stop an agent run?",
      "body": "I have agno running agents on the server side. On the client side, there's a custom chat interface. If the user hit's the stop button via the chat interface, how do I actually stop the agent server side?\n\nI'm running the agent like this:\n```\n            for chunk in agent.run(content, stream=True,\n                                   reasoning_use_tools=True,\n                                   stream_intermediate_steps=True,\n                                   show_full_reasoning=True):\n                process_run_chunk(chunk, conversation_id, user_id)\n```\nSo I would keep track of the agent in the session data, and then when the client hits the stop_agent endpoint, I would terminate it. But how do I actually terminate it?",
      "state": "open",
      "author": "SethTurin",
      "author_type": "User",
      "created_at": "2025-05-07T00:54:33Z",
      "updated_at": "2025-06-13T00:35:14Z",
      "closed_at": null,
      "labels": [
        "stale"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3106/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3106",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3106",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:46.241783",
      "comments": [
        {
          "author": "SethTurin",
          "body": "Any help on this would be greatly appreciated",
          "created_at": "2025-05-09T20:50:58Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @SethTurin \nWe are very sorry in the delay in responding. I have passed this question to our engineers and we will get back to you asap",
          "created_at": "2025-05-12T08:19:36Z"
        },
        {
          "author": "Ayush0054",
          "body": "Hey @SethTurin ,\nAre you referring to stop the  streaming  while the agent is streaming output?\nThat’s not supported just yet  ,but it is on our roadmap!\n\nThanks! 🙌",
          "created_at": "2025-05-12T11:53:46Z"
        },
        {
          "author": "SethTurin",
          "body": "@Ayush0054 Well if you look at it from the perspective of a chat window, the user might hit stop during the thought phase, or a tool call, or the output stream. So I think just a universal agent.stop() is what I'm looking for.\n\nIn the meantime, what do you recommend? Should I just run it on a thread",
          "created_at": "2025-05-12T19:30:05Z"
        },
        {
          "author": "Ayush0054",
          "body": "hey @SethTurin Yes running in a thread and killing the thread would work .",
          "created_at": "2025-05-13T10:10:23Z"
        }
      ]
    },
    {
      "issue_number": 3540,
      "title": "[Bug] No transcript available for the YouTube Video",
      "body": "### Description\n\nfrom agno.agent import Agent\nimport os\nfrom dotenv import load_dotenv\nfrom agno.agent import Agent\nfrom agno.models.google import Gemini\nfrom agno.tools.youtube import YouTubeTools\n\nload_dotenv()\nos.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n\nagent = Agent(\n    model=Gemini(),\n    tools=[YouTubeTools()],\n    show_tool_calls=True,\n    description=\"You are a YouTube agent. Obtain the captions of a YouTube video and answer questions.\",\n)\n\nagent.print_response(\"Summarize this video https://www.youtube.com/watch?v=Iv9dewmcFbs&t\", markdown=True)\n\nThis is the code which I am trying to run , but its continuously showing that \"No transcript are available for the video and captions are not enabled\" . But the video has captions and transcripts both.\nAlso tried to change the video many times.\n\n### Steps to Reproduce\n\nSet up an agent using Gemini and YouTubeTools() as shown above.\n\nUse agent.print_response to query a YouTube video with known captions.\n\nObserve that the response says: \"No transcript are available for the video and captions are not enabled.\"\n\n\n\n### Agent Configuration (if applicable)\n\nagent = Agent(\n    model=Gemini(),\n    tools=[YouTubeTools()],\n    show_tool_calls=True,\n    description=\"You are a YouTube agent. Obtain the captions of a YouTube video and answer questions.\",\n)\n\n\n### Expected Behavior\n\nExpected the agent to retrieve the captions or transcript of the specified YouTube video and provide a summarized response.\n\n### Actual Behavior\n\nThe agent returns an error message stating that no transcript is available and captions are not enabled, even when the video clearly has them.\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nOS: Windows 11\n\nBrowser (if relevant): Chrome 137\n\nAgno Version: v0.5.1\n\nExternal Dependencies:\n\nopenai: 1.3.5\n\nlangchain: 0.0.350\n\npython-dotenv: 1.0.1\n\nPython Version: 3.12\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "sanika-jain",
      "author_type": "User",
      "created_at": "2025-06-11T15:54:04Z",
      "updated_at": "2025-06-12T15:08:51Z",
      "closed_at": "2025-06-12T15:08:51Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3540/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3540",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3540",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:46.438444",
      "comments": [
        {
          "author": "mishramonalisha76",
          "body": "Hi @sanika-jain , I tested it and upgrading to the latest `youtube-transcript-api` works for me. You can try the same and it should work.",
          "created_at": "2025-06-12T14:29:39Z"
        },
        {
          "author": "sanika-jain",
          "body": "\nThanks @mishramonalisha76 , it worked.",
          "created_at": "2025-06-12T15:08:42Z"
        }
      ]
    },
    {
      "issue_number": 3418,
      "title": "[Feature Request] The agent replies too slowly",
      "body": "### Problem Description\n\nI use the agent to execute the code with the same logic and the same prompt, why is the agent executing much slower than directly calling the large model?\n\n### Proposed Solution\n\nI use the agent to execute the code with the same logic and the same prompt, why is the agent executing much slower than directly calling the large model?\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.",
      "state": "open",
      "author": "sznariOsmosis",
      "author_type": "User",
      "created_at": "2025-05-30T01:21:00Z",
      "updated_at": "2025-06-12T13:30:51Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3418/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3418",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3418",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:46.627623",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-347/feature-request-the-agent-replies-too-slowly\">SUPPORT-347 [Feature Request] The agent replies too slowly</a></p>",
          "created_at": "2025-05-30T01:21:03Z"
        },
        {
          "author": "ysolanky",
          "body": "Hi @sznariOsmosis ! Can you please share your Agent configuration so that I can help you better",
          "created_at": "2025-05-30T03:24:10Z"
        },
        {
          "author": "sznariOsmosis",
          "body": "> Hi [@sznariOsmosis](https://github.com/sznariOsmosis) ! Can you please share your Agent configuration so that I can help you better\nfrom agno.agent import Agent\nfrom agno.models.openai import OpenAIChat\nfrom agno.models.openai.like import OpenAILike\nfrom textwrap import dedent\nimport time\n\n\nreason",
          "created_at": "2025-05-30T09:33:38Z"
        },
        {
          "author": "sznariOsmosis",
          "body": "Measured that it takes me 0.22 seconds to directly call the classification of the llm model, while it takes me 3~4 seconds to use the agno agent，Direct call to the code sample：messages = [{\"role\": \"system\", \"content\": prompt},\n            {\"role\": \"user\", \"content\": \"What is the working power supply",
          "created_at": "2025-05-30T09:37:49Z"
        },
        {
          "author": "AmoabaKelvin",
          "body": "a bit of code formatting in the issue will help a lot",
          "created_at": "2025-05-30T12:04:16Z"
        }
      ]
    },
    {
      "issue_number": 3430,
      "title": "[Bug] Connection error w/ Anthropic Models on Playground",
      "body": "### Description\n\nHello, guys. First of all, loving the Agno framework so far. \nAmazing job!\n\nI've started to face a new bug today, specifically with Agents based on Anthropic models inside the Playground.\n\nWhen I run my agent through Playground, I'm getting \"Something went wrong. Connection error.\", just after I say something. If I change the model to OpenAI, it works perfectly.\n\nThanks in advance.\n\n### Steps to Reproduce\n\n1. Just execute the code bellow\n\n### Agent Configuration (if applicable)\n\n```python\nfrom agno.agent import Agent\nfrom agno.models.openai import OpenAIChat\nfrom agno.models.anthropic import Claude\n\nfrom agno.memory.v2.db.sqlite import SqliteMemoryDb\nfrom agno.memory.v2.memory import Memory\nfrom agno.storage.sqlite import SqliteStorage\n\nfrom agno.tools.tavily import TavilyTools\nfrom agno.playground import Playground, serve_playground_app\nimport json\nfrom pymongo import MongoClient, ASCENDING\nimport yaml\n\nfrom dotenv import load_dotenv\nload_dotenv()\n\n\nagent_storage: str = \"tmp/agents.db\"\n\n\n\nreels_creator_prompt = yaml.safe_load(open(\"prompts/reels_creator.yaml\"))\nreels_creator = Agent(\n    model=Claude(id=\"claude-sonnet-4-20250514\"),\n    # model=OpenAIChat(id=\"gpt-4o-mini\"),\n    name=\"Reels Creator\",\n    storage=SqliteStorage(table_name=\"agent_sessions\", db_file=agent_storage),\n\n    add_history_to_messages=True,\n    num_history_runs=3,\n    \n    show_tool_calls=True,\n    description=reels_creator_prompt[\"description\"],\n    instructions=reels_creator_prompt[\"instructions\"]\n)\n\n\n\napp = Playground(agents=[\n        reels_creator\n]).get_app()\n\nif __name__ == \"__main__\":\n    serve_playground_app(\"ig_modeller:app\", reload=True)\n```\n\n### Expected Behavior\n\nThe agent start to answer.\n\n### Actual Behavior\n\nGot the error described.\n\n### Screenshots or Logs (if applicable)\n\n```log\nuv run ig_modeller.py                                       2 х │ 6m 31s │ agno_mcp Py │ base Py │ 16:09:58 \nwarning: `VIRTUAL_ENV=/Users/rtadewald/Projetos-Locais/Tools/MCPs/agno_mcp/.venv` does not match the project environment path `.venv` and will be ignored; use `--active` to target the active environment instead\nINFO Starting playground on http://localhost:7777                                                                                     \n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ Agent Playground ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                             ┃\n┃                                                                             ┃\n┃  Playground URL: https://app.agno.com/playground?endpoint=localhost%3A7777  ┃\n┃                                                                             ┃\n┃                                                                             ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\nINFO:     Will watch for changes in these directories: ['/Users/rtadewald/Projetos-Locais/Tools/Agno']\nINFO:     Uvicorn running on http://localhost:7777 (Press CTRL+C to quit)\nINFO:     Started reloader process [15288] using WatchFiles\nINFO:     Started server process [15296]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     127.0.0.1:61489 - \"OPTIONS /v1/playground/status HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:61491 - \"GET /v1/playground/status HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:61489 - \"OPTIONS /v1/playground/agents HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:61493 - \"OPTIONS /v1/playground/agents/830f12dc-d8d3-40b8-824c-e8505ec69ca9/sessions/0e7355f0-20f0-45b8-98d1-96dc68fa3ce5?user_id=rodrigo.tadewald_3414 HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:61491 - \"GET /v1/playground/agents HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:61495 - \"GET /v1/playground/agents/830f12dc-d8d3-40b8-824c-e8505ec69ca9/sessions/0e7355f0-20f0-45b8-98d1-96dc68fa3ce5?user_id=rodrigo.tadewald_3414 HTTP/1.1\" 404 Not Found\nINFO:     127.0.0.1:61493 - \"OPTIONS /v1/playground/agents/f67bfbbd-28cf-4c3c-b648-77d513ec67d6/sessions?user_id=rodrigo.tadewald_3414 HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:61489 - \"OPTIONS /v1/playground/agents/f67bfbbd-28cf-4c3c-b648-77d513ec67d6/sessions/0e7355f0-20f0-45b8-98d1-96dc68fa3ce5?user_id=rodrigo.tadewald_3414 HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:61495 - \"GET /v1/playground/agents/f67bfbbd-28cf-4c3c-b648-77d513ec67d6/sessions?user_id=rodrigo.tadewald_3414 HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:61491 - \"GET /v1/playground/agents/f67bfbbd-28cf-4c3c-b648-77d513ec67d6/sessions/0e7355f0-20f0-45b8-98d1-96dc68fa3ce5?user_id=rodrigo.tadewald_3414 HTTP/1.1\" 404 Not Found\nINFO:     127.0.0.1:61491 - \"GET /v1/playground/status HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:61495 - \"GET /v1/playground/agents HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:61498 - \"GET /v1/playground/agents/830f12dc-d8d3-40b8-824c-e8505ec69ca9/sessions/0e7355f0-20f0-45b8-98d1-96dc68fa3ce5?user_id=rodrigo.tadewald_3414 HTTP/1.1\" 404 Not Found\nINFO:     127.0.0.1:61499 - \"GET /v1/playground/agents/f67bfbbd-28cf-4c3c-b648-77d513ec67d6/sessions/0e7355f0-20f0-45b8-98d1-96dc68fa3ce5?user_id=rodrigo.tadewald_3414 HTTP/1.1\" 404 Not Found\nINFO:     127.0.0.1:61501 - \"GET /v1/playground/agents/f67bfbbd-28cf-4c3c-b648-77d513ec67d6/sessions?user_id=rodrigo.tadewald_3414 HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:61489 - \"OPTIONS /v1/playground/agents/f67bfbbd-28cf-4c3c-b648-77d513ec67d6/runs HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:61489 - \"POST /v1/playground/agents/f67bfbbd-28cf-4c3c-b648-77d513ec67d6/runs HTTP/1.1\" 200 OK\nERROR    Connection error while calling Claude API: Connection error.                                                                 \nTraceback (most recent call last):\n  File \"/Users/rtadewald/Projetos-Locais/Tools/Agno/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 101, in map_httpcore_exceptions\n    yield\n  File \"/Users/rtadewald/Projetos-Locais/Tools/Agno/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 394, in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/rtadewald/Projetos-Locais/Tools/Agno/.venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n    raise exc from None\nhttpcore.ConnectError\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/rtadewald/Projetos-Locais/Tools/Agno/.venv/lib/python3.12/site-packages/anthropic/_base_client.py\", line 1561, in request\n    response = await self._client.send(\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/rtadewald/Projetos-Locais/Tools/Agno/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1629, in send\n    response = await self._send_handling_auth(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/rtadewald/Projetos-Locais/Tools/Agno/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1657, in _send_handling_auth\n    response = await self._send_handling_redirects(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nhttpx.ConnectError\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/rtadewald/Projetos-Locais/Tools/Agno/.venv/lib/python3.12/site-packages/agno/models/anthropic/claude.py\", line 405, in ainvoke_stream\n    async with self.get_async_client().messages.stream(\n  File \"/Users/rtadewald/Projetos-Locais/Tools/Agno/.venv/lib/python3.12/site-packages/anthropic/lib/streaming/_messages.py\", line 288, in __aenter__\n    raw_stream = await self.__api_request\n                 ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/rtadewald/Projetos-Locais/Tools/Agno/.venv/lib/python3.12/site-packages/anthropic/_base_client.py\", line 1819, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nanthropic.APIConnectionError: Connection error.\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/rtadewald/Projetos-Locais/Tools/Agno/.venv/lib/python3.12/site-packages/agno/app/playground/async_router.py\", line 70, in chat_response_streamer\n    async for run_response_chunk in run_response:\n  File \"/Users/rtadewald/Projetos-Locais/Tools/Agno/.venv/lib/python3.12/site-packages/agno/agent/agent.py\", line 1171, in _arun_stream\n    async for event in self._ahandle_model_response_stream(\n  File \"/Users/rtadewald/Projetos-Locais/Tools/Agno/.venv/lib/python3.12/site-packages/agno/agent/agent.py\", line 2993, in _ahandle_model_response_stream\n    async for model_response_chunk in model_response_stream:  # type: ignore\nagno.exceptions.ModelProviderError: Connection error.\n```\n\n### Environment\n\n```markdown\n- MacOS Sequoia 15.5\n- agno==1.5.6\n- anthropic==0.52.1\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "rtadewald",
      "author_type": "User",
      "created_at": "2025-05-30T19:16:59Z",
      "updated_at": "2025-06-12T13:28:58Z",
      "closed_at": "2025-06-12T13:28:44Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3430/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3430",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3430",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:46.875122",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-351/bug-connection-error-w-anthropic-models-on-playground\">SUPPORT-351 [Bug] Connection error w/ Anthropic Models on Playground</a></p>",
          "created_at": "2025-05-30T19:17:02Z"
        },
        {
          "author": "rtadewald",
          "body": "Looks like Groq and Gemini doesn't work too",
          "created_at": "2025-05-30T19:58:37Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@rtadewald are you still experiencing this? We don't have any such issues, I am wondering whether it is a network issue on your side? \n",
          "created_at": "2025-06-06T10:12:44Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Closing for now, please let me know if you get stuck still",
          "created_at": "2025-06-12T13:28:58Z"
        }
      ]
    },
    {
      "issue_number": 3432,
      "title": "[Feature Request] Support Streaming Reasoning Process Output",
      "body": "### Problem Description\n\n# Title\n[Feature Request] Support Streaming Reasoning Process Output\n\n## Description\nCurrently, agno caches the entire reasoning process and outputs all reasoning steps at once after completion. This prevents users from seeing the model's thinking process in real-time, which reduces the interactive experience.\n\n## Current Behavior\n1. When `show_full_reasoning=True` is enabled, the model performs reasoning\n2. The reasoning process is cached and output only after completion\n3. Users must wait for the entire reasoning process to complete before seeing any thinking content\n\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\n## Expected Behavior\n1. Support streaming output of the reasoning process, similar to streaming response content\n2. Send new reasoning content to the frontend immediately via event stream as soon as the model generates it\n3. Allow frontend to display the model's thinking process in real-time, enhancing the interactive experience\n\n## Technical Implementation Suggestions\n1. Add streaming processing for reasoning content in `_handle_model_response_chunk`\n2. Add new event type for reasoning process, e.g., `ReasoningChunk`\n3. Modify `ModelResponse` structure to support streaming reasoning content\n4. Add streaming reasoning configuration option in Agent class\n\n## Code Example\n```python\n# Current code\nresponse = agent.run(task, stream=True, show_full_reasoning=True)\n\n# Expected streaming reasoning output\nasync for chunk in response:\n    if chunk.event == \"ReasoningChunk\":\n        print(f\"Reasoning: {chunk.reasoning_content}\")\n    elif chunk.event == \"AssistantResponse\":\n        print(f\"Response: {chunk.content}\")\n```\n\n## Priority\n- Importance: High\n- Urgency: Medium\n- Impact: All users utilizing reasoning functionality\n\n## Related Components\n- agno.agent.Agent\n- agno.models.base.ModelResponse\n- agno.models.base.ModelResponseChunk\n\n## Additional Information\n- This feature is particularly useful for debugging and demonstrating AI's thinking process\n- Can improve user understanding and trust in AI's decision-making process\n- Facilitates development of more complex AI applications, such as multi-step reasoning and problem decomposition\n\n## Use Cases\n1. Real-time debugging of AI decision-making\n2. Educational applications showing AI's thought process\n3. Complex problem-solving scenarios where step-by-step reasoning is important\n4. Interactive AI applications requiring immediate feedback\n\n## Technical Considerations\n1. Need to handle potential interruptions in the reasoning stream\n2. Consider memory management for long reasoning processes\n3. Ensure backward compatibility with existing implementations\n4. Maintain performance while adding streaming capability\n\n## Success Criteria\n1. Reasoning content is delivered in real-time as it's generated\n2. No degradation in overall response time\n3. Smooth integration with existing streaming response system\n4. Clear documentation for frontend implementation\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "zhuayi",
      "author_type": "User",
      "created_at": "2025-05-31T06:06:38Z",
      "updated_at": "2025-06-12T13:28:20Z",
      "closed_at": "2025-06-12T13:28:20Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3432/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3432",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3432",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:52.069007",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-352/feature-request-support-streaming-reasoning-process-output\">SUPPORT-352 [Feature Request] Support Streaming Reasoning Process Output</a></p>",
          "created_at": "2025-05-31T06:06:40Z"
        },
        {
          "author": "dirkbrnd",
          "body": "This has been added to the roadmap! We'll get to it asap.",
          "created_at": "2025-06-12T13:28:20Z"
        }
      ]
    },
    {
      "issue_number": 3496,
      "title": "[Bug] Breaking change with new rerankers",
      "body": "### Description\n\nThere are newly added rerankers in `agno.reranker.__init__.py`:\n```python\nfrom agno.reranker.cohere import CohereReranker\nfrom agno.reranker.infinity import InfinityReranker\n```\n\nThese imports break existing installations because they try to import `cohere` and `infinity_client`, even if these rerankers are never used.\n\n### Steps to Reproduce\n\n1. Install agno==1.5.9\n2. Do not have `cohere` installed\n3. Try to execute any script that imports `agno.vectordb.pgvector.pgvector.PgVector`\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nExisting codebases continue to run normally after updating to Agno 1.5.9.\n\n### Actual Behavior\n\nExecution fails with:\n```\n.venv/lib/python3.12/site-packages/agno/vectordb/pgvector/__init__.py:3: in <module>\n    from agno.vectordb.pgvector.pgvector import PgVector\n.venv/lib/python3.12/site-packages/agno/vectordb/pgvector/pgvector.py:24: in <module>\n    from agno.reranker.base import Reranker\n.venv/lib/python3.12/site-packages/agno/reranker/__init__.py:2: in <module>\n    from agno.reranker.cohere import CohereReranker\n.venv/lib/python3.12/site-packages/agno/reranker/cohere.py:10: in <module>\n    raise ImportError(\"cohere not installed, please run pip install cohere\")\nE   ImportError: cohere not installed, please run pip install cohere\n```\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n- Agno version: 1.5.9\n```\n\n### Possible Solutions (optional)\n\n* Remove the `__all__` imports from `__init__.py`\n* Or show a warning instead of raising an exception; only raise it when trying to instantiate the reranker\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "kepler",
      "author_type": "User",
      "created_at": "2025-06-06T13:44:09Z",
      "updated_at": "2025-06-12T13:23:30Z",
      "closed_at": "2025-06-12T13:23:30Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3496/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3496",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3496",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:52.287471",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-423/bug-breaking-change-with-new-rerankers\">SUPPORT-423 [Bug] Breaking change with new rerankers</a></p>",
          "created_at": "2025-06-06T13:44:13Z"
        },
        {
          "author": "kepler",
          "body": "Additionally, `infinity-client` is incompatible with `exa-py`:\n```zsh\n✗ uv add infinity_client\n  × No solution found when resolving dependencies for split (python_full_version >= '3.13' and python_full_version < '4' and platform_python_implementation == 'PyPy'):\n  ╰─▶ Because exa-py>=1.13.1 depends ",
          "created_at": "2025-06-06T13:48:03Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Sorry about this. The fix was released with 1.6.0",
          "created_at": "2025-06-12T13:23:30Z"
        }
      ]
    },
    {
      "issue_number": 3435,
      "title": "[Bug] [Bug] ToolCallStarted Event Not Propagated to Frontend When Sub-Agent Successfully Executes Tools in Team Routing Mode",
      "body": "### Description\n\nIn the team routing mode, when a task is forwarded to a sub-agent (e.g., Agent A) using `aforward_task_to_member`, the sub-agent successfully executes tools but the `ToolCallStarted` event is not propagated to the frontend. This creates a disconnect between the actual tool execution and the frontend display, even though the tools are working correctly.\n\n### Steps to Reproduce\n\n1. Set up a team with multiple agents (e.g., RouteAgent and HR Agent)\n2. Send a query that requires tool execution\n3. RouteAgent forwards the task to HR Agent using `aforward_task_to_member`\n4. HR Agent successfully executes a tool call\n5. Observe that:\n- Tool execution is successful (verified in logs)\n- Frontend does not receive `ToolCallStarted` event\n- Frontend cannot display tool execution status\n\n### Agent Configuration (if applicable)\n\n```python\n# RouteAgent setup\nroute_agent = RouteAgent()\nroot_agent = SubAgent(\nname=\"hr助手\",\nrole=\"HR Assistant\",\ninstructions=\"Handle HR related queries\"\n)\nroute_agent.members.append(root_agent)\n﻿\n# Tool execution in HR Agent\n@tool\nasync def some_tool():\n# Tool execution succeeds but event not propagated\nreturn \"Tool execution result\"\n```\n\n### Expected Behavior\n\n- When a sub-agent calls a tool:\n1. `ToolCallStarted` event should be sent to frontend\n2. Tool execution should proceed normally\n3. Frontend should display tool execution status\n4. Tool execution result should be returned\n\n### Actual Behavior\n\n- Tool execution succeeds in the backend\n- `ToolCallStarted` event is not sent to frontend\n- Frontend cannot display tool execution status\n- Tool execution result is still returned\n- Logs show successful tool execution\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n- agno version: latest\n- Python version: 3.13\n- OS: macOS 24.5.0\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "zhuayi",
      "author_type": "User",
      "created_at": "2025-05-31T17:19:03Z",
      "updated_at": "2025-06-12T13:22:14Z",
      "closed_at": "2025-06-12T13:22:14Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3435/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3435",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3435",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:52.514401",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-355/bug-bug-toolcallstarted-event-not-propagated-to-frontend-when-sub\">SUPPORT-355 [Bug] [Bug] ToolCallStarted Event Not Propagated to Frontend When Sub-Agent Successfully Executes Tools in Team Routing Mode</a></p>",
          "created_at": "2025-05-31T17:19:06Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@zhuayi we are working on this! Should be released early next week",
          "created_at": "2025-06-06T10:09:47Z"
        },
        {
          "author": "dirkbrnd",
          "body": "This has been released with 1.6.0! \nThis will be on our playground very soon!",
          "created_at": "2025-06-12T13:22:14Z"
        }
      ]
    },
    {
      "issue_number": 3504,
      "title": "[Feature Request] Improving Reliability for Structured Output Failures",
      "body": "### Problem Description\n\nWe encountered errors when using structured output with complex schemas. Currently, there is no built-in mechanism to handle these failures gracefully. Specifically, when an error occurs, the system lacks a retry strategy that would allow re-generating the output by appending the encountered exception message to the LLM input as context.\n\n### Proposed Solution\n\nTo improve reliability when handling structured outputs with complex schemas, we propose implementing a retry mechanism inspired by the [Instructor](https://github.com/567-labs/instructor) library. Specifically:\n\n**Retry on Validation/Error:** When the output from the LLM fails to conform to the expected schema or raises an exception, the system should automatically retry the generation.\n\n**Context Augmentation:** Each retry attempt should include the exception message appended to the prompt, giving the model additional context to correct its output.\n\n**Framework Integration:** This retry logic can be integrated directly into our existing framework, allowing for seamless recovery from structural failures without requiring manual intervention.\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [x] Yes, I’d love to work on it!\n- [x] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "anhphong22",
      "author_type": "User",
      "created_at": "2025-06-08T03:05:49Z",
      "updated_at": "2025-06-12T13:19:24Z",
      "closed_at": "2025-06-12T13:19:24Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3504/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3504",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3504",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:52.741099",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-428/feature-request-improving-reliability-for-structured-output-failures\">SUPPORT-428 [Feature Request] Improving Reliability for Structured Output Failures</a></p>",
          "created_at": "2025-06-08T03:05:53Z"
        },
        {
          "author": "ysolanky",
          "body": "Hi @anhphong22! Awesome feature request - this has actually been on our radar for a while. Give us a little time and we’ll get back to you.\nIf you’d like to take a stab at implementing it, I’m happy to answer any questions!",
          "created_at": "2025-06-10T04:56:02Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Just added this feature request. We'll add it!",
          "created_at": "2025-06-12T13:19:24Z"
        }
      ]
    },
    {
      "issue_number": 3506,
      "title": "[Feature Request] Get access to the environment we're running in.",
      "body": "### Problem Description\n\nIn our application, we want to use ollama and that infrastructure in `dev_resources.py`. I created a little hack in `settings.py` in the workspace:\n\n```python\nruntime_env = getenv(\"RUNTIME_ENV\", \"dev\")\nare_we_in_dev = runtime_env is not None and runtime_env == \"dev\"\n```\n\nBut this seems redundant and error prone when calling a function like this:\n\n```python\ndef get_dev_model_and_embedder(model_id: str = \"llama3.1:8b\"):\n    from agno.embedder.ollama import OllamaEmbedder\n    from ollama import AsyncClient as AsyncOllamaClient\n    print(\"IN DEV\")\n    ollama_host = getenv(\"OLLAMA_HOST\", \"http://ollama:11434\")\n    embedder = OllamaEmbedder(host=ollama_host)\n    async_client = AsyncOllamaClient(host=ollama_host)\n    model = Ollama(id=model_id, host=ollama_host, async_client=async_client)\n    return model, embedder\n\ndef get_prd_model_and_embedder(model_id: str = \"gpt-4o-mini\"):\n    from agno.models.openai import OpenAIChat\n    from agno.embedder.openai import OpenAIEmbedder\n    from workspace.prd_resources import prd_secret\n    print(\"IN PROD\", prd_secret.get_secret_value(\"OPENAI_API_KEY\"))\n\n    openai_api_key = prd_secret.get_secret_value(\"OPENAI_API_KEY\")\n    embedder = OpenAIEmbedder(api_key=openai_api_key)\n    model = OpenAIChat(id=model_id, api_key=openai_api_key)\n    return model, embedder\n\nmodel, embedder = get_dev_model_and_embedder() if are_we_in_dev else get_prd_model_and_embedder()\n```\n\nIn order to get this to work, we have to call our `ag ws` commands with an environment variable:\n\n```bash\nAGNO_ENV=prd ag ws up --env prd --infra docker --type image\n```\n\nIsn't it redundant to have to have both `AGNO_ENV=prd` and the `--env prd` flag? How can we just use the `env` that is passed into the `ag ws` command?\n\n### Proposed Solution\n\nI included the solution we're currently using, but it feels like a hack.\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "auser",
      "author_type": "User",
      "created_at": "2025-06-08T18:09:43Z",
      "updated_at": "2025-06-12T13:17:52Z",
      "closed_at": "2025-06-12T13:17:52Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3506/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3506",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3506",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:53.003359",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-430/feature-request-get-access-to-the-environment-were-running-in\">SUPPORT-430 [Feature Request] Get access to the environment we're running in.</a></p>",
          "created_at": "2025-06-08T18:09:46Z"
        },
        {
          "author": "ysolanky",
          "body": "Hi @auser ! I think there is some confusion here regarding the use of `RUNTIME_ENV` environment variable. If you are running your agno workspace locally, `RUNTIME_ENV` env variable in your docker container will have the value `dev`. And similarly `prd` if the container is running in production. To r",
          "created_at": "2025-06-10T04:51:42Z"
        },
        {
          "author": "dirkbrnd",
          "body": "I'll close for now, please let me know if you want to open it again.",
          "created_at": "2025-06-12T13:17:52Z"
        }
      ]
    },
    {
      "issue_number": 3509,
      "title": "[Feature Request] Prompt caching for AWS Bedrock Claude",
      "body": "### Problem Description\n\nIn models like GPT-4.1 prompt caching is automatic, saving major costs.\nIn AWS Bedrock Claude models it seems like it requires manual input.\n\n### Proposed Solution\n\nFor relevant connectors:\nAWS Bedrock - when working with Claude models implementing the prompt caching protocol for system prompts:\nhttps://aws.amazon.com/cn/blogs/machine-learning/effectively-use-prompt-caching-on-amazon-bedrock/\nhttps://github.com/aws-samples/amazon-bedrock-samples/blob/main/introduction-to-bedrock/prompt-caching/getting_started_with_prompt_caching.ipynb\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\nDify has already seamlessly implemented Bedrock Prompt Caching support.\n![Image](https://github.com/user-attachments/assets/4bc570f2-fb9c-40ba-9e14-155760758799)\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [x] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "krisxia0506",
      "author_type": "User",
      "created_at": "2025-06-09T05:53:48Z",
      "updated_at": "2025-06-12T13:16:51Z",
      "closed_at": "2025-06-12T13:16:51Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3509/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3509",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3509",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:53.652282",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-439/feature-request-prompt-caching-for-aws-bedrock-claude\">SUPPORT-439 [Feature Request] Prompt caching for AWS Bedrock Claude</a></p>",
          "created_at": "2025-06-09T05:53:52Z"
        },
        {
          "author": "dirkbrnd",
          "body": "We have added this to the roadmap!",
          "created_at": "2025-06-12T13:16:51Z"
        }
      ]
    },
    {
      "issue_number": 3525,
      "title": "[Feature Request] TeamRunResponse missing agent_id field for multi-agent identification",
      "body": "### Problem Description\n\nWhen developing multi-agent systems with the Agno framework, we've identified that `TeamRunResponse` objects lack an explicit `agent_id` field to identify which specific agent generated the response. This makes it impossible to directly determine the message source from the response object when processing streaming responses.\n\n\n### Proposed Solution\n\nThe current `TeamRunResponse` structure looks like this:\n\n```python\nTeamRunResponse(\n    event='RunResponse', \n    content='Hello', \n    content_type='str', \n    thinking=None, \n    messages=None, \n    metrics=None, \n    model=None, \n    model_provider=None, \n    member_responses=[], \n    run_id='9794a33e-f927-49bb-8958-89af9e9c691f', \n    team_id='e1703a86-e156-46f8-9509-6e9977fb2877', \n    session_id='e0db277e-de6c-4a94-b9a5-ba63c47380e7',\n    # ❌ Missing agent_id field\n    ...\n)\n```\n\n## 🎯 **Expected Behavior**\n\nWe expect `TeamRunResponse` to include an `agent_id` field:\n\n```python\nTeamRunResponse(\n    event='RunResponse', \n    content='Hello', \n    content_type='str', \n    agent_id='marketing_agent',  # ✅ New field\n    agent_name='Marketing Agent',  # ✅ Optional: friendly display name\n    ...\n)\n```\n\n## 🔧 **Use Cases**\n\nIn multi-agent teams, we need to:\n\n1. **UI Display**: Show message sender in chat interfaces\n2. **Logging**: Accurately track response sources for debugging\n3. **State Management**: Apply different business logic based on agent identity\n4. **Analytics**: Measure performance and usage statistics per agent\n\n## 🛠️ **Current Workaround**\n\nCurrently, we have to infer agent identity by parsing tool calls:\n\n```python\ndef _get_member_id_from_tools(self, chunk) -> str:\n    if not chunk.tools or len(chunk.tools) == 0:\n        return self.role\n        \n    tool = chunk.tools[0]\n    if tool.tool_name == 'aforward_task_to_member':\n        return tool.tool_args.get('member_id', self.role)\n    return self.role\n```\n\nThis approach is:\n- ❌ Complex and fragile\n- ❌ Dependent on specific tool implementations\n- ❌ Unable to handle all scenarios\n\n## 💡 **Proposed Solution**\n\nAdd the following fields to the `TeamRunResponse` class:\n\n```python\n@dataclass\nclass TeamRunResponse:\n    # ... existing fields ...\n    agent_id: Optional[str] = None  # Unique agent identifier\n    agent_name: Optional[str] = None  # Display-friendly agent name (optional)\n```\n\n**Implementation considerations**:\n1. Automatically set `agent_id` during team internal routing\n2. Maintain backward compatibility with optional fields\n3. Consider adding `agent_name` for display purposes\n\n## 🔍 **Environment**\n\n- **Agno Version**: 1.5.10\n- **Python Version**: 3.13\n- **Use Case**: Multi-agent customer service system\n- **Team Mode**: \"route\"\n\n## 📝 **Additional Context**\n\nThis issue is particularly critical when building enterprise-grade multi-agent systems that require:\n- Role-based access control\n- Accurate user experience with clear agent identification\n- Detailed performance analytics per agent\n- Proper message attribution in conversation logs\n\n## 🙏 **Impact**\n\nThis feature would significantly improve the developer experience for multi-agent systems by:\n- Reducing boilerplate code for agent identification\n- Improving code reliability and maintainability\n- Enabling better user interfaces with clear message attribution\n- Facilitating proper logging and analytics\n\n## 📋 **Acceptance Criteria**\n\n- [ ] `TeamRunResponse` includes `agent_id` field\n- [ ] `agent_id` is automatically populated during team routing\n- [ ] Backward compatibility is maintained\n- [ ] Documentation is updated with examples\n- [ ] Optional `agent_name` field for display purposes\n\n## 🔗 **Related Issues**\n\nNone identified yet, but this may relate to other multi-agent workflow improvements.\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "zhuayi",
      "author_type": "User",
      "created_at": "2025-06-10T12:10:04Z",
      "updated_at": "2025-06-12T13:15:21Z",
      "closed_at": "2025-06-12T13:15:21Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3525/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3525",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3525",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:53.860950",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Hi @zhuayi \nThese are great suggestions. Please take a look at the recently released 1.6.0 and [these docs](https://docs.agno.com/teams/run). We now yield events for member responses as well, in between the top-level team responses. The member responses have agent-id.\n\nWe can look at adding agent na",
          "created_at": "2025-06-10T20:14:01Z"
        }
      ]
    },
    {
      "issue_number": 3083,
      "title": "Current CSV Reader doesn't preserve the column metadata context for each row",
      "body": "## Problem Description\nThe current CSV reader  converts CSV files to text by simply joining all values with commas, which loses the context of what each value represents. This makes the resulting text less useful for both human readers and AI systems that need to understand the semantic meaning of the data.\n\n## Proposed Solution\nImplement a better CSV-to-text conversion that preserves the relationship between column headers and values. Each row should be converted to a formatted text block where each line follows the pattern \"Field Name: Value\". This provides context to each value and makes the output much more meaningful.\n\nCurrently, its not possible to implement the custom csv reader as CSVKnowledgeBase doesn't accept a custom csv reader. \n\n![Image](https://github.com/user-attachments/assets/5d82ee08-d7b2-46ea-a972-dda8f0f61df1)\n\nIdeally it should be of type reader or csv reader must be an interface that can be modified. \n\n\nThe solution should:\n1. Modify `CSVReader` to maintain column-to-value mapping or allow custom reader objects to be passed to `CSVKnowledgeBase`\n2. Format each field name to be more readable (e.g., replacing underscores with spaces)\n3. Include an optional title parameter for each record\n4. Add proper formatting and separation between entries\n5. Skip empty values to keep the output clean\n\n## Additional context\nHere's a simple example of the transformation:\n**Current Output**\nProduct123, 15.99, Electronics, In Stock, 4.5, 250\n\n**Proposed Output**\nProduct Entry \nProduct Name: Product123\nPrice: 15.99\nCategory: Electronics\nStatus: In Stock\nRating: 4.5\nUnits Sold: 250\n\n## Would you like to work on this?\n[] Yes, I'd love to work on it!\n[x ] I'm open to collaborating but need guidance.\n[ ] No, I'm just sharing the idea.",
      "state": "open",
      "author": "mancunian1792",
      "author_type": "User",
      "created_at": "2025-05-05T08:17:01Z",
      "updated_at": "2025-06-12T00:34:42Z",
      "closed_at": null,
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3083/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3083",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3083",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:54.046762",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-06-12T00:34:42Z"
        }
      ]
    },
    {
      "issue_number": 3493,
      "title": "[Bug] Schema generation fails with Field descriptions on nested models in 1.5.8 after upgrading from 1.5.4",
      "body": "### Description\n\nAfter upgrading from Agno version 1.5.4 to 1.5.8, a schema validation error occurs when running my agent and serving structured output responses using Pydantic models that include nested objects with Field(..., description=...). \nThe error is:\n\n\n```\nInvalid schema for response_format 'SearchResult': context=('properties', 'home'), $ref cannot have keywords {'description'}.\n```\n\n\n\n### Steps to Reproduce\n\nDefine a Pydantic response model with nested models for an agent, where the nested fields use Field(..., description=\"...\"):\n```\n\nclass Nested(BaseModel):\n    value: str = Field(..., description=\"Some value\")\n\nclass Parent(BaseModel):\n    nested: Nested = Field(..., description=\"Nested object\")\n\n```\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nThe schema should be generated correctly, just like in version 1.5.4, where the description field on a nested model was accepted and shown properly.\n\n### Actual Behavior\n\n```\nInvalid schema for response_format 'SearchResult': context=('properties', 'home'), $ref cannot have keywords {'description'}.\n```\nin version 1.5.8\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nAgno Version: 1.5.8\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "lironesamoun",
      "author_type": "User",
      "created_at": "2025-06-06T09:44:14Z",
      "updated_at": "2025-06-11T13:28:44Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 12,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3493/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3493",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3493",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:54.248384",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-421/bug\">SUPPORT-421 [Bug]</a></p>",
          "created_at": "2025-06-06T09:44:17Z"
        },
        {
          "author": "rahulsamant37",
          "body": "@lironesamoun I tried to replicate your issue, but in my case, it is working fine—if this is what you meant. Could you please confirm this or share more details about your specific use case where you're encountering the issue? -\n\n#### Script Scheme:\n![Image](https://github.com/user-attachments/asset",
          "created_at": "2025-06-07T00:59:14Z"
        },
        {
          "author": "rahulsamant37",
          "body": "I think the error might be occurring because when you're using a $ref (JSON Schema reference) along with other keywords like description in the same schema object. In JSON Schema, when you use $ref, it should be the only property in that schema object.\n\nI think your Issue will resolve if you use \n``",
          "created_at": "2025-06-07T01:08:11Z"
        },
        {
          "author": "lironesamoun",
          "body": "@rahulsamant37 \nI have investigated a bit more and those are more log\n\n```\n  File \"/Users/Documents/dev/engine/src/core/agents/insights_agent.py\", line 127, in find_insights\n    return self.agent.run(message=message)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/Documents/dev/engine/.ven",
          "created_at": "2025-06-09T07:58:09Z"
        },
        {
          "author": "rahulsamant37",
          "body": "@lironesamoun See if this includes your problem - https://portkey.ai/error-library/schema-validation-error-10538",
          "created_at": "2025-06-09T09:35:23Z"
        }
      ]
    },
    {
      "issue_number": 3461,
      "title": "[Bug] Reasoning not working | Reasoning response is None, continuing regular session...",
      "body": "### Description\n\nWhen an agent is set with `reasoning = true` and `reasoning_model = AzureOpenAI(id='o3-mini', api_version='2024-12-01-preview')`, an error occurs during the reasoning start process, causing the reasoning to be skipped or not executed.\n\n### Steps to Reproduce\n\nCreate an Agent with `reasoning = true` and `reasoning_model = AzureOpenAI(id='o3-mini', api_version='2024-12-01-preview')`\n\n### Agent Configuration (if applicable)\n\n```python\nagent = Agent(\n        name=\"Chat\",\n        agent_id=\"chat\",\n        user_id=user_id,\n        tools=[get_specific_documents],\n        session_id=session_id,\n        model=AzureOpenAI(id=\"gpt-4o\"),\n        reasoning=reasoning,\n        markdown=True,\n        add_datetime_to_instructions=True,\n        reasoning_model=AzureOpenAI(id=\"o3-mini\", api_version=\"2024-12-01-preview\"),\n        storage=storage,\n        add_history_to_messages=True,\n        num_history_responses=3,\n        read_chat_history=True,\n        debug_mode=True,\n        show_tool_calls=True,\n        read_tool_call_history=True,\n        telemetry=False,\n        stream=True,\n)\n```\n\n### Expected Behavior\n\nReasoning is running.\n\n### Actual Behavior\n\nReasoning is not running.\n\n\n\n### Screenshots or Logs (if applicable)\n\n```log\nDEBUG =============== Starting OpenAI Reasoning ================     \nWARNING  Reasoning error: 'NoneType' object has no attribute 'replace'        \nWARNING  Reasoning error. Reasoning response is None, continuing regular session... \n```\n\n### Environment\n\n```markdown\n- Agno Version: 1.5.8\n```\n\n### Possible Solutions (optional)\n\nSomewhere in class/func: `Agent.arun`\n\n### Additional Context\n\nSame behaviour with other resoning models",
      "state": "open",
      "author": "oza-c",
      "author_type": "User",
      "created_at": "2025-06-04T05:22:15Z",
      "updated_at": "2025-06-11T06:33:31Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3461/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3461",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3461",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:54.453176",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-393/bug-reasoning-not-working-or-reasoning-response-is-none-continuing\">SUPPORT-393 [Bug] Reasoning not working | Reasoning response is None, continuing regular session...</a></p>",
          "created_at": "2025-06-04T05:22:18Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@oza-c Sorry, I still can't reproduce. I am on the latest agno 1.5.9 and the latest openai 1.84.0",
          "created_at": "2025-06-06T08:58:44Z"
        },
        {
          "author": "oza-c",
          "body": "@dirkbrnd Same model, same provider? Strange, because after a complete reinstallation (with Agno 1.5.9 and openai 1.84.0) of all packages I still end up with the same error",
          "created_at": "2025-06-06T14:50:47Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Yes same model with AzureOpenAI...  I'll try again",
          "created_at": "2025-06-07T04:31:50Z"
        },
        {
          "author": "oza-c",
          "body": "If I set `reasoning = False` and still set the reasoningModel then I still get the error message.\n\n@dirkbrnd Which imports do you use?\nI use `from agno.models.azure.openai_chat import AzureOpenAI`\n",
          "created_at": "2025-06-11T06:33:30Z"
        }
      ]
    },
    {
      "issue_number": 2612,
      "title": "[Bug] Not able of making tool calls and response format at the same time",
      "body": "# Description\nA simple agent is not able of having tools and response_model at the same time. If removed one of the arguments it does work.\n\n## Steps to Reproduce\n```\nfrom agno.agent import Agent\nfrom agno.models.openrouter import OpenRouter\nfrom agno.tools.duckduckgo import DuckDuckGoTools\nfrom pydantic import BaseModel\n\n\nclass News(BaseModel):\n    title: str\n    content: str\n\n\nagent = Agent(\n    model=OpenRouter(\n        id=\"google/gemini-2.0-flash-001\",\n        api_key=<API_KEY>,\n    ),\n    description=\"You are an enthusiastic news reporter with a flair for storytelling!\",\n    tools=[DuckDuckGoTools()],\n    show_tool_calls=True,\n    markdown=True,\n    response_model=News,\n)\nagent.print_response(\"Tell me about a breaking news story from New York.\", stream=True)\n\n```\n\n\n## Expected Behavior\nTo work, because is needed for workflows.\n\n## Screenshots or Logs (if applicable)\n`raise ModelProviderError(message=str(e), model_name=self.name, model_id=self.id) from e\nagno.exceptions.ModelProviderError: 'NoneType' object is not iterable\n`\n\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- OS: macOs\n- Agno Version: 1.2.6\n- Additional Environment Details: python 3.13\n\n",
      "state": "closed",
      "author": "aiorga-sherpas",
      "author_type": "User",
      "created_at": "2025-03-30T13:06:52Z",
      "updated_at": "2025-06-11T04:30:11Z",
      "closed_at": "2025-04-19T00:31:21Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 17,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2612/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2612",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2612",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:54.636883",
      "comments": [
        {
          "author": "aiorga-sherpas",
          "body": "Not happening with `id\"openai/gpt-4o\"` so it may be a gemini limitation",
          "created_at": "2025-03-30T13:14:54Z"
        },
        {
          "author": "aiorga-sherpas",
          "body": "response.content\n```\nb'\\n         \\n\\n         \\n\\n         \\n\\n         \\n\\n         \\n{\"error\":{\"message\":\"Provider returned error\",\"code\":400,\"metadata\":{\"raw\":\"{\\\\n  \\\\\"error\\\\\": {\\\\n    \\\\\"code\\\\\": 400,\\\\n    \\\\\"message\\\\\": \\\\\"For controlled generation of only function calls (forced function ca",
          "created_at": "2025-03-30T13:30:55Z"
        },
        {
          "author": "aiorga-sherpas",
          "body": "Related to this issue https://github.com/agno-agi/agno/issues/2186 but `structured_outputs=False,` does not solve it\n",
          "created_at": "2025-03-30T16:18:46Z"
        },
        {
          "author": "kausmeows",
          "body": "Hi @aiorga-sherpas, thanks for reaching out. So i tried with OpenAI and it works. So it could be a Gemini issue.\n\n<img width=\"1150\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/2441f94f-6fa4-44c4-b7f3-cce9c1fcff27\" />\n\nBut to make sure can you try this-\n> Related to this issue [#2186]",
          "created_at": "2025-03-30T17:19:12Z"
        },
        {
          "author": "aiorga-sherpas",
          "body": "```python\nagent = Agent(\n    model=OpenRouter(\n        id=\"google/gemini-2.0-flash-001\",\n        api_key=API_KEY,\n    ),\n    description=\"You are an enthusiastic news reporter with a flair for storytelling!\",\n    tools=[DuckDuckGoTools()],\n    show_tool_calls=True,\n    use_json_mode=True,\n    respon",
          "created_at": "2025-03-31T08:52:44Z"
        }
      ]
    },
    {
      "issue_number": 3520,
      "title": "[Bug] Error with tools calling in agent running",
      "body": "### Description\n\nWhen I add SQLTools and ReasoningTools, the Agent doesn't complete the task properly.\n\n### Steps to Reproduce\n\n1. Build a sql agent like the sample(https://docs.agno.com/examples/streamlit/text-to-sql)\n2. Input the query\n\n### Agent Configuration (if applicable)\n\n```python\nAgent(\n        name=name,\n        model=get_basic_model(framework=\"agno\"),\n        debug_mode=debug_mode,\n        knowledge=agent_knowledge,\n        search_knowledge=search_knowledge,\n        read_chat_history=read_chat_history,\n        read_tool_call_history=read_tool_call_history,\n        add_history_to_messages=add_history_to_messages,\n        tools=[\n            SQLTools(db_url=\"mysql+pymysql://localhost:3306/data_analytics\", list_tables=False),\n            ReasoningTools(add_instructions=True, add_few_shot=True),\n        ],\n        description=load_prompts(prompt_type=\"desc\", prompt_name=\"sql_generator.md\"),\n        instructions=load_prompts(prompt_type=\"instruct\", prompt_name=\"sql_generator.md\"),\n        additional_context=load_prompts(prompt_type=\"context\", prompt_name=\"sql_generator.md\"),\n    )\n```\n\n### Expected Behavior\n\ngenerate sql and execute sql statement\n\n### Actual Behavior\n\n<img width=\"632\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/7828f345-5eab-4933-ba1b-e96c9ae1b437\" />\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n- 0S: macOs 15.5 \n- Agno Version: v1.5.10\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "Hakstar",
      "author_type": "User",
      "created_at": "2025-06-10T07:06:43Z",
      "updated_at": "2025-06-11T01:21:52Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3520/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3520",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3520",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:54.882933",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-458/bug-error-with-tools-calling-in-agent-running\">SUPPORT-458 [Bug] Error with tools calling in agent running</a></p>",
          "created_at": "2025-06-10T07:06:47Z"
        },
        {
          "author": "Hakstar",
          "body": "add SQLTools, same problem arises here.\n\n<img width=\"639\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/3e5e6c1d-a4fb-469f-86b3-f7e27f9ef165\" />",
          "created_at": "2025-06-10T08:38:14Z"
        },
        {
          "author": "ysolanky",
          "body": "Hi @Hakstar ! Looks like the model is returning the SQL instead of using the tool to execute it. I have observed that adding very specific instructions helps. For example, you can instruct the Agent to call `run_sql` tool with the correct query. Also, which model are you using with your Agent? ",
          "created_at": "2025-06-10T13:22:50Z"
        },
        {
          "author": "Hakstar",
          "body": "> Hi [@Hakstar](https://github.com/Hakstar) ! Looks like the model is returning the SQL instead of using the tool to execute it. I have observed that adding very specific instructions helps. For example, you can instruct the Agent to call `run_sql` tool with the correct query. Also, which model are ",
          "created_at": "2025-06-11T01:21:52Z"
        }
      ]
    },
    {
      "issue_number": 3528,
      "title": "[Bug] Double-escaping of quotes in `escape_quotes_in_values` function in re.sub operation",
      "body": "### Description\n\nThe `escape_quotes_in_values` function currently causes unintended double-escaping of double quotes (`\"`) when applied to strings that already contain escaped quotes (`\\\"`). This results in incorrect output with excessive backslashes (e.g., `\\\\\\\"`), which is invalid or problematic in downstream use cases such as JSON processing.\n\n### Steps to Reproduce\n\n1. Execute the `escape_quotes_in_values` function with a match containing a value that already contains escaped quotes (`\\\"`).\n2. Observe the output to verify that the quotes are unnecessarily double-escaped.\n3. Example input to reproduce the bug:\n{\n    \"name\": \"Normal \\\"quote\\\"\",\n    \"data\": \"Already escaped \\\\\\\"quote\\\\\\\"\"\n}\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nThe function should only escape unescaped double quotes in the value.\n\n### Actual Behavior\n\nThe function currently double-escapes quotes that are already escaped,\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n- OS: Ubuntu 22.04 LTS\n- Agno Version: 1.5.10\n- Python Version: Python 3.12.10\n- Dependencies: `re` module\n```\n\n### Possible Solutions (optional)\n\n`def escape_quotes_in_values(match):\n    key = match.group(1)\n    value = match.group(2)\n    # Escape ONLY unescaped quotes\n    escaped_value = re.sub(r'(?<!\\\\)\"', r'\\\\\"', value)\n    return f'\"{key.lower()}\": \"{escaped_value}\"'\n`\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "kostadinov92",
      "author_type": "User",
      "created_at": "2025-06-10T14:20:58Z",
      "updated_at": "2025-06-10T20:26:32Z",
      "closed_at": "2025-06-10T20:26:32Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3528/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3528",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3528",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:55.136197",
      "comments": []
    },
    {
      "issue_number": 3513,
      "title": "[Bug] Apify gives error",
      "body": "### Description\n\nHello, thank you for developing this amazing framework. However, I’ve encountered an error with the Apify tool. Is this a bug, or am I missing something?\n\n### Steps to Reproduce\n\n1. I've installed latest version of agno and apify_client\n2. Tried this tutorial - https://docs.agno.com/tools/toolkits/others/apify#basic-usage\n3. Set my apify_key and openai key \n4. Run command\n\n### Agent Configuration (if applicable)\n\n```python\nfrom agno.agent import Agent\nfrom agno.tools.apify import ApifyTools\n\n# Create an agent with ApifyTools\n\nagent = Agent(\n    tools=[\n        ApifyTools(\n            actors=[\"apify/rag-web-browser\"],  # Specify which Apify Actors to use, use multiple ones if needed\n            apify_api_token=\"my_apify_api_token\"\n        )\n    ],\n    show_tool_calls=True,\n    markdown=True\n)\n\n# Use the agent to get website content\nagent.print_response(\"Summarize the content from https://docs.agno.com/introduction\", markdown=True)\n```\n\n### Expected Behavior\n\nSummarized content of https://docs.agno.com/introduction\n\n### Actual Behavior\n\n```bash\nTraceback (most recent call last):\n  File \"/Users/erdene-ochir/Desktop/demo/tests/test_tool.py\", line 8, in <module>\n    ApifyTools(\n  File \"/Users/erdene-ochir/Desktop/demo/venv/lib/python3.12/site-packages/agno/tools/apify.py\", line 82, in __init__\n    super().__init__(name=\"ApifyTools\", tools=tools)\n  File \"/Users/erdene-ochir/Desktop/demo/venv/lib/python3.12/site-packages/agno/tools/toolkit.py\", line 57, in __init__\n    available_tools=[tool.__name__ for tool in tools], include_tools=include_tools, exclude_tools=exclude_tools\n                     ^^^^^^^^^^^^^\nAttributeError: 'str' object has no attribute '__name__'. Did you mean: '__ne__'?\n```\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n- OS: macOS Ventura 13.2\n- agno version: 1.5.10\n- apify_client: 1.10.0\n- openai: 1.76.2\n- python: 3.12.6\n```\n\n### Possible Solutions (optional)\n\nThe tool in Toolkit expects a list of Callables, but I'm giving a list of strings instead.\n```python\nclass Toolkit:\n    def __init__(\n        self,\n        name: str = \"toolkit\",\n        tools: List[Callable] = [],\n```\n\n```python\ntools: List[Any] = []\nif actors:\n    actor_list = [actors] if isinstance(actors, str) else actors\n    for actor_id in actor_list:\n        tools.append(actor_id)\n\nsuper().__init__(name=\"ApifyTools\", tools=tools)\n```\n\nAlso, I haven't seen the registering actor since Agno version 1.5.2.\n```python\n# agno==1.5.2\nif actors:\n    actor_list = [actors] if isinstance(actors, str) else actors\n    for actor_id in actor_list:\n        self.register_actor(actor_id)\n```\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "Erdene-Ochir0417",
      "author_type": "User",
      "created_at": "2025-06-09T09:15:38Z",
      "updated_at": "2025-06-10T20:09:56Z",
      "closed_at": "2025-06-10T20:09:56Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3513/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3513",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3513",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:55.136217",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-453/bug-apify-gives-error\">SUPPORT-453 [Bug] Apify gives error</a></p>",
          "created_at": "2025-06-09T09:15:40Z"
        },
        {
          "author": "sumansuhag",
          "body": "Hi Erdene-Ochir0417,\n\nThanks for the thorough bug report! You’ve nailed the cause of the AttributeError, which is super helpful.\n\nYou’re right: the error AttributeError: 'str' object has no attribute '__name__' happens because the Toolkit class (which ApifyTools is based on) is expecting a list of c",
          "created_at": "2025-06-09T15:56:02Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Working on a fix!\n",
          "created_at": "2025-06-09T21:23:46Z"
        },
        {
          "author": "dirkbrnd",
          "body": "This should be resolved in 1.6.0!",
          "created_at": "2025-06-10T20:09:56Z"
        }
      ]
    },
    {
      "issue_number": 3512,
      "title": "[Bug] Mistral AI response format fails with Pydantic Optional fields containing default=None",
      "body": "### Description\n\nWhen using Pydantic models with `Optional[str] = Field(None, ...)` as response format for Mistral AI models, the response_format_from_pydantic_model function fails with ValueError: Unexpected type: None.\n\n```\nTraceback (most recent call last):\n  File \"/path/to/project/playground/structured_output_with_tool_use.py\", line 39, in <module>\n    researcher.print_response(\"Find information about Elon Musk\")\n  File \"/path/to/venv/lib/python3.11/site-packages/agno/agent/agent.py\", line 6772, in print_response\n    run_response = self.run(\n                   ^^^^^^^^^\n  File \"/path/to/venv/lib/python3.11/site-packages/agno/agent/agent.py\", line 1040, in run\n    response = self._run(\n               ^^^^^^^^^^\n  File \"/path/to/venv/lib/python3.11/site-packages/agno/agent/agent.py\", line 651, in _run\n    model_response: ModelResponse = self.model.response(\n                                    ^^^^^^^^^^^^^^^^^^^^\n  File \"/path/to/venv/lib/python3.11/site-packages/agno/models/base.py\", line 321, in response\n    assistant_message, has_tool_calls = self._process_model_response(\n                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/path/to/venv/lib/python3.11/site-packages/agno/models/base.py\", line 521, in *process*model_response\n    response = self.invoke(\n               ^^^^^^^^^^^^\n  File \"/path/to/venv/lib/python3.11/site-packages/agno/models/mistral/mistral.py\", line 183, in invoke\n    response_format=response_format_from_pydantic_model(response_format),\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/path/to/venv/lib/python3.11/site-packages/mistralai/extra/utils/response_format.py\", line 13, in response_format_from_pydantic_model\n    model_schema = rec_strict_json_schema(model.model_json_schema())\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/path/to/venv/lib/python3.11/site-packages/mistralai/extra/utils/_pydantic_helper.py\", line 14, in rec_strict_json_schema\n    schema_node[key] = rec_strict_json_schema(value)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/path/to/venv/lib/python3.11/site-packages/mistralai/extra/utils/_pydantic_helper.py\", line 14, in rec_strict_json_schema\n    schema_node[key] = rec_strict_json_schema(value)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/path/to/venv/lib/python3.11/site-packages/mistralai/extra/utils/_pydantic_helper.py\", line 14, in rec_strict_json_schema\n    schema_node[key] = rec_strict_json_schema(value)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/path/to/venv/lib/python3.11/site-packages/mistralai/extra/utils/_pydantic_helper.py\", line 19, in rec_strict_json_schema\n    raise ValueError(f\"Unexpected type: {schema_node}\")\nValueError: Unexpected type: None\n```\n\n### Steps to Reproduce\n\nFor reproducing, instead of taking my case, I will take the exemple provided on the cookbook by modifying it a little bit.\n\n```\nimport os\n\nfrom agno.agent import Agent\nfrom agno.models.mistral import MistralChat\nfrom agno.tools.duckduckgo import DuckDuckGoTools\nfrom dotenv import load_dotenv\nfrom pydantic import BaseModel, Field\n\n\nclass Person(BaseModel):\n    name: str\n    description: str | None = Field(None, description=\"description if available\") # Modified it\n\n\nmodel = MistralChat(\n    id=\"mistral-medium-latest\",\n    temperature=0.0,\n    api_key=os.environ.get(\"MISTRAL_API_KEY\"),\n)\n\nresearcher = Agent(\n    name=\"Researcher\",\n    model=model,\n    role=\"You find people with a specific role at a provided company.\",\n    instructions=[\n        \"- Search the web for the person described\"\n        \"- Find out if they have public contact details\"\n        \"- Return the information in a structured format\"\n    ],\n    show_tool_calls=True,\n    tools=[DuckDuckGoTools()],\n    response_model=Person,\n    add_datetime_to_instructions=True,\n)\n\nresearcher.print_response(\"Find information about Elon Musk\")\n```\n\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nThe Pydantic model should be successfully converted to a Mistral-compatible response format without errors.\n\n\n### Actual Behavior\n\nI guess, the issue occurs because:\n\nPydantic generates \"default\": null in the JSON schema for Optional[str] = Field(None, ...)\nThe Mistral AI library's rec_strict_json_schema function cannot handle null values in the schema\nWhen it encounters None during recursive processing, it raises ValueError: Unexpected type: None\n\n**.venv/lib/python3.11/site-packages/mistralai/extra/utils/response_format.py**\n\n```\ndef response_format_from_pydantic_model(\n    model: Type[CustomPydanticModel],\n) -> ResponseFormat:\n    \"\"\"Generate a strict JSON schema from a pydantic model.\"\"\"\n    model_schema = rec_strict_json_schema(model.model_json_schema())\n    json_schema = JSONSchema.model_validate(\n        {\"name\": model.__name__, \"schema\": model_schema, \"strict\": True}\n    )\n    return ResponseFormat(type=\"json_schema\", json_schema=json_schema)\n\n```\n\n\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nAgno version: 1.5.10\nPython version: 3.11\n```\n\n### Possible Solutions (optional)\n\n**Workaround 1: Use ... instead of None**\n\nclass MyModel(BaseModel):\n    optional_field: Optional[str] = Field(..., description=\"An optional field\")  # Works!\n\n**Workaround 2: Use empty string default**\nclass MyModel(BaseModel):\n    optional_field: str = Field(\"\", description=\"An optional field, empty if not available\")\n\n**Workaround 3: Remove default entirely**\nclass MyModel(BaseModel):\n    optional_field: Optional[str] = Field(description=\"An optional field\")  # No default specified\n\nBut I'm not satisfied because it's not the rootcause.\nI tried to add a fallback on the response_format_from_pydantic_model method but not able to make it work.\n\nAny insights ?\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "lironesamoun",
      "author_type": "User",
      "created_at": "2025-06-09T09:12:53Z",
      "updated_at": "2025-06-10T08:50:18Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3512/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3512",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3512",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:57.139273",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-452/bug-mistral-ai-response-format-fails-with-pydantic-optional-fields\">SUPPORT-452 [Bug] Mistral AI response format fails with Pydantic Optional fields containing default=None</a></p>",
          "created_at": "2025-06-09T09:12:56Z"
        },
        {
          "author": "manuhortet",
          "body": "- The `response_format_from_pydantic_model` method we use from the Mistral library calls `model.model_json_schema()` on the Person model we are using, which outputs the following: \n```python\n{'properties': {'name': {'title': 'Name', 'type': 'string'}, 'description': {'anyOf': [{'type': 'string'}, {'",
          "created_at": "2025-06-10T08:50:18Z"
        }
      ]
    },
    {
      "issue_number": 3514,
      "title": "How to manage chat sessions for different users and conversations>",
      "body": "### Description\n\nwe all know there is not only 1 user in prouction..\nHow to manage chat sessions for different users and conversations?\n\n### Steps to Reproduce\n\n.\n\n### Agent Configuration (if applicable)\n\n.\n\n### Expected Behavior\n\n.\n\n### Actual Behavior\n\n.\n\n### Screenshots or Logs (if applicable)\n\n.\n\n### Environment\n\n```markdown\n.\n```\n\n### Possible Solutions (optional)\n\n.\n\n### Additional Context\n\n.",
      "state": "closed",
      "author": "Arslan-Mehmood1",
      "author_type": "User",
      "created_at": "2025-06-09T14:04:44Z",
      "updated_at": "2025-06-10T06:16:57Z",
      "closed_at": "2025-06-09T21:18:04Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3514/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3514",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3514",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:57.359352",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-454/how-to-manage-chat-sessions-for-different-users-and-conversations\">SUPPORT-454 How to manage chat sessions for different users and conversations&gt;</a></p>",
          "created_at": "2025-06-09T14:04:46Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Please see [this](https://docs.agno.com/agents/sessions#multi-user%2C-multi-session-agents) for more information!",
          "created_at": "2025-06-09T21:18:04Z"
        },
        {
          "author": "Arslan-Mehmood1",
          "body": "Thanks, I had checked the source code for agent run and it helped.",
          "created_at": "2025-06-10T06:16:56Z"
        }
      ]
    },
    {
      "issue_number": 3505,
      "title": "[Bug] Google Gemma models through 400 error",
      "body": "### Description\n\nWhen Gemma models `model=Gemini(id=\"gemma-3-12b-it\")` are used.we get below error, regardless of tools are provided or not:\n```\nERROR    Error from Gemini API: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Developer instruction is not enabled for                       \n         models/gemma-3-12b-it', 'status': 'INVALID_ARGUMENT'}}    \n```\n\n### Steps to Reproduce\n\nRun below test script\n\n### Agent Configuration (if applicable)\n\nAgent definition:\n```python\n# travel_agent.py\nfrom agno.agent import Agent\nfrom agno.models.google import Gemini\n# from agno.models.ollama import Ollama\nfrom agno.models.openrouter import OpenRouter\nfrom agno.tools.googlesearch import GoogleSearchTools\nfrom agno.tools.crawl4ai import Crawl4aiTools\nfrom agno.storage.sqlite import SqliteStorage\nfrom agno.tools.mcp import MCPTools  # Keep this import\n# from tools.browser_tool import AgnoBrowserToolkit # Assuming this is not used or handled elsewhere\n\n# import asyncio # Not strictly needed here anymore for MCPTools init\nfrom pathlib import Path # Keep if folder_path logic remains, though it's better in main.py now\n\nagent_storage = SqliteStorage(\n    table_name=\"agent_sessions\",\n    db_file=\"tmp/persistent_memory.db\", # Ensure 'tmp' directory exists or adjust path\n)\n\n# Modified: create_agent now accepts mcp_tools\ndef create_agent(mcp_tools: MCPTools) -> Agent:\n    \"\"\"\n    Creates and configures the Agno agent instance.\n    Args:\n        mcp_tools (MCPTools): An initialized MCPTools instance.\n    Returns:\n        Agent: Configured Agno agent instance\n    \"\"\"\n    # folder_path logic can be removed from here if MCPTools is initialized outside\n    # If you still need folder_path for other things, keep it:\n    # folder_path = f\"{str(Path(__file__).parent.resolve())}/tmp_fs\"\n    # print(f\"Folder path used by agent (if any other part needs it): {folder_path}\")\n\n    return Agent(\n        name=\"MyAgnoAgent\",\n        description=\"You are a helpful travel assistant with the ability to browse the internet for doing research and planning trips. You can also crawl web pages to get more information.\",\n        instructions=[\n            \"Avoid over-talking or repeating information.\",\n            \"Ask only very limited and relevant question, if required. DO NOT frustrate the user by asking many questions\",\n            \"DO NOT make up things, always do research and find the information using browser tools.\",\n            \"Always use Browser tools for browsing the internet to do your research about trips, itenary, places, hotels, flights etc.\",\n            \"Be detailed in your research and prepare a comprehensive travel trip.\",\n            \"Always include some tips and recommendations at the end of the plan.\",\n            \"Provide the references and sources for the information you provide.\",\n            \"If you are stuck in browsing and need help like captcha solving or login, ask the user for help\",\n            \"Never say no and try your best to research and plan trips. If you need some missing information, ask user in advance\",\n            \"\"\"How to:\n            1. Always first create a detailed plan on how you are going to research and plan the trip. This plan should include the tools you are going to use, what you plan to do at each step.\n            2. Start by writing the detailed plan in todo.md file. Each step in the plan should be like `[ ] Step description`. Show the prepared plan to user to keep the user updated.\n            3. Do extensive deep research about the transportation options, places to visit, hotels, flights, activities etc. using browser tools (not google search tool) to visit multiple websites and gather all the required information.\n            4. After each step plan is executed to your satisfaction, update the todo.md file to keep track of your progress. Reread the todo.md file to know the next step to be executed and continue till all the steps are completed. Also mark the completed steps as done and show the latest todo.md file to the user to keep the user updated, but do not expect user confirmation.\n            5. As you go through each step, show the relevant information to user to keep the updated.\n            6. Keep on working unless the whole plan is not completed. Complete the plan systematically from top to bottom.\n            7. If you are asked to change the plan, update the todo.md file accordingly and then show it to the user and proceed.\n            8. Once you are satisfied with plan execution and got all the steps completed, compile your findings / research to create travel_plan.md file with all required details. Final travel plan should include the itinerary, places to visit, hotels details with prices, flights details with airlines, prices and timings, activities to do, restaurants to eat, shopping options, sightseeing, tips and recommendations etc.\n            9. Finally present the contents of travel_plan.md file to the user without ```markdown``` syntax.\n            \"\"\"\n        ],\n        # model=Gemini(id=\"gemini-2.5-flash-preview-05-20\"),\n        model=Gemini(id=\"gemma-3-12b-it\"),\n        # model=OpenRouter(id=\"google/gemini-2.5-flash-preview-05-20\"), \n        # retries=5,\n        # tools=[mcp_tools, GoogleSearchTools(), Crawl4aiTools(max_length=5000), AgnoBrowserToolkit()], # Use the passed mcp_tools\n        markdown=True,\n        add_datetime_to_instructions=True,\n        debug_mode=True,\n        storage=agent_storage,\n    )\n\nagent = create_agent(None)\nagent.print_response(\"Plan a trip to japan from phoenix for a family of 4 (2 kids - 10 and 14 years). Do a deep research on internet for planning the trip. Include the detailed itenary with details of transportation, accommodation, hotels, food, sight seeing, other recommendations, tips etc. For doing deep research use browser tools to visit multiple websites and get info.\")\n```\n\n### Expected Behavior\n\nAgent should run perfectly fine. By just changing the model to `gemini-2.5-flash-preview-05-20`, the test script runs fine, but not with Gemma models.\n\n### Actual Behavior\n\nHere is the test run:\n```\n❯ python travel_agent.py\nDEBUG ******************************************* Agent ID: 6867facd-dfce-4f54-b89e-7e35da635ebe ******************************************              \nDEBUG ****************************************** Session ID: c046d414-6562-4601-a7e3-5e5818bf6411 *****************************************              \nDEBUG *************************************** Agent Run Start: ea2bc67b-8c80-42fa-b7e8-16d1b2d4780e ***************************************              \nDEBUG ------------------------------------------------------- Google Response Start -------------------------------------------------------              \nDEBUG ------------------------------------------------------- Model: gemma-3-12b-it -------------------------------------------------------              \nDEBUG =============================================================== system ==============================================================              \nDEBUG You are a helpful travel assistant with the ability to browse the internet for doing research and planning trips. You can also crawl web pages to  \n      get more information.                                                                                                                              \n      <instructions>                                                                                                                                     \n      - Avoid over-talking or repeating information.                                                                                                     \n      - Ask only very limited and relevant question, if required. DO NOT frustrate the user by asking many questions                                     \n      - DO NOT make up things, always do research and find the information using browser tools.                                                          \n      - Always use Browser tools for browsing the internet to do your research about trips, itenary, places, hotels, flights etc.                        \n      - Be detailed in your research and prepare a comprehensive travel trip.                                                                            \n      - Always include some tips and recommendations at the end of the plan.                                                                             \n      - Provide the references and sources for the information you provide.                                                                              \n      - If you are stuck in browsing and need help like captcha solving or login, ask the user for help                                                  \n      - Never say no and try your best to research and plan trips. If you need some missing information, ask user in advance                             \n      - How to:                                                                                                                                          \n                  1. Always first create a detailed plan on how you are going to research and plan the trip. This plan should include the tools you are  \n      going to use, what you plan to do at each step.                                                                                                    \n                  2. Start by writing the detailed plan in todo.md file. Each step in the plan should be like `[ ] Step description`. Show the prepared  \n      plan to user to keep the user updated.                                                                                                             \n                  3. Do extensive deep research about the transportation options, places to visit, hotels, flights, activities etc. using browser tools  \n      (not google search tool) to visit multiple websites and gather all the required information.                                                       \n                  4. After each step plan is executed to your satisfaction, update the todo.md file to keep track of your progress. Reread the todo.md   \n      file to know the next step to be executed and continue till all the steps are completed. Also mark the completed steps as done and show the latest \n      todo.md file to the user to keep the user updated, but do not expect user confirmation.                                                            \n                  5. As you go through each step, show the relevant information to user to keep the updated.                                             \n                  6. Keep on working unless the whole plan is not completed. Complete the plan systematically from top to bottom.                        \n                  7. If you are asked to change the plan, update the todo.md file accordingly and then show it to the user and proceed.                  \n                  8. Once you are satisfied with plan execution and got all the steps completed, compile your findings / research to create              \n      travel_plan.md file with all required details. Final travel plan should include the itinerary, places to visit, hotels details with prices, flights\n      details with airlines, prices and timings, activities to do, restaurants to eat, shopping options, sightseeing, tips and recommendations etc.      \n                  9. Finally present the contents of travel_plan.md file to the user without ```markdown``` syntax.                                      \n                                                                                                                                                         \n      </instructions>                                                                                                                                    \n                                                                                                                                                         \n      <additional_information>                                                                                                                           \n      - Use markdown to format your answers.                                                                                                             \n      - The current time is 2025-06-08 00:19:56.451037.                                                                                                  \n      </additional_information>                                                                                                                          \nDEBUG ================================================================ user ===============================================================              \nDEBUG Plan a trip to japan from phoenix for a family of 4 (2 kids - 10 and 14 years). Do a deep research on internet for planning the trip. Include the  \n      detailed itenary with details of transportation, accommodation, hotels, food, sight seeing, other recommendations, tips etc. For doing deep        \n      research use browser tools to visit multiple websites and get info.                                                                                \nERROR    Error from Gemini API: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Developer instruction is not enabled for                       \n         models/gemma-3-12b-it', 'status': 'INVALID_ARGUMENT'}}                                                                                          \nWARNING  Attempt 1/1 failed: <Response [400]>                                                                                                            \nERROR    Failed after 1 attempts. Last error using Gemini(gemma-3-12b-it)                                                                                \n▰▱▱▱▱▱▱ Thinking...\n┏━ Message ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                                                                                                       ┃\n┃ Plan a trip to japan from phoenix for a family of 4 (2 kids - 10 and 14 years). Do a deep research on internet for planning the trip. Include the     ┃\n┃ detailed itenary with details of transportation, accommodation, hotels, food, sight seeing, other recommendations, tips etc. For doing deep research  ┃\n┃ use browser tools to visit multiple websites and get info.                                                                                            ┃\n┃                                                                                                                                                       ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\nTraceback (most recent call last):\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/vercel-agno-integration/server/.venv-server/lib/python3.13/site-packages/agno/models/google/gemini.py\", line 233, in invoke\n    return self.get_client().models.generate_content(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        model=self.id,\n        ^^^^^^^^^^^^^^\n        contents=formatted_messages,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        **request_kwargs,\n        ^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/vercel-agno-integration/server/.venv-server/lib/python3.13/site-packages/google/genai/models.py\", line 5286, in generate_content\n    response = self._generate_content(\n        model=model, contents=contents, config=config\n    )\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/vercel-agno-integration/server/.venv-server/lib/python3.13/site-packages/google/genai/models.py\", line 4256, in _generate_content\n    response_dict = self._api_client.request(\n        'post', path, request_dict, http_options\n    )\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/vercel-agno-integration/server/.venv-server/lib/python3.13/site-packages/google/genai/_api_client.py\", line 557, in request\n    response = self._request(http_request, stream=False)\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/vercel-agno-integration/server/.venv-server/lib/python3.13/site-packages/google/genai/_api_client.py\", line 471, in _request\n    return self._request_unauthorized(http_request, stream)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/vercel-agno-integration/server/.venv-server/lib/python3.13/site-packages/google/genai/_api_client.py\", line 494, in _request_unauthorized\n    errors.APIError.raise_for_response(response)\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/vercel-agno-integration/server/.venv-server/lib/python3.13/site-packages/google/genai/errors.py\", line 114, in raise_for_response\n    raise ClientError(status_code, response)\ngoogle.genai.errors.ClientError: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Developer instruction is not enabled for models/gemma-3-12b-it', 'status': 'INVALID_ARGUMENT'}}\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/vercel-agno-integration/server/agents/travel_agent.py\", line 71, in <module>\n    agent.print_response(\"Plan a trip to japan from phoenix for a family of 4 (2 kids - 10 and 14 years). Do a deep research on internet for planning the trip. Include the detailed itenary with details of transportation, accommodation, hotels, food, sight seeing, other recommendations, tips etc. For doing deep research use browser tools to visit multiple websites and get info.\")\n    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/vercel-agno-integration/server/.venv-server/lib/python3.13/site-packages/agno/agent/agent.py\", line 4725, in print_response\n    run_response = self.run(\n        message=message,\n    ...<9 lines>...\n        **kwargs,\n    )\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/vercel-agno-integration/server/.venv-server/lib/python3.13/site-packages/agno/agent/agent.py\", line 1204, in run\n    raise last_exception\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/vercel-agno-integration/server/.venv-server/lib/python3.13/site-packages/agno/agent/agent.py\", line 1174, in run\n    return next(resp)\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/vercel-agno-integration/server/.venv-server/lib/python3.13/site-packages/agno/agent/agent.py\", line 811, in _run\n    model_response = self.model.response(messages=run_messages.messages)\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/vercel-agno-integration/server/.venv-server/lib/python3.13/site-packages/agno/models/base.py\", line 187, in response\n    assistant_message, has_tool_calls = self._process_model_response(\n                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        messages=messages,\n        ^^^^^^^^^^^^^^^^^^\n        model_response=model_response,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/vercel-agno-integration/server/.venv-server/lib/python3.13/site-packages/agno/models/base.py\", line 323, in _process_model_response\n    response = self.invoke(messages=messages)\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/vercel-agno-integration/server/.venv-server/lib/python3.13/site-packages/agno/models/google/gemini.py\", line 240, in invoke\n    raise ModelProviderError(\n        message=e.response, status_code=e.code, model_name=self.name, model_id=self.id\n    ) from e\nagno.exceptions.ModelProviderError: <Response [400]>\n```\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n❯ uv pip show agno\nName: agno\nVersion: 1.4.5\nLocation: /Users/gauravdhiman/projects/python/ai/playgrounds/vercel-agno-integration/server/.venv-server/lib/python3.13/site-packages\nRequires: docstring-parser, gitpython, httpx, pydantic, pydantic-settings, python-dotenv, python-multipart, pyyaml, rich, tomli, typer, typing-extensions\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "gauravdhiman",
      "author_type": "User",
      "created_at": "2025-06-08T07:28:13Z",
      "updated_at": "2025-06-10T04:43:29Z",
      "closed_at": "2025-06-10T04:43:28Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3505/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3505",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3505",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:57.536967",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-429/bug-google-gemma-models-through-400-error\">SUPPORT-429 [Bug] Google Gemma models through 400 error</a></p>",
          "created_at": "2025-06-08T07:28:16Z"
        },
        {
          "author": "rahulsamant37",
          "body": "I think gemma model not allowing some of the tool as Developer instruction is not enabled for models/gemma-3-12b-it indicates an issue with using tools with this specific Gemma model via the API as search_knowledge: bool = True for agent for default\n\n## Try to Debug\n![Image](https://github.com/user-",
          "created_at": "2025-06-08T14:11:20Z"
        },
        {
          "author": "gauravdhiman",
          "body": "Thanks the fix looks good for system prompt issue. I think the same issue is also there when tools are used with Gemma models. This is what I see when I run the agent with Gemma and tools.\n\n## Error:\n```\nraise ClientError(status_code, response)\ngoogle.genai.errors.ClientError: 400 INVALID_ARGUMENT. ",
          "created_at": "2025-06-08T23:04:53Z"
        },
        {
          "author": "ysolanky",
          "body": "Closing as this is a model limitation ",
          "created_at": "2025-06-10T04:43:28Z"
        }
      ]
    },
    {
      "issue_number": 1988,
      "title": "[Bug] Mongo Vector Gave this error [SSL: CERTIFICATE_VERIFY_FAILED]",
      "body": "# Description\nwhen i try to use my my mongodb for vector search [SSL: CERTIFICATE_VERIFY_FAILED] this error is occurring\n\n```python\n MongoDb(\n            collection_name=companyName,\n            db_url=mdb_connection_string,\n            wait_until_index_ready=60,\n            wait_after_insert=300,\n        ),\n```\n\n## Environment\n- OS: macOS\n- Agno Version: latest\n-  Python 3.11\n\n",
      "state": "closed",
      "author": "emirhanyagci",
      "author_type": "User",
      "created_at": "2025-02-03T12:49:05Z",
      "updated_at": "2025-06-09T08:48:33Z",
      "closed_at": "2025-02-04T08:48:22Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/1988/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/1988",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/1988",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:57.732254",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Are you hosting mongodb yourself locally? If so can pass `tls=True, tlsAllowInvalidCertificates=True` and this will be passed to the underlying `MongoClient`. ",
          "created_at": "2025-02-04T08:42:02Z"
        },
        {
          "author": "emirhanyagci",
          "body": "I was using connection string fixed addig this params `tlsAllowInvalidCertificates=true`",
          "created_at": "2025-02-04T08:48:16Z"
        },
        {
          "author": "Sharath1036",
          "body": "hey @emirhanyagci how did you set up atlas vector search index? i am facing issues, can you help me out?",
          "created_at": "2025-06-09T08:48:32Z"
        }
      ]
    },
    {
      "issue_number": 3422,
      "title": "[Bug] Team routes queries to wrong agents and responses are frequently incorrect.",
      "body": "### Description\n\nI'm working on a customer service chatbot for an iGaming project. The bot is supposed to respond to player's queries on various topics like game rules, responsible gambling, spam detection, profanity detection etc, mostly typical front facing chatbot stuff. I created multiple agents to handle different topics, and a team leader which must reroute the query to an appropriate agent. However, quite often, I have noticed some problems here -\n- Leader routes to the correct agent, but the response generated is incorrect.\n<img width=\"1383\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/2a1c8b07-fe97-416b-b3eb-f40817e23b99\" />\n<img width=\"1434\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/268be576-f9a1-4fe6-a053-492acb4bf5c5\" />\n- Leader routes the query to a wrong agent, resulting in incorrect answer (this is relatively rare).\n<img width=\"1383\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/7c95ddaa-1c1e-4175-8b48-e9d74f268db7\" />\n<img width=\"1383\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/630e7719-692d-4840-9c70-ec602f14757e\" />\n- Leader responds to a previously asked question, and keeps answering the same question despite the memory being disabled, and the user asking different questions.\n<img width=\"1434\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/13807c60-90a0-4f82-a08d-af458d77fbe9\" />\n<img width=\"1434\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/c1b662e4-bebc-4455-9921-fa236e3e3d56\" />\n\nThe incorrect responses are almost always answers to questions which have been asked previously in the session. The bottomline seems to be that, the team leader does not always respond to the current query, but responds to something from its memory, despite the memory being turned off.\n\n### Steps to Reproduce\n\nI'm not exactly sure how to reproduce this, as these issues seem quite random and unpredictable. Here is the code I'm using\n\n```python\nfrom dotenv import load_dotenv\nfrom textwrap import dedent\nfrom agno.agent import Agent\nfrom agno.team.team import Team\nfrom agno.models.openai import OpenAIChat\nfrom agno.embedder.openai import OpenAIEmbedder\nfrom agno.vectordb.lancedb import LanceDb, SearchType\nfrom agno.knowledge.pdf import PDFKnowledgeBase, PDFReader\nfrom tools import get_screen_name_change_instructions, check_chat_block_status, get_round_details_by_id, redirect_to_agent  # these functions just return mock results\n\nload_dotenv()\n\n# --- Knowledge Base --- #\nfrom pathlib import Path\ncwd = Path(__file__).parent\ntmp_dir = cwd.joinpath(\"tmp\")\ntmp_dir.mkdir(parents=True, exist_ok=True)\npdf_knowledge_base = PDFKnowledgeBase(\n    path=\"data/game-rules.pdf\",\n    vector_db=LanceDb(\n        uri=str(tmp_dir.joinpath(\"lancedb\")),\n        table_name=\"agno_assist_knowledge\",\n        search_type=SearchType.hybrid,\n        embedder=OpenAIEmbedder(id=\"text-embedding-3-small\"),\n    ),\n    reader=PDFReader(),\n)\n\n# --- Customer Support Intent Agents --- #\n\nscreen_name_change_agent = Agent(\n    name=\"Screen Name Change Agent\",\n    role=\"You assist users who want to change their screen name, also referred as display name, profile name, nickname, name, or username.\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[get_screen_name_change_instructions],\n    monitoring=True,\n    instructions=\"Only output the `get_screen_name_change_instructions` tool response, no other text.\"\n)\n\nchat_issue_agent = Agent(\n    name=\"Chat Issue Agent\",\n    role=\"Assist users having trouble typing or sending messages in the public chat where players can message each other, can be referred as chat disabled, chat restricted, chat locked.\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[check_chat_block_status],\n    monitoring=True,\n    instructions=dedent(\"\"\"\n        1. Use the 'check_chat_block_status' tool to determine if the user is blocked from chat.\n        2. If blocked:\n           - If 'block_until' is set, inform the user when the restriction ends.\n           - If 'block_until' is None, it is a permanent block — inform the user and direct them to contact support for more information.\n        3. If not blocked, advise the user to clear cache or refresh the app.\n        4. Always remind them that chat activates only after placing a bet equal to or above the minimum required amount.\n    \"\"\")\n)\n\nwinnings_not_credited_agent = Agent(\n    name=\"Winnings Not Credited Agent\",\n    role=\"You assist users who claim that winnings from a bet have not been added to their account.\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    monitoring=True,\n    tools=[get_round_details_by_id],\n    instructions=dedent(\"\"\"\n        1. Inform users that winnings may take a few minutes to appear, and suggest refreshing the page or logging out and back in.\n        2. Ask them to provide the Round ID if they want you to check the bet manually.\n        3. Once you have the Round ID, use the 'get_round_details_by_id' tool with that ID.\n        4. Parse the response:\n           - If it contains an 'error', share the error message and ask for a valid Round ID.\n           - If successful, present the round details clearly to the user.\n    \"\"\")\n)\n\nbet_rejected_agent = Agent(\n    name=\"Bet Rejected Agent\",\n    role=\"Assist users whose bets were rejected. Determine whether funds were deducted and collect details to proceed accordingly.\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    monitoring=True,\n    instructions=dedent(\"\"\"\n        1. If the user says their bet was rejected and money was **deducted**, ask for the following:\n           - Game name\n           - Bet amount\n           - Game ID (or round ID)\n           Then inform the user you'll escalate the case to a live agent.\n\n        2. If the bet was rejected but **no money was deducted**, acknowledge the rejection and ask the user to confirm:\n           - Which game\n           - Approximate time of the attempted bet\n\n        Always respond empathetically and confirm that you're here to help them resolve the issue.\n    \"\"\")\n)\n\ngame_not_working_agent = Agent(\n    name=\"Game Not Working Agent\",\n    role=\"Assist users reporting a game is not loading, crashing, or unplayable.\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    monitoring=True,\n)\n\ndeposit_issue_agent = Agent(\n    name=\"Deposit Issue Agent\",\n    role=\"Assist users experiencing problems with depositing funds.\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    monitoring=True,\n)\n\nresponsible_gambling_agent = Agent(\n    name=\"Responsible Gambling Agent\",\n    role=\"Assist users asking about responsible gambling resources or mentioning gambling addiction.\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    monitoring=True,\n)\n\ngame_rules_agent = Agent(\n    name=\"Game Rules Agent\",\n    role=\"Assist users asking for the rules of a specific game.\",\n    instructions=\"Search your knowledge base before answering the question.\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    knowledge=pdf_knowledge_base,\n    monitoring=True,\n)\n\nhuman_handoff_agent = Agent(\n    name=\"Human Handoff Agent\",\n    role=\"Assist users who want to speak to a live agent, real person, or customer support.\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    monitoring=True,\n    tools=[redirect_to_agent],\n)\n\nspam_agent = Agent(\n    name=\"Spam Agent\",\n    role=\"Identify and handle irrelevant, unsolicited, or meaningless content.\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    monitoring=True,\n)\n\nprofanity_agent = Agent(\n    name=\"Profanity Agent\",\n    role=\"Identify and handle messages containing offensive language.\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    monitoring=True,\n)\n\nother_intent_agent = Agent(\n    name=\"Other Intent Agent\",\n    role=\"Handle intents that do not fit any of the other predefined categories.\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    monitoring=True,\n)\n\n# --- Customer Support Router Team --- #\n\ncustomer_support_team = Team(\n    name=\"Customer Support Team\",\n    mode=\"route\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    markdown=False,\n    debug_mode=True,\n    show_tool_calls=False,\n    enable_team_history=False,\n    show_members_responses=False,\n    members=[\n        screen_name_change_agent,\n        chat_issue_agent,\n        winnings_not_credited_agent,\n        bet_rejected_agent,\n        game_not_working_agent,\n        deposit_issue_agent,\n        responsible_gambling_agent,\n        game_rules_agent,\n        human_handoff_agent,\n        spam_agent,\n        profanity_agent,\n        other_intent_agent,\n    ],\n    description=\"You are the lead customer support agent. Your primary role is to accurately classify incoming player messages and route them to the specialist agent best equipped to handle the specific inquiry.\",\n    instructions=dedent(\"\"\"\n        Analyze the user's message carefully to identify their main intent.\n\n        For inquiries about changing screen names or usernames (e.g., 'How can I change my screen name?', 'I want to update my username.'), route to 'Screen Name Change Agent'.\n        For problems with chat functionality, like inability to type or send messages (e.g., 'Why can't I type this?', 'The chat is not letting me send messages.'), route to 'Chat Issue Agent'.\n        If a user claims winnings from a bet have not been credited to their account (e.g., 'My winnings weren’t added.', 'Where is my money from the bet?'), route to 'Winnings Not Credited Agent'.\n        If a user's bet was rejected or failed to process (e.g., 'Why was my bet rejected?', 'My bet didn’t go through.'), route to 'Bet Rejected Agent'.\n        When a user reports a game is not loading, crashing, or is unplayable (e.g., 'The game is not loading.', 'I can't play the game.'), route to 'Game Not Working Agent'.\n        For issues related to depositing funds (e.g., 'My deposit didn’t go through.', 'I tried to add funds, but it failed.'), route to 'Deposit Issue Agent'.\n        When a user asks about responsible gambling resources or mentions gambling addiction (e.g., 'I think I have a gambling problem.', 'Where can I get help for gambling addiction?'), route to 'Responsible Gambling Agent'.\n        For questions about the rules of a specific game (e.g., 'What are the rules for [game name]?', 'How do I play [game]?'), route to 'Game Rules Agent'.\n        If a user explicitly requests to speak to a live agent, human, or customer support (e.g., 'Talk to a live agent', 'I need to speak to a human'), route to 'Human Handoff Agent'.\n        For messages identified as irrelevant, unsolicited, or meaningless content, route to 'Spam Agent'.\n        If a message contains offensive or profane language, route to 'Profanity Agent'.\n        If the user's intent does not clearly align with any of the specialized agents above, route to 'Other Intent Agent'. This agent handles general inquiries or uncategorized issues.\n        \n        Do not invent answers, or return answers from the internet, or from your own knowledge base. Only use knowledge base provided with the agents. If answer is not available, say \"I do not have a response for that.\"\n        \"\"\"),\n)\n\nif __name__ == \"__main__\":\n    print(\"\\n--- Interactive Customer Support Chatbot ---\")\n    print(\"Type 'quit' or 'exit' to end the conversation.\")\n\n    while True:\n        user_input = input(\"\\nYou: \")\n        if user_input.lower() in [\"quit\", \"exit\"]:\n            print(\"Exiting chatbot.\")\n            break\n        \n        if not user_input.strip():\n            print(\"Please enter a message.\")\n            continue\n\n        print(\"Bot: \", end=\"\")\n        customer_support_team.print_response(user_input, stream=True)\n        print() # Add a newline after the streamed response for better formatting\n```\n\nI cannot provide the game rules files for obvious reasons, but any online manual containing rules for various casino games should do.\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nThe team leader should return response for the asked question, nothing else. Not answer to a previously asked question.\n\n### Actual Behavior\n\nThe team leader -\n- responds to a previously asked question,\n- keeps repeating same answer for different question, likely something from memory\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nPython version: \n3.11\n\nOS\nmacOS 15.5 (Apple Silicon)\n\nAgno Version:\n1.5.5\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\nOne interesting thing I have noticed is, instead of using a team of agents, if I use a single agent and assign it all the categories in the instructions, then it works almost flawlessly.\nLooks like a single agent with multiple responsibilites works better than a team of agents with single responsibility each.",
      "state": "closed",
      "author": "ppsid24",
      "author_type": "User",
      "created_at": "2025-05-30T11:40:29Z",
      "updated_at": "2025-06-09T07:43:31Z",
      "closed_at": "2025-06-07T04:29:45Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3422/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3422",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3422",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:57.916718",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-348/bug-team-routes-queries-to-wrong-agents-and-responses-are-frequently\">SUPPORT-348 [Bug] Team routes queries to wrong agents and responses are frequently incorrect.</a></p>",
          "created_at": "2025-05-30T11:40:33Z"
        },
        {
          "author": "FaniPet",
          "body": "I dug into this and confirmed that the root cause is the combination of:\n\n1. Closure capture of the first message in `get_forward_task_function`, and\n2. Agno’s caching of the `Function` instance inside `determine_tools_for_model`.\n\nMore specifically:\n\nIn `get_forward_task_function(self, message: Mes",
          "created_at": "2025-06-04T18:13:24Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Ah thanks for the spot! Fixing ",
          "created_at": "2025-06-06T10:15:23Z"
        },
        {
          "author": "dirkbrnd",
          "body": "This was released with [1.5.10.](https://github.com/agno-agi/agno/releases/tag/v1.5.10) Please check whether it works for you!",
          "created_at": "2025-06-07T04:29:45Z"
        },
        {
          "author": "FaniPet",
          "body": "@dirkbrnd Works for me now! Thanks",
          "created_at": "2025-06-09T07:43:30Z"
        }
      ]
    },
    {
      "issue_number": 3480,
      "title": "[Bug] Pydantic Serialization Error",
      "body": "### Description\n\nGetting an error `pydantic_core._pydantic_core.PydanticSerializationError: Unable to serialize unknown type: <class 'agno.utils.timer.Timer'>` when using \"arun\" on agent \n\n\n\n### Steps to Reproduce\n\nCall `arun` on agent (the agent should be pointing to a MCP Server running on SSE transport and it returns some JSON)\n\n### Agent Configuration (if applicable)\n\n```python\nfrom agno.agent import Agent\nfrom agno.models.google.gemini import Gemini\nfrom agno.tools.mcp import MCPTools, SSEClientParams\n\nfrom context import get_context\n\n# This is the URL of the MCP server we want to use.\nserver_url = \"http://localhost:8691/local/sse\"\n\nasync def get_agent_async(authorization_header : str)-> Agent:\n    params = SSEClientParams(headers={\"Authorization\": authorization_header}, url=server_url)\n    async with MCPTools(transport=\"sse\", server_params=params) as mcp_tools:\n        agent = Agent(\n            model=Gemini(),\n            tools=[mcp_tools],\n            markdown=True,\n            instructions=\"\"\"Use the tools below to answer the user's question. \n                    \"\"\",\n        )\n        return agent\n\n\nasync def execute(request: str):\n    \"\"\"\n    Execute the agent with the given request.\n\n    Args:\n        request: The user's request string\n    \"\"\"\n    ctx = get_context()\n\n\n    # Get agent\n    host_agent = await get_agent_async(ctx[\"authorization_header\"])\n    response = await host_agent.arun(request)\n\n\n    return response or {\"summary\": \"No response generated\"}\n```\n\n### Expected Behavior\n\nReturn response from MCP Server (or a LLM summarized version)\n\n### Actual Behavior\n\nError\n```\n line 463, in model_dump\n    return self.__pydantic_serializer__.to_python(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        self,\n        ^^^^^\n    ...<11 lines>...\n        serialize_as_any=serialize_as_any,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\npydantic_core._pydantic_core.PydanticSerializationError: Unable to serialize unknown type: <class 'agno.utils.timer.Timer'>\n```\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n- macOS\n- Agno v1.5.8\n```\n\n### Possible Solutions (optional)\n\nSimilar to https://github.com/agno-agi/agno/issues/2286 \n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "akeemphilbert",
      "author_type": "User",
      "created_at": "2025-06-05T11:13:14Z",
      "updated_at": "2025-06-08T13:52:52Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3480/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3480",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3480",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:58.146535",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-412/bug-pydantic-serialization-error\">SUPPORT-412 [Bug] Pydantic Serialization Error</a></p>",
          "created_at": "2025-06-05T11:13:17Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@akeemphilbert I am struggling to replicate. Any chance you have a longer stacktrace that can help me get more info? ",
          "created_at": "2025-06-05T18:50:11Z"
        },
        {
          "author": "akeemphilbert",
          "body": "ERROR    Failed to call MCP tool 'listPurchaseOrders':                          \n         Traceback (most recent call last):                                     \n           File                                                                 \n         \"/Users/username/PycharmProjects/project-folder/",
          "created_at": "2025-06-08T13:52:51Z"
        }
      ]
    },
    {
      "issue_number": 3503,
      "title": "[Bug] Cohere Chat not working with tool calls",
      "body": "### Description\n\nWhen using Cohere chat with tool calls the following error is arising:\n```sh\n*** cohere.errors.unprocessable_entity_error.UnprocessableEntityError: status_code: 422, body: {'message': \"unknown field: parameter 'requires_confirmation' is not a valid field. For proper usage, please refer to https://docs.cohere.com/reference/chat\"}\n```\n\n### Steps to Reproduce\n\n1. Create a team of agents\n2. Use `Cohere(id=\"command-a-03-2025\", temperature=0)` in the team + agents\n3. Get it to trigger a tool call\n\n### Agent Configuration (if applicable)\n\n```py\n\n```\n\n### Expected Behavior\n\nExpected no error\n\n### Actual Behavior\n\nError\n\n### Screenshots or Logs (if applicable)\n\n```\n*** cohere.errors.unprocessable_entity_error.UnprocessableEntityError: status_code: 422, body: {'message': \"unknown field: parameter 'requires_confirmation' is not a valid field. For proper usage, please refer to https://docs.cohere.com/reference/chat\"}\n```\n\n### Environment\n\n```markdown\n- OS: macOS Sonoma\n\n\"agno=1.5.10\",\n\"cohere=5.15.0\"\n```\n\n### Possible Solutions (optional)\n\nI fixed it locally by adding the following lines into `agno/models/cohere/chat.py`\n\nInside of the invoke function:\n```py\nfor tool in request_kwargs['tools']:\n    if 'requires_confirmation' in tool['function']:\n        del tool['function']['requires_confirmation']\n    if 'external_execution' in tool['function']:\n        del tool['function']['external_execution']\n```\n\n\n<img width=\"690\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/a7cdf81d-e968-4dfb-b732-ea3b5c8481b4\" />\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "parker84",
      "author_type": "User",
      "created_at": "2025-06-07T20:53:01Z",
      "updated_at": "2025-06-07T20:53:05Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3503/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3503",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3503",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:58.351633",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-427/bug-cohere-chat-not-working-with-tool-calls\">SUPPORT-427 [Bug] Cohere Chat not working with tool calls</a></p>",
          "created_at": "2025-06-07T20:53:04Z"
        }
      ]
    },
    {
      "issue_number": 3500,
      "title": "[Bug] Embedder not provided, using OpenAIEmbedder",
      "body": "### Description\n\nI was practicing the \"VectorDB\" part of the documentation where I used Qdrant. I got a message in the terminal \"Embedder not provided, using OpenAIEmbedder\", so i provided the \"embedder\" attribute with embedders from Ollama and I also tried HuggingFace since I don't have OpenAI API key. But I'm still getting the same message in terminal \"Embedder not provided, using OpenAIEmbedder\" and I'm unable to perform embeddings.\n\n### Steps to Reproduce\n\nThe Python code and instructions have been given in the below file:\n[qdrant.txt](https://github.com/user-attachments/files/20639512/qdrant.txt)\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nI expected the embedding to be performed successfully with Ollama's embedding model\n\n### Actual Behavior\n\nIn terminal, it displays \"Embedder not provided, using OpenAIEmbedder\"\n\n### Screenshots or Logs (if applicable)\n\nBefore using embedder (check the terminal)\n![Image](https://github.com/user-attachments/assets/e4642117-1d8d-4fb4-8b82-51e0ed3d850c)\n\nAfter using Ollama embedder (check the terminal)\n![Image](https://github.com/user-attachments/assets/94d67091-bf4f-4e09-81e5-c5e191e7e910)\n\n### Environment\n\n```markdown\n- OS: [Windows 11]\n- Agno version: [1.5.8]\n- External dependencies versions: [qdrant-client==1.14.2, pypdf==5.5.0, openai==1.82.1, ollama==0.4.9]\n- Additional environment details: [Python 3.11.0]\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "Sharath1036",
      "author_type": "User",
      "created_at": "2025-06-07T15:47:24Z",
      "updated_at": "2025-06-07T18:42:29Z",
      "closed_at": "2025-06-07T18:42:29Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3500/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3500",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3500",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:58.538843",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-425/bug-embedder-not-provided-using-openaiembedder\">SUPPORT-425 [Bug] Embedder not provided, using OpenAIEmbedder</a></p>",
          "created_at": "2025-06-07T15:47:28Z"
        }
      ]
    },
    {
      "issue_number": 3499,
      "title": "How to send image from agent ui and how to get sessions for a specific user",
      "body": "### Description\n\nNot able to get all sessions for a user using user id as only methods available are:\n  PlaygroundStatus: (PlaygroundApiUrl: string) =>\n    `${PlaygroundApiUrl}/v1/playground/status`,\n  GetPlaygroundSessions: (PlaygroundApiUrl: string, agentId: string) =>\n    `${PlaygroundApiUrl}/v1/playground/agents/${agentId}/sessions`\n\nNot able to send image through Agent UI\nhow to send image through agent ui, as playground is able to process image, but how to send it using agent ui\n\n### Steps to Reproduce\n\nSessions section in agent ui only has sessions until agent id is same\n\nNot able to send image in message, in which format do we need to send image\n\n### Agent Configuration (if applicable)\n\nux_memory = Memory(\n    db=SqliteMemoryDb(table_name=\"ux_memory\", db_file=\"tmp/ux_memory.db\"),\n    model=Claude(id=CLAUDE_MODEL_ID, max_tokens=12000),\n)\n\nux_agent = Agent(\n    name=\"UX Designer\",\n    model=Claude(id=CLAUDE_MODEL_ID, max_tokens=12000),\n    storage=ux_storage,\n    read_chat_history=True,\n    user_id=user_id,\n    memory=ux_memory,\n    enable_agentic_memory=True,\n    enable_user_memories=True,\n    tools=[ReasoningTools(add_instructions=True), JiraTools()],\n    show_tool_calls=True,\n    instructions=ux_instructions,\n    add_history_to_messages=True,\n    num_history_runs=10,\n    add_datetime_to_instructions=True,\n    markdown=True,\n    debug_mode=True,\n    num_history_sessions=3,\n    search_previous_sessions_history=True\n)\n\n\n### Expected Behavior\n\nShould be able to fetch sessions of a user for an agent using agent id and user id\n\nShould be able to attach image in message through agent ui\n\n### Actual Behavior\n\nNot able to fetch sessions of a user for an agent using agent id and user id\n\nNot able to attach image in message through agent ui\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nOS: Windows, MAC\nBrowser: Chrome\n\nAgno: 1.4.6\nPython: 3.13\n\nCLAUDE_MODEL_ID = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n\ndependencies = [\n    \"agno>=1.4.6\",\n    \"anthropic>=0.51.0\",\n    \"boto3>=1.38.13\",\n    \"jira>=3.8.0\",\n    \"python-dotenv>=1.1.0\",\n]\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "nikita-pawar",
      "author_type": "User",
      "created_at": "2025-06-07T07:45:32Z",
      "updated_at": "2025-06-07T07:45:36Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3499/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3499",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3499",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:58.721852",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-424/how-to-send-image-from-agent-ui-and-how-to-get-sessions-for-a-specific\">SUPPORT-424 How to send image from agent ui and how to get sessions for a specific user</a></p>",
          "created_at": "2025-06-07T07:45:35Z"
        }
      ]
    },
    {
      "issue_number": 3406,
      "title": "[Bug] aprint_response swallows exceptions & log_debug output in custom retriever function",
      "body": "### Description\n\nWhen I combine aprint_response with a custom retriever callback, any raise Exception(...) inside the retriever is silently ignored and calls to log_debug() never appear in the console. The rest of the pipeline continues to run, so debugging becomes impossible.\n\n\n### Steps to Reproduce\n\nReproduce code\n\n```python\n\nimport asyncio\n\nfrom agno.agent import Agent\nfrom agno.models.openrouter import OpenRouter\nfrom agno.utils.log import log_debug\n\n# ---------------------------------------------------------\n\n\n# Define the custom async retriever\nasync def retriever(query: str, agent: Agent | None = None, num_documents: int = 5, **kwargs) -> list[dict] | None:\n    \"\"\"\n    Custom async retriever function to search the vector database for relevant documents.\n    \"\"\"\n    log_debug(f\"\\n\\n\\n\\n\\nretriever: {query}\\n\\n\\n\\n\\n\")\n    raise Exception(\"test\")\n\n\nasync def main():\n    \"\"\"Async main function to demonstrate agent usage.\"\"\"\n    agent = Agent(\n        model=OpenRouter(id=\"openai/gpt-4o-mini\"),\n        retriever=retriever,\n        search_knowledge=True,\n        instructions=\"Search the knowledge base for information\",\n        show_tool_calls=True,\n        retries=2,\n        markdown=True,\n        debug_mode=True,\n        telemetry=False,\n    )\n\n    query = \"List down the ingredients to make Massaman Gai\"\n    await agent.aprint_response(query, markdown=True)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n\n\n```\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\n* The exception should propagate (or at least appear in the logs) so the developer sees “Intentional failure for test”.\n* The log_debug message “Retriever called with …” should be visible.\n\n### Actual Behavior\n\n* No exception is raised or logged.\n* No log_debug output from inside my_retriever appears.\n* The agent falls back to repeatedly calling the default asearch_knowledge_base tool, as shown in the excerpt below, and finally prints a response as if nothing went wrong.\n\n### Screenshots or Logs (if applicable)\n\n<img width=\"1085\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/79cb71b3-ba4f-409f-ab52-69790524678b\" />\n\n### Environment\n\n```markdown\nPython version: \n3.11\n\nOS\nmacOS 15.5 (Apple Silicon)\n\nAsync runtime\nasyncio (default)\n\nAgno Version:\n1.5.5\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\nIt seems that Openrouter must be used as the model provider to reproduce this exception",
      "state": "closed",
      "author": "CraxGrix",
      "author_type": "User",
      "created_at": "2025-05-29T08:41:08Z",
      "updated_at": "2025-06-07T04:33:01Z",
      "closed_at": "2025-06-07T04:33:00Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3406/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3406",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3406",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:58.961491",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-344/bug-aprint-response-swallows-exceptions-and-log-debug-output-in-custom\">SUPPORT-344 [Bug] aprint_response swallows exceptions &amp; log_debug output in custom retriever function</a></p>",
          "created_at": "2025-05-29T08:41:11Z"
        },
        {
          "author": "kausmeows",
          "body": "Hey @CraxGrix i tried in following way works for me- \n```py\nimport asyncio\nfrom typing import Optional\n\nfrom agno.agent import Agent\nfrom agno.embedder.openai import OpenAIEmbedder\nfrom agno.knowledge.pdf_url import PDFUrlKnowledgeBase\nfrom agno.vectordb.qdrant import Qdrant\nfrom qdrant_client impor",
          "created_at": "2025-05-29T10:52:27Z"
        },
        {
          "author": "CraxGrix",
          "body": "> 嘿[@CraxGrix](https://github.com/CraxGrix)我尝试了以下对我有用的方法-\n> \n> import asyncio\n> from typing import Optional\n> \n> from agno.agent import Agent\n> from agno.embedder.openai import OpenAIEmbedder\n> from agno.knowledge.pdf_url import PDFUrlKnowledgeBase\n> from agno.vectordb.qdrant import Qdrant\n> from qd",
          "created_at": "2025-05-29T11:34:06Z"
        },
        {
          "author": "dirkbrnd",
          "body": "A fix was released with [1.5.10.](https://github.com/agno-agi/agno/releases/tag/v1.5.10) Please check whether it works for you!",
          "created_at": "2025-06-07T04:33:00Z"
        }
      ]
    },
    {
      "issue_number": 3469,
      "title": "[Bug] Adding state to message is brittle",
      "body": "### Description\n\nWhen using an agent with `add_state_in_messages=True`, any user message (or even a delegated team message) with content containing curly braces, like JSON, causes a crash when the [formatting function is called](https://github.com/agno-agi/agno/blob/8c8e822266755d103faa9166aaa4ab3f2aa3e578/libs/agno/agno/agent/agent.py#L4052):\n```\n        if self.add_state_in_messages:\n            user_msg_content = self.format_message_with_state_variables(message)\n```\nThe error is:\n```\n(...)/lib/python3.12/string.py\", line 201, in _vformat\n    raise ValueError('Max string recursion exceeded')\n```\n\n\n\n### Steps to Reproduce\n\n1. Create an agent with `add_state_in_messages=True`\n2. Call the agent with:\n```\nHey\n```json\n{\n  \"properties\": {\n    \"title\": {\n      \"title\": \"a\"\n    }\n  }\n}```\n```\n\n\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nJSON content, or any other curly braces content, is left intact, while proper state variables get formatted/replaced correctly.\n\n### Actual Behavior\n\nThe formatter is not robust to nested curly braces and reaches a maximum recursion depth (set by Python to 2), crashing the agent execution.\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n- Agno version: 1.5.6\n```\n\n### Possible Solutions (optional)\n\nEither escape existing curly braces, doubling them, before inserting state placeholders, or use string.Template, using `${user_id}` instead of `{user_id}`:\n```\n>>> from string import Template\n>>> t = Template('{\"fvAp\": {\"attributes\": {\"name\": \"${name}\"}}')\n>>> t.substitute(name='StackOverflow')\n'{\"fvAp\": {\"attributes\": {\"name\": \"StackOverflow\"}}'\n```\n\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "kepler",
      "author_type": "User",
      "created_at": "2025-06-04T15:10:52Z",
      "updated_at": "2025-06-07T04:32:40Z",
      "closed_at": "2025-06-07T04:32:39Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3469/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3469",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3469",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:59.245676",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-406/bug-adding-state-is-brittle\">SUPPORT-406 [Bug] Adding state is brittle</a></p>",
          "created_at": "2025-06-04T15:10:55Z"
        },
        {
          "author": "rahulsamant37",
          "body": "Hello @kepler, Yes, you're right\nThe Problem is the current formatter treats ALL curly braces as potential template variables, so when it encounters JSON like '{\"fvAp\": {\"attributes\": {\"name\": \"${name}\"}}}', it tries to process,  {\"fvAp\": {\"attributes\": {\"name\": \"${name}\"}}} as a template variable, ",
          "created_at": "2025-06-04T20:58:40Z"
        },
        {
          "author": "kepler",
          "body": "Hi @rahulsamant37. Thank you for looking into this and for your suggestion.\n\nUnfortunately, I don't think that solves the issue. What it is doing is catching the `ValueError('Max string recursion exceeded')` exception and returning the message without any formatting.\n\nUsing your modified function wi",
          "created_at": "2025-06-05T10:35:32Z"
        },
        {
          "author": "rahulsamant37",
          "body": "Hello @kepler Sir, Yes you were right about that I totally missed that\nIs this what you mean? When you said \"So it would be a matter of using string.Template instead of string.Formatter\"\nChanges -\n```bash\ndef format_message_with_state_variables(self, msg: Any) -> Any:\n        \"\"\"Format a message wit",
          "created_at": "2025-06-05T14:55:30Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Thanks for digging into this! I have a PR out with that last solution which works well",
          "created_at": "2025-06-06T07:29:00Z"
        }
      ]
    },
    {
      "issue_number": 3466,
      "title": "[Bug] Claude tools, non-empty content",
      "body": "### Description\n\nWhen the agent uses the custom tool, it works everything fine. But at the next message an error appears.\n\n\n### Steps to Reproduce\n\n```python\n# Example of code\n@tool(show_result=False, requires_confirmation=False) \nasync def send_sticker_tool(emoji_keyword: str) -> Dict[str, Any]:\n    asyncio.create_task(\n        _send_sticker_delayed(emoji_keyword, chat_id=current_user)\n    )\n\n    return {\"success\": True}\n```\n\n\n\n\n### Agent Configuration (if applicable)\n\n```python\n agent = Agent(\n        agent_id=\"default\",\n        user_id=user_id,\n        session_id=session_id,\n        model=Claude(\n            id=CLAUDE_MODEL,\n            api_key=ANTHROPIC_API_KEY,\n            max_tokens=8192,\n            cache_system_prompt=True,\n            default_headers={\n                \"anthropic-beta\": \"files-api-2025-04-14\"\n            }\n        ),\n        tools=[\n            {\n                \"type\": \"web_search_20250305\",\n                \"name\": \"web_search\",\n                \"max_uses\": 5,\n            },\n            *STICKER_TOOLS,\n        ],\n        show_tool_calls=True, \n        debug_mode=True,\n        add_datetime_to_instructions=True,\n        memory=memory_storage,\n        enable_agentic_memory=True,\n        enable_session_summaries=True,\n        storage=sessions_storage,\n        add_history_to_messages=True,\n        num_history_runs=HISTORY_RUNS_KEEP,\n        read_chat_history=True,  \n)\n```\n\n### Expected Behavior\n\nEmpty message not included to request, or smth like that\n\n### Actual Behavior\n\nEmpty message included to api. So it cause error.\n\n### Screenshots or Logs (if applicable)\n\n## Before bug\n```logs\nDEBUG ======================== user =========================              \nDEBUG sticker please                                            \nDEBUG ======================== assistant =========================              \nDEBUG Tool Calls:                                                               \n        - ID: 'toolu_015sq3aP2wGiahep47xepiUN'                                  \n          Name: 'send_sticker_tool'                                             \n          Arguments: 'emoji_keyword: 🍎'                                        \nDEBUG ************************  METRICS  *************************              \nDEBUG * Tokens:                      input=446, output=60, total=506,           \n      cache_write_tokens=6396                                                   \nDEBUG * Time:                        2.6180s                                    \nDEBUG * Tokens per second:           22.9183 tokens/s                           \nDEBUG * Time to first token:         1.7164s                                    \nDEBUG ************************  METRICS  *************************              \n2025-06-04 14:37:30,749 - INFO - Chat 101: Tool call started event.\n2025-06-04 14:37:30,749 - INFO - Chat 101: Tool call send_sticker_tool hidden from user output.\nDEBUG Running: send_sticker_tool(emoji_keyword=🍎)                              \n2025-06-04 14:37:30,806 - INFO - Attempting to send sticker for emoji '🍎' to user_id: 101\n2025-06-04 14:37:30,807 - INFO - Chat 101: Tool call completed event.\n2025-06-04 14:37:30,807 - INFO - Chat 101: Tool completion send_sticker_tool hidden from user output.\nDEBUG =========================== tool ===========================              \nDEBUG Tool call Id: toolu_015sq3aP2wGiahep47xepiUN                              \nDEBUG {'success': True}                                                         \nDEBUG **********************  TOOL METRICS  **********************              \nDEBUG * Time:                        0.0025s                                    \nDEBUG **********************  TOOL METRICS  **********************              \nDEBUG =========================== tool ===========================              \nDEBUG Tool call Id: toolu_015sq3aP2wGiahep47xepiUN                              \nDEBUG {'success': True}                                                         \nDEBUG **********************  TOOL METRICS  **********************              \nDEBUG * Time:                        0.0025s                                    \nDEBUG **********************  TOOL METRICS  **********************              \nDEBUG ======================== assistant =========================      \n```\n\n## Next message\n\n```logs\nDEBUG =========================== user ===========================              \nDEBUG sticker please                                            \nDEBUG ======================== assistant =========================              \nDEBUG Tool Calls:                                                               \n        - ID: 'toolu_015sq3aP2wGiahep47xepiUN'                                  \n          Name: 'send_sticker_tool'                                             \n          Arguments: 'emoji_keyword: 🍎'                                        \nDEBUG =========================== user ===========================              \nDEBUG [{'type': 'tool_result', 'tool_use_id': 'toolu_015sq3aP2wGiahep47xepiUN', \n      'content': \"{'success': True}\"}]                                          \nDEBUG ======================== assistant =========================              \nDEBUG =========================== user ===========================              \nDEBUG thanks                                                                    \nERROR    Claude API error (status 400): Error code: 400 - {'type': 'error',     \n         'error': {'type': 'invalid_request_error', 'message': 'messages.15: all\n         messages must have non-empty content except for the optional final     \n         assistant message'}}  \n```\n\n### Environment\n\n```markdown\n- Agno 1.5.8 (also tried from main branch)\n- Python 3.12\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "stanislavlysenko0912",
      "author_type": "User",
      "created_at": "2025-06-04T12:46:41Z",
      "updated_at": "2025-06-07T04:32:13Z",
      "closed_at": "2025-06-07T04:32:12Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3466/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3466",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3466",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:59.553491",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-405/bug-claude-tools-non-empty-content\">SUPPORT-405 [Bug] Claude tools, non-empty content</a></p>",
          "created_at": "2025-06-04T12:46:44Z"
        },
        {
          "author": "manuhortet",
          "body": "Hey @stanislavlysenko0912, thanks for reporting. It does look like a bug on our side, but I'm not being able to reproduce it. Can you share some more info with me?\n \n1. how you are running your agent?\n2. can I see the implementation of `_send_sticker_delayed `? \n",
          "created_at": "2025-06-05T08:02:31Z"
        },
        {
          "author": "stanislavlysenko0912",
          "body": "Hey @manuhortet, thanks for the reply, I made another example can you try running it to tell me if you get a repeat error?\n\n```python\nimport asyncio\nimport importlib\nfrom random import randint\n\nfrom agno.agent import Agent\nfrom agno.models.anthropic import Claude\nfrom agno.storage.sqlite import Sqli",
          "created_at": "2025-06-05T16:19:28Z"
        },
        {
          "author": "manuhortet",
          "body": "Thanks @stanislavlysenko0912, I could recreate the situation now! It seems to be a problem with our `add_history_to_messages` flag. If you set it to False for now you will consistently avoid this error.\n\nWe will dive into the problem and work on a fix asap. Thanks again for reporting this!",
          "created_at": "2025-06-06T07:36:55Z"
        },
        {
          "author": "dirkbrnd",
          "body": "This was released with [1.5.10.](https://github.com/agno-agi/agno/releases/tag/v1.5.10) Please check whether it works for you!",
          "created_at": "2025-06-07T04:32:12Z"
        }
      ]
    },
    {
      "issue_number": 3448,
      "title": "[Bug] 'dict' object has no attribute 'model_dump'",
      "body": "### Description\n\nOn enabling storage we are getting below error on UI while Streaming \n\n{\n    \"content\": \"'dict' object has no attribute 'model_dump'\",\n    \"content_type\": \"str\",\n    \"event\": \"RunError\",\n    \"created_at\": 1748881982\n}\n\nNo error logs on backend,\n\nour backend configuration\n\nux_agent = Agent(\n    name=\"UX Designer\",\n    model=Claude(id=CLAUDE_MODEL_ID, max_tokens=12000),\n    storage=UXstorage,\n    read_chat_history=True,\n    user_id=user_id,\n    memory=ux_memory,\n    enable_agentic_memory=True,\n    enable_user_memories=True,\n    tools=[ReasoningTools(add_instructions=True), JiraTools()],\n    show_tool_calls=True,\n    instructions=ux_instructions,\n    add_history_to_messages=True,\n    num_history_runs=10,\n    add_datetime_to_instructions=True,\n    markdown=True,\n    debug_mode=True\n)\n UXstorage = SqliteStorage(\n            table_name=\"ux_session\",\n            db_file=\"tmp/data1.db\",\n        )\n\nWe are using below model\n\nCLAUDE_MODEL_ID = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n\n### Steps to Reproduce\n\nEnable storage in ux_agent,\nRun: uv run playground.py\non UI : send some messages, on 2nd or 3rd message we receive below error on ui \n\n\nOops! Something went wrong while streaming. 'dict' object has no attribute 'model_dump'\n\n### Agent Configuration (if applicable)\n\n{\n    \"content\": \"'dict' object has no attribute 'model_dump'\",\n    \"content_type\": \"str\",\n    \"event\": \"RunError\",\n    \"created_at\": 1748881982\n}\n\nNo error logs on backend,\n\nour backend configuration\n\nux_agent = Agent(\n    name=\"UX Designer\",\n    model=Claude(id=CLAUDE_MODEL_ID, max_tokens=12000),\n    storage=UXstorage,\n    read_chat_history=True,\n    user_id=user_id,\n    memory=ux_memory,\n    enable_agentic_memory=True,\n    enable_user_memories=True,\n    tools=[ReasoningTools(add_instructions=True), JiraTools()],\n    show_tool_calls=True,\n    instructions=ux_instructions,\n    add_history_to_messages=True,\n    num_history_runs=10,\n    add_datetime_to_instructions=True,\n    markdown=True,\n    debug_mode=True\n)\n UXstorage = SqliteStorage(\n            table_name=\"ux_session\",\n            db_file=\"tmp/data1.db\",\n        )\n\n### Expected Behavior\n\nNo error should be there on UI\n\n### Actual Behavior\n\non UI : send some messages, on 2nd or 3rd message we receive below error on ui \n\n\nOops! Something went wrong while streaming. 'dict' object has no attribute 'model_dump'\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nOS: Windows, MAC\nBrowser: Chrome\n\nAgno: 1.4.6\nPython: 3.13\n\nCLAUDE_MODEL_ID = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n\ndependencies = [\n    \"agno>=1.4.6\",\n    \"anthropic>=0.51.0\",\n    \"boto3>=1.38.13\",\n    \"jira>=3.8.0\",\n    \"python-dotenv>=1.1.0\",\n]\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "nikita-pawar",
      "author_type": "User",
      "created_at": "2025-06-03T07:49:43Z",
      "updated_at": "2025-06-07T04:31:06Z",
      "closed_at": "2025-06-07T04:31:06Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3448/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3448",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3448",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:59.790024",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-390/bug-dict-object-has-no-attribute-model-dump\">SUPPORT-390 [Bug] 'dict' object has no attribute 'model_dump'</a></p>",
          "created_at": "2025-06-03T07:49:47Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @nikita-pawar \nWe resolved this in one of the 1.5.x versions. Can you please confirm whether the latest release still gives this issue?",
          "created_at": "2025-06-06T09:35:11Z"
        }
      ]
    },
    {
      "issue_number": 3458,
      "title": "[Bug] ImageArtifact validation error from storage",
      "body": "### Description\n\n```\npydantic_core._pydantic_core.ValidationError: 1 validation error for ImageArtifact\nid\n  Field required [type=missing, input_value={'content': '/9j/4AAQSkZJ...mime_type': 'image/jpg'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n```\n\nI generate a picture with GeminiTools, the result is saved in storage postgresql, any repeated request to the same session gives an error\n\n### Steps to Reproduce\n\n1) Create an agent with GeminiTools and PostgresStorage\n2) Ask the agent to generate an image\n3) Ask any other question \n4) Get validation error\n\n### Agent Configuration (if applicable)\n\n```python\nstorage = PostgresStorage(\n    table_name=\"team_sessions\",\n    db_url=settings.DATABASE_URL_PSYCOPG,\n    mode=\"team\",\n    schema='public',\n)\n\nTeam(\n      team_id=\"team_agent\",\n      name=\"Team Agent\",\n      mode=\"coordinate\",\n      model=OpenAIChat(\n          id=\"o4-mini\",\n          http_client=client_factory.make_async_client(),\n          api_key=settings.OPENAI_API_KEY,\n      ),\n      members=[\n        Agent(\n              name=\"Image Generation Agent\",\n              model=OpenAIChat(\n                  id=\"gpt-4.1-mini\",\n                  http_client=client_factory.make_async_client(),\n                  api_key=settings.OPENAI_API_KEY,\n              ),\n              tools=[GeminiTools],\n              add_datetime_to_instructions=True,\n  \n              monitoring=True,\n              markdown=True,\n              debug_mode=debug_mode,\n       )     \n ],\n      storage=storage,\n)\n```\n\n### Expected Behavior\n\nThe agent responds to the request\n\n### Actual Behavior\n\nFalls saved image validation error\n\n### Screenshots or Logs (if applicable)\n\n```log\nERROR:    Exception in ASGI application\nTraceback (most recent call last):\n  File \"/home/maxim/PythonProjects/ai-agent/backend/.venv/lib/python3.13/site-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n    result = await app(  # type: ignore[func-returns-value]\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        self.scope, self.receive, self.send\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/home/maxim/PythonProjects/ai-agent/backend/.venv/lib/python3.13/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n    return await self.app(scope, receive, send)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/maxim/PythonProjects/ai-agent/backend/.venv/lib/python3.13/site-packages/fastapi/applications.py\", line 1054, in __call__\n    await super().__call__(scope, receive, send)\n  File \"/home/maxim/PythonProjects/ai-agent/backend/.venv/lib/python3.13/site-packages/starlette/applications.py\", line 112, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/home/maxim/PythonProjects/ai-agent/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py\", line 187, in __call__\n    raise exc\n  File \"/home/maxim/PythonProjects/ai-agent/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    await self.app(scope, receive, _send)\n  File \"/home/maxim/PythonProjects/ai-agent/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    await self.simple_response(scope, receive, send, request_headers=headers)\n  File \"/home/maxim/PythonProjects/ai-agent/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    await self.app(scope, receive, send)\n  File \"/home/maxim/PythonProjects/ai-agent/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/home/maxim/PythonProjects/ai-agent/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/home/maxim/PythonProjects/ai-agent/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/home/maxim/PythonProjects/ai-agent/backend/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 714, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/home/maxim/PythonProjects/ai-agent/backend/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 734, in app\n    await route.handle(scope, receive, send)\n  File \"/home/maxim/PythonProjects/ai-agent/backend/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"/home/maxim/PythonProjects/ai-agent/backend/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/home/maxim/PythonProjects/ai-agent/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/home/maxim/PythonProjects/ai-agent/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/home/maxim/PythonProjects/ai-agent/backend/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 73, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"/home/maxim/PythonProjects/ai-agent/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 301, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n    )\n    ^\n  File \"/home/maxim/PythonProjects/ai-agent/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    return await dependant.call(**values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/maxim/PythonProjects/ai-agent/backend/src/core/sessions/routes.py\", line 52, in stream_chat\n    response = await team.arun(message, stream=True, session_id=session_id, user_id=user_id)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/maxim/PythonProjects/ai-agent/backend/.venv/lib/python3.13/site-packages/agno/team/team.py\", line 1346, in arun\n    self.read_from_storage(session_id=session_id)\n    ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/maxim/PythonProjects/ai-agent/backend/.venv/lib/python3.13/site-packages/agno/team/team.py\", line 5956, in read_from_storage\n    self.load_team_session(session=self.team_session)\n    ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/maxim/PythonProjects/ai-agent/backend/.venv/lib/python3.13/site-packages/agno/team/team.py\", line 6046, in load_team_session\n    self.images.extend([ImageArtifact.model_validate(img) for img in images_from_db])\n                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^\n  File \"/home/maxim/PythonProjects/ai-agent/backend/.venv/lib/python3.13/site-packages/pydantic/main.py\", line 703, in model_validate\n    return cls.__pydantic_validator__.validate_python(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        obj, strict=strict, from_attributes=from_attributes, context=context, by_alias=by_alias, by_name=by_name\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\npydantic_core._pydantic_core.ValidationError: 1 validation error for ImageArtifact\nid\n  Field required [type=missing, input_value={'content': '/9j/4AAQSkZJ...mime_type': 'image/jpg'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n```\n\nMight help:\n\n**.venv/lib/python3.13/site-packages/agno/run/response.py:142**\n![Image](https://github.com/user-attachments/assets/8a3bb73a-6d90-4443-820d-5bde4e2f4039)\n\n**.venv/lib/python3.13/site-packages/agno/memory/v2/memory.py:221**\n\n### Environment\n\n```markdown\n- OS: Ubuntu 25.04\n- agno v1.5.8\n- python 3.13\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "cyberjq",
      "author_type": "User",
      "created_at": "2025-06-03T22:03:46Z",
      "updated_at": "2025-06-07T04:31:03Z",
      "closed_at": "2025-06-07T04:31:03Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3458/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3458",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3458",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:25:59.981893",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-392/bug-imageartifact-validation-error-from-storage\">SUPPORT-392 [Bug] ImageArtifact validation error from storage</a></p>",
          "created_at": "2025-06-03T22:03:50Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@cyberjq I believe this issue was fixed with 1.5.9. Can you please confirm? I could not replicate it after 1.5.9.",
          "created_at": "2025-06-06T09:33:47Z"
        }
      ]
    },
    {
      "issue_number": 3437,
      "title": "[Feature Request] Typing Indicator and other custom settings for WhatsApp inetgration",
      "body": "### Problem Description\n\nTo have typing indicator in the whatsapp integration, we need to have this parameter in the payload \n```\n'https://graph.facebook.com/<API_VERSION>/<WHATSAPP_BUSINESS_PHONE_NUMBER_ID>/messages'\n-H 'Authorization: Bearer <ACCESS_TOKEN>' \\\n-H 'Content-Type: application/json' \\\n-d '\n{\n  \"messaging_product\": \"whatsapp\",\n  \"status\": \"read\",\n  \"message_id\": \"<WHATSAPP_MESSAGE_ID>\",\n  \"typing_indicator\": {\n    \"type\": \"text\"\n  }\n}\n```\n\nBut the current payload only has \n```\n{\"messaging_product\":\"whatsapp\",\"contacts\":[{\"input\":\"917010626916\",\"wa_id\n      \":\"917010626916\"}],\"messages\":[{\"id\":\"wamid.HBgMOTE3MDEwNjI2OTE2FQIAERgSMj\n      ZDQzEzRTE0ODUzMkFGODIwAA==\"}]}          \n```\n\n### Proposed Solution\n\nNeed custom payload settings where we can enable such features\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [x] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "AkashS0510",
      "author_type": "User",
      "created_at": "2025-06-01T06:54:55Z",
      "updated_at": "2025-06-07T04:29:56Z",
      "closed_at": "2025-06-07T04:29:55Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3437/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3437",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3437",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:00.183323",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-356/feature-request-typing-indicator-and-other-custom-settings-for\">SUPPORT-356 [Feature Request] Typing Indicator and other custom settings for WhatsApp inetgration</a></p>",
          "created_at": "2025-06-01T06:54:58Z"
        },
        {
          "author": "AkashS0510",
          "body": "@ashpreetbedi ",
          "created_at": "2025-06-01T06:55:53Z"
        },
        {
          "author": "VirusDumb",
          "body": "Thanks for the suggestions, we will add these custom payload settings soon in the next iteration of our WhatsApp apps",
          "created_at": "2025-06-02T08:46:32Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@AkashS0510 adding asap!",
          "created_at": "2025-06-06T10:14:12Z"
        },
        {
          "author": "dirkbrnd",
          "body": "This was released with [1.5.10.](https://github.com/agno-agi/agno/releases/tag/v1.5.10) Please check whether it works for you!",
          "created_at": "2025-06-07T04:29:55Z"
        }
      ]
    },
    {
      "issue_number": 3443,
      "title": "[Bug] Session Metrics are stored as 0 when \"stream=True\" using AzureAIFoundry model.",
      "body": "### Description\n\nWhen using an agent powered by an AzureAIFoundry model with MongoDB storage, I encounter an issue where input and output token counts are reported as zero when ```stream=True``` is set during agent execution. This behavior does not occur when ```stream=False```—in that case, the token counts are correctly populated.\n\nNotably, this issue seems to be specific to Azure models, as I have not been able to reproduce it with models from Google or OpenAI providers under the same setup.\n\n### Steps to Reproduce\n\n- Create an agent using an AzureAIFoundry model.\n- Configure the agent to use MongoDB for storage.\n- Run the agent asynchronously with stream=True.\n- Observe that both input and output token counts are zero.\n- Run the same agent with stream=False and observe correct token usage tracking.\n\n\n\n### Agent Configuration (if applicable)\n\n```\nagent = Agent(\n    model=AzureAIFoundry(\n        id=\"gpt-4.1-mini\",\n        azure_endpoint=f\"{self.settings.azure_endpoint}/gpt-4.1-mini\"\n    ),\n    markdown=True,\n    storage=MongoDbStorage(\n        collection_name=\"sessions\",\n        db_url=settings.db_uri,\n        db_name=settings.db_name,\n    ),\n    add_history_to_messages=True,\n    num_history_runs=3,\n    read_chat_history=True,\n    monitoring=True,\n    instructions=AGENT_PROMPT,\n    add_state_in_messages=True,\n)\n```\n\n### Expected Behavior\n\nToken usage (input and output) should be accurately tracked and reported, regardless of the stream parameter value.\n\n### Actual Behavior\n\nWith ```stream=True```, both input and output token counts are zero for Azure models. With ```stream=False```, token counts are correctly reported.\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n├─ OS: Debian 12 (Bookworm, slim) via python:3.12-slim Docker image\n├─ Browser (if relevant): N/A\n├─ Agno Version: v1.5.1\n├─ External Dependency Versions: azure-ai-inference = \"^1.0.0b9\"\n├─ Additional Environment Details: Python 3.12\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "rnaidu-parallel",
      "author_type": "User",
      "created_at": "2025-06-02T06:40:29Z",
      "updated_at": "2025-06-06T11:47:11Z",
      "closed_at": "2025-06-06T09:53:31Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3443/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3443",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3443",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:00.382354",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-367/bug-session-metrics-are-stored-as-0-when-stream=true-using\">SUPPORT-367 [Bug] Session Metrics are stored as 0 when \"stream=True\" using AzureAIFoundry model.</a></p>",
          "created_at": "2025-06-02T06:40:32Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@rnaidu-parallel I was able to reproduce this, but Azure AI foundry is just not giving us any token usage information for GPT-4.1 for some reason. It does work with other models I tested with.\n\nI tried with `AzureOpenAI` and got metrics back from Azure. I can suggest that change?\nUnfortunately I don",
          "created_at": "2025-06-06T09:53:31Z"
        },
        {
          "author": "rnaidu-parallel",
          "body": "Thanks for looking into this! Yes, if AzureOpenAI is returning token usage metrics reliably, I'm okay with switching to that for now.",
          "created_at": "2025-06-06T11:47:10Z"
        }
      ]
    },
    {
      "issue_number": 3390,
      "title": "[Bug] cache_stystem_compt   --- stream",
      "body": "### Description\n\nhi, I have set the parameter cache_stystem_compt=True for claude, and the stream format of the agent, but i  cannot see if the cache is effective,  METRICS does not contain any information about cache_token:\n\nMessageMetrics(input_tokens=0, output_tokens=70, total_tokens=70, audio_tokens=0, input_audio_tokens=0, output_audio_tokens=0, cached_tokens=0, cache_write_tokens=0, reasoning_tokens=0, prompt_tokens=0, completion_tokens=0, prompt_tokens_details=None, completion_tokens_details=None, additional_metrics=None, time=2.7365310000022873, time_to_first_token=2.2907760000089183, timer=<agno.utils.timer.Timer object at 0x1608cf7a0>)\n\n### Steps to Reproduce\n\n-\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\n-\n\n### Actual Behavior\n\n-\n\n### Screenshots or Logs (if applicable)\n\n-\n\n### Environment\n\n```markdown\n-\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "harrisHxy",
      "author_type": "User",
      "created_at": "2025-05-28T09:42:05Z",
      "updated_at": "2025-06-06T10:58:16Z",
      "closed_at": "2025-06-06T10:58:15Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3390/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3390",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3390",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:00.593092",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-333/bug-cache-stystem-compt-stream\">SUPPORT-333 [Bug] cache_stystem_compt --- stream</a></p>",
          "created_at": "2025-05-28T09:42:09Z"
        },
        {
          "author": "dirkbrnd",
          "body": "This should now be working as that PR was merged!",
          "created_at": "2025-06-06T10:58:15Z"
        }
      ]
    },
    {
      "issue_number": 3463,
      "title": "[Bug] qwen2.5 tool calling not working",
      "body": "### Description\n\nIt is giving in response : \n\n\n                                                                                                                                                                                                        \n<tool_call>                                                                                                                                                                                             \n{\"name\": \"fetch_gpt_answer\", \"arguments\": \"{\\\"query\\\": \\\"fees of B.Tech in Computer Science from KIET Ghaziabad\\\"}\"}                    \n</tool_call>                                                                                                                                                                                            \n\n\nbut tool calling not happening:\n\n\nCode:\n\n```\nagent = Agent(\n    model=Ollama(id=\"qwen2.5:14b-instruct\", host=\"http://IP:12345\"),\n    tools=[fetch_gpt_answer],\n    show_tool_calls=True,\n    instructions=[\n     system_prompt\n    ],\n     add_history_to_messages=True,\n     num_history_responses=100,\n     session_id=\"ankit\",\n     debug_mode=False\n)\n```\n\nAlso it is working for llama3.3\n`• fetch_gpt_answer(data_str={\"query\": \"Hello, I am Neha calling from Shiksha.com. I see that you have shown interest in Btech in computer science from KIET Ghaziabad. Can we talk now?\"})             `                                                                                                                                           \n\n\n### Steps to Reproduce\n\nSimlpy run the agent\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nit should do tool call\n\n### Actual Behavior\n\nnot calling tool even though model is returning tool call\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nCUDA 12\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "ban1989ban",
      "author_type": "User",
      "created_at": "2025-06-04T09:46:19Z",
      "updated_at": "2025-06-06T10:45:39Z",
      "closed_at": "2025-06-06T10:45:39Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3463/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3463",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3463",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:00.885796",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-404/bug-qwen25-tool-calling-not-working\">SUPPORT-404 [Bug] qwen2.5 tool calling not working</a></p>",
          "created_at": "2025-06-04T09:46:23Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @ban1989ban \nUnfortunately the qwen model with 14b params is just not strong enough for correct tool calling. This is a known issue with some Ollama served models. ",
          "created_at": "2025-06-05T19:02:51Z"
        }
      ]
    },
    {
      "issue_number": 3293,
      "title": "[Bug] Gemini model not working with a documentation example",
      "body": "### Description\n\nTried using gemini in https://docs.agno.com/teams/introduction and am getting null responses\n\n### Steps to Reproduce\n\nGo to https://docs.agno.com/teams/introduction\nReplace all agent models with Gemini using gemini-2.5-flash-preview-05-20\nGet null responses\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nSame behaviour as when using OpenAIChat\n\n### Actual Behavior\n\nGetting null responses from the agents\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nagno version: 1.5.1\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "motapinto",
      "author_type": "User",
      "created_at": "2025-05-22T11:52:21Z",
      "updated_at": "2025-06-06T06:56:11Z",
      "closed_at": "2025-06-06T06:56:11Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3293/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3293",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3293",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:01.064573",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-267/bug-gemini-model-not-working-with-a-documentation-example\">SUPPORT-267 [Bug] Gemini model not working with a documentation example</a></p>",
          "created_at": "2025-05-22T11:52:24Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @motapinto \nI have tried all the above examples with only Gemini model instances (with `gemini-2.5-flash-preview-05-20`) and I always get a response. We believe this was an intermittent issue with Gemini that has since been resolved. Can you confirm this is the case for you?",
          "created_at": "2025-05-26T11:15:31Z"
        }
      ]
    },
    {
      "issue_number": 3342,
      "title": "[Bug] litellm bedrock claude tool call error",
      "body": "### Description\n\nagent/agno/cookbook/examples/agents/thinking_finance_agent.py\ncan't run this example using litellm with bedrock claude 3.7\n\n### Steps to Reproduce\n\nwith:\n    model=OpenAIChat(id=\"claude-3.7-sonnet\", api_key=\"sk-12341234\", base_url=\"http://localhost:4000\"),\n\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nrun successfully\n\n### Actual Behavior\n\nrun with error\n\n### Screenshots or Logs (if applicable)\n\n```log\nTraceback (most recent call last):\n  File \"/home/ubuntu/py312/lib/python3.12/site-packages/agno/models/openai/chat.py\", line 452, in invoke_stream\n    yield from self.get_client().chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ubuntu/py312/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 287, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ubuntu/py312/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 925, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/ubuntu/py312/lib/python3.12/site-packages/openai/_base_client.py\", line 1239, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ubuntu/py312/lib/python3.12/site-packages/openai/_base_client.py\", line 1034, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': 'litellm.BadRequestError: BedrockException - {\"message\":\"The toolUse blocks at messages.2.content contain duplicate Ids: tooluse_S2Y-ihliT5GaxJrradA5CA\"}. Received Model Group=claude-3.7-sonnet\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '400'}}\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/agent/agno/cookbook/examples/agents/thinking_finance_agent.py\", line 68, in <module>\n    finance_agent.print_response(\n  File \"/home/ubuntu/py312/lib/python3.12/site-packages/agno/agent/agent.py\", line 6247, in print_response\n    for resp in self.run(\n                ^^^^^^^^^\n  File \"/home/ubuntu/py312/lib/python3.12/site-packages/agno/agent/agent.py\", line 700, in _run_stream\n    for event in self._handle_model_response_stream(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ubuntu/py312/lib/python3.12/site-packages/agno/agent/agent.py\", line 2807, in _handle_model_response_stream\n    for model_response_chunk in self.model.response_stream(\n                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ubuntu/py312/lib/python3.12/site-packages/agno/models/base.py\", line 724, in response_stream\n    yield from self.process_response_stream(\n  File \"/home/ubuntu/py312/lib/python3.12/site-packages/agno/models/base.py\", line 689, in process_response_stream\n    for response_delta in self.invoke_stream(\n                          ^^^^^^^^^^^^^^^^^^^\n  File \"/home/ubuntu/py312/lib/python3.12/site-packages/agno/models/openai/chat.py\", line 487, in invoke_stream\n    raise ModelProviderError(\nagno.exceptions.ModelProviderError: litellm.BadRequestError: BedrockException - {\"message\":\"The toolUse blocks at messages.2.content contain duplicate Ids: tooluse_S2Y-ihliT5GaxJrradA5CA\"}. Received Model Group=claude-3.7-sonnet\nAvailable Model Group Fallbacks=None\n```\n\n### Environment\n\n```markdown\n- os: ubuntu linux\n- agno: 1.5.4\n- python: 3.12.10\n- litellm: 1.71\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "colorzhang",
      "author_type": "User",
      "created_at": "2025-05-25T06:55:19Z",
      "updated_at": "2025-06-06T06:56:00Z",
      "closed_at": "2025-06-06T06:56:00Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3342/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3342",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3342",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:01.387095",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-300/bug-litellm-bedrock-claude-tool-call-error\">SUPPORT-300 [Bug] litellm bedrock claude tool call error</a></p>",
          "created_at": "2025-05-25T06:55:22Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @colorzhang \nIt looks like you are using the OpenAI model class for LiteLLM. Have you tried to use our LiteLLM class instead? Or even better yet would be the AwsBedrock or AwsBedrock Claude model class.\n- [LiteLLM docs](https://docs.agno.com/models/litellm)\n- [AWS Claud docs](https://docs.agno.co",
          "created_at": "2025-05-26T09:33:58Z"
        }
      ]
    },
    {
      "issue_number": 3476,
      "title": "[Bug] Team User Memories",
      "body": "### Description\n\nWhen using Team and enable_user_memories user memories are recorder only after first conversation. If memory class is recreated user memories are not generated.\n```python\n                user_memories = self.memory.memories.get(user_id, {})  # type: ignore\n                if user_memories and len(user_memories) > 0:\n                    system_message_content += (\n                        \"You have access to memories from previous interactions with the user that you can use:\\n\\n\"\n                    )\n                    system_message_content += \"<memories_from_previous_interactions>\"\n                    for _memory in user_memories.values():  # type: ignore\n                        system_message_content += f\"\\n- {_memory.memory}\"\n```\n\n\n\n### Steps to Reproduce\n\n1. Create user memory in team:  \"My name is john billings and I live in nyc.\"\n2. Reload application\n3. Ask team \"Who i am?\" with new session\n4. Team does not remember you\n\n### Agent Configuration (if applicable)\n\n```python\n\"\"\"\nThis recipe shows how to store personalized memories and summaries in a sqlite database.\n\nSteps:\n1. Run: `pip install openai sqlalchemy agno` to install dependencies\n2. Run: `python cookbook/teams/memory/03_user_memories.py` to run the agent\n\"\"\"\n\nfrom agno.agent import Agent\nfrom agno.memory.v2.db.sqlite import SqliteMemoryDb\nfrom agno.memory.v2.memory import Memory\nfrom agno.models.google.gemini import Gemini\nfrom agno.models.openai import OpenAIChat\nfrom agno.models.perplexity.perplexity import Perplexity\nfrom agno.storage.agent.sqlite import SqliteAgentStorage\nfrom agno.team.team import Team\nfrom agno.tools.yfinance import YFinanceTools\nfrom utils import print_chat_history, print_team_memory\n\n# This memory is shared by all the agents in the team\nmemory_db = SqliteMemoryDb(table_name=\"memory\", db_file=\"tmp/memory.db\")\n\nmemory = Memory(model=Gemini(id=\"gemini-2.0-flash-exp\"), db=memory_db)\n\n# Reset the memory for this example\nmemory.clear()\n\n\nstock_searcher = Agent(\n    name=\"Stock Searcher\",\n    model=OpenAIChat(\"gpt-4o\"),\n    role=\"Searches the web for information on a stock.\",\n    tools=[YFinanceTools(cache_results=True)],\n    storage=SqliteAgentStorage(\n        table_name=\"agent_sessions\", db_file=\"tmp/persistent_memory.db\"\n    ),\n    memory=memory,\n)\n\nweb_searcher = Agent(\n    name=\"Web Searcher\",\n    model=Perplexity(id=\"sonar-pro\"),\n    role=\"Searches the web for information on a company.\",\n    storage=SqliteAgentStorage(\n        table_name=\"agent_sessions\", db_file=\"tmp/persistent_memory.db\"\n    ),\n    memory=memory,\n)\n\nteam = Team(\n    name=\"Stock Team\",\n    mode=\"coordinate\",\n    model=OpenAIChat(\"gpt-4o\"),\n    # Store team sessions in a database\n    storage=SqliteAgentStorage(\n        table_name=\"team_sessions\", db_file=\"tmp/persistent_memory.db\"\n    ),\n    # The memories are personalized for this user\n    user_id=\"john_billings\",\n    # Store the memories and summary in a table: agent_memory\n    memory=memory,\n    members=[stock_searcher, web_searcher],\n    instructions=[\n        \"You can search the stock market for information about a particular company's stock.\",\n        \"You can also search the web for wider company information.\",\n    ],\n    # Set enable_team_history=true to add the previous chat history to the messages sent to the Model.\n    enable_team_history=True,\n    num_of_interactions_from_history=5,\n    # Create and store personalized memories for this user\n    enable_user_memories=True,\n    show_tool_calls=True,\n    markdown=True,\n    show_members_responses=True,\n    debug_mode=True\n)\n\nsession_id = \"stock_team_session_1\"\nuser_id = \"john_billings\"\n\n# -*- Share personal information\nteam.print_response(\n    \"My name is john billings and I live in nyc.\",\n    stream=True,\n    session_id=session_id,\n    user_id=user_id,\n)\n\n# Reinitialize the team after reload of application\n\n# This memory is shared by all the agents in the team\nmemory_db = SqliteMemoryDb(table_name=\"memory\", db_file=\"tmp/memory.db\")\n\nmemory = Memory(model=Gemini(id=\"gemini-2.0-flash-exp\"), db=memory_db)\n\nteam = Team(\n    name=\"Stock Team\",\n    mode=\"coordinate\",\n    model=OpenAIChat(\"gpt-4o\"),\n    # Store team sessions in a database\n    storage=SqliteAgentStorage(\n        table_name=\"team_sessions\", db_file=\"tmp/persistent_memory.db\"\n    ),\n    # The memories are personalized for this user\n    user_id=\"john_billings\",\n    # Store the memories and summary in a table: agent_memory\n    memory=memory,\n    members=[stock_searcher, web_searcher],\n    instructions=[\n        \"You can search the stock market for information about a particular company's stock.\",\n        \"You can also search the web for wider company information.\",\n    ],\n    # Set enable_team_history=true to add the previous chat history to the messages sent to the Model.\n    enable_team_history=True,\n    num_of_interactions_from_history=5,\n    # Create and store personalized memories for this user\n    enable_user_memories=True,\n    show_tool_calls=True,\n    markdown=True,\n    show_members_responses=True,\n    debug_mode=True\n)\n\nimport uuid\n# -*- Share personal information\nteam.print_response(\n    \"Who i am?\",\n    stream=True,\n    session_id=uuid.uuid4(),\n    user_id=user_id,\n)\n```\n\n### Expected Behavior\n\n You are John Billings, and you live in NYC.\n\n### Actual Behavior\n\n I currently do not have any information about you or past interactions. If you'd like to share more about yourself or your interests, feel free to do so! \n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n- Agno Version: 1.5.8\n```\n\n### Possible Solutions (optional)\n\n```python\n                user_memories = self.memory.get_user_memories(user_id=user_id)\n                if user_memories and len(user_memories) > 0:\n                    system_message_content += (\n                        \"You have access to memories from previous interactions with the user that you can use:\\n\\n\"\n                    )\n                    system_message_content += \"<memories_from_previous_interactions>\"\n                    for _memory in user_memories:  # type: ignore\n```\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "PT-Cloud2",
      "author_type": "User",
      "created_at": "2025-06-05T07:19:30Z",
      "updated_at": "2025-06-05T18:58:27Z",
      "closed_at": "2025-06-05T18:58:26Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3476/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3476",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3476",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:01.626899",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-411/bug-team-user-memories\">SUPPORT-411 [Bug] Team User Memories</a></p>",
          "created_at": "2025-06-05T07:19:34Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Thanks for raising! Fix coming out with 1.5.9!",
          "created_at": "2025-06-05T18:58:26Z"
        }
      ]
    },
    {
      "issue_number": 3202,
      "title": "[Bug] Inefficiency in local embedder model loading",
      "body": "### Description\n\nIt's not exactly a bug, but I find the model loading logic below a bit wasteful.\nUnless there's some reason behind it, shouldn't we load the model only once at init time instead of loading the same model every time on `get_embedding` calls?\n\nhttps://github.com/agno-agi/agno/blob/969c86274bc8e6d29a6466c92cba60425b4f673a/libs/agno/agno/embedder/fastembed.py#L21-L22\n\nAnd here as well\n\nhttps://github.com/agno-agi/agno/blob/969c86274bc8e6d29a6466c92cba60425b4f673a/libs/agno/agno/embedder/sentence_transformer.py#L24-L30\n\n(which has a related PR pending #2420 with similar intention as to reuse a model client)\n\n### Steps to Reproduce\n\nnot applicable\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nloading embedding models only once at Embedder init time to save unnecessary subsequent loads \n\n### Actual Behavior\n\nevery time we call get_embedding the embedding model gets initiated/loaded again\n\n(depending on the underlying library, this might be cached away but still we shouldn't rely on that)\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nnot applicable\n```\n\n### Possible Solutions (optional)\n\ninitialize a self.model in __init__ then use that inside get_embedding\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "zhixing0",
      "author_type": "User",
      "created_at": "2025-05-15T03:06:12Z",
      "updated_at": "2025-06-05T18:36:51Z",
      "closed_at": "2025-06-05T18:36:50Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3202/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 1
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3202",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3202",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:01.828484",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Being released with 1.5.9!",
          "created_at": "2025-06-05T18:36:50Z"
        }
      ]
    },
    {
      "issue_number": 3449,
      "title": "[Bug] Issue when using tools and user_input_schema is None",
      "body": "### Description\n\nThere is an issue when using `storage` (Mongo) as the keeper of memories and tools as part of the agent. If the `user_input_schema` field is None, then the memory cannot be parsed into a `RunResponse` object. In that case, it tries to iterate over a `None` value, leading to an error. (error is in file `/agno/models/response.py:72`\n\nThis error causes that memory to be destroyed in a new interaction with the same `session_id`. I will create a PR to solve this issue.\n\n### Steps to Reproduce\n\n1. Generate an agent\n2. Run the agent using the session_id for the entirety of the conversation\n3. Use a tool decorated with `@tool` without defining user_input\n4. Run a subsequent question, memory should not include question/answers that used the tool\n\n### Agent Configuration (if applicable)\n\n```python\nAgent(\n            name=\"Agent\",\n            user_id=user_id,\n            session_id=session_id,\n            show_tool_calls=True,\n            model=azure_model,\n            tools=tools,\n            add_datetime_to_instructions=True,\n            session_state={\"source\": {}, 'LLIM': LLIM, 'RLIM':RLIM, 'SOURCE_ID_LENGTH': SOURCE_ID_LENGTH,\n                            'session_id': session_id},\n            add_state_in_messages=True,\n            instructions=get_instructions(web_search=web_search),\n            storage=MongoDbStorage(db_url=mongo_db_uri, db_name=db_name, collection_name=collection_name_storage),\n            enable_agentic_memory=True,  # Agent can update memory during runs\n            enable_user_memories=True,  # Agent stores user facts/preferences\n            enable_session_summaries=True,  # Agent stores session summaries\n            add_session_summary_references=True,  # Add session summary references to responses\n            add_history_to_messages=True,  # Include chat history in model context\n            read_chat_history=True,\n            num_history_responses=8,  # Number of past runs to include in context, ...\n```\n\n### Expected Behavior\n\nThe expected behaviour is for all memories to be added to the agent memory in a run.\n\n### Actual Behavior\n\nAt the moment, memories where `user_input_schema` field is None are not included in the run memory and then deleted from database.\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n- OS Mac Sequoia & Ubuntu\n- Agno Version: 1.5.4\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "mastertilla",
      "author_type": "User",
      "created_at": "2025-06-03T07:57:31Z",
      "updated_at": "2025-06-05T18:20:09Z",
      "closed_at": "2025-06-05T18:20:08Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3449/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3449",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3449",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:01.991178",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-391/bug-issue-when-using-tools-and-user-input-schema-is-none\">SUPPORT-391 [Bug] Issue when using tools and user_input_schema is None</a></p>",
          "created_at": "2025-06-03T07:57:35Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Released with 1.5.9!",
          "created_at": "2025-06-05T18:20:08Z"
        }
      ]
    },
    {
      "issue_number": 3484,
      "title": "[Feature Request]  Please add file extension in knowledge base metadata name field",
      "body": "### Problem Description\n\n### Description\n\nI have created a teams of agent were one of the sub agent has access to knowledgebase. While retrieving the data from Knowledgebase, its not showing the extension of document in result meta_data.\n\nBelow is my knowledge declaration \n\npdf_knowledge_base=  PDFKnowledgeBase(\npath=Path(r\"Docs\"),\nvector_db=LanceDb(\nuri=\"vectordb\",\ntable_name=\"policy_data\", search_type=SearchType.hybrid, \nembedder=azure_embedding_model\n),\n)\n\nIt's fetching the contents and doc name properly, only file extension is missing in the name. \n\n### Steps to Reproduce\n\nGive a doc related query to agent\nAgent will fetch the records from Knowledgebase without extension in name.\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nExtension should also be there within the name.\n\n### Actual Behavior\n\nGiving only the name without extension.\n\n### Screenshots or Logs (if applicable)\n\n![Image](https://github.com/user-attachments/assets/7812f245-b998-4b1a-9646-e5f81cf6924a)\n\n### Environment\n\n```markdown\nWindows 11\nPython 3.12\nAgno 1.5.1\nlancedb 0.22.0\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_\n\n### Proposed Solution\n\nAdd extension as well\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [x] No, I’m just sharing the idea.",
      "state": "open",
      "author": "AkhilmsAchu",
      "author_type": "User",
      "created_at": "2025-06-05T16:40:48Z",
      "updated_at": "2025-06-05T16:41:36Z",
      "closed_at": null,
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3484/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3484",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3484",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:02.190822",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-413/feature-request-please-add-file-extension-in-knowledge-base-metadata\">SUPPORT-413 [Feature Request] Please add file extension in knowledge base metadata name field</a></p>",
          "created_at": "2025-06-05T16:40:51Z"
        }
      ]
    },
    {
      "issue_number": 2501,
      "title": "[Bug] MistralChat immediately cause error with Agno > 1.1.13",
      "body": "# Description\nOnce I upgrade Ango from 1.1.9 to the latest (1.1.16), the agent that is using MistralChat failed. I downgrade Agno back to 1.1.9 then slowly upgrade up until 1.1.13 where it is still working fine with the same exact code. It looks to fail before it makes the call to api.mistral.ai. \n\n## CODE\n`class NewsArticle(BaseModel):\n    date: Optional[str] = Field(None, description=\"Date of the article.\")\n    title: Optional[str] = Field(None, description=\"Title of the article.\")\n    url: Optional[str] = Field(None, description=\"Link to the article.\")\n    source: Optional[str] = Field(None, description=\"Source of the article.\") \n\nclass SearchResults(BaseModel):\n    articles: list[NewsArticle]\n\nsearch_analyzer: Agent = Agent(\n    model=MistralChat(\n        id=\"mistral-large-latest\",\n        api_key=MISTRAL_API_KEY\n    ),\n    description=\"You are an AI assistant responsible for analyzing search results (titles, URLs, descriptions) to identify up to 10 URLs directly related to a specific Product Name and its Domain. Your task involves filtering out non-relevant content (e.g., documentation, technical references, administrative pages) and retaining only articles with substantive product information. Your goal is to return a ranked list of URLs based on relevance to the Product Name and Domain.\",\n    instructions=dedent(\"\"\"\\\n    Follow these instructions carefully:\n        Analyze the title, URL, and description of each search result.\n        Retain articles that:\n            - Directly mention the Product Name or Domain.\n            - Provide substantive product details (e.g., features, benefits, use cases, pricing, reviews).\n        Exclude articles that:\n            - Are documentation, technical guides, or API references.\n            - Belong to administrative pages (e.g., login, terms of service, privacy policy).\n            - Focus on unrelated topics or generic industry news.\n        Rank the retained URLs by relevance:\n            - Highest priority: Articles explicitly about the product/domain with detailed information.\n            - Lower priority: Articles mentioning the product/domain briefly.\n        Return only the URLs in a ranked list (most relevant first).\n        IMPORTANT: Ensure the list contains no duplicates and is limited to 10 URLs.\\\n    \"\"\"),\n    markdown=False,\n    show_tool_calls=True,    \n    debug_mode=True,\n    response_model=SearchResults\n)`\n\n## Environment\n- OS: macOS and Ubuntu\n- Agno Version: 1.1.14 to 1.1.16\n- Additional Environment Details: Python 3.12\n\n## Possible Solutions (optional)\nVersion Agno lower than 1.1.14 works perfectly fine. \nCurrent version of Agno = 1.1.13 and it is working on my dev box (macOS) and production (Ubuntu)\n\n## Error Log\n`ERROR    Workflow.run() failed: Unexpected type: None\nTraceback (most recent call last):\n  File \"/var/www/aitools/agents/tools_workflow.py\", line 1958, in <module>\n    aitool_content: RunResponse = generate_blog_post.run(topic=topic)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/var/www/aitools/venv/lib/python3.12/site-packages/agno/workflow/workflow.py\", line 169, in run_workflow\n    raise e\n  File \"/var/www/aitools/venv/lib/python3.12/site-packages/agno/workflow/workflow.py\", line 166, in run_workflow\n    result = self._subclass_run(**kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/var/www/aitools/agents/tools_workflow.py\", line 1880, in run\n    search_results_analysed = self.get_search_analyzed_results(topic, search_results)\n                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/var/www/aitools/agents/tools_workflow.py\", line 1273, in get_search_analyzed_results\n    search_results_analysed_response = self.search_analyzer.run( prompt )\n                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/var/www/aitools/venv/lib/python3.12/site-packages/agno/agent/agent.py\", line 980, in run\n    return next(resp)\n           ^^^^^^^^^^\n  File \"/var/www/aitools/venv/lib/python3.12/site-packages/agno/agent/agent.py\", line 695, in _run\n    model_response = self.model.response(messages=run_messages.messages)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/var/www/aitools/venv/lib/python3.12/site-packages/agno/models/base.py\", line 176, in response\n    assistant_message, has_tool_calls = self._process_model_response(\n                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/var/www/aitools/venv/lib/python3.12/site-packages/agno/models/base.py\", line 315, in _process_model_response\n    response = self.invoke(messages=messages)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/var/www/aitools/venv/lib/python3.12/site-packages/agno/models/mistral/mistral.py\", line 256, in invoke\n    response = self.get_client().chat.parse(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/var/www/aitools/venv/lib/python3.12/site-packages/mistralai/chat.py\", line 37, in parse\n    json_response_format = response_format_from_pydantic_model(response_format)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/var/www/aitools/venv/lib/python3.12/site-packages/mistralai/extra/utils/response_format.py\", line 13, in response_format_from_pydantic_model\n    model_schema = rec_strict_json_schema(model.model_json_schema())\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/var/www/aitools/venv/lib/python3.12/site-packages/mistralai/extra/utils/_pydantic_helper.py\", line 14, in rec_strict_json_schema\n    schema_node[key] = rec_strict_json_schema(value)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/var/www/aitools/venv/lib/python3.12/site-packages/mistralai/extra/utils/_pydantic_helper.py\", line 14, in rec_strict_json_schema\n    schema_node[key] = rec_strict_json_schema(value)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/var/www/aitools/venv/lib/python3.12/site-packages/mistralai/extra/utils/_pydantic_helper.py\", line 14, in rec_strict_json_schema\n    schema_node[key] = rec_strict_json_schema(value)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [Previous line repeated 2 more times]\n  File \"/var/www/aitools/venv/lib/python3.12/site-packages/mistralai/extra/utils/_pydantic_helper.py\", line 19, in rec_strict_json_schema\n    raise ValueError(f\"Unexpected type: {schema_node}\")\nValueError: Unexpected type: None\n2025-03-23 11:34:24,607 - DEBUG - Using selector: EpollSelector`\n\n",
      "state": "closed",
      "author": "josephtrinh",
      "author_type": "User",
      "created_at": "2025-03-23T05:15:23Z",
      "updated_at": "2025-06-05T16:18:21Z",
      "closed_at": "2025-04-07T20:20:21Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2501/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2501",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2501",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:02.398408",
      "comments": [
        {
          "author": "lironesamoun",
          "body": "I have an error as well since the update related to the json mode. I would like to keep `response_model=Mymodel`\nIf I remove it, it's working but I don't have control of the json output.\n\n```\nagno.exceptions.ModelProviderError: API error occurred: Status 400\n{\"object\":\"error\",\"message\":\"Cannot use j",
          "created_at": "2025-03-24T08:57:19Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @josephtrinh\nSo we now use structured output by default where it is supported. It turns out that Mistral does not like Pydantic models with optional fields. If you make all the fields required, then it is happy. \nI am working on a resolution to get around this limitation.",
          "created_at": "2025-03-24T14:32:06Z"
        },
        {
          "author": "josephtrinh",
          "body": "> Hi [@josephtrinh](https://github.com/josephtrinh) So we now use structured output by default where it is supported. It turns out that Mistral does not like Pydantic models with optional fields. If you make all the fields required, then it is happy. I am working on a resolution to get around this l",
          "created_at": "2025-03-25T03:46:40Z"
        },
        {
          "author": "dirkbrnd",
          "body": "This is just a limitation on Mistral's library that we can't get around I am afraid. We'll keep an eye out on how their support for this changes in the future.",
          "created_at": "2025-04-07T20:20:22Z"
        },
        {
          "author": "josephtrinh",
          "body": "@dirkbrnd\n\nI ended up using LiteLLM then loading Mistral through it. It's working well without any errors so far. \n\nmodel=LiteLLM(\n        id=\"mistral/mistral-small-latest\",\n        temperature=0.3,\n        top_p=0.3,\n        api_key=MISTRAL_API_KEY,\n    ),",
          "created_at": "2025-06-05T16:18:20Z"
        }
      ]
    },
    {
      "issue_number": 2607,
      "title": "[Bug]: Wrong Classifier on AgentMemory for Ollama",
      "body": "# Description\nI just try to run the memory example for Ollama. And it seems for me that despite Ollama is selected, still an OpenAI classifier for the AgentMemory is used.\n\nHere is the code (taken form https://github.com/agno-agi/agno/blob/main/cookbook/models/ollama/memory.py):\n\n```\n\"\"\"\nThis recipe shows how to use personalized memories and summaries in an agent.\nSteps:\n1. Run: `./cookbook/scripts/run_pgvector.sh` to start a postgres container with pgvector\n2. Run: `pip install ollama sqlalchemy 'psycopg[binary]' pgvector` to install the dependencies\n3. Run: `python cookbook/models/ollama/memory.py` to run the agent\n\"\"\"\n\nfrom agno.agent import Agent, AgentMemory\nfrom agno.memory.db.postgres import PgMemoryDb\nfrom agno.models.ollama.chat import Ollama\nfrom agno.storage.postgres import PostgresStorage\n\ndb_url = \"postgresql+psycopg://ai:ai@localhost:5532/ai\"\nagent = Agent(\n    model=Ollama(id=\"qwen2.5:latest\", host=\"192.168.178.250\"),\n    # Store the memories and summary in a database\n    memory=AgentMemory(\n        db=PgMemoryDb(table_name=\"agent_memory\", db_url=db_url),\n        create_user_memories=True,\n        create_session_summary=True,\n    ),\n    # Store agent sessions in a database\n    storage=PostgresStorage(table_name=\"personalized_agent_sessions\", db_url=db_url),\n    # Show debug logs so, you can see the memory being created\n    # debug_mode=True,\n)\n\n# -*- Share personal information\nagent.print_response(\"My name is john billings?\", stream=True)\n\n# -*- Share personal information\nagent.print_response(\"I live in nyc?\", stream=True)\n\n# -*- Share personal information\nagent.print_response(\"I'm going to a concert tomorrow?\", stream=True)\n\n# Ask about the conversation\nagent.print_response(\n    \"What have we been talking about, do you know my name?\", stream=True\n)\n```\n\n\n## Steps to Reproduce\nJust run the example:\n\n```\npython3 memory.py \nERROR    OPENAI_API_KEY not set. Please set the OPENAI_API_KEY environment variable.                                                                                      \nERROR    Error from OpenAI API: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable       \n▰▰▰▰▰▱▱ Thinking...\n┏━ Message ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                                                                                                                        ┃\n┃ My name is john billings?                                                                                                                                              ┃\n┃                                                                                                                                                                        ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n┏━ Response (3.5s) ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                                                                                                                        ┃\n┃ Hello John! Nice to meet you. Is there anything specific you would like to discuss or any questions you have?                                                          ┃\n┃                                                                                                                                                                        ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\nTraceback (most recent call last):\n  File \"/home/cd/_workspace/agno/venv/lib/python3.12/site-packages/agno/models/openai/chat.py\", line 322, in invoke\n    return self.get_client().chat.completions.create(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/cd/_workspace/agno/venv/lib/python3.12/site-packages/agno/models/openai/chat.py\", line 138, in get_client\n    self.client = OpenAIClient(**client_params)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cd/_workspace/agno/venv/lib/python3.12/site-packages/openai/_client.py\", line 114, in __init__\n    raise OpenAIError(\nopenai.OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/cd/_workspace/agno/memory.py\", line 30, in <module>\n    agent.print_response(\"My name is john billings?\", stream=True)\n  File \"/home/cd/_workspace/agno/venv/lib/python3.12/site-packages/agno/agent/agent.py\", line 3691, in print_response\n    for resp in self.run(\n                ^^^^^^^^^\n  File \"/home/cd/_workspace/agno/venv/lib/python3.12/site-packages/agno/agent/agent.py\", line 787, in _run\n    self.memory.update_memory(input=run_messages.user_message.get_content_string())\n  File \"/home/cd/_workspace/agno/venv/lib/python3.12/site-packages/agno/memory/agent.py\", line 288, in update_memory\n    should_update_memory = force or self.should_update_memory(input=input)\n                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cd/_workspace/agno/venv/lib/python3.12/site-packages/agno/memory/agent.py\", line 256, in should_update_memory\n    classifier_response = self.classifier.run(input)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cd/_workspace/agno/venv/lib/python3.12/site-packages/agno/memory/classifier.py\", line 79, in run\n    response = self.model.response(messages=messages_for_model)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cd/_workspace/agno/venv/lib/python3.12/site-packages/agno/models/base.py\", line 175, in response\n    assistant_message, has_tool_calls = self._process_model_response(\n                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cd/_workspace/agno/venv/lib/python3.12/site-packages/agno/models/base.py\", line 311, in _process_model_response\n    response = self.invoke(messages=messages)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cd/_workspace/agno/venv/lib/python3.12/site-packages/agno/models/openai/chat.py\", line 363, in invoke\n    raise ModelProviderError(message=str(e), model_name=self.name, model_id=self.id) from e\nagno.exceptions.ModelProviderError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n\n```",
      "state": "closed",
      "author": "schniggie",
      "author_type": "User",
      "created_at": "2025-03-29T16:47:34Z",
      "updated_at": "2025-06-05T07:51:43Z",
      "closed_at": "2025-04-18T00:32:19Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2607/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2607",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2607",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:02.590372",
      "comments": [
        {
          "author": "willemcdejongh",
          "body": "Hi @schniggie This is due to AgentMemory using OpenAI and OpenAILike models under the hood \nhttps://docs.agno.com/agents/memory#user-preferences-and-conversation-summaries\nWe are in the process of improving memory and we should have broader support for this in the very near future",
          "created_at": "2025-03-31T15:04:43Z"
        },
        {
          "author": "schniggie",
          "body": "I suggest to update the ollama example at https://github.com/agno-agi/agno/blob/main/cookbook/models/ollama/memory.py\n\nto:\n\n```\n\"\"\"\nThis recipe shows how to use personalized memories and summaries in an agent.\nSteps:\n1. Run: `./cookbook/scripts/run_pgvector.sh` to start a postgres container with pgv",
          "created_at": "2025-04-03T19:03:57Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-18T00:32:18Z"
        },
        {
          "author": "pauldesmondparker",
          "body": "Simplified in Agno 1.5.6:\n```python\n            memory_with_model = Memory(\n                model=Ollama(id=\"llama3.2\", host=\"127.0.0.1\"),\n                db=SqliteMemoryDb(\n                    db_file=str(sql_db_path_user_memories),\n                    table_name=\"user_memory\",\n                ),\n ",
          "created_at": "2025-06-05T07:50:58Z"
        }
      ]
    },
    {
      "issue_number": 3250,
      "title": "[Bug] Knowledgebase always returns wrong page number",
      "body": "### Description\n\nI have created a teams of agent were one of the sub agent has access to knowledgebase. While retrieving the data from Knowledgebase, its always returning last page number of the documen as the page number of result meta_data.\n\nBelow is my knowledge declaration \n\npdf_knowledge_base=  PDFKnowledgeBase(\npath=Path(r\"Docs\"),\nvector_db=LanceDb(\nuri=\"vectordb\",\ntable_name=\"policy_data\", search_type=SearchType.hybrid, \nembedder=azure_embedding_model\n),\n)\n\nIt's fetching the contents properly, only page no is coming wrong. \n\n### Steps to Reproduce\n\nGive a doc related query to agent\nAgent will fetch the records from Knowledgebase with wrong page number \n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nPage no should be the actual page no from where result was fetched 4\n\n### Actual Behavior\n\nGiving last page no of the pdf for every search meta data\n\n### Screenshots or Logs (if applicable)\n\n![Image](https://github.com/user-attachments/assets/7812f245-b998-4b1a-9646-e5f81cf6924a)\n\n### Environment\n\n```markdown\nWindows 11\nPython 3.12\nAgno 1.5.1\nlancedb 0.22.0\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "AkhilmsAchu",
      "author_type": "User",
      "created_at": "2025-05-20T05:45:35Z",
      "updated_at": "2025-06-05T06:33:49Z",
      "closed_at": "2025-06-05T06:33:48Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3250/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3250",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3250",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:02.827760",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-222/bug-knowledgebase-always-returns-wrong-page-number\">SUPPORT-222 [Bug] Knowledgebase always returns wrong page number</a></p>",
          "created_at": "2025-05-20T05:45:39Z"
        },
        {
          "author": "kausmeows",
          "body": "This is fixed here- https://github.com/agno-agi/agno/pull/3363",
          "created_at": "2025-06-05T06:33:48Z"
        }
      ]
    },
    {
      "issue_number": 3438,
      "title": "[Bug] MCP Compatibility Issue mcp.client.streamable_http",
      "body": "### Description\n\nThe `agno.tools.mcp` module is incompatible with the current version of the `mcp` package (0.9.1), causing import errors when trying to use MCPTools in agents. This prevents the FastAPI application from starting when using Docker. for information the MCP package is properly installed and listed in requirements.txt\n\nModuleNotFoundError: No module named 'mcp.client.streamable_http'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/app/api/main.py\", line 13, in <module>\n    from api.routes.v1_router import v1_router\n  File \"/app/api/routes/v1_router.py\", line 4, in <module>\n    from api.routes.playground import playground_router\n  File \"/app/api/routes/playground.py\", line 17, in <module>\n    from agents.hoax import fact_checker_agent\n  File \"/app/agents/hoax.py\", line 9, in <module>\n    from agno.tools.mcp import MCPTools\n  File \"/usr/local/lib/python3.12/site-packages/agno/tools/mcp.py\", line 19, in <module>\n    raise ImportError(\"`mcp` not installed. Please install using `pip install mcp`\")\nImportError: `mcp` not installed. Please install using `pip install mcp`\n```\n\n### Steps to Reproduce\n\n1. **Clone the repository**\n   ```bash\n   git clone https://github.com/agno-agi/agno-demo-app.git\n   cd agno-demo-app\n   ```\n\n2. **Build Docker image**\n   ```bash\n   docker build -t agno-api:dev .\n   ```\n\n3. **Run the container**\n   ```bash\n   docker run -p 8000:8000 agno-api:dev\n   ```\n\n1. Install agno==1.5.6 and mcp==0.9.1\n2. Try to import: `from agno.tools.mcp import MCPTools`\n3. The import fails with the above error\n\n### Agent Configuration (if applicable)\n\n```python\n  from agno.tools.mcp import MCPTools\n from mcp import StdioServerParameters\n\ntools=[\n    GoogleSearchTools(), \n    Newspaper4kTools(),\n     MCPTools(\n         server_params=StdioServerParameters(\n             command=\"npx\",\n             args=[\"-y\", \"@modelcontextprotocol/server-sequential-thinking\"]\n         )\n     )\n]\n```\n\n### Expected Behavior\n\n- **Expected**: FastAPI application starts successfully and serves on port 8000\n\n\n### Actual Behavior\n\n- **Actual**: Application crashes with MCP import error\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nagno==1.5.6 and mcp==0.9.1\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "isikepalaku",
      "author_type": "User",
      "created_at": "2025-06-01T07:34:02Z",
      "updated_at": "2025-06-03T16:49:26Z",
      "closed_at": "2025-06-03T16:49:26Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3438/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3438",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3438",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:04.811925",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-357/bug-mcp-compatibility-issue-mcpclientstreamable-http\">SUPPORT-357 [Bug] MCP Compatibility Issue mcp.client.streamable_http</a></p>",
          "created_at": "2025-06-01T07:34:04Z"
        },
        {
          "author": "manuhortet",
          "body": "Hey @isikepalaku! \n\nThe current version of the `mcp` library seems to be`1.9.2 ` - upgrading to that version will probably solve this issue. \n\nIf you get to try, please let me know how it goes! I'm happy to help further if you need me.",
          "created_at": "2025-06-03T07:52:53Z"
        }
      ]
    },
    {
      "issue_number": 2115,
      "title": "[Feature Request] Deep Research",
      "body": "Hi there\nExcited to try alto out :)\n\nWas wondering if you're planning on make a deep research pipeline\n\nPlenty of opensource implementions are starting to pop out. I would love for several pipelines\nFor example how deepseek does it 30-50 search results + thinking \nAnd openai style where does deep research until it is satisfied it compiled everything it needs \nAnd maybe other styles\n\nThanks a lot and all the best!",
      "state": "closed",
      "author": "fire17",
      "author_type": "User",
      "created_at": "2025-02-13T22:49:36Z",
      "updated_at": "2025-06-02T09:32:03Z",
      "closed_at": "2025-03-08T08:20:45Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2115/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2115",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2115",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:05.046054",
      "comments": [
        {
          "author": "pritipsingh",
          "body": "Hey @fire17 thats a great request! Would love for you to elaborate more on it. This is something easily achievable via our workflows concept. Is this something you’re looking for in playground front end or something we can improve on the sdk? ",
          "created_at": "2025-02-14T07:18:30Z"
        },
        {
          "author": "samyogdhital",
          "body": "@pritipsingh My recommendation here is we go completely open-source route.\n\n### Precise User query understanding\n- Master agent is given detailed prompt by the user.\n- Master agent first analyzes the query itself, asks user 3-5 follow-up questions to precisely understand how broad and depth user wan",
          "created_at": "2025-02-14T14:22:57Z"
        },
        {
          "author": "pritipsingh",
          "body": "Hey @samyogdhital, thank you for such a detailed response - we really appreciate it! \n\nThis is easily achievable with the concept of workflows introduced by Agno. Workflows are deterministic, stateful, multi-agent programs that give you full control over the process, including how the input is handl",
          "created_at": "2025-02-17T06:49:05Z"
        },
        {
          "author": "manthanguptaa",
          "body": "Hey @samyogdhital! We have added SearXNG tool and you can check it out here https://docs.agno.com/tools/toolkits/searxng",
          "created_at": "2025-03-08T08:20:45Z"
        },
        {
          "author": "ovyan",
          "body": "Updated link https://docs.agno.com/tools/toolkits/search/searxng",
          "created_at": "2025-06-02T09:32:02Z"
        }
      ]
    },
    {
      "issue_number": 3440,
      "title": "[Bug] DeepSeek R1 Agent reasoning_content Missing and Streaming Response Handling Issue",
      "body": "### Description\n\nWhen integrating DeepSeek R1 as an agent in agno, the model’s response contains a reasoning_content field, but this field is missing in the agent’s RunResponse, causing the frontend to fail to display the “thinking” content. Additionally, in streaming (stream mode) responses, the handling logic for reasoning_content is incomplete, which may result in missing or discontinuous content.\n\n### Steps to Reproduce\n\n1. Start agno and configure DeepSeek R1 as the agent model.\n2. Initiate an agent conversation request (e.g., input \"hello\").\n3. Observe the backend logs and the frontend page.\n4. The logs show that the model response contains reasoning_content, but it is None in the RunResponse, and the frontend does not display any thinking content.\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\n1. The RunResponse should correctly include and pass the reasoning_content field.\n2. The frontend should display the agent’s thinking content as expected.\n3. In streaming responses, reasoning_content should be fully accumulated and displayed.\n\n### Actual Behavior\n\n1. The reasoning_content field in RunResponse is None.\n2. The frontend cannot display the agent’s thinking content.\n3. In streaming responses, reasoning_content is not handled properly and content is lost.\n\n### Screenshots or Logs (if applicable)\n\n```log\ndata: {\"choices\":[{\"delta\":{\"content\":\"\",\"reasoning_content\":\"OK\",\"role\":\"assistant\"},\"index\":0}]}\ndata: {\"choices\":[{\"delta\":{\"content\":\"\",\"reasoning_content\":\",\",\"role\":\"assistant\"},\"index\":0}]}\ndata: {\"choices\":[{\"delta\":{\"content\":\"\",\"reasoning_content\":\"user\",\"role\":\"assistant\"},\"index\":0}]}\n...\ndata: {\"choices\":[{\"delta\":{\"content\":\"\\n\\n\",\"role\":\"assistant\"},\"index\":0}]}\n...\nRunResponse(content='', content_type='str', thinking=None, reasoning_content=None, event='RunResponse' ...)\nRunResponse(content='', content_type='str', thinking=None, reasoning_content=None, event='RunResponse' ...)\nRunResponse(content='', content_type='str', thinking=None, reasoning_content=None, event='RunResponse' ...)\n...\nRunResponse(content='Hello', content_type='str', thinking=None, reasoning_content=None, event='RunResponse' ...)\n```\n\n### Environment\n\n```markdown\nOS: macOS Sonoma 14.5 (darwin 24.5.0)\nBrowser: [e.g., Chrome 120]\nAgno Version: [please fill in the actual version]\nExternal Dependency Versions: deepseek-r1-250120\nPython: 3.11.5\nRelevant agent initialization code:\n\nsuper().__init__(\n    model=deepseek_R1,\n    name=self.name,\n    role=self.role,\n    tools=[get_now_iso],  # Tools not set at initialization\n    debug_mode=True\n)\n```\n\n### Possible Solutions (optional)\n\n1. Check and fix the RunResponse construction logic to ensure reasoning_content is correctly parsed and passed.\n2. Improve the streaming response handling logic to support accumulation and display of reasoning_content.\n3. Add more detailed logs for response handling to facilitate troubleshooting.\n\n### Additional Context\n\n3. There is redundant /openai/v1 in the URL concatenation; it is recommended to use the correct API endpoint directly.\n2. The agent is initialized with response_model=None; this should be completed.\n1. The tool list initialization logic should be unified.",
      "state": "open",
      "author": "zhuayi",
      "author_type": "User",
      "created_at": "2025-06-01T19:20:49Z",
      "updated_at": "2025-06-01T20:04:28Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3440/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3440",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3440",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:05.339132",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-358/bug-deepseek-r1-agent-reasoning-content-missing-and-streaming-response\">SUPPORT-358 [Bug] DeepSeek R1 Agent reasoning_content Missing and Streaming Response Handling Issue</a></p>",
          "created_at": "2025-06-01T19:20:52Z"
        }
      ]
    },
    {
      "issue_number": 3425,
      "title": "[Feature Request]  Make `infer` parameter configurable in Mem0Tools",
      "body": "### Problem Description\n\nCurrently, the `add_memory` method in `Mem0Tools` doesn't allow users to control the `infer` parameter when adding memories through the Mem0 client. This parameter is important as it determines whether the AI can decide to add information to the memory database or not.\n\n## Use Case\nWhen using Mem0 as a memory database for security information and guardrails, it's critical that all specified information is stored without the AI deciding what's important. The original Mem0AI library allows this control, and Agno's implementation should maintain this flexibility.\n\n## Benefits\n- Gives users more control over memory storage behavior\n- Aligns with the original Mem0AI library's functionality\n- Enables more reliable memory storage for critical applications like security guardrails\n\n## Additional Context\nThis is particularly important for applications where the memory database is used for security monitoring, compliance, or other scenarios where complete information storage is required.\n\n### Proposed Solution\n\nAllow users to configure the `infer` parameter through:\n1. A parameter in the `add_memory` method\n2. A configuration option during Mem0Tools initialization\n\n\n### Alternatives Considered\n\nIn the current implementation in `agno/tools/mem0.py`, in `add_memory` function:\n\n```python\ndef add_memory(self, agent: Agent, content: Union[str, Dict[str, str]]) -> str:\n    # ...\n    result = self.client.add(\n        messages_list,\n        user_id=resolved_user_id,\n        infer=False,  # Hardcoded to False\n    )\n    # ...\n```\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [x] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "moiraphill",
      "author_type": "User",
      "created_at": "2025-05-30T14:47:05Z",
      "updated_at": "2025-05-31T14:14:25Z",
      "closed_at": "2025-05-31T14:14:25Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3425/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3425",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3425",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:10.536156",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-350/feature-request-make-infer-parameter-configurable-in-mem0tools\">SUPPORT-350 [Feature Request] Make `infer` parameter configurable in Mem0Tools</a></p>",
          "created_at": "2025-05-30T14:47:07Z"
        }
      ]
    },
    {
      "issue_number": 3384,
      "title": "[Bug] PgVector Knowledge Filtering Issues: Wrong Column Search and Tool Filter Validation",
      "body": "### Description\n\n**Apologies in advance if I have some fundamental misunderstanding of how this is supposed to work.**\n\nWe're experiencing issues with knowledge filtering in Agno agents when using custom filters with PgVector. Our `knowledge_filters` parameter doesn't seem to be working as expected for visibility controls (e.g., filtering documents by `visibility: \"internal-only\"` vs `\"customer-facing\"`).\n\nAfter investigating, we've identified what appear to be two potential issues, though I'm unsure whether these represent bugs or incorrect usage on our part:\n\n1. **Database column mismatch**: PgVector appears to search the `meta_data` column for filters, but our visibility data is stored in the `filters` column (which may be intentional design)\n\n2. **Filter validation restrictions**: The built-in `asearch_knowledge_base` tool seems to reject custom filters, only accepting hardcoded values like `url`, `chunk`, `page`, `chunk_size`\n\nThis breaks knowledge visibility controls and security filtering, but I'm uncertain whether:\n- We're using the wrong API/parameter for our use case\n- There's a bug in how `knowledge_filters` queries the database  \n- We need to use a different approach for filtering\n\nI'd appreciate clarification on the intended usage pattern for filtering documents by custom fields like `visibility` when using `knowledge_filters`. If this is user error rather than a bug, I apologize for the confusion and would welcome guidance on the correct implementation approach.\n\n\n### Steps to Reproduce\n\nCreate documents with filters using `knowledge_base.load_documents()`:\n\n```python\n# Example from our knowledge_source.py implementation\nagno_filters = {\n    \"visibility\": \"internal-only\",  # or \"customer-facing\", \"both\"\n}\n\nknowledge_base.load_documents(\n    documents=all_documents,\n    upsert=True,\n    skip_existing=False,\n    filters=agno_filters,\n)\n```\n\n### Issue 1: PgVector Column Mismatch\n\n1. Create documents with filters using `knowledge_base.load_documents()`:\n```python\nknowledge_base.load_documents(\n    documents=[doc], \n    filters={\"visibility\": \"internal-only\"}\n)\n```\n\n2. Search with filters:\n```python\ndocuments = knowledge_base.search(\n    query=\"test\", \n    filters={\"visibility\": [\"customer-facing\", \"both\"]}\n)\n```\n\n3. Check database - filters stored in `filters` column, but PgVector searches `meta_data` column\n\n### Issue 2: Tool Filter Validation\n\n1. Initialize Agent with knowledge_filters:\n```python\nagent = Agent(\n    knowledge=knowledge_base,\n    knowledge_filters={\"visibility\": [\"customer-facing\", \"both\"]},\n    search_knowledge=True\n)\n```\n\n2. Agent automatically adds `asearch_knowledge_base` tool\n3. Tool rejects visibility filters with error:\n```\nInvalid filter key: visibility - not present in knowledge base\nValid filter keys are: {'url', 'chunk_size', 'chunk', 'page'}\n```\n\n### Agent Configuration (if applicable)\n\n```py\nknowledge_base = AgentKnowledge(\n    vector_db=PgVector(\n        table_name=\"knowledge_table\",\n        db_engine=engine,\n        search_type=SearchType.hybrid\n    )\n)\n\nagent = Agent(\n    knowledge=knowledge_base,\n    knowledge_filters={\"visibility\": [\"customer-facing\", \"both\"]},\n    search_knowledge=True  # Enables asearch_knowledge_base tool\n)\n```\n\n### Expected Behavior\n\n1. **PgVector should filter on `filters` column** where filter data is actually stored\n2. **`asearch_knowledge_base` tool should accept custom filters** passed via `knowledge_filters`\n3. **Filtered search should return only documents matching filter criteria**\n\n\n### Actual Behavior\n\n1. **PgVector filters on `meta_data` column** (wrong column) - returns unfiltered results\n2. **Tool validation rejects custom filters** - proceeds with empty filters `{}`\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n- OS: Linux (Docker container)\n- Browser: N/A (Backend API)\n- Agno Version: 1.5.5\n- External Dependencies: PostgreSQL, PgVector extension\n```\n\n### Possible Solutions (optional)\n\n### Solution 1: Fix PgVector Column Search\nUpdate PgVector to search the correct `filters` column:\n```python\n# In PgVector.search() method\n# Current (wrong):\nstmt = stmt.where(self.table.c.meta_data.contains(filters))\n\n# Should be:\nstmt = stmt.where(self.table.c.filters.contains(filters))\n```\n\n### Solution 2: Make Tool Filter Validation Configurable\nAllow custom filter keys in `asearch_knowledge_base` tool:\n```python\n# Accept knowledge_filters from agent\ndef validate_filters(self, filters):\n    # Don't hardcode valid keys - accept agent's knowledge_filters\n    return filters  # or make validation configurable\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "jesalg",
      "author_type": "User",
      "created_at": "2025-05-28T04:28:26Z",
      "updated_at": "2025-05-31T03:16:34Z",
      "closed_at": "2025-05-29T03:42:36Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3384/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3384",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3384",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:10.705843",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-331/bug-pgvector-knowledge-filtering-issues-wrong-column-search-and-tool\">SUPPORT-331 [Bug] PgVector Knowledge Filtering Issues: Wrong Column Search and Tool Filter Validation</a></p>",
          "created_at": "2025-05-28T04:28:30Z"
        },
        {
          "author": "kausmeows",
          "body": "Hi @jesalg a few things here-\n- its an oversight from our side on the upsert implementation, fixed here- https://github.com/agno-agi/agno/pull/3401, should be available with the next release.\n\n- I noticed you are also doing a few things with incorrect params.\n```\nknowledge_base.load_documents(\n    d",
          "created_at": "2025-05-28T22:49:02Z"
        },
        {
          "author": "jesalg",
          "body": "@kausmeows Thank you! I will give that a shot. The `filters` parameter in `load_documents` tripped me up",
          "created_at": "2025-05-29T02:05:21Z"
        },
        {
          "author": "jesalg",
          "body": "I was still running into an issue where this is not working, but then I realized it looks like filters are not passed into traditional RAG (https://github.com/agno-agi/agno/pull/3421), which is what was introducing an extra layer of unexpected behavior. I'll wait for that fix to go out.",
          "created_at": "2025-05-31T03:13:47Z"
        },
        {
          "author": "kausmeows",
          "body": "> I was still running into an issue where this is not working, but then I realized it looks like filters are not passed into traditional RAG ([#3421](https://github.com/agno-agi/agno/pull/3421)), which is what was introducing an extra layer of unexpected behavior. I'll wait for that fix to go out.\n\n",
          "created_at": "2025-05-31T03:16:32Z"
        }
      ]
    },
    {
      "issue_number": 3273,
      "title": "[Bug] Security Enhancement",
      "body": "### Description\n\nDon't log any secret env with OTEL\n\n### Steps to Reproduce\n\n1. Log anything into Monitor Service\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\n![Image](https://github.com/user-attachments/assets/3fbbfd8f-b0d4-4cd6-8050-2ba4f2eb0dc3)\n\n### Actual Behavior\n\nHidden or mask sensitive data like secrets\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nagno==1.5.2\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "anhphong22",
      "author_type": "User",
      "created_at": "2025-05-21T09:53:55Z",
      "updated_at": "2025-05-30T23:27:11Z",
      "closed_at": "2025-05-30T23:27:10Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3273/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3273",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3273",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:10.904773",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-249/bug-security-enhancement\">SUPPORT-249 [Bug] Security Enhancement</a></p>",
          "created_at": "2025-05-21T09:53:58Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Very valid request! We will fix",
          "created_at": "2025-05-30T15:38:38Z"
        },
        {
          "author": "kausmeows",
          "body": "This is fixed here- https://github.com/Arize-ai/openinference/pull/1737\n\nThanks for raising!",
          "created_at": "2025-05-30T23:27:10Z"
        }
      ]
    },
    {
      "issue_number": 3423,
      "title": "[Bug] SearXNG tools usage example in website isn't valid",
      "body": "### Description\n\nWhen trying to use the searxng tool, we have to import it as `from agno.tools.searxng import Searxng` but then on the website, it is imported as `from agno.tools.searxng import SearxNGTools`. There is no exported class `SearxNGTools` and going through the code for it we see it's class is Searxng https://github.com/agno-agi/agno/blob/498351cbbce5933edfd4666c568e18b1f9a79809/libs/agno/agno/tools/searxng.py#L11-L47, we can clearly see it's defined as `Searxng`\n\n### Steps to Reproduce\n\n1. Go to https://docs.agno.com/examples/concepts/tools/search/searxng\n2. See the example in the codeblock\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nShould rather import from `from agno.tools.searxng import Searxng` or have the tool name be updated.\n\n### Actual Behavior\n\nImports as `from agno.tools.searxng import SearxNGTools`\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n- OS: Macos Sonoma\n- Browser: Chrome\n```\n\n### Possible Solutions (optional)\n\nUpdating the docs to suite the expected import statement.\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "AmoabaKelvin",
      "author_type": "User",
      "created_at": "2025-05-30T12:12:13Z",
      "updated_at": "2025-05-30T18:47:33Z",
      "closed_at": "2025-05-30T14:17:31Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3423/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3423",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3423",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:11.209312",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-349/bug-searxng-tools-usage-example-in-website-isnt-valid\">SUPPORT-349 [Bug] SearXNG tools usage example in website isn't valid</a></p>",
          "created_at": "2025-05-30T12:12:15Z"
        },
        {
          "author": "AmoabaKelvin",
          "body": "Also, it does not correctly import Toolkit. It imports from `from agno.tools.toolkit import Toolkit` rather than `from agno.tools import Toolkit` just like the other tools, hence it fails to correctly register the tools with `include_tools`. Opening a PR to fix this",
          "created_at": "2025-05-30T12:37:02Z"
        },
        {
          "author": "ysolanky",
          "body": "Thanks for your contribution! ",
          "created_at": "2025-05-30T14:17:31Z"
        },
        {
          "author": "anuragshas",
          "body": "> Also, it does not correctly import Toolkit. It imports from `from agno.tools.toolkit import Toolkit` rather than `from agno.tools import Toolkit` just like the other tools, hence it fails to correctly register the tools with `include_tools`. Opening a PR to fix this\n\nI had fixed this issue in the ",
          "created_at": "2025-05-30T18:47:32Z"
        }
      ]
    },
    {
      "issue_number": 3336,
      "title": "[Bug] Wren-MCP -- Error when interacting with Wren-MCP for snowflake",
      "body": "### Description\n\nWren MCP Snowflake Agent is ready! Type your request (type 'exit' to quit).\n\nEnter your data analysis request: how many tables we have\n\nProcessing your request...\n\nERROR    Failed to call MCP tool 'list_remote_tables': Timed out while waiting for response to   \n         ClientRequest. Waited 5.0 seconds.                                                      \n         Traceback (most recent call last):                                                      \n           File                                                                                  \n         \"/opt/anaconda3/envs/wren-mcp/lib/python3.10/site-packages/anyio/streams/memory.py\",    \n         line 111, in receive                                                                    \n             return self.receive_nowait()                                                        \n           File                                                                                  \n         \"/opt/anaconda3/envs/wren-mcp/lib/python3.10/site-packages/anyio/streams/memory.py\",    \n         line 106, in receive_nowait                                                             \n             raise WouldBlock                                                                    \n         anyio.WouldBlock                                                                        \n                                                                                                 \n         During handling of the above exception, another exception occurred:                     \n                                                                                                 \n         Traceback (most recent call last):                                                      \n           File                                                                                  \n         \"/opt/anaconda3/envs/wren-mcp/lib/python3.10/site-packages/anyio/_core/_tasks.py\", line \n         115, in fail_after                                                                      \n             yield cancel_scope                                                                  \n           File                                                                                  \n         \"/opt/anaconda3/envs/wren-mcp/lib/python3.10/site-packages/mcp/shared/session.py\", line \n         280, in send_request                                                                    \n             response_or_error = await response_stream_reader.receive()                          \n           File                                                                                  \n         \"/opt/anaconda3/envs/wren-mcp/lib/python3.10/site-packages/anyio/streams/memory.py\",    \n         line 119, in receive                                                                    \n             await receive_event.wait()                                                          \n           File \"/opt/anaconda3/envs/wren-mcp/lib/python3.10/asyncio/locks.py\", line 214, in wait\n             await fut                                                                           \n         asyncio.exceptions.CancelledError: Cancelled by cancel scope 10b25aa40                  \n                                                                                                 \n         During handling of the above exception, another exception occurred:                     \n                                                                                                 \n         Traceback (most recent call last):                                                      \n           File                                                                                  \n         \"/opt/anaconda3/envs/wren-mcp/lib/python3.10/site-packages/mcp/shared/session.py\", line \n         279, in send_request                                                                    \n             with anyio.fail_after(timeout):                                                     \n           File \"/opt/anaconda3/envs/wren-mcp/lib/python3.10/contextlib.py\", line 153, in        \n         __exit__                                                                                \n             self.gen.throw(typ, value, traceback)                                               \n           File                                                                                  \n         \"/opt/anaconda3/envs/wren-mcp/lib/python3.10/site-packages/anyio/_core/_tasks.py\", line \n         118, in fail_after                                                                      \n             raise TimeoutError                                                                  \n         TimeoutError                                                                            \n                                                                                                 \n         During handling of the above exception, another exception occurred:                     \n                                                                                                 \n         Traceback (most recent call last):                                                      \n           File \"/opt/anaconda3/envs/wren-mcp/lib/python3.10/site-packages/agno/utils/mcp.py\",   \n         line 33, in call_tool                                                                   \n             result: CallToolResult = await session.call_tool(tool_name, kwargs)  # type: ignore \n           File                                                                                  \n         \"/opt/anaconda3/envs/wren-mcp/lib/python3.10/site-packages/mcp/client/session.py\", line \n         277, in call_tool                                                                       \n             return await self.send_request(                                                     \n           File                                                                                  \n         \"/opt/anaconda3/envs/wren-mcp/lib/python3.10/site-packages/mcp/shared/session.py\", line \n         282, in send_request                                                                    \n             raise McpError(                                                                     \n         mcp.shared.exceptions.McpError: Timed out while waiting for response to ClientRequest.  \n         Waited 5.0 seconds.                                                                     \n┏━ Message ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                                               ┃\n┃ how many tables we have                                                                       ┃\n┃                                                                                               ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n┏━ Response (12.5s) ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                                               ┃\n┃ It seems there was a timeout error when attempting to retrieve the list of tables. Let's try  ┃\n┃ again.There are 8 tables available in the Snowflake database. Here is the list of tables:     ┃\n┃                                                                                               ┃\n┃  1 TPCH_SF1.PARTSUPP: Partsupp data as defined by TPC-H.                                      ┃\n┃  2 TPCH_SF1.SUPPLIER: Supplier data as defined by TPC-H.                                      ┃\n┃  3 TPCH_SF1.CUSTOMER: Customer data as defined by TPC-H.                                      ┃\n┃  4 TPCH_SF1.PART: Part data as defined by TPC-H.                                              ┃\n┃  5 TPCH_SF1.ORDERS: Orders data as defined by TPC-H.                                          ┃\n┃  6 TPCH_SF1.LINEITEM: Lineitem data as defined by TPC-H.                                      ┃\n┃  7 TPCH_SF1.NATION: Nation data as defined by TPC-H.                                          ┃\n┃  8 TPCH_SF1.REGION: Region data as defined by TPC-H.                                          ┃\n┃                                                                                               ┃\n┃ If you need more detailed information about any of these tables or require specific analysis, ┃\n┃ feel free to ask!                                                                             ┃\n┃                                                                                               ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n\nReady for another request.\nEnter your data analysis request: give top 10 rows from NATION\n\nProcessing your request...\n\n┏━ Message ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                                               ┃\n┃ give top 10 rows from NATION                                                                  ┃\n┃                                                                                               ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n┏━ Tool Calls ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                                               ┃\n┃ • query(sql=SELECT * FROM TPCH_SF1.NATION LIMIT 10;)                                          ┃\n┃ • dry_run(sql=SELECT * FROM TPCH_SF1.NATION LIMIT 10;)                                        ┃\n┃ • query(sql=SELECT * FROM TPCH_SF1.NATION LIMIT 10;)                                          ┃\n┃                                                                                               ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n┏━ Response (9.5s) ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                                               ┃\n┃ It seems there was an internal error while attempting to query the NATION table. I'll         ┃\n┃ investigate the issue further to ensure the query runs correctly. Let's try this again.I      ┃\n┃ encountered the same internal error while trying to execute the query. This issue seems to be ┃\n┃ related to the system's ability to process the query request. I recommend checking the        ┃\n┃ connectivity with the Snowflake database or trying again later. If this issue persists,       ┃\n┃ please contact your technical support team for further assistance.   \n\n### Steps to Reproduce\n\n1.Spin up wre-MCP server https://github.com/Canner/wren-engine/tree/main/mcp-server\n2.create a data analyst agent and use wren mcp \n\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nseamless interaction with Wren MCP \n\n### Actual Behavior\n\nTime out error and not able to execute query\n\n### Screenshots or Logs (if applicable)\n\nagno (1.5.4)\n\nimport os\nimport asyncio\nfrom dotenv import load_dotenv\nfrom agno.agent import Agent\nfrom agno.models.openai import OpenAIChat\nfrom agno.tools.mcp import MCPTools\n\n# Load environment variables from .env\nload_dotenv()\n\n# Check for OpenAI API key\nopenai_api_key = os.environ.get(\"OPENAI_API_KEY\")\nif not openai_api_key:\n    raise ValueError(\"OPENAI_API_KEY environment variable not set. Please set it before running.\")\n\n# Set the MCP server command with correct working directory\nmcp_server_command = \"uv run app/wren.py\"\n\nasync def main():\n    print(\"\\nWren MCP Snowflake Agent is ready! Type your request (type 'exit' to quit).\\n\")\n    async with MCPTools(mcp_server_command) as mcp_tools:\n        agent = Agent(\n            name=\"Wren SQL Agent\",\n            role=\"You are a Data Analyst who specializes in analyzing Snowflake data using SQL. You have access to a Snowflake database through Wren Engine MCP. You can list tables, describe table structures, and execute SQL queries.\",\n            model=OpenAIChat(id=\"gpt-4o\"),\n            tools=[mcp_tools],\n            instructions=[\n                \"Use the Wren MCP tools to interact with the Snowflake database.\",\n                \"Start by listing available tables or models using the tables or listModels tool.\",\n                \"When asked to query data, first understand the schema using tableStructure or listModels.\",\n                \"Generate appropriate SQL queries based on the user's natural language request.\",\n                \"Execute queries using MCP tools\",\n                \"Present results in a clear, well-formatted manner with explanations when needed.\",\n                \"Always validate your queries for syntax and logic errors before execution.\"\n            ],\n            show_tool_calls=True,\n            markdown=True,\n        )\n        while True:\n            user_query = input(\"Enter your data analysis request: \")\n            if user_query.lower() in [\"exit\", \"quit\", \"q\"]:\n                print(\"\\nExiting Wren MCP Agent. Goodbye!\")\n                break\n            print(\"\\nProcessing your request...\\n\")\n            try:\n                await agent.aprint_response(user_query, stream=True)\n            except Exception as e:\n                print(f\"\\nError processing request: {e}\")\n            print(\"\\nReady for another request.\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n\n\n### Environment\n\n```markdown\nagno                       1.5.4\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "manjukampali1",
      "author_type": "User",
      "created_at": "2025-05-24T06:34:55Z",
      "updated_at": "2025-05-30T08:27:30Z",
      "closed_at": "2025-05-30T08:27:30Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3336/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3336",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3336",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:11.533376",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-298/bug-wren-mcp-error-when-interacting-with-wren-mcp-for-snowflake\">SUPPORT-298 [Bug] Wren-MCP -- Error when interacting with Wren-MCP for snowflake</a></p>",
          "created_at": "2025-05-24T06:34:57Z"
        },
        {
          "author": "manjukampali1",
          "body": "mdl file for snowflake trial account \n\n{\n  \"dataSource\": \"snowflake\",\n  \"catalog\": \"SNOWFLAKE_SAMPLE_DATA\",\n  \"schema\": \"TPCH_SF1\",\n  \"models\": [\n    {\n      \"name\": \"Customer\",\n      \"tableReference\": {\n        \"table\": \"CUSTOMER\"\n      },\n      \"columns\": [\n        {\"name\": \"custkey\", \"expression\"",
          "created_at": "2025-05-24T06:39:26Z"
        },
        {
          "author": "manuhortet",
          "body": "Hey @manjukampali1, have you tried setting a higher timeout value? It is valid that the MCP server takes more than the default 5 seconds to respond. You can try:\n\n```python\nasync with MCPTools(mcp_server_command, timeout_seconds=30) as mcp_tools:\n    ...\n```\n\nIf this doesn't work, let me know so I d",
          "created_at": "2025-05-26T12:50:13Z"
        },
        {
          "author": "Mak8823",
          "body": "yes , tried with 30 sec too . not helped ",
          "created_at": "2025-05-26T14:25:44Z"
        },
        {
          "author": "manuhortet",
          "body": "It seems the connections between Agno and the Wren MCP server happen successfully. \nThis seems to be a problem between the Wren MCP server and the Snowflake data source you are trying to use.\n\nI see you opened an issue on the Wren repository too. Maybe they can give us more insights on what is faili",
          "created_at": "2025-05-30T08:25:51Z"
        }
      ]
    },
    {
      "issue_number": 2752,
      "title": "Browser use support on agno?",
      "body": "Can we support [browser use](https://github.com/browser-use/browser-use) in agno?\nSuch that we are able to do browser automation to the existing browser.",
      "state": "closed",
      "author": "samyogdhital",
      "author_type": "User",
      "created_at": "2025-04-10T03:07:03Z",
      "updated_at": "2025-05-30T04:32:35Z",
      "closed_at": "2025-05-06T17:59:31Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2752/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2752",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2752",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:11.892317",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hey @samyogdhital thank you for reaching out and sharing your request with us\nAdding this to our community wishlist.\n\nin the meantime, we do have integration with broswerbase https://docs.agno.com/tools/toolkits/browserbase\nyou can use it to build browser automating agents",
          "created_at": "2025-04-10T06:25:55Z"
        },
        {
          "author": "rpvitrux",
          "body": "You can use Microsoft Playwright MCP: [playwright-mcp](https://github.com/microsoft/playwright-mcp)\n\nHere's an example:\n```python\nimport asyncio\nimport os\n\nfrom agno.agent import Agent\nfrom agno.models.anthropic import Claude\nfrom agno.tools.mcp import MCPTools\n\nfrom mcp import StdioServerParameters",
          "created_at": "2025-04-10T12:45:05Z"
        },
        {
          "author": "kausmeows",
          "body": "Hi @samyogdhital, `browseruse` is on the community wish list and we’ll get to it soon. Meanwhile if it’s helpful we do have `browserbase` support. See here- https://docs.agno.com/tools/toolkits/browserbase\n\nThis could also be useful for browser automation, taking ss of webpage, filling forms, etc.",
          "created_at": "2025-04-10T22:03:59Z"
        },
        {
          "author": "reynoldw",
          "body": "Can I create custom tool for browser-use or other functions? ",
          "created_at": "2025-04-15T16:59:40Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @reynoldw \nYes, you absolutely can.\nPls refer: https://docs.agno.com/tools/tools, they will help you get started\n",
          "created_at": "2025-04-23T08:14:41Z"
        }
      ]
    },
    {
      "issue_number": 3416,
      "title": "[Feature Request] Brave Search API in Search toolkit",
      "body": "### Problem Description\n\nWhen implementing agents, as an engineer who used [Brave's Search API](https://api-dashboard.search.brave.com/app/documentation/web-search/get-started) within `open-webui` as search tool for `ollama` models, I would like to use the same Search API within `agno`.\n\n### Proposed Solution\n\nExtend the `Search` toolkit in `agno` with a new one, i.e `BraveSearchTools`, which would be similar to `GoogleSearchTools` or `DuckDuckGoTools`.\n\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\nI think extending the Search toolkit helps `agno` for wider adaptability and more tooling available for engineers.\n\n### Would you like to work on this?\n\n- [x] Yes, I’d love to work on it!\n- [x] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "gergob",
      "author_type": "User",
      "created_at": "2025-05-29T22:00:15Z",
      "updated_at": "2025-05-30T03:22:17Z",
      "closed_at": "2025-05-30T03:22:16Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3416/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3416",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3416",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:12.067721",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-346/feature-request-brave-search-api-in-search-toolkit\">SUPPORT-346 [Feature Request] Brave Search API in Search toolkit</a></p>",
          "created_at": "2025-05-29T22:00:18Z"
        },
        {
          "author": "AmoabaKelvin",
          "body": "implemented this in #3417 ",
          "created_at": "2025-05-30T01:06:28Z"
        },
        {
          "author": "ysolanky",
          "body": "Thank you for your contribution @AmoabaKelvin !",
          "created_at": "2025-05-30T03:22:16Z"
        }
      ]
    },
    {
      "issue_number": 3163,
      "title": "[Feature Request] Support Handoffs Mechanism",
      "body": "## Problem Description\nIt can be difficult to manage seamless transitions between LLM agents or from an LLM to a human operator in multi-agent or group chat settings. Without a structured handoff mechanism, context can be lost, interactions can feel disjointed, and users may not be routed to the most appropriate agent. This limits the scalability and robustness of complex AI-driven workflows.\n\n## Proposed Solution\nImplement a structured handoffs mechanism similar to what AG2 AI supports. This includes:\n\nLLM-based handoffs: where the current model determines when and to whom to pass control, based on context or trigger conditions.\n\nConfiguration options: allowing developers to define rules or use model outputs to orchestrate agent transitions.\n\nLogging and traceability: capturing the reason for handoffs and preserving context for continuity.\n\nHuman-in-the-loop support: enabling transitions from LLM to human agents for escalations or high-confidence thresholds.\n\nThis would provide a more modular and dynamic orchestration layer, enabling collaborative agent scenarios with context-aware routing.\n\n## Alternatives Considered\nManually orchestrating agents using external logic, but this requires heavy lifting on the developer side and lacks the flexibility and dynamism of model-driven handoffs.\n\nUsing separate endpoints and routing logic outside the LLM environment, but this often breaks context continuity.\n\n## Additional context\nAG2 AI’s [handoffs documentation](https://docs.ag2.ai/latest/docs/user-guide/advanced-concepts/orchestration/group-chat/handoffs/) serves as a good reference.\n\nSimilar concepts exist in customer support platforms like Intercom or Zendesk, but bringing this into LLM orchestration would enhance AI-native workflows.\n\n```python\nfrom typing import Annotated\nfrom autogen import ConversableAgent, LLMConfig\nfrom autogen.agentchat import initiate_group_chat\nfrom autogen.agentchat.group.patterns import AutoPattern\nfrom autogen.agentchat.group import (\n    ContextVariables, ReplyResult, AgentTarget,\n    OnCondition, StringLLMCondition,\n    OnContextCondition, ExpressionContextCondition, ContextExpression,\n    RevertToUserTarget\n)\n\n# Initialize context variables for our support system\nsupport_context = ContextVariables(data={\n    \"query_count\": 0,\n    \"repeat_issue\": False,\n    \"previous_solutions\": [],\n    \"issue_type\": \"\",\n    \"issue_subtype\": \"\",\n})\n\n# Configure the LLM\nllm_config = LLMConfig(api_type=\"openai\", model=\"gpt-4o-mini\")\n\n# Create all our support agents\nwith llm_config:\n    # Main triage agent - the starting point for all user queries\n    triage_agent = ConversableAgent(\n        name=\"triage_agent\",\n        system_message=\"\"\"You are a support triage agent. Your role is to:\n        1. Determine if a query is technical or general\n        2. Use the classify_query function to route appropriately\n\n        Do not attempt to solve issues yourself - your job is proper routing.\"\"\"\n    )\n\n    # General support for non-technical questions\n    general_agent = ConversableAgent(\n        name=\"general_agent\",\n        system_message=\"\"\"You are a general support agent who handles non-technical questions.\n        If the user is a premium customer (check account_tier context variable),\n        you should transfer them directly to the premium support agent.\n        Otherwise, provide helpful responses to general inquiries.\"\"\"\n    )\n\n    # Tech agent for initial technical assessment\n    tech_agent = ConversableAgent(\n        name=\"tech_agent\",\n        system_message=\"\"\"You are a technical support agent who handles the initial assessment\n        of all technical issues.\n\n        If the user is a premium customer (check account_tier context variable),\n        you should transfer them directly to the premium support agent.\n\n        Otherwise, determine if the issue is related to:\n        - Computer issues (laptops, desktops, PCs, Macs)\n        - Smartphone issues (iPhones, Android phones, tablets)\n\n        And route to the appropriate specialist.\"\"\"\n    )\n\n    # Device-specific agents\n    computer_agent = ConversableAgent(\n        name=\"computer_agent\",\n        system_message=\"\"\"You are a computer specialist who handles issues with laptops, desktops,\n        PCs, and Macs. You provide troubleshooting for hardware and software issues specific to\n        computers. You're knowledgeable about Windows, macOS, Linux, and common computer peripherals.\n\n        For first-time issues, provide a solution directly.\n\n        If a user returns and says they tried your solution but are still having the issue,\n        use the check_repeat_issue function to escalate to advanced troubleshooting. Do not provide a solution yourself for returning users, simply route it to advanced troubleshooting.\"\"\"\n    )\n\n    smartphone_agent = ConversableAgent(\n        name=\"smartphone_agent\",\n        system_message=\"\"\"You are a smartphone specialist who handles issues with mobile devices\n        including iPhones, Android phones, and tablets. You're knowledgeable about iOS, Android,\n        mobile apps, battery issues, screen problems, and connectivity troubleshooting.\n\n        For first-time issues, provide a solution directly.\n\n        If a user returns and says they tried your solution but are still having the issue,\n        use the check_repeat_issue function to escalate to advanced troubleshooting. Do not provide a solution yourself for returning users, simply route it to advanced troubleshooting\"\"\"\n    )\n\n    # Advanced troubleshooting for complex issues\n    advanced_troubleshooting_agent = ConversableAgent(\n        name=\"advanced_troubleshooting_agent\",\n        system_message=\"\"\"You are an advanced troubleshooting specialist who handles complex,\n        persistent issues that weren't resolved by initial solutions. You provide deeper\n        diagnostic approaches and more comprehensive solutions for difficult technical problems.\"\"\"\n    )\n\n# Define tool functions\ndef classify_query(\n    query: Annotated[str, \"The user query to classify\"],\n    context_variables: ContextVariables\n) -> ReplyResult:\n    \"\"\"Classify a user query and route to the appropriate agent.\"\"\"\n    # Update query count\n    context_variables[\"query_count\"] += 1\n\n    # Simple classification logic\n    technical_keywords = [\"error\", \"bug\", \"broken\", \"crash\", \"not working\", \"shutting down\",\n                        \"frozen\", \"blue screen\", \"won't start\", \"slow\", \"virus\"]\n\n    if any(keyword in query.lower() for keyword in technical_keywords):\n        return ReplyResult(\n            message=\"This appears to be a technical issue. Let me route you to our tech support team.\",\n            target=AgentTarget(tech_agent),\n            context_variables=context_variables\n        )\n    else:\n        return ReplyResult(\n            message=\"This appears to be a general question. Let me connect you with our general support team.\",\n            target=AgentTarget(general_agent),\n            context_variables=context_variables\n        )\n\ndef check_repeat_issue(\n    description: Annotated[str, \"User's description of the continuing issue\"],\n    context_variables: ContextVariables\n) -> ReplyResult:\n    \"\"\"Check if this is a repeat of an issue that wasn't resolved.\"\"\"\n    # Mark this as a repeat issue in the context\n    context_variables[\"repeat_issue\"] = True\n    context_variables[\"continuing_issue\"] = description\n\n    return ReplyResult(\n        message=\"I understand that your issue wasn't resolved. Let me connect you with our advanced troubleshooting specialist.\",\n        target=AgentTarget(advanced_troubleshooting_agent),\n        context_variables=context_variables\n    )\n\n# Add tool functions to the appropriate agents\ntriage_agent.functions = [classify_query]\ncomputer_agent.functions = [check_repeat_issue]\nsmartphone_agent.functions = [check_repeat_issue]\n\n# Route based on device type\ntech_agent.handoffs.add_llm_conditions([\n    OnCondition(\n        target=AgentTarget(computer_agent),\n        condition=StringLLMCondition(prompt=\"Route to computer specialist when the issue involves laptops, desktops, PCs, or Macs.\"),\n    ),\n    OnCondition(\n        target=AgentTarget(smartphone_agent),\n        condition=StringLLMCondition(prompt=\"Route to smartphone specialist when the issue involves phones, mobile devices, iOS, or Android.\"),\n    )\n])\n\n# For other tech issues, revert to user\ntech_agent.handoffs.set_after_work(RevertToUserTarget())\n\n# Configure handoffs for computer agent - for repeat issues\ncomputer_agent.handoffs.add_context_conditions([\n    OnContextCondition(\n        target=AgentTarget(advanced_troubleshooting_agent),\n        condition=ExpressionContextCondition(\n            expression=ContextExpression(\"${repeat_issue} == True\")\n        )\n    )\n])\n\n# For first-time issues, revert to user\n# computer_agent.handoffs.set_after_work(RevertToUserTarget())\n\n# Similarly for smartphone agent\nsmartphone_agent.handoffs.add_context_conditions([\n    OnContextCondition(\n        target=AgentTarget(advanced_troubleshooting_agent),\n        condition=ExpressionContextCondition(\n            expression=ContextExpression(\"${repeat_issue} == True\")\n        )\n    )\n])\n# smartphone_agent.handoffs.set_after_work(RevertToUserTarget())\n\n# Configure handoffs for advanced troubleshooting agent\nadvanced_troubleshooting_agent.handoffs.set_after_work(RevertToUserTarget())\n\ngeneral_agent.handoffs.set_after_work(RevertToUserTarget())\n\n# Create the user agent\nuser = ConversableAgent(name=\"user\", human_input_mode=\"ALWAYS\")\n\n# Set up the conversation pattern\npattern = AutoPattern(\n    initial_agent=triage_agent,\n    agents=[\n        triage_agent,\n        tech_agent,\n        computer_agent,\n        smartphone_agent,\n        advanced_troubleshooting_agent,\n        general_agent\n    ],\n    user_agent=user,\n    context_variables=support_context,\n    group_manager_args = {\"llm_config\": llm_config},\n)\n\n# Run the chat\nresult, final_context, last_agent = initiate_group_chat(\n    pattern=pattern,\n    messages=\"My laptop keeps shutting down randomly. Can you help?\",\n    max_rounds=15\n)\n```",
      "state": "closed",
      "author": "anhphong22",
      "author_type": "User",
      "created_at": "2025-05-12T03:29:48Z",
      "updated_at": "2025-05-29T19:09:10Z",
      "closed_at": "2025-05-29T19:09:10Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3163/reactions",
        "total_count": 7,
        "+1": 7,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3163",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3163",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:12.322404",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Hi @anhphong22 \nMost of these functionalities should be possible with our [`Teams`](https://docs.agno.com/teams/introduction) implementation! \n\nLLM-based handoffs -> This is our teams implementation, either in `coordinate` or `route` mode\n\nConfiguration options -> You can provide instructions to the",
          "created_at": "2025-05-26T12:07:24Z"
        }
      ]
    },
    {
      "issue_number": 3328,
      "title": "[Bug] `session_name` erased upon new session",
      "body": "### Description\n\nMaybe I misunderstand the purpose of `session_name`. My intention is to manually provide a name (similar to manually providing a `session_id`) upon agent instantiation, and have it show up as label in the Playground. However, the `session_name` is not written to the session storage after the agent interaction.\n\nI believe this is the culprit: https://github.com/agno-agi/agno/blob/8c60bf3287e6000862082f6a9579fb654dab5c0e/libs/agno/agno/agent/agent.py#L3743\n\n\n\n### Steps to Reproduce\n\nInstantiate agent with `session_name` and `storage` provided, issue a new session.\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\n`session_name` should not be written to the session storage.\n\n### Actual Behavior\n\n`session_name` is erased if a storage is provided but a new session created.\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nAgno Version: 1.5.3\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "m-breitbach",
      "author_type": "User",
      "created_at": "2025-05-23T13:46:14Z",
      "updated_at": "2025-05-29T18:55:59Z",
      "closed_at": "2025-05-29T18:55:58Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3328/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3328",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3328",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:12.509979",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-294/bug-session-name-erased-upon-new-session\">SUPPORT-294 [Bug] `session_name` erased upon new session</a></p>",
          "created_at": "2025-05-23T13:46:17Z"
        },
        {
          "author": "mishramonalisha76",
          "body": "Thanks for pointing this out @m-breitbach . Our team will be working on it and it should be out soon. ",
          "created_at": "2025-05-29T07:59:18Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@m-breitbach The reason we do that is for when you switch sessions, but I see how that is an incorrect implementation. I am fixing it with something better.",
          "created_at": "2025-05-29T09:11:39Z"
        },
        {
          "author": "dirkbrnd",
          "body": "This should now be resolved with [1.5.6](https://github.com/agno-agi/agno/releases/tag/v1.5.6)!",
          "created_at": "2025-05-29T18:55:58Z"
        }
      ]
    },
    {
      "issue_number": 2699,
      "title": "[Bug] Error Processing Tool Output: content is null or AttributeError after Successful Tool Call (v1.2.9)",
      "body": "We could not find any existing public issues or documentation describing this specific `content: null` bug. Our conclusion that this is an Agno framework bug stems from detailed investigation and testing during our development process:\n\n1.  **Systematic Investigation:** We performed various troubleshooting steps:\n    *   Tried different tool output formats (string, Markdown, dictionary).\n    *   Modified Agent instructions.\n    *   Changed the LLM endpoint (tested with Yunwu AI).\n    *   Confirmed API key validity.\n    *   Finally, we successfully ran the LLM interaction by directly using the `openai` library, bypassing Agno.\n\n2.  **Pinpointing the Issue:** The errors (`AttributeError: 'dict' object has no attribute 'role'` or `agno.exceptions.ModelProviderError: Invalid value for 'content': expected a string, got null`) consistently occur *within* the Agno Agent framework. This happens specifically *after* the first tool successfully executes, when the framework attempts to process the tool's return value and construct the next message to send to the LLM (often observed as `messages[3]`, corresponding to the tool result message). The `AttributeError` appears to originate within the `_format_message` function when handling the tool result.\n\n3.  **Direct Call Validation:** When we bypassed the Agno Agent and its `OpenAIChat` wrapper, using the `openai` library directly with the standard message format to call the same LLM endpoint, the process succeeded without error. This strongly indicates the problem lies within the Agno framework's handling of messages, particularly the processing of tool call results before the subsequent LLM call.\n\n**Bug Report Details:**\n\n*   **Agno Version:** `agno==1.2.9` (confirmed from installation logs)\n*   **Environment:**\n    *   Python Version: 3.11\n    *   Operating System: Ubuntu 22.04\n*   **Steps to Reproduce:**\n    1.  Create an Agno Agent that includes at least one simple tool (e.g., a basic function decorated with `@tool`, like the example `StockRealtimeQuoteTool` implies).\n    2.  Configure the Agent's instructions to require calling this tool first as part of its task.\n    3.  Trigger the Agent using `agent.run()` or `agent.print_response()`.\n*   **Observed Behavior:**\n    The Agent successfully executes the first tool, but then fails when attempting to prepare the message containing the tool's output for the subsequent LLM call.\n*   **Error Message(s):**\n    The primary error observed is often:\n    ```\n    agno.exceptions.ModelProviderError: Invalid value for 'content': expected a string, got null\n    ```\n    This may stem from an earlier internal error during message formatting, such as:\n    ```\n    AttributeError: 'dict' object has no attribute 'role' \n    ```\n    (Occurring within Agno's internal message formatting, likely `_format_message` when processing the tool result).\n\n*   **Expected Behavior:**\n    The Agno framework should correctly process the output from the tool (whether it's a string, dict, etc.), format it into the appropriate message structure (e.g., a message with `role: 'tool'`), and successfully send the updated message list (including the tool result) to the LLM for the next step in the conversation.\n\n*   **Additional Context:**\n    *   The tool itself functions correctly when tested in isolation.\n    *   Directly using the `openai` library with the same LLM endpoint, API key, and manually constructed messages (including a simulated tool response message) works successfully.\n    *   The issue appears specifically localized to how the Agno framework handles the transition from a tool's successful execution back to interacting with the LLM.\n\nWe hope this information helps in diagnosing and resolving the issue. Thank you!\n",
      "state": "closed",
      "author": "leoncuhk",
      "author_type": "User",
      "created_at": "2025-04-06T04:49:36Z",
      "updated_at": "2025-05-29T17:38:31Z",
      "closed_at": "2025-05-29T17:38:31Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2699/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kausmeows"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2699",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2699",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:12.694981",
      "comments": [
        {
          "author": "kausmeows",
          "body": "Hey @leoncuhk, sorry about the inconvenience. Can you provide with the `Agent` config you are using here, and an example of for which tool call this happens.\n\nAlso can you try updating to the recent version `pip install -U agno` and try checking again? ",
          "created_at": "2025-04-14T08:20:30Z"
        },
        {
          "author": "NTTLuke",
          "body": "With Agno 1.2.7 I didn't have this issue so I don't know if it's related the new model or code lib.\nI have the same issue with the new Azure OpenAI 4.1 update this morning, using agno 1.3.1.\n\nI investigated the issue (with some help from AI, LOL) and found a way to fix it. I’m sharing these details ",
          "created_at": "2025-04-15T15:09:45Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-05-16T00:34:31Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@NTTLuke Has this been resolved on the latest version of Agno? We have made updates to how content is handled.",
          "created_at": "2025-05-28T13:59:36Z"
        },
        {
          "author": "NTTLuke",
          "body": "Yes! Feel free to close this issue.\nThanks guys u are amazing  🙏 ",
          "created_at": "2025-05-29T17:37:19Z"
        }
      ]
    },
    {
      "issue_number": 3335,
      "title": "[Feature Request] Agent UI playground  show tool calling paramters",
      "body": "### Problem Description\n\nHi ango team,\n\nThanks you for the great agno Agent UI.  Could you show MCP tools calling paramters in Agent UI playground?\nI want to know what paramters agent used. Thanks!\n\n\n### Proposed Solution\n\n Now I see agno debug logging  show it,  \n\n```\nDEBUG Running: io_read(request={'filename': 'demo.txt'})                     \nDEBUG Calling MCP Tool 'io_read' with args: {'request': {'filename': 'demo.txt'}}   \n```\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [x] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "huang-sh",
      "author_type": "User",
      "created_at": "2025-05-23T20:24:40Z",
      "updated_at": "2025-05-29T13:47:11Z",
      "closed_at": "2025-05-29T13:47:11Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3335/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3335",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3335",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:18.015590",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-297/feature-request-agent-ui-playground-show-tool-calling-paramters\">SUPPORT-297 [Feature Request] Agent UI playground show tool calling paramters</a></p>",
          "created_at": "2025-05-23T20:24:43Z"
        },
        {
          "author": "mishramonalisha76",
          "body": "Hi @huang-sh ,\nThanks for the suggestion — it’s a great one and definitely aligns with our future roadmap. While we’re currently focused on a few higher-priority items, we want to highlight that Agent UI is an open-source project and we actively welcome community contributions.\n\nIf you're interested",
          "created_at": "2025-05-29T08:14:48Z"
        },
        {
          "author": "huang-sh",
          "body": "@mishramonalisha76  thanks  for your work.",
          "created_at": "2025-05-29T13:45:36Z"
        }
      ]
    },
    {
      "issue_number": 3370,
      "title": "[Bug] Team Leader unable to detect Agent response",
      "body": "### Description\n\nI am building a simple Team-based multi-agent system that comprises of two agents. Given the name of a software, the first Agent detects the download URL of the software and the second agent installs the software from the download URL on a local machine. When I trigger the Team to run (passing software name), it invokes the first agent to search for the download URL of the software using Internet. The first agent uses a tool to do so. Even though the tool is properly returning the download URL, the team leader is unable to detect that and exiting the agent loop with message \"I will wait for response from agent\".\n\n### Steps to Reproduce\n\nHere is the code:\nfrom agno.agent import Agent, RunResponse\nfrom agno.knowledge import AgentKnowledge\nfrom agno.knowledge.website import WebsiteKnowledgeBase\nfrom agno.models.ollama import Ollama \nfrom agno.models.google import Gemini\nfrom agno.tools.duckduckgo import DuckDuckGoTools\nfrom agno.team import Team\nfrom agno.tools.tavily import TavilyTools\nfrom agno.tools.serpapi import SerpApiTools\nfrom agno.tools.googlesearch import GoogleSearchTools\nfrom agno.tools.crawl4ai import Crawl4aiTools\nfrom agno.exceptions import StopAgentRun\nfrom agno.vectordb.chroma import ChromaDb\nfrom agno.tools import tool\n\nimport certifi\nimport urllib\nimport os\n\nos.environ[\"REQUESTS_CA_BUNDLE\"] = certifi.where()\nos.environ[\"SSL_CERT_FILE\"] = certifi.where()\n\n# Google LLM Model\ngmodel = Gemini(id=\"gemini-2.0-flash\")\n\n# Agent that determines whether the input command is harmful or not\ncommand_reviewer_agent = Agent(\n    role=\"Agent that reviews an input command\",\n    name=\"Command Reviewer Agent\",\n    model=gmodel,\n    description=\"You are an intelligent AI Agent that reviews a given command and determines whether the command can cause harm to local machine or not\",\n    exponential_backoff=True,\n    retries=2,\n    instructions=\"\"\"\n    Check the given command.\n    If the command is trying to delete or remove a file or folder from the local machine, then reply as \"reject\"\n    Otherwise, reply as \"accept\"\n    Do not reply anything else\n    Do not find anything else\n    \"\"\",\n    show_tool_calls=True\n)\n\n# Execute command on local machine\ndef execute_command(cmd: str) -> str:\n    \"\"\"\n    Use this function to execute a command on local machine\n    Args:\n        cmd(str): command to be executed\n    Returns:\n        str: String indicating status of command execution\n    \"\"\"\n    print(\"*************************************  Command received -> ************************************ \", cmd)\n    print(\"********************** Checking with command_reviewer_agent whether the command should be accepted or not *************\")\n    response = command_reviewer_agent.run(cmd)\n    print(\"Response -> \", response.content)\n    if (response.content.strip() == \"reject\"):\n        print(\"*************** WARNING: The LLM has advised against running this command **************\")\n        print(\"*************** Do you still want to run this command? Type N or No or n if you do not want to run this command ***********\")\n        user_response = input()\n        if (user_response == 'n' or user_response == 'No' or user_response == 'N'):\n            print(\"********* Command NOT Executed **********\")\n            raise StopAgentRun(\"Command execution cancelled !!\", agent_message=\"Stopping execution since LLM has determined the command to be harmful !!\")\n        else:\n            print(\"************* You want to go ahead with running the command !!!!\")\n            os.system(cmd) \n            print(\"********* Command Executed **********\")\n    else:\n        os.system(cmd) \n        print(\"********* Command Executed **********\")\n    \n    return \"Done\"\n\n\n\n# Software Download Agent\ndownload_agent = Agent(\n    role=\"Agent for downloading and installation of a software from a given URL string\",\n    name=\"Software Downloader Agent\",\n    tools=[execute_command],\n    add_datetime_to_instructions=True,\n    model=gmodel,\n    description=\"You are an intelligent AI Agent that downloads a software from a given URL string and then installs the software\",\n    exponential_backoff=True,\n    retries=2,\n    instructions=\"\"\"\n    You have to download a software using the given URL string\n    Download the software only if it is based on Python. Otherwise, do not download it\n    First, delete directory, if exists, with same name as name of software.\n    Then, Execute command to create a directory on local machine. Use lowercase while creating the directory.\n    The name of directory should be same as name of software\n    Next, check whether Python is installed on the local machine or not\n    If Python is not installed, then install latest version of Python on local machine \n    Now, go inside that directory and create a Python Virtual Environment\n    Then, activate the Python Virtual Environment\n    Next download the software on local machine from the given URL\n    Finally, install the software on local machine\n    Do not find anything else\n    At the end, return a message indicating whether the software has been downloaded or not successfully.\n    \"\"\",\n    show_tool_calls=True,\n    read_chat_history=True,\n    debug_mode=True\n)\n\n# Agent that determines the download URL of a software\ndownload_url_agent = Agent(\n    role=\"Agent that identifies the download URL of a software\",\n    name=\"Download URL Retriever Agent\",\n    add_datetime_to_instructions=True,\n    model=gmodel, \n    expected_output=\"URL string of software\",\n    description=\"You are an intelligent AI Agent that can identify the download URL string of a software from the given content\",\n    exponential_backoff=True,\n    retries=2,\n    instructions=\"\"\"\n    Check the given content.\n    Identify the URL that pertains to installation and/or download of a software\n    Identify only one URL\n    Return the URL \n    Do not find anything else\n    \"\"\",\n    show_tool_calls=True,\n    read_chat_history=True,\n    debug_mode=True\n)\n\n# Locate Software URL\n@tool(show_result=True, stop_after_tool_call=True)\ndef locate_software_url(software_name:str) -> str:\n    \"\"\"\n    Use this function to locate the URL of a software\n    Args:\n        software_name(str): software name\n    Returns:\n        str: URL of software\n    \"\"\"\n    print(\"*************************************  Software Name received -> ************************************ \", software_name)\n\n    googlesearch = GoogleSearchTools()\n    result = googlesearch.google_search(query=\"download \" + software_name)\n    print(\"Search result -> \", result)\n\n    # Now, let's feed the result into a Model to determine the URL of the software\n    url = download_url_agent.run(result)\n    print(\"*************** Download URL of software ************* \", url.content)\n    return url.content\n\n\n# Locate Software Agent\nlocate_software_agent = Agent(\n    role=\"Agent for locating software\",\n    name=\"Software Locator Agent\",\n    model=gmodel,\n    add_datetime_to_instructions=True,\n    tools=[locate_software_url],\n    description=\"You are an intelligent AI Agent that locates the URL of a software on the Internet\",\n    exponential_backoff=True,\n    retries=2,\n    instructions=\"\"\"\n    Use your tool to find the URL of the software\n    Whatever your tool returns as a string, use the same as the URL of the software\n    Do not find anything else\n    Do not hallucinate or guess\n    If you can not find the software URL, just return empty string\n    If you find the software URL, return the URL as a string\n    \"\"\",\n    expected_output=\"URL string of software\",\n    show_tool_calls=True,\n    debug_mode=True,\n    read_chat_history = True\n)\n\n# Proof of Concept Team\npoc_team = Team(\n    name = \"POC Team\",\n    mode=\"coordinate\",\n    model=gmodel,\n    add_datetime_to_instructions=True,\n    markdown=True,\n    debug_mode=True,\n    show_members_responses=True,\n    members=[locate_software_agent, download_agent],\n    success_criteria=\"Identification of download URL of a software and Download and Installation of software on local machine ensures completion of a POC\",\n    instructions=\"\"\"\n    You are an AI Assistant that can do a Proof of Concept using a software\n    First, use the Agent for locating software to locate the download URL string of the software using Internet\n    Then, use the Agent for software downloader to download the software binary from the URL string\n    Finally, install the software on local machine\n    Do not find anything else\n    Your work is complete only after the software is successfully installed on local machine\n    \"\"\",\n    show_tool_calls=True\n)\n\n# Main function\ndef main():\n    print(\"Enter your text. Once done, type END in a new line.\\n\")\n    lines = []\n    while True:\n        line = input()\n        if line == 'END':\n            break\n        lines.append(line)\n\n    print(\"Text entered -> \", lines)\n    poc_team.print_response(lines)\n\nif __name__ == \"__main__\":\n    main()\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nI would expect the Team Leader to invoke the second Agent, passing the URL returned by tool of first Agent.\n\n### Actual Behavior\n\nTeam Leader is unable to detect response from First Agent.\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nUsing latest version.\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "newtechcollab",
      "author_type": "User",
      "created_at": "2025-05-27T11:24:43Z",
      "updated_at": "2025-05-29T11:16:31Z",
      "closed_at": "2025-05-29T11:16:31Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3370/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3370",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3370",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:18.256790",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-326/bug-team-leader-unable-to-detect-agent-response\">SUPPORT-326 [Bug] Team Leader unable to detect Agent response</a></p>",
          "created_at": "2025-05-27T11:24:46Z"
        }
      ]
    },
    {
      "issue_number": 1784,
      "title": "An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'",
      "body": "I have encountered this error, but it is intermittent. How should I seek help to resolve it\r\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. (insufficient tool messages following tool_calls message)\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\r\n",
      "state": "closed",
      "author": "touful",
      "author_type": "User",
      "created_at": "2025-01-14T14:01:09Z",
      "updated_at": "2025-05-29T10:20:38Z",
      "closed_at": "2025-02-09T00:32:02Z",
      "labels": [
        "stale"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 13,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/1784/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/1784",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/1784",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:18.469710",
      "comments": [
        {
          "author": "touful",
          "body": "同样的代码运行有时会出现这个错误，有时却不会，求助",
          "created_at": "2025-01-14T14:04:43Z"
        },
        {
          "author": "ysolanky",
          "body": "Hello @touful ! Please share your Agent configuration so that I can help debug. ",
          "created_at": "2025-01-14T14:39:51Z"
        },
        {
          "author": "touful",
          "body": "this is my main.py ，but as I said before ,the same codes run return error or return normally.And now ,it works .I don't no why,please and thanks . @ysolanky \r\n```import config\r\nfrom aiagent.xmlagent import xml_search\r\nfrom aiagent.virusagent import virus_detect\r\nfrom aiagent.llmres import get_llm_re",
          "created_at": "2025-01-14T16:12:15Z"
        },
        {
          "author": "ysolanky",
          "body": "@touful it looks like it is an issue with `DeepSeekChat(id=\"deepseek-chat\"),` not returning the tool call ids properly.\r\n\r\nCan you please:\r\n- Share debug logs. I would like to review the tool calls made by the Agent. \r\n- Test the same Agents with `OpenAIChat` and see if you can replicate the error. ",
          "created_at": "2025-01-15T04:31:01Z"
        },
        {
          "author": "touful",
          "body": "here is my stack traceback, as you said that I will try OpenAIChat after I get opanai_api_key(in my area ,I can't pay for it directly):\r\n```└─────────────────────────────────────────────────────────────────────────────┘Traceback (most recent call last):\r\n  File \"C:\\Users\\ASUS\\Desktop\\app_forensic\\ag",
          "created_at": "2025-01-15T14:03:41Z"
        }
      ]
    },
    {
      "issue_number": 2641,
      "title": "[Feature Request] Does agno's human in the loop capability handle only approval/disapproval related interrupts?",
      "body": "I might be wrong but in the cookbook as well as by default it seems like the agno's HITL capabilities handle only yes/no related human responses.\n\nCan we have a langgraph like interrupt function to change the state and give more detailed inputs to our agents?\nIs it possible to have a HITL feature to handle json inputs as well as prompts related placeholder inputs?\n\nI’m open to collaborating but need guidance.\n",
      "state": "closed",
      "author": "Enish258",
      "author_type": "User",
      "created_at": "2025-04-02T10:43:06Z",
      "updated_at": "2025-05-29T07:30:10Z",
      "closed_at": "2025-05-26T10:36:15Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 12,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2641/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "mishramonalisha76"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2641",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2641",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:18.710365",
      "comments": [
        {
          "author": "kausmeows",
          "body": "Hi @Enish258 yes you are right currently the HITL only supports yes/no type interrupt plus things mentioned [here](https://docs.agno.com/examples/getting-started/human-in-the-loop#human-in-the-loop), we should ideally extend it to what you said. I can add it to the `community wishlist`. We'd love fo",
          "created_at": "2025-04-03T06:51:30Z"
        },
        {
          "author": "Enish258",
          "body": "Yes can you please add it to the community wishlist.\nAnd also ,can I override this functionality to create my own HITL as part of my downloaded agno package?\n\nSince while adding this feature in agno itself would take some time while I need this urgently.",
          "created_at": "2025-04-03T08:54:48Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-18T00:32:15Z"
        },
        {
          "author": "marianocodes",
          "body": "Also seems like HTL only work through the console. I don’t understand how I could use with a API",
          "created_at": "2025-04-20T05:38:34Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @Enish258 \nAdded this to the Agno Roadmap. \n\nTo answer your doubt, we are working on a new HITL Loop. This will solve this",
          "created_at": "2025-04-23T09:06:52Z"
        }
      ]
    },
    {
      "issue_number": 3403,
      "title": "[Feature Request] Support OR conditions and NULL handling in knowledge base filtering",
      "body": "### Problem Description\n\nCurrently, Agno's knowledge base filtering uses PostgreSQL's JSONB `contains` operator (`@>`), which only supports exact matches and doesn't allow for OR conditions or NULL value handling. This creates limitations for real-world use cases where documents need to be filtered based on multiple possible values or when dealing with legacy data.\n\n**Current behavior:**\n```python\n# This looks for documents where meta_data contains exactly one filter match\nfilters = {\"visibility\": \"customer-facing\"}\nknowledge_base.search(query=\"test\", filters=filters)\n```\n\n**What we need:**\n```python\n# We want to find documents where visibility is \"customer-facing\" OR \"both\" OR NULL\n# Currently impossible with Agno's filtering system\n```\n\n**Use Case:** We want to surface documents by the following visibility:\n- `\"internal-only\"` - Only visible to internal team members\n- `\"customer-facing\"` - Visible to customers\n- `\"both\"` - Visible to everyone\n- `NULL` - Legacy documents (should be treated as \"both\")\n\n\n### Proposed Solution\n\nAdd support for more flexible filtering options in the `search()` method:\n\n### Option 1: OR Operator Support\n```python\n# Allow OR conditions using a special operator\nfilters = {\n    \"visibility\": {\n        \"$or\": [\"customer-facing\", \"both\", None]\n    }\n}\n```\n\n### Option 2: SQL-like Operators\n```python\n# Support common SQL operators\nfilters = {\n    \"visibility\": {\n        \"$in\": [\"customer-facing\", \"both\"],\n        \"$or_null\": True  # Include NULL values\n    }\n}\n```\n\n### Option 3: Custom Filter Functions\n```python\n# Allow custom filter functions for complex logic\ndef visibility_filter(meta_data):\n    visibility = meta_data.get(\"visibility\")\n    return visibility in [\"customer-facing\", \"both\"] or visibility is None\n\nknowledge_base.search(query=\"test\", custom_filters=[visibility_filter])\n\n### Option 4: Enhanced SQL Generation\nModify the internal SQL generation to support:\n```sql\n-- Instead of: meta_data @> '{\"visibility\": [\"customer-facing\", \"both\"]}'\n-- Generate: (meta_data->>'visibility' IN ('customer-facing', 'both') OR meta_data->>'visibility' IS NULL)\n\n### Alternatives Considered\n\n**Custom retriever** - Write a custom retriever to implement complex filtering logic. While this provides full control over the filtering behavior, it requires:\n   - Duplicating or reimplementing existing Agno functionality \n   - Maintaining compatibility with Agno updates\n   - Additional complexity in the codebase\n   - Potential loss of optimizations and features built into Agno's retrievers\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [x] No, I’m just sharing the idea.",
      "state": "open",
      "author": "jesalg",
      "author_type": "User",
      "created_at": "2025-05-29T03:54:19Z",
      "updated_at": "2025-05-29T03:54:23Z",
      "closed_at": null,
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3403/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3403",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3403",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:18.906518",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-336/feature-request-support-or-conditions-and-null-handling-in-knowledge\">SUPPORT-336 [Feature Request] Support OR conditions and NULL handling in knowledge base filtering</a></p>",
          "created_at": "2025-05-29T03:54:22Z"
        }
      ]
    },
    {
      "issue_number": 3402,
      "title": "[Feature Request] Custom prompt and enhanced metadata for AgenticChunking",
      "body": "### Problem Description\n\nHi authors, thanks for the amazing product!\n\nI am probing into the AgenticChunking function of agno, and I like the design very much. The following is my test codes. \n\n```\nimport os\nimport typer\nfrom rich.prompt import Prompt\nfrom typing import Optional\nfrom pathlib import Path\nimport pandas as pd\n\nfrom agno.agent import Agent\nfrom agno.document.chunking.agentic import AgenticChunking\nfrom agno.knowledge.markdown import MarkdownKnowledgeBase\nfrom agno.vectordb.lancedb import LanceDb\nfrom agno.models.openai import OpenAIChat\n\n# --- Configuration ---\n\nMD_FILE_PATH = \"./Auto_extract_topics.md\" # Path to your Markdown file\nLANCEDB_URI = \"./agno_lancedb_agentic\" # Path for LanceDB data\nTABLE_NAME = \"auto_md_agentic_chunks\"\n# Ensure OpenAI API key is set, or configure for your LLM\n\nllm_instance = OpenAIChat(\n    id='gpt-4.1-mini'\n)\n\n# --- Load Knowledge Database--- \n\n# Setup LanceDB Vector Store\nprint(f\"Initializing LanceDB at: {LANCEDB_URI}\")\nvector_db = LanceDb(\n    table_name=TABLE_NAME,\n    uri=LANCEDB_URI\n)\n\n# Setup Knowledge Base with Agentic Chunking\nprint(f\"Setting up KnowledgeBase with AgenticChunking for file: {MD_FILE_PATH}\")\n\nagentic_chunker = AgenticChunking(\n    model=llm_instance   \n)\n\nknowledge_base = MarkdownKnowledgeBase(\n    path=Path('Auto_extract_topics.md'), # Use a list of local file paths\n    vector_db=vector_db,\n    chunking_strategy=agentic_chunker,\n)\n\n# Load the knowledge base\nknowledge_base.load(recreate=True)\n\n# --- View the populated KB---\n\nimport lancedb\n\nDB_PATH = \"./agno_lancedb_agentic\"\nTABLE_NAME = \"auto_md_agentic_chunks\"\n\n# Connect to LanceDB\ndb = lancedb.connect(DB_PATH)\n\n# Open the table\ntable = db.open_table(TABLE_NAME)\n\n# Transfer into pandas dataframe\ndata = table.to_pandas()\n\n# Drop vector column for illustration\ndata = `data.drop(columns='vector')``\n\n```\n\nThe codes work well, and gives a decent chunking result. For example, below is the first chunk ( begning sections of a journal paper. I cut some of the content for better reading)\n\n```\nprint(data['payload'][0])\n\n{\"name\": \"Auto_extract_topics\", \n \"meta_data\": {\"chunk\": 1, \"chunk_size\": 1921}, \n \"content\": \"RESEARCH Open Access\n           Automatic extraction of informal topics from online suicidal ideation   Reilly N. Grant1, David Kucher2, Ana M. Le\\u00f3n3, Jonathan F. Gemmell4*, Daniela S. Raicu4 and Samah J. Fodeh5\n           From The 11th International Workshop on Data and Text Mining in Biomedical Informatics Singapore, Singapore. 10 November 2017     \n            Abstract\\n\\nBackground: Suicide is an alarming public health problem accounting for a considerable number of deaths each year worldwide. .......\\n\\nConclusions: These informal topics topics can be more... ... and precision of language.\\n\\nKeywords: Suicidal ideation, Word2Vec, Text mining\", \n\"usage\": {\"prompt_tokens\": 363, \"total_tokens\": 363}}\n\n```\n\nI got two more requirements which might better improve the knowledge base, and hopefully it could be possible.\n\n1.  **Custom the prompt in the AgenticChunking** so that I can handling the chunking meet the user's personalized need. For example, seperating the author information and the abstract text in the example above.\n\n2. **Incorporatting more meta_data items** basing on the chunked piecies. For example, the LLM should identifiy the section type (with tailored custom prompts), so it would be ideal to incoporate it into meta_data. \n\nMy ideal chunking looks like below:\n\n```\nprint(data['payload'][0])\n\n{\"name\": \"Auto_extract_topics\", \n \"meta_data\": {\"chunk\": 1, \"chunk_size\": 1921, \"chunk_type\": \"general info\"}, \n \"content\": \"RESEARCH Open Access Automatic extraction of informal topics from online suicidal ideation   Reilly N. Grant1, David Kucher2, Ana M. Le\\u00f3n3, Jonathan F. Gemmell4*, Daniela S. Raicu4 and Samah J. Fodeh5\\n\\nFrom The 11th International Workshop on Data and Text Mining in Biomedical Informatics Singapore, Singapore. 10 November 2017 \", \n\"usage\": {\"prompt_tokens\": xx, \"total_tokens\": xx}}\n\nprint(data['payload'][1])\n\n{\"name\": \"Auto_extract_topics\", \n \"meta_data\": {\"chunk\": 1, \"chunk_size\": 1921, \"chunk_type\": \"Abstract\"}, \n \"content\": \"Abstract\\n\\nBackground: Suicide is an alarming public health problem accounting for a considerable number of deaths each year worldwide. .......\\n\\nConclusions: These informal topics topics can be more... ... and precision of language.\\n\\nKeywords: Suicidal ideation, Word2Vec, Text mining\", \n\"usage\": {\"prompt_tokens\": xx, \"total_tokens\": xx}}\n```\n\nI thought it could provide more robust knowledgebase for downstream application, and the current AgenticChunking gives quiet a good starting point. But I don't kown if it is possible to directly achieved in AgenticChunking, or by other tweaking method?  \n\nMany thanks !\n\n\nbtw, I attached the md file in my example above. It is a journal article. \n[Auto_extract_topics.md](https://github.com/user-attachments/files/20497357/Auto_extract_topics.md)\n\n\n\n\n### Proposed Solution\n\nNot yet ideal solution. \n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.",
      "state": "open",
      "author": "yangxg",
      "author_type": "User",
      "created_at": "2025-05-29T02:38:48Z",
      "updated_at": "2025-05-29T02:38:52Z",
      "closed_at": null,
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3402/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3402",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3402",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:19.113181",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-335/feature-request-custom-prompt-and-enhanced-metadata-for\">SUPPORT-335 [Feature Request] Custom prompt and enhanced metadata for AgenticChunking</a></p>",
          "created_at": "2025-05-29T02:38:51Z"
        }
      ]
    },
    {
      "issue_number": 1411,
      "title": "Add SQLite as VectorDB",
      "body": null,
      "state": "closed",
      "author": "ArchishmanSengupta",
      "author_type": "User",
      "created_at": "2024-11-07T15:38:34Z",
      "updated_at": "2025-05-28T17:47:17Z",
      "closed_at": "2024-12-03T02:58:18Z",
      "labels": [
        "enhancement",
        "good first issue"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/1411/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ArchishmanSengupta"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/1411",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/1411",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:19.293320",
      "comments": [
        {
          "author": "manthanguptaa",
          "body": "Hey @ArchishmanSengupta, great that you created an issue after our conversation on X. I would love to see a PR for this issue! Here is a vector search extension for SQLite https://github.com/asg017/sqlite-vec that you can use ",
          "created_at": "2024-11-08T05:47:19Z"
        },
        {
          "author": "ArchishmanSengupta",
          "body": "@ysolanky hi I am currently working on this issue, it's not completed yet(at least couldn't see any PRs)",
          "created_at": "2024-11-27T09:01:29Z"
        },
        {
          "author": "manthanguptaa",
          "body": "I have reopened the issue @ArchishmanSengupta. ",
          "created_at": "2024-11-27T09:09:03Z"
        },
        {
          "author": "manthanguptaa",
          "body": "Hey @ArchishmanSengupta, how far ahead you are in implementing it? This is of high priority right now and would love to get this merged as soon as possible. ",
          "created_at": "2024-12-01T13:48:42Z"
        },
        {
          "author": "josemcorderoc",
          "body": "Hi, is this feature implemented? Couldn't find anything in the docs.",
          "created_at": "2025-05-28T17:47:17Z"
        }
      ]
    },
    {
      "issue_number": 1811,
      "title": "Prompt caching update in Anthropic API",
      "body": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching",
      "state": "closed",
      "author": "rpvitrux",
      "author_type": "User",
      "created_at": "2025-01-16T18:41:58Z",
      "updated_at": "2025-05-28T17:22:02Z",
      "closed_at": "2025-04-23T11:24:19Z",
      "labels": [
        "enhancement",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/1811/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/1811",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/1811",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:19.526328",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Thanks! Noted to look at",
          "created_at": "2025-01-19T15:25:43Z"
        },
        {
          "author": "AbhishekRP2002",
          "body": "hi @dirkbrnd  if this is open for contribution, i would love to brainstorm on this and take this up !\nthanks",
          "created_at": "2025-01-29T02:54:56Z"
        },
        {
          "author": "rpvitrux",
          "body": "Hey @dirkbrnd, can this issue have the enhancement tag?",
          "created_at": "2025-02-12T20:17:12Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@AbhishekRP2002 Yes please! We welcome contributions. It is on our roadmap to add it soon, but feel free to take a stab.",
          "created_at": "2025-02-12T20:30:51Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-02-27T00:30:32Z"
        }
      ]
    },
    {
      "issue_number": 2732,
      "title": "Need support for Playwright MCP",
      "body": "I'm trying to implement a solution where an AI agent can maintain state across multiple browser interactions using the Playwright MCP tool.\n\nCode that's failing:\n```python\nfrom agno.agent import Agent\nfrom agno.models.anthropic import Claude\nfrom agno.tools.mcp import MCPTools\n\nfrom mcp import ClientSession, StdioServerParameters\nfrom mcp.client.stdio import stdio_client\n\nasync def initialize_if_needed():\n    global mcp_session, mcp_tools, agent\n\n    if mcp_tools is None:\n        # Define server parameters for a long-running server\n        server_params = StdioServerParameters(\n            command=\"npx\", args=[\"-y\", \"@playwright/mcp@latest\"], env=os.environ\n        )\n\n        # Create a persistent connection\n        read, write = await stdio_client(server_params)  # Error occurs here\n        mcp_session = ClientSession(read, write)\n        await mcp_session.__aenter__()\n\n        # Initialize tools with this session\n        mcp_tools = MCPTools(session=mcp_session)\n        await mcp_tools.initialize()\n\n        # Create agent with these tools\n        agent = Agent(\n            model=Claude(id=CLAUDE_SONNET_MODEL_ID, api_key=ANTHROPIC_API_KEY),\n            tools=[mcp_tools],\n            instructions=\"You are a form-filling assistant...\",\n            markdown=True,\n            show_tool_calls=True,\n            add_history_to_messages=True,\n        )\n```\n\nError:\n```TypeError: object _AsyncGeneratorContextManager can't be used in 'await' expression```\n\nCurrent approach:\n- Attempting to create a persistent connection to the Playwright MCP server\n- Maintaining the same browser session across multiple agent.agenerate_response() calls\n\nEnvironment:\n- agno version: 1.2.5\n- Using MCPTools with Playwright\n\nIs there a way to reuse the same browser session with multiple calls to the agent?",
      "state": "closed",
      "author": "rpvitrux",
      "author_type": "User",
      "created_at": "2025-04-08T15:33:25Z",
      "updated_at": "2025-05-28T17:19:26Z",
      "closed_at": "2025-05-28T17:19:26Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2732/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2732",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2732",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:19.773075",
      "comments": [
        {
          "author": "rpvitrux",
          "body": "The main challenge is that complex web tasks often need to be broken down into smaller steps or handled by multiple specialized agents, but without the ability to share the same browser session between agent calls or different agents, I can't effectively split these tasks. Each new agent or call wou",
          "created_at": "2025-04-08T15:37:53Z"
        },
        {
          "author": "pritipsingh",
          "body": "Hi @rpvitruvix , sorry about this!\n\nThe error `TypeError: object _AsyncGeneratorContextManager can't be used in 'await' expression` occurs because stdio_client() returns an async context manager that should be used with async with rather than being directly awaited. \n\n\nAdditionally, I feel your appr",
          "created_at": "2025-04-17T10:53:15Z"
        },
        {
          "author": "rpvitrux",
          "body": "Thank you @pritipsingh, that example would be very helpful, because with the current example in the docs each new agent or call would start with a fresh browser session, losing all previous state.",
          "created_at": "2025-04-17T15:49:31Z"
        },
        {
          "author": "pritipsingh",
          "body": "Thanks @rpvitruvix , @kausmeows will be working on it once he gets some time or let us know if you're interested in taking this up with the help of or team",
          "created_at": "2025-04-18T04:20:07Z"
        },
        {
          "author": "rpvitrux",
          "body": "Hey @pritipsingh, I'm still working through the Playwright MCP integration. While I wait for the official solution, I've been exploring some alternative approaches but I haven't written anything like the class-based approach you suggested.\nDo you have any specific recommendations or code examples th",
          "created_at": "2025-05-06T18:11:54Z"
        }
      ]
    },
    {
      "issue_number": 3240,
      "title": "[Bug] MCP Tool freezes at `__aexit__`",
      "body": "### Description\n\nI wrote:\n* A `mongo_agent: agno.agent.Agent` with `MCPTools(command=<run mongodb-mcp-server>)` and `Reasontool`\n* A `team: agno.team.team.Team` with `mode=\"coordinate\"` and `Reasontool` \n\nThen I call `team.print_response(\"Check the mongo database list for me\", stream=True)`.\n\nThe passing from `team` to `mongo_agent` is successful and `mongo_agent` can call `list_database()`.\n\nHowever, `mongo_agent` cannot receive the data from `list_database()` and the program finished with output `\"Sorry, I cannot ...\"`.\n\nFurthermore, it freezes when exiting `async with MCPTools()` context. I have to enter `Ctrl+C` to force it stopping, then it tells me that `RuntimeWarning: coroutine 'get_entrypoint_for_tool.<locals>.call_tool' was never awaited`.\n\nI believe it is not the MCP's problem, since I have tested it manually by calling the API and it worked.\n\n---\n\nThis is maybe relevant to https://github.com/agno-agi/agno/issues/3238.\n\n### Steps to Reproduce\n\n`mongo_agent.py`:\n\n```python\nfrom agno.tools.mcp import MCPTools\nfrom agno.agent import Agent\nfrom xd_agno.utils.azure import get_azure_openai\nfrom agno.tools.reasoning import ReasoningTools\n\n\ndef create_mongo_agent(mcp_mongo_tools: MCPTools) -> Agent:\n    \"\"\"\n    Create a MongoDB agent from the given tools.\n\n    Example:\n        >>> async with MCPTools(command=\"npx mongo-mcp mongodb://localhost:27017\") as mcp_mongo_tools:\n        >>>     mongo_agent = create_mongo_agent(mcp_mongo_tools)\n    \"\"\"\n\n    return Agent(\n        model=get_azure_openai(),\n        name=\"MongoDB Agent\",\n        role=\"Reads or Writes to the MongoDB database\",\n        tools=[\n            ReasoningTools(add_instructions=True),\n            mcp_mongo_tools,\n        ],\n        description=(\n            \"You are a helpful assistant that can answer questions or\"\n            \"do database operations about the MongoDB database.\"\n        ),\n        instructions=[\n            \"The user might ask you to find some information or do some operations in native language.\",\n            \"\",\n            \"You need to always remember:\",\n            \"1. Think twice before you do any operations.\",\n            \"2. Remember to check the actual fields in the database, since the user might not know the exact field names.\",\n            \"3. You can use the tools provided to do the operations.\",\n            \"4. You SHOULD always add all necessary information from tool result into your response.\",\n            \"\",\n            \"A standard workflow for you to follow:\",\n            \"First, call `list-databases` to list all the databases.\",\n            \"Second, call `list-collections` to list all the collections in the database.\",\n            \"Third, call `find` to find the documents with filter or projection.\",\n            \"You should ALWAYS remember to add filters and projections to the query\",\n            \"if necessary in order to get the most accurate and relevant results.\",\n            \"\",\n        ],\n        show_tool_calls=True,\n        markdown=True,\n    )\n```\n\n`team.py`:\n\n```python\nfrom agno.agent import Agent\nfrom agno.team.team import Team\nfrom agno.tools.reasoning import ReasoningTools\nfrom xd_agno.utils.azure import get_azure_openai\n\n\ndef create_team(members: list[Agent]) -> Team:\n    return Team(\n        name=\"Leader\",\n        model=get_azure_openai(),\n        mode=\"coordinate\",\n        members=list(members),\n        description=(\n            \"You are the leader of the team.\"\n            \"You are responsible for the overall plan and the big picture.\"\n            \"As you are talking to a Chinese user, you need to always use Chinese.\"\n        ),\n        instructions=[\n            \"Remember:\",\n            \"1. Always think twice before you make any decisions.\",\n            \"2. You need to be very careful when you make any decisions.\",\n            \"3. Always remember to use Chinese.\",\n        ],\n        tools=[\n            ReasoningTools(add_instructions=True),\n        ],\n        add_datetime_to_instructions=True,\n        add_member_tools_to_system_message=False,  # This can be tried to make the agent more consistently get the transfer tool call correct\n        enable_agentic_context=True,  # Allow the agent to maintain a shared context and send that to members.\n        share_member_interactions=True,  # Share all member responses with subsequent member requests.\n        show_members_responses=True,\n        markdown=True,\n    )\n```\n\n`__init__.py`:\n\n```python\nimport asyncio\n\nfrom agno.tools.mcp import MCPTools\n\nfrom xd_agno.agents.jira_db_agent import create_jira_db_agent\nfrom xd_agno.agents.mongo_agent import create_mongo_agent\nfrom xd_agno.agents.team import create_team\n\nimport logging\n\nlogging.basicConfig(level=logging.DEBUG)\n\n\nasync def async_main():\n    print(\"Hello from test-agno!\")\n    async with MCPTools(\n        command=\"npx -y mongodb-mcp-server --connectionString mongodb://localhost:27017\",\n        timeout_seconds=10,\n    ) as mcp_mongo_tools:\n        team = create_team(\n            [\n                create_jira_db_agent(),\n                create_mongo_agent(mcp_mongo_tools),\n            ]\n        )\n        print(\"Team created\")\n        team.print_response(\"Check the mongo database list for me\", stream=True)\n\n\ndef main():\n    \"\"\"Entry point for the package.\"\"\"\n    asyncio.run(async_main())\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nNone\n\n### Actual Behavior\n\nNone\n\n### Screenshots or Logs (if applicable)\n\nAfter I force it stop using `Ctrl+C`:\n\n```log\nDEBUG:pymongo.topology:{\"message\": \"Server heartbeat succeeded\", \"topologyId\": {\"$oid\": \"682b07813eddacaf9cc40e92\"}, \"driverConnectionId\": 1, \"serverConnectionI\nd\": 144, \"serverHost\": \"localhost\", \"serverPort\": 27017, \"awaited\": true, \"durationMS\": 10000.0, \"reply\": \"{\\\"isWritablePrimary\\\": true, \\\"topologyVersion\\\": {\\\n\"processId\\\": {\\\"$oid\\\": \\\"6811d1e60704aeeb9e4f9f46\\\"}}, \\\"maxBsonObjectSize\\\": 16777216, \\\"maxMessageSizeBytes\\\": 48000000, \\\"maxWriteBatchSize\\\": 100000, \\\"lo\ncalTime\\\": {\\\"$date\\\": \\\"2025-05-19T10:27:43.382Z\\\"}, \\\"logicalSessionTimeoutMinutes\\\": 30, \\\"connectionId\\\": 144, \\\"maxWireVersion\\\": 25, \\\"ok\\\": 1.0}\"}\nDEBUG:pymongo.topology:{\"message\": \"Server heartbeat started\", \"topologyId\": {\"$oid\": \"682b07813eddacaf9cc40e92\"}, \"driverConnectionId\": 1, \"serverConnectionId\"\n: 144, \"serverHost\": \"localhost\", \"serverPort\": 27017, \"awaited\": true}\n  + Exception Group Traceback (most recent call last):\n  |   File \"<frozen runpy>\", line 198, in _run_module_as_main\n  |   File \"<frozen runpy>\", line 88, in _run_code\n  |   File \"E:\\work\\test\\test-agno\\.venv\\Scripts\\xd-agno.exe\\__main__.py\", line 10, in <module>\n  |   File \"E:\\work\\test\\test-agno\\src\\xd_agno\\__init__.py\", line 32, in main\n  |     asyncio.run(async_main())\n  |   File \"C:\\Users\\A-AAA-202109-83\\AppData\\Roaming\\uv\\python\\cpython-3.12.9-windows-x86_64-none\\Lib\\asyncio\\runners.py\", line 195, in run\n  |     return runner.run(main)\n  |            ^^^^^^^^^^^^^^^^\n  |   File \"C:\\Users\\A-AAA-202109-83\\AppData\\Roaming\\uv\\python\\cpython-3.12.9-windows-x86_64-none\\Lib\\asyncio\\runners.py\", line 118, in run\n  |     return self._loop.run_until_complete(task)\n  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  |   File \"C:\\Users\\A-AAA-202109-83\\AppData\\Roaming\\uv\\python\\cpython-3.12.9-windows-x86_64-none\\Lib\\asyncio\\base_events.py\", line 691, in run_until_complete\n  |     return future.result()\n  |            ^^^^^^^^^^^^^^^\n  |   File \"E:\\work\\test\\test-agno\\src\\xd_agno\\__init__.py\", line 16, in async_main\n  |     async with MCPTools(\n  |                ^^^^^^^^^\n  |   File \"E:\\work\\test\\test-agno\\.venv\\Lib\\site-packages\\agno\\tools\\mcp.py\", line 196, in __aexit__\n  |     await self._context.__aexit__(exc_type, exc_val, exc_tb)\n  |   File \"C:\\Users\\A-AAA-202109-83\\AppData\\Roaming\\uv\\python\\cpython-3.12.9-windows-x86_64-none\\Lib\\contextlib.py\", line 217, in __aexit__\n  |     await anext(self.gen)\n  |   File \"E:\\work\\test\\test-agno\\.venv\\Lib\\site-packages\\mcp\\client\\stdio\\__init__.py\", line 171, in stdio_client\n  |     anyio.create_task_group() as tg,\n  |     ^^^^^^^^^^^^^^^^^^^^^^^^^\n  |   File \"E:\\work\\test\\test-agno\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 772, in __aexit__\n  |     raise BaseExceptionGroup(\n  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"E:\\work\\test\\test-agno\\.venv\\Lib\\site-packages\\mcp\\client\\stdio\\__init__.py\", line 148, in stdout_reader\n    |     await read_stream_writer.send(session_message)\n    |   File \"E:\\work\\test\\test-agno\\.venv\\Lib\\site-packages\\anyio\\streams\\memory.py\", line 242, in send\n    |     self.send_nowait(item)\n    |   File \"E:\\work\\test\\test-agno\\.venv\\Lib\\site-packages\\anyio\\streams\\memory.py\", line 213, in send_nowait\n    |     raise BrokenResourceError\n    | anyio.BrokenResourceError\n    +------------------------------------\nDEBUG:pymongo.topology:{\"message\": \"Server heartbeat failed\", \"topologyId\": {\"$oid\": \"682b07813eddacaf9cc40e92\"}, \"serverHost\": \"localhost\", \"serverPort\": 27017\n, \"awaited\": true, \"durationMS\": 7641.000000061467, \"failure\": \"\\\"_OperationCancelled('operation cancelled')\\\"\", \"driverConnectionId\": 1}\nException ignored in: <function BaseSubprocessTransport.__del__ at 0x000001485A1D8860>\nTraceback (most recent call last):\n  File \"C:\\Users\\A-AAA-202109-83\\AppData\\Roaming\\uv\\python\\cpython-3.12.9-windows-x86_64-none\\Lib\\asyncio\\base_subprocess.py\", line 126, in __del__\n  File \"C:\\Users\\A-AAA-202109-83\\AppData\\Roaming\\uv\\python\\cpython-3.12.9-windows-x86_64-none\\Lib\\asyncio\\base_subprocess.py\", line 104, in close\n  File \"C:\\Users\\A-AAA-202109-83\\AppData\\Roaming\\uv\\python\\cpython-3.12.9-windows-x86_64-none\\Lib\\asyncio\\proactor_events.py\", line 109, in close\n  File \"C:\\Users\\A-AAA-202109-83\\AppData\\Roaming\\uv\\python\\cpython-3.12.9-windows-x86_64-none\\Lib\\asyncio\\base_events.py\", line 799, in call_soon\n  File \"C:\\Users\\A-AAA-202109-83\\AppData\\Roaming\\uv\\python\\cpython-3.12.9-windows-x86_64-none\\Lib\\asyncio\\base_events.py\", line 545, in _check_closed\nRuntimeError: Event loop is closed\nDEBUG:httpcore.connection:close.started\nDEBUG:httpcore.connection:close.complete\nDEBUG:httpcore.connection:close.started\nDEBUG:httpcore.connection:close.complete\nsys:1: RuntimeWarning: coroutine 'get_entrypoint_for_tool.<locals>.call_tool' was never awaited\n(test-agno)\n```\n\n### Environment\n\n```markdown\n- OS: Windows 10\n- Agno Version: v1.5.1\n- Python Version: 3.12.9\n```\n\n### Possible Solutions (optional)\n\nCheck the using of `Function.entrypoint(...)`.\n\nIn `mcp.py`:\n\nhttps://github.com/agno-agi/agno/blob/d7ba6336962fb3d9a770f6b7c983f93c9a86e805/libs/agno/agno/tools/mcp.py#L233-L243\n\n`get_entrypoint_for_tool(...) -> AsyncCallable` is assigned to `Function.entrypoint: Optional[Callable]`.\n\nHowever, `Function.entrypoint` is called sync in some cases:\n\nhttps://github.com/agno-agi/agno/blob/cdc3811e85c168a111eec7f5f30ef2410d0491bb/libs/agno/agno/tools/function.py#L627-L632\n\nIt might need to check if these cases are calling correctly.\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "cutekibry",
      "author_type": "User",
      "created_at": "2025-05-19T10:44:33Z",
      "updated_at": "2025-05-28T05:56:18Z",
      "closed_at": "2025-05-28T05:56:16Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3240/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3240",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3240",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:19.967630",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-207/bug-mcp-tool-stop-responding-at-call-tool\">SUPPORT-207 [Bug] MCP Tool stop responding at `call_tool`</a></p>",
          "created_at": "2025-05-19T10:44:37Z"
        },
        {
          "author": "cutekibry",
          "body": "Further exploring shows that it stopped at:\n\n* `In agno.tools.mcp.MCPTools.__aexit__():`\n  * Calling `await self._context.__aexit__(exc_type, exc_val, exc_tb)`\n  * Which is `mcp.client.stddio.stdio_client.__aexit__()`\n  * In `mcp.client.stddio.stdio_client.__aexit__()`:\n    * Freezed when calling `a",
          "created_at": "2025-05-20T06:22:47Z"
        },
        {
          "author": "cutekibry",
          "body": "I try to insert debug prints into the `mcp.client.stdio.win32.terminate_windows_process`, but the debug output is unreasonable for me. In `mcp/client/stdio/win32.py`:\n\n```python\nasync def terminate_windows_process(process: Process):\n    \"\"\"\n    Terminate a Windows process.\n\n    Note: On Windows, ter",
          "created_at": "2025-05-20T06:52:22Z"
        },
        {
          "author": "cutekibry",
          "body": "Update: The MCP Tool will also freezes on WSL (Ubuntu 24 on Windows 10). Furthermore, on WSL, it both freezes at MCP function calling (before returning result) or `__aexit__` (if there is no function calling).",
          "created_at": "2025-05-26T09:26:12Z"
        },
        {
          "author": "cutekibry",
          "body": "Closed by #3356 on Agno `v1.5.5`.\n\nNotice that use `await team.aprint_response` instead of `team.print_response` will fix it.",
          "created_at": "2025-05-28T05:56:16Z"
        }
      ]
    },
    {
      "issue_number": 3382,
      "title": "[Bug] the `Playground` class no longer has the `create_endpoint` method agno api",
      "body": "### Description\n\n[https://github.com/agno-agi/agno-demo-app/blob/main/api/routes/playground.py](url)\n\nIn version 1.5.5, the `Playground` class no longer has the `create_endpoint` method, causing an `AttributeError` when trying to initialize the playground endpoint in development mode.\n\n\n### Steps to Reproduce\n\n1. Install agno version 1.5.5\n2. Create a Playground instance with agents/teams\n3. Try to call `playground.create_endpoint(\"http://localhost:8000\")` \n4. Run the application\n\n### Agent Configuration (if applicable)\n\n```python\nfrom agno.playground import Playground\n\nplayground = Playground(\n    agents=[...],\n    workflows=[...],\n    teams=[...]\n)\n\n# This line causes the error\nif getenv(\"RUNTIME_ENV\") == \"dev\":\n    playground.create_endpoint(\"http://localhost:8000\")\n```\n\n### Expected Behavior\n\nThe `create_endpoint` method should be available on the `Playground` class to register the playground with the monitoring service, or there should be clear documentation about the alternative method to achieve this functionality.\n\n### Actual Behavior\n\nThe application crashes with the following error:\n\nFile \"/app/api/routes/playground.py\", line 123, in <module>\nplayground.create_endpoint(\"http://localhost:8000\")\n^^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'Playground' object has no attribute 'create_endpoint'\n\n### Screenshots or Logs (if applicable)\n\n![Image](https://github.com/user-attachments/assets/ca033c35-7146-4170-bdb4-b7d2e729e1be)\n\n### Environment\n\n```markdown\n- **Agno version**: 1.5.5\n- **Python version**: 3.12\n- **Operating System**: Linux (Docker container)\n- **FastAPI version**: 0.115.12\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "isikepalaku",
      "author_type": "User",
      "created_at": "2025-05-27T21:47:41Z",
      "updated_at": "2025-05-28T01:32:57Z",
      "closed_at": "2025-05-28T01:32:57Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3382/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3382",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3382",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:20.193733",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-330/bug-the-playground-class-no-longer-has-the-create-endpoint-method-agno\">SUPPORT-330 [Bug] the `Playground` class no longer has the `create_endpoint` method agno api</a></p>",
          "created_at": "2025-05-27T21:47:44Z"
        },
        {
          "author": "isikepalaku",
          "body": "can we get update documentation please @dirkbrnd ",
          "created_at": "2025-05-27T21:49:20Z"
        },
        {
          "author": "isikepalaku",
          "body": "Sorry i have found solution on agno api repo",
          "created_at": "2025-05-28T01:32:52Z"
        }
      ]
    },
    {
      "issue_number": 3374,
      "title": "[Bug] Tool results are no longer visible in playground",
      "body": "### Description\n\nIn the version 1.5.5, when an agent or team calls a tool, the result from that tool is no longer showed in the playground when clicking the tool.\n\n### Steps to Reproduce\n\nI have updated the package to 1.5.5, and this happens with all my agents. Is this intentional?\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nIn the previous versions, after a tool finished running, if i clicked on that tool in the Playground, then I could see the output of the tool, which was very helpful when debugging, as well as it was helpful for a user in general.\n\n### Actual Behavior\n\nCurrently, the tool's output is no longer visibile and it is quite annoying because I can't see if my LLM is halucinating or not without seeing the tool's output.\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n- Agno version: 1.5.5\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "andreiionut1411",
      "author_type": "User",
      "created_at": "2025-05-27T13:45:13Z",
      "updated_at": "2025-05-27T14:27:50Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3374/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3374",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3374",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:20.385815",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-328/bug-tool-results-are-no-longer-visible-in-playground\">SUPPORT-328 [Bug] Tool results are no longer visible in playground</a></p>",
          "created_at": "2025-05-27T13:45:17Z"
        },
        {
          "author": "dirkbrnd",
          "body": "We are looking into it! Thanks for raising\n",
          "created_at": "2025-05-27T13:55:38Z"
        },
        {
          "author": "anuragts",
          "body": "Hey @andreiionut1411 , can you send us you agent config code to help us the issue locally ?",
          "created_at": "2025-05-27T14:05:24Z"
        },
        {
          "author": "andreiionut1411",
          "body": "`import asyncio\nfrom os import getenv\nfrom textwrap import dedent\n\nimport nest_asyncio\nfrom agno.agent import Agent\nfrom agno.models.openai import OpenAIChat\nfrom agno.playground import Playground, serve_playground_app\nfrom agno.storage.agent.sqlite import SqliteAgentStorage\nfrom agno.tools.mcp impo",
          "created_at": "2025-05-27T14:26:59Z"
        },
        {
          "author": "andreiionut1411",
          "body": "This is just a small example, but basically for every agent you can't see the tool response",
          "created_at": "2025-05-27T14:27:48Z"
        }
      ]
    },
    {
      "issue_number": 3261,
      "title": "[Bug] Custom role maps",
      "body": "### Description\n\nAs it stands, using the OpenAI library with OpenAI-like endpoints will trigger an error related to the unsupported \"developer\" role. Since most models use \"system\" for roles, we should allow custom role mappings to avoid such errors.\n\n### Steps to Reproduce\n\n1. Configure 03_agent_with_knowledge.py to use a different base url and model.\n2. Execute:\n\n```\n(agno) (agno-env) alberto@barrahome:~/Projects/agno$ python cookbook/getting_started/03_agent_with_knowledge.py\nINFO Loading knowledge base                                                                                                                                                         \nINFO Reading: .............                                                                   \nINFO Skipped 2 existing/duplicate documents.                                                                                                                                        \nINFO Added 0 documents to knowledge base                                                                                                                                            \nERROR    API status error from OpenAI API: Error code: 400 - {'object': 'error', 'message': '1 validation error for ChatCompletionRequest\\nmessages.0\\n  Input tag \\'developer\\'    \n         found using \\'role\\' does not match any of the expected tags: <Roles.system: \\'system\\'>, <Roles.user: \\'user\\'>, <Roles.assistant: \\'assistant\\'>, <Roles.tool: \\'tool\\'> \n         [type=union_tag_invalid, input_value={\\'content\\': \"<instruction...>\", \\'role\\': \\'developer\\'}, input_type=dict]\\n    For further information visit                       \n         https://errors.pydantic.dev/2.10/v/union_tag_invalid', 'type': 'BadRequestError', 'param': None, 'code': 400}                                                              \n▰▰▱▱▱▱▱ Thinking...\n```\n\n### Agent Configuration (if applicable)\n\n```python\n    model=OpenAIChat(\n        id=\"mistralai/Mistral-Small-24B-Instruct-2501\", \n        base_url=\"https://........../v1\", \n        api_key=\"........\"\n    ),\n\n    embedder=OpenAIEmbedder(\n        id=\"mixedbread-ai/mxbai-embed-large-v1\",\n        base_url=\"https://......\",\n        api_key=\"..........\"\n    ),\n` ``\n\n### Expected Behavior\n\nThe agent to run.         \n\n### Actual Behavior\n\nCrashes\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nOS: Ubuntu 24.04 noble\n Kernel: x86_64 Linux 6.9.12-060912-generic\n Shell: bash\n Disk: 863G / 1.8T (50%)\n CPU: AMD Ryzen 9 7900X 12-Core @ 24x 5.733GHz\n GPU: NVIDIA RTX A6000, NVIDIA GeForce RTX 3060\n RAM: 14195MiB / 128408MiB\n```\n\n### Possible Solutions (optional)\n\nImplement a custom role if not present then fallback to default, IE:\n\n*libs/agno/agno/models/openai/chat.py*\nReplace role_map with something like:\n```python\n    default_role_map = {\n        \"system\": \"developer\",\n        \"user\": \"user\",\n        \"assistant\": \"assistant\",\n        \"tool\": \"tool\",\n        \"model\": \"assistant\",\n    }\n```\n\nThen on the ```_format_message``` we implement the following:\n\n```python\nrole_mapping = self.role_map if self.role_map is not None else self.default_role_map\n```\n\nThen when we do the call:\n\n```python\nagent = Agent(\n    model=OpenAIChat(\n        id=\"mistralai/Mistral-Small-24B-Instruct-2501\", \n        base_url=\"https://...../v1\", \n        api_key=\"......\",\n\n        role_map={\n            \"system\": \"system\",      # Maps internal \"system\" role to API's \"system\" role\n            \"user\": \"user\",          # Maps internal \"user\" role to API's \"user\" role\n            \"assistant\": \"assistant\", # Maps internal \"assistant\" role to API's \"assistant\" role\n            \"tool\": \"tool\",          # Maps internal \"tool\" role to API's \"tool\" role\n            \"model\": \"assistant\",    # Maps internal \"model\" role to API's \"assistant\" role\n            \"developer\": \"system\",   # Maps \"developer\" role to \"system\" role in the API\n            \"expert\": \"assistant\"    # Maps \"expert\" role to \"assistant\" role in the API\n        }\n    ),\n```\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "bet0x",
      "author_type": "User",
      "created_at": "2025-05-20T19:41:30Z",
      "updated_at": "2025-05-27T13:58:23Z",
      "closed_at": "2025-05-27T13:58:21Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3261/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3261",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3261",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:20.629637",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-238/bug-custom-role-maps\">SUPPORT-238 [Bug] Custom role maps</a></p>",
          "created_at": "2025-05-20T19:41:33Z"
        },
        {
          "author": "manuhortet",
          "body": "Hey @bet0x, thank you for reporting this. You are right and your proposed solution is great! \n\nI opened a PR fixing this: https://github.com/agno-agi/agno/pull/3355. We will try to release it asap. \n\nThanks again for putting in the time!",
          "created_at": "2025-05-26T09:38:51Z"
        },
        {
          "author": "dirkbrnd",
          "body": "This was released with 1.5.5!",
          "created_at": "2025-05-27T13:58:21Z"
        }
      ]
    },
    {
      "issue_number": 3259,
      "title": "[Bug] sanitize_arguments = True considered harmful",
      "body": "### Description\n\nA function call has the default setting of `sanitize_arguments` being set to `True`. This being set will cause arguments to tool functions be changed so that:\n\n- \"None\" becomes \"null\"\n- \"True\" becomes \"true\"\n- \"False\" becomes \"false\"\n\nI cannot come up with a case where I would want arguments for a tool call from an  LLM to be mangled in this way, but many cases where it will in fact cause issues. Case in point: One of my tools updates a file, and this default setting meant it actually changed the code. I don't know the rationale for this to begin with so I won't argue for it's total removal, but at the very least it should not be the default.  \n\n### Steps to Reproduce\n\nSee description\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nNot for the framework to butcher the LLM output.\n\n### Actual Behavior\n\nIt does.\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nLatest master as of the time of the report.\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "nilnor",
      "author_type": "User",
      "created_at": "2025-05-20T16:48:17Z",
      "updated_at": "2025-05-27T13:14:58Z",
      "closed_at": "2025-05-27T10:37:19Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3259/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3259",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3259",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:20.848145",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-237/bug-sanitize-arguments-=-true-considered-harmful\">SUPPORT-237 [Bug] sanitize_arguments = True considered harmful</a></p>",
          "created_at": "2025-05-20T16:48:19Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@nilnor I can see how this could produce results that are not desired. Do you use the tool decorator for your custom functions? ",
          "created_at": "2025-05-26T12:32:08Z"
        },
        {
          "author": "nilnor",
          "body": "@dirkbrnd I do not, I use a class based approach to tools and wrap their execution. I do some custom stuff with agno.tools.tool now to pass the flag for every tool so it's not an immediate concern for me, but it's just a default I cannot fathom the reasoning behind and one that means you will spend ",
          "created_at": "2025-05-26T17:19:18Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@nilnor you are right. I have a fix to remove this and handle it properly. The original reason for it is to sanitize invalid JSON that comes from the model, which can happen. But as you mentioned, it has other adverse effects",
          "created_at": "2025-05-26T20:48:20Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Fixed with [1.5.5](https://github.com/agno-agi/agno/releases/tag/v1.5.5)!",
          "created_at": "2025-05-27T10:37:19Z"
        }
      ]
    },
    {
      "issue_number": 3373,
      "title": "MLFLow autologging for Observability",
      "body": "### Problem Description\n\nCan you please add mlflow integration for Agent tracing/observability? Thanks!\n\n### Proposed Solution\n\nImplement mlflow autologging for agno Agents tracing/observability\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [x] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "cv-mg",
      "author_type": "User",
      "created_at": "2025-05-27T12:27:31Z",
      "updated_at": "2025-05-27T12:39:00Z",
      "closed_at": "2025-05-27T12:38:58Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3373/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3373",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3373",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:21.055110",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-327/mlflow-integration-for-observability\">SUPPORT-327 MLFLow Integration for Observability</a></p>",
          "created_at": "2025-05-27T12:27:34Z"
        },
        {
          "author": "cv-mg",
          "body": "Probably better to request this on mlflow project than there.",
          "created_at": "2025-05-27T12:38:58Z"
        }
      ]
    },
    {
      "issue_number": 3338,
      "title": "[Bug] FalTools object has No attribute called functions",
      "body": "### Description\n\nDEBUG ********************************************************** Agent ID: 8172e58d-d169-4693-9694-c31038396ca7 *********************************************************\nDEBUG ********************************************************* Session ID: c9bba4a5-e31e-419d-98ba-2298606714e0 ********************************************************\n▰▱▱▱▱▱▱ Thinking...\n┏━ Message ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                                                                                                                                     ┃\n┃ Generate image of a balloon in the ocean                                                                                                                                            ┃\n┃                                                                                                                                                                                     ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n```\nTraceback (most recent call last):\n  File \"/Users/naidu/codebase/experiment/agents/story/fal_test.py\", line 20, in <module>\n    fal_agent.print_response(\"Generate image of a balloon in the ocean\")\n  File \"/Users/naidu/codebase/experiment/agents/story/.venv311/lib/python3.12/site-packages/agno/agent/agent.py\", line 6433, in print_response\n    run_response = self.run(\n                   ^^^^^^^^^\n  File \"/Users/naidu/codebase/experiment/agents/story/.venv311/lib/python3.12/site-packages/agno/agent/agent.py\", line 899, in run\n    self.determine_tools_for_model(\n  File \"/Users/naidu/codebase/experiment/agents/story/.venv311/lib/python3.12/site-packages/agno/agent/agent.py\", line 3348, in determine_tools_for_model\n    agent_tools = self.get_tools(\n                  ^^^^^^^^^^^^^^^\n  File \"/Users/naidu/codebase/experiment/agents/story/.venv311/lib/python3.12/site-packages/agno/agent/agent.py\", line 3293, in get_tools\n    self._raise_if_async_tools()\n  File \"/Users/naidu/codebase/experiment/agents/story/.venv311/lib/python3.12/site-packages/agno/agent/agent.py\", line 3261, in _raise_if_async_tools\n    for func in tool.functions:\n                ^^^^^^^^^^^^^^\nAttributeError: 'FalTools' object has no attribute 'functions'\n```\n\n### Steps to Reproduce\n\n```\nfrom agno.agent import Agent\nfrom agno.models.openai import OpenAIChat\nfrom agno.tools.fal import FalTools\n\nfal_agent = Agent(\n    name=\"Fal Image Generator Agent\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[FalTools(\"fal-ai/flux-schnell\")],\n    description=\"You are an AI agent that can generate images using the Fal API.\",\n    instructions=[\n        \"When the user asks you to create an image, use the `generate_media` tool to create the image.\",\n        \"Return the URL as raw to the user.\",\n        \"Don't convert image URL to markdown or anything else.\",\n    ],\n    markdown=True,\n    debug_mode=True,\n    show_tool_calls=True,\n)\n\nfal_agent.print_response(\"Generate image of a balloon in the ocean\")\n```\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nWe should be able to make call to faltools and generate images\n\n### Actual Behavior\n\nError with \n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nAgno - 1.5.4\nMacOS\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "naiduasn",
      "author_type": "User",
      "created_at": "2025-05-24T18:29:22Z",
      "updated_at": "2025-05-27T10:38:56Z",
      "closed_at": "2025-05-27T10:38:55Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3338/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3338",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3338",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:21.224622",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-299/bug-faltools-object-has-no-attribute-called-functions\">SUPPORT-299 [Bug] FalTools object has No attribute called functions</a></p>",
          "created_at": "2025-05-24T18:29:25Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@naiduasn apologies, this will be fixed asap!",
          "created_at": "2025-05-26T09:38:02Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Fixed with [1.5.5](https://github.com/agno-agi/agno/releases/tag/v1.5.5)!",
          "created_at": "2025-05-27T10:38:55Z"
        }
      ]
    },
    {
      "issue_number": 3282,
      "title": "[Feature Request] Add timeout to Exa",
      "body": "### Problem Description\n\nExa search sometimes hangs indefinitely. We should add a `timeout` to all the Exa functions.\n\n### Proposed Solution\n\nWe should add a `timeout` to all the Exa functions\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [x] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "arsaboo",
      "author_type": "User",
      "created_at": "2025-05-21T23:02:22Z",
      "updated_at": "2025-05-27T10:38:09Z",
      "closed_at": "2025-05-26T10:56:09Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3282/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3282",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3282",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:21.444408",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-251/feature-request-add-timeout-to-exa\">SUPPORT-251 [Feature Request] Add timeout to Exa</a></p>",
          "created_at": "2025-05-21T23:02:24Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Merged! Will release asap",
          "created_at": "2025-05-26T10:56:09Z"
        },
        {
          "author": "arsaboo",
          "body": "Thanks @dirkbrnd for the quick fix!",
          "created_at": "2025-05-26T13:57:08Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Fixed with [1.5.5](https://github.com/agno-agi/agno/releases/tag/v1.5.5)!",
          "created_at": "2025-05-27T10:38:08Z"
        }
      ]
    },
    {
      "issue_number": 3331,
      "title": "[Bug]  AttributeError: 'InferenceClient' object has no attribute 'post' on HuggingfaceCustomEmbedder",
      "body": "### Description\n\nWhen attempting to initialize and use HuggingfaceCustomEmbedder, an AttributeError is raised:\n`AttributeError: 'InferenceClient' object has no attribute 'post'`\n\nThis error suggests that HuggingfaceCustomEmbedder attempts to call a .post() method on an instance of InferenceClient, which does not exist in the current version of the huggingface_hub package.\n\n### Steps to Reproduce\n\n1. Install dependencies from agno-ai.\n2. Set up a valid Hugging Face API token and MongoDB URI.\n3. Use the following code to initialize the embedder and vector DB:\n\n```\nembedder = HuggingfaceCustomEmbedder(\n    api_key=token\n)\n\nvector_db = MongoDb(\n    collection_name='recipes',\n    db_url=mongo_uri,\n    wait_until_index_ready_in_seconds=60,\n    wait_after_insert_in_seconds=300,\n    embedder=embedder\n)\n\nknowledge_base = JSONKnowledgeBase(\n    path='./data.json',\n    vector_db=vector_db\n)\n```\n4. Run the code and observe the error:\n`AttributeError: 'InferenceClient' object has no attribute 'post'`\n\n### Agent Configuration (if applicable)\n\n```\nmodel = OpenRouter(\n  api_key=open_route_key,\n  id='xxxxxx'\n)\n\nagent = Agent(\n  knowledge=knowledge_base,\n  search_knowledge=True,\n  model=model\n)\n```\n\n### Expected Behavior\n\nThe embedder should correctly interface with the Hugging Face inference API, and not attempt to call non-existent methods on InferenceClient.\n\n### Actual Behavior\n\nHuggingfaceCustomEmbedder attempts to call .post() on InferenceClient, resulting in an AttributeError.\n\n### Screenshots or Logs (if applicable)\n\n```\nTraceback (most recent call last):\n  File \"/project/vector_test.py\", line 46, in <module>\n    agent.knowledge.load(recreate=False)\n  File \"/project/.venv/lib/python3.12/site-packages/agno/knowledge/agent.py\", line 135, in load\n    self.vector_db.insert(documents=documents_to_load, filters=doc.meta_data)\n  File \"/project/.venv/lib/python3.12/site-packages/agno/vectordb/mongodb/mongodb.py\", line 481, in insert\n    doc_data = self.prepare_doc(document, filters)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/project/.venv/lib/python3.12/site-packages/agno/vectordb/mongodb/mongodb.py\", line 724, in prepare_doc\n    document.embed(embedder=self.embedder)\n  File \"/project/.venv/lib/python3.12/site-packages/agno/document/base.py\", line 27, in embed\n    self.embedding, self.usage = _embedder.get_embedding_and_usage(self.content)\n                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/project/.venv/lib/python3.12/site-packages/agno/embedder/huggingface.py\", line 52, in get_embedding_and_usage\n    return self.get_embedding(text=text), None\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/project/.venv/lib/python3.12/site-packages/agno/embedder/huggingface.py\", line 42, in get_embedding\n    response = self._response(text=text)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/project/.venv/lib/python3.12/site-packages/agno/embedder/huggingface.py\", line 39, in _response\n    return self.client.post(json={\"inputs\": text}, model=self.id, task=self.task)\n           ^^^^^^^^^^^^^^^^\nAttributeError: 'InferenceClient' object has no attribute 'post'\n```\n\n### Environment\n\n```markdown\nOS: WSL Ubuntu 24 (Run on Windows 11)\nPython Version: 3.12\nAgno Version: 1.5.2\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "lazuardi100",
      "author_type": "User",
      "created_at": "2025-05-23T15:14:26Z",
      "updated_at": "2025-05-27T10:38:02Z",
      "closed_at": "2025-05-27T10:38:01Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 15,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3331/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3331",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3331",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:21.635641",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-295/bug-attributeerror-inferenceclient-object-has-no-attribute-post-on\">SUPPORT-295 [Bug] AttributeError: 'InferenceClient' object has no attribute 'post' on HuggingfaceCustomEmbedder</a></p>",
          "created_at": "2025-05-23T15:14:29Z"
        },
        {
          "author": "omsite45",
          "body": "@linear We dont have access to this link getting below error:\n\n![Image](https://github.com/user-attachments/assets/63f1271d-447c-411c-9c52-763cb03b7ab1)",
          "created_at": "2025-05-25T06:26:57Z"
        },
        {
          "author": "omsite45",
          "body": "Hi All,  I am getting below error:\n\n![Image](https://github.com/user-attachments/assets/d7d93f48-328a-403a-93ae-3650fc149957)",
          "created_at": "2025-05-25T06:27:46Z"
        },
        {
          "author": "kausmeows",
          "body": "> [@linear](https://github.com/linear) We dont have access to this link getting below error:\n> \n> ![Image](https://github.com/user-attachments/assets/63f1271d-447c-411c-9c52-763cb03b7ab1)\n\nHi @omsite45 that is an auto linear ticket generation for tracking support internally. So its meant for the use",
          "created_at": "2025-05-26T11:01:46Z"
        },
        {
          "author": "kausmeows",
          "body": "Thanks for raising this @lazuardi100 @omsite45 , i've a PR out to fix this- https://github.com/agno-agi/agno/pull/3357\nShould be released soon",
          "created_at": "2025-05-26T11:02:06Z"
        }
      ]
    },
    {
      "issue_number": 3284,
      "title": "[Bug] empty response from gemini-2.5-flash-preview-05-20",
      "body": "### Description\n\nWhen using the new Gemini Flash Preview model (gemini-2.5-flash-preview-05-20), the agent returns an empty response. Downgrading to the previous preview version (04-17) resolves the issue, responses are generated as expected.\n\n### Steps to Reproduce\n\nJust running regular agent via fast api and using gemini-2.5-flash-preview-05-20 model\n\n### Agent Configuration (if applicable)\n\ndef get_cookmaster_agent(\n    user_id: Optional[str] = None,\n    session_id: Optional[str] = None,\n    debug_mode: bool = True,\n) -> Agent:\n    extra = f\"<context>User: {user_id}</context>\" if user_id else \"\"\n    return Agent(\n        name=\"CookMaster Chat\",\n        agent_id=\"cookmaster-chat\",\n        session_id=session_id,\n        user_id=user_id,\n        model=Gemini(id=\"gemini-2.5-flash-preview-05-20\"),\n        use_json_mode=True,\n        tools=[\n            GoogleSearchTools(),\n            Newspaper4kTools(),\n            ThinkingTools(add_instructions=True),\n        ],\n\n### Expected Behavior\n\nNo response\n\n### Actual Behavior\n\nNo response\n\n### Screenshots or Logs (if applicable)\n\n![Image](https://github.com/user-attachments/assets/1874bc29-345b-4caf-a452-8f2e292f3aea)\n\n### Environment\n\n```markdown\nAgno 1.5.3\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "isikepalaku",
      "author_type": "User",
      "created_at": "2025-05-22T01:03:48Z",
      "updated_at": "2025-05-27T10:37:49Z",
      "closed_at": "2025-05-27T10:37:48Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3284/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3284",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3284",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:21.843495",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-252/bug-empty-response-from-gemini-25-flash-preview-05-20\">SUPPORT-252 [Bug] empty response from gemini-2.5-flash-preview-05-20</a></p>",
          "created_at": "2025-05-22T01:03:51Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @isikepalaku \nI am unable to reproduce this on both versions of Gemini. It could be that it was an issue they resolved? Can you confirm you are still facing? What version of `google-genai` library do you have installed? ",
          "created_at": "2025-05-26T11:14:29Z"
        },
        {
          "author": "isikepalaku",
          "body": "> Hi @isikepalaku \n> I am unable to reproduce this on both versions of Gemini. It could be that it was an issue they resolved? Can you confirm you are still facing? What version of `google-genai` library do you have installed? \n\nThe problem same as this langchain  repo project [https://github.com/la",
          "created_at": "2025-05-26T11:39:40Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@isikepalaku that links to this current issue. Could you confirm whether you are still facing this issue on the latest version of Agno and latest version of `google-genai`? \n",
          "created_at": "2025-05-26T12:12:01Z"
        },
        {
          "author": "isikepalaku",
          "body": "> [@isikepalaku](https://github.com/isikepalaku) that links to this current issue. Could you confirm whether you are still facing this issue on the latest version of Agno and latest version of `google-genai`?\n\nsorry, i have update to latest google-genai i think its now working fine",
          "created_at": "2025-05-26T16:18:25Z"
        }
      ]
    },
    {
      "issue_number": 3291,
      "title": "[Bug] `tool_choice` results in endless loop.",
      "body": "### Description\n\nI am working with the DuckDBTools and an agent. If I set tool_choice to 'required' or use `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}`, the tool gets called repeatedly without exiting.\n\nAdditionally - is there a way to set more than one required tool in `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` ?\n\n### Steps to Reproduce\n\n1. Set up the duck db tools\n```\nfrom agno.tools.duckdb import DuckDbTools\n\nduckdb_tools = DuckDbTools(\n    init_commands=[\"SHOW TABLES\"],\n    run_queries=False,\n    )\n``` \n\n2. Dummy agent:\n```\nfrom agno.agent import Agent, RunResponse\n\nrewriter = Agent(\n    model=OpenAIChat(),\n    tools=[duckdb_tools],\n    show_tool_calls=True,\n    tool_call_limit=5,\n    tool_choice={\"type\": \"function\", \"function\": {\"name\": \"show_tables\"}},\n    name=\"Test\",\n    instructions=\"Rewrite my initial message using the tool context\"\n)\n```\n3. Result:\n```\nIn [62]: res = rewriter.run(\"What is the average age of the people in my dataset?\")\nINFO Running: SHOW TABLES                                                                                                                                  \nINFO Running: SHOW TABLES                                                                                                                                  \nINFO Running: SHOW TABLES                                                                                                                                  \nINFO Running: SHOW TABLES                                                                                                                                  \nINFO Running: SHOW TABLES                                                                                                                                  \nINFO Running: SHOW TABLES                                                                                                                                  \nINFO Running: SHOW TABLES                                                                                                                                  \nINFO Running: SHOW TABLES                                                                                                                                  \nINFO Running: SHOW TABLES                                                                                                                                  \nINFO Running: SHOW TABLES                                                                                                                                  \nINFO Running: SHOW TABLES                                                                                                                                  \nINFO Running: SHOW TABLES                                                                                                                                  \nINFO Running: SHOW TABLES                                                                                                                                  \nINFO Running: SHOW TABLES                                                                                                                                  \nINFO Running: SHOW TABLES                                                                                                                                  \nINFO Running: SHOW TABLES                                                                                                                                  \nINFO Running: SHOW TABLES                                                                                                                                  \nINFO Running: SHOW TABLES                                                                                                                                  \nINFO Running: SHOW TABLES                                                                                                                                  \nINFO Running: SHOW TABLES   \n```\n\n### Agent Configuration (if applicable)\n\nSee above\n\n### Expected Behavior\n\nMake a few tool calls and then exit.\n\n### Actual Behavior\n\nCalls the tool indefinitely (see above)\n\n### Screenshots or Logs (if applicable)\n\nSee above.\n\n### Environment\n\n```markdown\n- OS: MacBook Pro\n- agno>=1.5.0\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "sebastian-montero",
      "author_type": "User",
      "created_at": "2025-05-22T10:45:40Z",
      "updated_at": "2025-05-27T10:37:13Z",
      "closed_at": "2025-05-27T10:37:00Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3291/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3291",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3291",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:22.052246",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-265/bug-tool-choice-results-in-endless-loop\">SUPPORT-265 [Bug] `tool_choice` results in endless loop.</a></p>",
          "created_at": "2025-05-22T10:45:43Z"
        },
        {
          "author": "kausmeows",
          "body": "Hey @sebastian-montero if inside any Tool you want to set specifically which tool functions to include or exclude you can try using `include_tools` or `exclude_tools`. More context here- https://docs.agno.com/tools/selecting-tools#example\n\nSo basically you do not need to do \n```py\ninit_commands=[\"SH",
          "created_at": "2025-05-26T10:29:42Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@sebastian-montero So the flow of the model inside the agent is:\n1. The initial prompt is provided to the model and in the case where it has a required tool it will call that tool.\n2. We then execute the tool\n3. We provide the result to the model, but the same parameters are used as in the first too",
          "created_at": "2025-05-26T14:44:45Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Please let us know if you want to re-open this.",
          "created_at": "2025-05-27T10:37:12Z"
        }
      ]
    },
    {
      "issue_number": 3304,
      "title": "[Bug] Gemini model does not handle empty responses",
      "body": "### Description\n\nGemini sometimes respond without any actionable content (HTTP level debug below):\n\n```\n2025-05-22 20:45:07,481 - __main__ - INFO - <= AI RESPONSE BODY: data: {\"candidates\": [{\"content\": {\"role\": \"model\"},\"finishReason\": \"STOP\",\"index\": 0}],\"usageMetadata\": {\"promptTo\nkenCount\": 16425,\"totalTokenCount\": 16425,\"cachedContentTokenCount\": 13947,\"promptTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\": 16425}],\"cacheTokensDetails\": [{\"modality\": \"TE\nXT\",\"tokenCount\": 13947}]},\"modelVersion\": \"models/gemini-2.5-pro-preview-05-06\"}\n```\n\nWhen this happens the next run will fail since agno will send an empty parts for the model, debug below:\n\n```\n  {\n    \"parts\": [],\n    \"role\": \"model\"\n  },\n```\n\nThis will cause the following error when trying to continue the run:\n\n```\nError from Gemini API: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': '* GenerateContentRequest.contents[7].parts: contents.parts must not be empty.\\n',\n         'status': 'INVALID_ARGUMENT'}}\n```\n\n\n\n### Steps to Reproduce\n\nEh, use the Gemini model until this happens and try to continue.\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nIt continues\n\n### Actual Behavior\n\nIt fails\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nThis is with gemini-2.5-pro-preview-05-06\n```\n\n### Possible Solutions (optional)\n\nFilter out any empty messages/parts\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "nilnor",
      "author_type": "User",
      "created_at": "2025-05-22T19:02:18Z",
      "updated_at": "2025-05-27T10:36:49Z",
      "closed_at": "2025-05-27T10:36:48Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3304/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3304",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3304",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:22.304356",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-270/bug-gemini-model-does-not-handle-empty-responses\">SUPPORT-270 [Bug] Gemini model does not handle empty responses</a></p>",
          "created_at": "2025-05-22T19:02:21Z"
        },
        {
          "author": "nilnor",
          "body": "FYI: I've locally patched the Gemini model to skip these and with that one can continue (e.g. prompt = \"continue\"), but it seems better if these could be filtered out in a more central location. \n",
          "created_at": "2025-05-22T19:34:57Z"
        },
        {
          "author": "wildchron",
          "body": "I am having the same problem multiple times now.",
          "created_at": "2025-05-23T13:32:29Z"
        },
        {
          "author": "dirkbrnd",
          "body": "This will be released today with 1.5.5",
          "created_at": "2025-05-26T15:11:29Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Fixed with [1.5.5](https://github.com/agno-agi/agno/releases/tag/v1.5.5)!",
          "created_at": "2025-05-27T10:36:48Z"
        }
      ]
    },
    {
      "issue_number": 2850,
      "title": "[Bug] Agno causes False in generated Python code sent to MCP calls to always become lowercase false",
      "body": "# Description\nI cannot use Agno with filesystem MCPs to write Python source code because the constant False always becomes false when written to disk. I have confirmed this is not a model / MCP problem, as the combination model and MCP work correctly with Claude Desktop. I have also confirmed that this is not unconditional lower case in the generated source code, only certain tokens are affected.\n\n## Steps to Reproduce\nCreate a small Agno agent with the stock filesystem MCP from the official repo. Edit the paths as necessary:\n\n```\nimport asyncio\nimport sys\nfrom typing import Union\nfrom urllib.parse import quote\n\nimport click\nfrom agno.agent import Agent\nfrom agno.api.playground import PlaygroundEndpointCreate, create_playground_endpoint\nfrom agno.cli.console import console\nfrom agno.cli.settings import agno_cli_settings\nfrom agno.tools.mcp import MCPTools\nfrom agno.utils.log import logger\nfrom fastapi import FastAPI\nfrom rich import box\nfrom rich.panel import Panel\n\n\nasync def serve_playground_app_async(\n    app: Union[str, FastAPI],\n    *,\n    scheme: str = \"http\",\n    host: str = \"localhost\",\n    port: int = 7777,\n    reload: bool = False,\n    prefix=\"/v1\",\n    **kwargs,\n):\n    import uvicorn\n\n    try:\n        create_playground_endpoint(\n            playground=PlaygroundEndpointCreate(\n                endpoint=f\"{scheme}://{host}:{port}\", playground_data={\"prefix\": prefix}\n            ),\n        )\n    except Exception as e:\n        logger.error(f\"Could not create playground endpoint: {e}\")\n        logger.error(\"Please try again.\")\n        return\n\n    logger.info(f\"Starting playground on {scheme}://{host}:{port}\")\n    # Encode the full endpoint (host:port)\n    encoded_endpoint = quote(f\"{host}:{port}\")\n\n    # Create a panel with the playground URL\n    url = f\"{agno_cli_settings.playground_url}?endpoint={encoded_endpoint}\"\n    panel = Panel(\n        f\"[bold green]Playground URL:[/bold green] [link={url}]{url}[/link]\",\n        title=\"Agent Playground\",\n        expand=False,\n        border_style=\"cyan\",\n        box=box.HEAVY,\n        padding=(2, 2),\n    )\n\n    # Print the panel\n    console.print(panel)\n\n    config = uvicorn.Config(app=app, host=host, port=port, reload=reload, **kwargs)\n    server = uvicorn.Server(config)\n    await server.serve()\n\n\nasync def main(hello_world: bool = False):\n    async with MCPTools(f\"npx -y /Users/ezyang/Dev/mcp-servers/src/filesystem /Users/ezyang/Dev/ghninja-mobile\") as codemcp:\n        # TODO: cli-ify the model\n        from agno.models.anthropic import Claude\n\n        # from agno.models.google import Gemini\n        agent = Agent(\n            model=Claude(id=\"claude-3-7-sonnet-20250219\"),\n            # model=Gemini(id=\"gemini-2.5-pro-exp-03-25\"),\n            tools=[codemcp],\n            instructions=\"\",\n            markdown=True,\n            show_tool_calls=True,\n        )\n\n        # If --hello-world flag is used, run the short-circuited response and return\n        if hello_world:\n            await agent.aprint_response(\n                \"What tools do you have?\",\n                stream=True,\n                show_full_reasoning=True,\n                stream_intermediate_steps=True,\n            )\n            return\n\n        # Comment out the playground code\n        # playground = Playground(agents=[agent]).get_app()\n        # await serve_playground_app_async(playground)\n\n        # Replace with a simple async loop for stdin input\n        print(\"Enter your query (Ctrl+C to exit):\")\n        while True:\n            try:\n                # Use asyncio to read from stdin in an async-friendly way\n                loop = asyncio.get_event_loop()\n                user_input = await loop.run_in_executor(None, lambda: input(\"> \"))\n\n                # Properly await the async print_response method\n                await agent.aprint_response(\n                    user_input,\n                    stream=True,\n                    show_full_reasoning=True,\n                    stream_intermediate_steps=True,\n                )\n            except KeyboardInterrupt:\n                print(\"\\nExiting...\")\n                break\n\n\n@click.command()\n@click.option(\n    \"--hello-world\", is_flag=True, help=\"Run a simple test query to see available tools\"\n)\ndef cli(hello_world: bool = False):\n    \"\"\"CLI for the Agno agent with CodeMCP integration.\"\"\"\n    from agno.debug import enable_debug_mode\n\n    enable_debug_mode()\n    import logging\n\n    logging.basicConfig(level=logging.DEBUG)\n    logging.getLogger(\"httpx\").setLevel(logging.DEBUG)  # For HTTP logging\n    logging.getLogger(\"anthropic\").setLevel(logging.DEBUG)\n    logging.getLogger(\"google_genai\").setLevel(logging.DEBUG)\n\n    asyncio.run(main(hello_world=hello_world))\n\n\nif __name__ == \"__main__\":\n    cli()\n\n```\n\nRun this (once again, can adjust path)\n\n```\necho \"Write a file /Users/ezyang/Dev/ghninja-mobile/foo4.py with a Python function that always returns False\" | python -m file.py\n```\n\nInspect the output file:\n\n```\ndef always_false():\n    \"\"\"\n    A function that always returns false.\n    \n    Returns:\n        bool: Always returns false\n    \"\"\"\n    return false\n```\n\nThe token false is always lower case.\n\n## Environment\n- OS: macOS\n- Agno Version: 1.2.16\n- Additional Environment Details: Python 3.12.9",
      "state": "closed",
      "author": "ezyang",
      "author_type": "User",
      "created_at": "2025-04-16T13:59:01Z",
      "updated_at": "2025-05-27T10:36:38Z",
      "closed_at": "2025-05-27T10:36:37Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2850/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2850",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2850",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:22.508499",
      "comments": [
        {
          "author": "pritipsingh",
          "body": "Hey @ezyang thanks for letting us know- we'll have this fixed soon! If you'd like to contribute - please let me know- it would be similar to something like this: https://github.com/agno-agi/agno/pull/2823",
          "created_at": "2025-04-24T17:56:58Z"
        },
        {
          "author": "ezyang",
          "body": "Tbh I haven't the foggiest how this could be happening ",
          "created_at": "2025-04-25T04:37:58Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-05-26T00:35:43Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@ezyang Working on a fix!",
          "created_at": "2025-05-26T20:44:50Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Fixed with [1.5.5](https://github.com/agno-agi/agno/releases/tag/v1.5.5)!",
          "created_at": "2025-05-27T10:36:37Z"
        }
      ]
    },
    {
      "issue_number": 3362,
      "title": "[Bug]",
      "body": "### Description\n\nWhen using the embedder from huggingface_hub, if it is not installed, the user sees an error message:\nhuggingface-hub not installed, please run pip install huggingface-hub.\n\nExecuting this command installs version 0.31.2 of the library, which lacks the post method, leading to embedding generation errors.\n\nFix #3190 \n\n### Steps to Reproduce\n\n1. Install agno and huggingface-hub\n2. Use some hf embedding model\n\n```\nfrom agno.embedder.huggingface import HuggingfaceCustomEmbedder\n\n# Embed sentence in database\nembeddings = HuggingfaceCustomEmbedder(model=\"BAAI/bge-m3\").get_embedding(\"The quick brown fox jumps over the lazy dog.\")\n```\n\n3. See error if hf_hub installed > 0.30.2\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nrun pip install huggingface-hub and no errors\n\n### Actual Behavior\n\nWhen using the embedder from huggingface_hub, if it is not installed, the user sees an error message:\nhuggingface-hub not installed, please run pip install huggingface-hub.\n\nExecuting this command installs version 0.31.2 of the library, which lacks the post method, leading to embedding generation errors.\n\nFix #3190 \n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nWin11\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "versus666jzx",
      "author_type": "User",
      "created_at": "2025-05-26T19:43:00Z",
      "updated_at": "2025-05-27T10:36:29Z",
      "closed_at": "2025-05-27T10:36:28Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3362/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3362",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3362",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:22.717653",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-324/bug\">SUPPORT-324 [Bug]</a></p>",
          "created_at": "2025-05-26T19:43:04Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @versus666jzx \nWe have a fix coming for this!",
          "created_at": "2025-05-26T20:52:12Z"
        },
        {
          "author": "versus666jzx",
          "body": "Hi @dirkbrnd \nIn main branch?\n\nagno  v1.5.4\nhuggingface-hub  v0.32.1\n\nWhen i try do \n\n```\nfrom agno.agent import Agent\nfrom agno.embedder.huggingface import HuggingfaceCustomEmbedder\nfrom agno.knowledge.website import WebsiteKnowledgeBase\nfrom agno.models.openrouter import OpenRouter\nfrom agno.vecto",
          "created_at": "2025-05-26T21:13:20Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Fixed with [1.5.5](https://github.com/agno-agi/agno/releases/tag/v1.5.5)!",
          "created_at": "2025-05-27T10:36:28Z"
        }
      ]
    },
    {
      "issue_number": 3366,
      "title": "[Bug] ReasoningTools instructions cannot be normally added to the system prompt",
      "body": "### Description\n\nWhile learning from the official documentation, I found that when ReasoningTools enables `add_few_shot=True` and `add_instructions=True`, its instructions are not properly appended to the system prompt.\n\n### Steps to Reproduce\n\n\n```python\nimport asyncio\n\nimport httpx\nfrom agno.agent import Agent\nfrom agno.models.deepseek import DeepSeek\nfrom agno.tools.duckduckgo import DuckDuckGoTools\nfrom agno.tools.reasoning import ReasoningTools\n\nfrom src.conf import settings\n\nagent = Agent(\n    model=DeepSeek(\n        id=\"deepseek-chat\",\n        base_url=settings.deepseek_base_url,\n        api_key=settings.deepseek_api_key,\n        http_client=httpx.Client(proxy=settings.proxy_url, verify=False),\n    ),\n    tools=[\n        ReasoningTools(add_instructions=True, add_few_shot=True),\n        DuckDuckGoTools(verify_ssl=False, proxy=settings.proxy_url_str),\n    ],\n    description=\"You are a helpful assistant.\",\n    add_datetime_to_instructions=True,\n    stream=True,\n    stream_intermediate_steps=True,\n    debug_mode=True,\n    markdown=True,\n    show_tool_calls=True,\n)\n\n\ndef main():\n    agent.print_response(\n        \"\"\"hello\"\"\",\n        stream=True,\n        show_full_reasoning=True,\n        stream_intermediate_steps=True,\n    )\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nReasoningTools instructions are normally added to the prompt\n\n### Actual Behavior\n\n![Image](https://github.com/user-attachments/assets/f1779fe2-150a-420c-ad4e-242e7ea6fbd3)\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n- OS: Windows 11\n- Agno Version: v1.5.4\n- Additional Environment Details: Python 3.12.6\n```\n\n### Possible Solutions (optional)\n\n`ReasoningTools.__init__` starts by storing `instructions` into `self`, but when calling `super().__init__`, it still passes the instructions parameter (None), thereby overwriting the original `self.instructions`.\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "mxp-xc",
      "author_type": "User",
      "created_at": "2025-05-27T02:08:53Z",
      "updated_at": "2025-05-27T10:35:25Z",
      "closed_at": "2025-05-27T10:35:25Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3366/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3366",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3366",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:22.939562",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-325/bug-reasoningtools-instructions-cannot-be-normally-added-to-the-system\">SUPPORT-325 [Bug] ReasoningTools instructions cannot be normally added to the system prompt</a></p>",
          "created_at": "2025-05-27T02:08:56Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Thanks for raising, small bug on our side. Fixing to release today!\n",
          "created_at": "2025-05-27T07:37:14Z"
        },
        {
          "author": "mxp-xc",
          "body": "> Thanks for raising, small bug on our side. Fixing to release today!\n\nI also found that `KnowledgeTools`,   `ThinkingTools`has the same problem. I think we may need to investigate the use of `instructions ` `Toolkit` to avoid any missed cases.",
          "created_at": "2025-05-27T08:04:24Z"
        },
        {
          "author": "dirkbrnd",
          "body": "I will fix those as well. We were incorrectly assigning the default\n",
          "created_at": "2025-05-27T08:59:16Z"
        },
        {
          "author": "mxp-xc",
          "body": "> I will fix those as well. We were incorrectly assigning the default\n\nThank you for your work.",
          "created_at": "2025-05-27T09:15:24Z"
        }
      ]
    },
    {
      "issue_number": 3112,
      "title": "[Feature Request] Support Openai extra_body params to custom Qwen3 thinking params",
      "body": "## Problem Description\nI want to use Qwen3, and I want to be able to set some parameters of it\n\n## Proposed Solution\nexample code:\n```python\ncompletion = client.chat.completions.create(\n    model=\"qwen-plus-2025-04-28\",  \n    messages=messages,\n    extra_body={\n        \"enable_thinking\": True,\n        \"thinking_budget\": 50\n        },\n    stream=True,\n)\n```\nor HTTP:\n```curl\ncurl -X POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions \\\n-H \"Authorization: Bearer $DASHSCOPE_API_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"model\": \"qwen-plus-2025-04-28\",\n    \"messages\": [\n        {\n            \"role\": \"user\", \n            \"content\": \"你是谁\"\n        }\n    ],\n    \"stream\": true,\n    \"stream_options\": {\n        \"include_usage\": true\n    },\n    \"enable_thinking\": true,\n    \"thinking_budget\": 50\n}'\n```\n\n\n## Alternatives Considered\nHave you found any workarounds or alternative solutions?\nShare other approaches you've tried or thought about.\n\n## Additional context\nI tried using the request_params parameter but it gives an error：\n```python\nERROR    Error from OpenAI API: AsyncCompletions.create() got an unexpected keyword argument 'enable_thinking'   \n```\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[ ] Yes, I’d love to work on it!**\n**[ ] I’m open to collaborating but need guidance.**\n**[ ] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "rednels",
      "author_type": "User",
      "created_at": "2025-05-07T07:02:31Z",
      "updated_at": "2025-05-27T01:37:14Z",
      "closed_at": "2025-05-12T13:29:51Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3112/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3112",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3112",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:23.159998",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @rednels ! Can you please try running the following code?\n\n```python\nfrom agno.agent import Agent\nfrom agno.models.openai import OpenAILike\n\nmodel = OpenAILike(id=\"qwen-plus-2025-04-28\", base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\", request_params={\"enable_thin",
          "created_at": "2025-05-07T19:29:26Z"
        },
        {
          "author": "rednels",
          "body": "Hi @ysolanky , I tried the above code, The following is the result of running：\n\n```python\nDEBUG ****** Agent ID: 2a3f71c8-49cc-4c12-887e-7fd49d37aade ******              \nDEBUG ***** Session ID: 3d4853ea-d86f-4ccb-9474-48a4013838fb *****              \nDEBUG ** Agent Run Start: 9be44c2d-9df4-4245-92a",
          "created_at": "2025-05-08T02:10:06Z"
        },
        {
          "author": "ysolanky",
          "body": "Thanks for sharing @rednels ! Looks like the endpoint `https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions` does not support the `enable_thinking ` param. You can also query it directly to confirm the same  ",
          "created_at": "2025-05-08T14:39:20Z"
        },
        {
          "author": "rednels",
          "body": "> Thanks for sharing [@rednels](https://github.com/rednels) ! Looks like the endpoint `https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions` does not support the `enable_thinking ` param. You can also query it directly to confirm the same\n\nHi, here is the document of it :\n[qwen documen",
          "created_at": "2025-05-09T05:53:49Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @rednels 😊\n\nThank you so much for reaching out and for your support for Agno — it truly means a lot to us. We’ve added your suggestion to our roadmap! \n\nLooking forward to building together!",
          "created_at": "2025-05-12T13:29:51Z"
        }
      ]
    },
    {
      "issue_number": 3157,
      "title": "[Bug]Getting exception when running agent a second time",
      "body": "# Description\nI have a simple agent that does web searches, I call it's run operation multiple times, but after the first i get an exception \n\n  _dict[\"citations\"] = self.citations.model_dump(exclude_none=True)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n         AttributeError: 'dict' object has no attribute 'model_dump'\n\n## Steps to Reproduce\nAgent using Gemini with internal search tool\n\n## Expected Behavior\nRun similar to previous iteration\n\n## Actual Behavior\nException\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- OS: windows 11\n- Agno Version: v1.4.6\n- Additional Environment Details: Python 3.13\n",
      "state": "closed",
      "author": "eri-rubin",
      "author_type": "User",
      "created_at": "2025-05-11T04:21:17Z",
      "updated_at": "2025-05-26T15:58:37Z",
      "closed_at": "2025-05-26T11:23:31Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3157/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3157",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3157",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:25.195135",
      "comments": [
        {
          "author": "dotannn",
          "body": "why did you close it? i'm experiencing the same issue with 1.4.6",
          "created_at": "2025-05-11T18:03:02Z"
        },
        {
          "author": "Ayush0054",
          "body": "Hey @dotannn ,\nCould you please share your agent config so we can try to replicate the issue on our end?\n\nThanks! 🙌",
          "created_at": "2025-05-13T08:45:30Z"
        }
      ]
    },
    {
      "issue_number": 3298,
      "title": "[Bug] Facing an issue with Gemini model in MCPTools",
      "body": "### Description\n\nI've been trying to use this [MCP server](https://github.com/acryldata/mcp-server-datahub) within `MCPTools` using the Gemini model (default - flash 2.0), but it gives an error.\n\n\n### Steps to Reproduce\n\n```\nfrom agno.agent import Agent\nfrom agno.models.google import Gemini\nfrom agno.tools.mcp import MCPTools\n\nimport asyncio\n\n\nasync def get_response_from_datahub(user_input):\n    async with MCPTools(\n        command=\"uvx mcp-server-datahub\",\n        env={\"DATAHUB_GMS_TOKEN\": \"\", \"DATAHUB_GMS_URL\": \"http://localhost:8080\"}\n    ) as mcp_tools:\n        agent = Agent(\n            model=Gemini(),\n            tools=[mcp_tools],\n            markdown=True,\n            show_tool_calls=True,\n            instructions=\"some system prompt here\"\n        )\n        await agent.aprint_response(f\"User input: {user_input}\", stream=True)\n\n\nif __name__ == \"__main__\":\n    user_input = input()\n    asyncio.run(generate_db_query(user_input))\n```\nFollowing this [example](https://docs.agno.com/tools/mcp/mcp#basic-example%3A-filesystem-agent).\n\nMCP inspector reveals no issues with datahub MCP server.\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nIt should run without errors\n\n### Actual Behavior\n\nI am running Datahub locally (`datahub docker quickstart`). However, upon running this script, I am encountering this error\n```\nan error occurred during closing of asynchronous generator <async_generator object stdio_client at 0x105f28e00>\nasyncgen: <async_generator object stdio_client at 0x105f28e00>\n  + Exception Group Traceback (most recent call last):\n  |   File \"/Users/rahulb99/.pyenv/versions/3.12.7/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 772, in __aexit__\n  |     raise BaseExceptionGroup(\n  | BaseExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"/Users/rahulb99/.pyenv/versions/3.12.7/lib/python3.12/site-packages/mcp/client/stdio/__init__.py\", line 177, in stdio_client\n    |     yield read_stream, write_stream\n    | GeneratorExit\n    +------------------------------------\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/rahulb99/.pyenv/versions/3.12.7/lib/python3.12/site-packages/mcp/client/stdio/__init__.py\", line 171, in stdio_client\n    anyio.create_task_group() as tg,\n    ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/rahulb99/.pyenv/versions/3.12.7/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 778, in __aexit__\n    if self.cancel_scope.__exit__(type(exc), exc, exc.__traceback__):\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/rahulb99/.pyenv/versions/3.12.7/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 457, in __exit__\n    raise RuntimeError(\nRuntimeError: Attempted to exit cancel scope in a different task than it was entered in\n  + Exception Group Traceback (most recent call last):\n  |   File \"/Users/rahulb99/Desktop/agno-mcp/agents/agent.py\", line 39, in <module>\n  |     asyncio.run(generate_db_query(user_input))\n  |   File \"/Users/rahulb99/.pyenv/versions/3.12.7/lib/python3.12/asyncio/runners.py\", line 194, in run\n  |     return runner.run(main)\n  |            ^^^^^^^^^^^^^^^^\n  |   File \"/Users/rahulb99/.pyenv/versions/3.12.7/lib/python3.12/asyncio/runners.py\", line 118, in run\n  |     return self._loop.run_until_complete(task)\n  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  |   File \"/Users/rahulb99/.pyenv/versions/3.12.7/lib/python3.12/asyncio/base_events.py\", line 687, in run_until_complete\n  |     return future.result()\n  |            ^^^^^^^^^^^^^^^\n  |   File \"/Users/rahulb99/Desktop/agno-mcp/agents/agent.py\", line 14, in generate_db_query\n  |     async with MCPTools(\n  |                ^^^^^^^^^\n  |   File \"/Users/rahulb99/.pyenv/versions/3.12.7/lib/python3.12/site-packages/agno/tools/mcp.py\", line 191, in __aexit__\n  |     await self._session_context.__aexit__(exc_type, exc_val, exc_tb)\n  |   File \"/Users/rahulb99/.pyenv/versions/3.12.7/lib/python3.12/site-packages/mcp/shared/session.py\", line 220, in __aexit__\n  |     return await self._task_group.__aexit__(exc_type, exc_val, exc_tb)\n  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  |   File \"/Users/rahulb99/.pyenv/versions/3.12.7/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 772, in __aexit__\n  |     raise BaseExceptionGroup(\n  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"/Users/rahulb99/.pyenv/versions/3.12.7/lib/python3.12/site-packages/agno/models/google/gemini.py\", line 332, in ainvoke_stream\n    |     async for chunk in async_stream:\n    |   File \"/Users/rahulb99/.pyenv/versions/3.12.7/lib/python3.12/site-packages/google/genai/models.py\", line 7266, in async_generator\n    |     response = await self._generate_content_stream(\n    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/Users/rahulb99/.pyenv/versions/3.12.7/lib/python3.12/site-packages/google/genai/models.py\", line 6191, in _generate_content_stream\n    |     response_stream = await self._api_client.async_request_streamed(\n    |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/Users/rahulb99/.pyenv/versions/3.12.7/lib/python3.12/site-packages/google/genai/_api_client.py\", line 806, in async_request_streamed\n    |     response = await self._async_request(http_request=http_request, stream=True)\n    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/Users/rahulb99/.pyenv/versions/3.12.7/lib/python3.12/site-packages/google/genai/_api_client.py\", line 721, in _async_request\n    |     await errors.APIError.raise_for_async_response(response)\n    |   File \"/Users/rahulb99/.pyenv/versions/3.12.7/lib/python3.12/site-packages/google/genai/errors.py\", line 129, in raise_for_async_response\n    |     raise ClientError(status_code, response_json, response)\n    | google.genai.errors.ClientError: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Invalid value at \\'tools[0].function_declarations[1].parameters.properties[1].value.any_of[0].type\\' (type.googleapis.com/google.ai.generativelanguage.v1beta.Type), \"\"\\nInvalid value at \\'tools[0].function_declarations[1].parameters.properties[1].value.any_of[1].type\\' (type.googleapis.com/google.ai.generativelanguage.v1beta.Type), \"\"\\nInvalid value at \\'tools[0].function_declarations[1].parameters.properties[1].value.any_of[2].type\\' (type.googleapis.com/google.ai.generativelanguage.v1beta.Type), \"\"\\nInvalid value at \\'tools[0].function_declarations[1].parameters.properties[1].value.any_of[3].type\\' (type.googleapis.com/google.ai.generativelanguage.v1beta.Type), \"\"\\nInvalid value at \\'tools[0].function_declarations[1].parameters.properties[1].value.any_of[4].type\\' (type.googleapis.com/google.ai.generativelanguage.v1beta.Type), \"\"\\nInvalid value at \\'tools[0].function_declarations[1].parameters.properties[1].value.any_of[5].type\\' (type.googleapis.com/google.ai.generativelanguage.v1beta.Type), \"\"\\nInvalid value at \\'tools[0].function_declarations[1].parameters.properties[1].value.any_of[6].type\\' (type.googleapis.com/google.ai.generativelanguage.v1beta.Type), \"\"\\nInvalid value at \\'tools[0].function_declarations[1].parameters.properties[1].value.any_of[7].type\\' (type.googleapis.com/google.ai.generativelanguage.v1beta.Type), \"\"\\nInvalid value at \\'tools[0].function_declarations[1].parameters.properties[1].value.any_of[8].type\\' (type.googleapis.com/google.ai.generativelanguage.v1beta.Type), \"\"\\nInvalid value at \\'tools[0].function_declarations[1].parameters.properties[1].value.any_of[9].type\\' (type.googleapis.com/google.ai.generativelanguage.v1beta.Type), \"\"', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.BadRequest', 'fieldViolations': [{'field': 'tools[0].function_declarations[1].parameters.properties[1].value.any_of[0].type', 'description': 'Invalid value at \\'tools[0].function_declarations[1].parameters.properties[1].value.any_of[0].type\\' (type.googleapis.com/google.ai.generativelanguage.v1beta.Type), \"\"'}, {'field': 'tools[0].function_declarations[1].parameters.properties[1].value.any_of[1].type', 'description': 'Invalid value at \\'tools[0].function_declarations[1].parameters.properties[1].value.any_of[1].type\\' (type.googleapis.com/google.ai.generativelanguage.v1beta.Type), \"\"'}, {'field': 'tools[0].function_declarations[1].parameters.properties[1].value.any_of[2].type', 'description': 'Invalid value at \\'tools[0].function_declarations[1].parameters.properties[1].value.any_of[2].type\\' (type.googleapis.com/google.ai.generativelanguage.v1beta.Type), \"\"'}, {'field': 'tools[0].function_declarations[1].parameters.properties[1].value.any_of[3].type', 'description': 'Invalid value at \\'tools[0].function_declarations[1].parameters.properties[1].value.any_of[3].type\\' (type.googleapis.com/google.ai.generativelanguage.v1beta.Type), \"\"'}, {'field': 'tools[0].function_declarations[1].parameters.properties[1].value.any_of[4].type', 'description': 'Invalid value at \\'tools[0].function_declarations[1].parameters.properties[1].value.any_of[4].type\\' (type.googleapis.com/google.ai.generativelanguage.v1beta.Type), \"\"'}, {'field': 'tools[0].function_declarations[1].parameters.properties[1].value.any_of[5].type', 'description': 'Invalid value at \\'tools[0].function_declarations[1].parameters.properties[1].value.any_of[5].type\\' (type.googleapis.com/google.ai.generativelanguage.v1beta.Type), \"\"'}, {'field': 'tools[0].function_declarations[1].parameters.properties[1].value.any_of[6].type', 'description': 'Invalid value at \\'tools[0].function_declarations[1].parameters.properties[1].value.any_of[6].type\\' (type.googleapis.com/google.ai.generativelanguage.v1beta.Type), \"\"'}, {'field': 'tools[0].function_declarations[1].parameters.properties[1].value.any_of[7].type', 'description': 'Invalid value at \\'tools[0].function_declarations[1].parameters.properties[1].value.any_of[7].type\\' (type.googleapis.com/google.ai.generativelanguage.v1beta.Type), \"\"'}, {'field': 'tools[0].function_declarations[1].parameters.properties[1].value.any_of[8].type', 'description': 'Invalid value at \\'tools[0].function_declarations[1].parameters.properties[1].value.any_of[8].type\\' (type.googleapis.com/google.ai.generativelanguage.v1beta.Type), \"\"'}, {'field': 'tools[0].function_declarations[1].parameters.properties[1].value.any_of[9].type', 'description': 'Invalid value at \\'tools[0].function_declarations[1].parameters.properties[1].value.any_of[9].type\\' (type.googleapis.com/google.ai.generativelanguage.v1beta.Type), \"\"'}]}]}}\n    | \n    | The above exception was the direct cause of the following exception:\n    | \n    | Traceback (most recent call last):\n    |   File \"/Users/rahulb99/Desktop/agno-mcp/agents/agent.py\", line 34, in generate_db_query\n    |     await agent.aprint_response(f\"User input: {user_input}\", stream=True)\n    |   File \"/Users/rahulb99/.pyenv/versions/3.12.7/lib/python3.12/site-packages/agno/agent/agent.py\", line 5356, in aprint_response\n    |     async for resp in result:\n    |   File \"/Users/rahulb99/.pyenv/versions/3.12.7/lib/python3.12/site-packages/agno/agent/agent.py\", line 1415, in _arun\n    |     async for model_response_chunk in model_response_stream:  # type: ignore\n    |   File \"/Users/rahulb99/.pyenv/versions/3.12.7/lib/python3.12/site-packages/agno/models/base.py\", line 645, in aresponse_stream\n    |     async for response in self.aprocess_response_stream(\n    |   File \"/Users/rahulb99/.pyenv/versions/3.12.7/lib/python3.12/site-packages/agno/models/base.py\", line 609, in aprocess_response_stream\n    |     async for response_delta in self.ainvoke_stream(\n    |   File \"/Users/rahulb99/.pyenv/versions/3.12.7/lib/python3.12/site-packages/agno/models/google/gemini.py\", line 336, in ainvoke_stream\n    |     raise ModelProviderError(\n    | agno.exceptions.ModelProviderError: <Response [400 Bad Request]>\n    +------------------------------------\n```\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n- Agno Version 1.5.1\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "rahulb99",
      "author_type": "User",
      "created_at": "2025-05-22T15:30:26Z",
      "updated_at": "2025-05-26T13:37:12Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3298/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3298",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3298",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:25.376541",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-269/bug-facing-an-issue-with-gemini-model-with-mcptools\">SUPPORT-269 [Bug] Facing an issue with Gemini model with MCPTools</a></p>",
          "created_at": "2025-05-22T15:30:29Z"
        },
        {
          "author": "manuhortet",
          "body": "Hey @rahulb99, I'm sorry you're facing these errors. It seems that the input schema we receive from this MCP server doesn't follow the [OpenAPI 3.0 schema](https://spec.openapis.org/oas/v3.0.3#schema-object), while Gemini enforces it. \n\nIt's on our roadmap to handle this situation for Gemini setups.",
          "created_at": "2025-05-26T13:37:11Z"
        }
      ]
    },
    {
      "issue_number": 3270,
      "title": "[Bug] Cannot return RunResponse",
      "body": "### Description\n\nI found a bug when running agent to get RunResponse\n\n### Steps to Reproduce\n\nUse `Agent.run()` and response_model is pydantic Model\n\n### Agent Configuration (if applicable)\n\n```python\nres: RunResponse = agent.run(\n        message=test_output,\n        # stream=True\n    )\n```\n\n### Expected Behavior\n\nReturn `RunResponse` model\n\n### Actual Behavior\n\n![Image](https://github.com/user-attachments/assets/c6eaf818-ddde-48c8-974e-a0f91d3a8d85)\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nagno==1.5.2\n```\n\n### Possible Solutions (optional)\n\n`[agno/agent/agent.py](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/agent/agent.py#L924)`\n```\n                    response = list(\n                        self._run(\n                            run_response=run_response,\n                            run_messages=run_messages,\n                            message=message,\n                            user_id=user_id,\n                            session_id=session_id,\n                            response_format=response_format,\n                            messages=messages,\n                        )\n                    )\n```\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "anhphong22",
      "author_type": "User",
      "created_at": "2025-05-21T07:35:37Z",
      "updated_at": "2025-05-26T11:49:55Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3270/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3270",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3270",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:25.623927",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-248/bug-cannot-return-runresponse\">SUPPORT-248 [Bug] Cannot return RunResponse</a></p>",
          "created_at": "2025-05-21T07:35:40Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @anhphong22 \nWhat is the issue you are experiencing? Are you referring to the debug logs?",
          "created_at": "2025-05-26T11:49:54Z"
        }
      ]
    },
    {
      "issue_number": 3043,
      "title": "[Bug] us.amazon.nova-lite responses include unparsed <thinking> sections",
      "body": "# Description\nus.amazon.nova-lite model responses include unparsed <thinking> sections. I would expect these were pulled out into separate sections vs the text content.\n\n## Steps to Reproduce\nUse AWS Bedrock and the us.amazon.nova-lite model.\n\n## Agent Configuration (if applicable)\nProvide relevant agent configuration.\n\n## Expected Behavior\nI would expect the <thinking> sections were pulled out into separate sections vs the text content.\n\n## Actual Behavior\nThe <thinking> sections were returned along with other text.\n\n## Screenshots or Logs (if applicable)\nportion of logs:\n```\nRunResponse(content='<thinking>I need to search for information about the hosting infrastructure used by the tool.</thinking>\\nThe tool uses the following AWS services for its hosting infrastructure:\\n\\n- **Route 53**: A scalable domain name system (DNS) web service provided by AWS. It is used to manage DNS records for the website.)\n```\n\n## Environment\n- OS: (e.g. macOS, Windows 11)\n- Browser (if relevant): (e.g. Chrome 108, Firefox 107)\n- Agno Version: (e.g. v1.0.0)\n- External Dependency Versions: (e.g., yfinance 0.2.52)\n- Additional Environment Details: (e.g., Python 3.10)\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "rayterrill",
      "author_type": "User",
      "created_at": "2025-05-01T05:03:38Z",
      "updated_at": "2025-05-26T11:25:22Z",
      "closed_at": "2025-05-26T11:25:22Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3043/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3043",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3043",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:25.821162",
      "comments": [
        {
          "author": "mishramonalisha76",
          "body": "Hi @rayterrill, thanks for pointing this out! This is already on our near-term priority list, and our team is actively working on it.",
          "created_at": "2025-05-02T11:33:32Z"
        }
      ]
    },
    {
      "issue_number": 3312,
      "title": "[Feature Request] Prompt caching for Claude",
      "body": "### Problem Description\n\nIn models like GPT-4.1 prompt caching is automatic, saving major costs.\nIn Anthropic models it seems like it requires manual input.\n\n### Proposed Solution\n\nFor relevant connectors:\nOpenrouter, Claude, AWS Bedrock - when working with Claude models implementing the prompt caching protocol for system prompts:\nhttps://docs.anthropic.com/en/docs/build-with-claude/prompt-caching\n\n\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\nIt seems this has been implemented in the past:\nhttps://github.com/agno-agi/agno/pull/1161\n\nBut seems like current code doesn't exist in Agno, not sure why.\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [x] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "onesecurity-app",
      "author_type": "User",
      "created_at": "2025-05-23T01:42:42Z",
      "updated_at": "2025-05-26T10:44:17Z",
      "closed_at": "2025-05-26T10:44:16Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3312/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3312",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3312",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:26.021282",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-272/feature-request-prompt-caching-for-claude\">SUPPORT-272 [Feature Request] Prompt caching for Claude</a></p>",
          "created_at": "2025-05-23T01:42:45Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi! This is already a [feature request on our roadmap](https://github.com/orgs/agno-agi/projects/6/views/1?pane=issue&itemId=107600949&issue=agno-agi%7Cagno%7C1811)!\nWe'll resolve asap!",
          "created_at": "2025-05-26T10:44:16Z"
        }
      ]
    },
    {
      "issue_number": 3318,
      "title": "[Feature Request]  fallback model in agent",
      "body": "### Problem Description\n\nhttps://discord.com/channels/965734768803192842/1374797201884315658/1375248280262541474\n\n### Proposed Solution\n\nfallback agent when current agent doesnt respond\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "Ayush0054",
      "author_type": "User",
      "created_at": "2025-05-23T06:56:06Z",
      "updated_at": "2025-05-26T10:43:31Z",
      "closed_at": "2025-05-26T10:43:30Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3318/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3318",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3318",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:26.201900",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-287/feature-request-fallback-model-in-agent\">SUPPORT-287 [Feature Request] fallback model in agent</a></p>",
          "created_at": "2025-05-23T06:56:09Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Thanks for the request! We have added it to our [roadmap](https://github.com/orgs/agno-agi/projects/6/views/1)",
          "created_at": "2025-05-26T10:43:30Z"
        }
      ]
    },
    {
      "issue_number": 3319,
      "title": "[Feature Request] In the media handling for gemini, add a case to handle gs urls ,",
      "body": "### Problem Description\n\nIn some environments , people use gcp as there storage also gemini api , to reduce egress and ingress , rather than downloading gs urls , allow to directly pass url and mimetype, which allows gemini directly access  from gcs, \n\n### Proposed Solution\n\nIn the Gemini class , in the _format_file_for_message add something like this:\n # PRIORITY 1: Check for GCS URI in filepath\n        if file.filepath and isinstance(file.filepath, str) and file.filepath.startswith(\"gs://\"):\n            if not file.mime_type:\n                # It's CRUCIAL to have a MIME type for GCS URIs with Gemini\n                guessed_mime_type, _ = mimetypes.guess_type(file.filepath)\n                if not guessed_mime_type:\n                    # You might want to be stricter here or have a defined fallback policy\n                    log_warning(f\"Could not guess MIME type for GCS URI {file.filepath}. This might fail with Gemini.\")\n                    # Option: raise ValueError(\"MIME type is required for GCS URIs and could not be guessed.\")\n                    # Option: use a default like application/octet-stream, but it's risky for multimodal\n                    effective_mime_type = \"application/octet-stream\" # Example fallback, use with caution\n                else:\n                    effective_mime_type = guessed_mime_type\n                log_warning(f\"MIME type for GCS URI {file.filepath} was not provided, guessed as {effective_mime_type}.\")\n            else:\n                effective_mime_type = file.mime_type\n\n            # Ensure the MIME type is now valid based on your File model's validation (if it was expanded)\n            # Or, if it's a direct pass-through to Gemini, trust the provided/guessed one.\n            # if effective_mime_type not in File.valid_mime_types(): # If checking against Agno's File\n            #     log_error(f\"MIME type {effective_mime_type} for GCS URI {file.filepath} is not in Agno's allowed list.\")\n            #     return None # Or handle error\n\n            log_info(f\"Using GCS URI directly: {file.filepath} with MIME type: {effective_mime_type}\") # Added log_info\n            # For Gemini, the parameter is `uri`, not `file_uri` like in the File API part\n            return Part.from_uri(uri=file.filepath, mime_type=effective_mime_type)\n\n\n\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [x] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "Vamshi3130",
      "author_type": "User",
      "created_at": "2025-05-23T07:55:07Z",
      "updated_at": "2025-05-26T10:43:00Z",
      "closed_at": "2025-05-26T10:42:59Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3319/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3319",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3319",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:26.380561",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-290/feature-request-in-the-media-handling-for-gemini-add-a-case-to-handle\">SUPPORT-290 [Feature Request] In the media handling for gemini, add a case to handle gs urls ,</a></p>",
          "created_at": "2025-05-23T07:55:10Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Thanks for the request! We have added it to our [roadmap](https://github.com/orgs/agno-agi/projects/6/views/1)",
          "created_at": "2025-05-26T10:42:59Z"
        }
      ]
    },
    {
      "issue_number": 2960,
      "title": "[Feature Request] A2A support on Agno",
      "body": "## Problem Description\nProvide a clear and concise explanation of the issue you're facing.\n**Example:** *\"I often find it frustrating when [...] because [...]”*\n\n## Proposed Solution\nExplain your ideal solution. How should this feature work?\nBe as detailed as possible to help us understand your vision.\n\n## Alternatives Considered\nHave you found any workarounds or alternative solutions?\nShare other approaches you've tried or thought about.\n\n## Additional context\nInclude any extra information that might be helpful, such as:\n- Screenshots\n- Examples of similar features elsewhere\n- Any relevant links or references\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[ ] Yes, I’d love to work on it!**\n**[ ] I’m open to collaborating but need guidance.**\n**[ ] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "monali7-d",
      "author_type": "User",
      "created_at": "2025-04-24T08:12:25Z",
      "updated_at": "2025-05-26T10:39:34Z",
      "closed_at": "2025-04-24T09:19:34Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2960/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2960",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2960",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:26.589324",
      "comments": [
        {
          "author": "maceip",
          "body": "this would be a huge boon to agentic devs; once  we pick an interface  for <>, it unlocks a network of agents and a different way of thinking. i know it's early and fast moving _and_ there are already 3+ i've heard of and dont even want to search:\n\n## ACP: \n - from IBM\n - lightweight docker based op",
          "created_at": "2025-05-03T05:05:18Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Great suggestion! This is on our roadmap and we are currently in the scoping phase!",
          "created_at": "2025-05-08T10:04:33Z"
        },
        {
          "author": "dirkbrnd",
          "body": "We have an [A2A example ](https://github.com/agno-agi/agno/tree/main/cookbook/examples/a2a) that might be of use",
          "created_at": "2025-05-26T10:39:34Z"
        }
      ]
    },
    {
      "issue_number": 2064,
      "title": "[Feature Request] I need XInference support",
      "body": "## Problem Description\nCurrently, the project lacks support for integrating models deployed via [Xinference](https://inference.readthedocs.io/en/latest/models/index.html), such as large language models (LLMs), embedding models, rerank models, and multimodal embedding models. This limits the flexibility and scalability of the project, as Xinference provides a robust and efficient way to deploy and manage these models. Without this integration, users are unable to leverage the advanced capabilities of Xinference-deployed models within the project.\n\nExample: \"I often find it frustrating when I need to use advanced models like LLMs or multimodal embeddings in my project, but the current setup doesn’t support Xinference, which is my preferred deployment tool. This forces me to use less efficient or less scalable alternatives.\"\n\n## Proposed Solution\nI propose adding support for Xinference-deployed models to the project. This would involve:\n\nIntegration with Xinference API: Implement functionality to connect to Xinference-deployed models via its API. This includes support for:\n\nLarge Language Models (LLMs)\n\nEmbedding Models\n\nRerank Models\n\nMultimodal Embedding Models\n\nModel Configuration: Allow users to configure Xinference-deployed models through a simple configuration file or environment variables. This should include:\n\nModel endpoints\n\nAPI keys (if required)\n\nModel-specific parameters (e.g., temperature, max tokens for LLMs)\n\nSeamless Usage: Ensure that the integration allows for seamless usage of these models within the existing project workflow. For example:\n\nEmbedding models should work with existing vector search functionality.\n\nLLMs should integrate with the project’s text generation or chat features.\n\nRerank models should enhance search or recommendation systems.\n\nDocumentation: Provide clear documentation on how to set up and use Xinference-deployed models within the project.\n\n## Alternatives Considered\nLocal Model Deployment: One alternative is to deploy models locally without using Xinference. However, this approach is less scalable and requires more resources, making it less ideal for production environments.\n\nOther Model Deployment Tools: I considered using other model deployment tools, but Xinference stands out due to its ease of use, scalability, and support for a wide range of models.\n\n## Additional Context\nXinference Documentation: [Xinference Models](https://inference.readthedocs.io/en/latest/models/index.html)\n\nSimilar Features: Other projects like LangChain and Haystack have integrations with various model deployment tools, which could serve as inspiration for this implementation.\n\nUse Case: This feature would be particularly useful for users who need to deploy and manage multiple models in a scalable and efficient manner, especially in production environments.\n\nThis feature request outlines the need for Xinference support in the project and provides a clear path for implementation. If accepted, it would significantly enhance the project’s capabilities and flexibility.",
      "state": "closed",
      "author": "moshilangzi",
      "author_type": "User",
      "created_at": "2025-02-10T10:38:39Z",
      "updated_at": "2025-05-26T10:38:33Z",
      "closed_at": "2025-02-27T00:30:26Z",
      "labels": [
        "enhancement",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2064/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2064",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2064",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:26.765325",
      "comments": [
        {
          "author": "pritipsingh",
          "body": "@moshilangzi Thanks for such a detailed request. We really appreciate it. We've added this to our community wishlist. However, it will definitely take some time on our end due to current priorities. If you have some time, feel free to explore & contribute.",
          "created_at": "2025-02-11T19:15:00Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-02-27T00:30:25Z"
        }
      ]
    },
    {
      "issue_number": 2688,
      "title": "Adding \"stop_before_tool_call\" parameter ",
      "body": "## Problem Description\nI would like to be able to run an agent with tools but also to be able to provide client tools. This means that I want the tools of the agent to be augmented with additional \"dummy\" tool functions that the user provides as part of his request. I don't want the agent to call any of these tools but rather I want the agent to stop processing and return control to the user. \n\n## Proposed Solution\nIs there a way to do this with existing architecture? I have checked stop_after_tool_call parameter and it does work but it also runs the tool call and adds a new tool message to the history. I would rather have the agent stop BEFORE the tool call so that the last message contains tool calls and then I want my code to add the tool message. \n\n## Alternatives Considered\nCreating dummy functions for client tools and then filtering out the last tool message if it relates to a dummy function. Clunky and a bit impractical. \n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[x] Yes, I’d love to work on it!**\n**[x] I’m open to collaborating but need guidance.**\n**[ ] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "mkschreder",
      "author_type": "User",
      "created_at": "2025-04-05T10:57:22Z",
      "updated_at": "2025-05-26T10:37:01Z",
      "closed_at": "2025-05-26T10:37:01Z",
      "labels": [
        "enhancement",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2688/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "dirkbrnd"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2688",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2688",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:26.980403",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-22T00:33:17Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @mkschreder \nVery good suggestion. I am working on a solution for this already that should be out soon. Basically the agent is \"paused\" allowing you to execute \"external tools\" and then continue the agent with results of these tools. I think that is what you are saying. \nWe have added it to our [",
          "created_at": "2025-04-23T10:07:12Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-05-24T00:32:50Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@mkschreder Please take a look at our User Control Flows released with 1.5.4\n\nSee docs [here](https://docs.agno.com/agents/user-control-flow)",
          "created_at": "2025-05-26T10:37:01Z"
        }
      ]
    },
    {
      "issue_number": 3266,
      "title": "[Bug] FirecrawlReader is passing \"params\" to firecrawl instead of \"Formats\"",
      "body": "### Description\n\nFirecrawlReader subsequently FireCrawlKnowledgeBase is not working\n\nFirecrawlReader upon running showing following error:\nError type: <class 'requests.exceptions.HTTPError'>\nError occurred: Unexpected error during scrape URL: Status code 400. Bad Request - [{'code': 'unrecognized_keys', 'keys': ['params'], 'path': [], 'message': 'Unrecognized key in body -- please review the v1 API documentation for request body changes'}]\n\n### Steps to Reproduce\n\nRun Code:\n  md_content = FirecrawlReader(\n    api_key= FIRECRAWL_API_KEY,\n    mode=\"scrape\",\n    params={\"formats\": [\"markdown\"]},\n  )\n\n  try:\n    print(\"Starting scrape...\")\n    documents = await md_content.async_read(url)\n\n    if documents:\n      for doc in documents:\n        print(doc.name)\n        print(doc.content)\n        print(f\"Content length: {len(doc.content)}\")\n        print(\"-\" * 80)\n        return {\"status\": \"completed\", \"message\": \"Content scraped successfully.\"}\n    else:\n        print(\"No documents were returned\")\n        return {\"status\": \"failed\", \"error\": \"No documents returned from Firecrawl\"}\n  except Exception as e:\n    print(f\"Error type: {type(e)}\")\n    print(f\"Error occurred: {str(e)}\")\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nShould return List of documents\n\n### Actual Behavior\n\nThrowing error\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n- Google Colab notebook\n```\n\n### Possible Solutions (optional)\n\nFirecrawlReader Class needs tweaking\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "Manas-repo",
      "author_type": "User",
      "created_at": "2025-05-21T06:09:54Z",
      "updated_at": "2025-05-26T06:11:10Z",
      "closed_at": "2025-05-26T06:11:09Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3266/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3266",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3266",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:27.208338",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-243/bug-firecrawlreader-is-passing-params-to-firecrawl-instead-of-formats\">SUPPORT-243 [Bug] FirecrawlReader is passing \"params\" to firecrawl instead of \"Formats\"</a></p>",
          "created_at": "2025-05-21T06:09:57Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@Manas-repo This has been fixed in the latest release! agno > 1.5.3 should do the trick. I tested your code and it worked.",
          "created_at": "2025-05-23T10:09:58Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Correction, this will be released with the next release today.",
          "created_at": "2025-05-23T10:12:35Z"
        },
        {
          "author": "dirkbrnd",
          "body": "This has been released!\n",
          "created_at": "2025-05-26T06:11:09Z"
        }
      ]
    },
    {
      "issue_number": 3292,
      "title": "[Bug] Gemini: `ModelProviderError` - \"Function calling with a response mime type: application/json is unsupported\" when Team has `response_model` and members use tools",
      "body": "### Description\n\nI am encountering a ModelProviderError when using a Gemini model as the orchestrator for an Agno Team. The Team (the \"leader\" agent) is configured with a response_model to ensure structured JSON output. Its member Agents are equipped with and use tools.\nThe core issue is that an error arises from the Gemini API: \"Function calling with a response mime type: 'application/json' is unsupported\". This occurs for the Team's coordinating LLM call, even though the Team itself is not directly assigned any tools in its configuration. It appears the framework's attempt to manage tool-using members and enforce a response_model for the team's final output simultaneously leads to this conflict with the Gemini API.\n\n### Steps to Reproduce\n\nRun the given code\n\n### Agent Configuration (if applicable)\n\n```python\nfrom agno.tools.duckduckgo import DuckDuckGoTools\nfrom agno.tools.newspaper4k import Newspaper4kTools\nfrom agno.agent import Agent\nfrom agno.team import Team\nfrom agno.models.openai import OpenAIChat\nfrom agno.models.google import Gemini\nfrom pydantic import BaseModel\n\n\nclass Content(BaseModel): \n    title: str\n    content: str\n    date: str\n\n\n\ngemini_model_pro = Gemini(\"gemini-2.5-pro-preview-05-06\")\n\n\n\nsearcher = Agent(\n    name=\"Searcher\",\n    role=\"Searches the top URLs for a topic\",\n    model=gemini_model_pro,\n    instructions=[\n        \"Given a topic, first generate a list of 3 search terms related to that topic.\",\n        \"For each search term, search the web and analyze the results.Return the 10 most relevant URLs to the topic.\",\n        \"You are writing for the New York Times, so the quality of the sources is important.\",\n    ],\n    tools=[DuckDuckGoTools()],\n    add_datetime_to_instructions=True,\n)\nwriter = Agent(\n    name=\"Writer\",\n    role=\"Writes a high-quality article\",\n    model=gemini_model_pro,\n    description=(\n        \"You are a senior writer for the New York Times. Given a topic and a list of URLs, \"\n        \"your goal is to write a high-quality NYT-worthy article on the topic.\"\n    ),\n    instructions=[\n        \"First read all urls using `read_article`.\"\n        \"Then write a high-quality NYT-worthy article on the topic.\"\n        \"The article should be well-structured, informative, engaging and catchy.\",\n        \"Ensure the length is at least as long as a NYT cover story -- at a minimum, 15 paragraphs.\",\n        \"Ensure you provide a nuanced and balanced opinion, quoting facts where possible.\",\n        \"Focus on clarity, coherence, and overall quality.\",\n        \"Never make up facts or plagiarize. Always provide proper attribution.\",\n        \"Remember: you are writing for the New York Times, so the quality of the article is important.\",\n    ],\n    tools=[Newspaper4kTools()],\n    add_datetime_to_instructions=True,\n)\n\neditor = Team(\n    name=\"Editor\",\n    mode=\"coordinate\",\n    model=gemini_model_pro,\n    members=[searcher, writer],\n    description=\"You are a senior NYT editor. Given a topic, your goal is to write a NYT worthy article.\",\n    instructions=[\n        \"First ask the search journalist to search for the most relevant URLs for that topic.\",\n        \"Then ask the writer to get an engaging draft of the article.\",\n        \"Edit, proofread, and refine the article to ensure it meets the high standards of the New York Times.\",\n        \"The article should be extremely articulate and well written. \"\n        \"Focus on clarity, coherence, and overall quality.\",\n        \"Remember: you are the final gatekeeper before the article is published, so make sure the article is perfect.\",\n    ],\n    add_datetime_to_instructions=True,\n    add_member_tools_to_system_message=False,  # This can be tried to make the agent more consistently get the transfer tool call correct\n    enable_agentic_context=True,  # Allow the agent to maintain a shared context and send that to members.\n    share_member_interactions=True,  # Share all member responses with subsequent member requests.\n    show_members_responses=True,\n    response_model=Content,\n    markdown=True,\n)\neditor.print_response(\"Write an article about latest developments in AI.\")\n```\n\n### Expected Behavior\n\nThe Editor team should successfully coordinate the Searcher and Writer agents, and its final output should be structured according to the Content Pydantic model, without the Gemini API error. The framework should manage the API calls in a way that respects the model's capabilities regarding function calling and JSON mode.\n\n\n\n### Actual Behavior\n\nThe program fails with agno.exceptions.ModelProviderError: <Response [400 Bad Request]> and the Gemini API error: {'error': {'code': 400, 'message': \"Function calling with a response mime type: 'application/json' is unsupported\", 'status': 'INVALID_ARGUMENT'}}.\n\n\n\n### Screenshots or Logs (if applicable)\n\n```\nWARNING  Attempt 1/4 failed: <Response [400 Bad Request]>                                                                                                                                            \nERROR    Error from Gemini API: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': \"Function calling with a response mime type: 'application/json' is unsupported\", 'status':                  \n         'INVALID_ARGUMENT'}}   \n```\n\n\n\n### Environment\n\n```markdown\nAgno version: `1.5.2`\nPython version: `Python 3.12.7`\ngoogle-genai==1.16.1\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "kishan-plivo",
      "author_type": "User",
      "created_at": "2025-05-22T11:38:03Z",
      "updated_at": "2025-05-26T06:10:48Z",
      "closed_at": "2025-05-26T06:10:48Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3292/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3292",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3292",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:27.386832",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-266/bug-gemini-modelprovidererror-function-calling-with-a-response-mime\">SUPPORT-266 [Bug] Gemini: `ModelProviderError` - \"Function calling with a response mime type: application/json is unsupported\" when Team has `response_model` and members use too",
          "created_at": "2025-05-22T11:38:06Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @kishan-plivo \nSo the team automatically has tools because it has to transfer tasks to members, and Gemini has had a bug since release that they haven't resolved yet, where it rejects structured output combined with tools. \n\nWe have had better success if you set `use_json_mode=True` on the team /",
          "created_at": "2025-05-23T14:32:00Z"
        },
        {
          "author": "kishan-plivo",
          "body": "@dirkbrnd \nIs there a flag, or should there be a flag where only the member (agent) where we have explicitly added tool call should have access to tool call and not share the tools with members or team leader? ",
          "created_at": "2025-05-23T14:39:36Z"
        },
        {
          "author": "dirkbrnd",
          "body": "The members don't share tools with the team leader or other members, it is isolated. But the team leader has a built-in tool called `transfer_task_to_member` (in the case of coordinate mode) and this combined with the response model is being rejected by Gemini.",
          "created_at": "2025-05-23T15:21:38Z"
        },
        {
          "author": "kishanhitk",
          "body": "Understood, thanks for the clarification @dirkbrnd.",
          "created_at": "2025-05-23T15:37:24Z"
        }
      ]
    },
    {
      "issue_number": 2549,
      "title": "[Bug] Team Agent Not Propagating Files to Sub-Agents",
      "body": "# Description\nThe team agent is not correctly passing file attachments to its specialized sub-agents when processing user requests. \n\n## Steps to Reproduce\n1. Send a message to the agent with one or more file attachments\n2. The files can be of any type (images, documents, etc.)\n3. The agent will process the request but will not handle the files correctly\n4. The specialized agents will not receive the files in their expected format\n\n## Agent Configuration\n```\n# Initialize the team agent with specialized sub-agents\nagent = Team(\n    members=[...],\n    mode=\"route\",\n)\n\n# Files are passed in this format\nfiles = [\n    File(url=\"https://example.com/file.csv\")\n]\n\n# Generate response with files\nresponse = await self.team.arun(\n    user_input,\n    stream=False,\n    files=files if files else None,\n)\n```\n## Expected Behavior\n1. Files should be properly passed through the team agent to the specialized agents\n2. The specialized agents should receive the files in their proper format\n3. Files should be processed according to their type (images, documents, etc.)\n\n## Actual Behavior\n1. Files are not being properly propagated to the specialized agents\n2. The current workaround is to append file URLs to the user input text which works\n\n## Environment\n- OS: Linux 6.13.7 (OrbStack)\n- Agno Version: 1.2.4\n- Python Version: 3.11\n\n## Possible Solutions\n1. Investigate the team implementation to ensure proper file propagation\n2. Update the team agent to explicitly handle file passing to specialized agents\n3. Implement proper file handling across the entire agent hierarchy\n4. Add comprehensive testing for file handling scenarios\n",
      "state": "closed",
      "author": "jesalg",
      "author_type": "User",
      "created_at": "2025-03-25T22:56:34Z",
      "updated_at": "2025-05-25T15:33:02Z",
      "closed_at": "2025-03-26T17:19:28Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2549/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2549",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2549",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:27.628855",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Hi @jesalg \nI have investigated and it seems this happens because the team-leader agent thinks it doesn't have any files to forward. The ability is there however. I have merged a change with better instructions to make it easier for the team-leader agent to succeed at this. If it is still a problem,",
          "created_at": "2025-03-27T10:18:55Z"
        },
        {
          "author": "jesalg",
          "body": "@dirkbrnd Thanks for quickly jumping on this. Unfortuantely this hasn't fully addressed the issue. What I'm seeing now in `1.2.5` is:\n\n- Files are successfully received and processed at the team level\n- The forwarding mechanism (`aforward_task_to_member`) appears to drop the file attachments when pa",
          "created_at": "2025-03-27T18:04:51Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @jesalg \nHave you seen this [example cookbook](https://github.com/agno-agi/agno/blob/239de92870128e51e9f27ddc334e2059d95b2c28/cookbook/examples/teams/route/multi_purpose_team.py)? I recently added a file analysis agent here as a member of a team. This one works for me.\n\nThe file will automaticall",
          "created_at": "2025-03-31T09:34:28Z"
        },
        {
          "author": "jesalg",
          "body": "Thanks for that example @dirkbrnd. Some differences from the cookbook that may be impacting the outcome:\n- I'm using gpt-4o\n- My `File` objects have a `url` vs a `filepath`",
          "created_at": "2025-03-31T23:11:02Z"
        }
      ]
    },
    {
      "issue_number": 2319,
      "title": "[Feature Request] Any plan to support liteLLM ?",
      "body": "## **Problem Description**  \nCurrently, Agno does not support **LiteLLM**, which provides a unified API for multiple LLM providers, reducing integration complexity and enhancing flexibility. This limitation makes it challenging to switch between different model providers dynamically.  \n\n## **Proposed Solution**  \nIt would be beneficial if Agno supported **LiteLLM** natively, allowing users to interact with multiple LLMs through a single API. Ideally, Agno should provide:  \n- Seamless integration with **LiteLLM** as a backend option.  \n- Configuration settings to define model providers dynamically.  \n- Compatibility with existing Agno features (e.g., caching, rate limiting, logging).  \n\n## **Alternatives Considered**  \n- Manually wrapping LiteLLM within Agno, but this requires additional middleware and increases maintenance overhead.  \n- Using different model APIs separately, which defeats the purpose of a unified interface.  \n\n## **Additional Context**  \n- LiteLLM: [https://github.com/BerriAI/litellm](https://github.com/BerriAI/litellm)  \n- Many AI platforms (e.g., LangChain, LlamaIndex) are already integrating LiteLLM for easier model switching.  \n\n## **Would you like to work on this?**  \n**[ ] Yes, I’d love to work on it!**  \n**[ ] I’m open to collaborating but need guidance.**  \n**[x] No, I’m just sharing the idea.**  ",
      "state": "closed",
      "author": "isaac47",
      "author_type": "User",
      "created_at": "2025-03-07T11:59:24Z",
      "updated_at": "2025-05-23T18:06:00Z",
      "closed_at": "2025-03-21T07:24:58Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2319/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2319",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2319",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:27.832401",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "This is now supported!",
          "created_at": "2025-03-21T07:24:58Z"
        },
        {
          "author": "ShivanshJ",
          "body": "Literally was deciding on Agno based on this - thanks!\nHere are the docs for reference for whoever visits this.: [link](https://docs.agno.com/examples/models/litellm/basic)",
          "created_at": "2025-05-23T18:03:27Z"
        }
      ]
    },
    {
      "issue_number": 1814,
      "title": "add AI/ML API as llm provider",
      "body": "Hi!\nI'm from the Integrations team over at [AI/ML API](https://aimlapi.com/)\n\nYour project looks dope, so we'd like to have a native integration with it.\n\nSay you're interested, and we'll test the compatibility, update the docs to include us, and add a tutorial on using phidata with AI/ML API to our docs",
      "state": "closed",
      "author": "OctavianTheI",
      "author_type": "User",
      "created_at": "2025-01-17T08:42:17Z",
      "updated_at": "2025-05-23T11:37:30Z",
      "closed_at": "2025-02-02T00:31:27Z",
      "labels": [
        "stale"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/1814/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/1814",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/1814",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:28.018100",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Thanks!\nWe welcome contributions. It would be amazing if you added that as a provider. I will review.",
          "created_at": "2025-01-18T05:55:28Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-02-02T00:31:26Z"
        },
        {
          "author": "OctavianTheI",
          "body": "took us a while - but we'd love to get integrated and do some crosspromo :)\n\nhttps://github.com/agno-agi/agno/pull/3209",
          "created_at": "2025-05-23T11:37:29Z"
        }
      ]
    },
    {
      "issue_number": 3321,
      "title": "[Bug] The 'session_state' parameter invalidates the 'storage' parameter",
      "body": "### Description\n\nIf \"session_state\" is set,\"storage\" will be disabled (no data will be stored in the postgresql database); If I turn off \"session_state\", everything is back to normal and the chat data is stored in the database store as expected\n\n### Steps to Reproduce\n\n1. Run the script\n\n### Agent Configuration (if applicable)\n\n```python\nimport sys, os\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nfrom agno.agent import Agent\nfrom agno.playground import Playground, serve_playground_app\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\nfrom textwrap import dedent\nfrom llm.base import qwen_chat_model\nfrom agno.storage.postgres import PostgresStorage\nfrom config import settings\n\nclass DebtInfo(BaseModel):\n    debtor_name: Optional[str] = Field(None, description=\"The name of the debtor\")\n    debt_amount: Optional[float] = Field(None, description=\"The amount of the debt\")\n    debtor_card_id: Optional[str] = Field(None, description=\"The ID of the debtor\")\n    debtor_enforcement: Optional[bool] = Field(None, description=\"Whether the debtor is an executor\")\n    debtor_enforcement_check_source: Optional[str] = Field(None, description=\"The source of the debtor's enforcement status\")\n\nclass EvidenceItem(BaseModel):\n    debt_type: Optional[str] = Field(None, description=\"The type of the debt\")\n    evidence_name: Optional[str] = Field(None, description=\"The name of the evidence\")\n    evidence_description: Optional[str] = Field(None, description=\"The description of the evidence\")\n    \nclass EvidenceChain(BaseModel):\n    debt_type: Optional[str] = Field(None, description=\"The type of the debt\")\n    evidences_required: Optional[List[EvidenceItem]] = Field(None, description=\"The evidences required for the debt\")\n    \nclass DeptInfo(BaseModel):\n    debt_type: Optional[str] = Field(None, description=\"The type of the debt\")\n    debtor_name: Optional[str] = Field(None, description=\"The name of the debtor\")\n    debt_amount: Optional[float] = Field(None, description=\"The amount of the debt\")\n    debtor_card_id: Optional[str] = Field(None, description=\"The ID of the debtor\")\n    debtor_enforcement: Optional[bool] = Field(None, description=\"Whether the debtor is an executor\")\n    debtor_enforcement_check_source: Optional[str] = Field(None, description=\"The source of the debtor's enforcement status\")\n    \nclass CaseInfo(BaseModel):\n    debt_info: Optional[DeptInfo] = Field(None, description=\"The information of the debt\")\n    evidence_chain: Optional[EvidenceChain] = Field(None, description=\"The evidence chain\")\n    \n\"\"\"\n1. 明确'债权债务基本情况'\n2. 根据'债权债务基本情况'，检索知识库确认证据链要求\n3. 进入证据链证据收集，引导用户收集证据\n4. 将收集的证据更新到全局的证据链词槽\n\"\"\"\n\nagent_storage = PostgresStorage(\n    table_name=\"evidence_data\",\n    db_url=settings.DB_URL,\n    auto_upgrade_schema=True,\n)\n\nsession_state = dict()\nsession_state[\"case_info\"] = CaseInfo(\n    debt_info=DeptInfo(),\n    evidence_chain=EvidenceChain()\n)\nsession_state[\"next_step_key\"] = \"\"\n\nprint(session_state)\n\nevidence_analysis_agent = Agent(\n    name=\"Case Analysis Agent\",\n    role=\"Case Analysis Professor\",\n    model=qwen_chat_model,\n    description=\"Analyze the basic situation of creditor's rights and debts, and give guidance.\",\n    # session_state=session_state,\n    user_id=\"u15\",\n    session_id=\"s15\",\n    add_state_in_messages=True,\n    context={\n        \"case_info\": session_state[\"case_info\"],\n        \"next_step_key\": session_state[\"next_step_key\"]\n    },\n    \n    markdown=True,\n    debug_mode=True,\n    show_tool_calls=True,\n    add_history_to_messages=True,\n    num_history_responses=3,\n    storage=agent_storage,\n    \n    instructions=dedent(\"\"\"\n    # 流程说明\n    1. 始终先确认{case_info}中的内容，并关注{next_step_key}的值，它们是案件要求的相关信息和当前的确认执行的步骤.\n    2. 根据{case_info}中的内容（有先后顺序），询问用户是否可以提供某个信息.\n    3. 如果用户可以提供某个信息，则将该信息更新到{case_info}中，并注意更新{next_step_key}的值.\n    4. 如果用户不能提供某个信息，则给出指导，让用户提供该信息.\n    \n    # 注意事项\n    1. 始终以{case_info}和{next_step_key}为驱动，不要使用其他信息或自行生成信息.\n    2. 始终不要向用户解释你的执行过程.\n    \"\"\"),   \n)\n\napp = Playground(agents=[evidence_analysis_agent]).get_app()\n\nif __name__ == \"__main__\":\n    serve_playground_app(\"evidence_analysis:app\", reload=True, host=\"0.0.0.0\", port=9003)\n```\n\n### Expected Behavior\n\nWhen the \"session_state\" parameter and \"storage\" are configured, session data is stored in the specified postgresql database as expected\n\n### Actual Behavior\n\nWhen the \"session_state\" parameter and \"storage\" are configured, the session data is not stored in the corresponding postgresql database\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n- OS: macOS Sequoia 15.5\n- Agno: 1.5.1\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "open",
      "author": "sungaoxiang-backend",
      "author_type": "User",
      "created_at": "2025-05-23T08:35:49Z",
      "updated_at": "2025-05-23T08:35:53Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3321/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3321",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3321",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:28.220655",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-292/bug-the-session-state-parameter-invalidates-the-storage-parameter\">SUPPORT-292 [Bug] The 'session_state' parameter invalidates the 'storage' parameter</a></p>",
          "created_at": "2025-05-23T08:35:52Z"
        }
      ]
    },
    {
      "issue_number": 2583,
      "title": "[Feature Request]How can I use Human in the Loop in Playground or streamlit? Do you have any examples or demos",
      "body": "## Problem Description\nHow can I use Human in the Loop in Playground or streamlit? Do you have any examples or demos\nthanks",
      "state": "closed",
      "author": "ruidanwang",
      "author_type": "User",
      "created_at": "2025-03-28T04:20:25Z",
      "updated_at": "2025-05-22T13:07:03Z",
      "closed_at": "2025-04-12T00:31:40Z",
      "labels": [
        "question",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2583/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2583",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2583",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:28.404685",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hey @ruidanwang \nThank you for reaching out.\nPlease find the examples in our cookbooks, here's the link https://github.com/agno-agi/agno/blob/e67ee577664da81d64486d0682baa2083ae8659b/cookbook/getting_started/19_human_in_the_loop.py\n\nplease reach out incase you have any doubts",
          "created_at": "2025-03-28T16:29:10Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-12T00:31:39Z"
        },
        {
          "author": "meetzuber",
          "body": "How can we use HITL using API. I want to use this as human approval before executing some tools. any example of using this as API endpoint or web.\n\nThanks",
          "created_at": "2025-05-01T10:50:56Z"
        },
        {
          "author": "ilesh-vinayaktech",
          "body": "@meetzuber  Have you find any solution for the same? I want similar functionality",
          "created_at": "2025-05-22T13:07:02Z"
        }
      ]
    },
    {
      "issue_number": 3137,
      "title": "[Bug] Empty anthropic responses generated but these are invalid when sent back to the model in aws/claude.py",
      "body": "# Description\nAnthropic model sometimes responds with empty assistant messages (empty content) with tool calls. However sending these back in results in an error.\n\nValueError: Bad response code, expected 200: {'status_code': 400, 'headers': {':exception-type': 'validationException', ':content-type': 'application/json', ':message-type': 'exception'}, 'body': b'{\"message\":\"messages: text content blocks must contain non-whitespace text\"}'}\n\n## Steps to Reproduce\nShould be reproducible on any anthropic model.\n\n## Agent Configuration (if applicable)\nProvide relevant agent configuration.\n\n## Expected Behavior\nSmooth streaming of response\n## Actual Behavior\nThis crashes the agent because empty content messages are invalid with anthropic.\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n![Image](https://github.com/user-attachments/assets/14d64fd2-6d0d-4377-95b9-00f41b5ccf01)\n\n## Environment\nlatest agno version and using Anthropic Claude 3.7 on bedrock.\n\n## Possible Solutions (optional)\nThe temporary solution that I am using is to overwrite the changes in aws/claude.py that was done in anthropic/claude.py . The file content is below. Please do fix the fix the code in future release.\n\nimport json\nfrom dataclasses import dataclass\nfrom os import getenv\nfrom typing import Any, AsyncIterator, Dict, List, Optional, Tuple\n\nfrom agno.exceptions import ModelProviderError, ModelRateLimitError\nfrom agno.media import Image\nfrom agno.models.anthropic import Claude as AnthropicClaude\nfrom agno.models.message import Message\nfrom agno.utils.log import log_error, log_warning\nfrom agno.utils.models.claude import format_messages\n\ntry:\n    from anthropic import AnthropicBedrock, APIConnectionError, APIStatusError, AsyncAnthropicBedrock, RateLimitError\n    from anthropic.types import Message as AnthropicMessage\n    from anthropic.types import (\n        TextBlock,\n        ToolUseBlock,\n    )\nexcept ImportError:\n    log_error(\"`anthropic[bedrock]` not installed. Please install it via `pip install anthropic[bedrock]`.\")\n    raise\n\ntry:\n    from boto3.session import Session\nexcept ImportError:\n    log_error(\"`boto3` not installed. Please install it via `pip install boto3`.\")\n    raise\n\n@dataclass\nclass Claude(AnthropicClaude):\n    \"\"\"\n    AWS Bedrock Claude model.\n\n    Args:\n        aws_region (Optional[str]): The AWS region to use.\n        aws_access_key (Optional[str]): The AWS access key to use.\n        aws_secret_key (Optional[str]): The AWS secret key to use.\n        session (Optional[Session]): A boto3 Session object to use for authentication.\n    \"\"\"\n\n    id: str = \"anthropic.claude-3-5-sonnet-20240620-v1:0\"\n    name: str = \"AwsBedrockAnthropicClaude\"\n    provider: str = \"AwsBedrock\"\n\n    aws_access_key: Optional[str] = None\n    aws_secret_key: Optional[str] = None\n    aws_region: Optional[str] = None\n    session: Optional[Session] = None\n\n    # -*- Request parameters\n    max_tokens: int = 4096\n    temperature: Optional[float] = None\n    top_p: Optional[float] = None\n    top_k: Optional[int] = None\n    stop_sequences: Optional[List[str]] = None\n\n    # -*- Request parameters\n    request_params: Optional[Dict[str, Any]] = None\n    # -*- Client parameters\n    client_params: Optional[Dict[str, Any]] = None\n\n    def to_dict(self) -> Dict[str, Any]:\n        _dict = super().to_dict()\n        _dict[\"max_tokens\"] = self.max_tokens\n        _dict[\"temperature\"] = self.temperature\n        _dict[\"top_p\"] = self.top_p\n        _dict[\"top_k\"] = self.top_k\n        _dict[\"stop_sequences\"] = self.stop_sequences\n        return _dict\n\n    client: Optional[AnthropicBedrock] = None  # type: ignore\n    async_client: Optional[AsyncAnthropicBedrock] = None  # type: ignore\n\n    def get_client(self):\n        if self.client is not None:\n            return self.client\n\n        client_params = {}\n\n        if self.session:\n            credentials = self.session.get_credentials()\n            client_params = {\n                \"aws_access_key\": credentials.access_key,\n                \"aws_secret_key\": credentials.secret_key,\n                \"aws_session_token\": credentials.token,\n                \"aws_region\": self.session.region_name,\n            }\n        else:\n            self.aws_access_key = self.aws_access_key or getenv(\"AWS_ACCESS_KEY\")\n            self.aws_secret_key = self.aws_secret_key or getenv(\"AWS_SECRET_KEY\")\n            self.aws_region = self.aws_region or getenv(\"AWS_REGION\")\n\n            client_params = {\n                \"aws_secret_key\": self.aws_secret_key,\n                \"aws_access_key\": self.aws_access_key,\n                \"aws_region\": self.aws_region,\n            }\n\n        if self.client_params:\n            client_params.update(self.client_params)\n\n        self.client = AnthropicBedrock(\n            **client_params,  # type: ignore\n        )\n        return self.client\n\n    def get_async_client(self):\n        if self.async_client is not None:\n            return self.async_client\n\n        client_params = {}\n\n        if self.session:\n            credentials = self.session.get_credentials()\n            client_params = {\n                \"aws_access_key\": credentials.access_key,\n                \"aws_secret_key\": credentials.secret_key,\n                \"aws_session_token\": credentials.token,\n                \"aws_region\": self.session.region_name,\n            }\n        else:\n            client_params = {\n                \"aws_secret_key\": self.aws_secret_key,\n                \"aws_access_key\": self.aws_access_key,\n                \"aws_region\": self.aws_region,\n            }\n\n        if self.client_params:\n            client_params.update(self.client_params)\n\n        self.async_client = AsyncAnthropicBedrock(\n            **client_params,  # type: ignore\n        )\n        return self.async_client\n\n    @property\n    def request_kwargs(self) -> Dict[str, Any]:\n        \"\"\"\n        Generate keyword arguments for API requests.\n        \"\"\"\n        _request_params: Dict[str, Any] = {}\n        if self.max_tokens:\n            _request_params[\"max_tokens\"] = self.max_tokens\n        if self.temperature:\n            _request_params[\"temperature\"] = self.temperature\n        if self.stop_sequences:\n            _request_params[\"stop_sequences\"] = self.stop_sequences\n        if self.top_p:\n            _request_params[\"top_p\"] = self.top_p\n        if self.top_k:\n            _request_params[\"top_k\"] = self.top_k\n        if self.request_params:\n            _request_params.update(self.request_params)\n        return _request_params\n\n    def invoke(self, messages: List[Message]) -> AnthropicMessage:\n        \"\"\"\n        Send a request to the Anthropic API to generate a response.\n\n        Args:\n            messages (List[Message]): A list of messages to send to the model.\n\n        Returns:\n            AnthropicMessage: The response from the model.\n\n        Raises:\n            APIConnectionError: If there are network connectivity issues\n            RateLimitError: If the API rate limit is exceeded\n            APIStatusError: For other API-related errors\n        \"\"\"\n\n        try:\n            chat_messages, system_message = format_messages(messages)\n            request_kwargs = self._prepare_request_kwargs(system_message)\n\n            return self.get_client().messages.create(\n                model=self.id,\n                messages=chat_messages,  # type: ignore\n                **request_kwargs,\n            )\n        except APIConnectionError as e:\n            log_error(f\"Connection error while calling Claude API: {str(e)}\")\n            raise ModelProviderError(message=e.message, model_name=self.name, model_id=self.id) from e\n        except RateLimitError as e:\n            log_warning(f\"Rate limit exceeded: {str(e)}\")\n            raise ModelRateLimitError(message=e.message, model_name=self.name, model_id=self.id) from e\n        except APIStatusError as e:\n            log_error(f\"Claude API error (status {e.status_code}): {str(e)}\")\n            raise ModelProviderError(\n                message=e.message, status_code=e.status_code, model_name=self.name, model_id=self.id\n            ) from e\n        except Exception as e:\n            log_error(f\"Unexpected error calling Claude API: {str(e)}\")\n            raise ModelProviderError(message=str(e), model_name=self.name, model_id=self.id) from e\n\n    def invoke_stream(self, messages: List[Message]) -> Any:\n        \"\"\"\n        Stream a response from the Anthropic API.\n\n        Args:\n            messages (List[Message]): A list of messages to send to the model.\n\n        Returns:\n            Any: The streamed response from the model.\n        \"\"\"\n\n        chat_messages, system_message = format_messages(messages)\n        request_kwargs = self._prepare_request_kwargs(system_message)\n\n        try:\n            return (\n                self.get_client()\n                .messages.stream(\n                    model=self.id,\n                    messages=chat_messages,  # type: ignore\n                    **request_kwargs,\n                )\n                .__enter__()\n            )\n        except APIConnectionError as e:\n            log_error(f\"Connection error while calling Claude API: {str(e)}\")\n            raise ModelProviderError(message=e.message, model_name=self.name, model_id=self.id) from e\n        except RateLimitError as e:\n            log_warning(f\"Rate limit exceeded: {str(e)}\")\n            raise ModelRateLimitError(message=e.message, model_name=self.name, model_id=self.id) from e\n        except APIStatusError as e:\n            log_error(f\"Claude API error (status {e.status_code}): {str(e)}\")\n            raise ModelProviderError(\n                message=e.message, status_code=e.status_code, model_name=self.name, model_id=self.id\n            ) from e\n        except Exception as e:\n            log_error(f\"Unexpected error calling Claude API: {str(e)}\")\n            raise ModelProviderError(message=str(e), model_name=self.name, model_id=self.id) from e\n\n    async def ainvoke(self, messages: List[Message]) -> AnthropicMessage:\n        \"\"\"\n        Send an asynchronous request to the Anthropic API to generate a response.\n\n        Args:\n            messages (List[Message]): A list of messages to send to the model.\n\n        Returns:\n            AnthropicMessage: The response from the model.\n\n        Raises:\n            APIConnectionError: If there are network connectivity issues\n            RateLimitError: If the API rate limit is exceeded\n            APIStatusError: For other API-related errors\n        \"\"\"\n\n        try:\n            chat_messages, system_message = format_messages(messages)\n            request_kwargs = self._prepare_request_kwargs(system_message)\n\n            return await self.get_async_client().messages.create(\n                model=self.id,\n                messages=chat_messages,  # type: ignore\n                **request_kwargs,\n            )\n        except APIConnectionError as e:\n            log_error(f\"Connection error while calling Claude API: {str(e)}\")\n            raise ModelProviderError(message=e.message, model_name=self.name, model_id=self.id) from e\n        except RateLimitError as e:\n            log_warning(f\"Rate limit exceeded: {str(e)}\")\n            raise ModelRateLimitError(message=e.message, model_name=self.name, model_id=self.id) from e\n        except APIStatusError as e:\n            log_error(f\"Claude API error (status {e.status_code}): {str(e)}\")\n            raise ModelProviderError(\n                message=e.message, status_code=e.status_code, model_name=self.name, model_id=self.id\n            ) from e\n        except Exception as e:\n            log_error(f\"Unexpected error calling Claude API: {str(e)}\")\n            raise ModelProviderError(message=str(e), model_name=self.name, model_id=self.id) from e\n\n    async def ainvoke_stream(self, messages: List[Message]) -> AsyncIterator[Any]:\n        \"\"\"\n        Stream an asynchronous response from the Anthropic API.\n\n        Args:\n            messages (List[Message]): A list of messages to send to the model.\n\n        Returns:\n            Any: The streamed response from the model.\n        \"\"\"\n\n        try:\n            chat_messages, system_message = format_messages(messages)\n            request_kwargs = self._prepare_request_kwargs(system_message)\n            async with self.get_async_client().messages.stream(\n                model=self.id,\n                messages=chat_messages,  # type: ignore\n                **request_kwargs,\n            ) as stream:\n                async for chunk in stream:\n                    yield chunk\n        except APIConnectionError as e:\n            log_error(f\"Connection error while calling Claude API: {str(e)}\")\n            raise ModelProviderError(message=e.message, model_name=self.name, model_id=self.id) from e\n        except RateLimitError as e:\n            log_warning(f\"Rate limit exceeded: {str(e)}\")\n            raise ModelRateLimitError(message=e.message, model_name=self.name, model_id=self.id) from e\n        except APIStatusError as e:\n            log_error(f\"Claude API error (status {e.status_code}): {str(e)}\")\n            raise ModelProviderError(\n                message=e.message, status_code=e.status_code, model_name=self.name, model_id=self.id\n            ) from e\n        except Exception as e:\n            log_error(f\"Unexpected error calling Claude API: {str(e)}\")\n            raise ModelProviderError(message=str(e), model_name=self.name, model_id=self.id) from e\n",
      "state": "closed",
      "author": "ABRAHSI1",
      "author_type": "User",
      "created_at": "2025-05-09T10:50:16Z",
      "updated_at": "2025-05-22T05:49:07Z",
      "closed_at": "2025-05-22T05:49:07Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3137/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kausmeows"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3137",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3137",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:28.639523",
      "comments": [
        {
          "author": "kausmeows",
          "body": "Hi @ABRAHSI1 , thanks for raising this. We're working on a fix asap!",
          "created_at": "2025-05-12T10:04:14Z"
        },
        {
          "author": "kausmeows",
          "body": "Hi @ABRAHSI1 can you tell  a bit more on how to reproduce this? Or could be provide the code you're using.\n\nI tried running the following cookbooks-\n- https://github.com/agno-agi/agno/blob/main/cookbook/models/aws/claude/tool_use.py\n- https://github.com/agno-agi/agno/blob/main/cookbook/models/aws/cl",
          "created_at": "2025-05-20T17:25:55Z"
        },
        {
          "author": "ABRAHSI1",
          "body": "Hi @kausmeows , The strange part was that this error didn't occur every time, maybe once in 10 times of calling the agent. The model i used is **us.anthropic.claude-3-7-sonnet-20250219-v1:0**. The setup was a multiagent system using Teams in route mode with one agent which interacts with confluence ",
          "created_at": "2025-05-21T06:42:19Z"
        },
        {
          "author": "ysolanky",
          "body": "Hi @ABRAHSI1 ! I have fixed the bug here: https://github.com/agno-agi/agno/pull/3285. ",
          "created_at": "2025-05-22T04:23:10Z"
        },
        {
          "author": "ABRAHSI1",
          "body": "Thanks @ysolanky and @kausmeows !!!",
          "created_at": "2025-05-22T05:49:01Z"
        }
      ]
    },
    {
      "issue_number": 2972,
      "title": "transfer_task_to_member is broken in coordinate mode",
      "body": "# Description\n\nWhen using teams mode with coordinate I get this Error always when moving to from Agent A -> Agent B.\nHere the coordinator accepts the request, passes it Agent A and then when Agent A is done its suppose to pass the work to Agent B but it instead fails and breaks the execution here \n```\nERROR    Function transfer_task_to_member not found                                                                          \n```\nPlease help",
      "state": "closed",
      "author": "UvRoxx",
      "author_type": "User",
      "created_at": "2025-04-24T15:23:59Z",
      "updated_at": "2025-05-21T17:49:07Z",
      "closed_at": "2025-05-06T15:40:11Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2972/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2972",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2972",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:28.846813",
      "comments": [
        {
          "author": "anuragts",
          "body": "Hey @UvRoxx can you provide us with your team config code, so we can reproduce the bug",
          "created_at": "2025-04-25T11:33:03Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@UvRoxx This should be fixed with the latest releases! Please share your agent code so we can confirm and confirm which version of `agno` you are running",
          "created_at": "2025-05-04T07:57:02Z"
        },
        {
          "author": "saikanov",
          "body": "> [@UvRoxx](https://github.com/UvRoxx) This should be fixed with the latest releases! Please share your agent code so we can confirm and confirm which version of `agno` you are running\n\nwhat is the version you guys talking about? tried version 1.4.3-1.4.6 and i got the same result",
          "created_at": "2025-05-13T12:55:42Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@saikanov We just released a fix that addresses similar issues. Please let me know if 1.5.0 works for you? If not, please share how you are configuring your team? \n",
          "created_at": "2025-05-13T15:40:36Z"
        },
        {
          "author": "saikanov",
          "body": "> [@saikanov](https://github.com/saikanov) We just released a fix that addresses similar issues. Please let me know if 1.5.0 works for you? If not, please share how you are configuring your team?\n\nhey, thanks, i already use your the PR and it is worked, waiting for the next release. i fix it with th",
          "created_at": "2025-05-13T15:42:58Z"
        }
      ]
    },
    {
      "issue_number": 3268,
      "title": "[Feature Request]  Support for Venice API",
      "body": "### Problem Description\n\n.https://discord.com/channels/965734768803192842/1374136168500957184/1374137037086789683\n\n### Proposed Solution\n\n.\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "monali7-d",
      "author_type": "User",
      "created_at": "2025-05-21T06:56:12Z",
      "updated_at": "2025-05-21T14:04:08Z",
      "closed_at": "2025-05-21T06:56:22Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3268/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3268",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3268",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:29.043709",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-247/feature-request-support-for-venice-api\">SUPPORT-247 [Feature Request] Support for Venice API</a></p>",
          "created_at": "2025-05-21T06:56:16Z"
        }
      ]
    },
    {
      "issue_number": 3254,
      "title": "[Bug] Team shared context are lost whenever move onto subsequent Agent",
      "body": "### Description\n\nExample, I have a Team that consist of 3 Agent.\nAgent A, B & C.\n\nWhenever Agent A finishes the tasks then will update to team_context.\nOnce that's done, the below would pop up in the debugging logs.\nWhenever such message appears, the subsequent Agent will pickup malformed team_context (JSON data that wasn't updated by Agent A) to process the tasks.\n\nAnd this process would keep repeating until final output is attainted (Could also be malformed team_context data).\n\nI've also no idea why connection attempt would keep failing only when using Team of Agents.\nThat too includes the cookbook with Team sample with the same issue.\n\n```bash\nDEBUG Added RunResponse to Memory                                                                                                 \nDEBUG Logging Agent Run \nDEBUG Could not create Agent run: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n```\n\n### Steps to Reproduce\n\n1. Setup a simple Team\n2. Provide 3 Agent to the Team with some tasks\n\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nteam_context should persist across Agents\n\n### Actual Behavior\n\nteam_context data are malformed when process by subsequent Agent\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n- Agno version 1.4.4\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "KageyamaJie",
      "author_type": "User",
      "created_at": "2025-05-20T11:58:04Z",
      "updated_at": "2025-05-21T09:01:02Z",
      "closed_at": "2025-05-21T09:00:16Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3254/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3254",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3254",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:29.239196",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-234/bug-team-shared-context-are-lost-whenever-move-onto-subsequent-agent\">SUPPORT-234 [Bug] Team shared context are lost whenever move onto subsequent Agent</a></p>",
          "created_at": "2025-05-20T11:58:06Z"
        },
        {
          "author": "KageyamaJie",
          "body": "Turns out need to pass the below to `http_client` parameter to your LLM Model's param\n\n```python\nshared_sync_client = httpx.Client(trust_env=True)\nshared_async_client = httpx.AsyncClient(trust_env=True)\n```\n\nWhile having the below in `.env` file, especially `NO_PROXY` as following:\n\n```bash\nexport H",
          "created_at": "2025-05-21T09:00:16Z"
        }
      ]
    },
    {
      "issue_number": 3241,
      "title": "[Bug]     sse_read_timeout=200 do not work",
      "body": "### Description\n\nagno 1.5.1\n\nwhen a tool response time  more than 5 seconds , it will return  timeout ,even if i set \"sse_read_timeout=200\" and  \"timeout=100\"  in SSEClientParams\n\n\n### Steps to Reproduce\n\n\ncode like below\n\n```python\nserver_params = SSEClientParams(\n    url=\"https://xxxxx/sse\",\n    headers={\"Authorization\":\"Bearer YYYYYYYYYYYYYYYYYYYYYYYYY\"},\n    timeout=100,\n    sse_read_timeout=200\n)\n\nasync def run_agent(message: str):\n    # Initialize the MCP server\n    async with MCPTools( \n        server_params=server_params,\n        transport=\"sse\"\n    ) as fs_tools:\n\n```\n\nand terminal output  like \n\n```log\n\nDEBUG =================================================================================================== tool ===================================================================================================\nDEBUG Tool call Id: call_d96a223145a64aa2a0b250\nDEBUG Error: Timed out while waiting for response to ClientRequest. Waited 5.0 seconds.\nDEBUG **********************************************************************************************  TOOL METRICS  **********************************************************************************************\nDEBUG * Time:                        5.0211s\nDEBUG **********************************************************************************************  TOOL METRICS  **********************************************************************************************\n\n```\n\n### Agent Configuration (if applicable)\n\nlike above\n\n### Expected Behavior\n\ncall the tool as shorter tools invoke\n\n### Actual Behavior\n\nshow timeout error and retry again and fail again\n\n### Screenshots or Logs (if applicable)\n\n```log\n\nDEBUG =================================================================================================== tool ===================================================================================================\nDEBUG Tool call Id: call_d96a223145a64aa2a0b250\nDEBUG Error: Timed out while waiting for response to ClientRequest. Waited 5.0 seconds.\nDEBUG **********************************************************************************************  TOOL METRICS  **********************************************************************************************\nDEBUG * Time:                        5.0211s\nDEBUG **********************************************************************************************  TOOL METRICS  **********************************************************************************************\n\n```\n\n### Environment\n\n```markdown\nit shows above\n```\n\n### Possible Solutions (optional)\n\nmaybe the timeout does not work\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "lilongthinker",
      "author_type": "User",
      "created_at": "2025-05-19T13:33:20Z",
      "updated_at": "2025-05-21T08:31:11Z",
      "closed_at": "2025-05-21T08:31:10Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3241/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3241",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3241",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:29.576590",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-217/bug-sse-read-timeout=200-do-not-work\">SUPPORT-217 [Bug] sse_read_timeout=200 do not work</a></p>",
          "created_at": "2025-05-19T13:33:23Z"
        },
        {
          "author": "lilongthinker",
          "body": "finally when i set timeout_seconds in the mcp tool param it works\n\n```python\nasync def run_agent(message: str):\n    # Initialize the MCP server\n    async with MCPTools( \n        server_params=server_params,\n        transport=\"sse\",\n        timeout_seconds=30        #this works\n    ) as fs_tools:\n```",
          "created_at": "2025-05-20T12:05:55Z"
        },
        {
          "author": "manuhortet",
          "body": "Hey @lilongthinker, I see how this was confusing! We will refactor so the `timeout` field in the client params take effect over the tool's `timeout_seconds` when relevant. \n\nThanks for raising this, and let us know if we can help with anything else!",
          "created_at": "2025-05-21T08:31:10Z"
        }
      ]
    },
    {
      "issue_number": 3267,
      "title": "[Feature Request]  Agno support with Apache Solr as Vector DB,",
      "body": "### Problem Description\n\n.\n\n### Proposed Solution\n\n.\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\n.\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "monali7-d",
      "author_type": "User",
      "created_at": "2025-05-21T06:55:32Z",
      "updated_at": "2025-05-21T06:56:32Z",
      "closed_at": "2025-05-21T06:56:32Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3267/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3267",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3267",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:30.803524",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-246/feature-request-agno-support-with-apache-solr-as-vector-db\">SUPPORT-246 [Feature Request] Agno support with Apache Solr as Vector DB,</a></p>",
          "created_at": "2025-05-21T06:55:34Z"
        }
      ]
    },
    {
      "issue_number": 3264,
      "title": "[Feature Request]  Support for Supabase Integration",
      "body": "### Problem Description\n\n.\n\n### Proposed Solution\n\n.\n\n### Alternatives Considered\n\n.\n\n### Additional Context\n\n.\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "monali7-d",
      "author_type": "User",
      "created_at": "2025-05-21T05:38:16Z",
      "updated_at": "2025-05-21T05:38:32Z",
      "closed_at": "2025-05-21T05:38:32Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3264/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3264",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3264",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:31.037549",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-240/feature-request-support-for-supabase-integration\">SUPPORT-240 [Feature Request] Support for Supabase Integration</a></p>",
          "created_at": "2025-05-21T05:38:19Z"
        }
      ]
    },
    {
      "issue_number": 3201,
      "title": "[Bug] LangchainKnowledgeBase",
      "body": "### Description\n\nWhen I was using Agno version 1.4.5, I could retrieve relevant information from the knowledge base when querying an agent about a certain example. However, after updating to version 1.4.6, it can no longer find the related information, even though I haven't changed the knowledge base. Could it be that the knowledge base interface has changed in the new version of Agno?\n\n`\nfrom langchain.embeddings import HuggingFaceEmbeddings\nembeddings = HuggingFaceEmbeddings(\n    model_name=\"BAAI/bge-large-zh-v1.5\",  \n    cache_folder=\"/home/kino/.cache/huggingface/hub\",\n    model_kwargs={\n        \"local_files_only\": True\n    }\n)\n\nvector_db_pro = Milvus(\n    collection_name=\"pro_alld\",\n    embedding_function=embeddings,\n    connection_args={\n        \"uri\": \"./milvus_allprod300_large_1_5.db\",\n    },\n)\n\nretriever_pro = vector_db_pro.as_retriever()\nknowledge_base_pro = LangChainKnowledgeBase(retriever=retriever_pro)\n\nagent = Agent(\n     model=DeepSeek(api_key=DEEPSEEK_API_KEY),\n     instructions=[\n         \"Always search your knowledge before answering the question.\"\n     ],\n     markdown=True,\n     debug_mode=True,\n     knowledge=knowledge_base_pro, \n     add_references=False,\n     search_knowledge=True)\n`\n\n### Steps to Reproduce\n\n1. use LangchainKnowledgeBase\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\n1.Successfully retrieved information from the knowledge base.\n\n### Actual Behavior\n\nnot get any replay\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nuv pip list\nPackage                  Version\n------------------------ -----------\nagno                     1.4.6\naiohappyeyeballs         2.6.1\naiohttp                  3.11.18\naiosignal                1.3.2\nannotated-types          0.7.0\nanyio                    4.9.0\nasttokens                3.0.0\nattrs                    25.3.0\ncachetools               5.5.2\ncertifi                  2025.4.26\ncharset-normalizer       3.4.1\nchonkie                  1.0.5\nclick                    8.1.8\ncomm                     0.2.2\ndataclasses-json         0.6.7\ndebugpy                  1.8.14\ndecorator                5.2.1\ndeepseek                 1.0.0\ndistro                   1.9.0\ndocstring-parser         0.16\nduckduckgo-search        8.0.1\nexecuting                2.2.0\nfilelock                 3.18.0\nfrozenlist               1.6.0\nfsspec                   2025.3.2\ngitdb                    4.0.12\ngitpython                3.1.44\ngoogle-auth              2.39.0\ngoogle-genai             1.12.1\ngreenlet                 3.2.1\ngrpcio                   1.67.1\nh11                      0.16.0\nhttpcore                 1.0.9\nhttpx                    0.28.1\nhttpx-sse                0.4.0\nhuggingface-hub          0.30.2\nidna                     3.10\nipykernel                6.29.5\nipython                  9.1.0\nipython-pygments-lexers  1.1.1\nipywidgets               8.1.6\njedi                     0.19.2\njinja2                   3.1.6\njiter                    0.9.0\njoblib                   1.4.2\njsonpatch                1.33\njsonpointer              3.0.0\njupyter-client           8.6.3\njupyter-core             5.7.2\njupyterlab-widgets       3.0.14\nlangchain                0.3.24\nlangchain-community      0.3.22\nlangchain-core           0.3.55\nlangchain-milvus         0.1.9\nlangchain-text-splitters 0.3.8\nlangsmith                0.3.33\nlxml                     5.4.0\nmarkdown                 3.8\nmarkdown-it-py           3.0.0\nmarkdown2                2.5.3\nmarkupsafe               3.0.2\nmarshmallow              3.26.1\nmatplotlib-inline        0.1.7\nmdurl                    0.1.2\nmilvus-lite              2.4.12\nmpmath                   1.3.0\nmultidict                6.4.3\nmypy-extensions          1.1.0\nnest-asyncio             1.6.0\nnetworkx                 3.4.2\nnumpy                    2.2.5\nnvidia-cublas-cu12       12.6.4.1\nnvidia-cuda-cupti-cu12   12.6.80\nnvidia-cuda-nvrtc-cu12   12.6.77\nnvidia-cuda-runtime-cu12 12.6.77\nnvidia-cudnn-cu12        9.5.1.17\nnvidia-cufft-cu12        11.3.0.4\nnvidia-cufile-cu12       1.11.1.6\nnvidia-curand-cu12       10.3.7.77\nnvidia-cusolver-cu12     11.7.1.2\nnvidia-cusparse-cu12     12.5.4.2\nnvidia-cusparselt-cu12   0.6.3\nnvidia-nccl-cu12         2.26.2\nnvidia-nvjitlink-cu12    12.6.85\nnvidia-nvtx-cu12         12.6.77\nopenai                   1.76.0\norjson                   3.10.16\npackaging                24.2\npandas                   2.2.3\nparso                    0.8.4\npexpect                  4.9.0\npillow                   11.2.1\nplatformdirs             4.3.7\nprimp                    0.15.0\nprompt-toolkit           3.0.51\npropcache                0.3.1\nprotobuf                 6.30.2\npsutil                   7.0.0\nptyprocess               0.7.0\npure-eval                0.2.3\npyasn1                   0.6.1\npyasn1-modules           0.4.2\npydantic                 2.11.4\npydantic-core            2.33.2\npydantic-settings        2.9.1\npygments                 2.19.1\npymilvus                 2.5.6\npython-dateutil          2.9.0.post0\npython-dotenv            1.1.0\npython-multipart         0.0.20\npytz                     2025.2\npyyaml                   6.0.2\npyzmq                    26.4.0\nregex                    2024.11.6\nrequests                 2.32.3\nrequests-toolbelt        1.0.0\nrich                     14.0.0\nrsa                      4.9.1\nsafetensors              0.5.3\nscikit-learn             1.6.1\nscipy                    1.15.2\nsentence-transformers    4.1.0\nsetuptools               79.0.1\nshellingham              1.5.4\nsix                      1.17.0\nsmmap                    5.0.2\nsniffio                  1.3.1\nsqlalchemy               2.0.40\nstack-data               0.6.3\nsympy                    1.13.3\ntenacity                 9.1.2\nthreadpoolctl            3.6.0\ntokenizers               0.21.1\ntomli                    2.2.1\ntorch                    2.7.0\ntornado                  6.4.2\ntqdm                     4.67.1\ntraitlets                5.14.3\ntransformers             4.51.3\ntriton                   3.3.0\ntyper                    0.15.4\ntyping-extensions        4.13.2\ntyping-inspect           0.9.0\ntyping-inspection        0.4.0\ntzdata                   2025.2\nujson                    5.10.0\nurllib3                  2.4.0\nwcwidth                  0.2.13\nwebsockets               15.0.1\nwidgetsnbextension       4.0.14\nyarl                     1.20.0\nzstandard                0.23.0\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "KinonoChen",
      "author_type": "User",
      "created_at": "2025-05-15T02:32:06Z",
      "updated_at": "2025-05-21T02:43:29Z",
      "closed_at": "2025-05-15T07:14:28Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3201/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3201",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3201",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:31.241200",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-157/bug-langchainknowledgebase\">SUPPORT-157 [Bug] LangchainKnowledgeBase</a></p>",
          "created_at": "2025-05-15T02:32:09Z"
        },
        {
          "author": "KinonoChen",
          "body": "\"I’ve resolved the issue and will submit a PR later.",
          "created_at": "2025-05-15T07:14:15Z"
        },
        {
          "author": "rayterrill",
          "body": "Can we get more details on this and what version this is in? I saw this same issue, but it didn't seem limited to just langchainknowledgebase - I wasn't able to find knowledge from LanceDB either. Reverted to 1.2.16 that I was using previously and it's working again. Very difficult to troubleshoot.",
          "created_at": "2025-05-20T16:27:59Z"
        },
        {
          "author": "KinonoChen",
          "body": "> Can we get more details on this and what version this is in? I saw this same issue, but it didn't seem limited to just langchainknowledgebase - I wasn't able to find knowledge from LanceDB either. Reverted to 1.2.16 that I was using previously and it's working again. Very difficult to troubleshoot",
          "created_at": "2025-05-21T02:43:27Z"
        }
      ]
    },
    {
      "issue_number": 3246,
      "title": "[Bug]  Multiple bugs in Todoist integration tools",
      "body": "### Description\n\nI encountered several bugs when using the Todoist integration tools that prevent proper task handling:\n\n1. In `get_active_tasks`: Error `'list' object has no attribute 'id'` - API returns a nested list structure\n2. Task to dict conversion error: `'Task' object has no attribute 'comment_count'`\n3. Due date handling error: `'Due' object has no attribute 'datetime'`\n4. JSON serialization error: `Object of type datetime is not JSON serializable`\n\n\n\n### Steps to Reproduce\n\n\n1. Set up a Todoist account with tasks that have deadlines in the Inbox\n2. Run the following code:\n   ```python\n   from agno.tools.todoist import TodoistTools\n   tools = TodoistTools()\n   tasks = tools.get_active_tasks()\n   ```\n\n\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nThe ` get_active_tasks()` method should retrieve and return all active tasks from Todoist without errors.\n\n### Actual Behavior\n\n**Error sequence that occurs:**\n   * First error: `ERROR Failed to get active tasks: 'list' object has no attribute 'id'`\n   * After fixing list handling: `ERROR Failed to get active tasks: 'Task' object has no attribute 'comment_count'`\n   * After fixing attribute check: `ERROR Failed to get active tasks: 'Due' object has no attribute 'datetime'`\n   * After fixing Due object handling: `ERROR Failed to get active tasks: Object of type datetime is not JSON serializable`\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n-OS: Windows 10\n- Agno Version:1.5.1\n- Dependencies = [\n    \"groq=0.25.0\",\n    \"python-dotenv=1.1.0\",\n    \"todoist-api-python=3.1.0\",\n    \"tzdata=2025.2\",\n]\n- Python Version: tested on 3.10.17 and 3.11.6\n```\n\n### Possible Solutions (optional)\n\nI plan to submit a PR with the following fixes:\n1. Fix list handling in `get_active_tasks`\n2. Add attribute existence checks before adding to dict\n3. Replace missing `datetime` with actual attributes from API response\n4. Add `default=str` parameter to `json.dumps` calls for datetime serialization\n\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "SGP07",
      "author_type": "User",
      "created_at": "2025-05-20T04:55:02Z",
      "updated_at": "2025-05-20T17:15:16Z",
      "closed_at": "2025-05-20T17:15:16Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3246/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3246",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3246",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:31.451562",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-220/bug-multiple-bugs-in-todoist-integration-tools\">SUPPORT-220 [Bug] Multiple bugs in Todoist integration tools</a></p>",
          "created_at": "2025-05-20T04:55:05Z"
        }
      ]
    },
    {
      "issue_number": 3170,
      "title": "[Bug] Team moving from one agent to another produces a type error",
      "body": "### Description\n\nWhen the team leader in coordinate mode moves from any one agent to another agent, it produces this error:\n\nSomething went wrong. Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'messages.2: `tool_use` ids were found without `tool_result` blocks immediately after: call_IU3V69WqUdAPA1a1u515BLI4. Each `tool_use` block must have a corresponding `tool_result` block in the next message.'}}\n\nThis error does not occur if only one member is called and it also doesn't happen if each agent is run in isolation. This error occurs in the playground and using Team's arun() function.\n\n### Steps to Reproduce\n\n1. Create team with 2 members and same parameters as shown below\n\n### Agent Configuration (if applicable)\n\n```python\n# # initialize the agents by passing the prompt\n    agent_list = []\n    agent_list.append(load_data_analyst(user_id=user_id, session_id=session_id))\n\n    if sql_agent_enabled:\n        agent_list.append(load_sql_agent(user_id=user_id, session_id=session_id))\n\n    agent_team = Team(\n        name=\"Router Team\",\n        description=\"You are an ...\"\n        mode=\"coordinate\",\n        model=Claude(\"claude-3-7-sonnet-20250219\", temperature=0.8),\n        members=agent_list,\n        instructions=[\n           \"...\"\n            \"Whenever using the data analyst team member you **MUST** synchronise the \"sources\" key n your session state with this member's\n            session state *before* you answer the user. You will only do this using the sources tools provided to you.\"\n        ],\n        show_tool_calls=True,\n        markdown=True,\n        add_datetime_to_instructions=True,\n        enable_agentic_context=True,  # Allow the agent to maintain a shared context and send that to members.\n        share_member_interactions=True,  # Share all member responses with subsequent member requests.\n        show_members_responses=True,\n        get_member_information_tool=True,\n        monitoring=True,\n        session_id=session_id,\n        user_id=user_id,\n        session_state={\"sources\": [], \"user_id\": user_id},\n        add_state_in_messages=True,\n        storage=storage,\n        memory=memory,\n        read_team_history=True,\n        num_history_runs=5,\n        enable_session_summaries=True,\n        tools=[add_source,\n            bulk_add_sources,\n            clear_sources,\n            list_sources,\n            remove_source,\n            replace_sources,]\n    )\n\n    return agent_team\n\ndef load_data_analyst(user_id: Optional[str], session_id: Optional[str]):\n    print(user_id, session_id)\n    return Agent(\n        name=\"Data Analyst\",\n        role=\"Data Analyst\",\n        model=OpenAIChat(id=\"gpt-4.1\"),\n        tools=[\n            add_source,\n            remove_source,\n            list_sources,\n            clear_sources,\n            bulk_add_sources,\n            replace_sources,\n            find_relevant_summaries,\n            get_document_summaries_by_id,\n            find_relevant_document_chunks,\n            find_chunks_from_sources,\n            list_all_files,\n            find_file_by_name,\n            find_file_by_id,\n            ReasoningTools(add_instructions=True),\n            TavilyTools(search_depth=\"advanced\"),\n            get_date_time,\n        ],\n        session_id=session_id,\n        user_id=user_id,\n        monitoring=True,\n        session_state={\"sources\": [], \"user_id\": user_id},\n        add_state_in_messages=True,\n        show_tool_calls=True,\n        markdown=True,\n        storage=storage,\n        memory=memory,\n        enable_agentic_memory=True,\n        read_chat_history=True,\n        add_history_to_messages=True,\n        instructions=\"\"\"\n        You are an expert data analyst agent...    \n        \"\"\",\n    )\n\ndef load_sql_agent(user_id: Optional[str], session_id: Optional[str]):\n    return Agent(\n        name=\"SQL Wizard\",\n        role=\"SQL Expert\",\n        model=Claude(id=\"claude-3-7-sonnet-latest\", temperature=0),\n        # Agentic RAG is enabled by default when `knowledge` is provided to the Agent.\n        tools=[\n            SQLTools(\n                db_url=db_url,\n                # run_sql_query=False,\n                schema=\"ai\",\n                tables=tables,\n            ),\n            ReasoningTools(add_instructions=True),\n            get_date_time,\n        ],\n        session_id=session_id,\n        user_id=user_id,\n        monitoring=True,\n        session_state={\"sources\": [], \"user_id\": user_id},\n        add_state_in_messages=True,\n        show_tool_calls=True,\n        markdown=True,\n        storage=storage,\n        memory=memory,\n        enable_agentic_memory=True,\n        read_chat_history=True,\n        add_history_to_messages=True,\n        instructions=[get_sql_prompt(\"\")],\n    )\n```\n\n### Expected Behavior\n\npipe results team member to team member as string\n\n### Actual Behavior\n\nerror as shown above\n\n### Screenshots or Logs (if applicable)\n\n<img width=\"608\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/908c904c-9faa-4c0a-a468-83be724718d1\" />\n\n### Environment\n\n```markdown\nAgno version 1.4.4\nPython 3.12\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "ravishrawal",
      "author_type": "User",
      "created_at": "2025-05-12T15:43:16Z",
      "updated_at": "2025-05-20T15:30:01Z",
      "closed_at": "2025-05-13T15:00:23Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3170/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3170",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3170",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:33.426337",
      "comments": [
        {
          "author": "isikepalaku",
          "body": "Have you try update to 1.4.6?",
          "created_at": "2025-05-12T19:41:23Z"
        },
        {
          "author": "ravishrawal",
          "body": "> Have you try update to 1.4.6?\n\nHey @isikepalaku yes, tried upgrading agno to 1.4.6. Also tried upgrading Claude to latest. All to no avail",
          "created_at": "2025-05-13T06:47:37Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@ravishrawal This is known, we are fixing in the coming release (which is a about an hour away)",
          "created_at": "2025-05-13T13:24:55Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Released with [1.5.0](https://github.com/agno-agi/agno/releases/tag/v1.5.0)!",
          "created_at": "2025-05-13T15:00:23Z"
        },
        {
          "author": "ravishrawal",
          "body": "@dirkbrnd was this error fixed? It is still erring for me:\n\n<img width=\"859\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/63b082ed-03b8-453d-9e0e-a6f2acca0374\" />\n\nSeems to be a known Claude issue: https://github.com/anthropics/claude-code/issues/473\n\nIf I switch to OpenAIChat this er",
          "created_at": "2025-05-14T10:49:02Z"
        }
      ]
    },
    {
      "issue_number": 2336,
      "title": "[Bug] Tools: Stream=True causing each tool to be ran twice in same call causing duplicate tool id.",
      "body": "# Description\nBriefly describe the issue you’re experiencing or the bug you’ve found.\nFor tool calls specifically, the agent appears to be yielding the same tool call multiple times in the response stream.\n\n## Steps to Reproduce\nList the steps needed to encounter this bug or issue.\n\nUsing basic example of tool usage. Tried multiple tools and even python as functions example and still running into duplicate calls. \n\n## Expected Behavior\nWhat did you expect to happen?\n\nBased on the query, use the correct tool and respond with the answer.\n\n## Actual Behavior\nWhat actually happened instead?\n\nCalls the tool twice causing duplicate ids error. \n\n## Screenshots or Logs (if applicable)\nBedrockException -  \n         {\"message\":\"The toolUse blocks at messages.2.content contain duplicate Ids: tooluse_}\n\n<img width=\"908\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/ce8fd70b-3d2f-4c38-909c-ea83d61a232d\" />\n",
      "state": "closed",
      "author": "Ichigo3766",
      "author_type": "User",
      "created_at": "2025-03-09T06:15:20Z",
      "updated_at": "2025-05-20T14:18:15Z",
      "closed_at": "2025-03-26T17:39:55Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2336/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2336",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2336",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:38.638747",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "@Ichigo3766 Would you mind sharing the agent configuration you used that caused this? This could be due to the model itself.",
          "created_at": "2025-03-14T10:24:38Z"
        },
        {
          "author": "Ichigo3766",
          "body": "@dirkbrnd I am using Claude sonnet 3.5. Works just fine with everything else.",
          "created_at": "2025-03-14T21:59:58Z"
        },
        {
          "author": "ysolanky",
          "body": "Hello @Ichigo3766 ! Using parallel tool calls with Claude, I have not been able to replicate this issue. Please reopen if you are still facing it. \n\n![Image](https://github.com/user-attachments/assets/e4beb211-0ac5-4fc9-8b6d-ba9b9be9e14e)",
          "created_at": "2025-03-26T17:39:55Z"
        },
        {
          "author": "armanckeser",
          "body": "```python\nAgnoAgent(\n    name=\"agno\",\n    model=OpenAILike(\n        id=\"anthropic-claude-v3.7-sonnet\",\n        api_key=getenv(\"LITELLM_API_KEY\"),\n        base_url=getenv(\"LITELLM_API_BASE\"),\n    ),\n    system_message=lambda agent: self.system_prompt,\n    tools=self.tools,\n    telemetry=False,\n    de",
          "created_at": "2025-05-12T14:25:52Z"
        },
        {
          "author": "ysolanky",
          "body": "Hi @armanckeser ! Looks like Claude does not follow the OpenAI spec for function calling using LiteLLM endpoint. \n\nCan you please try using the LiteLLM Model class directly or the Claude class?\n\n```python\nagent = Agent(\n    model=LiteLLM(\n        id=\"gpt-4o\",\n    ),\n    markdown=True,\n    tools=[YFi",
          "created_at": "2025-05-20T14:18:14Z"
        }
      ]
    },
    {
      "issue_number": 3236,
      "title": "[Feature Request] enable_agentic_knowledge_filters on Team",
      "body": "### Problem Description\n\nThe enable_agentic_knowledge_filters seems to be available only for the Agent class\n\n### Proposed Solution\n\nMake enable_agentic_knowledge_filters available for the Team class as well\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [x] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "onesecurity-app",
      "author_type": "User",
      "created_at": "2025-05-19T04:16:38Z",
      "updated_at": "2025-05-20T12:37:08Z",
      "closed_at": "2025-05-20T12:37:07Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3236/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3236",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3236",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:38.825442",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-181/feature-request-enable-agentic-knowledge-filters-on-team\">SUPPORT-181 [Feature Request] enable_agentic_knowledge_filters on Team</a></p>",
          "created_at": "2025-05-19T04:16:40Z"
        },
        {
          "author": "kausmeows",
          "body": "Hey @onesecurity-app i already have a PR out for this, should be merged and released soon!\n\nHere- https://github.com/agno-agi/agno/pull/3181",
          "created_at": "2025-05-19T06:30:22Z"
        },
        {
          "author": "kausmeows",
          "body": "The PR is merged and will be released soon. Closing this!",
          "created_at": "2025-05-20T12:37:07Z"
        }
      ]
    },
    {
      "issue_number": 3255,
      "title": "[Feature Request] Add cohere v4 native multimodal capabilities",
      "body": "### Problem Description\n\n.\n\n### Proposed Solution\n\n.\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "mishramonalisha76",
      "author_type": "User",
      "created_at": "2025-05-20T12:12:44Z",
      "updated_at": "2025-05-20T12:15:49Z",
      "closed_at": "2025-05-20T12:15:49Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3255/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3255",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3255",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:39.050133",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-235/feature-request-add-cohere-v4-native-multimodal-capabilities\">SUPPORT-235 [Feature Request] Add cohere v4 native multimodal capabilities</a></p>",
          "created_at": "2025-05-20T12:12:47Z"
        }
      ]
    },
    {
      "issue_number": 3238,
      "title": "[Bug] Tool call instead creates markdown output and stops responding",
      "body": "### Description\n\nI have assigned several tools, but when the toolcall executes it instead streams the following:\n\n\n---\nLet's analyze the performance of TSLA and AAPL between 2025-02-17 and 2025-02-22.\n\n```plaintext\nPerformanceTool.compare(\n    tickers=[\"TSLA\", \"AAPL\"],\n    start_date=\"2025-02-17\",\n    end_date=\"2025-02-22\"\n)\n```\n---\n\ninstead of actually calling the tool!\n\nRunning the tool by itself works (ignore the fact that the tool returns nonsense markdown).\n\n<img width=\"938\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/a721dc08-9505-480f-8549-0a38bf36f7dc\" />\n\n\n### Steps to Reproduce\n\nGo to https://colab.research.google.com/drive/1GkcDJIOcvGXKEb5xe5rwpBzKPU0Xoa-g?usp=sharing\n\nAdd your OpenAI api key. \n\nRun all cells.\n\n### Agent Configuration (if applicable)\n\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom typing import List\nfrom agno.agent import Agent\nfrom agno.models.openai import OpenAIChat\n\n# ─── validate your table ───────────────────────────────────────────\nassert {\"stockname\", \"timestamp\", \"open\", \"high\", \"low\", \"close\"}.issubset(tbl.columns)\nTICKERS = set(tbl[\"stockname\"].unique())\n\n# ─── TOOL DEFINITIONS WITH FULL TYPE HINTS ─────────────────────────\n\nclass CandlestickTool:\n    name: str = \"CandlestickTool\"\n    description: str = \"Generate an OHLC candlestick chart for a ticker over [start,end].\"\n\n    def run(self, ticker: str, start: str, end: str) -> str:\n        df = tbl[\n            (tbl.stockname == ticker) &\n            (tbl.timestamp.between(start, end))\n        ].sort_values(\"timestamp\")\n        if df.empty:\n            return f\"No data for {ticker} between {start} and {end}.\"\n\n        df2 = df.set_index(\"timestamp\")[[\"open\", \"high\", \"low\", \"close\"]]\n        df2.index = pd.DatetimeIndex(df2.index)\n\n        path: str = f\"candlestick_{ticker}.png\"\n        try:\n            import mplfinance as mpf\n            mpf.plot(df2, type=\"candle\", style=\"charles\", volume=False, savefig=path)\n        except ImportError:\n            fig, ax = plt.subplots(figsize=(6, 4))\n            ax.plot(df2.index, df2[\"close\"], marker=\"o\")\n            ax.set_title(f\"{ticker} Close Price\")\n            ax.set_xlabel(\"Time\")\n            ax.set_ylabel(\"Close\")\n            fig.tight_layout()\n            fig.savefig(path)\n            plt.close(fig)\n\n        return f\"![{ticker} Candlestick]({path})\"\n\n\nclass BollingerBandsTool:\n    name: str = \"BollingerBandsTool\"\n    description: str = \"Plot Bollinger Bands (20-day MA ±2σ) for a ticker over [start,end].\"\n\n    def run(self, ticker: str, start: str, end: str) -> str:\n        df = tbl[\n            (tbl.stockname == ticker) &\n            (tbl.timestamp.between(start, end))\n        ].sort_values(\"timestamp\")\n        if df.empty:\n            return f\"No data for {ticker} between {start} and {end}.\"\n\n        df[\"ma20\"] = df[\"close\"].rolling(20, min_periods=1).mean()\n        df[\"std20\"] = df[\"close\"].rolling(20, min_periods=1).std()\n        df[\"upper\"] = df[\"ma20\"] + 2 * df[\"std20\"]\n        df[\"lower\"] = df[\"ma20\"] - 2 * df[\"std20\"]\n\n        path: str = f\"bollinger_{ticker}.png\"\n        fig, ax = plt.subplots(figsize=(10, 5))\n        ax.plot(df.timestamp, df.close, label=\"Close\")\n        ax.plot(df.timestamp, df.ma20, label=\"MA20\")\n        ax.plot(df.timestamp, df.upper, \"--\", label=\"Upper Band\")\n        ax.plot(df.timestamp, df.lower, \"--\", label=\"Lower Band\")\n        ax.fill_between(df.timestamp, df.lower, df.upper, alpha=0.2)\n\n        fig.autofmt_xdate(rotation=45, ha=\"right\")\n        ax.set_title(f\"{ticker} Bollinger Bands\")\n        ax.set_xlabel(\"Time\")\n        ax.set_ylabel(\"Price\")\n        ax.legend(loc=\"best\")\n        fig.tight_layout()\n        fig.savefig(path)\n        plt.close(fig)\n\n        return f\"![{ticker} Bollinger]({path})\"\n\n\nclass VolatilityTool:\n    name: str = \"VolatilityTool\"\n    description: str = \"Compute annualized volatility of a ticker’s log-returns over [start,end].\"\n\n    def run(self, ticker: str, start: str, end: str) -> str:\n        df = tbl[\n            (tbl.stockname == ticker) &\n            (tbl.timestamp.between(start, end))\n        ].sort_values(\"timestamp\")\n        if len(df) < 2:\n            return f\"Not enough data for {ticker} between {start} and {end}.\"\n\n        prices: np.ndarray = df[\"close\"].to_numpy()\n        rets: np.ndarray = np.diff(np.log(prices))\n        vol: float = np.std(rets) * np.sqrt(252) * 100\n\n        return (\n            f\"{ticker} annualized volatility from {start} to {end} \"\n            f\"is {vol:.2f}%.\"\n        )\n\n\nclass PerformanceTool:\n    name: str = \"PerformanceTool\"\n    description: str = \"Normalize price (start=100) for multiple tickers over [start,end].\"\n\n    def run(self, tickers: List[str], start: str, end: str) -> str:\n        df = tbl[\n            tbl.stockname.isin(tickers) &\n            tbl.timestamp.between(start, end)\n        ]\n        if df.empty:\n            return f\"No data for {', '.join(tickers)} between {start} and {end}.\"\n\n        price_df = (\n            df\n            .pivot_table(\n                index=\"timestamp\",\n                columns=\"stockname\",\n                values=\"close\",\n                aggfunc=\"last\"\n            )\n            .sort_index()\n            .ffill().bfill()\n        )\n        normed = price_df.div(price_df.iloc[0]).mul(100)\n\n        path: str = \"performance.png\"\n        fig, ax = plt.subplots(figsize=(10, 5))\n        for t in tickers:\n            ax.plot(normed.index, normed[t], label=t)\n\n        fig.autofmt_xdate(rotation=45, ha=\"right\")\n        ax.set_title(f\"Performance {start} → {end}\")\n        ax.set_xlabel(\"Time\")\n        ax.set_ylabel(\"Indexed Price (Start = 100)\")\n        ax.legend(loc=\"best\")\n        fig.tight_layout()\n        fig.savefig(path)\n        plt.close(fig)\n\n        return f\"![Performance]({path})\"\n\n\nclass CorrelationTool:\n    name: str = \"CorrelationTool\"\n    description: str = \"Compute & plot daily-return correlation for ≥2 tickers over [start,end].\"\n\n    def run(self, tickers: List[str], start: str, end: str) -> str:\n        df = tbl[\n            tbl.stockname.isin(tickers) &\n            tbl.timestamp.between(start, end)\n        ]\n        if df.empty:\n            return f\"No data for {', '.join(tickers)} between {start} and {end}.\"\n\n        pivot = (\n            df\n            .pivot_table(\n                index=\"timestamp\",\n                columns=\"stockname\",\n                values=\"close\",\n                aggfunc=\"last\"\n            )\n            .sort_index()\n            .ffill().bfill()\n        )\n        rets = pivot.pct_change().dropna()\n        corr = rets.corr()\n\n        # if exactly two tickers, return numeric correlation\n        if corr.shape[0] == 2:\n            a, b = corr.columns\n            return f\"Correlation {a}↔{b} = {corr.loc[a, b]:.2f}\"\n\n        path: str = \"corr_heatmap.png\"\n        fig, ax = plt.subplots(figsize=(8, 6))\n        cax = ax.imshow(corr, vmin=-1, vmax=1, cmap=\"coolwarm\")\n        fig.colorbar(cax, label=\"Correlation\")\n        ax.set_xticks(range(len(corr))); ax.set_xticklabels(corr.columns, rotation=45, ha=\"right\")\n        ax.set_yticks(range(len(corr))); ax.set_yticklabels(corr.columns)\n        ax.set_title(\"Correlation Heatmap\")\n        fig.tight_layout()\n        fig.savefig(path)\n        plt.close(fig)\n\n        return f\"![Corr]({path})\"\n\n\nclass ReturnHistogramTool:\n    name: str = \"ReturnHistogramTool\"\n    description: str = \"Plot histogram of daily returns for a ticker over [start,end].\"\n\n    def run(self, ticker: str, start: str, end: str, bins: int = 40) -> str:\n        df = tbl[\n            (tbl.stockname == ticker) &\n            (tbl.timestamp.between(start, end))\n        ].sort_values(\"timestamp\")\n        if len(df) < 2:\n            return f\"Not enough data for {ticker} between {start} and {end}.\"\n\n        rets = df[\"close\"].pct_change().dropna()\n\n        path: str = f\"returns_{ticker}.png\"\n        fig, ax = plt.subplots(figsize=(6, 4))\n        ax.hist(rets, bins=bins)\n        ax.set_title(f\"{ticker} Returns ({start} → {end})\")\n        ax.set_xlabel(\"Percent Change\")\n        fig.tight_layout()\n        fig.savefig(path)\n        plt.close(fig)\n\n        return f\"![Returns]({path})\"\n\n\n# ─── AGENT SETUP ───────────────────────────────────────────────────\n\nagent: Agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    description=(\n        \"A stock‐analysis assistant. Always call the right tool \"\n        \"with explicit ticker(s), start, end dates (YYYY-MM-DD).\"\n    ),\n    tools=[\n        CandlestickTool(),\n        BollingerBandsTool(),\n        VolatilityTool(),\n        PerformanceTool(),\n        CorrelationTool(),\n        ReturnHistogramTool(),\n    ],\n    instructions=[\n        \"You are a finance agent. Your job is to answer financial questions using data.\",\n        \"Your data range is 2024-12-14 00:00:00 through 2025-02-22 00:59:59.\"\n    ],\n    show_tool_calls=True,\n    markdown=True,\n)\n\n# Usage example (set your API key in env beforehand):\nresp = agent.run(\"Compare TSLA and AAPL between 2025-02-17 and 2025-02-22. Use PerformanceTool!\")\nprint(resp.content)\n\n### Expected Behavior\n\nI'd expect the toolcall to be done, and the agent to see that there is gibberish markdown returned.\n\n### Actual Behavior\n\nTool call is not executed and execution stops\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nColab, Current Agno version (i believe) Version: 1.5.1\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "mrmps",
      "author_type": "User",
      "created_at": "2025-05-19T09:15:07Z",
      "updated_at": "2025-05-19T11:33:55Z",
      "closed_at": "2025-05-19T11:33:18Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3238/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3238",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3238",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:39.249137",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-205/bug-tool-call-instead-creates-markdown-output-and-stops-responding\">SUPPORT-205 [Bug] Tool call instead creates markdown output and stops responding</a></p>",
          "created_at": "2025-05-19T09:15:10Z"
        },
        {
          "author": "mrmps",
          "body": "Resolved! Related issue is not!",
          "created_at": "2025-05-19T11:33:54Z"
        }
      ]
    },
    {
      "issue_number": 2844,
      "title": "[Bug] Issues with Counting and Processing in the DocumentChunking Class",
      "body": "version: agno-1.3.1\n\nQuestion 1：\n\nFile: agno/document/chunking/document.py\n\nLine 20:\n` \n       paragraphs = self.clean_text(document.content).split(\"\\n\\n\")\n`\n\nImplementation of clean_text function：\nFile: agno/document/chunking/strategy.py ,line 19、21:\n```\n        cleaned_text = re.sub(r\"\\n+\", \"\\n\", text)\n        # Replace multiple spaces with a single space\n        cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text)\n```\n\nThere is a logical issue here: the function first replaces multiple newlines (\\n+) with a single newline (\\n), but immediately after that, it replaces all whitespace characters (including \\n) with a single space. As a result, all newlines are eliminated, which makes the later .split(\"\\n\\n\") ineffective. This will likely affect how the document is chunked, as the paragraph boundaries can no longer be detected properly.\n\n\nQuestion 2：\n\nFile: agno/document/chunking/document.py\n\nIn the same class, the chunk_number variable does not increment automatically during the chunking process. This can cause issues such as duplicate or missing chunk IDs when saving to the database, since the id field relies on chunk_number to differentiate chunks.",
      "state": "open",
      "author": "XuDL",
      "author_type": "User",
      "created_at": "2025-04-16T02:38:30Z",
      "updated_at": "2025-05-19T00:36:28Z",
      "closed_at": null,
      "labels": [
        "question",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2844/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2844",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2844",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:39.447990",
      "comments": [
        {
          "author": "XuDL",
          "body": "If a feature allowing custom delimiters for chunk splitting could be provided, that would be fantastic.",
          "created_at": "2025-04-16T02:44:51Z"
        },
        {
          "author": "Mustafa-Esoofally",
          "body": "Hey @XuDL Thanks for detailed analysis. We need to look into deeper and add more chunking strategies. Working with the team on this!\n\nWill get back with updates",
          "created_at": "2025-04-18T17:11:29Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-05-19T00:36:27Z"
        }
      ]
    },
    {
      "issue_number": 2791,
      "title": "[Bug] When MCP omits type from input schema (e.g., because it accepts all objects), Agno incorrectly fills type with blank string which is invalid JSON schema",
      "body": "# Description\nAgno was generating invalid JSON schema when I added a custom MCP that was known to work with Claude Desktop:\n\n```\nError code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error',\n         'message': 'tools.0.custom.input_schema: JSON schema is invalid. It must match JSON Schema draft 2020-12     \n         (https://json-schema.org/draft/2020-12). Learn more about tool use at                                        \n         https://docs.anthropic.com/en/docs/tool-use.'}} \n```\n\nIt turns out this is because Agno incorrectly postprocesses input schema. See below.\n\n## Steps to Reproduce\n\nWhen an argument to a tool is annotated with 'object' type signature, the official Python MCP SDK generates this schema, with the 'type' argument omitted.\n\n```\nobj:\n{\ntitle:\n\"Obj\"\n}\n```\n\nFor example, this MCP can trigger this situation:\n\n```\nfrom mcp.server.fastmcp import FastMCP\nfrom typing import Dict, Any\n\n# Create an MCP server\nmcp = FastMCP(\"Object Arguments Demo\")\n\n\n@mcp.tool()\ndef print_object(obj1: str, obj: object) -> str:\n    \"\"\"\n    Takes an object as an argument and prints its structure.\n    The object can be any JSON-serializable dictionary.\n\n    Args:\n        obj: A dictionary/object to print\n\n    Returns:\n        A string representation of the object\n    \"\"\"\n    # Convert the object to a formatted string\n    return f\"Received object: {obj}\"\n\n\nif __name__ == \"__main__\":\n    mcp.run()\n```\n\nWhen you integrate this agent with Agno, Agno then creates this schema:\n\n```\n'obj': {'description': '', 'type': ''}\n```\n\nwhich can be observed by inspecting the \"Request options: \" debug log.\n\n```\n    from agno.debug import enable_debug_mode\n    enable_debug_mode()\n    import logging\n    logging.basicConfig(level=logging.DEBUG)\n    logging.getLogger(\"httpx\").setLevel(logging.DEBUG)  # For HTTP logging\n    logging.getLogger(\"anthropic\").setLevel(logging.DEBUG)\n```\n\nThis schema is then rejected by Anthropic's API.\n\n## Agent Configuration (if applicable)\nUse the tutorial agent config + the MCP above.\n\n## Expected Behavior\nIt works\n\n## Actual Behavior\n```\nError code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error',\n         'message': 'tools.0.custom.input_schema: JSON schema is invalid. It must match JSON Schema draft 2020-12     \n         (https://json-schema.org/draft/2020-12). Learn more about tool use at                                        \n         https://docs.anthropic.com/en/docs/tool-use.'}} \n```\n\n## Screenshots or Logs (if applicable)\n\nI minimized the repro from this following real world log:\n\n```\nINFO:     Started server process [8698]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://localhost:7777 (Press CTRL+C to quit)\nINFO:     ::1:65185 - \"OPTIONS /v1/playground/status HTTP/1.1\" 200 OK\nINFO:     ::1:65185 - \"GET /v1/playground/status HTTP/1.1\" 200 OK\nINFO:     ::1:65185 - \"OPTIONS /v1/playground/agents HTTP/1.1\" 200 OK\nINFO:     ::1:65185 - \"GET /v1/playground/agents HTTP/1.1\" 200 OK\nINFO:     ::1:65188 - \"OPTIONS /v1/playground/agents/f8cd8eec-63b7-49bd-8821-ab7b3f451d28/runs HTTP/1.1\" 200 OK\nDEBUG AgentRunRequest: Which tools do you have access to?  ezyang_134b f8cd8eec-63b7-49bd-8821-ab7b3f451d28           \nDEBUG Creating new session                                                                                            \nINFO:     ::1:65188 - \"POST /v1/playground/agents/f8cd8eec-63b7-49bd-8821-ab7b3f451d28/runs HTTP/1.1\" 200 OK\n[04/12/25 22:16:18] DEBUG    Request options: {'method': 'post', 'url': '/v1/messages', 'headers': _base_client.py:474\n                             {'X-Stainless-Stream-Helper': 'messages'}, 'files': None,                                \n                             'json_data': {'max_tokens': 4096, 'messages': [{'role': 'user',                          \n                             'content': [{'type': 'text', 'text': 'Which tools do you have access                     \n                             to?'}]}], 'model': 'claude-3-7-sonnet-20250219', 'system':                               \n                             '<instructions>\\ninit codemcp                                                            \n                             /Users/ezyang/Dev/refined-claude\\n</instructions>\\n\\n<additional_info                    \n                             rmation>\\n- Use markdown to format your                                                  \n                             answers.\\n</additional_information>\\n\\nDo not reflect on the quality                     \n                             of the returned search results in your response', 'tools': [{'name':                     \n                             'codemcp', 'description': 'If and only if the user explicitly asks                       \n                             you to initialize codemcp with\\n    path, you should invoke this                         \n                             tool.  This will return instructions which you should\\n                                  \n                             IMMEDIATELY follow before continuing, in particular, it will explain                     \n                             other ways\\n    you can invoke this tool.\\n\\n    If the user                             \n                             indicates they want to \"amend\" or \"continue working\" on a PR,\\n                          \n                             you should set reuse_head_chat_id=True to continue using the same                        \n                             chat ID.\\n\\n    In each subsequent request NOT including the initial                     \n                             request to initialize\\n    codemcp, you must call the UserPrompt tool                    \n                             with the user\\'s verbatim\\n    request text.\\n\\n    Arguments:\\n                         \n                             subtool: The subtool to run (InitProject, ...)\\n      path: The path                     \n                             to the file or directory to operate on\\n      user_prompt: The                           \n                             user\\'s original prompt verbatim, starting AFTER instructions to                         \n                             initialize codemcp (e.g., you should exclude \"Initialize codemcp for                     \n                             PATH\")\\n      subject_line: A short subject line in Git conventional                     \n                             commit format (for InitProject)\\n      reuse_head_chat_id: If True,                      \n                             reuse the chat ID from the HEAD commit instead of generating a new                       \n                             one (for InitProject)\\n      ... (there are other arguments which                        \n                             will be documented when you InitProject)\\n    ', 'input_schema':                         \n                             {'type': 'object', 'properties': {'subtool': {'description': '',                         \n                             'type': 'string'}, 'path': {'description': '', 'anyOf': [{'type':                        \n                             'string'}, {'type': 'null'}]}, 'content': {'description': '', 'type':                    \n                             ''}, 'old_string': {'description': '', 'anyOf': [{'type': 'string'},                     \n                             {'type': 'null'}]}, 'new_string': {'description': '', 'anyOf':                           \n                             [{'type': 'string'}, {'type': 'null'}]}, 'offset': {'description':                       \n                             '', 'anyOf': [{'type': 'integer'}, {'type': 'null'}]}, 'limit':                          \n                             {'description': '', 'anyOf': [{'type': 'integer'}, {'type':                              \n                             'null'}]}, 'description': {'description': '', 'anyOf': [{'type':                         \n                             'string'}, {'type': 'null'}]}, 'pattern': {'description': '',                            \n                             'anyOf': [{'type': 'string'}, {'type': 'null'}]}, 'include':                             \n                             {'description': '', 'anyOf': [{'type': 'string'}, {'type': 'null'}]},                    \n                             'command': {'description': '', 'anyOf': [{'type': 'string'}, {'type':                    \n                             'null'}]}, 'arguments': {'description': '', 'anyOf': [{'type':                           \n                             'string'}, {'type': 'null'}]}, 'old_str': {'description': '',                            \n                             'anyOf': [{'type': 'string'}, {'type': 'null'}]}, 'new_str':                             \n                             {'description': '', 'anyOf': [{'type': 'string'}, {'type': 'null'}]},                    \n                             'chat_id': {'description': '', 'anyOf': [{'type': 'string'}, {'type':                    \n                             'null'}]}, 'user_prompt': {'description': '', 'anyOf': [{'type':                         \n                             'string'}, {'type': 'null'}]}, 'subject_line': {'description': '',                       \n                             'anyOf': [{'type': 'string'}, {'type': 'null'}]},                                        \n                             'reuse_head_chat_id': {'description': '', 'anyOf': [{'type':                             \n                             'boolean'}, {'type': 'null'}]}, 'thought': {'description': '',                           \n                             'anyOf': [{'type': 'string'}, {'type': 'null'}]}, 'mode':                                \n                             {'description': '', 'anyOf': [{'type': 'string'}, {'type':                               \n                             'null'}]}}, 'required': ['subtool', 'path', 'content', 'old_string',                     \n                             'new_string', 'offset', 'limit', 'description', 'pattern', 'include',                    \n                             'command', 'arguments', 'old_str', 'new_str', 'chat_id',                                 \n                             'user_prompt', 'subject_line', 'reuse_head_chat_id', 'thought',                          \n                             'mode']}}], 'stream': True}}                                                             \n                    INFO     HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 400    _client.py:1740\n                             Bad Request\"                                                                             \n                    DEBUG    HTTP Request: POST https://api.anthropic.com/v1/messages \"400 Bad    _base_client.py:1689\n                             Request\"                                                                                 \n                    DEBUG    Encountered httpx.HTTPStatusError                                    _base_client.py:1696\n                             ╭─────────────── Traceback (most recent call last) ────────────────╮                     \n                             │ /Users/ezyang/Dev/codemcp/.venv/lib/python3.12/site-packages/ant │                     \n                             │ hropic/_base_client.py:1694 in _request                          │                     \n                             │                                                                  │                     \n                             │   1691 │   │   )                                                 │                     \n                             │   1692 │   │                                                     │                     \n                             │   1693 │   │   try:                                              │                     \n                             │ ❱ 1694 │   │   │   response.raise_for_status()                   │                     \n                             │   1695 │   │   except httpx.HTTPStatusError as err:  # thrown on │                     \n                             │   1696 │   │   │   log.debug(\"Encountered httpx.HTTPStatusError\" │                     \n                             │   1697                                                           │                     \n                             │                                                                  │                     \n                             │ /Users/ezyang/Dev/codemcp/.venv/lib/python3.12/site-packages/htt │                     \n                             │ px/_models.py:829 in raise_for_status                            │                     \n                             │                                                                  │                     \n                             │    826 │   │   }                                                 │                     \n                             │    827 │   │   error_type = error_types.get(status_class, \"Inval │                     \n                             │    828 │   │   message = message.format(self, error_type=error_t │                     \n                             │ ❱  829 │   │   raise HTTPStatusError(message, request=request, r │                     \n                             │    830 │                                                         │                     \n                             │    831 │   def json(self, **kwargs: typing.Any) -> typing.Any:   │                     \n                             │    832 │   │   return jsonlib.loads(self.content, **kwargs)      │                     \n                             ╰──────────────────────────────────────────────────────────────────╯                     \n                             HTTPStatusError: Client error '400 Bad Request' for url                                  \n                             'https://api.anthropic.com/v1/messages'                                                  \n                             For more information check:                                                              \n                             https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400                             \n                    DEBUG    Not retrying as header `x-should-retry` is set to `false`             _base_client.py:756\n                    DEBUG    Re-raising status error                                              _base_client.py:1714\nERROR    Claude API error (status 400): Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error',\n         'message': 'tools.0.custom.input_schema: JSON schema is invalid. It must match JSON Schema draft 2020-12     \n         (https://json-schema.org/draft/2020-12). Learn more about tool use at                                        \n         https://docs.anthropic.com/en/docs/tool-use.'}}                                                              \n^CINFO:     Shutting down\nINFO:     Waiting for application shutdown.\nINFO:     Application shutdown complete.\nINFO:     Finished server process [8698]\nTraceback (most recent call last):\n```\n\n\n## Environment\n- OS: macOS\n- Agno Version: I tested against 1f456b1d7fe5b8554a994b29164d539b7b172d55\n- Additional Environment Details: Python 3.12\n\n## Possible Solutions (optional)\nA workaround was to replace the 'object' signature with an expanded signature that enumerated all valid JSON types.",
      "state": "closed",
      "author": "ezyang",
      "author_type": "User",
      "created_at": "2025-04-12T13:59:30Z",
      "updated_at": "2025-05-18T19:59:09Z",
      "closed_at": "2025-05-13T15:13:33Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2791/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2791",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2791",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:39.666780",
      "comments": [
        {
          "author": "Ayush0054",
          "body": "Hey @ezyang,\nReally sorry for the late reply! Could you please test this again on the latest version of Agno? We’ve released several fixes for MCP and added SSE support as well.\n\nPlease let us know if you still encounter the issue.\nThanks! 🙌",
          "created_at": "2025-04-28T21:24:53Z"
        },
        {
          "author": "Hendler",
          "body": "see https://github.com/orgs/modelcontextprotocol/discussions/366",
          "created_at": "2025-05-17T15:40:18Z"
        }
      ]
    },
    {
      "issue_number": 3179,
      "title": "[Bug] Filters in chroma db are not being passed query",
      "body": "### Description\n\nin chroma db filters are not being passed https://github.com/agno-agi/agno/blob/2feb8d551f99f915d5a778ce2aa91d34b2e409ce/libs/agno/agno/vectordb/chroma/chromadb.py#L236\n\nam i reading this correct ? \n\n### Steps to Reproduce\n\nfilters being asked to pass in chroma db based knowledge base have no impact \n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nfilters being applied first and then closest matching happening to it\n\n### Actual Behavior\n\nfilters being applied or passed have no effect on search\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n- OS: [mac, ubuntu docker]\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "navdeep710",
      "author_type": "User",
      "created_at": "2025-05-13T15:35:46Z",
      "updated_at": "2025-05-16T12:39:15Z",
      "closed_at": "2025-05-16T12:39:15Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3179/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3179",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3179",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:39.897653",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-140/bug-filters-in-chroma-db-are-not-being-passed-query\">SUPPORT-140 [Bug] Filters in chroma db are not being passed query</a></p>",
          "created_at": "2025-05-13T15:35:49Z"
        },
        {
          "author": "kausmeows",
          "body": "Hi @navdeep710 filters are currently only supported in Qdrant, LanceDB and MongoDB. I have a PR out which adds filtering support to a bunch of other vector dbs including Chroma, see here- https://github.com/agno-agi/agno/pull/3199\n\nThis should be released in the next version.",
          "created_at": "2025-05-14T22:27:02Z"
        },
        {
          "author": "kausmeows",
          "body": "You can see other examples here- https://github.com/agno-agi/agno/tree/main/cookbook/agent_concepts/knowledge/filters",
          "created_at": "2025-05-14T22:29:12Z"
        }
      ]
    },
    {
      "issue_number": 3206,
      "title": "[Feature Request]  In case if Pre/Post hooks are deprecated is there any alternative?",
      "body": "### Problem Description\n\nI have a requirement that i want the direct response from the tool without any refinement from llm , till now i was using post hook for that but , now on the official site of agno , in documentation they have written Pre and Post Hooks (Deprecated). \nIf it is deprecated is there any other feature to implement same?\n\n### Proposed Solution\n\n.\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "cmdjaylohar",
      "author_type": "User",
      "created_at": "2025-05-15T08:17:56Z",
      "updated_at": "2025-05-16T09:28:41Z",
      "closed_at": "2025-05-16T09:28:40Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3206/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3206",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3206",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:40.144238",
      "comments": [
        {
          "author": "cmdjaylohar",
          "body": "sorry it was my mistake is already now defined in \n@tool(show_result=True, stop_after_tool_call=True)",
          "created_at": "2025-05-16T09:28:40Z"
        }
      ]
    },
    {
      "issue_number": 2329,
      "title": "[Bug] Agent Memory managing in Agent Teams.",
      "body": "# Description\n\nHello, I'm working on a team of agents.\n\nHowever, after several attempts, I found that the Agent would not run the tool even though it was a new session. I tried to create a new session, and for the same input, the output was different.\n\nThe system configuration consists of three agents: the first is a `main agent` that talks to the user, and the other two are agents for subtasks.\n\nWhen we checked each agent with storage (this validation may be good or problematic), we found that when the `session_id` of the managing agent changed, the `session_id` of the subtasking agent did not change, and it seemed to be carrying over the previous information.\n\n## Steps to Reproduce\nList the steps needed to encounter this bug or issue.\n\n- Chat to the `main agent`. \n- Then create a new session, and chat again with the `main_agent`.\n- Repeat several times.\n- The output will be different.\n\n## Agent Configuration (if applicable)\nProvide relevant agent configuration.\n\n- For all agetns: temperature = 0.0\n- About `main agent`:\n\n```\nagent = Agent(\n        name=\"...\",\n        agent_id=\"...\",\n        session_id=session_id,\n        user_id=user_id,\n        stream=False,\n        model=get_model(),\n        tools=[TaskExecuteTool(session_id=session_id)],\n        search_knowledge=False,\n        show_tool_calls=True,\n        team=[\n            get_agent1(),\n            get_agent2()\n        ],\n       storage=PostgresAgentStorage(...),\n       add_history_to_messages=True,\n       num_history_responses=4,\n       tool_call_limit=3,\n       debug_mode=True\n```\n\n- About the other 2 agents:\n\n`get_agent1`:\n\n```\ndef get_agent1(\n    session_id: Optional[str] = None,\n    user_id: Optional[str] = None,\n):\n  agent = Agent(\n        name=\"...\",\n        role=\"...\",\n        user_id=user_id,\n        session_id=session_id,\n        model=get_model(),\n        search_knowledge=True,\n        knowledge=...,\n        show_tool_calls=True,\n        tool_call_limit=2,\n   )\n   return agent\n```\n\n`get_agent2`:\n\n```\ndef get_agent2(\n    session_id: Optional[str] = None,\n    user_id: Optional[str] = None,\n):\n  agent = Agent(\n        name=\"...\",\n        role=\"...\",\n        user_id=user_id,\n        session_id=session_id,\n        model=get_model(),\n        structured_outputs=True,\n        storage=PostgresAgentStorage(...)\n        show_tool_calls=True,\n        tool_call_limit=2,\n   )\n   return agent\n```\n\n## Expected Behavior\n\nThe output is similar for all inputs.\n\n## Actual Behavior\n\nOutputs are different for all inputs. When creating a new session, the `session_id` of the `main agent` changes, but the `session_id`s of other Agents do not change.\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- OS: Ubuntu 22\n- Browser (if relevant): Chrome\n- Agno Version: v1.0.1\n- External Dependency Versions: None\n- Additional Environment Details: Python3.10\n\n\n## Possible Solutions (optional)\n\n`session_id` should change when the `main agent` assigns tasks to other Agents.\n\n## Additional Context\n\nI tried changing the following variables, no change. `add_history_to_messages`, `num_history_responses=0`, and `read_chat_history=False` on the sub agents.\n",
      "state": "closed",
      "author": "galaxygliese",
      "author_type": "User",
      "created_at": "2025-03-08T10:45:42Z",
      "updated_at": "2025-05-16T03:41:41Z",
      "closed_at": "2025-04-10T00:32:14Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2329/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2329",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2329",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:40.330840",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-03-23T00:34:24Z"
        },
        {
          "author": "manthanguptaa",
          "body": "Hey @galaxygliese! We have pushed launched a new teams implementation that you might want to check out. Let us know if you still face same issues with it!",
          "created_at": "2025-03-26T06:35:40Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-10T00:32:13Z"
        },
        {
          "author": "e96031413",
          "body": "@manthanguptaa \nThe issue still exists.",
          "created_at": "2025-05-16T03:41:39Z"
        }
      ]
    },
    {
      "issue_number": 3153,
      "title": "[Feature Request] include different tools for different agent with same mcp server session",
      "body": "## Problem Description\nWith  one same MCP session, I want to assign different tools for different  agent member within a team.  How do agno acheive it?\n",
      "state": "closed",
      "author": "huang-sh",
      "author_type": "User",
      "created_at": "2025-05-10T19:34:30Z",
      "updated_at": "2025-05-15T11:27:13Z",
      "closed_at": "2025-05-15T11:27:12Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3153/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3153",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3153",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:40.574148",
      "comments": [
        {
          "author": "manuhortet",
          "body": "Hey @huang-sh. You can't do exactly that right now, but it is a great idea. We could specify which tools to include or exclude when initializing the agent. We will take it into account for coming releases.\n\nIn the meantime, notice you can use `include_tools` and `exclude_tools` when initializing the",
          "created_at": "2025-05-15T07:47:42Z"
        },
        {
          "author": "huang-sh",
          "body": "@manuhortet Thanks for you help.\n\nBecause different tool calls need to perform data calculations on the same object in the MCP server's memory, we need to maintain the MCP session. At the same time, since there are many MCP tools, to reduce  tokens, I want different agents to only use the tools rele",
          "created_at": "2025-05-15T08:41:14Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@huang-sh Ah I see, is this what you are looking for?\n\nhttps://github.com/agno-agi/agno/blob/main/cookbook/tools/mcp/include_exclude_tools.py\nhttps://github.com/agno-agi/agno/blob/main/cookbook/tools/mcp/include_tools.py\n\nWe allow you to specify, for a single MCP server, which tools to include/exclu",
          "created_at": "2025-05-15T11:27:12Z"
        }
      ]
    },
    {
      "issue_number": 3203,
      "title": "[Bug] : MultiMCPTools is not working",
      "body": "### Description\n\nI was trying to use Multiple MCP Tools in my Agent, but it threw the following error:\n\n```ImportError: cannot import name 'MultiMCPTools' from 'agno.tools.mcp'```\n\nI also took a look at this [Example](https://github.com/agno-agi/agno/blob/main/cookbook/tools/mcp/multiple_servers.py). It also has the same implementation\n\n<img width=\"1253\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/998ce573-0382-4276-8ed4-ce1373373711\" />\n\n\n### Steps to Reproduce\n\n1. Go to https://github.com/agno-agi/agno/blob/main/cookbook/tools/mcp/multiple_servers.py\n2. Run this\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nIt should work with multiple Agents\n\n### Actual Behavior\n\nImportError: cannot import name 'MultiMCPTools' from 'agno.tools.mcp'\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\n- OS: MacOS\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "Arindam200",
      "author_type": "User",
      "created_at": "2025-05-15T05:05:10Z",
      "updated_at": "2025-05-15T08:50:41Z",
      "closed_at": "2025-05-15T08:50:40Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3203/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3203",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3203",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:40.804283",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-161/bug-multimcptools-is-not-working\">SUPPORT-161 [Bug] : MultiMCPTools is not working</a></p>",
          "created_at": "2025-05-15T05:05:14Z"
        },
        {
          "author": "manuhortet",
          "body": "Hey @Arindam200! The example you shared seems to be working fine for me, and `MultiMCPTools` is indeed in `agno.tools.mcp`, as you can see here: https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/mcp.py\n\nThis could be a problem with your local Python environment. Make sure agno is insta",
          "created_at": "2025-05-15T08:50:40Z"
        }
      ]
    },
    {
      "issue_number": 2499,
      "title": "[Feature Request] Async workflow run",
      "body": "I don't think workflow currently supports async runs ? Would be helpful to have like an async arun function, like we have for agents.",
      "state": "closed",
      "author": "yathaarthmagi",
      "author_type": "User",
      "created_at": "2025-03-22T19:25:08Z",
      "updated_at": "2025-05-15T05:27:59Z",
      "closed_at": "2025-04-08T00:31:54Z",
      "labels": [
        "enhancement",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2499/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2499",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2499",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:41.036482",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hey @yathaarthmagi,\nThankyou for your suggestion, we have added this to our community wishlist.",
          "created_at": "2025-03-24T04:43:39Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-08T00:31:53Z"
        },
        {
          "author": "Ce1ling",
          "body": "Hi, is there any progress here? Async support is a very important feature.",
          "created_at": "2025-04-10T07:03:20Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @Ce1ling \nvery happy to let you know, that workflow now support async run.\nPlease give it a try and let us know what you think",
          "created_at": "2025-04-10T08:24:14Z"
        },
        {
          "author": "kasem-io",
          "body": "@monali7-d great news! any docs on using async run in workflows?",
          "created_at": "2025-04-10T17:07:23Z"
        }
      ]
    },
    {
      "issue_number": 2627,
      "title": "[Feature Request] Langfuse observivility support",
      "body": "## Problem Description\n\nI like to able to trace the both exact LLM input output with their cose, currently I am using [Langfuse](https://langfuse.com/) which is great. Do we have any plan to support langfuse integration? \n\n## Proposed Solution\n\nSupport tracking Session, token & time consumption via Langfuse.\n\n## Would you like to work on this?\n\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n\n- [ ] Yes, I’d love to work on it!\n- [x] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.\n\nI love to work on this, but might need a little bit of time and guidance from the team.\n",
      "state": "closed",
      "author": "BrikerMan",
      "author_type": "User",
      "created_at": "2025-04-01T01:00:11Z",
      "updated_at": "2025-05-14T18:54:43Z",
      "closed_at": "2025-04-22T11:38:34Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 23,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2627/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kausmeows"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2627",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2627",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:41.336197",
      "comments": []
    },
    {
      "issue_number": 3191,
      "title": "[Feature Request]  Api to track cost monitoring",
      "body": "### Problem Description\n\nProvide APIs that track cost per call, or is this data already included somewhere in the response payload? \n\nI've been looking at the Network tab and noticed the responses include token counts but not the actual monetary values when I was following this tutorial https://docs.agno.com/agent-ui/introduction#a-beautiful-ui-for-your-agents. \n\nI saw that other platforms like Portkey and OpenRouter have specific endpoints for cost data:\nhttps://portkey.ai/docs/api-reference/admin-api/control-plane/analytics/graphs-time-series-data/get-cost-data\nhttps://openrouter.ai/docs/api-reference/overview#querying-cost-and-stats\n\n### Proposed Solution\n\n.\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "mishramonalisha76",
      "author_type": "User",
      "created_at": "2025-05-14T14:05:15Z",
      "updated_at": "2025-05-14T14:05:36Z",
      "closed_at": "2025-05-14T14:05:36Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3191/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3191",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3191",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:41.336211",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-154/feature-request-api-to-track-cost-monitoring\">SUPPORT-154 [Feature Request] Api to track cost monitoring</a></p>",
          "created_at": "2025-05-14T14:05:19Z"
        }
      ]
    },
    {
      "issue_number": 3188,
      "title": "[Feature Request]  option to choose a fallback for tools",
      "body": "### Problem Description\n\nUser should have an option to choose a fallback for tools\n\n### Proposed Solution\n\n-\n\n### Alternatives Considered\n\n_No response_\n\n### Additional Context\n\n_No response_\n\n### Would you like to work on this?\n\n- [ ] Yes, I’d love to work on it!\n- [ ] I’m open to collaborating but need guidance.\n- [ ] No, I’m just sharing the idea.",
      "state": "closed",
      "author": "monali7-d",
      "author_type": "User",
      "created_at": "2025-05-14T09:54:56Z",
      "updated_at": "2025-05-14T09:55:11Z",
      "closed_at": "2025-05-14T09:55:11Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3188/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3188",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3188",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:41.555472",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-153/feature-request-option-to-choose-a-fallback-for-tools\">SUPPORT-153 [Feature Request] option to choose a fallback for tools</a></p>",
          "created_at": "2025-05-14T09:54:59Z"
        }
      ]
    },
    {
      "issue_number": 3006,
      "title": "[Bug] Teams calling non-existent tools",
      "body": "# Description\nI have a  'coordinate' Team set-up with multiple Agents. Sometimes, not always, if i ask more complex questions that require 2-3 steps to solve, where the Team should call an agent, wait for the response and based on the response to call another agent, the Team tries to call non-existent tools.\n\nFrom my experiments I clustered the types of non-existent tools in 3 categories:\n1) The Team called a function that the Agents have, but this should be task of the Agent. I don't think the team should have access to the agent's tools.\n2) Completely made up function (this happened only once though). The team tried to call \"atran_diovricrtnsk\" and \"atran_ennurlddiovatsay\", which seem like a jumbled up version of the atransfer_task_to_memeber\n3) The Team tried to call the agent directly. What I mean by that is that instead of transfering to an agent, it tried to call the agent as a tool, and of course it failed saying that it didn't find it.\n\n## Steps to Reproduce\nI spent like 20 minutes talking to the team and saw these problems.\n\n## Agent Configuration (if applicable)\nThis is the agents' configuration:\n```\nagent = Agent(\n            name=\"Agent\",\n            role=<placeholder>,\n            model=base_model,\n            tools=[mcp_tools,ReasoningTools(add_instructions=True)],\n            storage=pg_storage(\"agent_sessions\"),\n            #enable_user_memories=True,\n            markdown=True,\n            show_tool_calls=True,\n            add_history_to_messages=True,\n            num_history_responses=3,\n            num_history_runs=3,\n            read_chat_history=True,\n            enable_agentic_memory=True\n        )\n```\n\nThis is the Team configuration:\n```\nmcp_team = Team(\n            name=\"MCP Tools Team\",\n            team_id=\"mcp_tools_team\",\n            description=\"Routes questions to the right MCP specialist.\",\n            members=[\n               agent1, agent2\n            ],\n            mode=\"coordinate\",\n            model=base_model,\n            tools=[ReasoningTools(add_instructions=True)],\n            instructions=<placeholder>,\n            storage=pg_storage(\"mcp_team\", mode=\"team\"),\n            enable_user_memories=True,\n            enable_agentic_memory=True,\n            show_members_responses=True,\n            markdown=True,\n            add_datetime_to_instructions=True,\n            show_tool_calls=True,\n            enable_agentic_context=True,\n            enable_team_history=True,\n            num_of_interactions_from_history=3,\n            share_member_interactions=True,  # Share interactions\n            add_member_tools_to_system_message=False\n        )\n```\n\n## Expected Behavior\nI was expecting the team to only call predefined tools like atransfer_task_to_member.\n\n## Actual Behavior\nIn some casese, the Team tries to call non-existent functions.\n\n## Screenshots or Logs (if applicable)\nLogs\n```\nDEBUG Tool Calls:                                                                        \n    - ID: 'call_TDtGEanDx8T301r4E8YcZodA'                                                          \n     Name: 'atransfer_task_to_member'                                                            \n     Arguments: 'member_id: agent1, task_description: Find people that acted in the same movies as Samuel L. Jackson., expected_output: List\n   of people that acted in the same movies as 'Samuel L. Jackson'.'                                             \n    - ID: 'call_4xjv9MvAlmC5Hrrb98PsWqtk'                                                          \n     Name: 'atran_diovricrtnsk'                                                               \n     Arguments: 'member_id: agent2, task_description: Check if any people that acted in the same movies as Samuel L. Jackson are new actors., expected_output: List of new actors that acted in the same movies as 'Samuel L. Jackson'.'                 \n    - ID: 'call_w8TbJCryeAPcJyvMY3GnpBYx'                                                          \n     Name: 'atran_ennurlddiovatsay'                                                             \n     Arguments: 'member_id: agent3, task_description: Determine if any people that acted in the same movies as Samuel L. Jackson are new actors., expected_output:  List of new actors that acted in the same movies as 'Samuel L. Jackson'.'                          \nDEBUG **************************************************************** METRICS *****************************************************************        \nDEBUG * Tokens:           input=2857, output=229, total=3086                                             \nDEBUG * Prompt tokens details:    {'audio_tokens': 0, 'cached_tokens': 0}                                           \nDEBUG * Completion tokens details:  {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}        \nDEBUG * Time:            4.7664s                                                           \nDEBUG * Tokens per second:      48.0450 tokens/s                                                      \nDEBUG * Time to first token:     4.5367s                                                           \nDEBUG **************************************************************** METRICS *****************************************************************        \nDEBUG Getting function atransfer_task_to_member                                                         \nDEBUG Getting function atran_diovricrtnsk                                                            \nERROR   Function atran_diovricrtnsk not found                                                          \nDEBUG Getting function atran_ennurlddiovatsay                                                          \nERROR   Function atran_ennurlddiovatsay not found                                                        \nDEBUG Running: atransfer_task_to_member(member_id=agent1, task_description=..., expected_output=...)\n```\n\n## Environment\n- Agno Version: (e.g. v1.4.2)\n",
      "state": "closed",
      "author": "anionescubd",
      "author_type": "User",
      "created_at": "2025-04-28T15:16:34Z",
      "updated_at": "2025-05-14T09:01:33Z",
      "closed_at": "2025-05-13T14:59:27Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3006/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3006",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3006",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:41.807740",
      "comments": [
        {
          "author": "zizake",
          "body": "I encountered similar issue. Adding the 'add_member_tools_to_system_message=False' helped but sometimes there are cases where the coordinator tries to call a function or tool id that doesn't exist.\n",
          "created_at": "2025-04-28T15:23:09Z"
        },
        {
          "author": "MahorShekhar",
          "body": "I've also faced similar issues in the past. however I was told `v1.4.2` will fix this issue. But seems issue is still there even in latest version.\n\nCC @dirkbrnd ",
          "created_at": "2025-04-29T06:45:35Z"
        },
        {
          "author": "pritipsingh",
          "body": "Hey @anionescubd,\nWould you mind upgrading to the latest version of Agno and setting stricter instructions when you get a chance?\n\nAlso, to help us investigate further, could you please share the team's config so we can debug it together? Thanks a lot!",
          "created_at": "2025-04-29T07:27:46Z"
        },
        {
          "author": "anionescubd",
          "body": "I am already on the latest version (1.4.2).\nThe issue occurs when I assign the agent a task that requires a step-by-step approach and 3-4 tools calls, where the output of one tool needs to be used as the input for another tool — and these tools are managed by different agents.",
          "created_at": "2025-04-29T09:43:15Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @anionescubd \nLooking into it!",
          "created_at": "2025-05-02T10:12:16Z"
        }
      ]
    },
    {
      "issue_number": 3177,
      "title": "[Bug] v1.4.6 affects the ability to perform data analysis using tools",
      "body": "### Description\n\nI used the same code to compare the output results of versions v1.4.5 and v1.4.6. \nv1.4.5 provided satisfactory answers, but v1.4.6 did not.\n\n### Steps to Reproduce\n\nimport json, os\nfrom pathlib import Path\nfrom textwrap import dedent\nfrom threading import Lock\nfrom typing import Any, Dict, Generator, List, Optional, Mapping\n\nfrom agno.agent import Agent\nfrom agno.models.azure import AzureOpenAI\nfrom agno.tools.python import PythonTools\nfrom agno.tools.reasoning import ReasoningTools\nfrom fastapi import APIRouter, File, Form, HTTPException, Request, UploadFile\nfrom fastapi.responses import JSONResponse, StreamingResponse\nfrom pydantic import BaseModel\n\n\nclass EmployeeMemory(BaseModel):\n    conversation_history: List[Dict[str, str]] = []\n    temp_path: Optional[str] = None\n    cache_dir: Optional[str] = None\n\n\nclass AnalysisRequest(BaseModel):\n    employee_id: str\n    query: str\n\n\nclass StreamChunk(BaseModel):\n    stage: str\n    message: Optional[str] = None\n    is_end: bool\n\n\nrouter = APIRouter()\nemployee_locks = {}\nEMPLOYEE_MEMORIES_PATH = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), \"temp_files\")\n\n\ndef get_employee_dir(employee_id: str) -> str:\n    \"\"\"获取员工数据目录路径\"\"\"\n    os.makedirs(EMPLOYEE_MEMORIES_PATH, exist_ok=True)\n    employee_dir = os.path.join(EMPLOYEE_MEMORIES_PATH, employee_id)\n    os.makedirs(employee_dir, exist_ok=True)\n    return employee_dir\n\n\ndef create_employee_lock(employee_id: str) -> Lock:\n    \"\"\"创建员工锁\"\"\"\n    if employee_id not in employee_locks:\n        employee_locks[employee_id] = Lock()\n    return employee_locks[employee_id]\n\n\ndef load_employee_memory(employee_id: str) -> EmployeeMemory:\n    \"\"\"加载员工记忆数据\"\"\"\n    with create_employee_lock(employee_id):\n        employee_dir = get_employee_dir(employee_id)\n        memory_file = os.path.join(employee_dir, \"memory.json\")\n        if os.path.exists(memory_file):\n            with open(memory_file, 'r', encoding='utf-8') as file:\n                return EmployeeMemory.model_validate(json.load(file))\n        return EmployeeMemory()\n\n\ndef save_employee_memory(employee_id: str, memory: EmployeeMemory):\n    \"\"\"保存员工记忆数据\"\"\"\n    with create_employee_lock(employee_id):\n        employee_dir = get_employee_dir(employee_id)\n        memory_file = os.path.join(employee_dir, \"memory.json\")\n        with open(memory_file, 'w', encoding='utf-8') as file:\n            json.dump(memory.model_dump(), file, ensure_ascii=False, indent=2)\n\n\ndef create_analyze_agent(python_dir: str) -> Agent:\n    \"\"\"创建数据分析代理\"\"\"\n    llm_azure = AzureOpenAI(\n        temperature=0,\n        api_key=\"。。。\",\n        api_version=\"2024-10-21\",\n        azure_endpoint=\"。。。\",\n        azure_deployment=\"gpt-41\"\n    )\n\n    return Agent(\n        model=llm_azure,\n        tools=[\n            ReasoningTools(add_instructions=True),\n            PythonTools(Path(python_dir)),\n        ],\n        instructions=dedent(\n            \"\"\"\\\n            ## 要求：\n            - 重要：使用中文进行思考。\n            - 始终先使用思考工具梳理完成任务所需的步骤。\n            - 在回应用户之前，收到Python工具给出的结果后，使用思考工具作为草稿本，反复验证结果的正确性。\n            - 理解当前问题与之前问题的关系，识别当前问题是否基于之前的分析结果，是否需要引用之前的数据或分析。\n            - 最终为用户输出经过严谨思考的数据分析结果，不要输出类似“请查看输出结果以获取详细信息”这样的结果，优先考虑输出表格。\n            - 如果之前已经问过并回答过这个问题，就完全按照之前给出的答案回复。\n            \n            ## 使用Python工具：\n            - 使用Python工具分析数据，不要假设工作表和字段，应先浏览缓存数据的工作表名称和字段名称，然后根据用户问题的语义进行分析判断，使用明确匹配或密切相关的字段。\n\n            ## 使用思考工具：\n            - 由于每个思考步骤执行环境都会重置，使用以下方法避免重复读取文件并识别异常工作表：\n                1.设置环境：\n                    - 使用中文代码注释。\n                    - 设置显示所有列及适当的行数。\n                    - 导入pandas、os等必要的库。\n                2.第一次读取文件时，识别异常工作表并使用缓存策略：\n                    - 异常工作表的判断标准：\n                        a. 行数少于5行或列数少于2列的工作表\n                        b. 数据填充率低于30%的工作表\n                        c. 列名全部或大部分是数字的工作表\n                        d. 包含大量合并单元格的工作表\n                        e. 前几行都是空值或NaN的工作表\n                    - 读取Excel文件后，识别出异常工作表并跳过，立即将有效的工作表保存为单独的pickle文件到临时目录。\n                    - 示例代码：\n                        ```python\n                        import pandas as pd\n                        import os\n                        from pathlib import Path\n                        \n                        # 读取Excel文件\n                        excel_path = r\"文件路径\"\n                        cache_dir = r\"缓存目录\"\n                        os.makedirs(cache_dir, exist_ok=True)\n                        \n                        # 读取所有工作表并缓存\n                        excel_file = pd.ExcelFile(excel_path)\n                        sheet_names = excel_file.sheet_names\n                        \n                        # 打印工作表信息\n                        print(f\"文件包含以下工作表: {sheet_names}\")\n                        \n                        # 保存每个工作表到缓存\n                        for sheet in sheet_names:\n                            df = pd.read_excel(excel_file, sheet_name=sheet)\n                            # 删除 Unnamed 列\n                            unnamed_cols = [col for col in df.columns if 'Unnamed:' in str(col)]\n                            if unnamed_cols:\n                                df = df.drop(columns=unnamed_cols)\n                            # 保存到缓存\n                            cache_path = os.path.join(cache_dir, f\"{sheet}.pkl\")\n                            df.to_pickle(cache_path)\n                            print(f\"已缓存工作表 '{sheet}' 到 {cache_path}\")\n                        ```\n                3.在后续步骤中，从缓存读取数据而非原始文件，只分析有效工作表：\n                    - 示例代码：\n                        ```python\n                        import pandas as pd\n                        import os\n\n                        # 从缓存读取工作表\n                        cache_dir = r\"缓存目录\"\n\n                        # 在缓存目录中查找 .pkl 文件\n                        pkl_files = [f for f in os.listdir(cache_dir) if f.endswith(\".pkl\")]\n\n                        if not pkl_files:\n                            print(f\"在目录 '{cache_dir}' 中未找到 .pkl 缓存文件。\")\n\n                        sheet_name_with_ext = \"在 pkl_files 中选择要分析的一个或多个工作表\"\n                        cache_path = os.path.join(cache_dir, f\"{sheet_name_with_ext}\")\n                        \n                        if os.path.exists(cache_path):\n                            df = pd.read_pickle(cache_path)\n                            print(f\"从缓存加载工作表 '{sheet_name_with_ext}' \")\n                        else:\n                            print(f\"缓存文件 '{cache_path}' 不存在，请先缓存数据\")\n                        ```\n                4.不要忘记导入pandas、os等必要的库。\n                5.对于每个用户问题，只对有效工作表进行分析。\n                6.查看并确认要使用的工作表：不要假设工作表，应先浏览缓存数据的工作表名称，然后再来确定要使用的工作表。\n                7.查看并确认要使用的字段：不要假设字段，应先浏览缓存数据的字段名称，然后根据用户问题的语义进行分析判断，使用明确匹配或密切相关的字段。\n                8.确认是否需要分组计算与排序：不要假设字段，应先浏览缓存数据的字段名称，然后根据用户问题的语义进行分析判断，使用明确匹配或密切相关的字段进行分组去重计算。\n                9.进行剩余的数据分析步骤：\n                    - 字段关联与合并：如需要合并多个工作表，使用缓存数据进行操作。\n                    - 数据去重与一致性检查：检查是否存在重复数据或异常值。\n                    - 验证结果：确保代码执行无误，并对结果进行必要的解释。\\\n            \"\"\"\n            ),\n        add_history_to_messages=True,\n        num_history_responses=10,\n        markdown=True,\n        show_tool_calls=True,\n    )\n\n\n@router.post(\"/upload_file_stream\")\nasync def upload_file_stream(\n    employee_id: str = Form(...),\n    file_ext: str = Form(...),\n    file: UploadFile = File(...),\n):\n    \"\"\"文件流上传\"\"\"\n    if not employee_id:\n        raise HTTPException(status_code=400, detail=\"员工ID不能为空\")\n    \n    if not file_ext:\n        raise HTTPException(status_code=400, detail=\"文件类型不能为空\")\n    \n    if not file or not file.filename:\n        raise HTTPException(status_code=400, detail=\"文件不能为空\")\n    \n    try:\n        file_size = 0\n        chunk = await file.read(1024)\n        if not chunk:\n            raise HTTPException(status_code=400, detail=\"上传的文件内容为空\")\n        # 重置文件指针，以便后续读取完整内容\n        await file.seek(0)\n    except Exception as e:\n        raise HTTPException(status_code=400, detail=f\"文件验证失败: {str(e)}\")\n    \n    filename = f\"upload_file.{file_ext}\"\n\n    try:\n        content = await file.read()\n        file_size = len(content)\n        max_size = 10 * 1024 * 1024\n\n        if file_size > max_size:\n            raise HTTPException(\n                status_code=400,\n                detail=f\"文件大小超过限制(10MB)，当前大小：{file_size/1024/1024:.2f}MB\",\n            )\n\n        file_extension = Path(filename).suffix.lower()\n        if file_extension not in [\".xlsx\", \".xls\", \".csv\"]:\n            raise HTTPException(\n                status_code=400,\n                detail=f\"不支持的文件类型：{file_extension}，仅支持 .xlsx, .xls, .csv\",\n            )\n\n        memory = load_employee_memory(employee_id)\n        employee_dir = get_employee_dir(employee_id)\n\n        if memory.temp_path and os.path.exists(memory.temp_path):\n            try:\n                os.unlink(memory.temp_path)\n            except:\n                pass\n\n        file_path = os.path.join(employee_dir, filename)\n\n        with open(file_path, 'wb') as file:\n            file.write(content)\n\n        memory.temp_path = file_path\n        memory.cache_dir = employee_dir\n        memory.conversation_history = []\n\n        save_employee_memory(employee_id, memory)\n\n        return JSONResponse(\n            content={\"choices\": [{\"message\": {\"content\": \"文件上传成功\"}}]}\n        )\n\n    except Exception as exception:\n        raise HTTPException(status_code=500, detail=f\"文件上传失败: {str(exception)}\")\n\n\n@router.post(\"/analyze_stream\")\nasync def analyze_stream(request: AnalysisRequest):\n    \"\"\"数据分析\"\"\"\n    def generate_stream() -> Generator[str, None, None]:\n        if not request.employee_id:\n            error_chunk = StreamChunk(stage=\"error\", message=\"员工ID不能为空\", is_end=True)\n            error_json = json.dumps(error_chunk.model_dump(), ensure_ascii=False)\n            yield f\"data: {error_json}\\n\\n\"\n            return\n\n        if not request.query:\n            error_chunk = StreamChunk(stage=\"error\", message=\"问题不能为空\", is_end=True)\n            error_json = json.dumps(error_chunk.model_dump(), ensure_ascii=False)\n            yield f\"data: {error_json}\\n\\n\"\n            return\n\n        memory = load_employee_memory(request.employee_id)\n        if not memory.temp_path:\n            error_chunk = StreamChunk(stage=\"error\", message=\"请先上传文件\", is_end=True)\n            error_json = json.dumps(error_chunk.model_dump(), ensure_ascii=False)\n            yield f\"data: {error_json}\\n\\n\"\n            return\n        \n        context = f\"文件路径：{memory.temp_path}，缓存目录：{memory.cache_dir}\"\n        if memory.conversation_history and len(memory.conversation_history) >= 2:\n            last_query = memory.conversation_history[-2][\"content\"]\n            last_answer = memory.conversation_history[-1][\"content\"]\n            context += f\"\\n\\n上一个问题是：{last_query}\\n\\n上一次的回答是：{last_answer}\"\n\n        full_query = f\"{context}\\n\\n问题：{request.query}\"\n\n        analyze_agent = create_analyze_agent(memory.cache_dir)\n        tool_index = 0\n        response_content = \"\"\n\n        try:\n            response_stream = analyze_agent.run(full_query, stream=True, stream_intermediate_steps=True)\n            step = 1\n            for chunk in response_stream:\n                if chunk.event == \"ReasoningStep\":\n                    reasoning_step = f\"\\n\\n## 第{step}步-{chunk.content.title} ##\\n\\n{chunk.content.reasoning}\\n\\n\"\n                    reasoning_chunk = StreamChunk(stage=\"thinking\", message=reasoning_step, is_end=False)\n                    reasoning_json = json.dumps(reasoning_chunk.model_dump(), ensure_ascii=False)\n                    yield f\"data: {reasoning_json}\\n\\n\"\n                    step += 1\n\n                elif chunk.event == \"ToolCallStarted\":\n                    code = chunk.tools[tool_index][\"tool_args\"].get(\"code\")\n                    if code:\n                        reasoning_step = f\"{code}\\n\\n\"\n                        reasoning_chunk = StreamChunk(stage=\"thinking\", message=reasoning_step, is_end=False)\n                        reasoning_json = json.dumps(reasoning_chunk.model_dump(), ensure_ascii=False)\n                        yield f\"data: {reasoning_json}\\n\\n\"\n                    tool_index += 1\n\n                elif chunk.event == \"RunResponse\" and chunk.content:\n                    if not response_content:\n                        end_chunk = StreamChunk(stage=\"thinking\", message=\"\", is_end=True)\n                        end_json = json.dumps(end_chunk.model_dump(), ensure_ascii=False)\n                        yield f\"data: {end_json}\\n\\n\"\n                    response_content += chunk.content\n                    content_chunk = StreamChunk(stage=\"content\", message=chunk.content, is_end=False)\n                    content_json = json.dumps(content_chunk.model_dump(), ensure_ascii=False)\n                    yield f\"data: {content_json}\\n\\n\"\n\n            memory.conversation_history.append({\"role\": \"user\", \"content\": request.query})\n            memory.conversation_history.append({\"role\": \"assistant\", \"content\": response_content})\n            save_employee_memory(request.employee_id, memory)\n\n            end_chunk = StreamChunk(stage=\"content\", message=\"\", is_end=True)\n            end_json = json.dumps(end_chunk.model_dump(), ensure_ascii=False)\n            yield f\"data: {end_json}\\n\\n\"\n\n        except Exception as exception:\n            error_chunk = StreamChunk(stage=\"error\", message=str(exception), is_end=True)\n            error_json = json.dumps(error_chunk.model_dump(), ensure_ascii=False)\n            yield f\"data: {error_json}\\n\\n\"\n\n    return StreamingResponse(\n        generate_stream(),\n        media_type=\"text/event-stream\"\n    )\n\n\n@router.post(\"/clear_conversation\")\nasync def clear_conversation(query_body: Mapping[str, Any]):\n    \"\"\"清除会话\"\"\"\n    if 'employee_id' not in query_body:\n        raise HTTPException(status_code=400, detail=\"员工ID不能为空\")\n    \n    employee_id = query_body[\"employee_id\"]\n\n    with create_employee_lock(employee_id):\n        temp_dir = get_employee_dir(employee_id)\n        if os.path.exists(temp_dir):\n            try:\n                import shutil\n                shutil.rmtree(temp_dir, ignore_errors=True)\n\n                return JSONResponse(\n                    content={\"choices\": [{\"message\": {\"content\": \"清除会话成功\"}}]}\n                )\n\n            except Exception as exception:\n                raise HTTPException(status_code=500, detail=f\"清除会话失败: {str(exception)}\")\n\n\n### Agent Configuration (if applicable)\n\n_No response_\n\n### Expected Behavior\n\nThe new version can provide correct answers.\n\n### Actual Behavior\n\nThe new version did not provide the correct answer.\n\n### Screenshots or Logs (if applicable)\n\n_No response_\n\n### Environment\n\n```markdown\nNo error.\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "Rainismer",
      "author_type": "User",
      "created_at": "2025-05-13T08:31:55Z",
      "updated_at": "2025-05-14T08:45:40Z",
      "closed_at": "2025-05-14T08:45:40Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3177/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3177",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3177",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:42.033811",
      "comments": []
    },
    {
      "issue_number": 3144,
      "title": "[Bug] OpenRouter model can't call tools",
      "body": "# Description\nOpenRouter model can't call mcp tools\n\n## Steps to Reproduce\n```\n\nfrom agno.agent import Agent\nfrom agno.models.openai import OpenAIChat\nfrom agno.tools.mcp import MCPTools\nfrom mcp import StdioServerParameters\nfrom agno.models.openrouter import OpenRouter\n\nasync def run_agent(message: str) -> None:\n    \"\"\"Run the filesystem agent with the given message.\"\"\"\n\n    file_path = str(Path(__file__).parent.parent.parent.parent)\n\n    # MCP server to access the filesystem (via `npx`)\n    async with MCPTools(f\"npx -y @modelcontextprotocol/server-filesystem {file_path}\") as mcp_tools:\n        agent = Agent(\n            model=OpenRouter(id=\"deepseek/deepseek-chat-v3-0324\"),\n            tools=[mcp_tools],\n            instructions=dedent(\"\"\"\\\n                You are a filesystem assistant. Help users explore files and directories.\n\n                - Navigate the filesystem to answer questions\n                - Use the list_allowed_directories tool to find directories that you can access\n                - Provide clear context about files you examine\n                - Use headings to organize your responses\n                - Be concise and focus on relevant information\\\n            \"\"\"),\n            markdown=True,\n            show_tool_calls=True,\n        )\n\n        # Run the agent\n        await agent.aprint_response(message, stream=True)\n\n\n# Example usage\nif __name__ == \"__main__\":\n    # Basic example - exploring project license\n    asyncio.run(run_agent(\"What is the license for this project?\"))\n```\n\n\n## Environment\n- OS: (Ubuntu)\n- Agno Version: (e.g. v1.4.5)\n\n",
      "state": "closed",
      "author": "huang-sh",
      "author_type": "User",
      "created_at": "2025-05-09T18:16:37Z",
      "updated_at": "2025-05-14T07:15:55Z",
      "closed_at": "2025-05-14T07:15:55Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3144/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3144",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3144",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:42.033831",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "@huang-sh Deepseek is notoriously bad at tool calling, however I ran your code and it passed for me? ",
          "created_at": "2025-05-10T21:45:42Z"
        }
      ]
    },
    {
      "issue_number": 3081,
      "title": "[Bug] PDFs from the same author using PDFKnowledgeBase",
      "body": "# Description\nApologies if this is not a bug, but I couldn't find any information in the docs related to this in the docs.\n\nI am trying to load approx. 50 files in my knowledge base for my Agent:\n\n```Python\nKNOWLEDGE_BASE = PDFKnowledgeBase(\n    path=\"data/partizanai_pdf_documents\",\n    vector_db=PgVector(\n        table_name=\"partizanai_pdf_documents\",\n        db_url=DB_URL,\n        # Default used is this one. This is from the code, because in docs it\n        # says \"text-embedding-ada-002\":\n        # embedder=OpenAIEmbedder(id=\"text-embedding-3-small\"),\n    ),\n)\n\n```\n\nThere are books which have the same author. Example of exact PDF file names:\n\n`Auksute_Ramanauskaite-Skokauskiene.-.Laisves_deklaracija_ir_jos_signatarai.2009.LT`\n\nand\n\n`Auksute_Ramanauskaite-Skokauskiene.-.Partizanu_vadas_generolas_Adolfas_Ramanauskas-Vanagas.2007.LT`\n\nIt adds the vector embeddings to my PostgreSQL database, but when attempting to add vectors to the second book, getting an error that `id Auksute_Ramanauskaite-Skokauskiene_2_1` (I think?) already exists and this violates non-null constraint:\n\n```bash\n[2025-05-05 09:18:16,425: ERROR/ForkPoolWorker-8] Task partizanai.load_knowledge_base[33fe861b-cec2-4f71-8c92-735db00a1f30] raised unexpected: IntegrityError('(psycopg.errors.UniqueViolation) duplicate key value violates unique constraint \"partizanai_pdf_documents_pkey\"\\nDETAIL:  Key (id)=(Auksute_Ramanauskaite-Skokauskiene_2_1) already exists.')\n```\n\nExample vector db entries from the 1st book that was added successfully:\n\n![Image](https://github.com/user-attachments/assets/c648279d-1627-4ad4-bef1-dfd9d7586f1c)\n\nMaybe it's somehow possible to workaround this? You could also point me to the code where I could override where this `id` field is set. \n\nIdeally I would like to maintain proper references to the book's author when chatting with the Agent if possible.\n\n## Steps to Reproduce\nList the steps needed to encounter this bug or issue.\n\n## Agent Configuration (if applicable)\nProvide relevant agent configuration.\n\n## Expected Behavior\nWhat did you expect to happen?\n\n## Actual Behavior\nWhat actually happened instead?\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- OS: (e.g. macOS, Windows 11)\n- Browser (if relevant): (e.g. Chrome 108, Firefox 107)\n- Agno Version: (e.g. v1.0.0)\n- External Dependency Versions: (e.g., yfinance 0.2.52)\n- Additional Environment Details: (e.g., Python 3.10)\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "Eimis",
      "author_type": "User",
      "created_at": "2025-05-05T06:22:38Z",
      "updated_at": "2025-05-14T04:14:33Z",
      "closed_at": "2025-05-08T15:37:57Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3081/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3081",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3081",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:42.204978",
      "comments": [
        {
          "author": "kausmeows",
          "body": "Hey @Eimis, thanks a lot for raising this. I have a PR out to fix this- https://github.com/agno-agi/agno/pull/3104\nIf you want to test on that branch please go ahead!",
          "created_at": "2025-05-06T19:50:14Z"
        },
        {
          "author": "kausmeows",
          "body": "Hi @Eimis the fix is merged and it will released soon today!",
          "created_at": "2025-05-08T15:37:57Z"
        },
        {
          "author": "Eimis",
          "body": "> Hi [@Eimis](https://github.com/Eimis) the fix is merged and it will released soon today!\n\nHey, thanks! I'll pull it tomorrow / the day after and will test, TYVM!",
          "created_at": "2025-05-08T18:27:52Z"
        },
        {
          "author": "Eimis",
          "body": "> Hi @Eimis the fix is merged and it will released soon today!\n\nUpdate - everything seems to work fine, thx again!",
          "created_at": "2025-05-14T04:14:32Z"
        }
      ]
    },
    {
      "issue_number": 2749,
      "title": "Teams and tool descriptions in team system prompt",
      "body": "I'm curious about what the purpose is of including team member tool descriptions into the system prompt for a team member. This makes the total team prompt huge if team members are specialized and have several tools. \n\n![Image](https://github.com/user-attachments/assets/e70af33c-1df5-4f05-acca-0b01c3ffdd26)\n\nI have tried removing this block and the results seem better for me than with this block in place. \n\nI think the idea with team members should be to minimize model token usage by delegating specialized tasks to team members who then only include their own tools into the subsequent message. \n\nAlso, tools are included already into the model request so why should we also be including them into the system prompt? \n\nWhat do you guys think? ",
      "state": "closed",
      "author": "mkschreder",
      "author_type": "User",
      "created_at": "2025-04-09T18:48:48Z",
      "updated_at": "2025-05-13T15:42:10Z",
      "closed_at": "2025-05-13T08:53:10Z",
      "labels": [
        "stale"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2749/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "dirkbrnd"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2749",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2749",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:42.430810",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-05-11T00:36:34Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @mkschreder \nThank you for your contribution. We have commented on your PR. Please let us know your feedback",
          "created_at": "2025-05-13T08:53:10Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@mkschreder We recently introduced `add_member_tools_to_system_message` flag for teams. You can now switch this off selectively.",
          "created_at": "2025-05-13T15:42:09Z"
        }
      ]
    },
    {
      "issue_number": 3120,
      "title": "[Bug]: Concurrent calls to Agent using `arun` are mixing RunResponses",
      "body": "# Description\nConcurrent calls to Agent are getting mixed together. I found this while working on https://github.com/mozilla-ai/any-agent/pull/225. I fixed a bug in our code that was causing traces/results from concurrent calls to be jumbled together. However, when I fixed the bug in any-agent, I then observed that my tests were now passing on all frameworks (google_adk/openai_agents/smolagents/llama_index/langchain) but continued to fail on Agno, which leads me to believe that there may be a bug in the agno implementation of `arun`. \n\n\n## Steps to Reproduce\nThis is just a snippet but basically, if you have a function like\n```\n  async def run_async(self, prompt: str, **kwargs: Any) -> \"AgentTrace\":\n      if not self._agent:\n          error_message = \"Agent not loaded. Call load_agent() first.\"\n          raise ValueError(error_message)\n      result: RunResponse = await self._agent.arun(prompt, **kwargs)\n      return AgentTrace(\n          final_output=result.content,\n      )\n```\nand then you do \n```\nresult1, result2 = await asyncio.gather(\n        agent.run_async(\"What is the capital of France?\"),\n        agent.run_async(\"What is the capital of Spain?\"),\n    )\nassert \"Paris\" in result1.final_output\nassert \"Madrid\" in result2.final_output\n```\n\nYou will observe that both results contain the same answer (either Paris, or Madrid) which leads me to believe that there is some memory sharing happening in agno under the hood that isn't isolating the two runs. I may be wrong so please help fill in my knowledge gap if this is the case 😅 \n\n\n\n## Agent Configuration (if applicable)\n\nhttps://github.com/mozilla-ai/any-agent/blob/main/src/any_agent/frameworks/agno.py\n\n## Expected Behavior\nI expected each async run to have its unique result\n\n## Actual Behavior\nthe agent runs both contained the same result\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\nagno==1.4.5\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "njbrake",
      "author_type": "User",
      "created_at": "2025-05-07T23:48:31Z",
      "updated_at": "2025-05-13T15:40:56Z",
      "closed_at": "2025-05-13T10:01:03Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3120/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3120",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3120",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:42.629727",
      "comments": [
        {
          "author": "kausmeows",
          "body": "Hi @njbrake thanks a lot for raising this, its indeed an issue from the `arun` implementation. I've fixed this in the PR- https://github.com/agno-agi/agno/pull/3138\n\nShould be released soon after some testing!",
          "created_at": "2025-05-09T13:26:01Z"
        },
        {
          "author": "njbrake",
          "body": "@kausmeows great, thanks!",
          "created_at": "2025-05-09T14:02:14Z"
        },
        {
          "author": "njbrake",
          "body": "Hi @monali7-d why was this closed as completed? @kausmeows 's PR #3138 is still open.",
          "created_at": "2025-05-13T09:44:20Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @njbrake \nsorry about that, reopened the issue",
          "created_at": "2025-05-13T09:47:00Z"
        },
        {
          "author": "kausmeows",
          "body": "Hey @njbrake , sorry about the oversight, its merged now!!",
          "created_at": "2025-05-13T10:00:57Z"
        }
      ]
    },
    {
      "issue_number": 2912,
      "title": "Error when using other module classes",
      "body": "why embedding not working in this code : \"from agno.agent import Agent\nfrom agno.embedder.huggingface import HuggingfaceCustomEmbedder\nfrom agno.knowledge.url import UrlKnowledge\nfrom agno.models.groq import Groq\nfrom agno.tools.reasoning import ReasoningTools\nfrom agno.vectordb.lancedb import LanceDb, SearchType\n\nfrom transformers import AutoModel, AutoTokenizer\nimport os\nfrom dotenv import load_dotenv\nload_dotenv()\n\n # loads .env into os.environ\n\nhf_token = (\n    os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n    or os.getenv(\"HF_HUB_TOKEN\")\n)\nif not hf_token:\n    raise RuntimeError(\n        \"Set HUGGINGFACEHUB_API_TOKEN or HF_HUB_TOKEN environment variable\"\n    )\n\nembedder = HuggingfaceCustomEmbedder(\n    id=\"sentence-transformers/all-MiniLM-L6-v2\",\n    api_key=hf_token,      # ← pass your token here\n    # if the class expects 'token' instead of 'api_key', swap the name\n)\n\n\"\"\"\nfrom agno.embedder.huggingface import HuggingfaceCustomEmbedder\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\nhf_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\") or os.getenv(\"HF_HUB_TOKEN\")\nif not hf_token:\n    raise RuntimeError(\"You must set HUGGINGFACEHUB_API_TOKEN or HF_HUB_TOKEN\")\n\nembedder = HuggingfaceCustomEmbedder(\n    #\"sentence-transformers/all-MiniLM-L6-v2\",\n    api_key=hf_token,      # or token=hf_token if that’s the arg name\n    # no need to pass `dimensions` here\n)\n\"\"\"\n\nprint(embedder)\n\n# Load Agno documentation in a knowledge base\nknowledge = UrlKnowledge(\n    urls=[\"https://docs.agno.com/introduction/agents.md\"],\n    vector_db=LanceDb(\n        uri=\"tmp/lancedb\",\n        table_name=\"agno_docs\",\n        search_type=SearchType.hybrid,\n        # Use OpenAI for embeddings\n        embedder=HuggingfaceCustomEmbedder(id=\"sentence-transformers/all-MiniLM-L6-v2\",api_key=os.getenv(\"HF_HUB_TOKEN\")),\n    ),\n)\n\nagent = Agent(\n    name=\"Agno Assist\",\n    model=Groq(id=\"deepseek-r1-distill-llama-70b\"),\n    instructions=[\n        \"Use tables to display data.\",\n        \"Include sources in your response.\",\n        \"Search your knowledge before answering the question.\",\n        \"Only include the output in your response. No other text.\",\n    ],\n    knowledge=knowledge,\n    tools=[ReasoningTools(add_instructions=True)],\n    add_datetime_to_instructions=True,\n    markdown=True,\n    debug_mode=True\n)\n\nif __name__ == \"__main__\":\n    # Load the knowledge base, comment out after first run\n    # Set recreate to True to recreate the knowledge base if needed\n    agent.knowledge.load(recreate=False)\n    agent.print_response(\n        \"What are Agents?\",\n        stream=True,\n        show_full_reasoning=True,\n        stream_intermediate_steps=True,\n    )\" \n\n---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n\nand the output is : \"---------------------------------------------------------------------------\nHTTPError                                 Traceback (most recent call last)\nFile ~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:406, in hf_raise_for_status(response, endpoint_name)\n    [405](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:405) try:\n--> [406](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:406)     response.raise_for_status()\n    [407](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:407) except HTTPError as e:\n\nFile ~/anaconda3/lib/python3.12/site-packages/requests/models.py:1024, in Response.raise_for_status(self)\n   [1023](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/requests/models.py:1023) if http_error_msg:\n-> [1024](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/requests/models.py:1024)     raise HTTPError(http_error_msg, response=self)\n\nHTTPError: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/sentence-transformers/all-MiniLM-L6-v2\n\nThe above exception was the direct cause of the following exception:\n\nBadRequestError                           Traceback (most recent call last)\nCell In[1], [line 52](vscode-notebook-cell:?execution_count=1&line=52)\n     [47](vscode-notebook-cell:?execution_count=1&line=47) print(embedder)\n     [49](vscode-notebook-cell:?execution_count=1&line=49) # Load Agno documentation in a knowledge base\n     [50](vscode-notebook-cell:?execution_count=1&line=50) knowledge = UrlKnowledge(\n     [51](vscode-notebook-cell:?execution_count=1&line=51)     urls=[\"https://docs.agno.com/introduction/agents.md\"],\n---> [52](vscode-notebook-cell:?execution_count=1&line=52)     vector_db=LanceDb(\n     [53](vscode-notebook-cell:?execution_count=1&line=53)         uri=\"tmp/lancedb\",\n     [54](vscode-notebook-cell:?execution_count=1&line=54)         table_name=\"agno_docs\",\n     [55](vscode-notebook-cell:?execution_count=1&line=55)         search_type=SearchType.hybrid,\n     [56](vscode-notebook-cell:?execution_count=1&line=56)         # Use OpenAI for embeddings\n     [57](vscode-notebook-cell:?execution_count=1&line=57)         embedder=HuggingfaceCustomEmbedder(id=\"sentence-transformers/all-MiniLM-L6-v2\",api_key=os.getenv(\"HF_HUB_TOKEN\")),\n     [58](vscode-notebook-cell:?execution_count=1&line=58)     ),\n     [59](vscode-notebook-cell:?execution_count=1&line=59) )\n     [61](vscode-notebook-cell:?execution_count=1&line=61) agent = Agent(\n     [62](vscode-notebook-cell:?execution_count=1&line=62)     name=\"Agno Assist\",\n     [63](vscode-notebook-cell:?execution_count=1&line=63)     model=Groq(id=\"deepseek-r1-distill-llama-70b\"),\n   (...)\n     [74](vscode-notebook-cell:?execution_count=1&line=74)     debug_mode=True\n     [75](vscode-notebook-cell:?execution_count=1&line=75) )\n     [77](vscode-notebook-cell:?execution_count=1&line=77) if __name__ == \"__main__\":\n     [78](vscode-notebook-cell:?execution_count=1&line=78)     # Load the knowledge base, comment out after first run\n     [79](vscode-notebook-cell:?execution_count=1&line=79)     # Set recreate to True to recreate the knowledge base if needed\n\nFile ~/anaconda3/lib/python3.12/site-packages/agno/vectordb/lancedb/lance_db.py:111, in LanceDb.__init__(self, uri, connection, table, async_connection, async_table, table_name, api_key, embedder, search_type, distance, nprobes, reranker, use_tantivy, on_bad_vectors, fill_value)\n    [109](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/agno/vectordb/lancedb/lance_db.py:109)         self._id = \"id\"\n    [110](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/agno/vectordb/lancedb/lance_db.py:110)         self._vector_col = \"vector\"\n--> [111](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/agno/vectordb/lancedb/lance_db.py:111)         self.table = self._init_table()\n    [113](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/agno/vectordb/lancedb/lance_db.py:113) self.reranker: Optional[Reranker] = reranker\n    [114](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/agno/vectordb/lancedb/lance_db.py:114) self.nprobes: Optional[int] = nprobes\n\nFile ~/anaconda3/lib/python3.12/site-packages/agno/vectordb/lancedb/lance_db.py:168, in LanceDb._init_table(self)\n    [167](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/agno/vectordb/lancedb/lance_db.py:167) def _init_table(self) -> lancedb.db.LanceTable:\n--> [168](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/agno/vectordb/lancedb/lance_db.py:168)     schema = self._base_schema()\n    [170](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/agno/vectordb/lancedb/lance_db.py:170)     log_info(f\"Creating table: {self.table_name}\")\n    [171](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/agno/vectordb/lancedb/lance_db.py:171)     tbl = self.connection.create_table(self.table_name, schema=schema, mode=\"overwrite\", exist_ok=True)  # type: ignore\n\nFile ~/anaconda3/lib/python3.12/site-packages/agno/vectordb/lancedb/lance_db.py:159, in LanceDb._base_schema(self)\n    [152](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/agno/vectordb/lancedb/lance_db.py:152) def _base_schema(self) -> pa.Schema:\n    [153](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/agno/vectordb/lancedb/lance_db.py:153)     return pa.schema(\n    [154](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/agno/vectordb/lancedb/lance_db.py:154)         [\n    [155](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/agno/vectordb/lancedb/lance_db.py:155)             pa.field(\n    [156](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/agno/vectordb/lancedb/lance_db.py:156)                 self._vector_col,\n    [157](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/agno/vectordb/lancedb/lance_db.py:157)                 pa.list_(\n    [158](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/agno/vectordb/lancedb/lance_db.py:158)                     pa.float32(),\n--> [159](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/agno/vectordb/lancedb/lance_db.py:159)                     len(self.embedder.get_embedding(\"test\")),  # type: ignore\n    [160](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/agno/vectordb/lancedb/lance_db.py:160)                 ),\n    [161](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/agno/vectordb/lancedb/lance_db.py:161)             ),\n    [162](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/agno/vectordb/lancedb/lance_db.py:162)             pa.field(self._id, pa.string()),\n    [163](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/agno/vectordb/lancedb/lance_db.py:163)             pa.field(\"payload\", pa.string()),\n    [164](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/agno/vectordb/lancedb/lance_db.py:164)         ]\n    [165](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/agno/vectordb/lancedb/lance_db.py:165)     )\n\nFile ~/anaconda3/lib/python3.12/site-packages/agno/embedder/huggingface.py:41, in HuggingfaceCustomEmbedder.get_embedding(self, text)\n     [40](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/agno/embedder/huggingface.py:40) def get_embedding(self, text: str) -> List[float]:\n---> [41](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/agno/embedder/huggingface.py:41)     response = self._response(text=text)\n     [42](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/agno/embedder/huggingface.py:42)     try:\n     [43](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/agno/embedder/huggingface.py:43)         decoded_string = response.decode(\"utf-8\")\n\nFile ~/anaconda3/lib/python3.12/site-packages/agno/embedder/huggingface.py:38, in HuggingfaceCustomEmbedder._response(self, text)\n     [37](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/agno/embedder/huggingface.py:37) def _response(self, text: str):\n---> [38](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/agno/embedder/huggingface.py:38)     return self.client.post(json={\"inputs\": text}, model=self.id)\n\nFile ~/anaconda3/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:305, in InferenceClient.post(self, json, data, model, task, stream)\n    [302](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:302)         raise InferenceTimeoutError(f\"Inference call timed out: {url}\") from error  # type: ignore\n    [304](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:304) try:\n--> [305](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:305)     hf_raise_for_status(response)\n    [306](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:306)     return response.iter_lines() if stream else response.content\n    [307](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:307) except HTTPError as error:\n\nFile ~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:460, in hf_raise_for_status(response, endpoint_name)\n    [456](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:456) elif response.status_code == 400:\n    [457](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:457)     message = (\n    [458](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:458)         f\"\\n\\nBad request for {endpoint_name} endpoint:\" if endpoint_name is not None else \"\\n\\nBad request:\"\n    [459](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:459)     )\n--> [460](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:460)     raise _format(BadRequestError, message, response) from e\n    [462](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:462) elif response.status_code == 403:\n    [463](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:463)     message = (\n    [464](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:464)         f\"\\n\\n{response.status_code} Forbidden: {error_message}.\"\n    [465](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:465)         + f\"\\nCannot access content at: {response.url}.\"\n    [466](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:466)         + \"\\nMake sure your token has the correct permissions.\"\n    [467](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:467)     )\n\nBadRequestError: (Request ID: Root=1-680631f0-6f3c8a2168e6bd900a91cb2b;6fc1a70a-cdd9-4ab7-9c73-279e6112dde1)\n\nBad request:\nInput should be a valid dictionary or instance of SentenceSimilarityInputsCheck: received `test` in `parameters`\"",
      "state": "closed",
      "author": "MohamedLahmeri01",
      "author_type": "User",
      "created_at": "2025-04-21T11:56:52Z",
      "updated_at": "2025-05-13T15:32:51Z",
      "closed_at": "2025-05-13T15:32:50Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2912/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2912",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2912",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:42.795446",
      "comments": [
        {
          "author": "anuragts",
          "body": "Hi @MohamedLahmeri01, thank you for reporting this issue and for the detailed example. We’ve identified the problem with the Huggingface embedder and have merged a fix. The update will be included in the next release, coming soon. We appreciate your patience and help in making Agno better!",
          "created_at": "2025-04-28T12:07:39Z"
        },
        {
          "author": "dirkbrnd",
          "body": "This has been released!",
          "created_at": "2025-05-13T15:32:50Z"
        }
      ]
    },
    {
      "issue_number": 2977,
      "title": "Embedding issues",
      "body": "please return the embedding creation as it was , the new methods not working with huggingface or other open-source : \n``from agno.agent import Agent\nfrom agno.models.groq import Groq\nfrom agno.knowledge.pdf_url import PDFUrlKnowledgeBase\nfrom agno.vectordb.chroma import ChromaDb\nfrom agno.embedder.huggingface import HuggingfaceCustomEmbedder\nfrom dotenv import load_dotenv\nimport os\n\nload_dotenv()\nhf_api_key = os.getenv(\"HF_HUB_TOKEN\")\n# Initialize ChromaDB with the correct parameters\nvector_db = ChromaDb(\n    collection=\"recipes\",  # Required parameter\n    path=\"tmp/chromadb\",   # Optional: specifies the storage path\n    persistent_client=True,  # Optional: enables persistent storage\n    embedder=HuggingfaceCustomEmbedder(api_key=hf_api_key,id=\"sentence-transformers/all-MiniLM-L6-v2\")  # Optional: custom embedder\n)\n\n# Create the knowledge base\nknowledge_base = PDFUrlKnowledgeBase(\n    urls=[\"https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n    vector_db=vector_db\n)\n\n# Load the knowledge base\nknowledge_base.load(upsert=True)\n\n# Initialize the agent\nagent = Agent(\n    model=Groq(),\n    knowledge=knowledge_base,\n    add_references=True,\n    search_knowledge=False,\n    markdown=True\n)\n\n# Use the agent to get a response\nagent.print_response(\"How do I make chicken and galangal in coconut milk soup\")\n``\nthe issue : \"---------------------------------------------------------------------------\nHTTPError                                 Traceback (most recent call last)\nFile ~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:406, in hf_raise_for_status(response, endpoint_name)\n    [405](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/1.Agents/~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:405) try:\n--> [406](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/1.Agents/~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:406)     response.raise_for_status()\n    [407](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/1.Agents/~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:407) except HTTPError as e:\n\nFile ~/anaconda3/lib/python3.12/site-packages/requests/models.py:1024, in Response.raise_for_status(self)\n   [1023](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/1.Agents/~/anaconda3/lib/python3.12/site-packages/requests/models.py:1023) if http_error_msg:\n-> [1024](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/1.Agents/~/anaconda3/lib/python3.12/site-packages/requests/models.py:1024)     raise HTTPError(http_error_msg, response=self)\n\nHTTPError: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/sentence-transformers/all-MiniLM-L6-v2\n\nThe above exception was the direct cause of the following exception:\n\nBadRequestError                           Traceback (most recent call last)\nCell In[16], [line 26](vscode-notebook-cell:?execution_count=16&line=26)\n     [20](vscode-notebook-cell:?execution_count=16&line=20) knowledge_base = PDFUrlKnowledgeBase(\n     [21](vscode-notebook-cell:?execution_count=16&line=21)     urls=[\"https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n     [22](vscode-notebook-cell:?execution_count=16&line=22)     vector_db=vector_db\n     [23](vscode-notebook-cell:?execution_count=16&line=23) )\n     [25](vscode-notebook-cell:?execution_count=16&line=25) # Load the knowledge base\n---> [26](vscode-notebook-cell:?execution_count=16&line=26) knowledge_base.load(upsert=True)\n     [28](vscode-notebook-cell:?execution_count=16&line=28) # Initialize the agent\n     [29](vscode-notebook-cell:?execution_count=16&line=29) agent = Agent(\n...\n\nBadRequestError: (Request ID: Root=1-680acc5a-4583769d2d9833bf6fffc005;a1653a9a-f915-41d2-a9fc-8aa94ffece75)\n\nBad request:\nInput should be a valid dictionary or instance of SentenceSimilarityInputsCheck: received `C O O K B O O K [www.thaiselect.com](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/1.Agents/www.thaiselect.com) [www.thaiselect.com](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/1.Agents/www.thaiselect.com) ` in `parameters`\nOutput is truncated. View as a [scrollable element](command:cellOutput.enableScrolling?183750bc-2785-4b1c-9b60-5842d9ddb419) or open in a [text editor](command:workbench.action.openLargeOutput?183750bc-2785-4b1c-9b60-5842d9ddb419). Adjust cell output [settings](command:workbench.action.openSettings?%5B%22%40tag%3AnotebookOutputLayout%22%5D)...\"",
      "state": "closed",
      "author": "MohamedLahmeri01",
      "author_type": "User",
      "created_at": "2025-04-24T23:44:44Z",
      "updated_at": "2025-05-13T15:32:01Z",
      "closed_at": "2025-05-13T15:32:01Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2977/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2977",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2977",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:42.990807",
      "comments": [
        {
          "author": "Mustafa-Esoofally",
          "body": "Hi! Thanks for reaching out. Could you try using ` 'SentenceTransformerEmbedder'` instead of HuggingfaceCustomEmbedder. Here's how the vector_db will be initialized:\n\n\n```\n# Initialize ChromaDB with the correct parameters\nvector_db = ChromaDb(\n    collection=\"recipes\", # Required parameter\n    path=",
          "created_at": "2025-04-25T20:40:50Z"
        }
      ]
    },
    {
      "issue_number": 3110,
      "title": "support agent testing with scenario",
      "body": " \nsupport [scenario](https://github.com/langwatch/scenario) testing integration \n\neample \nhttps://github.com/langwatch/create-agent-app/blob/main/agno_example/tests/test_customer_support_agent.py",
      "state": "closed",
      "author": "xmlking",
      "author_type": "User",
      "created_at": "2025-05-07T06:18:04Z",
      "updated_at": "2025-05-13T15:31:28Z",
      "closed_at": "2025-05-13T15:31:28Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3110/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3110",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3110",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:43.227516",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @xmlking ! Here is how you can use scenario to test your Agno Agents. \n\n```python\nimport pytest\n\nfrom scenario import Scenario, TestingAgent, scenario_cache\n\nScenario.configure(testing_agent=TestingAgent(model=\"openai/gpt-4o-mini\"))\n\n\n@pytest.mark.agent_test\n@pytest.mark.asyncio\nasync def test",
          "created_at": "2025-05-07T19:52:02Z"
        }
      ]
    },
    {
      "issue_number": 2946,
      "title": "Thinking tools can not be called on the client",
      "body": "# Description\nDue to special handling of thinking tools, the tool can not be instantiated on the client instead of server. It has to be attached directly to the agent (ie has to be on the server). \n\n## Steps to Reproduce\n\n![Image](https://github.com/user-attachments/assets/6c3441b8-c5e5-4b04-bcca-9cea23369d1e)\n\n## Alternative solutions\n\nWhile running the thinking tool on the server would work, we should in general try to make it possible to run tools remotely on the client or on the server just the same. This means that tool description must always include ALL tool parameters and the model should be able to instantiate all tool parameters as json. \n",
      "state": "closed",
      "author": "mkschreder",
      "author_type": "User",
      "created_at": "2025-04-23T15:31:52Z",
      "updated_at": "2025-05-13T15:19:30Z",
      "closed_at": "2025-05-13T15:19:30Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2946/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2946",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2946",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:43.413368",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @mkschreder ! Yes, you are right. As the thinking tool alters the state of the Agent itself, it takes the Agent as an argument. This is different from the way tools usually work.\n\nIf a function includes \"agent\" as a param, during the execution of the function, we give it access to the Agent in",
          "created_at": "2025-04-28T09:03:17Z"
        }
      ]
    },
    {
      "issue_number": 2833,
      "title": "[Bug] Structured Output + MCP Sequential Thinking = schema errror from OpenAI",
      "body": "# Description\nWhen trying to use a Pydantic response_model with the agent if you set structured_output to True, or leave it off (it will default to true with a response_model) you will get schema error about in my case is the sequentialthinking MCP tool like so: \nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for function 'sequentialthinking': In context=(), 'additionalProperties' is required to be supplied and to be false.\", 'type': 'invalid_request_error', 'param': 'tools[10].function.parameters', 'code': 'invalid_function_parameters'}}\n\n## Steps to Reproduce\nCreate an agent with MCP tools, in this case sequentialthinking is easy enough, and then set a response_model. \n\nNOTE: If you set json_mode on it will disabled structured_output for the agent and it works and the pydantic model gets hydrated by the agent. \n\n## Agent Configuration (if applicable)\nProvide relevant agent configuration.    async with MCPTools(f\"npx @modelcontextprotocol/server-sequential-thinking\") as mcp_tools:\n        agent = Agent(\n            model=OpenAIChat(id=\"gpt-4.1-mini\"),\n            storage=SqliteStorage(table_name=\"heinz_agent\"),\n            tools=[LinearTools(),GithubTools(),mcp_tools,ThinkingTools()],\n            reasoning_model=OpenAIChat(id=\"o3-mini\", reasoning_effort=\"high\"),\n            response_model=CreateTicketPayload,\n            debug_mode=True\n        )\n\n\n",
      "state": "closed",
      "author": "dustyp",
      "author_type": "User",
      "created_at": "2025-04-15T01:16:10Z",
      "updated_at": "2025-05-13T15:18:52Z",
      "closed_at": "2025-05-13T15:18:48Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2833/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2833",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2833",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:43.591107",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Hi @dustyp which version of Agno are you on? I tried this on the latest version and did not see this issue. ",
          "created_at": "2025-04-17T10:41:46Z"
        }
      ]
    },
    {
      "issue_number": 2908,
      "title": "using other embedders other then Openai not working",
      "body": "trying to use other embeddings like huggingface not working \n`---------------------------------------------------------------------------\nHTTPError                                 Traceback (most recent call last)\nFile ~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:406, in hf_raise_for_status(response, endpoint_name)\n    [405](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:405) try:\n--> [406](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:406)     response.raise_for_status()\n    [407](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:407) except HTTPError as e:\n\nFile ~/anaconda3/lib/python3.12/site-packages/requests/models.py:1024, in Response.raise_for_status(self)\n   [1023](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/requests/models.py:1023) if http_error_msg:\n-> [1024](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/requests/models.py:1024)     raise HTTPError(http_error_msg, response=self)\n\nHTTPError: 401 Client Error: Unauthorized for url: https://api-inference.huggingface.co/models/sentence-transformers/all-MiniLM-L6-v2\n\nThe above exception was the direct cause of the following exception:\n\nHfHubHTTPError                            Traceback (most recent call last)\nCell In[69], [line 52](vscode-notebook-cell:?execution_count=69&line=52)\n     [47](vscode-notebook-cell:?execution_count=69&line=47) print(embedder)\n     [49](vscode-notebook-cell:?execution_count=69&line=49) # Load Agno documentation in a knowledge base\n     [50](vscode-notebook-cell:?execution_count=69&line=50) knowledge = UrlKnowledge(\n     [51](vscode-notebook-cell:?execution_count=69&line=51)     urls=[\"https://docs.agno.com/introduction/agents.md\"],\n---> [52](vscode-notebook-cell:?execution_count=69&line=52)     vector_db=LanceDb(\n     [53](vscode-notebook-cell:?execution_count=69&line=53)         uri=\"tmp/lancedb\",\n     [54](vscode-notebook-cell:?execution_count=69&line=54)         table_name=\"agno_docs\",\n     [55](vscode-notebook-cell:?execution_count=69&line=55)         search_type=SearchType.hybrid,\n...\n--> [477](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:477) raise _format(HfHubHTTPError, str(e), response) from e\n\nHfHubHTTPError: 401 Client Error: Unauthorized for url: https://api-inference.huggingface.co/models/sentence-transformers/all-MiniLM-L6-v2 (Request ID: Root=1-68060a01-593ae2463b23b6de5def1f35;3d164222-8ec6-4e17-ba1b-7d46d07aff0d)\n\nInvalid credentials in Authorization header\nOutput is truncated. View as a [scrollable element](command:cellOutput.enableScrolling?aad570fb-ed20-46a9-8b4e-ff57334a0d60) or open in a [text editor](command:workbench.action.openLargeOutput?aad570fb-ed20-46a9-8b4e-ff57334a0d60). Adjust cell output [settings](command:workbench.action.openSettings?%5B%22%40tag%3AnotebookOutputLayout%22%5D)...`",
      "state": "closed",
      "author": "MohamedLahmeri01",
      "author_type": "User",
      "created_at": "2025-04-21T09:04:23Z",
      "updated_at": "2025-05-13T15:16:25Z",
      "closed_at": "2025-05-13T15:16:24Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2908/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2908",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2908",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:43.787845",
      "comments": [
        {
          "author": "anuragts",
          "body": "Hey @MohamedLahmeri01 \n\nCan you provide with your agent config code ?",
          "created_at": "2025-04-24T08:03:37Z"
        },
        {
          "author": "MohamedLahmeri01",
          "body": "@anuragts here is the code \n\n`from agno.agent import Agent\nfrom agno.embedder.huggingface import HuggingfaceCustomEmbedder\nfrom agno.knowledge.url import UrlKnowledge\nfrom agno.models.groq import Groq\nfrom agno.tools.reasoning import ReasoningTools\nfrom agno.vectordb.lancedb import LanceDb, SearchTy",
          "created_at": "2025-04-24T09:10:49Z"
        },
        {
          "author": "anuragts",
          "body": "Hi @MohamedLahmeri01,  \nThank you for reporting this issue and sharing your code.  \nWe have merged a fix for this problem. The update will be included in the next release, coming soon.  \nReally appreciate your patience and help in making Agno better!",
          "created_at": "2025-04-28T12:05:35Z"
        },
        {
          "author": "dirkbrnd",
          "body": "A fix has been released!",
          "created_at": "2025-05-13T15:16:24Z"
        }
      ]
    },
    {
      "issue_number": 2786,
      "title": "[Bug]",
      "body": "# Description\nDouble quotes in Oracle SQL queries\n\n## Steps to Reproduce\n\n1. Run similar query from Agent UI: Give me 5 products with 100% match on 10th April 2025\n2. LLama gives below\nSQL Query:  SELECT PRODUCT FROM PRODUCT_SUMMARY WHERE MATCH_PERCENT = 100 AND RUN_DATE = '10-Apr-25'\n3.  SQLTools prints below error  in log\nERROR    Error running query: (cx_Oracle.DatabaseError) ORA-00904: \"10-Apr-25\": invalid identifier\n         [SQL: SELECT PRODUCT  FROM PRODUCT_SUMMARY WHERE MATCH_PERCENT = 100 AND RUN_DATE = \"10-Apr-25\"]\n         (Background on this error at:  https://sqlalche.me/e/20/4xp6)\n\n\n## Agent Configuration (if applicable)\nsql_tools = SQLTools(\n    db_engine=engine,\n    tables=allowed_tables,\n    schema=\"CUSTOM_SCHEMA\",\n)\nsql_tools.add_instructions = True\nsql_tools.instructions = (\n    \"If double quotes are used in the SQL query, replace them with single quotes.\"\n)\nagent = Agent(\n        name=\"DB Analysis Agent\",\n        model=Ollama(id=\"llama3.2:3b-instruct-q8_0\"),\n        markdown=True,\n        show_tool_calls=True,\n        add_history_to_messages=True,\n        system_message=system_prompt,\n        tools=[sql_tools],\n    )\n\n## Expected Behavior\nDouble  quotes should not be there in Oracle SQL where conditions\n\n## Actual Behavior\nPython is probably changing the single quotes to double  quotes causing syntax issues while executing\n\n\n## Environment\n- OS: Windows 11\n- Agno Version: 1.2.11\n- Additional Environment Details: Python 3.12\n",
      "state": "closed",
      "author": "ravivanjarapu",
      "author_type": "User",
      "created_at": "2025-04-11T16:26:14Z",
      "updated_at": "2025-05-13T15:14:11Z",
      "closed_at": "2025-05-13T15:14:11Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2786/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2786",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2786",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:43.963568",
      "comments": [
        {
          "author": "Ayush0054",
          "body": "Hey @ravivanjarapu,\nCould you please try using this hotfix for Oracle SQL tool implementation?\n\n```\nfrom typing import Optional\n\nclass OracleSQLTools(SQLTools):\n    def run_sql_query(self, query: str, limit: Optional[int] = 10) -> str:\n        # Ensure string literals use single quotes for Oracle co",
          "created_at": "2025-04-28T21:04:28Z"
        }
      ]
    },
    {
      "issue_number": 2865,
      "title": "[Bug]",
      "body": "INFO:httpx:HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions \"HTTP/1.1 400 Bad Request\"\nERROR    API status error from OpenAI API: Error code: 400 - {'error': {'code': 'invalid_parameter_error', 'param': None, 'message': '<400> InternalError.Algo.InvalidParameter: An assistant message with         \n         \"tool_calls\" must be followed by tool messages responding to each \"tool_call_id\". The following tool_call_ids did not have response messages: message[3].role', 'type': 'invalid_request_error'}, 'id':   \n         'chatcmpl-76d0a62b-b14a-9c74-879d-c00997254635', 'request_id': '76d0a62b-b14a-9c74-879d-c00997254635'}                                                                                                    \n2025-04-17 19:58:19,973 - app - ERROR: <400> InternalError.Algo.InvalidParameter: An assistant message with \"tool_calls\" must be followed by tool messages responding to each \"tool_call_id\". The following tool_call_ids did not have response messages: message[3].role\n",
      "state": "closed",
      "author": "harrisHxy",
      "author_type": "User",
      "created_at": "2025-04-17T12:28:09Z",
      "updated_at": "2025-05-13T15:12:55Z",
      "closed_at": "2025-05-13T15:12:54Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2865/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2865",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2865",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:44.155887",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Hi @harrisHxy \nWould you mind sharing the code you used to get this? ",
          "created_at": "2025-04-17T12:43:09Z"
        },
        {
          "author": "harrisHxy",
          "body": "> Hi [@harrisHxy](https://github.com/harrisHxy) Would you mind sharing the code you used to get this?\n\nThis is an agent, which is one of the members of the team, and this bug sometimes appears during execution：\n\n\ncustomer_agent = Agent(\n    name=\"ai agent\",\n    agent_id=\"002\",\n    # aliyun qwen-max\n",
          "created_at": "2025-04-18T01:43:00Z"
        },
        {
          "author": "dirkbrnd",
          "body": "I have seen this happen when the team leader attempts to call a function on the member agent. You should be able to see this happen if you switch on `debug_logs=True`.\nA solve for that would be to exclude member tool definitions by setting `add_member_tools_to_system_message=False`",
          "created_at": "2025-04-18T13:02:13Z"
        },
        {
          "author": "zizake",
          "body": "Same for me.\n",
          "created_at": "2025-04-28T00:06:57Z"
        },
        {
          "author": "dirkbrnd",
          "body": "This should be resolved with the latest 1.5.0 release! Thanks for your patience!",
          "created_at": "2025-05-13T15:12:54Z"
        }
      ]
    },
    {
      "issue_number": 2881,
      "title": "[Bug] 'Please install the `semantic` extra to use this feature'",
      "body": "# Description\nUsing `agno.document.chunking.semantic.SemanticChunking` in Agno version 1.3.3 fails with an `ImportError` related to a missing `semantic` extra, even when using the default `OpenAIEmbedder` with model `text-embedding-3-small`. Attempting to install the suggested extra via `pip install \"agno[semantic]\"` results in a warning that this version does not provide the extra.\n\n## Steps to Reproduce\n1. Install `agno==1.3.3` and its dependencies (including `openai`, `qdrant-client`, `python-dotenv`).\n2. Create a Python script that initializes `agno.document.chunking.semantic.SemanticChunking`. This can be done directly or via a `Reader` class like `TextReader`. For example:\n   ```python\n   from agno.document.reader.text_reader import TextReader\n   from agno.document.chunking.semantic import SemanticChunking\n   # ... other imports\n   text_reader = TextReader(chunk=True, chunking_strategy=SemanticChunking())\n   ```\n3. Ensure an OpenAI embedder (like the default `text-embedding-3-small`) is implicitly or explicitly used by `SemanticChunking`.\n4. Run the script.\n\n## Agent Configuration (if applicable)\nWhile not strictly an agent issue, the problem occurs during the setup of components often used with agents, specifically when initializing the chunking strategy:\n```python\n# Example from load_docs_to_qdrant.py that triggers the error:\nfrom agno.document.reader.text_reader import TextReader\nfrom agno.document.chunking.semantic import SemanticChunking\n\ntext_reader = TextReader(chunk=True, chunking_strategy=SemanticChunking())\n```\n\n## Expected Behavior\n`SemanticChunking` should initialize successfully without errors, either by using the default `OpenAIEmbedder` or a provided compatible embedder instance. If an extra dependency is truly required, `pip install \"agno[semantic]\"` should successfully install it.\n\n## Actual Behavior\nThe script fails during the initialization of `SemanticChunking` with the following error:\n```\nImportError: ('text-embedding-3-small is not a valid embedding model', 'Please install the `semantic` extra to use this feature')\n```\nAttempting to install the extra dependency fails:\n```\n(.venv) E:\\AI\\RAG\\Agno> .venv\\Scripts\\pip.exe install \"agno[semantic]\"\nRequirement already satisfied: agno[semantic] in e:\\ai\\rag\\agno\\.venv\\lib\\site-packages (1.3.3)\nWARNING: agno 1.3.3 does not provide the extra 'semantic'\n... (other requirements satisfied) ...\n```\n\n## Screenshots or Logs (if applicable)\n```\n2025-04-18 22:17:32,552 - ERROR - An error occurred during the loading process: ('text-embedding-3-small is not a valid embedding model', 'Please install the `semantic` extra to use this feature')\nTraceback (most recent call last):\n  File \"E:\\AI\\RAG\\Agno\\load_docs_to_qdrant.py\", line 148, in <module>\n    text_reader = TextReader(chunk=True, chunking_strategy=SemanticChunking()) # Error occurs here\n  File \"E:\\AI\\RAG\\Agno\\.venv\\Lib\\site-packages\\agno\\document\\chunking\\semantic.py\", line 23, in __init__\n    self.chunker = SemanticChunker(\n                   ^^^^^^^^^^^^^^^^\n  File \"E:\\AI\\RAG\\Agno\\.venv\\Lib\\site-packages\\chonkie\\chunker\\semantic.py\", line 142, in __init__\n    raise ImportError(\nImportError: ('text-embedding-3-small is not a valid embedding model', 'Please install the `semantic` extra to use this feature')\n```\n\n## Environment\n- OS: Windows 11\n- Browser (if relevant): N/A\n- Agno Version: 1.3.3\n- External Dependency Versions: openai, qdrant-client, python-dotenv, chonkie (used internally by SemanticChunking)\n- Additional Environment Details: Python 3.12.6\n\n## Additional Context\nThe issue seems related to how optional dependencies (extras) are defined or handled in Agno v1.3.3. The error originates from the `chonkie` library when it receives the `text-embedding-3-small` model ID, but the inability to install the required `semantic` extra points to an issue within the Agno package definition itself for this version. This prevents the use of semantic chunking with the default (and potentially other) embedding models.\n```",
      "state": "closed",
      "author": "gabelul",
      "author_type": "User",
      "created_at": "2025-04-18T20:32:46Z",
      "updated_at": "2025-05-13T15:12:20Z",
      "closed_at": "2025-05-13T15:12:20Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2881/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2881",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2881",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:44.339501",
      "comments": [
        {
          "author": "coljac",
          "body": "Could this be a bug in the chonkie package? `chonkie[semantic]` does exist, but installing it does not resolve this issue.",
          "created_at": "2025-04-19T12:46:43Z"
        },
        {
          "author": "gabelul",
          "body": "I tried installing Chonkie [semantic] too, but it said it already existed. i used chonkie quite some time ago, but i remember the semantic chunking worked fine",
          "created_at": "2025-04-19T13:10:46Z"
        },
        {
          "author": "ysolanky",
          "body": "Hello @gabelul ! I have not been able to replicate your error. Can you please try running the following example and sharing the output?\n\n```python\nfrom agno.agent import Agent\nfrom agno.document.chunking.semantic import SemanticChunking\nfrom agno.knowledge.pdf_url import PDFUrlKnowledgeBase\nfrom agn",
          "created_at": "2025-04-24T00:14:45Z"
        }
      ]
    },
    {
      "issue_number": 2891,
      "title": "[Bug] AttributeError: 'NoneType' object has no attribute 'role' - agno/models/google/gemini.py\", line 707, in parse_provider_response_delta     if response_message.role is not None:",
      "body": "# Description\n\nAttributeError: 'NoneType' object has no attribute 'role'\n\nsite-packages/agno/models/google/gemini.py\", line 707, in parse_provider_response_delta\n    if response_message.role is not None:\n\nThis happen when agent is asked to return json wrapped with  ```json \nie; MUST wrap the visualization JSON in a ```json and ``` code block\",\n\n## Steps to Reproduce\nadd instruction for the agent to wrap json in  ```json and ``` code block\n\ni.e: MUST wrap the visualization JSON in a ```json and ``` code block\",\n\nstream\n\n## Agent Configuration (if applicable)\nProvide relevant agent configuration.\n\n## Expected Behavior\nno error return json wrapped in ```json and ```\n\n## Actual Behavior\ngot error: \n\nAttributeError: 'NoneType' object has no attribute 'role'\n\nsite-packages/agno/models/google/gemini.py\", line 707, in parse_provider_response_delta\n    if response_message.role is not None:\n",
      "state": "closed",
      "author": "samoritan",
      "author_type": "User",
      "created_at": "2025-04-19T17:53:42Z",
      "updated_at": "2025-05-13T15:12:05Z",
      "closed_at": "2025-05-13T15:12:03Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2891/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2891",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2891",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:44.523153",
      "comments": [
        {
          "author": "Ayush0054",
          "body": "Hey @samoritan,\nWe’ve released some fixes for Gemini. Could you please update to the latest version, try again, and let us know if you’re still encountering the error? \nthanks 🙌",
          "created_at": "2025-04-27T08:48:28Z"
        },
        {
          "author": "samoritan",
          "body": "Thanks for the update.\r\n\r\nI still have the same issue with the updated version. here is the error\r\nstack:\r\n\r\n File \"python3.13/site-packages/agno/agent/agent.py\", line 655, in _run\r\n    for model_response_chunk in\r\nself.model.response_stream(messages=run_messages.messages):\r\n\r\n~~~~~~~~~~~~~~~~~~~~~~",
          "created_at": "2025-04-27T19:48:07Z"
        },
        {
          "author": "Monikakusumanchi",
          "body": "even i too getting the same error?\n",
          "created_at": "2025-05-05T05:48:29Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @Monikakusumanchi @samoritan we recently released a fix for this. Could you confirm whether it is now fixed? ",
          "created_at": "2025-05-13T15:12:03Z"
        }
      ]
    },
    {
      "issue_number": 3149,
      "title": "[Bug] show_members_responses & show_tool_calls & stream_intermediate_steps for Team only shows team leader and not members' steps",
      "body": "# Description\nIf I run each agent individually all reasoning steps and tool calls are shown. However, if run in a team, only a team leader's calls & steps are shown, which means there is a lot of dead time waiting for responses.\n\n## Agent Configuration (if applicable)\nSee below\n\n## Screenshots or Logs (if applicable)\n\n<img width=\"574\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/5eeb9f88-bdd1-4aba-8f53-64d27e623276\" />\n\n## Steps to Reproduce\ndef load_team(user_id, project_id):\n  climate_team = Team(\n          name=\"...\",\n          description=\"... \"\n          \"...\",\n          mode=\"coordinate\",\n          model=Claude(\"claude-3-7-sonnet-20250219\", temperature=0.8),\n          members=agent_list,\n          instructions=[\n              \"...\"\n          ],\n          show_tool_calls=True,\n          markdown=True,\n          add_datetime_to_instructions=True,\n          enable_agentic_context=True,  # Allow the agent to maintain a shared context and send that to members.\n          share_member_interactions=True,  # Share all member responses with subsequent member requests.\n          show_members_responses=True,\n          get_member_information_tool=True,\n          monitoring=True,\n          session_id=session_id,\n          user_id=user_id,\n          session_state={\"sources\": [], \"user_id\": user_id},\n          add_state_in_messages=True,\n          storage=storage,\n          memory=memory,\n          read_team_history=True,\n          num_history_runs=5,\n          enable_session_summaries=True,\n      )\n  return climate_team\n\n return Agent(\n        name=\"Data Analyst\",\n        role=\"Data Analyst\",\n        model=OpenAIChat(id=\"gpt-4.1\"),\n        tools=[\n            list_all_files,\n            find_file_by_name,\n            find_file_by_id,\n            ReasoningTools(add_instructions=True),\n            get_date_time\n        ],\n        session_id=session_id,\n        user_id=user_id,\n        monitoring=True,\n        session_state={\"sources\": [], \"user_id\": user_id},\n        add_state_in_messages=True,\n        show_tool_calls=True,\n        markdown=True,\n        storage=storage,\n        memory=memory,\n        enable_agentic_memory=True,\n        read_chat_history=True,\n        add_history_to_messages=True,\n        instructions=\"\"\"...\"\"\"\n    )\n\nknowledge_agent = load_team(current_user.sub, str(project_id))[0]\n            stream = await knowledge_agent.arun(\n                question,\n                stream=True,\n                stream_intermediate_steps=True,\n            )",
      "state": "closed",
      "author": "ravishrawal",
      "author_type": "User",
      "created_at": "2025-05-10T13:27:56Z",
      "updated_at": "2025-05-13T15:04:44Z",
      "closed_at": "2025-05-13T15:04:42Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3149/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3149",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3149",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:44.726071",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "We have this as a feature request [here](https://github.com/orgs/agno-agi/projects/6/views/1?pane=issue&itemId=107590928&issue=agno-agi%7Cagno%7C2644)\n\nWe should be working on it soon!",
          "created_at": "2025-05-13T15:04:42Z"
        }
      ]
    },
    {
      "issue_number": 3093,
      "title": "[Feature Request] Support Langsmith",
      "body": "## Problem Description\nProvide a clear and concise explanation of the issue you're facing.\n**Example:** *\"I often find it frustrating when [...] because [...]”*\n\n## Proposed Solution\nExplain your ideal solution. How should this feature work?\nBe as detailed as possible to help us understand your vision.\n\n## Alternatives Considered\nHave you found any workarounds or alternative solutions?\nShare other approaches you've tried or thought about.\n\n## Additional context\nInclude any extra information that might be helpful, such as:\n- Screenshots\n- Examples of similar features elsewhere\n- Any relevant links or references\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[ ] Yes, I’d love to work on it!**\n**[ ] I’m open to collaborating but need guidance.**\n**[ ] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "monali7-d",
      "author_type": "User",
      "created_at": "2025-05-06T08:20:16Z",
      "updated_at": "2025-05-13T15:03:29Z",
      "closed_at": "2025-05-06T08:20:22Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3093/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3093",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3093",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:44.910389",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Released with [1.5.0](https://github.com/agno-agi/agno/releases/tag/v1.5.0)!",
          "created_at": "2025-05-13T15:03:28Z"
        }
      ]
    },
    {
      "issue_number": 3095,
      "title": "[Bug]Team mode coordinate,the \"Function transfer_task_to_member not found\" error occasionally occurs when using the aprint_response method.",
      "body": "As mentioned in the title, I was testing the example from https://docs.agno.com/teams/coordinate, but using the aprint_response method instead. In some random cases, the 'Function transfer_task_to_member not found' error appears, causing the program to fail.\n\nHere's my code:\n```python\nimport asyncio\n\nfrom dotenv import load_dotenv\nfrom agno.agent import Agent\nfrom agno.models.deepseek import DeepSeek\nfrom agno.team import Team\nfrom agno.tools.duckduckgo import DuckDuckGoTools\n\nload_dotenv(\"../.env\")\n\nmodel = DeepSeek(\n    temperature=0.01\n)\n\nresearcher = Agent(\n    name=\"Researcher\",\n    role=\"Expert at finding information\",\n    tools=[DuckDuckGoTools()],\n    model=model\n)\n\nwriter = Agent(\n    name=\"Writer\",\n    role=\"Expert at writing clear, engaging content\",\n    model=model\n)\n\ncontent_team = Team(\n    name=\"Content Team\",\n    mode=\"coordinate\",\n    members=[researcher, writer],\n    instructions=\"You are a team of researchers and writers that work together to create high-quality content.\",\n    model=model,\n    markdown=True,\n    debug_mode=True\n)\n\n\nasync def main():\n    await content_team.aprint_response(\n        \"Create a short article about quantum computing\",\n        stream=True\n    )\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\nThe reason I'm using aprint_response is that when I use print_response, I get the following error:\n```text\nTraceback (most recent call last):\n  File \"D:\\Documents\\PythonProject\\llms-practices-all\\venv\\Lib\\site-packages\\openai\\_base_client.py\", line 801, in\n__del__\n    if self.is_closed:\n       ^^^^^^^^^^^^^^\n  File \"D:\\Documents\\PythonProject\\llms-practices-all\\venv\\Lib\\site-packages\\httpx\\_client.py\", line 228, in is_closed\n    return self._state == ClientState.CLOSED\n           ^^^^^^^^^^^\nAttributeError: 'SyncHttpxClientWrapper' object has no attribute '_state'\n```",
      "state": "closed",
      "author": "qtalen",
      "author_type": "User",
      "created_at": "2025-05-06T10:02:29Z",
      "updated_at": "2025-05-13T14:58:08Z",
      "closed_at": "2025-05-12T16:57:10Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3095/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3095",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3095",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:45.091749",
      "comments": [
        {
          "author": "johnsxiong",
          "body": "the same",
          "created_at": "2025-05-06T12:56:37Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @qtalen @johnsxiong \nWhich version of `agno` are you running? We fixed related issues in a recent version. If this is happening on the latest version, I'll take a look!",
          "created_at": "2025-05-06T15:37:41Z"
        },
        {
          "author": "johnsxiong",
          "body": "> Hi [@qtalen](https://github.com/qtalen) [@johnsxiong](https://github.com/johnsxiong) Which version of `agno` are you running? We fixed related issues in a recent version. If this is happening on the latest version, I'll take a look!\n\nHi, @dirkbrnd \nIt works when run with PYTHONPATH, like `export P",
          "created_at": "2025-05-06T15:51:32Z"
        },
        {
          "author": "johnsxiong",
          "body": "> > Hi [@qtalen](https://github.com/qtalen) [@johnsxiong](https://github.com/johnsxiong) Which version of `agno` are you running? We fixed related issues in a recent version. If this is happening on the latest version, I'll take a look!\n> \n> Hi, [@dirkbrnd](https://github.com/dirkbrnd) It works when",
          "created_at": "2025-05-06T15:53:01Z"
        },
        {
          "author": "huang-sh",
          "body": "I also meet this error in latest version(1.4.5)\n```\nagno.exceptions.ModelProviderError: An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. (insufficient tool messages following tool_calls message)\n```",
          "created_at": "2025-05-06T21:19:02Z"
        }
      ]
    },
    {
      "issue_number": 3105,
      "title": "[Bug] An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. (insufficient tool messages following tool_calls message)",
      "body": "Hi agno team,\n\n\nI meet this error in latest version(1.4.5), it works well, but raise error sometimes.  Could you help to look it?\n```\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n  + Exception Group Traceback (most recent call last):\n  |   File \"/data20T/dev/scmcphub/decoupler-mcp/../test_session.py\", line 162, in <module>\n  |     asyncio.run(\n  |   File \"/data/software/micromamba/envs/gbi/lib/python3.10/asyncio/runners.py\", line 44, in run\n  |     return loop.run_until_complete(main)\n  |   File \"/data/software/micromamba/envs/gbi/lib/python3.10/asyncio/base_events.py\", line 641, in run_until_complete\n  |     return future.result()\n  |   File \"/data20T/dev/scmcphub/decoupler-mcp/../test_session.py\", line 79, in run_agent\n  |     async with client:\n  |   File \"/data/software/micromamba/envs/gbi/lib/python3.10/site-packages/fastmcp/client/client.py\", line 105, in __aexit__\n  |     await self._session_cm.__aexit__(exc_type, exc_val, exc_tb)\n  |   File \"/data/software/micromamba/envs/gbi/lib/python3.10/contextlib.py\", line 217, in __aexit__\n  |     await self.gen.athrow(typ, value, traceback)\n  |   File \"/data/software/micromamba/envs/gbi/lib/python3.10/site-packages/fastmcp/client/transports.py\", line 164, in connect_session\n  |     async with stdio_client(server_params) as transport:\n  |   File \"/data/software/micromamba/envs/gbi/lib/python3.10/contextlib.py\", line 217, in __aexit__\n  |     await self.gen.athrow(typ, value, traceback)\n  |   File \"/data/software/micromamba/envs/gbi/lib/python3.10/site-packages/mcp/client/stdio/__init__.py\", line 166, in stdio_client\n  |     async with (\n  |   File \"/data/software/micromamba/envs/gbi/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 772, in __aexit__\n  |     raise BaseExceptionGroup(\n  | exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Exception Group Traceback (most recent call last):\n    |   File \"/data/software/micromamba/envs/gbi/lib/python3.10/site-packages/mcp/client/stdio/__init__.py\", line 173, in stdio_client\n    |     yield read_stream, write_stream\n    |   File \"/data/software/micromamba/envs/gbi/lib/python3.10/site-packages/fastmcp/client/transports.py\", line 166, in connect_session\n    |     async with ClientSession(\n    |   File \"/data/software/micromamba/envs/gbi/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 772, in __aexit__\n    |     raise BaseExceptionGroup(\n    | exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n    +-+---------------- 1 ----------------\n      | Traceback (most recent call last):\n      |   File \"/data/software/micromamba/envs/gbi/lib/python3.10/site-packages/agno/models/openai/chat.py\", line 511, in ainvoke_stream\n      |     async_stream = await self.get_async_client().chat.completions.create(\n      |   File \"/data/software/micromamba/envs/gbi/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\", line 2000, in create\n      |     return await self._post(\n      |   File \"/data/software/micromamba/envs/gbi/lib/python3.10/site-packages/openai/_base_client.py\", line 1767, in post\n      |     return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n      |   File \"/data/software/micromamba/envs/gbi/lib/python3.10/site-packages/openai/_base_client.py\", line 1461, in request\n      |     return await self._request(\n      |   File \"/data/software/micromamba/envs/gbi/lib/python3.10/site-packages/openai/_base_client.py\", line 1562, in _request\n      |     raise self._make_status_error_from_response(err.response) from None\n      | openai.BadRequestError: Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. (insufficient tool messages following tool_calls message)\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n      | \n      | The above exception was the direct cause of the following exception:\n      | \n      | Traceback (most recent call last):\n      |   File \"/data/software/micromamba/envs/gbi/lib/python3.10/site-packages/fastmcp/client/transports.py\", line 170, in connect_session\n      |     yield session\n      |   File \"/data20T/dev/scmcphub/decoupler-mcp/../test_session.py\", line 155, in run_agent\n      |     await bio_team.aprint_response(message, stream=True)\n      |   File \"/data/software/micromamba/envs/gbi/lib/python3.10/site-packages/agno/team/team.py\", line 2901, in aprint_response\n      |     await self._aprint_response_stream(\n      |   File \"/data/software/micromamba/envs/gbi/lib/python3.10/site-packages/agno/team/team.py\", line 3300, in _aprint_response_stream\n      |     async for resp in stream_resp:\n      |   File \"/data/software/micromamba/envs/gbi/lib/python3.10/site-packages/agno/team/team.py\", line 1743, in _arun_stream\n      |     async for model_response_chunk in model_stream:\n      |   File \"/data/software/micromamba/envs/gbi/lib/python3.10/site-packages/agno/models/base.py\", line 615, in aresponse_stream\n      |     async for response in self.aprocess_response_stream(\n      |   File \"/data/software/micromamba/envs/gbi/lib/python3.10/site-packages/agno/models/base.py\", line 586, in aprocess_response_stream\n      |     async for response_delta in self.ainvoke_stream(messages=messages):  # type: ignore\n      |   File \"/data/software/micromamba/envs/gbi/lib/python3.10/site-packages/agno/models/openai/chat.py\", line 548, in ainvoke_stream\n      |     raise ModelProviderError(\n      | agno.exceptions.ModelProviderError: An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. (insufficient tool messages following tool_calls message)\n      +------------------------------------\n```\n\n\n```\nimport asyncio\nfrom pathlib import Path\nfrom textwrap import dedent\nfrom fastmcp import FastMCP, Client\nfrom agno.agent import Agent\nfrom agno.models.openai import OpenAIChat\nfrom agno.tools.mcp import MCPTools,MultiMCPTools\nfrom mcp import StdioServerParameters\n\nimport os \nos.environ[\"DEEPSEEK_API_KEY\"] = \"sk-**\"\n\n\n\nmodel = DeepSeek()\n\nmcp_config = {\n        \"mcpServers\": {\n            \"scanpy-mcp\": {\n                \"command\": \"scanpy-mcp\",\n                \"args\": [\"run\"],\n            }\n        }\n    }\n\nasync def create_sub_agent(name, role, tools, tool_prefix, mcp_session, model):\n    tool_names = [i.name for i in tools if i.name.startswith(tool_prefix)]\n    tool_deses = [i.description for i in tools if i.name in tool_names]\n    \n    # Define a template for each tool\n    tool_template = \"\"\"\n    <tool>\n    <name>{name}</name>\n    <description>{desc}</description>\n    </tool>\"\"\"\n    \n    # Generate XML using template and join\n    tools_xml = \"\\n\".join([\n        tool_template.format(name=name, desc=desc)\n        for name, desc in zip(tool_names, tool_deses)\n    ])\n    \n    description = f\"\"\"\n    You are a member of bioinformatics team. You have following tools:    \n    {tools_xml}\n    \"\"\"\n    description=\"\"\n    async with MCPTools(\n        session=mcp_session, include_tools=tool_names\n    ) as mcp_tools:\n        agent = Agent(\n            name=name,\n            role=role,\n            model=model,\n            tools=[mcp_tools],\n            description=description,\n            show_tool_calls=True,\n            debug_mode=True,\n            monitoring=True  \n        )\n        return agent\n\n\nasync def run_agent(message: str) -> None:\n    \"\"\"Run the filesystem agent with the given message.\"\"\"\n    client = Client(mcp_config)\n    async with client:\n        tools = await client.list_tools()\n      \n        io_agent = await create_sub_agent(\n            \"IO_Agent\", \"IO Module of Scanpy\", tools, \"io_\", client.session, model\n            )\n        pp_agent = await create_sub_agent(\n            \"PP_Agent\", \"Preprocess Module of Scanpy\", tools, \"pp_\", client.session, model\n            )\n        bio_team = Team(\n            name=\"Bioinformatics Team\",\n            #mode=\"route\",\n            model=model,\n            members=[io_agent, pp_agent],\n            show_tool_calls=True,\n            markdown=True,\n            description=\"\"\"\n                \"You are a Bioinformatics task router that directs task to the appropriate bioinformatics agent.\",\n            \"\"\",\n            enable_agentic_context=True,\n            share_member_interactions=True,\n            show_members_responses=True,\n            monitoring=True\n        )\n        await bio_team.aprint_response(message, stream=True)\n\n\n\nif __name__ == \"__main__\":\n    #  Basic example - exploring project license\n\n    asyncio.run(\n        run_agent(\n             \"read /data20T/dev/GBI-Eval/h5ad/GSE205013.h5ad, \"\n             \"then filter cells which gene number < 200; filter genes which express < 3 cells;\"      \n            )\n        )\n```",
      "state": "closed",
      "author": "huang-sh",
      "author_type": "User",
      "created_at": "2025-05-06T21:30:18Z",
      "updated_at": "2025-05-13T14:57:56Z",
      "closed_at": "2025-05-13T08:39:20Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3105/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3105",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3105",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:45.281591",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Hi @huang-sh \nThis is a bug we identified in teams. There is a [PR](https://github.com/agno-agi/agno/pull/3140) out to fix, will get it released asap!",
          "created_at": "2025-05-10T20:57:07Z"
        },
        {
          "author": "huang-sh",
          "body": "@dirkbrnd great, thanks for your work!",
          "created_at": "2025-05-11T20:31:06Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Released with [1.5.0](https://github.com/agno-agi/agno/releases/tag/v1.5.0)",
          "created_at": "2025-05-13T14:57:55Z"
        }
      ]
    },
    {
      "issue_number": 3066,
      "title": "[Feature Request] Add Native LangSmith Integration with Structured Tracing for LLMs, Tools, and Agent Steps",
      "body": "---\n\n###  Problem Description\n\nCurrently, LangSmith tracing with Agno only captures the **entire agent execution as a single trace**, without detailed **subtraces for LLM calls, tool use, intermediate steps, etc.** This makes it hard to debug or evaluate the performance of each part of the agent workflow (especially for multi-step chains or tool-based agents).\n\nI've manually instrumented LangSmith using the `@traceable` decorator like this:\n\n```python\nimport os\nfrom dotenv import load_dotenv, find_dotenv\nfrom langsmith import Client, traceable\nfrom agno.models.litellm import LiteLLM\nfrom agno.agent import Agent\n\nload_dotenv(find_dotenv())\n\nclient = Client(api_key=os.getenv(\"LANGSMITH_API_KEY\"))\n\nbase_llm = LiteLLM(\n    id=os.getenv(\"MODEL_ID\"),\n    name=\"LiteLLM\",\n)\nagent = Agent(model=base_llm, markdown=True)\n\n@traceable(name=\"AgnoAgentPrintRun\", client=client)\ndef run_and_print(prompt: str) -> str:\n    resp = agent.run(prompt)\n    print(resp.content)\n    return resp.content\n\nif __name__ == \"__main__\":\n    run_and_print(\"Share a 2 sentence horror story\")\n\n```\n\nBut this only shows **one big trace**, rather than structured nested traces (e.g., parent span = agent run, child spans = LLM call, tool call, parsing, etc.).\n\n---\n\n###  Proposed Solution\n\nAdd **first-class LangSmith integration into Agno**, similar to how LangChain and LiteLLM support it. This could include:\n\n* Automatically wrapping LLM calls inside Agno with `langsmith.traceable` spans.\n* Tracing tool usage, intermediate steps, and reasoning phases with child spans.\n* Optionally allow users to pass a `LangSmith Client` or enable tracing via environment variable.\n\nThis would provide **rich observability** for Agno agents with full step-by-step visibility in the LangSmith UI.\n\n---\n\n###  Alternatives Considered\n\n* Manually wrapping every internal LLM/tool call using LangSmith’s low-level `tracer.span()` context manager.\n  This is tedious and requires deep modification of Agno internals.\n\n---\n\n###  Additional Context\n\n* Example from LangChain’s tracing:\n\n  * Top-level agent call\n\n    * LLM subtrace\n    * Tool subtrace\n    * Tool return handling\n* Agno agent is being traced as a single block, missing this granularity.\n\n---\n\n###  Would you like to work on this?\n\n* [ ] Yes, I’d love to work on it!\n* [x] I’m open to collaborating but need guidance.\n* [ ] No, I’m just sharing the idea.\n\n---",
      "state": "closed",
      "author": "devv-shayan",
      "author_type": "User",
      "created_at": "2025-05-03T09:32:44Z",
      "updated_at": "2025-05-13T14:56:31Z",
      "closed_at": "2025-05-12T13:02:40Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3066/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3066",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3066",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:45.470622",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hey @devv-shayan \nThank you so much for reaching out and for your interest in Agno — we really appreciate your support!\nThis is a great question, and we’ll definitely add it to our community feature request list and bring it up for internal discussion. If it’s something we feel aligns well with our ",
          "created_at": "2025-05-05T08:21:54Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @devv-shayan This is being added via OpenInference! Should be out next week.",
          "created_at": "2025-05-10T21:47:03Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @devv-shayan \nThank you so much for reaching out and for your support for Agno — it truly means a lot to us. We’ve added your suggestion to our roadmap!  We are already progressing on it and should be out soon.",
          "created_at": "2025-05-12T13:02:40Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Released with [1.5.0](https://github.com/agno-agi/agno/releases/tag/v1.5.0)",
          "created_at": "2025-05-13T14:56:30Z"
        }
      ]
    },
    {
      "issue_number": 3162,
      "title": "MCP Multiples",
      "body": "Can multiple SSE MCPs be integrated? I see that only one MCP can be passed. Can you help me with this?",
      "state": "closed",
      "author": "cguilarte",
      "author_type": "User",
      "created_at": "2025-05-11T18:49:06Z",
      "updated_at": "2025-05-13T14:18:01Z",
      "closed_at": "2025-05-13T14:18:00Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3162/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3162",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3162",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:45.654948",
      "comments": [
        {
          "author": "manuhortet",
          "body": "Hey @cguilarte, yes, you can connect one agent to multiple MCP servers using SSE!\n\nFor this you can use our `MultiMCPTools` class, passing multiple values in `urls`:\n```python\nserver_url = \"http://localhost:3000\"\nserver_2_url = \"http://localhost:3001\"\n\n# Initialize MultiMCPTools with multiple server",
          "created_at": "2025-05-13T14:18:01Z"
        }
      ]
    },
    {
      "issue_number": 3178,
      "title": "[Bug] test",
      "body": "### Description\n\ntest\n\n### Steps to Reproduce\n\ntest\n\n### Agent Configuration (if applicable)\n\n### test\n\n### Expected Behavior\n\ntest\n\n### Actual Behavior\n\ntest\n\n### Screenshots or Logs (if applicable)\n\ntest\n\n### Environment\n\n```markdown\ntest\n```\n\n### Possible Solutions (optional)\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "state": "closed",
      "author": "monali7-d",
      "author_type": "User",
      "created_at": "2025-05-13T12:56:44Z",
      "updated_at": "2025-05-13T12:59:42Z",
      "closed_at": "2025-05-13T12:59:42Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3178/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3178",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3178",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:45.867084",
      "comments": [
        {
          "author": "linear[bot]",
          "body": "<p><a href=\"https://linear.app/agno/issue/SUPPORT-139/bug-test\">SUPPORT-139 [Bug] test</a></p>",
          "created_at": "2025-05-13T12:56:47Z"
        }
      ]
    },
    {
      "issue_number": 3001,
      "title": "[Bug] LiteLLM streaming parallel tool calling is not working properly with gemini-2.5-flash-preview",
      "body": "# Description\nWhen try to tool call in parallel with `gemini-2.5-flash-preview`.\n\n## Steps to Reproduce\n\n```python\nfrom agno.agent import Agent\nfrom agno.models.openrouter import OpenRouter\nfrom agno.models.litellm import LiteLLM\nfrom agno.tools.reasoning import ReasoningTools\nfrom agno.tools.exa import ExaTools\n\nagent = Agent(\n    # model=OpenRouter(id=\"google/gemini-2.5-flash-preview\"),\n    model=LiteLLM(id=\"openrouter/google/gemini-2.5-flash-preview\"),\n    tools=[\n        ReasoningTools(add_instructions=True),\n        ExaTools()\n    ],\n    instructions=[\n        \"Use tables to display data\",\n        \"ALWAYS CALL 2 or more tools in parallel\",\n    ],\n    markdown=True,\n    debug_mode=True\n)\nagent.print_response(\"Write a report on NVDA\", stream=True, show_full_reasoning=True, stream_intermediate_steps=True)\n```\n\nWhen using `OpenRouter` model, works without issue, when using `LiteLLM`, here is the result.\n\n```\nTraceback (most recent call last):\n  File \"/xx/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/streaming_handler.py\", line 1508, in __next__\n    chunk = next(self.completion_stream)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/xx/.venv/lib/python3.12/site-packages/litellm/llms/base_llm/base_model_iterator.py\", line 93, in __next__\n    return self._handle_string_chunk(str_line=str_line)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/xx/.venv/lib/python3.12/site-packages/litellm/llms/base_llm/base_model_iterator.py\", line 66, in _handle_string_chunk\n    return self.chunk_parser(chunk=stripped_json_chunk)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/xx/.venv/lib/python3.12/site-packages/litellm/llms/openrouter/chat/transformation.py\", line 133, in chunk_parser\n    raise e\n  File \"/xx/.venv/lib/python3.12/site-packages/litellm/llms/openrouter/chat/transformation.py\", line 109, in chunk_parser\n    raise OpenRouterException(\nlitellm.llms.openrouter.common_utils.OpenRouterException: Message: Provider returned error, Metadata: {'raw': '{\\n  \"error\": {\\n    \"code\": 400,\\n    \"message\": \"* GenerateContentRequest.contents[2].parts[0].function_response.name: Name cannot be empty.\\\\n\",\\n    \"status\": \"INVALID_ARGUMENT\"\\n  }\\n}\\n', 'provider_name': 'Google AI Studio'}, User ID: \n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/xx/app/ai/agent/debug.py\", line 32, in <module>\n    agent.print_response(\"Write a report on NVDA\", stream=True, show_full_reasoning=True, stream_intermediate_steps=True)\n  File \"/xx/.venv/lib/python3.12/site-packages/agno/agent/agent.py\", line 4512, in print_response\n    for resp in self.run(\n                ^^^^^^^^^\n  File \"/xx/.venv/lib/python3.12/site-packages/agno/agent/agent.py\", line 655, in _run\n    for model_response_chunk in self.model.response_stream(messages=run_messages.messages):\n                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/xx/.venv/lib/python3.12/site-packages/agno/models/base.py\", line 520, in response_stream\n    yield from self.process_response_stream(\n  File \"/xx/.venv/lib/python3.12/site-packages/agno/models/base.py\", line 492, in process_response_stream\n    for response_delta in self.invoke_stream(messages=messages):\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/xx/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/streaming_handler.py\", line 1620, in __next__\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/xx/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2214, in exception_type\n    raise e\n  File \"/xx/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2077, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenrouterException - Message: Provider returned error, Metadata: {'raw': '{\\n  \"error\": {\\n    \"code\": 400,\\n    \"message\": \"* GenerateContentRequest.contents[2].parts[0].function_response.name: Name cannot be empty.\\\\n\",\\n    \"status\": \"INVALID_ARGUMENT\"\\n  }\\n}\\n', 'provider_name': 'Google AI Studio'}, User ID: \n\n\n```\n\n## Environment\nagno                      1.4.2\nlitellm                   1.67.2\npython                    3.12.9\nsystem                    macOS\n\n",
      "state": "closed",
      "author": "BrikerMan",
      "author_type": "User",
      "created_at": "2025-04-27T13:33:53Z",
      "updated_at": "2025-05-13T09:40:43Z",
      "closed_at": "2025-05-13T09:40:43Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3001/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3001",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3001",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:46.081814",
      "comments": [
        {
          "author": "kausmeows",
          "body": "@BrikerMan a few things i want to confirm-\n- model=OpenRouter(id=\"google/gemini-2.5-flash-preview\") are you sure this worked? Because the OpenRouter model class only supports `OpenAILike` models and gemini does not follow the openai model spec\n<img width=\"690\" alt=\"Image\" src=\"https://github.com/use",
          "created_at": "2025-04-28T07:00:16Z"
        },
        {
          "author": "BrikerMan",
          "body": "@kausmeows Yes, because OpenRouter mapped all input/output to standard OpenAI style, so it works.\n\nFor now what I run into is, when using `OpenRouter` class\n- ✅ Streaming Single Tool Call\n- ✅ Streaming Parallel Tool Call\n\nWith `LiteLLM`,\n- ✅ Streaming Single Tool Call\n- ❌ Streaming Parallel Tool Cal",
          "created_at": "2025-04-28T08:12:05Z"
        },
        {
          "author": "kausmeows",
          "body": "@BrikerMan see here in your above litellm openrouter gemini output, this type of response is not in the openai spec and since. This is not being handled by either litellm or openrouter \n```\n \"message\": \"* GenerateContentRequest.contents[2].parts[0].function_response.name: Name \n```",
          "created_at": "2025-04-28T09:04:41Z"
        }
      ]
    },
    {
      "issue_number": 3156,
      "title": "[Feature Request] Need addition tool info in `RunEvent.tool_call_started` and `RunEvent.tool_call_completed` events",
      "body": "## Problem Description\nCurrently the tool call started / completed events look like this\n\n```\n{\n  \"content\": \"Some response from tool call as text\",\n  \"tool_call_id\": \"29664839-aeb0-4fed-91b5-074d1d5c3af4\",\n  \"tool_name\": \"google_search\",\n  \"tool_args\": {\n    \"query\": \"latest news about AI models\"\n  },\n  \"tool_call_error\": false,\n  \"metrics\": {\n    \"input_tokens\": 0,\n    \"output_tokens\": 0,\n    \"total_tokens\": 0,\n    \"audio_tokens\": 0,\n    \"input_audio_tokens\": 0,\n    \"output_audio_tokens\": 0,\n    \"cached_tokens\": 0,\n    \"reasoning_tokens\": 0,\n    \"prompt_tokens\": 0,\n    \"completion_tokens\": 0,\n    \"prompt_tokens_details\": null,\n    \"completion_tokens_details\": null,\n    \"additional_metrics\": null,\n    \"time\": 0.3089268329786137,\n    \"time_to_first_token\": null,\n    \"timer\": null\n  },\n  \"created_at\": 1746913738\n}\n```\n\nCan we have few more items added to this which would be helpful to show tool call details in UI.\nItems like:\n- Tool call display name -- Human readable tool call name\n- Tool call short description -- Human readable one liner to tell what the tool do\n- Description for each arg -- Human readable one liner description of each arg\n\n----\n\nAlso, is it possible to get tool call response (content key) as human readable markdown, right now it is raw response from tool ? not super important, but good if it is configurable and can be provided out of box. Anyway, this can be implemented in app, after capturing the tool call completed event.",
      "state": "closed",
      "author": "gauravdhiman",
      "author_type": "User",
      "created_at": "2025-05-10T22:07:41Z",
      "updated_at": "2025-05-13T09:08:31Z",
      "closed_at": "2025-05-13T09:08:30Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3156/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3156",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3156",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:46.300026",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hey @gauravdhiman \n\nThank you so much for reaching out and for your support for Agno — it truly means a lot to us. We’ve added your suggestion to our roadmap! Since Agno is open source, you’re more than welcome to take a stab at it yourself — and we’d be more than happy to support you along the way.",
          "created_at": "2025-05-13T09:08:30Z"
        }
      ]
    },
    {
      "issue_number": 3158,
      "title": "[Feature Request] Support for dotprompt",
      "body": "## Problem Description\nI just came across [dotprompt](https://github.com/google/dotprompt) in a [blog post](https://levelup.gitconnected.com/im-automating-my-job-as-a-google-engineer-with-a-custom-built-deep-research-system-here-s-how-to-75d610eea853)\n\nI like this idea a lot it would allow me to configure a multi-agent system and then specialize it for different purposes without having to refactor my code, I could just pass it different prompt files to configure it for different applications.\n\nI think this would be really easy to implement basic support for dotprompt.  I am going to start using dotprompt by writing a helper function to load the prompt file and pass it to the args of the agent.\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[ ] Yes, I’d love to work on it!**\n**[X] I’m open to collaborating.**\n**[ ] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "gwbischof",
      "author_type": "User",
      "created_at": "2025-05-11T04:25:25Z",
      "updated_at": "2025-05-13T09:07:02Z",
      "closed_at": "2025-05-13T09:07:01Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3158/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3158",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3158",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:46.493286",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hey @gwbischof \nThank you so much for reaching out and for your support for Agno — it truly means a lot to us. We’ve added your suggestion to our roadmap! Since Agno is open source, you’re more than welcome to take a stab at it yourself — and we’d be more than happy to support you along the way.\n\nLo",
          "created_at": "2025-05-13T09:07:01Z"
        }
      ]
    },
    {
      "issue_number": 3143,
      "title": "[Feature Request] Streamable HTTP transport support in MCPTools",
      "body": "## Problem Description\n`MCPTools` still ships only **STDIO** / **SSE**, it needs to also support **STREAMABLE-HTTP**.  \nModern hosts (Cloudflare Workers, Lambda, etc.) throttle long-lived SSE; agents can’t stream reliably.  \nThe **Python SDK** already merged Streamable HTTP (`src/mcp/transports/streamable_http.py`) in PR [#641](https://github.com/modelcontextprotocol/python-sdk/pull/641).\n\n## Proposed Solution\nAllow `transport=\"streamable-http\"` in `MCPTools(...)`, exposing the same params as the SDK for drop-in parity, with `mcp.client.streamable_http import streamablehttp_client` ([permalink](https://github.com/modelcontextprotocol/python-sdk/blob/ed25167fa5d715733437996682e20c24470e8177/src/mcp/client/streamable_http.py#L411C11-L411C32)).\n\n## Alternatives Considered\nNo alternatives observed - just keeping up with mcp development.\n\n## Additional context\n* **Spec** – Streamable HTTP is part of MCP spec 2025-03-26 ([changelog](https://github.com/modelcontextprotocol/modelcontextprotocol/blob/7f1b9e5a683acdaf574dc4e565763db75c70c57a/docs/specification/2025-03-26/changelog.mdx#L14))\n* **Reference impl & PR** – python-sdk PR [#641](https://github.com/modelcontextprotocol/python-sdk/pull/641). (“Streamable HTTP – improve usability, auth”).\n\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[X] Yes, I’d love to work on it!**\n**[ ] I’m open to collaborating but need guidance.**\n**[ ] No, I’m just sharing the idea.**\n\n**Note:** I’ve already started implementation on branch `feat/streamable-http` on my fork.  \nI’ll self-assign this issue and open a **draft pull request** - I'll try on this weekend.\n",
      "state": "closed",
      "author": "kkpalczewski",
      "author_type": "User",
      "created_at": "2025-05-09T17:18:17Z",
      "updated_at": "2025-05-13T08:42:30Z",
      "closed_at": "2025-05-13T08:42:29Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3143/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3143",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3143",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:46.688554",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "We are working on this! Should be out this week",
          "created_at": "2025-05-11T10:32:34Z"
        },
        {
          "author": "kkpalczewski",
          "body": "Ahh I've already rolled the change into https://github.com/agno-agi/agno/pull/3159 - hope you'll find it useful",
          "created_at": "2025-05-11T13:41:10Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @kkpalczewski Thank you very much for your contribution.\nWe will review the PR as soon as possible",
          "created_at": "2025-05-13T08:42:29Z"
        }
      ]
    },
    {
      "issue_number": 2690,
      "title": "Encoding Support for Emojis in save_response_to_file Method for Makrdown",
      "body": "https://github.com/agno-agi/agno/blame/62ae18304c4d74375df273478fb0beff04e2a718/libs/agno/agno/agent/agent.py#L2877\n\nHi Team,\n\nFirst, I want to express my appreciation for your excellent library—I've been using it extensively in my product development, and it's been a great help!\n\nHowever, I’ve encountered an issue when saving responses in markdown format that contain emojis. The file doesn't get saved due to an encoding issue when using the save_response_to_file method.\n\nHere’s the code I am using:\n\n```\nresearch_scholar = Agent(\n    model=OpenAILike(id=\"gpt-4o\", base_url='http://localhost:1234/v1' ,api_key='lm'),\n    save_response_to_file=\"tmp/{message}.md\",\n    instructions= \"\"\"Write response using emojis \"\"\",\n    stream=True,\n    markdown=True\n)\n```\n\nThe issue seems to stem from the encoding used when writing the response content to the file. The problem was resolved on my end when I modified this line: `fn_path.write_text(self.run_response.content)` to `fn_path.write_text(self.run_response.content, encoding=\"utf-8\")`\n\n\nAfter adding UTF-8 encoding, the emojis were saved correctly. I would like to suggest that you consider providing built-in support for encoding options in the save_response_to_file method, as this would resolve the issue for all users who deal with non-ASCII characters such as emojis.\n\nThank you for your consideration, and I look forward to any updates or fixes to address this\n\n\nNote: Also let me know in case you guys want me to raise the pull request with this fix, though this is small. \n",
      "state": "closed",
      "author": "statisticalplumber",
      "author_type": "User",
      "created_at": "2025-04-05T14:04:17Z",
      "updated_at": "2025-05-13T08:39:09Z",
      "closed_at": "2025-05-13T08:39:09Z",
      "labels": [
        "stale"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2690/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "Ayush0054"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2690",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2690",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:46.874365",
      "comments": [
        {
          "author": "Ayush0054",
          "body": "Hey @statisticalplumber,\nThanks for pointing out this issue! We’d really appreciate it if you could raise a PR with the fix — we’ll test it and get it merged.\nThanks again! 🙌\n",
          "created_at": "2025-04-11T06:12:42Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-05-12T00:36:12Z"
        }
      ]
    },
    {
      "issue_number": 3161,
      "title": "Display token usage metrics at the end of the stream",
      "body": "I want to migrate from Langchain to Agno, because I find things so easy to implement interesting. Now, to make that change, I want to know if I can get the amount of tokens used and other data at the end of the stream.",
      "state": "closed",
      "author": "cguilarte",
      "author_type": "User",
      "created_at": "2025-05-11T18:18:28Z",
      "updated_at": "2025-05-13T08:22:37Z",
      "closed_at": "2025-05-13T08:22:37Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3161/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3161",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3161",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:47.134310",
      "comments": [
        {
          "author": "kausmeows",
          "body": "Hi @cguilarte you can, see here-\n\n![Image](https://github.com/user-attachments/assets/fc99b556-c62b-4eb4-98a9-65ad44320c9f)\n\nAlso here's an example cookbook- https://github.com/agno-agi/agno/blob/main/cookbook/models/openai/chat/metrics.py\n",
          "created_at": "2025-05-12T06:43:39Z"
        },
        {
          "author": "cguilarte",
          "body": "thank you @kausmeows ",
          "created_at": "2025-05-12T13:38:53Z"
        }
      ]
    },
    {
      "issue_number": 2789,
      "title": "[Bug]",
      "body": "issue with using memory import v2 in the 1.2.16 package, does not seem to work.",
      "state": "closed",
      "author": "ahmadkhan100",
      "author_type": "User",
      "created_at": "2025-04-12T08:56:18Z",
      "updated_at": "2025-05-13T08:17:50Z",
      "closed_at": "2025-05-13T08:17:50Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2789/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2789",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2789",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:47.374735",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Hi @ahmadkhan100 \nCan you provide an example? We have not yet released Memory v2.",
          "created_at": "2025-04-12T11:57:07Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 30 days of inactivity.",
          "created_at": "2025-05-13T00:34:14Z"
        }
      ]
    },
    {
      "issue_number": 3033,
      "title": "[Feature Request] Replace Markdown Issue Templates with YAML Forms",
      "body": "## Problem Description\n\nI find that the current Markdown-based issue templates (`bug_report.md`, `feature_request.md`) lack the structure and guidance offered by GitHub's newer **YAML Issue Forms**. This can lead to contributors submitting issues that are missing key information or are formatted inconsistently, making it harder for maintainers to quickly understand and act on them.\n\n---\n\n## Proposed Solution\n\nMy ideal solution is to **replace the existing Markdown templates with YAML Issue Forms**. This involves:\n\n- Creating `bug-report.yml` with specific fields (e.g., *Description*, *Steps to Reproduce*, *Environment*, etc.) using elements like `textarea`, `input`, and `markdown` for clear guidance and structure.\n- Creating `feature-request.yml` similarly, with fields like *Problem Description*, *Proposed Solution*, and *Alternatives*.\n- Adding `config.yml` to disable blank issues and guide users towards the new forms.\n- Deleting the old `bug_report.md` and `feature_request.md` files.\n\nThis will provide a more guided and structured experience for users submitting issues, ensuring necessary details are captured consistently.\n\n---\n\n## Alternatives Considered\n\nThe main alternative is to keep the existing Markdown templates. However, this means missing out on the benefits of structured input fields, required field validation, and the overall improved user experience that YAML Issue Forms provide.\n\n---\n\n## Additional Context\n\n- This change aligns with current GitHub best practices for managing issue templates.\n- It will help maintainers by ensuring more complete and consistently formatted bug reports and feature requests.\n- The implementation for this proposal has already been completed on the `feature/issue-forms` branch.\n\n---\n\n## Would You Like to Work on This?\n\n- [X] Yes, I’d love to work on it! (The changes are already implemented on the `feature/issue-forms` branch.)\n",
      "state": "closed",
      "author": "aryan-dani",
      "author_type": "User",
      "created_at": "2025-04-30T12:40:43Z",
      "updated_at": "2025-05-12T16:31:48Z",
      "closed_at": "2025-05-12T13:01:37Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3033/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3033",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3033",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:47.616616",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hey @aryan-dani \nThank you for your contribution. We have implemented it and it will be released soon.",
          "created_at": "2025-05-12T13:01:37Z"
        },
        {
          "author": "aryan-dani",
          "body": "Thank you so much! Glad I could contribute.",
          "created_at": "2025-05-12T16:31:47Z"
        }
      ]
    },
    {
      "issue_number": 3101,
      "title": "[Feature Request] Graph databases, or instructions on how to overload knowledgebase",
      "body": "## Problem Description\nI want graph database agent knowledge because the tradition rag approach is inefficient.\n\n## Proposed Solution\nAdd instructions on how to overload knowledgebase to support graphrag. Currently the knowledge base only accepts vector dbs as storage.\n\n## Alternatives Considered\nWe could add context to the agent by first searching memory, but sometimes that context is unnecessary, so this would only waste tokens.\n\n## Additional context\nI looked at the mem0 integration (https://github.com/agno-agi/agno/blob/0ec58b81c0eb827c505ab211ab75aadf4f9a38e2/cookbook/agent_concepts/memory/08_mem0_memory.py) and it just adds context to the agent.\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[ ] Yes, I’d love to work on it!**\n**[ ] I’m open to collaborating but need guidance.**\n**[ x] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "freddyholms",
      "author_type": "User",
      "created_at": "2025-05-06T17:11:56Z",
      "updated_at": "2025-05-12T13:30:30Z",
      "closed_at": "2025-05-12T13:30:29Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3101/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3101",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3101",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:47.905399",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hey @freddyholms \n\nThank you so much for reaching out and for your support for Agno — it truly means a lot to us. We’ve added your suggestion to our roadmap! Since Agno is open source, you’re more than welcome to take a stab at it yourself — and we’d be more than happy to support you along the way.\n",
          "created_at": "2025-05-12T13:30:29Z"
        }
      ]
    },
    {
      "issue_number": 3108,
      "title": "[Feature Request] audio streaming agent",
      "body": "hello, how we can design streaming agent which accept audio from microphone and out audio?\ni mean real time audio agent, like openai live api.",
      "state": "closed",
      "author": "imrankh46",
      "author_type": "User",
      "created_at": "2025-05-07T04:48:25Z",
      "updated_at": "2025-05-12T13:30:13Z",
      "closed_at": "2025-05-12T13:30:12Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3108/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3108",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3108",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:48.074540",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @imrankh46 ! Currently, we do not support the OpenAI realtime API. Although we do plan on extending support for it. ",
          "created_at": "2025-05-07T19:53:57Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @imrankh46  😊\n\nThank you so much for reaching out and for your support for Agno — it truly means a lot to us. We’ve added your suggestion to our roadmap! \nLooking forward to building together!",
          "created_at": "2025-05-12T13:30:12Z"
        }
      ]
    },
    {
      "issue_number": 3124,
      "title": "[Feature Request] LightRAG with Agentic RAG will be powerful and boost Agentic capabilities",
      "body": "## Problem Description\nI feel Agentic RAG is not able to maintain proper relationships across multiple documents + if document is large, extracting too much without context never give good results. \n\n## Proposed Solution\nThis is why GraphRAG was introduced, however LightRAG had better results + was faster. \nAgno as of now has no graphRAG support, so I am requesting LightRAG or any other GraphRAG related support in Agno.\nhttps://github.com/HKUDS/LightRAG\n\n## Alternatives Considered\nReal time Knowledge Graph is also a powerful technique we should look into:\nhttps://github.com/getzep/graphiti\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n** Yes, but I don't get much time, so I'll try to help when I can if a PR is open for it **",
      "state": "closed",
      "author": "alaap001",
      "author_type": "User",
      "created_at": "2025-05-08T10:42:13Z",
      "updated_at": "2025-05-12T13:29:34Z",
      "closed_at": "2025-05-12T13:29:34Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3124/reactions",
        "total_count": 5,
        "+1": 5,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3124",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3124",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:48.267277",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hey @alaap001 \n\nThank you so much for reaching out and for your support for Agno — it truly means a lot to us. We’ve added your suggestion to our roadmap! Since Agno is open source, you’re more than welcome to take a stab at it yourself — and we’d be more than happy to support you along the way.\n\nLo",
          "created_at": "2025-05-12T13:29:34Z"
        }
      ]
    },
    {
      "issue_number": 3031,
      "title": "Add workflow to enforce PR title and description standards",
      "body": "## Problem Description\nI often find it frustrating when reviewing pull requests that have vague titles like \"updates\" or \"fixed stuff\", or when PRs don't clearly link to the issue they are addressing. This makes the commit history harder to scan and understand, and it complicates tracking which problems are being solved by which contributions, especially as the project grows. Manually reminding contributors about formatting and linking issues takes up valuable reviewer time.\n\n## Proposed Solution\nImplement an automated check using a GitHub Actions workflow (`.github/workflows/pr-lint.yml`) that runs on every pull request event (opened, edited, synchronize). This workflow enforces two key standards:\n\n1. **PR Title Format:** Ensures the pull request title starts with a valid type tag enclosed in square brackets, followed by a space and a concise subject.  \n   Example: `[feat] Add new login endpoint`  \n   Valid tags include: `[feat]`, `[fix]`, `[docs]`, `[test]`, `[refactor]`, `[build]`, `[ci]`, `[chore]`, `[perf]`, `[style]`, `[revert]`.\n\n2. **Linked Issue:** Verifies that the pull request description includes a reference to a tracked issue using keywords like `fixes #<issue_number>`, `closes #<issue_number>`, or `resolves #<issue_number>`.\n\nIf either check fails, the workflow will fail and provide clear instructions to the contributor on what needs to be corrected before the PR can be merged.\n\n## Alternatives Considered\nThe primary alternative is relying on manual enforcement by reviewers or maintainers. However, this is time-consuming, error-prone, and doesn't scale well as the project grows. Automating the check ensures consistent adherence to standards and allows reviewers to focus on the code itself rather than administrative details.\n\n## Additional context\nThe contribution guidelines in `CONTRIBUTING.md` have been updated to reflect these new requirements. They provide clear instructions for contributors and link directly to the workflow file to ensure transparency and understanding.\n\n## Would you like to work on this?\n**[X] Yes, I’d love to work on it! (In fact, the workflow and documentation updates have already been implemented.)**\n**[ ] I’m open to collaborating but need guidance.**\n**[ ] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "aryan-dani",
      "author_type": "User",
      "created_at": "2025-04-30T09:40:03Z",
      "updated_at": "2025-05-12T13:01:18Z",
      "closed_at": "2025-05-12T13:01:17Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3031/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "dirkbrnd"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3031",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3031",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:48.436999",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Thank you for the suggestion and the PR",
          "created_at": "2025-05-01T13:57:49Z"
        },
        {
          "author": "aryan-dani",
          "body": "> Thank you for the suggestion and the PR\n\nNo problem at all, glad I could help!",
          "created_at": "2025-05-04T12:00:18Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @aryan-dani \nThank you for your contribution. We have implemented it and it will be released soon.\n\n",
          "created_at": "2025-05-12T13:01:17Z"
        }
      ]
    },
    {
      "issue_number": 3050,
      "title": "[Bug]Function schema validation error with azure o3-mini model in Agno memory system",
      "body": "# Description\nWhen using newest model 'o3-mini' or o4 instead of 'gpt-4o-mini' with Agno's agent memory system, I'm encountering schema validation errors for the add_memory function. The error indicates that the schema is missing a required 'type' key in the 'topics' property.\n\n## Steps to Reproduce\n\n```\n# In single_agent.py\n# Changed fromgpt-4o-mini to o3-mini\n# self.model_id = 'gpt-4o-mini'\nself.model_id = 'o3-mini'\n\n# Agent initialization includes memory features\nself.agent = Agent(\n    # ...other parameters...\n    model=self.model,\n    user_id=self.user_id,\n    memory=self.memory,\n    enable_user_memories=True,\n    enable_session_summaries=True,\n    # ...other parameters...\n)\n```\n\n```\n# Create a custom httpx client\n    http_client = httpx.Client(timeout=30.0)\n    \n    # Create and return model\n    model = AzureOpenAI(\n        id=deployment_id,\n        api_key=api_key,\n        azure_deployment=deployment_id,\n        azure_endpoint=api_base,\n        api_version=api_version,\n        http_client=http_client,  # Pass custom client\n        timeout=30.0,\n        max_retries=2,\n    )\n```\n\n## Expected Behavior\nsave memory to my db\n\n## Actual Behavior\nERROR API status error from OpenAI API: Error code: 400 - {'error': {'message': \"Invalid schema for function 'add_memory': In context=('properties', 'topics'), schema must have a 'type' key.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n\nERROR:finoge_lib.llm.chat_service_agent:Error in stream_chat: Invalid schema for function 'add_memory': In context=('properties', 'topics'), schema must have a 'type' key.\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- Agno agno-1.4.3\n\n\n",
      "state": "closed",
      "author": "jy00295005",
      "author_type": "User",
      "created_at": "2025-05-01T14:04:10Z",
      "updated_at": "2025-05-10T21:48:12Z",
      "closed_at": "2025-05-10T21:48:11Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3050/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3050",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3050",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:50.409128",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Hi @jy00295005 , I am unable to replicate this issue. We have seen this before with older versions of OpenAI. Which version of the OpenAI library do you have running? ",
          "created_at": "2025-05-04T14:22:17Z"
        },
        {
          "author": "bksaini078",
          "body": "I am also getting similar issue with AzureOpenAI(o3-mini-2025-01-31) models. \n\n**Environment**\nagno- 1.4.5\nopenai-1.77.0",
          "created_at": "2025-05-06T20:38:49Z"
        },
        {
          "author": "kthilagarajan-agsft",
          "body": "I am also facing the same issue when using gpt-4.1. If I mention, gpt-4.1 with reasoning True, it is not happening. ",
          "created_at": "2025-05-07T07:09:25Z"
        },
        {
          "author": "jy00295005",
          "body": "> Hi [@jy00295005](https://github.com/jy00295005) , I am unable to replicate this issue. We have seen this before with older versions of OpenAI. Which version of the OpenAI library do you have running?\n\nthanks for your response. I'm using the latest OpenAI library, version 1.77. I've tried both agno",
          "created_at": "2025-05-07T07:58:27Z"
        },
        {
          "author": "dirkbrnd",
          "body": "This should be fixed in 1.4.6!\n\nPlease let me know and reopen if that is not the case.",
          "created_at": "2025-05-10T21:48:11Z"
        }
      ]
    },
    {
      "issue_number": 3126,
      "title": "`AgentKnowledge` ignores custom `chunking_strategy` and always uses `FixedSizeChunking` in `v1.4.5`",
      "body": "# Description\nIn version 1.4.5, the AgentKnowledge component is skipping the provided chunking_strategy and defaulting to FixedSizeChunking in all cases. This behavior was not present in earlier versions.\n\n## Steps to Reproduce\n```py\nfrom agno.agent import Agent\nfrom agno.document.chunking.semantic import SemanticChunking\nfrom agno.knowledge.pdf_url import PDFUrlKnowledgeBase\nfrom agno.vectordb.pgvector import PgVector\n\ndb_url = \"postgresql+psycopg://ai:ai@localhost:5532/ai\"\n\nknowledge_base = PDFUrlKnowledgeBase(\n    urls=[\"https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n    vector_db=PgVector(table_name=\"recipes_semantic_chunking\", db_url=db_url),\n    chunking_strategy=SemanticChunking(),\n)\nknowledge_base.load(recreate=False)  # Comment out after first run\n\nagent = Agent(\n    knowledge_base=knowledge_base,\n    search_knowledge=True,\n)\n\nagent.print_response(\"How to make Thai curry?\", markdown=True)\n```\n## What I Expected:\nThe PDF should be chunked using the SemanticChunking strategy.\n\n## What Actually Happened:\nDespite specifying SemanticChunking(), the system falls back to FixedSizeChunking and ignores the custom strategy.\n\n## Environment\n- OS: Ubuntu 22.04.5 LTS\n- Agno Version: 1.4.5\n- Additional Environment Details: Python 3.12.9\n\n## Additional Context\nThis issue only occurs in version 1.4.5. Downgrading to an earlier release restores the expected behavior.",
      "state": "closed",
      "author": "Khalid1G",
      "author_type": "User",
      "created_at": "2025-05-08T16:25:58Z",
      "updated_at": "2025-05-10T21:42:59Z",
      "closed_at": "2025-05-10T21:42:59Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3126/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3126",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3126",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:50.611657",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "@Khalid1G Apologies, this has been fixed in 1.4.6.",
          "created_at": "2025-05-10T21:42:54Z"
        }
      ]
    },
    {
      "issue_number": 2887,
      "title": "[Bug] Creating a TextKnowledgeBase fails with \"duplicate key value violates unique constraint\" error.",
      "body": "# Description\n\nCreating a TextKnowledgeBase **with a duplicate file name** fails with \"duplicate key value violates unique constraint\" error.\n\n## Steps to Reproduce\n\nI have a collection of ~2000 text files. A KB with this form:\n\n`TextKnowledgeBase(\n    path= f\"{docs_dir}\",\n    formats=[\".rst\"],\n    vector_db=PgVector(\n        table_name=\"godot_docs\",\n        db_url=\"postgresql://user:password@localhost:5432/phi_db\",\n    ),\n)`\n\nFails on creation, with:\n\nERROR    Error with batch starting at index 0: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"godot_docs_pkey\"           \n         DETAIL:  Key (id)=(class_line2d_4) already exists.         \n\n[stack.txt](https://github.com/user-attachments/files/19821148/stack.txt)\n\n## Expected behaviour\n\nFails gracefully, for example skips the file with a warning.\n\n## Environment\n- Agno Version: 1.3.4\n\n\n## Additional Context\n\nHappens with RecursiveChunking, FixedSizeChunking. Semantic and Document fail for other reasons.\n\nSeems similar to https://github.com/agno-agi/agno/issues/1588\nI attached a more detailed stack trace",
      "state": "closed",
      "author": "coljac",
      "author_type": "User",
      "created_at": "2025-04-19T12:35:26Z",
      "updated_at": "2025-05-08T15:38:22Z",
      "closed_at": "2025-05-08T15:38:21Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2887/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2887",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2887",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:50.776411",
      "comments": [
        {
          "author": "Ayush0054",
          "body": "Could you please clear the knowledge base, try again, and  share your agent config so we can replicate the issue?\n\nThanks! 🙌\n",
          "created_at": "2025-04-27T16:36:52Z"
        },
        {
          "author": "kausmeows",
          "body": "Hi @coljac, thanks for raising this. I've a PR out to fix this here- https://github.com/agno-agi/agno/pull/3104",
          "created_at": "2025-05-07T10:36:31Z"
        },
        {
          "author": "kausmeows",
          "body": "Hi @coljac the fix is merged and will be released soon today!",
          "created_at": "2025-05-08T15:38:21Z"
        }
      ]
    },
    {
      "issue_number": 2705,
      "title": "[Success Story] Compere: A Multi-Agent System on Agno Framework (Gemini 2.5 repo-level code generation)",
      "body": "I was using Gemini 2.5 in AI Studio, provided it with the required docs and the following task: \"Propose an implementation of Compere (I1) and its team using Agno\" 🥳\n\nPlease create a single document capturing the whole success story ✨\n\n[YouTube|NotebookLM](https://www.youtube.com/watch?v=lh0TlADJ3NQ)\n\n---\n\n## Problem Description\nThe Agno framework, specifically in the streaming path (response_stream in Model.base), is executing the tool call logic. When it encounters the async def get_response_draft_from_fizz tool, it calls the function but fails to await the resulting coroutine object. Instead of getting the string result after awaiting, it takes the coroutine object itself and tries to put it into the content field of the tool message. Since a coroutine object is neither a string nor a list, the Pydantic validation for the Message class fails.\n\nThis is likely an issue within the agno framework's handling of async def tools specifically during streaming responses. The non-streaming path might handle it correctly, but the streaming logic seems to miss the necessary await.\n\n## Proposed Solution\nThis requires a fix within the agno library itself to ensure that when a tool function defined with async def is executed during a streaming response, the returned coroutine is correctly awaited before its result is processed and packaged into the tool message.\n\n## Alternatives Considered\nAs a temporary workaround in your script (though it sacrifices the benefits of async IO for the tools), you could try making the tool functions synchronous:\n\nChange async def to def for all the tool functions (consult_fozz, delegate_to_qllickfizz, etc.).\n\nChange await persona.arun(...) to persona.run(...) inside each tool function.\n\nChange compere.cli_app(stream=True) - you might need to test if compere.run(...) (non-async, non-stream) works without error, or if compere.cli_app(stream=True) still functions correctly with sync tools.",
      "state": "closed",
      "author": "deniskropp",
      "author_type": "User",
      "created_at": "2025-04-06T19:17:38Z",
      "updated_at": "2025-05-08T14:38:26Z",
      "closed_at": "2025-05-08T14:38:25Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2705/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2705",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2705",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:50.967857",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-21T00:34:52Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @deniskropp \nI don't completely understand here, when the agent is run async (`await agent.arun`) we execute async functions correctly. If you run the agent sync (`agent.run()`) then async functions won't work.\nAre you saying it isn't properly supported on the CLI app? ",
          "created_at": "2025-04-23T10:18:37Z"
        },
        {
          "author": "deniskropp",
          "body": "Hi @dirkbrnd \n\nI cannot find the log file locally at the moment, but does the following link work for you?\n\nhttps://aistudio.google.com/app/prompts?state=%7B%22ids%22:%5B%221rd0OfCrsc3BZ5zvGOtskOf0YNzpjuWMW%22%5D,%22action%22:%22open%22,%22userId%22:%22116709578096200001986%22,%22resourceKeys%22:%7B",
          "created_at": "2025-05-04T02:04:55Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Ah I see. \nOk I think in that example the issue was that you were using `cli_app` and it would work with `acli_app`. We recently added this to the latest version of `agno`. Please let me know if that works for you.",
          "created_at": "2025-05-08T14:38:25Z"
        }
      ]
    },
    {
      "issue_number": 2026,
      "title": "Citations update in Anthropic API",
      "body": "https://docs.anthropic.com/en/docs/build-with-claude/citations",
      "state": "closed",
      "author": "rpvitrux",
      "author_type": "User",
      "created_at": "2025-02-05T21:05:48Z",
      "updated_at": "2025-05-07T12:15:42Z",
      "closed_at": "2025-05-07T12:15:42Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2026/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2026",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2026",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:51.171719",
      "comments": [
        {
          "author": "manthanguptaa",
          "body": "Hey @rpvitruvix! Is this a feature request to add support for citations in Claude?",
          "created_at": "2025-02-06T04:59:17Z"
        },
        {
          "author": "rpvitrux",
          "body": "Yes! Having citations would be super helpful, especially with prompt caching. Getting both working properly would be great since cache prompts have been acting up since the Agno update.",
          "created_at": "2025-02-06T13:14:34Z"
        },
        {
          "author": "monali7-d",
          "body": "Hi @rpvitruvix \n\nThank you for using Agno! I appreciate your suggestion and have added it to our community wishlist for internal discussion. We’ll review it and keep you updated on any developments.\n\nThanks again for your valuable input!",
          "created_at": "2025-02-07T04:14:07Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-02-27T00:30:27Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @rpvitruvix \nWe do now have citation support with claude! Please try this example to see it in action `cookbook/models/anthropic/pdf_input_local.py`",
          "created_at": "2025-04-23T10:46:50Z"
        }
      ]
    },
    {
      "issue_number": 2743,
      "title": "[Feature Request] Support for calling LLMs via API call(without any provider)",
      "body": "## Problem Description\nI have a llama model ruinning(without Ollama). Running APIs over it. Need to use this with Agno\n\n## Proposed Solution\nIdeally should be option to give url\n\n",
      "state": "closed",
      "author": "ban1989ban",
      "author_type": "User",
      "created_at": "2025-04-09T11:51:41Z",
      "updated_at": "2025-05-06T17:58:48Z",
      "closed_at": "2025-05-06T17:58:48Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2743/reactions",
        "total_count": 3,
        "+1": 3,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2743",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2743",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:51.430853",
      "comments": [
        {
          "author": "idankitgarg",
          "body": "This is much required for me too to try out my locally hosted model",
          "created_at": "2025-04-09T11:58:31Z"
        },
        {
          "author": "ysolanky",
          "body": "Hello @ban1989ban ! Can you please share details regarding how you are running the llama model? Is it following the OpenAI spec? If yes, you can just use OpenAILike model class with a custom base url. Checkout the docs [here](https://docs.agno.com/models/openai-like). If not then please do share how",
          "created_at": "2025-04-10T03:02:41Z"
        },
        {
          "author": "ban1989ban",
          "body": "So basically I am running llama-stack(meta-reference) \n\nSampe curl which is working:\n\n```\ncurl --location --request POST 'http://IP:PORT/v1/inference/chat-completion' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n    \"model_id\": \"meta-llama/Llama-3.1-8B-Instruct\",\n    \"messages\": [\n   ",
          "created_at": "2025-04-10T04:47:20Z"
        },
        {
          "author": "ysolanky",
          "body": "@ban1989ban thanks for sharing! What are you using as the engine for the model if not Ollama? ",
          "created_at": "2025-04-14T20:49:22Z"
        },
        {
          "author": "ysolanky",
          "body": "Closing due to inactivity",
          "created_at": "2025-05-06T17:58:48Z"
        }
      ]
    },
    {
      "issue_number": 2963,
      "title": "[Feature Request] Enhanced Structured Output Support in Agent Class",
      "body": "# Feature Request: Enhanced Structured Output Support in Agent Class\n\n## Problem Description\n\nCurrently, the `agno.Agent` class only accepts Pydantic `BaseModel` for the `response_model` parameter. This limits flexibility when working with dynamic output structures or when using simpler string-based formats.\n\nExample:\n```python\nresponse = client.models.generate_content(\n    model='gemini-2.0-flash-001',\n    contents='Give me information for the United States.',\n    config=types.GenerateContentConfig(\n        response_mime_type='application/json',\n        response_schema={\n            'required': [\n                'name',\n                'population',\n                'capital',\n                'continent',\n                'gdp',\n                'official_language',\n                'total_area_sq_mi',\n            ],\n            'properties': {\n                'name': {'type': 'STRING'},\n                'population': {'type': 'INTEGER'},\n                'capital': {'type': 'STRING'},\n                'continent': {'type': 'STRING'},\n                'gdp': {'type': 'INTEGER'},\n                'official_language': {'type': 'STRING'},\n                'total_area_sq_mi': {'type': 'INTEGER'},\n            },\n            'type': 'OBJECT',\n        },\n    ),\n)\n```\n\n## Proposed Solution\n\nEnhance the `response_model` parameter to accept either:\n- A Pydantic `BaseModel` type (current behavior)\n- A string template or identifier\n\nThis would allow the Agent to handle structured outputs in different ways depending on the type provided:\n- When given a `BaseModel`, use the existing Pydantic validation\n- When given a string option, implement an alternative processing approach\n\n## Benefits\n\n1. Provides more flexibility for runtime-defined output structures\n2. Reduces the need for defining static Pydantic models for every use case\n3. Simplifies working with dynamic structures derived from configuration\n\n## Implementation Considerations\n\nThe change would require adding type checking for the `response_model` parameter and implementing conditional logic based on the provided type. The existing functionality would remain unchanged for backward compatibility.\n\n### Would you like to work on this?\n\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[ ] Yes, I’d love to work on it!**\n**[x ] I’m open to collaborating but need guidance.**\n**[ ] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "diefergil",
      "author_type": "User",
      "created_at": "2025-04-24T10:22:37Z",
      "updated_at": "2025-05-06T17:57:33Z",
      "closed_at": "2025-05-06T17:57:33Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2963/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2963",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2963",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:56.601991",
      "comments": [
        {
          "author": "pritipsingh",
          "body": "Thanks for raising this, @diefergil !\n\nIt's a good point — we can definitely consider expanding support for other response formats in the future. At the moment, application/json seems to be mainly supported by Gemini, whereas using a Pydantic class offers a more consistent and standard approach acro",
          "created_at": "2025-05-02T04:49:26Z"
        }
      ]
    },
    {
      "issue_number": 2969,
      "title": "[Bug] AzureOpenAI models give \"401 Authorization Required\"",
      "body": "# Description\nUsing AzureOpenAI to define a simple Agent. Keep getting \"401 Authorization Required\" regardless of model or region.\n\nMy org's models are deployed in different regions. I think the current state of AzureOpenAI model in Agno doesn't support providing 'region' as a keyword argument, which is most likely causing the error.\n\n## Steps to Reproduce\n- Create an AzureOpenAI LLM for Agno models.\n\n## Agent Configuration (if applicable)\n```\nllm = AzureOpenAI(name = 'gpt-4o-global', api_key='<api_key>', api_version='<api_version>', azure_endpoint='<endpoint>')\n```\n\n\n## Expected Behavior\nLLM calls happening.\n\n## Actual Behavior\n401 - Authorization Error.\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- OS: (e.g. macOS, Windows 11)\n- Browser (if relevant): (e.g. Chrome 108, Firefox 107)\n- Agno Version: (e.g. v1.0.0)\n- External Dependency Versions: (e.g., yfinance 0.2.52)\n- Additional Environment Details: (e.g., Python 3.10)\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "chilicrabcakes",
      "author_type": "User",
      "created_at": "2025-04-24T14:08:39Z",
      "updated_at": "2025-05-06T17:55:41Z",
      "closed_at": "2025-05-06T17:55:39Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2969/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2969",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2969",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:56.777272",
      "comments": [
        {
          "author": "chilicrabcakes",
          "body": "Will work on a PR for this. Probably a very simple modification to add the 'region' argument in AzureOpenAI class.",
          "created_at": "2025-04-24T14:10:05Z"
        },
        {
          "author": "ysolanky",
          "body": "Hi @chilicrabcakes ! The official Azure OpenAI class does not support a reigon param:\n\n```python\nclass AsyncAzureOpenAI(BaseAzureClient[httpx.AsyncClient, AsyncStream[Any]], AsyncOpenAI):\n    @overload\n    def __init__(\n        self,\n        *,\n        azure_endpoint: str,\n        azure_deployment: ",
          "created_at": "2025-04-25T04:50:18Z"
        },
        {
          "author": "ysolanky",
          "body": "Closing due to inactivity. Please reopen if the issue persists ",
          "created_at": "2025-05-06T17:55:39Z"
        }
      ]
    },
    {
      "issue_number": 3073,
      "title": "[Bug] Agent worked with v1.4.3 but fails with v1.4.4",
      "body": "# Description\nBelow test agent worked with v1.4.3 but fails with `mcp` package error on v.1.4.4. Why `mcp` is mandatory requirement? Even if `mcp` is mandatory requirement, then it should be installed automatically with agno.\n\n### Test Agent code\n```\nfrom dotenv  import load_dotenv\nload_dotenv()\n\nfrom agno.agent import Agent\nfrom agno.models.openai import OpenAIChat\nfrom agno.models.google import Gemini\n# from agno.models.meta import Llama\nfrom agno.tools.googlesearch import GoogleSearchTools\nfrom agno.tools.yfinance import YFinanceTools\nfrom agno.tools.crawl4ai import Crawl4aiTools\nfrom agno.storage.sqlite import SqliteStorage\n\nagent_storage = SqliteStorage(\n    table_name=\"agent_sessions\",\n    db_file=\"tmp/persistent_memory.db\",\n)\n\nsample_agent = Agent(\n    name=\"agno_agent\",\n    description=\"You are a helpful assistant who can search web, crawl page contents and also search financial information using given tools to achieve the given user goal.\",\n    # model=OpenAIChat(id=\"gpt-4o-mini\"),\n    model=Gemini(id=\"gemini-2.5-flash-preview-04-17\"),  # or any other supported model\n    # model=Llama(id=\"Llama-4-Maverick-17B-128E-Instruct-FP8\"),\n    instructions=[\n        \"If user input is not sufficent, ask user relevant questions / clarifications\",\n        \"To search the web, use google search tool.\",\n        \"To crawl the pages use crawl4ai tools\",\n        \"To get financial information about companies, use YFinance tools\"\n    ],\n    storage=agent_storage,\n    tools=[\n        GoogleSearchTools(),\n        YFinanceTools(enable_all=True),\n        Crawl4aiTools(max_length=5000)\n    ],\n    stream_intermediate_steps=True,\n    add_datetime_to_instructions=True,\n    debug_mode=True\n)\n\nuser_prompt = \"whats the latest news about China\"\nfor res in sample_agent.run(user_prompt, stream=True):\n    print(f\"Response Type: {res.event}\")\n    print(f\"Tools: {res.tools}\")\n    # print(f\"Messages: {res.messages}\")\n```\n\n### Error\n```\nagno-copilotkit-integration/backend on  main [!] via 🐍 v3.12.4 (.venv-backend)\n❯ uv pip install -r requirements.txt\nUsing Python 3.12.4 environment at: .venv-backend\nResolved 145 packages in 276ms\nUninstalled 1 package in 40ms\nInstalled 1 package in 7ms\n - agno==1.4.3\n + agno==1.4.4\n\nagno-copilotkit-integration/backend on  main [!] via 🐍 v3.12.4 (.venv-backend)\n❯ python test.py\nTraceback (most recent call last):\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/agno-copilotkit-integration/backend/.venv-backend/lib/python3.12/site-packages/agno/utils/mcp.py\", line 7, in <module>\n    from mcp import ClientSession\nModuleNotFoundError: No module named 'mcp'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/agno-copilotkit-integration/backend/test.py\", line 4, in <module>\n    from agno.agent import Agent\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/agno-copilotkit-integration/backend/.venv-backend/lib/python3.12/site-packages/agno/agent/__init__.py\", line 1, in <module>\n    from agno.agent.agent import (\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/agno-copilotkit-integration/backend/.venv-backend/lib/python3.12/site-packages/agno/agent/agent.py\", line 43, in <module>\n    from agno.tools.mcp import MCPTools, MultiMCPTools\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/agno-copilotkit-integration/backend/.venv-backend/lib/python3.12/site-packages/agno/tools/mcp.py\", line 11, in <module>\n    from agno.utils.mcp import get_entrypoint_for_tool\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/agno-copilotkit-integration/backend/.venv-backend/lib/python3.12/site-packages/agno/utils/mcp.py\", line 11, in <module>\n    raise ImportError(\"`mcp` not installed. Please install using `pip install mcp`\")\nImportError: `mcp` not installed. Please install using `pip install mcp`\n```",
      "state": "closed",
      "author": "gauravdhiman",
      "author_type": "User",
      "created_at": "2025-05-04T08:46:37Z",
      "updated_at": "2025-05-06T15:39:08Z",
      "closed_at": "2025-05-06T15:39:08Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3073/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3073",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3073",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:56.961776",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Thanks for raising. I have pushed a fix, releasing asap.",
          "created_at": "2025-05-04T13:56:33Z"
        },
        {
          "author": "jesalg",
          "body": "+1",
          "created_at": "2025-05-04T16:54:09Z"
        },
        {
          "author": "tylertaewook",
          "body": "+1",
          "created_at": "2025-05-05T21:25:51Z"
        },
        {
          "author": "dirkbrnd",
          "body": "This has been fixed in 1.4.5. We apologise for the inconvenience. We are adding tests to avoid this kind of issue in future.",
          "created_at": "2025-05-06T15:39:08Z"
        }
      ]
    },
    {
      "issue_number": 3082,
      "title": "[Bug] Unable to use Team storage with Mongodb",
      "body": "# Description\nWhile hitting 2 queries with the same session ID gives an error : \n\n**Memory.__init__() got an unexpected keyword argument 'team_context'**\n\n## Steps to Reproduce\nI have used this cookbook example as well by changing the team mode to route\nhttps://docs.agno.com/examples/concepts/storage/team_storage/mongodb\n\n## Agent Configuration (if applicable)\nhn_researcher = Agent(\n    name=\"HackerNews Researcher\",\n    model=OpenAIChat(\"gpt-4o\"),\n    role=\"Gets top stories from hackernews.\",\n    tools=[HackerNewsTools()],\n)\n\nweb_searcher = Agent(\n    name=\"Web Searcher\",\n    model=OpenAIChat(\"gpt-4o\"),\n    role=\"Searches the web for information on a topic\",\n    tools=[DuckDuckGoTools()],\n    add_datetime_to_instructions=True,\n)\n\n\nhn_team = Team(\n    name=\"HackerNews Team\",\n    mode=\"route\",\n    model=OpenAIChat(\"gpt-4o\"),\n    members=[hn_researcher, web_searcher],\n    storage=MongoDbStorage(\n        collection_name=\"team_sessions\", db_url=db_url, db_name=\"agno_test\"\n    ),\n    instructions=[\n        \"First, search hackernews for what the user is asking about.\",\n        \"If user ask about web search then use this\",\n    ],\n    response_model=Article,\n    show_tool_calls=True,\n    markdown=True,\n    debug_mode=True,\n    show_members_responses=True,\n)\nhn_team.run(\"get top stories from hackernews\", session_id=\"1234\")\n\n\n## Actual Behavior\nGetting this error \nFile \"/Users/tusharleekha/PycharmProjects/PythonProject4/main.py\", line 63, in <module>\n    hn_team.run(\"get top stories from hackernews\", session_id=\"1234\")\n    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/tusharleekha/PycharmProjects/PythonProject4/.venv/lib/python3.13/site-packages/agno/team/team.py\", line 577, in run\n    self.read_from_storage(session_id=session_id)\n    ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/tusharleekha/PycharmProjects/PythonProject4/.venv/lib/python3.13/site-packages/agno/team/team.py\", line 5924, in read_from_storage\n    self.load_team_session(session=self.team_session)\n    ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/tusharleekha/PycharmProjects/PythonProject4/.venv/lib/python3.13/site-packages/agno/team/team.py\", line 6047, in load_team_session\n    self.memory = Memory(**self.memory)\n                  ~~~~~~^^^^^^^^^^^^^^^\nTypeError: Memory.__init__() got an unexpected keyword argument 'team_context'\n\n\n## Environment\n- OS: macOS\n- Agno Version: v1.4.4\n",
      "state": "closed",
      "author": "tusharleek",
      "author_type": "User",
      "created_at": "2025-05-05T07:45:59Z",
      "updated_at": "2025-05-06T15:38:32Z",
      "closed_at": "2025-05-06T15:38:31Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3082/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3082",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3082",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:57.140954",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "PR out to fix!",
          "created_at": "2025-05-05T12:58:15Z"
        },
        {
          "author": "dirkbrnd",
          "body": "This has been fixed in 1.4.5!",
          "created_at": "2025-05-06T15:38:31Z"
        }
      ]
    },
    {
      "issue_number": 3089,
      "title": "`MemoryV2` Messages are not stored in storage",
      "body": "# Description\nIf I have a team with `num_of_interactions_from_history` as any number larger than 3, ever subsequent call to the model will only have 3 messages. \n\nHere's a test I built to double check this:\n```\nimport os\nimport tempfile\nimport uuid\n\nimport pytest\n\nfrom agno.agent import Agent\nfrom agno.memory.v2.db.sqlite import SqliteMemoryDb\nfrom agno.memory.v2.memory import Memory\nfrom agno.models.anthropic.claude import Claude\nfrom agno.models.openai.chat import OpenAIChat\nfrom agno.storage.sqlite import SqliteStorage\nfrom agno.team.team import Team\n\n\n@pytest.fixture\ndef temp_storage_db_file():\n    \"\"\"Create a temporary SQLite database file for team storage testing.\"\"\"\n    with tempfile.NamedTemporaryFile(suffix=\".db\", delete=False) as temp_file:\n        db_path = temp_file.name\n\n    yield db_path\n\n    # Clean up the temporary file after the test\n    if os.path.exists(db_path):\n        os.unlink(db_path)\n\n\n@pytest.fixture\ndef temp_memory_db_file():\n    \"\"\"Create a temporary SQLite database file for memory testing.\"\"\"\n    with tempfile.NamedTemporaryFile(suffix=\".db\", delete=False) as temp_file:\n        db_path = temp_file.name\n\n    yield db_path\n\n    # Clean up the temporary file after the test\n    if os.path.exists(db_path):\n        os.unlink(db_path)\n\n\n@pytest.fixture\ndef team_storage(temp_storage_db_file):\n    \"\"\"Create a SQLite storage for team sessions.\"\"\"\n    # Use a unique table name for each test run\n    table_name = f\"team_sessions_{uuid.uuid4().hex[:8]}\"\n    storage = SqliteStorage(table_name=table_name, db_file=temp_storage_db_file, mode=\"team\")\n    storage.create()\n    return storage\n\n\n@pytest.fixture\ndef memory_db(temp_memory_db_file):\n    \"\"\"Create a SQLite memory database for testing.\"\"\"\n    db = SqliteMemoryDb(db_file=temp_memory_db_file)\n    db.create()\n    return db\n\n\n@pytest.fixture\ndef memory(memory_db):\n    \"\"\"Create a Memory instance for testing.\"\"\"\n    return Memory(model=Claude(id=\"claude-3-5-sonnet-20241022\"), db=memory_db)\n\n\n\n\n@pytest.fixture\ndef route_team(team_storage, memory):\n    \"\"\"Create a route team with storage and memory for testing.\"\"\"\n    return Team(\n        name=\"Route Team\",\n        mode=\"collaborate\",\n        model=OpenAIChat(id=\"gpt-4o-mini\"),\n        members=[],\n        storage=team_storage,\n        memory=memory,\n        enable_user_memories=True,\n        num_of_interactions_from_history=10,\n        num_history_runs=10,\n    )\n\n\n@pytest.mark.asyncio\nasync def test_run_history_persistence(route_team, team_storage, memory):\n    \"\"\"Test that all runs within a session are persisted in storage.\"\"\"\n    user_id = \"test_persistence_user@example.com\"\n    session_id = \"test_persistence_session\"\n    num_turns = 5\n\n    # Clear memory for this specific test case\n    memory.clear()\n\n    # Perform multiple turns\n    conversation_messages = [\n        \"What's the weather like today?\",\n        \"What about tomorrow?\",\n        \"Any recommendations for indoor activities?\",\n        \"Search for nearby museums.\",\n        \"Which one has the best reviews?\",\n    ]\n\n    assert len(conversation_messages) == num_turns\n\n    for i, msg in enumerate(conversation_messages):\n        print(f\"Turn {i+1}: {msg}\")\n        await route_team.arun(msg, user_id=user_id, session_id=session_id)\n        # Optional: Check memory state in RAM after each turn if needed for debugging\n        # print(f\"Runs in memory after turn {i+1}: {len(memory.runs.get(session_id, []))}\")\n\n    # Verify the stored session data after all turns\n    team_session = team_storage.read(session_id=session_id)\n\n\n    stored_memory_data = team_session.memory\n    assert stored_memory_data is not None, \"Memory data not found in stored session.\"\n    print(f\"Stored memory data: {stored_memory_data}\")\n    stored_runs = stored_memory_data[\"runs\"]\n    assert isinstance(stored_runs, list), \"Stored runs data is not a list.\"\n\n\n    first_user_message_content = stored_runs[0]['messages'][1]['content']\n    assert first_user_message_content == conversation_messages[0]\n```\n\nThis should pass but it fails and the \"first_user_message\" is always `Any recommendations for indoor activities?`\n\n## Additional Context\nDiscord link: https://discord.com/channels/965734768803192842/1369017040194502897\n",
      "state": "closed",
      "author": "DannyAziz",
      "author_type": "User",
      "created_at": "2025-05-05T20:33:21Z",
      "updated_at": "2025-05-06T15:38:14Z",
      "closed_at": "2025-05-06T15:38:13Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3089/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3089",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3089",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:57.309049",
      "comments": [
        {
          "author": "DannyAziz",
          "body": "Okay, it's an issue with the new v2 memory. I rewrote the test using the old `TeamMemory` and it seems to pass:\n```\nimport os\nimport tempfile\nimport uuid\n\nimport pytest\n\nfrom agno.agent import Agent\nfrom agno.memory.v2.db.sqlite import SqliteMemoryDb\nfrom agno.memory.v2.memory import Memory\nfrom agn",
          "created_at": "2025-05-05T20:43:51Z"
        },
        {
          "author": "DannyAziz",
          "body": "In my Discord thread I noted out that it seems like with `Memoryv2` that only the last 3 user messages were being saved in the storage provider",
          "created_at": "2025-05-05T20:44:38Z"
        },
        {
          "author": "chazo1994",
          "body": "I foud the error come from this part of code in team.py / agent.py\n`            elif isinstance(self.memory, Memory):\n                if \"runs\" in session.memory:\n                    try:\n                        if self.memory.runs is None:\n                            self.memory.runs = {}\n         ",
          "created_at": "2025-05-06T03:31:10Z"
        },
        {
          "author": "DannyAziz",
          "body": "@chazo1994 Thanks for pointing that out as the issue, I pushed a PR with a fix for that. Hopefully it gets merged soon",
          "created_at": "2025-05-06T13:53:57Z"
        },
        {
          "author": "dirkbrnd",
          "body": "We are fixing this! Thanks for raising!\n",
          "created_at": "2025-05-06T14:30:53Z"
        }
      ]
    },
    {
      "issue_number": 3076,
      "title": "[Bug]Error occurs while setting response_model and using mcp tools in a  agent instance with models from openrouter",
      "body": "# Description\n**Error occurs while setting response_model and using mcp tools in a  agent instance with models from openrouter**, the error is :   an error occurred during closing of asynchronous generator <async_generator object stdio_client at 0x000002BCE8F35A80>\nasyncgen: <async_generator object stdio_client at 0x000002BCE8F35A80>\n  + Exception Group Traceback (most recent call last):\n  |   File \"C:\\Users\\FLDJ\\Desktop\\ExploreEaseV0\\servers\\agent-server\\venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 772, in __aexit__\n  |     raise BaseExceptionGroup(\n  | BaseExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"C:\\Users\\FLDJ\\Desktop\\ExploreEaseV0\\servers\\agent-server\\venv\\Lib\\site-packages\\mcp\\client\\stdio\\__init__.py\", line 173, in stdio_client\n    |     yield read_stream, write_stream\n    | GeneratorExit\n    +------------------------------------\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\FLDJ\\Desktop\\ExploreEaseV0\\servers\\agent-server\\venv\\Lib\\site-packages\\mcp\\client\\stdio\\__init__.py\", line 166, in stdio_client\n    async with (\n  File \"C:\\Users\\FLDJ\\Desktop\\ExploreEaseV0\\servers\\agent-server\\venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 778, in __aexit__\n    if self.cancel_scope.__exit__(type(exc), exc, exc.__traceback__):\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\FLDJ\\Desktop\\ExploreEaseV0\\servers\\agent-server\\venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 457, in __exit__\n    raise RuntimeError(\nRuntimeError: Attempted to exit cancel scope in a different task than it was entered in\n  + Exception Group Traceback (most recent call last):\n  |   File \"C:\\Users\\FLDJ\\Desktop\\ExploreEaseV0\\servers\\agent-server\\agents\\location\\tool_use.py\", line 40, in <module>        \n  |     asyncio.run(run_agent(\"使用search_city_attractions工具查询杭州的热门景点信息并给我推荐三个景点\"))\n  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  |   File \"D:\\python3.11.9\\Lib\\asyncio\\runners.py\", line 190, in run\n  |     return runner.run(main)\n  |            ^^^^^^^^^^^^^^^^\n  |   File \"D:\\python3.11.9\\Lib\\asyncio\\runners.py\", line 118, in run\n  |     return self._loop.run_until_complete(task)\n  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  |   File \"D:\\python3.11.9\\Lib\\asyncio\\base_events.py\", line 654, in run_until_complete\n  |     return future.result()\n  |            ^^^^^^^^^^^^^^^\n  |   File \"C:\\Users\\FLDJ\\Desktop\\ExploreEaseV0\\servers\\agent-server\\agents\\location\\tool_use.py\", line 26, in run_agent       \n  |     async with MCPTools(mcp_cmd) as mcp_tools:\n  |   File \"C:\\Users\\FLDJ\\Desktop\\ExploreEaseV0\\servers\\agent-server\\venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 772, in __aexit__\n  |     raise BaseExceptionGroup(\n  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"C:\\Users\\FLDJ\\Desktop\\ExploreEaseV0\\servers\\agent-server\\venv\\Lib\\site-packages\\agno\\models\\openai\\chat.py\", line 379, in ainvoke\n    |     return await self.get_async_client().beta.chat.completions.parse(\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"C:\\Users\\FLDJ\\Desktop\\ExploreEaseV0\\servers\\agent-server\\venv\\Lib\\site-packages\\openai\\resources\\beta\\chat\\completions.py\", line 437, in parse\n    |     return await self._post(\n    |            ^^^^^^^^^^^^^^^^^\n    |   File \"C:\\Users\\FLDJ\\Desktop\\ExploreEaseV0\\servers\\agent-server\\venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1805, in post\n    |     return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"C:\\Users\\FLDJ\\Desktop\\ExploreEaseV0\\servers\\agent-server\\venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1495, in request\n    |     return await self._request(\n    |            ^^^^^^^^^^^^^^^^^^^^\n    |   File \"C:\\Users\\FLDJ\\Desktop\\ExploreEaseV0\\servers\\agent-server\\venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1602, in _request\n    |     return await self._process_response(\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"C:\\Users\\FLDJ\\Desktop\\ExploreEaseV0\\servers\\agent-server\\venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1699, in _process_response\n    |     return await api_response.parse()\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"C:\\Users\\FLDJ\\Desktop\\ExploreEaseV0\\servers\\agent-server\\venv\\Lib\\site-packages\\openai\\_response.py\", line 432, in parse\n    |     parsed = self._options.post_parser(parsed)\n    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"C:\\Users\\FLDJ\\Desktop\\ExploreEaseV0\\servers\\agent-server\\venv\\Lib\\site-packages\\openai\\resources\\beta\\chat\\completions.py\", line 431, in parser\n    |     return _parse_chat_completion(\n    |            ^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"C:\\Users\\FLDJ\\Desktop\\ExploreEaseV0\\servers\\agent-server\\venv\\Lib\\site-packages\\openai\\lib\\_parsing\\_completions.py\", line 70, in parse_chat_completion\n    |     for choice in chat_completion.choices:\n    | TypeError: 'NoneType' object is not iterable\n    |\n    | The above exception was the direct cause of the following exception:\n    |\n    | Traceback (most recent call last):\n    |   File \"C:\\Users\\FLDJ\\Desktop\\ExploreEaseV0\\servers\\agent-server\\agents\\location\\tool_use.py\", line 37, in run_agent     \n    |     await agent.aprint_response(message, stream=True)\n    |   File \"C:\\Users\\FLDJ\\Desktop\\ExploreEaseV0\\servers\\agent-server\\venv\\Lib\\site-packages\\agno\\agent\\agent.py\", line 4840, in aprint_response\n    |     run_response = await self.arun(\n    |                    ^^^^^^^^^^^^^^^^\n    |   File \"C:\\Users\\FLDJ\\Desktop\\ExploreEaseV0\\servers\\agent-server\\venv\\Lib\\site-packages\\agno\\agent\\agent.py\", line 1658, in arun\n    |     raise last_exception\n    |   File \"C:\\Users\\FLDJ\\Desktop\\ExploreEaseV0\\servers\\agent-server\\venv\\Lib\\site-packages\\agno\\agent\\agent.py\", line 1562, in arun\n    |     run_response = await self._arun(\n    |                    ^^^^^^^^^^^^^^^^^\n    |   File \"C:\\Users\\FLDJ\\Desktop\\ExploreEaseV0\\servers\\agent-server\\venv\\Lib\\site-packages\\agno\\agent\\agent.py\", line 1339, in _arun\n    |     model_response = await self.model.aresponse(messages=run_messages.messages)\n    |                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"C:\\Users\\FLDJ\\Desktop\\ExploreEaseV0\\servers\\agent-server\\venv\\Lib\\site-packages\\agno\\models\\base.py\", line 250, in aresponse\n    |     assistant_message, has_tool_calls = await self._aprocess_model_response(\n    |                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"C:\\Users\\FLDJ\\Desktop\\ExploreEaseV0\\servers\\agent-server\\venv\\Lib\\site-packages\\agno\\models\\base.py\", line 375, in _aprocess_model_response\n    |     response = await self.ainvoke(messages=messages)\n    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"C:\\Users\\FLDJ\\Desktop\\ExploreEaseV0\\servers\\agent-server\\venv\\Lib\\site-packages\\agno\\models\\openai\\chat.py\", line 427, in ainvoke\n    |     raise ModelProviderError(message=str(e), model_name=self.name, model_id=self.id) from e\n    | agno.exceptions.ModelProviderError: 'NoneType' object is not iterable\n    +------------------------------------\n\n## Steps to Reproduce\ncode: \nfrom agno.agent import Agent\nfrom agno.models.openrouter import OpenRouter\nimport asyncio\nfrom agno.tools.mcp import MCPTools\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\nimport os\nfrom dotenv import load_dotenv\nload_dotenv(os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), '.env'))\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\nmcp_path = os.path.abspath(os.path.join(current_dir, \"../../../mcp-server/cmd/mcp.exe\"))\nmcp_cmd = f'\"{mcp_path}\" stdio'\n\nclass RecommendLocationData(BaseModel):\n    name: str = Field(..., description=\"Name of the location\")\n    image: str = Field(..., description=\"Image of the location\")\n    latitude: float = Field(..., description=\"Latitude of the location\")\n    longitude: float = Field(..., description=\"Longitude of the location\")\nclass RecommendationList(BaseModel):\n    recommendations: List[RecommendLocationData]\nasync def run_agent(message: str):\n    async with MCPTools(mcp_cmd) as mcp_tools:\n        agent = Agent(\n            model=OpenRouter(id=\"mistralai/mistral-small-24b-instruct-2501\"),\n            tools=[mcp_tools],\n            show_tool_calls=True,\n            markdown=True,\n            response_model=RecommendationList\n        )\n        await agent.aprint_response(message, stream=True)\nif __name__ == \"__main__\":\n    # Basic example - exploring project license\n    asyncio.run(run_agent(\"use the 'search_city_attractions' tool to search popular attractions info in Hangzhou and recommend me three attractions \"))        \n## Agent Configuration (if applicable)\n        agent = Agent(\n            model=OpenRouter(id=\"mistralai/mistral-small-24b-instruct-2501\"),\n            tools=[mcp_tools],\n            show_tool_calls=True,\n            markdown=True,\n            response_model=RecommendationList\n        ) (it has been show in the above code which could reproduce the error)\n\n## Expected Behavior\noutput the structed result\n\n## Environment\n- OS: windows 11\n- Agno Version: 1.3.1\n- Additional Environment Details: Python 3.11.9, pydantic 2.11.3\n\n",
      "state": "closed",
      "author": "LDJ-creat",
      "author_type": "User",
      "created_at": "2025-05-04T14:59:19Z",
      "updated_at": "2025-05-06T15:33:24Z",
      "closed_at": "2025-05-06T15:33:23Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3076/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3076",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3076",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:57.485658",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Hi @LDJ-creat \nI am pushing a fix to fix general cases of using MCP with response_model. This does not however fix all OpenRouter cases. In the case of OpenRouter, unfortunately some of the models are really unhappy with tools and structured output being used together, and the OpenAI client hides th",
          "created_at": "2025-05-06T06:16:14Z"
        },
        {
          "author": "dirkbrnd",
          "body": "This should be fixed with [release 1.4.5](https://github.com/agno-agi/agno/releases/tag/v1.4.5)",
          "created_at": "2025-05-06T15:33:23Z"
        }
      ]
    },
    {
      "issue_number": 3063,
      "title": "[Bug] Fails to work with Meta Llama API with bad request (400 Error)",
      "body": "# Description\nSimple agent run fails with Llama API from Meta.\n\n## Test agent script:\n```\nfrom dotenv  import load_dotenv\nload_dotenv()\n\nfrom agno.agent import Agent\n# from agno.models.openai import OpenAIChat\n# from agno.models.google import Gemini\nfrom agno.models.meta import Llama\nfrom agno.tools.googlesearch import GoogleSearchTools\nfrom agno.tools.yfinance import YFinanceTools\nfrom agno.tools.crawl4ai import Crawl4aiTools\nfrom agno.storage.sqlite import SqliteStorage\n\nagent_storage = SqliteStorage(\n    table_name=\"agent_sessions\",\n    db_file=\"tmp/persistent_memory.db\",\n)\n\nsample_agent = Agent(\n    name=\"agno_agent\",\n    description=\"You are a helpful assistant who can search web, crawl page contents and also search financial information using given tools to achieve the given user goal.\",\n    # model=OpenAIChat(id=\"gpt-4o-mini\"),\n    # model=Gemini(id=\"gemini-2.5-flash-preview-04-17\"),  # or any other supported model\n    model=Llama(id=\"Llama-4-Maverick-17B-128E-Instruct-FP8\"),\n    instructions=[\n        \"If user input is not sufficent, ask user relevant questions / clarifications\",\n        \"To search the web, use google search tool.\",\n        \"To crawl the pages use crawl4ai tools\",\n        \"To get financial information about companies, use YFinance tools\"\n    ],\n    storage=agent_storage,\n    tools=[\n        GoogleSearchTools(),\n        YFinanceTools(enable_all=True),\n        Crawl4aiTools(max_length=5000)\n    ],\n    stream_intermediate_steps=True,\n    add_datetime_to_instructions=True,\n    debug_mode=True\n)\n\nuser_prompt = \"whats the latest news about China\"\nfor res in sample_agent.run(user_prompt, stream=True):\n    print(f\"Response Type: {res.event}\")\n    print(f\"Tools: {res.tools}\")\n    # print(f\"Messages: {res.messages}\")\n```\n\n## Run Output:\n```\nagno-copilotkit-integration/backend on  main [!] via 🐍 v3.12.4 (.venv-backend) \n❯ python test.py \nDEBUG ******************************************************** Agent ID: ec12872a-370e-4d24-b2a2-6a7e693c58e4 ********************************************************              \nDEBUG ******************************************************* Session ID: a2904abb-a060-48e0-922b-1bed04f98588 *******************************************************              \nDEBUG **************************************************** Agent Run Start: b98ade52-e8ff-4f9a-a932-972053cc2080 *****************************************************              \nDEBUG Processing tools for model                                                                                                                                                    \nDEBUG Added function google_search from googlesearch                                                                                                                                \nDEBUG Added function get_current_stock_price from yfinance_tools                                                                                                                    \nDEBUG Added function get_company_info from yfinance_tools                                                                                                                           \nDEBUG Added function get_stock_fundamentals from yfinance_tools                                                                                                                     \nDEBUG Added function get_income_statements from yfinance_tools                                                                                                                      \nDEBUG Added function get_key_financial_ratios from yfinance_tools                                                                                                                   \nDEBUG Added function get_analyst_recommendations from yfinance_tools                                                                                                                \nDEBUG Added function get_company_news from yfinance_tools                                                                                                                           \nDEBUG Added function get_technical_indicators from yfinance_tools                                                                                                                   \nDEBUG Added function get_historical_stock_prices from yfinance_tools                                                                                                                \nDEBUG Added function web_crawler from crawl4ai_tools                                                                                                                                \nResponse Type: RunStarted\nTools: None\nDEBUG ----------------------------------------------------------------- Llama Response Stream Start ------------------------------------------------------------------              \nDEBUG -------------------------------------------------------- Model: Llama-4-Maverick-17B-128E-Instruct-FP8 ---------------------------------------------------------              \nDEBUG ============================================================================ system ============================================================================              \nDEBUG You are a helpful assistant who can search web, crawl page contents and also search financial information using given tools to achieve the given user goal.                   \n      <instructions>                                                                                                                                                                \n      - If user input is not sufficent, ask user relevant questions / clarifications                                                                                                \n      - To search the web, use google search tool.                                                                                                                                  \n      - To crawl the pages use crawl4ai tools                                                                                                                                       \n      - To get financial information about companies, use YFinance tools                                                                                                            \n      </instructions>                                                                                                                                                               \n                                                                                                                                                                                    \n      <additional_information>                                                                                                                                                      \n      - The current time is 2025-05-02 17:12:45.329597.                                                                                                                             \n      </additional_information>                                                                                                                                                     \nDEBUG ============================================================================= user =============================================================================              \nDEBUG whats the latest news about China                                                                                                                                             \nERROR    Error from Llama API: Error code: 400 - {'title': 'Bad request', 'detail': 'Parameter type is required for `max_length`', 'status': 400}                                   \nTraceback (most recent call last):\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/agno-copilotkit-integration/backend/.venv-backend/lib/python3.12/site-packages/agno/models/meta/llama.py\", line 301, in invoke_stream\n    yield from self.get_client().chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/agno-copilotkit-integration/backend/.venv-backend/lib/python3.12/site-packages/llama_api_client/_utils/_utils.py\", line 283, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/agno-copilotkit-integration/backend/.venv-backend/lib/python3.12/site-packages/llama_api_client/resources/chat/completions.py\", line 259, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/agno-copilotkit-integration/backend/.venv-backend/lib/python3.12/site-packages/llama_api_client/_base_client.py\", line 1222, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/agno-copilotkit-integration/backend/.venv-backend/lib/python3.12/site-packages/llama_api_client/_base_client.py\", line 1031, in request\n    raise self._make_status_error_from_response(err.response) from None\nllama_api_client.BadRequestError: Error code: 400 - {'title': 'Bad request', 'detail': 'Parameter type is required for `max_length`', 'status': 400}\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/agno-copilotkit-integration/backend/test.py\", line 42, in <module>\n    for res in sample_agent.run(user_prompt, stream=True):\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/agno-copilotkit-integration/backend/.venv-backend/lib/python3.12/site-packages/agno/agent/agent.py\", line 655, in _run\n    for model_response_chunk in self.model.response_stream(messages=run_messages.messages):\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/agno-copilotkit-integration/backend/.venv-backend/lib/python3.12/site-packages/agno/models/base.py\", line 520, in response_stream\n    yield from self.process_response_stream(\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/agno-copilotkit-integration/backend/.venv-backend/lib/python3.12/site-packages/agno/models/base.py\", line 492, in process_response_stream\n    for response_delta in self.invoke_stream(messages=messages):\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/agno-copilotkit-integration/backend/.venv-backend/lib/python3.12/site-packages/agno/models/meta/llama.py\", line 309, in invoke_stream\n    raise ModelProviderError(message=str(e), model_name=self.name, model_id=self.id) from e\nagno.exceptions.ModelProviderError: Error code: 400 - {'title': 'Bad request', 'detail': 'Parameter type is required for `max_length`', 'status': 400}\n```",
      "state": "closed",
      "author": "gauravdhiman",
      "author_type": "User",
      "created_at": "2025-05-03T00:18:31Z",
      "updated_at": "2025-05-06T15:32:54Z",
      "closed_at": "2025-05-05T17:10:08Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3063/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3063",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3063",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:57.665174",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "PR out to fix! Thanks for raising",
          "created_at": "2025-05-04T07:37:41Z"
        },
        {
          "author": "dirkbrnd",
          "body": "This should be fixed with [release 1.4.5](https://github.com/agno-agi/agno/releases/tag/v1.4.5)",
          "created_at": "2025-05-06T15:32:53Z"
        }
      ]
    },
    {
      "issue_number": 2962,
      "title": "[Bug] Session metrics not recorded (all values are null or 0)",
      "body": "# Description\nWhen I configure the agent with a custom memory object using PostgresMemoryDb, the session metrics are all returned as 0 or None, and no metrics appear to be saved to the database. However, if I remove the memory=memory parameter, everything works as expected and complete metrics are recorded.\n\nThis seems to indicate a bug related to how memory is handled or interferes with session metric recording.\n\n## Steps to Reproduce\n\n1. Initialize PostgresMemoryDb and Memory:\n```\nmemory_db = PostgresMemoryDb(table_name=\"memory\", db_url=db_url)\nmemory = Memory(db=memory_db)\n```\n\n2. Create the agent with memory=memory:\n```\nagent = Agent(\n    name=\"Web Agent\",\n    role=\"Search the web for information\",\n    agent_id=\"web-agent\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[DuckDuckGoTools()],\n    instructions=[\n        \"Break down the users request into 2-3 different searches.\",\n        \"Always include sources\",\n    ],\n    storage=storage,\n    memory=memory, # HERE THE PROBLEM\n    enable_agentic_memory=True,\n    enable_session_summaries=True,\n    add_datetime_to_instructions=True,\n    markdown=True,\n)\n```\n\n3. Run a request:\n\n```\nagent.print_response(\"Share news about Apple\", stream=True)\nprint(agent.session_metrics)\n\n```\n\n## Agent Configuration (if applicable)\n```\nenable_agentic_memory=True\nenable_session_summaries=True\nmemory=Memory(db=PostgresMemoryDb(...))\n```\n\n## Expected Behavior\nSession metrics like input_tokens, output_tokens, total_tokens, and timestamps should be populated and saved.\n`SessionMetrics(input_tokens=1138, output_tokens=545, total_tokens=1683, audio_tokens=0, input_audio_tokens=0, output_audio_tokens=0, cached_tokens=0, reasoning_tokens=0, prompt_tokens=1138, completion_tokens=545, prompt_tokens_details={'audio_tokens': 0, 'cached_tokens': 0}, completion_tokens_details={'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, additional_metrics=None, time=25.48284649901325, time_to_first_token=2.621255750011187, timer=None)`\n\n\n## Actual Behavior\nAll session metrics return null values:\n`SessionMetrics(input_tokens=0, output_tokens=0, total_tokens=0, audio_tokens=0, input_audio_tokens=0, output_audio_tokens=0, cached_tokens=0, reasoning_tokens=0, prompt_tokens=0, completion_tokens=0, prompt_tokens_details=None, completion_tokens_details=None, additional_metrics=None, time=None, time_to_first_token=None, timer=None)`\n\nThis occurs only when a memory object is explicitly set. Without it, metrics populate correctly.\n\n\n\n## Environment\nAgno Version: (v1.4.1)\n\n",
      "state": "closed",
      "author": "lironesamoun",
      "author_type": "User",
      "created_at": "2025-04-24T09:14:15Z",
      "updated_at": "2025-05-06T15:32:40Z",
      "closed_at": "2025-05-04T14:22:38Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2962/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2962",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2962",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:57.899955",
      "comments": [
        {
          "author": "lironesamoun",
          "body": "I noticed that for all my previous agents with no storage and memory, I get as well `SessionMetrics(input_tokens=0, output_tokens=0, total_tokens=0, audio_tokens=0, input_audio_tokens=0, output_audio_tokens=0, cached_tokens=0, reasoning_tokens=0, prompt_tokens=0, completion_tokens=0, prompt_tokens_d",
          "created_at": "2025-04-24T12:22:04Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @lironesamoun \nThis should now be fixed. I will check out the related issue to be sure.",
          "created_at": "2025-05-04T14:00:46Z"
        }
      ]
    },
    {
      "issue_number": 3071,
      "title": "[Bug] MCP Tool Calls Fail Due to Extraneous Parameters in Requests",
      "body": "\n## Bug Report: MCP Tool Calls Fail Due to Extraneous Parameters in Requests\n\n### Issue description\nWhen calling Supabase MCP tools like `execute_sql` and `list_tables`, requests fail with a ZodError indicating unrecognized keys in the request object. The error consistently identifies `tool_description` as an unrecognized parameter that should not be included in the request.\n\n### Error message\n```\nERROR Failed to call MCP tool 'execute_sql': Error from MCP tool 'execute_sql': \n[TextContent(type='text', text='{\"error\":{\"name\":\"ZodError\",\"message\":\"[\\\\n  {\\\\n    \\\\\"code\\\\\": \\\\\"unrecognized_keys\\\\\",\\\\n    \\\\\"keys\\\\\": [\\\\n      \\\\\"tool_description\\\\\"\\\\n    ],\\\\n    \\\\\"path\\\\\": [],\\\\n    \\\\\"message\\\\\": \\\\\"Unrecognized key(s) in object: \\'tool_description\\'\\\\\"\\\\n  }\\\\n]\"}}', annotations=None)]\n```\n\n### Root cause\nIn `agno/utils/mcp.py`, the `get_entrypoint_for_tool` function creates a partial function that passes the `tool_description` parameter to every tool call:\n\n```python\nreturn partial(call_tool, tool_name=tool.name, tool_description=tool.description)\n```\n\nThis parameter is not expected by the MCP API schema for Supabase tools, causing validation errors.\n\n### Current workaround\nAdded a filtering mechanism in the `call_tool` function to remove the extraneous parameters:\n\n```python\ntool_params = {k: v for k, v in kwargs.items() if k not in ['tool_description', 'tool_name']}\nresult: CallToolResult = await session.call_tool(tool_name, tool_params)\n```\n\n### Suggested fix\nRemove the `tool_description` parameter from the partial function declaration:\n\n```python\n# Change this line\nreturn partial(call_tool, tool_name=tool.name, tool_description=tool.description)\n\n# To this\nreturn partial(call_tool, tool_name=tool.name)\n```\n\nThis is a cleaner solution than filtering parameters inside the function, as it avoids passing unnecessary data in the first place.\n\n### Environment\n- Python version: 3.12\n- agno version: 1.4.3\n- mcp version: 1.7.1\n",
      "state": "closed",
      "author": "moiraphill",
      "author_type": "User",
      "created_at": "2025-05-04T01:35:17Z",
      "updated_at": "2025-05-06T15:32:04Z",
      "closed_at": "2025-05-05T08:52:27Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3071/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3071",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3071",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:58.066342",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Thanks for raising! PR out to fix. ",
          "created_at": "2025-05-04T07:36:45Z"
        },
        {
          "author": "dirkbrnd",
          "body": "This has been merged. Releasing asap",
          "created_at": "2025-05-05T08:53:03Z"
        },
        {
          "author": "dirkbrnd",
          "body": "This should be fixed with [release 1.4.5](https://github.com/agno-agi/agno/releases/tag/v1.4.5)",
          "created_at": "2025-05-06T15:32:03Z"
        }
      ]
    },
    {
      "issue_number": 3078,
      "title": "[Bug] `load_session()` fails with `KeyError` error",
      "body": "# Description\nWhen Agent is configured with storage and we set the session_id and load the session explicitly (which may be required if if we want to set session explicitly - think of UI seeing it based on some logic), the `load_session()` call fails with below error:\n\nAs the `session_id` is newly created so it wont exist in storage\n\n```\nagno-copilotkit-integration/backend on  main [!⇡] via 🐍 v3.12.4 (.venv-backend) \n❯ python sample_agent.py\nDEBUG ******************************************************** Agent ID: fae798b3-cbbe-4f20-9f95-474fdc0ca7fd ********************************************************              \nTraceback (most recent call last):\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/agno-copilotkit-integration/backend/sample_agent.py\", line 49, in <module>\n    sample_agent.load_session()\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/agno-copilotkit-integration/backend/.venv-backend/lib/python3.12/site-packages/agno/agent/agent.py\", line 2524, in load_session\n    self.write_to_storage(user_id=self.user_id, session_id=self.session_id)  # type: ignore\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/agno-copilotkit-integration/backend/.venv-backend/lib/python3.12/site-packages/agno/agent/agent.py\", line 2466, in write_to_storage\n    self.storage.upsert(session=self.get_agent_session(session_id=session_id, user_id=user_id)),\n                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/gauravdhiman/projects/python/ai/playgrounds/agno-copilotkit-integration/backend/.venv-backend/lib/python3.12/site-packages/agno/agent/agent.py\", line 2223, in get_agent_session\n    run_responses = self.memory.runs[session_id]  # type: ignore\n                    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: '11981b36-56eb-4df2-8816-5459b1336917'\n```\n\n## Here is the agent test script:\n```\nfrom dotenv  import load_dotenv\nload_dotenv()\n\nfrom agno.agent import Agent\nfrom agno.models.openai import OpenAIChat\nfrom agno.models.google import Gemini\nfrom agno.models.meta import Llama\nfrom agno.tools.googlesearch import GoogleSearchTools\nfrom agno.tools.yfinance import YFinanceTools\nfrom agno.tools.crawl4ai import Crawl4aiTools\nfrom agno.storage.sqlite import SqliteStorage\n\nimport uuid\n\nagent_storage = SqliteStorage(\n    table_name=\"agent_sessions\",\n    db_file=\"tmp/persistent_memory.db\",\n)\n\nsample_agent = Agent(\n    name=\"agno_agent\",\n    description=\"You are a helpful assistant who can search web, crawl page contents and also search financial information using given tools to achieve the given user goal.\",\n    # model=OpenAIChat(id=\"gpt-4o-mini\"),\n    model=Gemini(id=\"gemini-2.5-flash-preview-04-17\"),\n    # model=Llama(id=\"Llama-4-Maverick-17B-128E-Instruct-FP8\"),\n    # model=OpenRouter(id=\"qwen/qwq-32b\"),\n    # model=Groq(id=\"llama-3.3-70b-versatile\"),\n    instructions=[\n        \"If user input is not sufficent, ask user relevant questions / clarifications\",\n        \"To search the web, use google search tool.\",\n        \"To crawl the pages use crawl4ai tools\",\n        \"To get financial information about companies, use YFinance tools\"\n    ],\n    storage=agent_storage,\n    # add_history_to_messages=True,\n    # num_history_responses=5,\n    tools=[\n        GoogleSearchTools(),\n        YFinanceTools(enable_all=True),\n        Crawl4aiTools(max_length=5000)\n    ],\n    # reasoning=True,\n    stream_intermediate_steps=True,\n    add_datetime_to_instructions=True,\n    debug_mode=True\n)\n\nsample_agent.session_id = str(uuid.uuid4()) # or UI passed session ID (session ID may be generated outside agent)\nsample_agent.load_session()\n# --OR--\n# sample_agent.new_session()\nuser_prompt = \"whats the latest news about China\"\nfor res in sample_agent.run(user_prompt, stream=True):\n    print(f\"Response Type: {res.event}\")\n    print(f\"Tools: {res.tools}\")\n    # print(f\"Messages: {res.messages}\")\n```",
      "state": "closed",
      "author": "gauravdhiman",
      "author_type": "User",
      "created_at": "2025-05-04T21:31:49Z",
      "updated_at": "2025-05-06T15:31:56Z",
      "closed_at": "2025-05-05T11:42:32Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3078/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3078",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3078",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:58.231651",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Thanks for raising! PR out to fix.",
          "created_at": "2025-05-05T11:29:19Z"
        },
        {
          "author": "dirkbrnd",
          "body": "This should be fixed with [release 1.4.5](https://github.com/agno-agi/agno/releases/tag/v1.4.5)",
          "created_at": "2025-05-06T15:31:55Z"
        }
      ]
    },
    {
      "issue_number": 3092,
      "title": "[Feature Request] let user evaluate each answer from agent (like/unlike) + signal wrong answer and give feedbacks",
      "body": "## Problem Description\nProvide a clear and concise explanation of the issue you're facing.\n**Example:** *\"I often find it frustrating when [...] because [...]”*\n\n## Proposed Solution\nExplain your ideal solution. How should this feature work?\nBe as detailed as possible to help us understand your vision.\n\n## Alternatives Considered\nHave you found any workarounds or alternative solutions?\nShare other approaches you've tried or thought about.\n\n## Additional context\nInclude any extra information that might be helpful, such as:\n- Screenshots\n- Examples of similar features elsewhere\n- Any relevant links or references\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[ ] Yes, I’d love to work on it!**\n**[ ] I’m open to collaborating but need guidance.**\n**[ ] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "monali7-d",
      "author_type": "User",
      "created_at": "2025-05-06T08:19:07Z",
      "updated_at": "2025-05-06T08:19:23Z",
      "closed_at": "2025-05-06T08:19:23Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3092/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3092",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3092",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:58.418539",
      "comments": []
    },
    {
      "issue_number": 3090,
      "title": "[Feature Request] support HuggingFace's inference providers",
      "body": "## Problem Description\nProvide a clear and concise explanation of the issue you're facing.\n**Example:** *\"I often find it frustrating when [...] because [...]”*\n\n## Proposed Solution\nExplain your ideal solution. How should this feature work?\nBe as detailed as possible to help us understand your vision.\n\n## Alternatives Considered\nHave you found any workarounds or alternative solutions?\nShare other approaches you've tried or thought about.\n\n## Additional context\nInclude any extra information that might be helpful, such as:\n- Screenshots\n- Examples of similar features elsewhere\n- Any relevant links or references\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[ ] Yes, I’d love to work on it!**\n**[ ] I’m open to collaborating but need guidance.**\n**[ ] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "monali7-d",
      "author_type": "User",
      "created_at": "2025-05-06T05:53:28Z",
      "updated_at": "2025-05-06T05:53:40Z",
      "closed_at": "2025-05-06T05:53:40Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3090/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3090",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3090",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:58.418562",
      "comments": []
    },
    {
      "issue_number": 3039,
      "title": "[Feature Request] Add tool response for `ToolCallCompleted` Event",
      "body": "## Problem Description\nIn current implementation, on tool call completion we get `role`, `tool_name` and `tool_args` (and `tool_call_id` although that is always `None`), but we don't get tool response. We want tool response also as developers may want to show it to user in some cases.\n\nAlso as mentioned above, I observed that `tool_call_id` is always `None`, so that may be a bug too.\n\nHere is the sample code to reproduce it:\n```\nfrom logging import debug\nfrom agno import tools\nfrom dotenv  import load_dotenv\nload_dotenv()\n\nfrom agno.agent import Agent\nfrom agno.models.openai import OpenAIChat\nfrom agno.models.google import Gemini\nfrom agno.models.openrouter import OpenRouter\nfrom agno.models.groq import Groq\nfrom agno.tools.googlesearch import GoogleSearchTools\nfrom agno.tools.yfinance import YFinanceTools\nfrom agno.tools.crawl4ai import Crawl4aiTools\nfrom agno.storage.sqlite import SqliteStorage\nfrom agno.utils.pprint import pprint_run_response\nfrom agno.tools import FunctionCall, tool\nfrom markitdown import MarkItDown\n\nagent_storage = SqliteStorage(\n    table_name=\"agent_sessions\",\n    db_file=\"tmp/persistent_memory.db\",\n)\n\nsample_agent = Agent(\n    name=\"agno_agent\",\n    description=\"You are a helpful assistant who can search web, crawl page contents and also search financial information using given tools to achieve the given user goal.\",\n    # model=OpenAIChat(id=\"gpt-4o-mini\"),\n    model=Gemini(id=\"gemini-2.5-flash-preview-04-17\"),  # or any other supported model\n    instructions=[\n        \"If user input is not sufficent, ask user relevant questions / clarifications\",\n        \"To search the web, use google search tool.\",\n        \"To crawl the pages use crawl4ai tools\",\n        \"To get financial information about companies, use YFinance tools\"\n    ],\n    storage=agent_storage,\n    tools=[\n        GoogleSearchTools(),\n        YFinanceTools(enable_all=True),\n        Crawl4aiTools(max_length=5000)\n    ],\n    # reasoning=True,\n    stream_intermediate_steps=True,\n    add_datetime_to_instructions=True,\n    debug_mode=True\n)\n\nuser_prompt = \"whats the latest news about China\"\nfor res in sample_agent.run(user_prompt, stream=True):\n    print(f\"Response Type: {res.event}, Tools: {res.tools}\")\n```\n\nHere is the output. Please specifically look at `ToolCallCompleted` event.\n```\nResponse Type: ToolCallCompleted, Tools: [{'role': 'tool', 'tool_call_id': None, 'tool_name': 'google_search', 'tool_args': {'query': 'latest news about China', 'language': 'en'}}]\n```\n\nFull output:\n```\n❯ python test.py        \nDEBUG ******************************************************** Agent ID: 5dad3964-0db5-4bb9-bbf4-4b063d91c3b9 ********************************************************              \nDEBUG ******************************************************* Session ID: c6ece813-f009-409b-b406-7ee48fb06449 *******************************************************              \nDEBUG **************************************************** Agent Run Start: 68a9511b-2538-4fa6-94b4-c80bd8b5ae5b *****************************************************              \nDEBUG Processing tools for model                                                                                                                                                    \nDEBUG Added function google_search from googlesearch                                                                                                                                \nDEBUG Added function get_current_stock_price from yfinance_tools                                                                                                                    \nDEBUG Added function get_company_info from yfinance_tools                                                                                                                           \nDEBUG Added function get_stock_fundamentals from yfinance_tools                                                                                                                     \nDEBUG Added function get_income_statements from yfinance_tools                                                                                                                      \nDEBUG Added function get_key_financial_ratios from yfinance_tools                                                                                                                   \nDEBUG Added function get_analyst_recommendations from yfinance_tools                                                                                                                \nDEBUG Added function get_company_news from yfinance_tools                                                                                                                           \nDEBUG Added function get_technical_indicators from yfinance_tools                                                                                                                   \nDEBUG Added function get_historical_stock_prices from yfinance_tools                                                                                                                \nDEBUG Added function web_crawler from crawl4ai_tools                                                                                                                                \nResponse Type: RunStarted, Tools: None\nDEBUG ----------------------------------------------------------------- Google Response Stream Start -----------------------------------------------------------------              \nDEBUG ------------------------------------------------------------ Model: gemini-2.5-flash-preview-04-17 -------------------------------------------------------------              \nDEBUG ============================================================================ system ============================================================================              \nDEBUG You are a helpful assistant who can search web, crawl page contents and also search financial information using given tools to achieve the given user goal.                   \n      <instructions>                                                                                                                                                                \n      - If user input is not sufficent, ask user relevant questions / clarifications                                                                                                \n      - To search the web, use google search tool.                                                                                                                                  \n      - To crawl the pages use crawl4ai tools                                                                                                                                       \n      - To get financial information about companies, use YFinance tools                                                                                                            \n      </instructions>                                                                                                                                                               \n                                                                                                                                                                                    \n      <additional_information>                                                                                                                                                      \n      - The current time is 2025-04-30 15:19:10.711129.                                                                                                                             \n      </additional_information>                                                                                                                                                     \nDEBUG ============================================================================= user =============================================================================              \nDEBUG whats the latest news about China                                                                                                                                             \nDEBUG ========================================================================== assistant ===========================================================================              \nDEBUG Tool Calls:                                                                                                                                                                   \n          Name: 'google_search'                                                                                                                                                     \n          Arguments: 'query: latest news about China, language: en'                                                                                                                 \nDEBUG **************************************************************************  METRICS  ***************************************************************************              \nDEBUG * Tokens:                      input=1064, output=23, total=1210                                                                                                              \nDEBUG * Time:                        1.3638s                                                                                                                                        \nDEBUG * Tokens per second:           16.8651 tokens/s                                                                                                                               \nDEBUG * Time to first token:         1.3471s                                                                                                                                        \nDEBUG **************************************************************************  METRICS  ***************************************************************************              \nDEBUG Getting function google_search                                                                                                                                                \nResponse Type: ToolCallStarted, Tools: [{'role': 'tool', 'tool_call_id': None, 'tool_name': 'google_search', 'tool_args': {'query': 'latest news about China', 'language': 'en'}}]\nDEBUG Running: google_search(query=latest news about China, language=en)                                                                                                            \nDEBUG Searching Google [en] for: latest news about China                                                                                                                            \nResponse Type: ToolCallCompleted, Tools: [{'role': 'tool', 'tool_call_id': None, 'tool_name': 'google_search', 'tool_args': {'query': 'latest news about China', 'language': 'en'}}]\nDEBUG ============================================================================= tool =============================================================================              \nDEBUG [                                                                                                                                                                             \n        {                                                                                                                                                                           \n          \"title\": \"China News | Today's Breaking Stories - Reuters\",                                                                                                               \n          \"url\": \"https://www.reuters.com/world/china/\",                                                                                                                            \n          \"description\": \" Reuters.com is your online source for the latest China news stories and current events, ensuring our readers up to date with any breaking news           \n      developments. \"                                                                                                                                                               \n        },                                                                                                                                                                          \n        {                                                                                                                                                                           \n          \"title\": \"China news - breaking news, video, headlines and opinion | CNN\",                                                                                                \n          \"url\": \"https://www.cnn.com/world/china\",                                                                                                                                 \n          \"description\": \" View the latest China news and videos, including politics, travel and business headlines. \"                                                              \n        },                                                                                                                                                                          \n        {                                                                                                                                                                           \n          \"title\": \"China | Latest News & Updates - BBC\",                                                                                                                           \n          \"url\": \"https://www.bbc.com/news/world/asia/china\",                                                                                                                       \n          \"description\": \" China shares rare Moon rocks with US despite trade war. Two US institutions have been granted access to samples collected by the Chang'e-5 mission in    \n      2020. \"                                                                                                                                                                       \n        },                                                                                                                                                                          \n        {                                                                                                                                                                           \n          \"title\": \"  China exports to U.S. plunge as tariffs hit, leading some experts to warn of product shortages  \",                                                            \n          \"url\": \"https://www.cbsnews.com/news/china-exports-to-us-drop-sharply/\",                                                                                                  \n          \"description\": \" China exports to U.S. plunge as tariffs hit, leading some experts to warn of product shortages \"                                                         \n        },                                                                                                                                                                          \n        {                                                                                                                                                                           \n          \"title\": \"China Breaking News & Headlines | South China Morning Post\",                                                                                                    \n          \"url\": \"https://www.scmp.com/news/china\",                                                                                                                                 \n          \"description\": \" Latest China news, opinions and analysis, covering Xi Jinping, Beijing's relations with Taiwan and China's tensions with the US. \"                       \n        }                                                                                                                                                                           \n      ]                                                                                                                                                                             \nDEBUG ************************************************************************  TOOL METRICS  ************************************************************************              \nDEBUG * Time:                        0.3986s                                                                                                                                        \nDEBUG ************************************************************************  TOOL METRICS  ************************************************************************              \nResponse Type: RunResponse, Tools: [{'role': 'tool', 'tool_call_id': None, 'tool_name': 'google_search', 'tool_args': {'query': 'latest news about China', 'language': 'en'}}]\nResponse Type: RunResponse, Tools: [{'role': 'tool', 'tool_call_id': None, 'tool_name': 'google_search', 'tool_args': {'query': 'latest news about China', 'language': 'en'}}]\nResponse Type: RunResponse, Tools: [{'role': 'tool', 'tool_call_id': None, 'tool_name': 'google_search', 'tool_args': {'query': 'latest news about China', 'language': 'en'}}]\nResponse Type: RunResponse, Tools: [{'role': 'tool', 'tool_call_id': None, 'tool_name': 'google_search', 'tool_args': {'query': 'latest news about China', 'language': 'en'}}]\nResponse Type: RunResponse, Tools: [{'role': 'tool', 'tool_call_id': None, 'tool_name': 'google_search', 'tool_args': {'query': 'latest news about China', 'language': 'en'}}]\nDEBUG ========================================================================== assistant ===========================================================================              \nDEBUG Here are some of the latest news headlines about China based on my search:                                                                                                    \n                                                                                                                                                                                    \n      *   **China News | Today's Breaking Stories - Reuters:** Your online source for the latest China news stories and current events.                                             \n      *   **China news - breaking news, video, headlines and opinion | CNN:** View the latest China news and videos, including politics, travel and business headlines.             \n      *   **China | Latest News & Updates - BBC:** China shares rare Moon rocks with US despite trade war.                                                                          \n      *   **China exports to U.S. plunge as tariffs hit, leading some experts to warn of product shortages - CBS News:** China exports to U.S. plunge as tariffs hit, leading some  \n      experts to warn of product shortages.                                                                                                                                         \n      *   **China Breaking News & Headlines | South China Morning Post:** Latest China news, opinions and analysis, covering Xi Jinping, Beijing's relations with Taiwan and China's\n      tensions with the US.                                                                                                                                                         \n                                                                                                                                                                                    \n      You can visit these links to read the full articles and get more details on the latest developments.                                                                          \nDEBUG **************************************************************************  METRICS  ***************************************************************************              \nDEBUG * Tokens:                      input=1521, output=213, total=2009                                                                                                             \nDEBUG * Time:                        2.8240s                                                                                                                                        \nDEBUG * Tokens per second:           75.4250 tokens/s                                                                                                                               \nDEBUG * Time to first token:         1.9939s                                                                                                                                        \nDEBUG **************************************************************************  METRICS  ***************************************************************************              \nDEBUG ------------------------------------------------------------------ Google Response Stream End ------------------------------------------------------------------              \nDEBUG Added 4 Messages to AgentMemory                                                                                                                                               \nDEBUG Added AgentRun to AgentMemory                                                                                                                                                 \nResponse Type: UpdatingMemory, Tools: [{'role': 'tool', 'tool_call_id': None, 'tool_name': 'google_search', 'tool_args': {'query': 'latest news about China', 'language': 'en'}}]\nDEBUG Logging Agent Run                                                                                                                                                             \nDEBUG ***************************************************** Agent Run End: 68a9511b-2538-4fa6-94b4-c80bd8b5ae5b ******************************************************              \nResponse Type: RunCompleted, Tools: [{'role': 'tool', 'tool_call_id': None, 'tool_name': 'google_search', 'tool_args': {'query': 'latest news about China', 'language': 'en'}}]\n```",
      "state": "closed",
      "author": "gauravdhiman",
      "author_type": "User",
      "created_at": "2025-04-30T21:23:20Z",
      "updated_at": "2025-05-04T21:35:15Z",
      "closed_at": "2025-05-04T21:35:13Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3039/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3039",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3039",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:58.418572",
      "comments": [
        {
          "author": "gauravdhiman",
          "body": "This should get resolved once https://github.com/agno-agi/agno/pull/3042 gets merged.\nAfter investigation, found that this issue was Gemini specific.",
          "created_at": "2025-05-01T16:43:09Z"
        },
        {
          "author": "gauravdhiman",
          "body": "We can close it. This PR solved the issue: https://github.com/agno-agi/agno/pull/3042",
          "created_at": "2025-05-04T21:35:13Z"
        }
      ]
    },
    {
      "issue_number": 2910,
      "title": "Cannot use embeddings",
      "body": "cannot use embedding even the one mention in docs : \n``\n---------------------------------------------------------------------------\nHTTPError                                 Traceback (most recent call last)\nFile ~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:406, in hf_raise_for_status(response, endpoint_name)\n    [405](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:405) try:\n--> [406](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:406)     response.raise_for_status()\n    [407](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:407) except HTTPError as e:\n\nFile ~/anaconda3/lib/python3.12/site-packages/requests/models.py:1024, in Response.raise_for_status(self)\n   [1023](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/requests/models.py:1023) if http_error_msg:\n-> [1024](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/requests/models.py:1024)     raise HTTPError(http_error_msg, response=self)\n\nHTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json\n\nThe above exception was the direct cause of the following exception:\n\nRepositoryNotFoundError                   Traceback (most recent call last)\nFile ~/anaconda3/lib/python3.12/site-packages/transformers/utils/hub.py:403, in cached_file(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\n    [401](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/transformers/utils/hub.py:401) try:\n    [402](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/transformers/utils/hub.py:402)     # Load from URL or cache if already cached\n--> [403](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/transformers/utils/hub.py:403)     resolved_file = hf_hub_download(\n    [404](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/transformers/utils/hub.py:404)         path_or_repo_id,\n    [405](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/transformers/utils/hub.py:405)         filename,\n    [406](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/transformers/utils/hub.py:406)         subfolder=None if len(subfolder) == 0 else subfolder,\n    [407](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/transformers/utils/hub.py:407)         repo_type=repo_type,\n    [408](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/transformers/utils/hub.py:408)         revision=revision,\n...\n    [436](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/transformers/utils/hub.py:436)         f\"'https://huggingface.co/{path_or_repo_id}' for available revisions.\"\n    [437](https://file+.vscode-resource.vscode-cdn.net/home/mohamed-lahmeri/Desktop/To%20D/Tutorials/AGNO%20projects/Course%20Agno/~/anaconda3/lib/python3.12/site-packages/transformers/utils/hub.py:437)     ) from e\n\nOSError: sentence-transformers/all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\nOutput is truncated. View as a [scrollable element](command:cellOutput.enableScrolling?1352e67d-3cca-48fa-9ed3-7b325e87540c) or open in a [text editor](command:workbench.action.openLargeOutput?1352e67d-3cca-48fa-9ed3-7b325e87540c). Adjust cell output [settings](command:workbench.action.openSettings?%5B%22%40tag%3AnotebookOutputLayout%22%5D)...\n",
      "state": "closed",
      "author": "MohamedLahmeri01",
      "author_type": "User",
      "created_at": "2025-04-21T09:15:23Z",
      "updated_at": "2025-05-04T14:56:35Z",
      "closed_at": "2025-05-04T14:56:35Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2910/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2910",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2910",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:58.580644",
      "comments": [
        {
          "author": "Ayush0054",
          "body": "Hey @MohamedLahmeri01,\nWe’ve fixed the HuggingFace embedder issue and merged the PR:\nhttps://github.com/agno-agi/agno/pull/2979\n\nThis fix will be included in the next release.\nWe really appreciate your patience! 🙌",
          "created_at": "2025-04-28T08:26:13Z"
        },
        {
          "author": "kausmeows",
          "body": "Closing this, as the fix PR https://github.com/agno-agi/agno/pull/2979 is merged",
          "created_at": "2025-05-04T14:56:34Z"
        }
      ]
    },
    {
      "issue_number": 3018,
      "title": "[Bug] Description and Instructions attributes of Agents are ignored",
      "body": "# Description\nAgent is not respecting prompts included in **Description** or **Instructions** attributes.\n\nAccording to documentation, Description attribute works in that way:\n`A description of the Agent that is added to the start of the system message`\n\nBut I'm not able to make it work. When I add agent instructions, Agent response is not following them. It only does when manually concatenating in the system_message.\n\n## Steps to Reproduce\n```\nagent = Agent(\n                model=AwsBedrock(\n                    id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\", session=self.session\n                ),\n                system_message=command.system_instruction\n                description=command.client_instruction, # Ignores this description. \n                description=command.client_instruction, # Ignores this instruction. \n                response_model=Asset,\n            )\n```\n\n```\nagent = Agent(\n                model=AwsBedrock(\n                    id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\", session=self.session\n                ),\n                system_message=command.system_instruction\n                + \"\\n\"\n                + command.client_instruction,  # That way respects the instruction\n                response_model=Asset,\n            )\n```\n\n## Expected Behavior\nI was expecting the description or instruction, to go into the system message like described in the documentation, and not having to manually concatenate.\n\nIs it again a model issue? Is it working for you as expected using different models/providers than me?\n\n## Environment\n- OS:  macOS\n- Agno Version: 1.3.1\n- Additional Environment Details: (e.g., Python 3.10)",
      "state": "closed",
      "author": "marcsc3",
      "author_type": "User",
      "created_at": "2025-04-29T13:27:26Z",
      "updated_at": "2025-05-04T14:39:33Z",
      "closed_at": "2025-05-04T14:39:32Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3018/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3018",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3018",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:58.759538",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "@marcsc3 We use `description`, `instructions` and other agent parameters to build up the `system_message` that is sent to the model. If you provide `system_message` manually like you are doing, it would use that system message in its entirety and not add anything else. \n\nI updated the information in",
          "created_at": "2025-05-04T14:39:32Z"
        }
      ]
    },
    {
      "issue_number": 3030,
      "title": "[Bug] coroutine 'AwsBedrock.ainvoke_stream' was never awaited",
      "body": "# Description\n\nThe playground does not work with AWS Bedrock. It fails with a `coroutine was never awaited` error.\n\n## Steps to Reproduce\n\n```\npip install fastapi[standard]==0.115.12 agno==1.4.2 boto3==1.38.5\n```\n```py\nfrom agno.agent import Agent\nfrom agno.models.aws import AwsBedrock\nfrom agno.playground import Playground, serve_playground_app\n\nAWS_ACCESS_KEY_ID = \"\"\nAWS_SECRET_ACCESS_KEY = \"\"\nAWS_REGION = \"\"\n\nagent = Agent(\n    name=\"Agent\",\n    markdown=True,\n\n    model=AwsBedrock(\n        id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n        aws_access_key_id=AWS_ACCESS_KEY_ID,\n        aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n        aws_region=AWS_REGION,\n    ),\n\n    show_tool_calls=True,\n    debug_mode=True,\n)\n\napp = Playground(agents=[agent]).get_app()\nif __name__ == '__main__':\n    serve_playground_app(\"main:app\", reload=True)\n```\n```sh\nag setup\n```\n\nGo to the Playground and prompt the agent with something.\n\n## Expected Behavior\n\nIt should output the answer.\n\n## Actual Behavior\n\nIn the console this gets printed:\n```\n.venv/lib/python3.12/site-packages/agno/models/base.py:586: RuntimeWarning: coroutine 'AwsBedrock.ainvoke_stream' was never awaited\n  async for response_delta in self.ainvoke_stream(messages=messages):  # type: ignore\n```\nIn the UI this is shown:\n```\nOops! Something went wrong while streaming. 'async for' requires an object with __aiter__ method, got coroutine\n```\n\n## Screenshots or Logs (if applicable)\n\nhttps://github.com/user-attachments/assets/cf7e0c78-9556-4ba0-9531-45bdc67085b8\n\n## Environment\n- OS: NixOS (Linux)\n- Agno Version: 1.4.2\n- External Dependency Versions: `fastapi[standard]==0.115.12 boto3==1.38.5`\n- Additional Environment Details: Python 3.12.9",
      "state": "closed",
      "author": "TheDevMinerTV",
      "author_type": "User",
      "created_at": "2025-04-30T08:52:37Z",
      "updated_at": "2025-05-04T14:27:44Z",
      "closed_at": "2025-05-04T14:27:43Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3030/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3030",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3030",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:58.951431",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Hi @TheDevMinerTV \nUnfortunately we don't support async with AWSBedrock. You can make it work with playground by saying `app = Playground(agents=[agent]).get_app(use_async=False)`",
          "created_at": "2025-05-04T07:54:21Z"
        },
        {
          "author": "TheDevMinerTV",
          "body": "Adding a more helpful error message or putting a warning on the website for this would be good.",
          "created_at": "2025-05-04T13:01:50Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Thanks for the suggestion. I added a warning to the docs. ",
          "created_at": "2025-05-04T14:27:43Z"
        }
      ]
    },
    {
      "issue_number": 3074,
      "title": "[Bug] PostgresMemoryDb doesn't add memories to the defined table",
      "body": "# Description\n\nFirst of all, thank you for this amazing library!\n\nI think this issue might be related to https://github.com/agno-agi/agno/issues/2962\n\n`PostgresMemoryDb` doesn't seem to be adding memories to the defined table. The table is created automatically, but it's not updated. The logs show:\n\n`DEBUG Added RunResponse to Memory`.\n\n## Agent Configuration (if applicable)\nMy code which uses `PostgresMemoryDb`:\n\n```Python\nimport asyncio\nfrom os import getenv\nfrom textwrap import dedent\n\nimport nest_asyncio\nfrom agno.agent import Agent\nfrom agno.knowledge.pdf import PDFKnowledgeBase\nfrom agno.models.deepseek import DeepSeek\nfrom agno.models.google import Gemini\nfrom agno.models.openai import OpenAIChat\nfrom agno.playground import Playground, serve_playground_app\nfrom agno.storage.agent.sqlite import SqliteAgentStorage\nfrom agno.storage.postgres import PostgresStorage\nfrom agno.tools.mcp import MCPTools\nfrom agno.tools.thinking import ThinkingTools\nfrom agno.vectordb.pgvector import PgVector\nfrom agno.memory.v2.db.postgres import PostgresMemoryDb\nfrom agno.memory.v2.memory import Memory\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n# Allow nested event loops\nnest_asyncio.apply()\n\ndb_url = \"postgresql+psycopg://ai:ai@localhost:5532/ai\"\n\nknowledge_base = PDFKnowledgeBase(\n    path=\"data/pdfs\",\n    vector_db=PgVector(\n        table_name=\"pdf_documents\",\n        db_url=db_url,\n    ),\n)\n\nmemory_db = PostgresMemoryDb(\n    table_name=\"agent_user_memories\",\n    db_url=db_url,\n)\nmemory = Memory(db=memory_db)\n\nstorage = PostgresStorage(\n    table_name=\"agent_sessions\",\n    db_url=db_url,\n)\n# Load the knowledge base: Comment after first run\n# knowledge_base.load(upsert=True)\n\n\nasync def run_server() -> None:\n    # Create a client session to connect to the MCP server\n    async with MCPTools(\"npx -y @playwright/mcp@latest\") as mcp_tools:\n        agent = Agent(\n            name=\"MCP-Playwright\",\n            description=\"Browser Agent with RAG knowledge about myself\",\n            tools=[\n                # ThinkingTools(add_instructions=True),\n                mcp_tools,\n            ],\n            instructions=dedent(\n                \"\"\"\\\n                \"You are a Browser agent. Your task is to browse websites and answer questions about them.\",\n                \"- Follow these browsing strategies:\",\n                \"  1. First scan the page to understand its structure\",\n                \"  2. Look for navigation elements to find relevant sections\",\n                \"  3. Use search functionality when available\",\n                \"  4. Extract key information and summarize concisely\",\n                \"- For data extraction tasks, compile information in markdown tables\",\n                \"- When encountering paywalls or login pages, inform the user instead of attempting bypasses\",\n                \"- Always cite the exact source URL for any information provided\"\n                \"- Very important: when asked to open the browser, ALWAYS use \"functions.browser_navigate\" tool to open the browser and do not navigate anywhere\"\n            \"\"\"\n            ),\n            reasoning=True,\n            # knowledge=knowledge_base,\n            memory=memory,\n            # # Enable RAG by adding references from AgentKnowledge to the user prompt.\n            # add_references=True,\n            # Set as False because Agents default to `search_knowledge=True`\n            search_knowledge=False,\n            model=OpenAIChat(id=\"gpt-4.1\"),\n            # model=DeepSeek(),\n            # model=OpenAIChat(id=\"o3-mini\"),\n            # model=Gemini(\n            # id=\"gemini-2.0-flash\",\n            # ),\n            storage=storage,\n            # Auto-runs MemoryManager after each user message\n            enable_user_memories=True,\n            # Creates and stores session summaries\n            enable_session_summaries=True,\n            # Gives agent a tool to manage user memories\n            enable_agentic_memory=True,\n            # Allow agent to read full history\n            read_chat_history=True,\n            # Add chat history to messages\n            add_history_to_messages=True,\n            # Include last 3 runs\n            num_history_runs=3,\n            # Include last 3 responses\n            num_history_responses=3,\n            read_tool_call_history=True,\n            # helps the agent maintain temporal awareness by including the\n            # current date and time in its instruction set. This can be\n            # useful when the agent needs to provide time-sensitive responses\n            # or reference current events\n            add_datetime_to_instructions=True,\n            monitoring=True,\n            markdown=True,\n            # Shows tool calls in the response\n            show_tool_calls=True,\n            # For detailed debugging information\n            debug_mode=True,\n        )\n\n        playground = Playground(agents=[agent])\n        app = playground.get_app()\n\n        # Serve the app while keeping the MCPTools context manager alive\n        serve_playground_app(app)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(run_server())\n\n```\n\n\n\n## Environment\n- Mac OS\n- Agno Version: `1.4.4`\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.",
      "state": "closed",
      "author": "Eimis",
      "author_type": "User",
      "created_at": "2025-05-04T11:52:36Z",
      "updated_at": "2025-05-04T14:16:34Z",
      "closed_at": "2025-05-04T14:16:33Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3074/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3074",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3074",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:59.224267",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Hi @Eimis !\nI tested your code and if I say something that is related to something personal, a preference, etc then the agent _decides_ to make a new user memory.  That is what `enable_agentic_memory` does. So if I say something like \"I love agents!\" then a memory is created. Since you have `enable_",
          "created_at": "2025-05-04T14:16:33Z"
        }
      ]
    },
    {
      "issue_number": 1972,
      "title": "[Bug] PythonTools fails with OpenAIChat",
      "body": "```\nAgent(\n        model=llm,\n        description=description,\n        instructions=instructions,\n        tools=[PythonTools(base_dir=Path(\"sandbox\"))],\n        show_tool_calls=False,\n        tool_call_limit=20,\n        response_model=response_model,\n        structured_outputs=True,\n        debug_mode=False,\n    )\n```\n\n```\nERROR    Error from OpenAI API: Error code: 400 - {'error': {'message': \"Invalid schema for function 'save_to_file_and_run': In context=('properties', 'variable_to_return'), schema must have a 'type' key.\",\n         'type': 'invalid_request_error', 'param': None, 'code': None}}\n<class 'TypeError'>\nYou tried to pass a `BaseModel` class to `chat.completions.create()`; You must use `beta.chat.completions.parse()` instead\n```",
      "state": "closed",
      "author": "sigren",
      "author_type": "User",
      "created_at": "2025-02-01T11:25:27Z",
      "updated_at": "2025-05-04T08:24:09Z",
      "closed_at": "2025-02-21T07:07:48Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/1972/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/1972",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/1972",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:59.462915",
      "comments": [
        {
          "author": "manthanguptaa",
          "body": "Hey @sigren! Can the whole code be shared with me?",
          "created_at": "2025-02-03T03:50:54Z"
        },
        {
          "author": "Criticalbarny01",
          "body": "I have the same issue. It's when the agent gets the structured_ooutputs=true param. The way to have structured_outputs has changed in the openai library. As the error shows it needs to use 'beta.chat.completions.parse()'.",
          "created_at": "2025-02-06T13:19:49Z"
        },
        {
          "author": "altunumut24",
          "body": "I have the same issue, any work around ?",
          "created_at": "2025-02-08T15:35:39Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@altunumut24 @Criticalbarny01 @sigren \n\nI tried the folllowing and it worked for me on the latest version of `agno` (`1.1.0`)\n```\nfrom pathlib import Path\nfrom typing import Optional\nfrom pydantic import BaseModel, Field\nfrom agno.agent import Agent\nfrom agno.models.openai import OpenAIChat\nfrom agn",
          "created_at": "2025-02-12T20:37:38Z"
        },
        {
          "author": "manthanguptaa",
          "body": "Closing due to inactivity",
          "created_at": "2025-02-21T07:07:48Z"
        }
      ]
    },
    {
      "issue_number": 3010,
      "title": "o3 and o4-mini with tools doesn't work",
      "body": "# Description\no3 and o4-mini fail to work with tools, results in this error:\n```\nItem 'fc_680a59708edc8192919fa6d8deece8d809adcab1a5183613' of type 'function_call' was provided without its required\n```\n\n## Steps to Reproduce\nSmall example agent:\n```\nagent = Agent(\n        model=OpenAIResponses(id=\"o3\"),\n        tools=[YFinanceTools(cache_results=True)],\n        show_tool_calls=True,\n        markdown=True,\n        telemetry=False,\n        monitoring=False,\n    )\n\n    response = agent.run(\"What is the current price of TSLA?\")\n```\n\n## Agent Configuration (if applicable)\nProvided above\n\n## Expected Behavior\nShould pass the tool call result to the model and get a final response\n\n## Actual Behavior\nTool call response is passed back to the model and throws errors from the API\n\n## Possible Solutions (optional)\nAs called out in this Discord message: https://discord.com/channels/965734768803192842/1365051310977847518\n\nit's because o3 and o4-mini need all of their reasoning passed back to them in subsequent calls, espically for tool calling\n\nUsing the openai SDK I was able to fix this by doing this:\nmessages.extend(response.output)\n\nconfirmed via the openAI docs: https://arc.net/l/quote/dldicbme\n",
      "state": "closed",
      "author": "DannyAziz",
      "author_type": "User",
      "created_at": "2025-04-28T19:22:56Z",
      "updated_at": "2025-05-04T07:54:57Z",
      "closed_at": "2025-05-04T07:54:56Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3010/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3010",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3010",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:59.724006",
      "comments": [
        {
          "author": "pritipsingh",
          "body": "Thanks for bringing it to our notice @DannyAziz , we're working on it and should be out soon!",
          "created_at": "2025-04-29T07:10:41Z"
        },
        {
          "author": "kausmeows",
          "body": "Hi @DannyAziz, this is an issue with how open ai expects stuff in their response api. For now you can use the same things with their normal api like this-\n```py\nfrom agno.agent import Agent\nfrom agno.models.openai import OpenAIChat\nfrom agno.tools.yfinance import YFinanceTools\n\nagent = Agent(model=O",
          "created_at": "2025-04-29T09:14:54Z"
        },
        {
          "author": "dirkbrnd",
          "body": "This fix was released with 1.4.4!",
          "created_at": "2025-05-04T07:54:56Z"
        }
      ]
    },
    {
      "issue_number": 3041,
      "title": "[Bug] In case of `Gemini` models, `tool_call_id` is always `None`",
      "body": "# Description\nWhen agent is configured to run with Gemini models, the `tool_call_id` is always `None` and as a result the `content` / response of the tool call is also missing in in `ToolCallCompleted` event.\n\nWorks fine with OpenAI models.\n\nHere is the agent script:\n```\nfrom logging import debug\nfrom agno import tools\nfrom dotenv  import load_dotenv\nload_dotenv()\n\nfrom agno.agent import Agent\nfrom agno.models.openai import OpenAIChat\nfrom agno.models.google import Gemini\nfrom agno.models.openrouter import OpenRouter\nfrom agno.models.groq import Groq\nfrom agno.tools.googlesearch import GoogleSearchTools\nfrom agno.tools.yfinance import YFinanceTools\nfrom agno.tools.crawl4ai import Crawl4aiTools\nfrom agno.storage.sqlite import SqliteStorage\nfrom agno.utils.pprint import pprint_run_response\nfrom agno.tools import FunctionCall, tool\nfrom markitdown import MarkItDown\n\nagent_storage = SqliteStorage(\n    table_name=\"agent_sessions\",\n    db_file=\"tmp/persistent_memory.db\",\n)\n\nsample_agent = Agent(\n    name=\"agno_agent\",\n    description=\"You are a helpful assistant who can search web, crawl page contents and also search financial information using given tools to achieve the given user goal.\",\n    # model=OpenAIChat(id=\"gpt-4o-mini\"),\n    model=Gemini(id=\"gemini-2.5-flash-preview-04-17\"),  # or any other supported model\n    instructions=[\n        \"If user input is not sufficent, ask user relevant questions / clarifications\",\n        \"To search the web, use google search tool.\",\n        \"To crawl the pages use crawl4ai tools\",\n        \"To get financial information about companies, use YFinance tools\"\n    ],\n    storage=agent_storage,\n    tools=[\n        GoogleSearchTools(),\n        YFinanceTools(enable_all=True),\n        Crawl4aiTools(max_length=5000)\n    ],\n    # reasoning=True,\n    stream_intermediate_steps=True,\n    add_datetime_to_instructions=True,\n    debug_mode=True\n)\n\nuser_prompt = \"whats the latest news about China\"\nfor res in sample_agent.run(user_prompt, stream=True):\n    print(f\"Response Type: {res.event}, Tools: {res.tools}\")\n```\n\nScript output:\n```\n❯ python test.py        \nDEBUG ******************************************************** Agent ID: 5dad3964-0db5-4bb9-bbf4-4b063d91c3b9 ********************************************************              \nDEBUG ******************************************************* Session ID: c6ece813-f009-409b-b406-7ee48fb06449 *******************************************************              \nDEBUG **************************************************** Agent Run Start: 68a9511b-2538-4fa6-94b4-c80bd8b5ae5b *****************************************************              \nDEBUG Processing tools for model                                                                                                                                                    \nDEBUG Added function google_search from googlesearch                                                                                                                                \nDEBUG Added function get_current_stock_price from yfinance_tools                                                                                                                    \nDEBUG Added function get_company_info from yfinance_tools                                                                                                                           \nDEBUG Added function get_stock_fundamentals from yfinance_tools                                                                                                                     \nDEBUG Added function get_income_statements from yfinance_tools                                                                                                                      \nDEBUG Added function get_key_financial_ratios from yfinance_tools                                                                                                                   \nDEBUG Added function get_analyst_recommendations from yfinance_tools                                                                                                                \nDEBUG Added function get_company_news from yfinance_tools                                                                                                                           \nDEBUG Added function get_technical_indicators from yfinance_tools                                                                                                                   \nDEBUG Added function get_historical_stock_prices from yfinance_tools                                                                                                                \nDEBUG Added function web_crawler from crawl4ai_tools                                                                                                                                \nResponse Type: RunStarted, Tools: None\nDEBUG ----------------------------------------------------------------- Google Response Stream Start -----------------------------------------------------------------              \nDEBUG ------------------------------------------------------------ Model: gemini-2.5-flash-preview-04-17 -------------------------------------------------------------              \nDEBUG ============================================================================ system ============================================================================              \nDEBUG You are a helpful assistant who can search web, crawl page contents and also search financial information using given tools to achieve the given user goal.                   \n      <instructions>                                                                                                                                                                \n      - If user input is not sufficent, ask user relevant questions / clarifications                                                                                                \n      - To search the web, use google search tool.                                                                                                                                  \n      - To crawl the pages use crawl4ai tools                                                                                                                                       \n      - To get financial information about companies, use YFinance tools                                                                                                            \n      </instructions>                                                                                                                                                               \n                                                                                                                                                                                    \n      <additional_information>                                                                                                                                                      \n      - The current time is 2025-04-30 15:19:10.711129.                                                                                                                             \n      </additional_information>                                                                                                                                                     \nDEBUG ============================================================================= user =============================================================================              \nDEBUG whats the latest news about China                                                                                                                                             \nDEBUG ========================================================================== assistant ===========================================================================              \nDEBUG Tool Calls:                                                                                                                                                                   \n          Name: 'google_search'                                                                                                                                                     \n          Arguments: 'query: latest news about China, language: en'                                                                                                                 \nDEBUG **************************************************************************  METRICS  ***************************************************************************              \nDEBUG * Tokens:                      input=1064, output=23, total=1210                                                                                                              \nDEBUG * Time:                        1.3638s                                                                                                                                        \nDEBUG * Tokens per second:           16.8651 tokens/s                                                                                                                               \nDEBUG * Time to first token:         1.3471s                                                                                                                                        \nDEBUG **************************************************************************  METRICS  ***************************************************************************              \nDEBUG Getting function google_search                                                                                                                                                \nResponse Type: ToolCallStarted, Tools: [{'role': 'tool', 'tool_call_id': None, 'tool_name': 'google_search', 'tool_args': {'query': 'latest news about China', 'language': 'en'}}]\nDEBUG Running: google_search(query=latest news about China, language=en)                                                                                                            \nDEBUG Searching Google [en] for: latest news about China                                                                                                                            \nResponse Type: ToolCallCompleted, Tools: [{'role': 'tool', 'tool_call_id': None, 'tool_name': 'google_search', 'tool_args': {'query': 'latest news about China', 'language': 'en'}}]\nDEBUG ============================================================================= tool =============================================================================              \nDEBUG [                                                                                                                                                                             \n        {                                                                                                                                                                           \n          \"title\": \"China News | Today's Breaking Stories - Reuters\",                                                                                                               \n          \"url\": \"https://www.reuters.com/world/china/\",                                                                                                                            \n          \"description\": \" Reuters.com is your online source for the latest China news stories and current events, ensuring our readers up to date with any breaking news           \n      developments. \"                                                                                                                                                               \n        },                                                                                                                                                                          \n        {                                                                                                                                                                           \n          \"title\": \"China news - breaking news, video, headlines and opinion | CNN\",                                                                                                \n          \"url\": \"https://www.cnn.com/world/china\",                                                                                                                                 \n          \"description\": \" View the latest China news and videos, including politics, travel and business headlines. \"                                                              \n        },                                                                                                                                                                          \n        {                                                                                                                                                                           \n          \"title\": \"China | Latest News & Updates - BBC\",                                                                                                                           \n          \"url\": \"https://www.bbc.com/news/world/asia/china\",                                                                                                                       \n          \"description\": \" China shares rare Moon rocks with US despite trade war. Two US institutions have been granted access to samples collected by the Chang'e-5 mission in    \n      2020. \"                                                                                                                                                                       \n        },                                                                                                                                                                          \n        {                                                                                                                                                                           \n          \"title\": \"  China exports to U.S. plunge as tariffs hit, leading some experts to warn of product shortages  \",                                                            \n          \"url\": \"https://www.cbsnews.com/news/china-exports-to-us-drop-sharply/\",                                                                                                  \n          \"description\": \" China exports to U.S. plunge as tariffs hit, leading some experts to warn of product shortages \"                                                         \n        },                                                                                                                                                                          \n        {                                                                                                                                                                           \n          \"title\": \"China Breaking News & Headlines | South China Morning Post\",                                                                                                    \n          \"url\": \"https://www.scmp.com/news/china\",                                                                                                                                 \n          \"description\": \" Latest China news, opinions and analysis, covering Xi Jinping, Beijing's relations with Taiwan and China's tensions with the US. \"                       \n        }                                                                                                                                                                           \n      ]                                                                                                                                                                             \nDEBUG ************************************************************************  TOOL METRICS  ************************************************************************              \nDEBUG * Time:                        0.3986s                                                                                                                                        \nDEBUG ************************************************************************  TOOL METRICS  ************************************************************************              \nResponse Type: RunResponse, Tools: [{'role': 'tool', 'tool_call_id': None, 'tool_name': 'google_search', 'tool_args': {'query': 'latest news about China', 'language': 'en'}}]\nResponse Type: RunResponse, Tools: [{'role': 'tool', 'tool_call_id': None, 'tool_name': 'google_search', 'tool_args': {'query': 'latest news about China', 'language': 'en'}}]\nResponse Type: RunResponse, Tools: [{'role': 'tool', 'tool_call_id': None, 'tool_name': 'google_search', 'tool_args': {'query': 'latest news about China', 'language': 'en'}}]\nResponse Type: RunResponse, Tools: [{'role': 'tool', 'tool_call_id': None, 'tool_name': 'google_search', 'tool_args': {'query': 'latest news about China', 'language': 'en'}}]\nResponse Type: RunResponse, Tools: [{'role': 'tool', 'tool_call_id': None, 'tool_name': 'google_search', 'tool_args': {'query': 'latest news about China', 'language': 'en'}}]\nDEBUG ========================================================================== assistant ===========================================================================              \nDEBUG Here are some of the latest news headlines about China based on my search:                                                                                                    \n                                                                                                                                                                                    \n      *   **China News | Today's Breaking Stories - Reuters:** Your online source for the latest China news stories and current events.                                             \n      *   **China news - breaking news, video, headlines and opinion | CNN:** View the latest China news and videos, including politics, travel and business headlines.             \n      *   **China | Latest News & Updates - BBC:** China shares rare Moon rocks with US despite trade war.                                                                          \n      *   **China exports to U.S. plunge as tariffs hit, leading some experts to warn of product shortages - CBS News:** China exports to U.S. plunge as tariffs hit, leading some  \n      experts to warn of product shortages.                                                                                                                                         \n      *   **China Breaking News & Headlines | South China Morning Post:** Latest China news, opinions and analysis, covering Xi Jinping, Beijing's relations with Taiwan and China's\n      tensions with the US.                                                                                                                                                         \n                                                                                                                                                                                    \n      You can visit these links to read the full articles and get more details on the latest developments.                                                                          \nDEBUG **************************************************************************  METRICS  ***************************************************************************              \nDEBUG * Tokens:                      input=1521, output=213, total=2009                                                                                                             \nDEBUG * Time:                        2.8240s                                                                                                                                        \nDEBUG * Tokens per second:           75.4250 tokens/s                                                                                                                               \nDEBUG * Time to first token:         1.9939s                                                                                                                                        \nDEBUG **************************************************************************  METRICS  ***************************************************************************              \nDEBUG ------------------------------------------------------------------ Google Response Stream End ------------------------------------------------------------------              \nDEBUG Added 4 Messages to AgentMemory                                                                                                                                               \nDEBUG Added AgentRun to AgentMemory                                                                                                                                                 \nResponse Type: UpdatingMemory, Tools: [{'role': 'tool', 'tool_call_id': None, 'tool_name': 'google_search', 'tool_args': {'query': 'latest news about China', 'language': 'en'}}]\nDEBUG Logging Agent Run                                                                                                                                                             \nDEBUG ***************************************************** Agent Run End: 68a9511b-2538-4fa6-94b4-c80bd8b5ae5b ******************************************************              \nResponse Type: RunCompleted, Tools: [{'role': 'tool', 'tool_call_id': None, 'tool_name': 'google_search', 'tool_args': {'query': 'latest news about China', 'language': 'en'}}]\n```\n\nPossible solution:\nI think its happening as [here](https://github.com/agno-agi/agno/blame/3277815e99600b58afed88376f8b139042c4f3c3/libs/agno/agno/models/google/gemini.py#L725) and [here](https://github.com/agno-agi/agno/blame/3277815e99600b58afed88376f8b139042c4f3c3/libs/agno/agno/models/google/gemini.py#L661) we are not setting `id` and `call_id`, which we are setting in case of OpenAI. I did not check how this is handled in case of other LLM providers.\n\nIn my local test, after setting `id` and `call_id` to UUID, I was able to see that it works fine. I will raise a PR for this bug.",
      "state": "closed",
      "author": "gauravdhiman",
      "author_type": "User",
      "created_at": "2025-05-01T01:53:03Z",
      "updated_at": "2025-05-04T07:52:51Z",
      "closed_at": "2025-05-04T07:52:50Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3041/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3041",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3041",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:26:59.903341",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Released with 1.4.4!",
          "created_at": "2025-05-04T07:52:50Z"
        }
      ]
    },
    {
      "issue_number": 3069,
      "title": "[Bug] YFinance Rate Limited",
      "body": "YFinance Tool returns error after each call, every time with no success.\n\n\"Error fetching current price for AAPL: Too Many Requests. Rate limited. Try after a while.\"\n",
      "state": "closed",
      "author": "conmeara",
      "author_type": "User",
      "created_at": "2025-05-03T20:41:29Z",
      "updated_at": "2025-05-03T20:50:06Z",
      "closed_at": "2025-05-03T20:50:06Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3069/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3069",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3069",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:00.083090",
      "comments": []
    },
    {
      "issue_number": 2695,
      "title": "[Bug] Inconsistency with output in agno/run/response.py",
      "body": "# Description\nI found an inconsistency with how response.py handles responses in the from_dict function\n\n## Steps to Reproduce\nNot sure , Teams have memory , meaning team 1 and team 2 and master  in my setup . also all agents and teams have a shared storage .The agents have acess to the same knowledge base.\n\n## Agent Configuration (if applicable)\nI have an this setup of agents : master (team agent with route mode) ,which includes these members . first team1 (team with coordinate with agents as members ) , team 2 (same as team 1 ) and finally a report generator agent . These are all members of master team\n\n## Expected Behavior\nProvide an output with sources meaning including the extra_data variable in the output as far as i can understand.\n\n## Actual Behavior\nThe extra_data attribute in  RunResponse class is expected to be an instance of RunResponseExtraData, which has a to_dict() method. However, it seems that at some point, extra_data is being set to a dict instead of an instance of RunResponseExtraData. This leads to the AttributeError when to_dict() is called.\n\n## Screenshots or Logs (if applicable)\nNot available\n\n## Environment\n- OS: (e.g. macOS, Windows 11)\n\n- Agno Version: (e.g. v1.2.6)\n- Additional Environment Details: (e.g., Python 3.11.9)\n\n## Possible Solutions (optional)\nFound a solution for this , although i do not know if it is optimal . Any ideas for a better solution to mine is welcome . So far it seems to work as intended and fixed the issue , but i am only tesing the master in terminal with print_response .\n\nProposed Solution by me:\nin agno/run/response.py \nSOLUTION LINE 145\nFROM    ->     return cls(messages=messages, **data)\nTO ->\nextra_data = data.pop(\"extra_data\", None) #CUSTOM IMPLEMENTATION IN AGNO \nif extra_data is not None:\nextra_data = RunResponseExtraData.from_dict(extra_data)  # Ensure it's an instance",
      "state": "closed",
      "author": "NikitasT2003",
      "author_type": "User",
      "created_at": "2025-04-05T17:51:41Z",
      "updated_at": "2025-05-02T17:55:35Z",
      "closed_at": "2025-05-02T17:55:34Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2695/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2695",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2695",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:00.083167",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-20T00:35:58Z"
        },
        {
          "author": "Ayush0054",
          "body": "Hey @NikitasT2003,\nReally sorry for the late reply!\nWe are looking into this issue — thanks a lot for pointing it out. 🙌\n",
          "created_at": "2025-04-26T19:11:42Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @NikitasT2003 \nI see the version of Agno you have is slightly outdated. On the current version this is fixed. Thanks again for raising!",
          "created_at": "2025-05-02T17:55:34Z"
        }
      ]
    },
    {
      "issue_number": 3046,
      "title": "[Bug]",
      "body": "# Description\nRunning a workflow from a previous version of agno fails on new version. It seems workflow session_ids cannot be re-used after upgrading. I'm not sure if this is intended to be supported behavior\n\n## Steps to Reproduce\n1. Run a workflow with an agno version < 1.4 (before the new memories were implemented)\n2. Upgrade agno to the latest\n3. Run the workflow again with the same session id\n5. Call pprint_run_response() on the workflow\n \n## Agent Configuration (if applicable)\nN/A\n\n## Expected Behavior\nThe run_response to print as shown in the docs\n\n## Actual Behavior\nAn error was thrown\n\n## Screenshots or Logs (if applicable)\n```\npprint_run_response(res)\nFile \"/usr/local/lib/python3.12/site-packages/agno/utils/pprint.py\", line 54, in pprint_run_response\nfor resp in run_response:\n^^^^^^^^^^^^\nFile \"/usr/local/lib/python3.12/site-packages/agno/workflow/workflow.py\", line 202, in result_generator\nself.memory.add_run(session_id=self.session_id, run=self.run_response) # type: ignore\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile \"/usr/local/lib/python3.12/site-packages/agno/memory/v2/memory.py\", line 672, in add_run\nself.runs.setdefault(session_id, []).append(run)\n^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'list' object has no attribute 'setdefault'\n```\n\n## Environment\n- OS: (debian)\n- Agno Version: 1.4.3\n- Additional Environment Details: (e.g., Python 3.12)\n\n## Additional Context\nN/A\n",
      "state": "closed",
      "author": "FredAtNeo",
      "author_type": "User",
      "created_at": "2025-05-01T09:31:10Z",
      "updated_at": "2025-05-02T17:26:40Z",
      "closed_at": "2025-05-02T17:26:40Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3046/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3046",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3046",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:00.306646",
      "comments": [
        {
          "author": "mishramonalisha76",
          "body": "Hi @FredAtNeo , thanks for pointing this out . The pr with the fix is out and it should be out in the next sdk release.",
          "created_at": "2025-05-02T15:00:47Z"
        }
      ]
    },
    {
      "issue_number": 2987,
      "title": "[Bug] Setting include_tools breaks MCPTool",
      "body": "# Description\nSetting include_tools breaks MCPTool\n\n## Steps to Reproduce\n```\nserver_params = MCPStdioParams(\n            command=\"docker\",\n            args=[\n                \"run\",\n                \"-i\",\n                \"--rm\",\n                \"--mount\",\n                f\"type=bind,src={tmp_path},dst=/projects\",\n                \"mcp/filesystem\",\n                \"/projects\",\n            ],\n            tools=[\n                \"write_file\",\n                \"read_file\"\n            ],\n        ),\nMCPTools(\n            command=server_params,\n            include_tools=[\"write_file\"],\n            env={**os.environ},\n  )\n```\n\n## Agent Configuration (if applicable)\nn/a\n\n## Expected Behavior\nNo crash\n\n## Actual Behavior\n\n```\n            if include_tools:\n                missing_includes = set(include_tools) - available_tools\n                if missing_includes:\n>                   raise ValueError(f\"Included tool(s) not present in the toolkit: {', '.join(missing_includes)}\")\nE                   ValueError: Included tool(s) not present in the toolkit: write_file\n\n.venv/lib/python3.12/site-packages/agno/tools/toolkit.py:51: ValueError\n```\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- Agno Version: 1.4.2\n\n## Possible Solutions (optional)\nThe problem I think is that `MCPTools` is calling `    super().__init__(name=\"MCPToolkit\", include_tools=include_tools, exclude_tools=exclude_tools, **kwargs)` and not passing in `tools` so then in that base class, tools is an empty list so the error happens\n\n## Additional Context\n\nI think some changes happened in agno 1.4 that made MCP less stable. I put a lot of work into writing a unit test on my side to check MCP functionality for filtering tools, maybe it would be a helpful thing to put into agno? https://github.com/mozilla-ai/any-agent/pull/152/files#diff-e52e4ddd58b7ef887ab03c04116e676f6280b824ab7469d5d3080e5cba4f2128 \n",
      "state": "closed",
      "author": "njbrake",
      "author_type": "User",
      "created_at": "2025-04-25T12:11:53Z",
      "updated_at": "2025-05-02T17:22:47Z",
      "closed_at": "2025-05-02T17:22:47Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2987/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2987",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2987",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:00.510526",
      "comments": [
        {
          "author": "njbrake",
          "body": "PR for the fix I think is in https://github.com/mozilla-ai/any-agent/pull/152#issuecomment-2830058294",
          "created_at": "2025-04-25T12:17:15Z"
        }
      ]
    },
    {
      "issue_number": 2709,
      "title": "[Feature Request] Consider enhancing AWS credentials management for Bedrock integration",
      "body": "Hi team! 👋\n\nFirst, thanks for creating this amazing library - I've been enjoying using it for my multimodal agent projects.\n\n## Problem Description\n\nThe current `boto3` client creation for Bedrock only supports hard-coded credentials and doesn't allow passing additional arguments to the Bedrock client. This creates security compliance challenges in some environments and somehow doesn't align with AWS best practices for credential management. This limitation not only restricts customization of client behavior but also limits adoption in security-conscious organizations that prohibit hardcoded credentials in code.\n\nI understand that you already support passing a boto3 session to handle authentication, which is great. However, it might be beneficial to either allow passing a fully pre-configured client directly or enable the session parameter to accept additional `kwargs` that would be forwarded when creating the Bedrock client internally. This would provide more flexibility for configuring proxies, timeouts, retries, and other client-specific settings that many specific environments require.\n\nWould you be open to enhancing this with more flexible credential and client options? This would be really helpful for security compliance in enterprise environments and could help drive adoption.\n\n## Proposed Solution\n\n### Accept a pre-configured client\n\n```python\nimport boto3\nfrom botocore.config import Config\nfrom agno.agent import Agent\nfrom agno.models.aws import AwsBedrock\n\nmodel = AwsBedrock()\n\n\n# Configure proxy settings\nproxy_config = Config(\n    proxies={\n        'http': 'http://proxy.example.com:8080',\n        'https': 'https://proxy.example.com:8080'\n    }\n)\n\n# Create session with profile and client with proxy config\nsession = boto3.Session(profile_name='my-secure-profile')\ncustom_client = session.client(\n    'bedrock-runtime', \n    region_name='us-west-2',\n    config=proxy_config\n)\n\n# Pass the pre-configured client to AwsBedrock\nmodel = AwsBedrock(id=\"mistral.mistral-large-2402-v1:0\", bedrock_client=custom_client)\n\nagent = Agent(\n    model=model,\n    markdown=True\n)\n\n# Print the response on the terminal\nagent.print_response(\"Share a 2 sentence horror story.\")\n```\n\nI'd be happy to help implement this and update the documentation if you're interested in the idea. What do you think?\n\n## Alternatives Considered\n\nAllow pass `kwagrs` to the client and session.\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[x] Yes, I’d love to work on it!**\n**[ ] I’m open to collaborating but need guidance.**\n**[ ] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "leandrodamascena",
      "author_type": "User",
      "created_at": "2025-04-07T10:55:28Z",
      "updated_at": "2025-05-02T16:26:45Z",
      "closed_at": "2025-05-02T16:26:45Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2709/reactions",
        "total_count": 2,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 1,
        "rocket": 0,
        "eyes": 1
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2709",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2709",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:00.693649",
      "comments": [
        {
          "author": "baileydoestech",
          "body": "+1 on this - currently a blocker to any real evaluation ",
          "created_at": "2025-04-07T12:49:11Z"
        },
        {
          "author": "monali7-d",
          "body": "Hi @baileydoestech @leandrodamascena \nThank you for using Agno and sharing the feature request with us.\nI have added this to our community Wishlist. We will take some time to discuss this internally and get back to you!",
          "created_at": "2025-04-08T06:32:15Z"
        },
        {
          "author": "dreamorosi",
          "body": "Hi @monali7-d - why was the issue closed as completed? \n\nIs there any place where we can follow up on this discussion and/or see the community wishlist?\n\nAlso just to be clear, we're willing to contribute the feature if you decide to add it to the backlog.",
          "created_at": "2025-04-08T07:17:10Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @dreamorosi,\nApologies for the confusion! We typically close issues if there hasn’t been any activity or response from the user for over 2 weeks—just to keep things tidy.\n\nThat said, we’re always open to valuable contributions. If you're still interested, please feel free to go ahead and impleme",
          "created_at": "2025-04-23T09:00:19Z"
        },
        {
          "author": "leandrodamascena",
          "body": "Hey @monali7-d! I'll send a PR early next week. \n\nThanks for reopening this.",
          "created_at": "2025-04-23T13:18:22Z"
        }
      ]
    },
    {
      "issue_number": 2991,
      "title": "[Bug] namespace parameter in vectordb.pinecone not respected",
      "body": "# Description\nWhen specifying namespace in pinecone index, it is not respected and documents are upserted and doc_exist-checked in default namespace. \n\n## Steps to Reproduce\nSpecify namespace when initializing vectordb\nDo upsert of any Document\nCheck in pinecone - the Document is in default namespace ('')\n\n\n```\nfrom agno.knowledge.website import WebsiteKnowledgeBase\nfrom agno.vectordb.pineconedb import PineconeDb\nfrom agno.utils.log import set_log_level_to_debug\nfrom os import getenv\nfrom agno.document import Document\n\nset_log_level_to_debug()\n\nurl = \"https://help.company.store/article/87-how-can-i-set-up-a-disclaimer-or-terms-of-conditions-for-my-customers\"\n\nknowledge_base = WebsiteKnowledgeBase(\n    urls=[url],\n    max_depth=2,\n    max_links=1,\n    vector_db=PineconeDb(\n        name=\"test\",\n        namespace=\"helpdocs\",\n        dimension=1536,\n        api_key=getenv(\"PINECONE_API\"),\n        spec=dict(serverless=dict(cloud=\"aws\", region=\"us-east-1\"))\n    ),\n)\nknowledge_base.vector_db.upsert([Document(\n    name=url, id=str(12), meta_data={\"url\": str(url)}, content=\"test content\"\n)])\n```\n\n## Agent Configuration (if applicable)\nNot applicable\n\n## Expected Behavior\nDocument should be upserted in specified namespace\n\n## Actual Behavior\nDocument was upserted in default namespace\n\n## Screenshots or Logs (if applicable)\n\n<img width=\"1142\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/0e631c86-951b-4731-9681-717525164538\" />\n\n## Environment\n- OS: Not relevant\n- Browser (if relevant): Not relevant\n- Agno Version: 1.4.1\n- External Dependency Versions: pinecone==5.4.2\n- Additional Environment Details: setup with provided dev script\n\n## Possible Solutions (optional)\nPR fixing that here https://github.com/agno-agi/agno/pull/2973\n\n## Additional Context\nChecked Pinecone API docs for v.5.4.2 - namespace argument is supported in:\nindex/upsert - used in agno.vectordb.pineconedb.upsert - sync requires fix, async version was already ok\nindex/query - used in agno.vectordb.pineconedb.search - sync/async ok in existing code\nvectors/fetch - used in agno.vectordb.pineconedb.doc_exists - sync requires fix, async already ok\nvectors/update, vectors/delete, vectors/list - not used in agno.vectordb.pineconedb\n",
      "state": "closed",
      "author": "5739n4",
      "author_type": "User",
      "created_at": "2025-04-25T14:35:03Z",
      "updated_at": "2025-05-02T12:14:23Z",
      "closed_at": "2025-05-02T12:14:23Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2991/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2991",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2991",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:02.673755",
      "comments": [
        {
          "author": "mishramonalisha76",
          "body": "Hi @5739n4,\nThank you for proactively raising a fix for the issue — we truly appreciate your contribution! 🙌\nThe fix has been reviewed and will be included in the upcoming SDK release.",
          "created_at": "2025-04-30T07:08:40Z"
        },
        {
          "author": "5739n4",
          "body": "Hi @mishramonalisha76 @ysolanky @manuhortet,\nwill #2973 be included in some upcoming release?",
          "created_at": "2025-04-30T20:12:50Z"
        },
        {
          "author": "manuhortet",
          "body": "The fix has been merged and will be in the next release. Thanks again @5739n4!",
          "created_at": "2025-05-02T12:14:17Z"
        }
      ]
    },
    {
      "issue_number": 2554,
      "title": "integrating human feedback into a agent.",
      "body": "## Problem Description\nif any way of integrating human feedback into a agent? like langgraph human-in-the-loop patterns.\n\n## Proposed Solution\nAgent can interact with users during the execution proces\n\n\n",
      "state": "closed",
      "author": "ruidanwang",
      "author_type": "User",
      "created_at": "2025-03-26T04:41:06Z",
      "updated_at": "2025-05-01T10:51:53Z",
      "closed_at": "2025-03-27T06:18:34Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2554/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2554",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2554",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:02.874345",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hey @ruidanwang, Thank you for reaching out and using Agno.\nWe do have HITL capabilities in Agno, please refer https://docs.agno.com/examples/getting-started/human-in-the-loop#human-in-the-loop\n\nPlease lmk incase you have doubts",
          "created_at": "2025-03-26T05:04:27Z"
        },
        {
          "author": "ruidanwang",
          "body": "thanks,in user guide i not found .",
          "created_at": "2025-03-26T05:07:21Z"
        },
        {
          "author": "manthanguptaa",
          "body": "Hey @ruidanwang! Here are the docs for Human in the loop\nhttps://docs.agno.com/examples/getting-started/human-in-the-loop#human-in-the-loop\nand here is the cookbook for the same https://github.com/agno-agi/agno/blob/main/cookbook/getting_started/19_human_in_the_loop.py\n\nLet us know if you face any i",
          "created_at": "2025-03-26T05:15:51Z"
        },
        {
          "author": "ruidanwang",
          "body": "thanks @monali7-d  @manthanguptaa ",
          "created_at": "2025-03-26T05:21:38Z"
        },
        {
          "author": "meetzuber",
          "body": "Hi\n\nHow can we use HITL using API. I want to use this as human approval before executing some tools. any example of using this as API endpoint.\n\nThanks",
          "created_at": "2025-05-01T10:51:52Z"
        }
      ]
    },
    {
      "issue_number": 3015,
      "title": "[Feature Request] https://community.agno.com/t/azure-ai-search-integration-with-agentic-rag-for-embeddings/1079?u=monali",
      "body": "## Problem Description\nProvide a clear and concise explanation of the issue you're facing.\n**Example:** *\"I often find it frustrating when [...] because [...]”*\n\n## Proposed Solution\nExplain your ideal solution. How should this feature work?\nBe as detailed as possible to help us understand your vision.\n\n## Alternatives Considered\nHave you found any workarounds or alternative solutions?\nShare other approaches you've tried or thought about.\n\n## Additional context\nInclude any extra information that might be helpful, such as:\n- Screenshots\n- Examples of similar features elsewhere\n- Any relevant links or references\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[ ] Yes, I’d love to work on it!**\n**[ ] I’m open to collaborating but need guidance.**\n**[ ] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "monali7-d",
      "author_type": "User",
      "created_at": "2025-04-29T07:58:53Z",
      "updated_at": "2025-04-30T05:46:45Z",
      "closed_at": "2025-04-30T05:46:45Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/3015/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/3015",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/3015",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:03.068717",
      "comments": []
    },
    {
      "issue_number": 2990,
      "title": "[Feature Request] Support o4-mini for reasoning",
      "body": "## Problem Description\nCurrent, agno do not support o4-mini for reasoning.\nhttps://github.com/agno-agi/agno/blob/main/libs/agno/agno/reasoning/openai.py#L11\n\n```python\ndef is_openai_reasoning_model(reasoning_model: Model) -> bool:\n    return (\n        (\n            reasoning_model.__class__.__name__ == \"OpenAIChat\"\n            or reasoning_model.__class__.__name__ == \"OpenAIResponses\"\n            or reasoning_model.__class__.__name__ == \"AzureOpenAI\"\n        )\n        and (\n            (\"o3\" in reasoning_model.id)\n            or (\"o1\" in reasoning_model.id)\n            or (\"4.1\" in reasoning_model.id)\n            or (\"4.5\" in reasoning_model.id)\n        )\n    ) or (isinstance(reasoning_model, OpenAILike) and \"deepseek-r1\" in reasoning_model.id.lower())\n```\n\nThere is a named match on this.\n\nError message:\n\n`WARNING  Reasoning model: OpenAIResponses is not a native reasoning model, defaulting to manual Chain-of-Thought reasoning`\n\n## Proposed Solution\nWe can have a way to users define witch model they wanna use, not a hardcoded list like this.\n\n## Alternatives Considered\nA quick solution for now is to add `o4` match and just fix it.\n```python\ndef is_openai_reasoning_model(reasoning_model: Model) -> bool:\n    return (\n        (\n            reasoning_model.__class__.__name__ == \"OpenAIChat\"\n            or reasoning_model.__class__.__name__ == \"OpenAIResponses\"\n            or reasoning_model.__class__.__name__ == \"AzureOpenAI\"\n        )\n        and (\n            (\"o4\" in reasoning_model.id) #New o4 reasoning model\n            or (\"o3\" in reasoning_model.id)\n            or (\"o1\" in reasoning_model.id)\n            or (\"4.1\" in reasoning_model.id)\n            or (\"4.5\" in reasoning_model.id)\n        )\n    ) or (isinstance(reasoning_model, OpenAILike) and \"deepseek-r1\" in reasoning_model.id.lower())\n```\n\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[X] Yes, I’d love to work on it!**\n**[X] I’m open to collaborating but need guidance.**\n**[ ] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "emerleite",
      "author_type": "User",
      "created_at": "2025-04-25T13:48:38Z",
      "updated_at": "2025-04-28T20:29:16Z",
      "closed_at": "2025-04-28T20:29:16Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2990/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2990",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2990",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:03.068738",
      "comments": [
        {
          "author": "mishramonalisha76",
          "body": "Hi @emerleite,\n\nThanks a lot for pointing this out!\nOur team will work on making it more flexible soon. But since being an open source project , we also encourage community contributions. You are open to raise a pr to fix this issue.\nIn the meantime, I encourage you to explore some of the other [rea",
          "created_at": "2025-04-26T05:25:32Z"
        }
      ]
    },
    {
      "issue_number": 2919,
      "title": "[Bug] Reliability eval not working as expected when using VertexAI",
      "body": "# Description\nWhen using vertexai models, failed tool list is returning an array with None elements instead of an empty array causing the test to fail\n\n## Steps to Reproduce\nRun reliability example using vertexai instead of openai:\nhttps://github.com/agno-agi/agno/blob/main/evals/reliability/single_tool_calls/openai/calculator.py\n\n## Agent Configuration (if applicable)\nagent=Agent(\n        model=Gemini(\n            id=\"gemini-2.0-flash-001\",\n             vertexai=True\n        ),\n        tools=[CalculatorTools(add=True, multiply=True, exponentiate=True)]\n)\n\n## Expected Behavior\nFailed Tool Calls should be an empty array to be able to pass\n\n## Actual Behavior\nFailed Tool Calls is returning an array with two elements with value None\n\n## Screenshots or Logs (if applicable)\n\nWhen using vertexai:\nEvaluation Status: FAILED\nFailed Tool Calls: [None, None]\nPassed Tool Calls: ['exponentiate', 'multiply']\n\nWhen using openai:\nEvaluation Status: PASSED\nFailed Tool Calls: []\nPassed Tool Calls: ['exponentiate', 'multiply']\n\n## Environment\n- Agno Version: v1.3.5\n",
      "state": "closed",
      "author": "snypech",
      "author_type": "User",
      "created_at": "2025-04-21T23:47:04Z",
      "updated_at": "2025-04-28T18:01:16Z",
      "closed_at": "2025-04-28T18:01:16Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2919/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "manuhortet"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2919",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2919",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:03.249272",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @snypech ! Thanks for raising this! We are currently working on improving our evals and this is really helpful. A fix for this will be out soon",
          "created_at": "2025-04-28T08:40:16Z"
        },
        {
          "author": "manuhortet",
          "body": "Thanks for reporting @snypech, a fix is on its way! ",
          "created_at": "2025-04-28T16:10:48Z"
        }
      ]
    },
    {
      "issue_number": 2929,
      "title": "[Bug] agno.exceptions.ModelProviderError: <400> InternalError.Algo.InvalidParameter: The tool call is not supported.",
      "body": "I use openailike to build a simple agent but comes up with an tool call error.\n\n## code:\nimport os\nfrom dotenv import load_dotenv\nfrom agno.agent import Agent, RunResponse\nfrom agno.models.openai.like import OpenAILike\nfrom agno.tools.yfinance import YFinanceTools\n\nload_dotenv()\n\nagent = Agent(\n    model=OpenAILike(\n        id=os.getenv(\"DASHSCOPE_MODEL_DSV3\"),\n        api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n        base_url=os.getenv(\"DASHSCOPE_API_BASE\"),\n    ),\n    tools=[\n        YFinanceTools(stock_price=True)\n    ],\n    instructions=[\n        \"Use tables to display data.\",\n        \"Only include tables in answers.\"\n    ],\n    markdown=True\n    )\n\nagent.print_response(\"What is the stock price of Apple?\", stream=True)\n\n## error：\nERROR    API status error from OpenAI API: Error code: 400 - {'error': {'code': 'invalid_parameter_error', 'param': None, 'message': '<400>                       \n         InternalError.Algo.InvalidParameter: The tool call is not supported.', 'type': 'invalid_request_error'}, 'id':                                           \n         'chatcmpl-37818767-085f-92c5-9abc-36abf797edab', 'request_id': '37818767-085f-92c5-9abc-36abf797edab'}                                                   \n▰▱▱▱▱▱▱ Thinking...\n┏━ Message ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                                                                                                                ┃\n┃ What is the stock price of Apple?                                                                                                                              ┃\n┃                                                                                                                                                                ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\nTraceback (most recent call last):\n  File \"/home/linrui/miniconda3/envs/mixrag/lib/python3.11/site-packages/agno/models/openai/chat.py\", line 441, in invoke_stream\n    yield from self.get_client().chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/linrui/miniconda3/envs/mixrag/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/linrui/miniconda3/envs/mixrag/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 914, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/linrui/miniconda3/envs/mixrag/lib/python3.11/site-packages/openai/_base_client.py\", line 1242, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/linrui/miniconda3/envs/mixrag/lib/python3.11/site-packages/openai/_base_client.py\", line 919, in request\n    return self._request(\n           ^^^^^^^^^^^^^^\n  File \"/home/linrui/miniconda3/envs/mixrag/lib/python3.11/site-packages/openai/_base_client.py\", line 1023, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'code': 'invalid_parameter_error', 'param': None, 'message': '<400> InternalError.Algo.InvalidParameter: The tool call is not supported.', 'type': 'invalid_request_error'}, 'id': 'chatcmpl-37818767-085f-92c5-9abc-36abf797edab', 'request_id': '37818767-085f-92c5-9abc-36abf797edab'}\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/linrui/projects/llm4TDA/agent/1.py\", line 26, in <module>\n    agent.print_response(\"What is the stock price of Apple?\", stream=True)\n  File \"/home/linrui/miniconda3/envs/mixrag/lib/python3.11/site-packages/agno/agent/agent.py\", line 4426, in print_response\n    for resp in self.run(\n  File \"/home/linrui/miniconda3/envs/mixrag/lib/python3.11/site-packages/agno/agent/agent.py\", line 646, in _run\n    for model_response_chunk in self.model.response_stream(messages=run_messages.messages):\n  File \"/home/linrui/miniconda3/envs/mixrag/lib/python3.11/site-packages/agno/models/base.py\", line 514, in response_stream\n    yield from self.process_response_stream(\n  File \"/home/linrui/miniconda3/envs/mixrag/lib/python3.11/site-packages/agno/models/base.py\", line 486, in process_response_stream\n    for response_delta in self.invoke_stream(messages=messages):\n  File \"/home/linrui/miniconda3/envs/mixrag/lib/python3.11/site-packages/agno/models/openai/chat.py\", line 476, in invoke_stream\n    raise ModelProviderError(\nagno.exceptions.ModelProviderError: <400> InternalError.Algo.InvalidParameter: The tool call is not supported.\n",
      "state": "closed",
      "author": "7vw58n3ftvq7cn89v",
      "author_type": "User",
      "created_at": "2025-04-22T16:31:27Z",
      "updated_at": "2025-04-28T08:38:41Z",
      "closed_at": "2025-04-28T08:38:39Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2929/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2929",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2929",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:03.469600",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hey @7vw58n3ftvq7cn89v ! Looks like the model that you are using with `OpenAILike` does not support Tool calling and the error is being raised from the model directly. \n\nIn order to use Tools with an Agent, the model needs to support tool calling",
          "created_at": "2025-04-28T08:38:39Z"
        }
      ]
    },
    {
      "issue_number": 2803,
      "title": "[Bug] Silenced exceptions",
      "body": "# Description\nException silencing in website reader is problematic. \n\n![Image](https://github.com/user-attachments/assets/d9c684bc-b4f0-483d-8b75-5940e8ec9107)\n\nThis means that we can not catch this exception in a higher level tool and return an appropriate error. Instead we only get a printout and then an empty list is returned. This is not just limited to this function - there is a lot of exception silencing going on in that file. \n\nWhat we should be doing instead is perhaps print a warning and then raise a CrawlError exception or something like that. Or even HTTP exception. \n",
      "state": "closed",
      "author": "mkschreder",
      "author_type": "User",
      "created_at": "2025-04-13T12:08:09Z",
      "updated_at": "2025-04-28T07:48:19Z",
      "closed_at": "2025-04-28T07:48:18Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2803/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "willemcdejongh"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2803",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2803",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:03.683519",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Thank you for bringing this up, @mkschreder. We've submitted a PR with improvements addressing this",
          "created_at": "2025-04-28T07:48:18Z"
        }
      ]
    },
    {
      "issue_number": 2186,
      "title": "[Bug] Gemini tools and response_model are incompatible",
      "body": "# Description\nGemini `tools` and `response_model` are incompatible\n\nCurrently, if you declare any tools and `response_model` argument, Gemini will throw an error saying \n\n```\ngoogle.genai.errors.ClientError: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': \"For controlled generation of only function calls (forced function calling), please set 'tool_config.function_calling_config.mode' field to ANY instead of populating 'response_mime_type' and 'response_schema' fields. For more details, see: https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling#tool-config\", 'status': 'INVALID_ARGUMENT'}}\n```\nI put the `tool_config` inside of request argument, and it doesn't work, persist the same error, but if i remove the `response_schema` and `response_mime_type` it work, but without the response schema\n\nScratching the code I found with that those combined arguments throw the error, I made an application with pydantic-ai and this error doesn't appear, because the `response_model` has inside of tools like `final_result` tool.\n\nSo, I can make a PR with these changes, and I want to ask, are you fine with this approach?\n\napproach:\nWhen you run an Agent and making the [request kwargs with tools](https://github.com/agno-agi/agno/blob/d3cceaf34db84f57d694be3f446a976aaa80a201/libs/agno/agno/models/google/gemini.py#L283C16-L283C16)\n\n1. check if you have `response_schema`\n  - if not, dont do it anything\n2. if yes\n3. append from `response_schema` as a new tool called `final_result`\n  - descrition: `Final result.`\n  - with the parameters of the object (for now only support pydantic BaseModel)\n4. remove `response_schema`\n5. remove `response_mime_type`\n6. ... (make the request to gemini)\n7. when [parse the tools](https://github.com/agno-agi/agno/blob/d3cceaf34db84f57d694be3f446a976aaa80a201/libs/agno/agno/models/google/gemini.py#L643C38-L643C38)\n8. check the tool name has `final_result`\n  - if not, dont do anythinh \n9. if so, put the answer with `json.dumps(part.function_call.args)` into `model_response.content`\n\nI think is a little tangled to avoid the gemini error, but will work\n\n\n## Steps to Reproduce\n\nThis is an example to reproduce the error\n\n```python\nimport os\n\nfrom agno.agent import Agent\nfrom agno.models.google import Gemini\nfrom agno.tools.googlesearch import GoogleSearchTools\nfrom agno.workflow import RunResponse\nfrom pydantic import BaseModel, Field\n\nif os.getenv(\"GOOGLE_API_KEY\") is None:\n    os.environ[\"GOOGLE_API_KEY\"] = \"API-KEY\"\nif os.getenv(\"OPENAI_API_KEY\") is None:\n    os.environ[\"OPENAI_API_KEY\"] = \"API-KEY\"\n\n\nclass IdeaClarification(BaseModel):\n    originality: str = Field(..., description=\"Originality of the idea.\")\n    mission: str = Field(..., description=\"Mission of the company.\")\n    objectives: str = Field(..., description=\"Objectives of the company.\")\n\n\nidea_clarifier_agent: Agent = Agent(\n    model=Gemini(\n        id=\"gemini-2.0-flash\",\n        # id=\"gemini-1.5-flash\",\n        # id=\"gemini-2.0-flash-exp\",\n        # id=\"gemini-2.0-flash-lite-preview-02-05\",\n        generation_config={},\n    ),\n    # model=OpenAIChat(id=\"gpt-4o-mini\"),\n    instructions=[\n        \"Given a user's startup idea, its your goal to refine that idea. \",\n        \"Evaluates the originality of the idea by comparing it with existing concepts. \",\n        \"Define the mission and objectives of the startup.\",\n    ],\n    add_history_to_messages=True,\n    add_datetime_to_instructions=True,\n    response_model=IdeaClarification,\n    structured_outputs=True,\n    tools=[GoogleSearchTools()],\n    debug_mode=False,\n)\n\nidea = \"A marketplace for Christmas Ornaments made from leather\"\nresponse: RunResponse = idea_clarifier_agent.run(idea)\n\nprint(response.content)\n\n```\n\n## Expected Behavior\nRun succesfully the model with `response_model` and `tools`\n\n## Actual Behavior\nthrow the follow error:\n\n```\ngoogle.genai.errors.ClientError: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': \"For controlled generation of only function calls (forced function calling), please set 'tool_config.function_calling_config.mode' field to ANY instead of populating 'response_mime_type' and 'response_schema' fields. For more details, see: https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling#tool-config\", 'status': 'INVALID_ARGUMENT'}}\n```\n\n## Environment\n- OS: Ubuntu 24.04\n- Agno Version: `1.1.4`, `1.1.3`, `1.1.2` tested\n- External Dependency Versions: `googlesearch-python` `pycountry`\n- Additional Environment Details: Python 3.12.9\n\n## Possible Solution\n<details>\n <summary>Possible Solution</summary>\n\nI can make a PR with these changes, and I want to ask, are you fine with this approach?\n\napproach:\nWhen you run an Agent and making the [request kwargs with tools](https://github.com/agno-agi/agno/blob/d3cceaf34db84f57d694be3f446a976aaa80a201/libs/agno/agno/models/google/gemini.py#L283C16-L283C16)\n\n1. check if you have `response_schema`\n  - if not, dont do it anything\n2. if yes\n3. append from `response_schema` as a new tool called `final_result`\n  - descrition: `Final result.`\n  - with the parameters of the object (for now only support pydantic BaseModel)\n4. remove `response_schema`\n5. remove `response_mime_type`\n6. ... (make the request to gemini)\n7. when [parse the tools](https://github.com/agno-agi/agno/blob/d3cceaf34db84f57d694be3f446a976aaa80a201/libs/agno/agno/models/google/gemini.py#L643C38-L643C38)\n8. check the tool name has `final_result`\n  - if not, dont do anythinh \n9. if so, put the answer with `json.dumps(part.function_call.args)` into `model_response.content`\n</details>\n\n## Additional Context\nTo avoid this current problem i move to openai for a while\n",
      "state": "closed",
      "author": "mvaldi",
      "author_type": "User",
      "created_at": "2025-02-19T12:32:31Z",
      "updated_at": "2025-04-26T17:11:07Z",
      "closed_at": "2025-02-19T18:39:08Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2186/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2186",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2186",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:03.850702",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "@mvaldi This seems to be an issue with JSON mode and function calling not supported by Gemini's SDK at the moment. [See here](https://github.com/google-gemini/cookbook/issues/393)\n\nIf you remove `structured_output=True`, it won't use Gemini's native structured output but the agent will take the JSON",
          "created_at": "2025-02-19T14:37:05Z"
        },
        {
          "author": "mvaldi",
          "body": "Yeah, it works! thanks you so much! \n\nI will close the issue",
          "created_at": "2025-02-19T18:39:08Z"
        },
        {
          "author": "strangehelix",
          "body": "This is still an issue even without using `structured_outputs=True` while this works in langgraph with Gemini models.",
          "created_at": "2025-04-26T17:11:05Z"
        }
      ]
    },
    {
      "issue_number": 2984,
      "title": "[Feature Request] Add support for AWS profile_name and custom boto3 session in DynamoDbStorage",
      "body": "## Problem Description\n\nI often find it frustrating when trying to use `DynamoDbStorage` with AWS SSO credentials or a shared AWS profile (configured via `~/.aws/config`) because the class currently requires `aws_access_key_id` and `aws_secret_access_key`.\n\nAs someone using AWS SSO for authentication, I do not have long-lived static credentials and prefer leveraging the AWS default credential provider chain, or explicitly passing a preconfigured `boto3.Session` or specifying a `profile_name`.\n\n## Proposed Solution\n\nI’d like to propose extending the `DynamoDbStorage` class to support either:\n\n1. Accepting a `profile_name` argument, which would be used to create a boto3 session via `boto3.Session(profile_name=...)`.\n2. Accepting an already-initialized `boto3.Session` or `boto3.resource` object, allowing greater flexibility for users managing credentials through modern approaches like AWS SSO.\n\n**Examples:**\n\nUsing a profile name:\n```python\nstorage = DynamoDbStorage(\n    table_name=\"agent_sessions\",\n    region_name=\"eu-west-3\",\n    profile_name=\"my-profile-name\"\n)\n```\n\nUsing a preconfigured session:\n```python\nsession = boto3.Session(profile_name=\"my-profile-name\")\ndynamodb = session.resource(\"dynamodb\")\n\nstorage = DynamoDbStorage(\n    table_name=\"agent_sessions\",\n    dynamodb_resource=dynamodb\n)\n\n```\n\nFor example on the code, it would be something like\n\n```\nclass DynamoDbStorage(Storage):\n    def __init__(\n        self,\n        table_name: str,\n        profile_name: Optional[str] = None,\n        region_name: Optional[str] = None,\n        aws_access_key_id: Optional[str] = None,\n        aws_secret_access_key: Optional[str] = None,\n        endpoint_url: Optional[str] = None,\n        create_table_if_not_exists: bool = True,\n        mode: Optional[Literal[\"agent\", \"team\", \"workflow\"]] = \"agent\",\n    ):\n   \n    self.profile_name = profile_name\n   \n      # Create session using profile name if provided\n        if self.profile_name:\n            session = boto3.Session(profile_name=self.profile_name)\n            self.dynamodb = session.resource(\n                \"dynamodb\",\n                region_name=self.region_name,\n                endpoint_url=self.endpoint_url,\n            )\n        else:\n            # Initialize DynamoDB resource with default credentials\n            self.dynamodb = boto3.resource(\n                \"dynamodb\",\n                region_name=self.region_name,\n                endpoint_url=self.endpoint_url,\n            )\n\n\n```\n\n\nThis approach would maintain backward compatibility while enhancing support for more secure and modern AWS authentication workflows.\n\n## Alternatives Considered\n\nA workaround would be to subclass `DynamoDbStorage` and override the `__init__` method to use a custom `boto3.Session`, but this is not ideal for maintainability or usage in production environments.\n",
      "state": "closed",
      "author": "lironesamoun",
      "author_type": "User",
      "created_at": "2025-04-25T08:51:30Z",
      "updated_at": "2025-04-25T16:01:14Z",
      "closed_at": "2025-04-25T16:01:14Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2984/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2984",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2984",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:04.026550",
      "comments": [
        {
          "author": "lironesamoun",
          "body": "I did a PR for this: https://github.com/agno-agi/agno/pull/2989",
          "created_at": "2025-04-25T13:44:39Z"
        }
      ]
    },
    {
      "issue_number": 2976,
      "title": "[Bug]ImportError: 'openai' not installed triggered when importing agno.models.litellm.chat.LiteLLM due to __init__.py structure",
      "body": "# Description\nHi Agno Team,\nI encountered an ImportError related to the openai package when trying to use the LiteLLM class from agno.models.litellm.chat. Even though my code doesn't directly use OpenAI functionality through Agno and specifically imports only agno.models.litellm.chat.LiteLLM, the import mechanism seems to trigger a check for the openai package.\nProblem:\nImporting agno.models.litellm.chat.LiteLLM results in the following error trace:\nTraceback (most recent call last):\n  File \"<your_entry_point_script>.py\", line X, in <module>\n    # ... potentially several levels of your own imports ...\n  File \"/path/to/your/project/src/libs/companyx/core/feature/msg/llm.py\", line 11, in <module>\n    from agno.models.litellm.chat import LiteLLM\n  File \"/path/to/your/venv/lib/pythonX.Y/site-packages/agno/models/litellm/__init__.py\", line 2, in <module>\n    from agno.models.litellm.litellm_openai import LiteLLMOpenAI\n  File \"/path/to/your/venv/lib/pythonX.Y/site-packages/agno/models/litellm/litellm_openai.py\", line 4, in <module>\n    from agno.models.openai.like import OpenAILike\n  File \"/path/to/your/venv/lib/pythonX.Y/site-packages/agno/models/openai/__init__.py\", line 3, in <module>\n    from agno.models.openai.responses import OpenAIResponses\n  File \"/path/to/your/venv/lib/pythonX.Y/site-packages/agno/models/openai/responses.py\", line 20, in <module>\n    raise ImportError(\"`openai` not installed. Please install using `pip install openai -U`\") from e\nImportError: `openai` not installed. Please install using `pip install openai -U`\n\n## Steps to Reproduce\nI just initialized an Agent, configured the model to be LiteLLM. Here's the snippet:\n\n## Agent Configuration\nagent = Agent(\n        name=\"Test Agent\",\n        description=\"An expert email writer\",\n        model=LiteLLM(id=llm_config().DEFAULT_MODEL),\n        instructions=\"\\n\".join(instructions),\n        response_model=GeneratedResponse,\n        tools=[SomeToolkit()],\n    )\n\n## Expected Behavior\nIt appears the issue stems from agno/models/litellm/__init__.py, which unconditionally imports agno.models.litellm.litellm_openai.LiteLLMOpenAI. This import chain eventually leads to agno.models.openai.responses, where the check for the openai package occurs.\n\n## Actual Behavior\nWhat actually happened instead?\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- OS: macOS\n- Browser (if relevant): (e.g. Chrome 108, Firefox 107)\n- Agno Version: (e.g. v1.0.0)\n- External Dependency Versions: (e.g., yfinance 0.2.52)\n- Additional Environment Details: (e.g., Python 3.10)\n\n## Possible Solutions (optional)\nImporting agno.models.litellm.chat.LiteLLM should not require the openai package to be installed if the user does not intend to use the LiteLLMOpenAI specific features. The dependency check should ideally only happen if LiteLLMOpenAI or other OpenAI-dependent components are explicitly imported or used.\n\nConsider restructuring the imports, perhaps by moving the LiteLLMOpenAI import out of the agno/models/litellm/__init__.py or making the check within agno.models.openai.responses conditional based on actual usage.\nThanks for looking into this! Great work on this awesome library!\n\n",
      "state": "closed",
      "author": "AccomplishedCode",
      "author_type": "User",
      "created_at": "2025-04-24T21:26:49Z",
      "updated_at": "2025-04-25T13:21:13Z",
      "closed_at": "2025-04-25T13:04:00Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2976/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2976",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2976",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:04.190772",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hey @AccomplishedCode ! I have a PR out to fix this bug. Thank you! ",
          "created_at": "2025-04-25T04:18:29Z"
        },
        {
          "author": "AccomplishedCode",
          "body": "Thanks for the fix @ysolanky !",
          "created_at": "2025-04-25T13:21:12Z"
        }
      ]
    },
    {
      "issue_number": 2933,
      "title": "[Bug] TypeError: cannot pickle '_thread.RLock' object (Memory v2 + Ollama)",
      "body": "# Description\nWhen using memory (v2) the memory is not working with Ollama.\n\n## Steps to Reproduce\nBuild and agent using Memory v2 with Ollama and:\n- from agno.memory.v2.db.redis import RedisMemoryDb\n- from agno.memory.v2.manager import MemoryManager\n- from agno.memory.v2.memory import Memory\n- from agno.memory.v2.summarizer import SessionSummarizer\n\n## Expected Behavior\nMemory should work.\n\n## Actual Behavior\nMemory breaks.\n\n## Screenshots or Logs (if applicable)\n```\nFile \"/usr/local/lib/python3.13/site-packages/agno/memory/v2/manager.py\", line 219, in acreate_or_update_memories\n    model_copy = deepcopy(self.model)\n```\n<img width=\"916\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/2f03aa31-20b0-41d3-a6d5-2fb43989cd96\" />\n\n## Possible Solutions (optional)\nMaybe something like this: https://github.com/ScrapeGraphAI/Scrapegraph-ai/issues/374\n",
      "state": "closed",
      "author": "malvavisc0",
      "author_type": "User",
      "created_at": "2025-04-22T21:29:08Z",
      "updated_at": "2025-04-24T20:39:05Z",
      "closed_at": "2025-04-24T20:39:05Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2933/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2933",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2933",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:04.374500",
      "comments": [
        {
          "author": "malvavisc0",
          "body": "Just to be clear, this looks like a problem just with the Ollama model. I tried using OpenRouter as llm and did not happen, but OpenRouter throws this error very often:\n```text\nERROR    Error from OpenAI API: 1 validation error for SessionSummaryResponse   \n           Invalid JSON: invalid number at",
          "created_at": "2025-04-23T08:10:47Z"
        },
        {
          "author": "malvavisc0",
          "body": "After more and more debugging... the problem is with the ollama client (from ollama import AsyncClient).",
          "created_at": "2025-04-23T08:54:40Z"
        },
        {
          "author": "malvavisc0",
          "body": "Workaround. Just instantiate Ollama by using the `host` param, like this.\n```python\nollama = Ollama(\n        id=MODEL,\n        host=OLLAMA_URL,\n    )\n``` \n\nUsing the `client` param, either async or sync, it will crash the memory code.",
          "created_at": "2025-04-23T20:06:48Z"
        }
      ]
    },
    {
      "issue_number": 2955,
      "title": "[Bug] UserMemory.__init__() got an unexpected keyword argument 'summaries'",
      "body": "# Description\nUserMemory.__init__() got an unexpected keyword argument 'summaries'\n\n## Steps to Reproduce\nTries to use the memory.\n\n## Agent Configuration (if applicable)\n```python\nfrom agno.memory.v2.manager import MemoryManager\nfrom agno.memory.v2.memory import Memory\nfrom agno.memory.v2.summarizer import SessionSummarizer\n```\n```python\ndef _get_memory(thread_id: str, model_id: str = TOOL_MODEL) -> Memory:\n    model = completion(model=model_id, temperature=0.0)\n    memory = Memory(\n        db=RedisMemoryDb(\n            prefix=thread_id,\n            host=REDIS_HOST,\n            port=REDIS_PORT,\n            password=REDIS_PASSWORD,\n            db=REDIS_DB,\n        ),\n        memory_manager=MemoryManager(model=model),\n        summarizer=SessionSummarizer(model=model),\n    )\n    return memory\n```\n## Expected Behavior\nmemory should work\n\n## Actual Behavior\nit breaks the memory\n\n## Screenshots or Logs (if applicable)\n```text\n  File \"/usr/local/lib/python3.12/site-packages/agno/agent/agent.py\", line 1250, in _arun\n    run_messages: RunMessages = self.get_run_messages(\n                                ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/site-packages/agno/agent/agent.py\", line 2914, in get_run_messages\n    system_message = self.get_system_message(session_id=session_id, user_id=user_id)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/site-packages/agno/agent/agent.py\", line 2679, in get_system_message\n    user_memories = self.memory.get_user_memories(user_id=user_id)  # type: ignore\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/site-packages/agno/memory/v2/memory.py\", line 239, in get_user_memories\n    self.refresh_from_db(user_id=user_id)\n  File \"/usr/local/lib/python3.12/site-packages/agno/memory/v2/memory.py\", line 189, in refresh_from_db\n    self.memories.setdefault(memory.user_id, {})[memory.id] = UserMemory.from_dict(memory.memory)\n                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/site-packages/agno/memory/v2/schema.py\", line 31, in from_dict\n    return cls(**data)\n           ^^^^^^^^^^^\nTypeError: UserMemory.__init__() got an unexpected keyword argument 'summaries'\n```\n\n## Environment\n- Agno Version: v1.4.1\n",
      "state": "closed",
      "author": "malvavisc0",
      "author_type": "User",
      "created_at": "2025-04-23T20:15:14Z",
      "updated_at": "2025-04-24T20:38:36Z",
      "closed_at": "2025-04-24T20:38:35Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2955/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2955",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2955",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:04.585037",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "We'll fix asap. Can you specify how you initialised the DB or used memory before that point?",
          "created_at": "2025-04-23T20:49:05Z"
        },
        {
          "author": "malvavisc0",
          "body": "I have something like this:\n```python\nfrom os import environ\nfrom typing import Callable, Dict, List, Optional, Union\n\nfrom agno.agent.agent import Agent\nfrom agno.knowledge.agent import AgentKnowledge\nfrom agno.memory.v2.db.redis import RedisMemoryDb\nfrom agno.memory.v2.manager import MemoryManager",
          "created_at": "2025-04-23T22:35:45Z"
        },
        {
          "author": "dirkbrnd",
          "body": "1. For Redis storage I wouldn't do the session ID as the prefix. We already store sessions by session ID, but just something to be aware of.\n2. I ran your code with llama 3.2 on Ollama and had no issues. I could get memories and session summaries. For example I ran\n```\nagent.print_response(\"Hi, my n",
          "created_at": "2025-04-24T10:41:16Z"
        },
        {
          "author": "malvavisc0",
          "body": "Yep, thanks @dirkbrnd this error is gone for me too.",
          "created_at": "2025-04-24T20:38:35Z"
        }
      ]
    },
    {
      "issue_number": 2968,
      "title": "[Feature Request] https://community.agno.com/t/can-the-url-connecting-postgresagentstorage-and-pgvector-use-postgresql-asyncpg/955",
      "body": "## Problem Description\nProvide a clear and concise explanation of the issue you're facing.\n**Example:** *\"I often find it frustrating when [...] because [...]”*\n\n## Proposed Solution\nExplain your ideal solution. How should this feature work?\nBe as detailed as possible to help us understand your vision.\n\n## Alternatives Considered\nHave you found any workarounds or alternative solutions?\nShare other approaches you've tried or thought about.\n\n## Additional context\nInclude any extra information that might be helpful, such as:\n- Screenshots\n- Examples of similar features elsewhere\n- Any relevant links or references\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[ ] Yes, I’d love to work on it!**\n**[ ] I’m open to collaborating but need guidance.**\n**[ ] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "monali7-d",
      "author_type": "User",
      "created_at": "2025-04-24T12:40:06Z",
      "updated_at": "2025-04-24T12:40:32Z",
      "closed_at": "2025-04-24T12:40:32Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2968/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2968",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2968",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:04.826782",
      "comments": []
    },
    {
      "issue_number": 2953,
      "title": "[Bug] MCP Hang",
      "body": "# Description\nPer https://modelcontextprotocol.io/specification/draft/basic/lifecycle#timeouts\n\n\"Implementations SHOULD establish timeouts for all sent requests, to prevent hung connections and resource exhaustion. When the request has not received a success or error response within the timeout period, the sender SHOULD issue a cancellation notification for that request and stop waiting for a response.\n\nSDKs and other middleware SHOULD allow these timeouts to be configured on a per-request basis.\"\n\n\n## Steps to Reproduce\n\nMake an MCP Stdio client and kill the server manually when the agent is running\n\n## Agent Configuration (if applicable)\nProvide relevant agent configuration.\n\n## Expected Behavior\nThere should be a read timeout\n\n## Actual Behavior\nWhat actually happened instead?\n\n## Screenshots or Logs (if applicable)\n\ntimeout goes here?\nhttps://github.com/agno-agi/agno/blob/751be6a1f422a64822f6534b00482fc89e2bdd77/libs/agno/agno/tools/mcp.py#L101\n## Environment\n- OS: (e.g. macOS, Windows 11)\n- Browser (if relevant): (e.g. Chrome 108, Firefox 107)\n- Agno Version: (e.g. v1.0.0)\n- External Dependency Versions: (e.g., yfinance 0.2.52)\n- Additional Environment Details: (e.g., Python 3.10)\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "njbrake",
      "author_type": "User",
      "created_at": "2025-04-23T19:11:37Z",
      "updated_at": "2025-04-24T12:28:54Z",
      "closed_at": "2025-04-24T12:28:53Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2953/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2953",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2953",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:04.826803",
      "comments": [
        {
          "author": "ssenthilnathan3",
          "body": "Hey! I just wanted to share that I’ve started working on this issue—it's actually my first open source contribution, so I’m really excited! I went ahead and opened a PR (hope that’s okay) even though it wasn’t officially assigned to me. Apologies if I jumped the gun. I’ve attached the PR here for yo",
          "created_at": "2025-04-24T08:16:50Z"
        },
        {
          "author": "njbrake",
          "body": "Thanks, @ssenthilnathan3 ! Fixed and looks like it got merged #2961 ",
          "created_at": "2025-04-24T12:28:53Z"
        }
      ]
    },
    {
      "issue_number": 2967,
      "title": "[Feature Request] support-for-event-triggers",
      "body": "Refer: https://community.agno.com/t/support-for-event-triggers/941",
      "state": "closed",
      "author": "monali7-d",
      "author_type": "User",
      "created_at": "2025-04-24T12:25:53Z",
      "updated_at": "2025-04-24T12:26:03Z",
      "closed_at": "2025-04-24T12:26:03Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2967/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2967",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2967",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:05.008207",
      "comments": []
    },
    {
      "issue_number": 2847,
      "title": "[Bug] Agent structured output not respecting response_model",
      "body": "I'm trying to use structured outputs, but the Agent doesn't return the response in the expected format.\n\n```\nclass Asset(BaseModel):\n    title: str = Field(..., description=\"Title of the asset\")\n    description: str = Field(..., description=\"Description of the asset\")\n\nagent = Agent(\n        model=AwsBedrock(\n            id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n        ),\n        response_model=Asset\n    )\n\nimage_path = Path(__file__).parent / 'image-9.jpg'\nimage_bytes = image_path.read_bytes()\n\nagent_response = agent.run(\n  message=\"Generate a title and description\", \n  images=[\n      Image(\n          content=image_bytes,\n          format=\"jpeg\",\n      )\n  ]\n)\n\nprint(agent_response.get_content_as_string())\n```\n\nExpected output would be a JSON with title and description, but it just returns text:\n\n> Title: \"Serene Seagull: A Coastal Companion\"\n> \n> Description: This captivating image showcases a solitary seagull perched on a white surface, likely a railing or ledge near the sea. The bird's pristine white feathers contrast beautifully against the soft, pale blue background, creating a serene and minimalist composition. The gull's bright red beak and feet add a pop of color to the otherwise muted palette. The image evokes a sense of tranquility and simplicity, perfectly capturing the essence of coastal life. This photograph would be ideal for themes related to marine life, seaside vacations, or peaceful nature scenes.\n\nWhen creating an Asset manually and calling `.model_dump_json()` works as expected, but it seems that it response is not returned as an Asset, like indicated in the response_model attribute.\n\n```\ndef get_content_as_string(self, **kwargs) -> str:\n        import json\n\n        from pydantic import BaseModel\n\n        if isinstance(self.content, str):\n            return self.content\n        elif isinstance(self.content, BaseModel):\n            return self.content.model_dump_json(exclude_none=True, **kwargs)\n        else:\n            return json.dumps(self.content, **kwargs)\n```\n\n## Environment\n- OS: macOS\n- Agno Version: (e.g. v1.3.1)\n- External Dependency Versions: pydantic 2.11.3\n- Additional Environment Details: Python 3.13.3\n\nAny clues?",
      "state": "closed",
      "author": "marcsc3",
      "author_type": "User",
      "created_at": "2025-04-16T10:11:02Z",
      "updated_at": "2025-04-24T09:44:06Z",
      "closed_at": "2025-04-17T10:33:44Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2847/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2847",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2847",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:05.008227",
      "comments": [
        {
          "author": "kausmeows",
          "body": "Hey @marcsc3, can you try following this here- https://docs.agno.com/faq/structured-outputs#json-mode",
          "created_at": "2025-04-17T07:12:46Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @marcsc3 \nI tried your example and got the result as a pydantic model. The would be the expectation if you set `response_model`. You can then take this output and call `model_dump_json()`\n\nFor example\n```\nagent_response = agent.run(\n  message=\"Generate a title and description\", \n  images=[\n      ",
          "created_at": "2025-04-17T10:33:34Z"
        },
        {
          "author": "marcsc3",
          "body": "Hey @dirkbrnd.\n\nWhat model did you use in your example?\nI saw that it was working out of the box with OpenAI models, but not with Claude for example.",
          "created_at": "2025-04-23T14:44:49Z"
        },
        {
          "author": "pAulseperformance",
          "body": "I was getting similar issues with response_model not being respected when using different models. I tried qwen and google flash. Just learning now that agno is only robust with openai.\n\n```python\nfrom models import ResumeData\n\nclass ResumeProcessor:\n    def __init__(self, supabase_url: str, supabase",
          "created_at": "2025-04-24T09:44:04Z"
        }
      ]
    },
    {
      "issue_number": 2714,
      "title": "[Bug] Huggingface embedder broken with the default setup",
      "body": "# Description\nHuggingface embedders are not compatible right now due to lack of supported tasks parameter.\nValueError: Model 'jinaai/jina-embeddings-v2-base-code' doesn't support task 'unknown'. Supported tasks: 'feature-extraction', got: 'unknown'\n\n## Steps to Reproduce\nUse the huggingface embedder for any rag operation.\n\n## Agent Configuration (if applicable)\nProvide relevant agent configuration.\n\n## Expected Behavior\nWhat did you expect to happen?\n\n## Actual Behavior\nWhat actually happened instead?\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- OS: (e.g. macOS, Windows 11)\n- Browser (if relevant): (e.g. Chrome 108, Firefox 107)\n- Agno Version: (e.g. v1.0.0)\n- External Dependency Versions: (e.g., yfinance 0.2.52)\n- Additional Environment Details: (e.g., Python 3.10)\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "Rohitkumarvarma-369",
      "author_type": "User",
      "created_at": "2025-04-07T16:47:25Z",
      "updated_at": "2025-04-24T07:55:17Z",
      "closed_at": "2025-04-23T00:32:42Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2714/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2714",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2714",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:05.265986",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-23T00:32:40Z"
        }
      ]
    },
    {
      "issue_number": 2256,
      "title": "[Feature Request]Hi, When it can support VLLM especially support VLLM use Tools, Thanks!",
      "body": "## Problem Description\nProvide a clear and concise explanation of the issue you're facing.\n**Example:** *\"I often find it frustrating when [...] because [...]”*\n\n## Proposed Solution\nExplain your ideal solution. How should this feature work?\nBe as detailed as possible to help us understand your vision.\n\n## Alternatives Considered\nHave you found any workarounds or alternative solutions?\nShare other approaches you've tried or thought about.\n\n## Additional context\nInclude any extra information that might be helpful, such as:\n- Screenshots\n- Examples of similar features elsewhere\n- Any relevant links or references\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[ ] Yes, I’d love to work on it!**\n**[ ] I’m open to collaborating but need guidance.**\n**[ ] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "lixy910915",
      "author_type": "User",
      "created_at": "2025-02-28T08:48:42Z",
      "updated_at": "2025-04-23T15:03:45Z",
      "closed_at": "2025-03-10T09:02:14Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2256/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2256",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2256",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:05.749310",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @lixy910915 ! You can use VLLM with Agno in the following way. We are also working on a new model class for VLLM and it should be released next week. \n\n```python\nfrom agno.agent import Agent\nfrom agno.models.openai import OpenAILike\n\nagent = Agent(model=OpenAILike(id=\"Qwen/Qwen2.5-1.5B-Instruc",
          "created_at": "2025-02-28T15:15:17Z"
        },
        {
          "author": "lixy910915",
          "body": "Thanks for your info. I'm trying to use deepseek r1 32b with vLLM through openai for calling duckduckgo, but it always failed. could you please give some demo?",
          "created_at": "2025-03-01T09:50:12Z"
        },
        {
          "author": "manthanguptaa",
          "body": "Hey @lixy910915! Can you please help me with your code? We will try to debug it",
          "created_at": "2025-03-08T03:41:14Z"
        },
        {
          "author": "lixy910915",
          "body": "Hi，I changed model to 'QWQ-32B', then it works.\ncode just like this:\n\nfrom pathlib import Path\nfrom agno.agent import Agent\nfrom agno.tools.python import PythonTools\n\nagent = Agent(\n    tools=[PythonTools(base_dir=Path(\"/root/agent-test\"))],\n    show_tool_calls=True)\nagent.print_response(\n    \"Write",
          "created_at": "2025-03-10T09:02:11Z"
        },
        {
          "author": "WuRui-Ella",
          "body": " How are QwQ models configured? Do you use OpenAILike? Could you share detailed info about it?\n\n> Hi，I changed model to 'QWQ-32B', then it works. code just like this:\n> \n> from pathlib import Path from agno.agent import Agent from agno.tools.python import PythonTools\n> \n> agent = Agent( tools=[Pytho",
          "created_at": "2025-04-01T10:20:55Z"
        }
      ]
    },
    {
      "issue_number": 2896,
      "title": "[Bug] Memory Creation Failing on Linux Machine using UV",
      "body": "# Description\nI run the Following Script from the examples:\n\nfrom agno.memory.v2 import Memory\nfrom agno.memory.v2.db.sqlite import SqliteMemoryDb\nfrom agno.models.google import Gemini\nfrom agno.models.message import Message\nimport os\nfrom dotenv import load_dotenv\n# Loading Env Variables\nload_dotenv()\nos.environ.get(\"GOOGLE_API_KEY\")\n\nmemory_db = SqliteMemoryDb(table_name=\"memory\", db_file=\"tmp/memory.db\")\n# Reset for this example\nmemory_db.clear()\n\nmemory = Memory(model=Gemini(id=\"gemini-2.0-flash-exp\"), db=memory_db)\n\njohn_doe_id = \"john_doe@example.com\"\n\nmemory.create_user_memories(\n    message=\"\"\"\n    I enjoy hiking in the mountains on weekends,\n    reading science fiction novels before bed,\n    cooking new recipes from different cultures,\n    playing chess with friends,\n    and attending live music concerts whenever possible.\n    Photography has become a recent passion of mine, especially capturing landscapes and street scenes.\n    I also like to meditate in the mornings and practice yoga to stay centered.\n    \"\"\",\n    user_id=john_doe_id,\n)\n\n\nmemories = memory.get_user_memories(user_id=john_doe_id)\nprint(\"John Doe's memories:\")\nfor i, m in enumerate(memories):\n    print(f\"{i}: {m.memory} - {m.topics}\")\n\n\njane_doe_id = \"jane_doe@example.com\"\n# Send a history of messages and add memories\nmemory.create_user_memories(\n    messages=[\n        Message(role=\"user\", content=\"My name is Jane Doe\"),\n        Message(role=\"assistant\", content=\"That is great!\"),\n        Message(role=\"user\", content=\"I like to play chess\"),\n        Message(role=\"assistant\", content=\"That is great!\"),\n    ],\n    user_id=jane_doe_id,\n)\n\nmemories = memory.get_user_memories(user_id=jane_doe_id)\nprint(\"Jane Doe's memories:\")\nfor i, m in enumerate(memories):\n    print(f\"{i}: {m.memory} - {m.topics}\")\n\nHowever, Here's the Output i Got:\n\n uv run tests/CheckMemories.py\nJohn Doe's memories:\n0: User enjoys cooking new recipes from different cultures. - ['hobbies']\n1: User enjoys playing chess with friends. - ['hobbies']\n2: User enjoys attending live music concerts whenever possible. - ['hobbies']\n3: User's recent passion is photography, especially landscapes and street scenes. - ['hobbies']\n4: User likes to meditate in the mornings and practice yoga to stay centered. - ['hobbies']\n5: User enjoys hiking in the mountains on weekends. - ['hobbies']\n6: User enjoys reading science fiction novels before bed. - ['hobbies']\nJane Doe's memories:\n\n\nI am running on the latest Agno Version",
      "state": "closed",
      "author": "KazuhiraBenedictMiller",
      "author_type": "User",
      "created_at": "2025-04-20T11:21:17Z",
      "updated_at": "2025-04-23T13:00:27Z",
      "closed_at": "2025-04-23T12:23:05Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2896/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2896",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2896",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:06.033515",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @KazuhiraBenedictMiller ! Looks like the memories from your earlier session with the same `user_id` persisted in this snippet:\n```python\nmemory.create_user_memories(\nmessages=[\nMessage(role=\"user\", content=\"My name is Jane Doe\"),\nMessage(role=\"assistant\", content=\"That is great!\"),\nMessage(rol",
          "created_at": "2025-04-20T17:46:50Z"
        },
        {
          "author": "KazuhiraBenedictMiller",
          "body": "Hi, \n\nFirst of all thank you so much for reaching out.\n\nI pulled the snippet from the website, so you should maybe change it for the future\n\nI also Have Another question if Possible.\n\nHow does the Team Handle Memories?\n\nI am having Troubles to Actually find memories for the Team of Agents for the fo",
          "created_at": "2025-04-20T17:54:54Z"
        },
        {
          "author": "KazuhiraBenedictMiller",
          "body": "UPDATE \n\nEven Within this Example, it's not Generating Any Memories for Some Reason\n\nMAIN BLOCK\n\n```\n# Importing Necessary Libraries\nfrom agno.agent import RunResponse\nfrom agno.memory.v2.db.sqlite import SqliteMemoryDb\nfrom agno.memory.v2.memory import Memory\nfrom utils.Agents import InitializeAgen",
          "created_at": "2025-04-21T10:08:34Z"
        },
        {
          "author": "KazuhiraBenedictMiller",
          "body": "[FIXED]\n\nAfter Inspecting Agno's Code, especially here:\n\nhttps://github.com/agno-agi/agno/blob/main/libs/agno/agno/memory/v2/manager.py\n\nI found out that the memory creation (the automatic agentic one) is not suited for my use case.\n\nIn my specific use case it's a narrative agent, so capturing thing",
          "created_at": "2025-04-21T20:29:57Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @KazuhiraBenedictMiller \nYou now have the ability to change the memory creation instructions. That might be useful to you\n[Here](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/memory/04_custom_memory_creation.py)",
          "created_at": "2025-04-23T12:23:00Z"
        }
      ]
    },
    {
      "issue_number": 2897,
      "title": "[Bug] Ollama Dependency | ModuleNotFoundError: No module named 'ollama'",
      "body": "![Image](https://github.com/user-attachments/assets/1de2fee0-6687-47b9-a147-c4d61deb6841)\n![Image](https://github.com/user-attachments/assets/51e31505-1554-417b-9fc2-ecfe48db3240)\n![Image](https://github.com/user-attachments/assets/9faeb556-2327-41d9-add0-0443f7e03475)\n![Image](https://github.com/user-attachments/assets/8ede76dc-8ecb-410a-815e-03eebbb0e918)\n![Image](https://github.com/user-attachments/assets/f7a2c200-1ecf-4a77-8d69-50db4d5364d5)\n\n# Description\nWhile trying to run agno-api workspace on local environment - If we change the model in sage agent to ollama. Its showing module missing.  Even though all the steps are taken as per documentation.\n\n## Steps to Reproduce\n1.Follow steps mentioned in https://docs.agno.com/workspaces/agent-api/local.\n2. Update the sage agent as follow (using Ollama instead of OpenAI)\n\n return Agent(\n        name=\"Sage\",\n        agent_id=\"sage\",\n        user_id=user_id,\n        session_id=session_id,\n        model=Ollama(id=\"llama3.2:3b\"),\n   \n   Import Statement added - from agno.models.ollama import Ollama\n3. Add ollama dependency based on following documentation \nhttps://docs.agno.com/workspaces/workspace-management/python-packages\n4. Deleted the docker images and started the container again.\n\n## Expected Behavior\nWhat did you expect to happen?\nNo Module missing error.\n\n## Actual Behavior\nWhat actually happened instead?\nError - \nmodule = importlib.import_module(module_str)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile \"/usr/local/lib/python3.12/importlib/__init__.py\", line 90, in import_module\nreturn _bootstrap._gcd_import(name[level:], package, level)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\nFile \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\nFile \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\nFile \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\nFile \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\nFile \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\nFile \"/app/api/main.py\", line 4, in <module>\nfrom api.routes.v1_router import v1_router\nFile \"/app/api/routes/v1_router.py\", line 3, in <module>\nfrom api.routes.agents import agents_router\nFile \"/app/api/routes/agents.py\", line 9, in <module>\nfrom agents.operator import AgentType, get_agent, get_available_agents\nFile \"/app/agents/operator.py\", line 4, in <module>\nfrom agents.sage import get_sage\nFile \"/app/agents/sage.py\", line 8, in <module>\nfrom agno.models.ollama import Ollama\nFile \"/usr/local/lib/python3.12/site-packages/agno/models/ollama/__init__.py\", line 1, in <module>\nfrom agno.models.ollama.chat import Ollama\nFile \"/usr/local/lib/python3.12/site-packages/agno/models/ollama/chat.py\", line 18, in <module>\nraise ImportError(\"`ollama` not installed. Please install using `pip install ollama`\")\nImportError: `ollama` not installed. Please install using `pip install ollama`\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- OS: ( Windows 11)\n- Browser : ( Firefox 107)\n- Agno Version: (latest)\n\n",
      "state": "closed",
      "author": "hakunamamamamamatatatatatata",
      "author_type": "User",
      "created_at": "2025-04-20T15:02:00Z",
      "updated_at": "2025-04-23T12:24:06Z",
      "closed_at": "2025-04-23T12:24:06Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2897/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2897",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2897",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:06.212070",
      "comments": [
        {
          "author": "hakunamamamamamatatatatatata",
          "body": "Seems like issue is with docker pull. The command 'ag ws up' is always pulling image from dockerhub registry  (https://hub.docker.com/r/agnohq/agent-api)   instead of building from my local Dockerfile and code.\n\n",
          "created_at": "2025-04-20T17:30:21Z"
        },
        {
          "author": "ysolanky",
          "body": "Hello @hakunamamamamamatatatatatata !  In order to build the image locally, you need to enable the `build_images=True`. [Here are some docs](https://docs.agno.com/workspaces/workspace-management/development-app#build-your-development-image). Please let us know if you have any questions ",
          "created_at": "2025-04-20T17:40:21Z"
        }
      ]
    },
    {
      "issue_number": 2821,
      "title": "[Bug]MCPTools tool call fails if using agent.run with async mode",
      "body": "# Description\ni use mcp with async mode, i want to pprint the response content then i got errors\n\n## Steps to Reproduce\n\n......\nasync def run_agent(message: str) -> None:\n....\n      async with fs_tools:\n          agent = Agent(\n              model=DeepSeek(id=\"deepseek-chat\"),\n              tools=[fs_tools],\n              show_tool_calls=True,\n              markdown=True,\n              memory=memory,\n              add_datetime_to_instructions=True,\n              enable_agentic_memory=True,\n              enable_user_memories=True,\n              num_history_responses=10,\n              add_history_to_messages=True,\n              user_id=user_id,\n              add_memory_references=True,\n          )\n          # Pass user profile to the agent\n          response_stream: Iterator[RunResponse] = agent.run(message, stream=True,user_id=user_id)\n          pprint_run_response(response_stream, markdown=True)\n\nif __name__ == \"__main__\":\n    asyncio.run(run_agent(\"xxxxxxxxxx\"))\n\n\n## Agent Configuration (if applicable)\nNA\n\n## Expected Behavior\nwithout errors\n\n## Actual Behavior\nError running agent: unhandled errors in a TaskGroup (1 sub-exception)\nan error occurred during closing of asynchronous generator <async_generator object stdio_client at 0x107168a40>\nasyncgen: <async_generator object stdio_client at 0x107168a40>\nTraceback (most recent call last):\n  File \"/opt/homebrew/lib/python3.12/site-packages/mcp/client/stdio/__init__.py\", line 173, in stdio_client\n    yield read_stream, write_stream\nGeneratorExit\n\nDuring handling of the above exception, another exception occurred:\n\n  + Exception Group Traceback (most recent call last):\n  |   File \"/opt/homebrew/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 767, in __aexit__\n  |     raise BaseExceptionGroup(\n  | BaseExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"/opt/homebrew/lib/python3.12/site-packages/mcp/client/stdio/__init__.py\", line 173, in stdio_client\n    |     yield read_stream, write_stream\n    | GeneratorExit\n    +------------------------------------\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/homebrew/lib/python3.12/site-packages/mcp/client/stdio/__init__.py\", line 167, in stdio_client\n    anyio.create_task_group() as tg,\n    ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 773, in __aexit__\n    if self.cancel_scope.__exit__(type(exc), exc, exc.__traceback__):\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 456, in __exit__\n    raise RuntimeError(\nRuntimeError: Attempted to exit cancel scope in a different task than it was entered in\nTraceback (most recent call last):\n  File \"/Users/duff/pythonlearning/testango.py\", line 70, in run_agent\n    pprint_run_response(response_stream, markdown=True)\n  File \"/opt/homebrew/lib/python3.12/site-packages/agno/utils/pprint.py\", line 54, in pprint_run_response\n    for resp in run_response:\n                ^^^^^^^^^^^^\n  File \"/opt/homebrew/lib/python3.12/site-packages/agno/agent/agent.py\", line 627, in _run\n    for model_response_chunk in self.model.response_stream(messages=run_messages.messages):\n                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/lib/python3.12/site-packages/agno/models/base.py\", line 546, in response_stream\n    for function_call_response in self.run_function_calls(\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/lib/python3.12/site-packages/agno/models/base.py\", line 888, in run_function_calls\n    function_call_result = self._create_function_call_result(\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/lib/python3.12/site-packages/agno/models/base.py\", line 819, in _create_function_call_result\n    return Message(\n           ^^^^^^^^\n  File \"/opt/homebrew/lib/python3.12/site-packages/pydantic/main.py\", line 214, in __init__\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\npydantic_core._pydantic_core.ValidationError: 2 validation errors for Message\ncontent.list[any]\n  Input should be a valid list [type=list_type, input_value=<coroutine object get_ent...all_tool at 0x10716b100>, input_type=coroutine]\n    For further information visit https://errors.pydantic.dev/2.10/v/list_type\ncontent.str\n  Input should be a valid string [type=string_type, input_value=<coroutine object get_ent...all_tool at 0x10716b100>, input_type=coroutine]\n    For further information visit https://errors.pydantic.dev/2.10/v/string_type\n\nDuring handling of the above exception, another exception occurred:\n\n  + Exception Group Traceback (most recent call last):\n  |   File \"/Users/duff/pythonlearning/testango.py\", line 91, in <module>\n  |     asyncio.run(run_agent(\"从北京交通大学到西直门最近的地铁口，请根据明天天气情况帮我规划出行方式，并告诉我耗时多久。如果天气不好，请推荐更合适的方式。\"))\n  |   File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/runners.py\", line 195, in run\n  |     return runner.run(main)\n  |            ^^^^^^^^^^^^^^^^\n  |   File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/runners.py\", line 118, in run\n  |     return self._loop.run_until_complete(task)\n  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  |   File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 691, in run_until_complete\n  |     return future.result()\n  |            ^^^^^^^^^^^^^^^\n  |   File \"/Users/duff/pythonlearning/testango.py\", line 53, in run_agent\n  |     async with fs_tools:\n  |                ^^^^^^^^\n  |   File \"/opt/homebrew/lib/python3.12/site-packages/agno/tools/mcp.py\", line 114, in __aexit__\n  |     await self._session_context.__aexit__(exc_type, exc_val, exc_tb)\n  |   File \"/opt/homebrew/lib/python3.12/site-packages/mcp/shared/session.py\", line 210, in __aexit__\n  |     return await self._task_group.__aexit__(exc_type, exc_val, exc_tb)\n  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  |   File \"/opt/homebrew/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 767, in __aexit__\n  |     raise BaseExceptionGroup(\n  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"/Users/duff/pythonlearning/testango.py\", line 70, in run_agent\n    |     pprint_run_response(response_stream, markdown=True)\n    |   File \"/opt/homebrew/lib/python3.12/site-packages/agno/utils/pprint.py\", line 54, in pprint_run_response\n    |     for resp in run_response:\n    |                 ^^^^^^^^^^^^\n    |   File \"/opt/homebrew/lib/python3.12/site-packages/agno/agent/agent.py\", line 627, in _run\n    |     for model_response_chunk in self.model.response_stream(messages=run_messages.messages):\n    |                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/opt/homebrew/lib/python3.12/site-packages/agno/models/base.py\", line 546, in response_stream\n    |     for function_call_response in self.run_function_calls(\n    |                                   ^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/opt/homebrew/lib/python3.12/site-packages/agno/models/base.py\", line 888, in run_function_calls\n    |     function_call_result = self._create_function_call_result(\n    |                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/opt/homebrew/lib/python3.12/site-packages/agno/models/base.py\", line 819, in _create_function_call_result\n    |     return Message(\n    |            ^^^^^^^^\n    |   File \"/opt/homebrew/lib/python3.12/site-packages/pydantic/main.py\", line 214, in __init__\n    |     validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n    |                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    | pydantic_core._pydantic_core.ValidationError: 2 validation errors for Message\ncontent.list[any]\n  Input should be a valid list [type=list_type, input_value=<coroutine object get_ent...all_tool at 0x10716b100>, input_type=coroutine]\n    For further information visit https://errors.pydantic.dev/2.10/v/list_type\ncontent.str\n  Input should be a valid string [type=string_type, input_value=<coroutine object get_ent...all_tool at 0x10716b100>, input_type=coroutine]\n    For further information visit https://errors.pydantic.dev/2.10/v/string_type\n    +------------------------------------\n\n## Screenshots or Logs (if applicable)\nNA\n\n## Environment\n- OS: McaOS\n- Additional Environment Details: (Python 3.12, agno 1.3.1)\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "duffqiu",
      "author_type": "User",
      "created_at": "2025-04-14T10:01:32Z",
      "updated_at": "2025-04-23T12:23:41Z",
      "closed_at": "2025-04-23T12:23:41Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2821/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2821",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2821",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:06.393883",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Hi @duffqiu \n1. With MCP it only works with async agents, so you have to use `await agent.arun(...)`.\n2. Even with that there was an issue with that util. I am releasing a fix!  I will make the demo in `cookbook/tools/mcp/airbnb.py` show the fix.",
          "created_at": "2025-04-17T12:41:09Z"
        }
      ]
    },
    {
      "issue_number": 2900,
      "title": "Error when changing the",
      "body": "# Description\nThere is an Error `UnboundLocalError: cannot access local variable 'OpenAIChat' where it is not associated with a value`, when the evaluation agent is changed from the default model in accuracy evals.\n\n## Steps to Reproduce\nThe code that gives the Error\n```\nfrom typing import Optional\n\nfrom agno.agent import Agent\nfrom agno.eval.accuracy import AccuracyEval, AccuracyResult\nfrom agno.models.openai import OpenAIChat\nfrom agno.tools.calculator import CalculatorTools\n\n\ndef multiply_and_exponentiate():\n    evaluation = AccuracyEval(\n        # comment the below model and the code works normal.\n        model=Claude(id=\"claude-3-7-sonnet-20250219\"),\n        agent=Agent(\n            model=OpenAIChat(id=\"gpt-4.1\"),\n            tools=[CalculatorTools(add=True, multiply=True, exponentiate=True)],\n        ),\n        question=\"What is 10*5 then to the power of 2? do it step by step\",\n        expected_answer=\"2500\",\n        num_iterations=1\n    )\n    result: Optional[AccuracyResult] = evaluation.run(print_results=True)\n\n    print(result)\n\n\nif __name__ == \"__main__\":\n    multiply_and_exponentiate()\n```\n\n## Agent Configuration (if applicable)\n```\nagent=Agent(\n            model=OpenAIChat(id=\"gpt-4.1\"),\n            tools=[CalculatorTools(add=True, multiply=True, exponentiate=True)],\n        ),\n```\n\n## Expected Behavior\nExpected to run the evals and get the accuracy metrics\n```\n╭────────────────────┬───────╮\n│ Number of Runs     │ 1     │\n│ Average Score      │ 10.00 │\n│ Mean Score         │ 10.00 │\n│ Minimum Score      │ 10.00 │\n│ Maximum Score      │ 10.00 │\n│ Standard Deviation │ 0.00  │\n╰────────────────────┴───────╯\n```\n\n## Actual Behavior\n```\nTraceback (most recent call last):\n  File \"/Users/pavanmantha/Pavans/PracticeExamples/DataScience_Practice/LLMs/phidata/agent_evals/accuracy_evals.py\", line 72, in <module>\n    multiply_and_exponentiate()\n  File \"/Users/pavanmantha/Pavans/PracticeExamples/DataScience_Practice/LLMs/phidata/agent_evals/accuracy_evals.py\", line 66, in multiply_and_exponentiate\n    result: Optional[AccuracyResult] = evaluation.run(print_results=True)\n                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/pavanmantha/Pavans/PracticeExamples/DataScience_Practice/LLMs/phidata/agent_evals/venv/lib/python3.12/site-packages/agno/eval/accuracy.py\", line 395, in run\n    evaluator_agent: Agent = self.get_evaluator_agent(\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/pavanmantha/Pavans/PracticeExamples/DataScience_Practice/LLMs/phidata/agent_evals/venv/lib/python3.12/site-packages/agno/eval/accuracy.py\", line 213, in get_evaluator_agent\n    model=OpenAIChat(id=\"gpt-4o-mini\"),\n          ^^^^^^^^^^\nUnboundLocalError: cannot access local variable 'OpenAIChat' where it is not associated with a value\n```\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- OS: macOS\n- Agno Version: `agno==1.3.4`\n- Additional Environment Details: `Python 3.12.4`\n\n## Possible Solutions (optional)\nFixed the issue and made a PR:\nhttps://github.com/agno-agi/agno/pull/2899\n\n## Additional Context\nN/A\n",
      "state": "closed",
      "author": "pavanjava",
      "author_type": "User",
      "created_at": "2025-04-20T16:34:01Z",
      "updated_at": "2025-04-23T12:21:14Z",
      "closed_at": "2025-04-23T12:21:14Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2900/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2900",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2900",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:06.559020",
      "comments": []
    },
    {
      "issue_number": 2870,
      "title": "[Bug] Reasoning Agent Error",
      "body": "I have a basic agent that fails to work with `reasoning` attribute on.\n\nerror I see:\n```\nERROR    Error calling Groq API: Error code: 400 - {'error': {'message': 'response_format` json_object cannot be combined with tool/function calling', 'type':\n         'invalid_request_error'}}\nWARNING  Attempt 1/1 failed: {\"error\":{\"message\":\"response_format` json_object cannot be combined with tool/function calling\",\"type\":\"invalid_request_error\"}}\n\nERROR    Failed after 1 attempts. Last error using Groq(llama-3.3-70b-versatile)\nERROR    Reasoning error: {\"error\":{\"message\":\"response_format` json_object cannot be combined with tool/function calling\",\"type\":\"invalid_request_error\"}}\n\n```\n\nAgent Code:\n```\nfrom logging import debug\nfrom dotenv  import load_dotenv\nload_dotenv()\n\nfrom agno.agent import Agent\nfrom agno.models.openai import OpenAIChat\nfrom agno.models.google import Gemini\nfrom agno.models.openrouter import OpenRouter\nfrom agno.models.groq import Groq\nfrom agno.tools.googlesearch import GoogleSearchTools\nfrom agno.storage.sqlite import SqliteStorage\nfrom agno.utils.pprint import pprint_run_response\n\nagent_storage = SqliteStorage(\n    table_name=\"agent_sessions\",\n    db_file=\"tmp/persistent_memory.db\",\n)\n\nsample_agent = Agent(\n    name=\"math_agno_agent\",\n    description=\"You are a helpful assistant who can solve math problems.\",\n    # model=OpenAIChat(id=\"gpt-4o-mini\"),\n    # model=Gemini(id=\"gemini-2.0-flash-exp\"),  # or any other supported model\n    # model=OpenRouter(id=\"qwen/qwq-32b\"),  # or any other supported model\n    model=Groq(id=\"llama-3.3-70b-versatile\"),  # or any other supported model\n    instructions=[\n        \"If user input is not sufficent, ask user relevant questions / clarifications\",\n        \"solve problems step by steps to find the answer. do not rush.\"\n    ],\n    storage=agent_storage,\n    # add_history_to_messages=True,\n    # num_history_responses=5,\n    tools=[GoogleSearchTools()],\n    reasoning=True,\n    stream_intermediate_steps=True,\n    add_datetime_to_instructions=True,\n    debug_mode=True\n)\n\nresponse = sample_agent.print_response(\"A chemist has a 10-liter solution that is 30% alcohol. How much pure alcohol must she add to make the solution 50% alcohol?\", stream=True)\n```\nOutput of run with Debug ON:\n\n```\nWARNING:  StatReload detected changes in 'sample_agent.py'. Reloading...\nINFO:     Shutting down\nINFO:     Waiting for application shutdown.\nINFO:     Application shutdown complete.\nINFO:     Finished server process [51180]\nDEBUG *********************************************** Agent ID: ec721292-f20a-4406-a232-5c7d988a939f ***********************************************\nDEBUG ********************************************** Session ID: 29c4aea5-ef63-41ef-a22a-0d42b3c09dc5 **********************************************\nDEBUG ******************************************* Agent Run Start: 885e506d-f60c-478b-9886-36f5f3738ec3 ********************************************\nDEBUG Processing tools for model\nDEBUG Added function google_search from googlesearch\nDEBUG ============================================================= Starting Reasoning =============================================================\nDEBUG =================================================================== Step 1 ===================================================================\nDEBUG *********************************************** Agent ID: 62553686-ca62-4125-b533-74f41df327f9 ***********************************************\nDEBUG ********************************************** Session ID: 33f1a30c-83ea-4e21-b8d8-8790a7907bf1 **********************************************\nDEBUG ******************************************* Agent Run Start: 12b554ba-ea01-454e-9bb8-700857aad2d7 ********************************************\nDEBUG Model does not support structured or JSON schema outputs.\nDEBUG Structured outputs: False\nDEBUG Processing tools for model\nDEBUG Added function google_search from googlesearch\nDEBUG ------------------------------------------------------------ Groq Response Start -------------------------------------------------------------\nDEBUG ------------------------------------------------------- Model: llama-3.3-70b-versatile -------------------------------------------------------\nDEBUG =================================================================== system ===================================================================\nDEBUG You are a meticulous, thoughtful, and logical Reasoning Agent who solves complex problems through clear, structured, step-by-step analysis.\n      <instructions>\n      Step 1 - Problem Analysis:\n      - Restate the user's task clearly in your own words to ensure full comprehension.\n      - Identify explicitly what information is required and what tools or resources might be necessary.\n\n      Step 2 - Decompose and Strategize:\n      - Break down the problem into clearly defined subtasks.\n      - Develop at least two distinct strategies or approaches to solving the problem to ensure thoroughness.\n\n      Step 3 - Intent Clarification and Planning:\n      - Clearly articulate the user's intent behind their request.\n      - Select the most suitable strategy from Step 2, clearly justifying your choice based on alignment with the user's intent and task constraints.\n      - Formulate a detailed step-by-step action plan outlining the sequence of actions needed to solve the problem.\n\n      Step 4 - Execute the Action Plan:\n      For each planned step, document:\n      1. **Title**: Concise title summarizing the step.\n      2. **Action**: Explicitly state your next action in the first person ('I will...').\n      3. **Result**: Execute your action using necessary tools and provide a concise summary of the outcome.\n      4. **Reasoning**: Clearly explain your rationale, covering:\n          - Necessity: Why this action is required.\n          - Considerations: Highlight key considerations, potential challenges, and mitigation strategies.\n          - Progression: How this step logically follows from or builds upon previous actions.\n          - Assumptions: Explicitly state any assumptions made and justify their validity.\n      5. **Next Action**: Clearly select your next step from:\n          - **continue**: If further steps are needed.\n          - **validate**: When you reach a potential answer, signaling it's ready for validation.\n          - **final_answer**: Only if you have confidently validated the solution.\n          - **reset**: Immediately restart analysis if a critical error or incorrect result is identified.\n      6. **Confidence Score**: Provide a numeric confidence score (0.0–1.0) indicating your certainty in the step’s correctness and its outcome.\n\n      Step 5 - Validation (mandatory before finalizing an answer):\n      - Explicitly validate your solution by:\n          - Cross-verifying with alternative approaches (developed in Step 2).\n          - Using additional available tools or methods to independently confirm accuracy.\n      - Clearly document validation results and reasoning behind the validation method chosen.\n      - If validation fails or discrepancies arise, explicitly identify errors, reset your analysis, and revise your plan accordingly.\n\n      Step 6 - Provide the Final Answer:\n      - Once thoroughly validated and confident, deliver your solution clearly and succinctly.\n      - Restate briefly how your answer addresses the user's original intent and resolves the stated task.\n\n      General Operational Guidelines:\n      - Ensure your analysis remains:\n          - **Complete**: Address all elements of the task.\n          - **Comprehensive**: Explore diverse perspectives and anticipate potential outcomes.\n          - **Logical**: Maintain coherence between all steps.\n          - **Actionable**: Present clearly implementable steps and actions.\n          - **Insightful**: Offer innovative and unique perspectives where applicable.\n      - Always explicitly handle errors and mistakes by resetting or revising steps immediately.\n      - Adhere strictly to a minimum of 1 and maximum of 10 steps to ensure effective task resolution.\n      - Execute necessary tools proactively and without hesitation, clearly documenting tool usage.\n      - Only create a single instance of ReasoningSteps for your response.\n      </instructions>\n\n      Provide your output as a JSON containing the following fields:\n      <json_fields>\n      [\"reasoning_steps\"]\n      </json_fields>\n\n      Here are the properties for each field:\n      <json_field_properties>\n      {\n        \"reasoning_steps\": {\n          \"description\": \"A list of reasoning steps\",\n          \"items\": {\n            \"$ref\": \"#/$defs/ReasoningStep\"\n          },\n          \"type\": \"array\"\n        },\n        \"$defs\": {\n          \"NextAction\": {\n            \"type\": \"string\",\n            \"enum\": [\n              \"continue\",\n              \"validate\",\n              \"final_answer\",\n              \"reset\"\n            ],\n            \"description\": \"\"\n          },\n          \"ReasoningStep\": {\n            \"title\": {\n              \"anyOf\": [\n                {\n                  \"type\": \"string\"\n                },\n                {\n                  \"type\": \"null\"\n                }\n              ],\n              \"default\": null,\n              \"description\": \"A concise title summarizing the step's purpose\"\n            },\n            \"action\": {\n              \"anyOf\": [\n                {\n                  \"type\": \"string\"\n                },\n                {\n                  \"type\": \"null\"\n                }\n              ],\n              \"default\": null,\n              \"description\": \"The action derived from this step. Talk in first person like I will ...\"\n            },\n            \"result\": {\n              \"anyOf\": [\n                {\n                  \"type\": \"string\"\n                },\n                {\n                  \"type\": \"null\"\n                }\n              ],\n              \"default\": null,\n              \"description\": \"The result of executing the action. Talk in first person like I did this and got ... \"\n            },\n            \"reasoning\": {\n              \"anyOf\": [\n                {\n                  \"type\": \"string\"\n                },\n                {\n                  \"type\": \"null\"\n                }\n              ],\n              \"default\": null,\n              \"description\": \"The thought process and considerations behind this step\"\n            },\n            \"next_action\": {\n              \"anyOf\": [\n                {\n                  \"$ref\": \"#/$defs/NextAction\"\n                },\n                {\n                  \"type\": \"null\"\n                }\n              ],\n              \"default\": null,\n              \"description\": \"Indicates whether to continue reasoning, validate the provided result, or confirm that the result is the final answer\"\n            },\n            \"confidence\": {\n              \"anyOf\": [\n                {\n                  \"type\": \"number\"\n                },\n                {\n                  \"type\": \"null\"\n                }\n              ],\n              \"default\": null,\n              \"description\": \"Confidence score for this step (0.0 to 1.0)\"\n            }\n          }\n        }\n      }\n      </json_field_properties>\n      Start your response with `{` and end it with `}`.\n      Your output will be passed to json.loads() to convert it to a Python object.\n      Make sure it only contains valid JSON.\nDEBUG =================================================================== system ===================================================================\nDEBUG You are a helpful assistant who can solve math problems.\n      <instructions>\n      - If user input is not sufficent, ask user relevant questions / clarifications\n      - solve problems step by steps to find the answer. do not rush.\n      </instructions>\n\n      <additional_information>\n      - The current time is 2025-04-17 12:26:10.684656.\n      </additional_information>\nDEBUG ==================================================================== user ====================================================================\nDEBUG A chemist has a 10-liter solution that is 30% alcohol. How much pure alcohol must she add to make the solution 50% alcohol?\nERROR    Error calling Groq API: Error code: 400 - {'error': {'message': 'response_format` json_object cannot be combined with tool/function calling', 'type':\n         'invalid_request_error'}}\nWARNING  Attempt 1/1 failed: {\"error\":{\"message\":\"response_format` json_object cannot be combined with tool/function calling\",\"type\":\"invalid_request_error\"}}\n\nERROR    Failed after 1 attempts. Last error using Groq(llama-3.3-70b-versatile)\nERROR    Reasoning error: {\"error\":{\"message\":\"response_format` json_object cannot be combined with tool/function calling\",\"type\":\"invalid_request_error\"}}\n\nDEBUG Total Reasoning steps: 0\nDEBUG ============================================================= Reasoning finished =============================================================\nDEBUG --------------------------------------------------------- Groq Response Stream Start ---------------------------------------------------------\nDEBUG ------------------------------------------------------- Model: llama-3.3-70b-versatile -------------------------------------------------------\nDEBUG =================================================================== system ===================================================================\nDEBUG You are a helpful assistant who can solve math problems.\n      <instructions>\n      - If user input is not sufficent, ask user relevant questions / clarifications\n      - solve problems step by steps to find the answer. do not rush.\n      </instructions>\n\n      <additional_information>\n      - The current time is 2025-04-17 12:26:10.684656.\n      </additional_information>\n\n      Your output should be in JSON format.\nDEBUG ==================================================================== user ====================================================================\nDEBUG A chemist has a 10-liter solution that is 30% alcohol. How much pure alcohol must she add to make the solution 50% alcohol?\nDEBUG ================================================================= assistant ==================================================================\nDEBUG I have worked through this problem in-depth, running all necessary tools and have included my raw, step by step research.\nDEBUG ================================================================= assistant ==================================================================\nDEBUG Now I will summarize my reasoning and provide a final answer. I will skip any tool calls already executed and steps that are not relevant to the final\n      answer.\nDEBUG ================================================================= assistant ==================================================================\nDEBUG\n\n      Let's start with what we know:\n      - The chemist has 10 liters of a solution that is 30% alcohol.\n      - The chemist wants to make the solution 50% alcohol by adding pure alcohol.\n\n      To find out how much pure alcohol must be added, we first need to calculate how much alcohol is currently in the 10-liter solution. Since the solution is\n      30% alcohol, we can find the amount of alcohol in the solution by multiplying the total volume by the percentage of alcohol:\n\n      Amount of alcohol in the solution = Total volume * Percentage of alcohol\n      Amount of alcohol in the solution = 10 liters * 30%\n      Amount of alcohol in the solution = 10 liters * 0.30\n      Amount of alcohol in the solution = 3 liters\n\n      Now, let's say x liters of pure alcohol are added to the solution. The total volume of the solution will then be 10 + x liters. The chemist wants this new\n      solution to be 50% alcohol. The amount of alcohol in the new solution will be the initial amount of alcohol (3 liters) plus the amount of pure alcohol added\n      (x liters).\n\n      Amount of alcohol in the new solution = 3 liters + x liters\n\n      The total volume of the new solution is 10 + x liters, and the chemist wants this to be 50% alcohol. So, we set up the equation for the new solution:\n\n      Amount of alcohol in the new solution = Total volume of the new solution * Percentage of alcohol in the new solution\n      3 + x = (10 + x) * 0.50\n\n      Solving for x gives us the amount of pure alcohol that needs to be added:\n\n      3 + x = 5 + 0.5x\n\n      Subtract 0.5x from both sides:\n\n      3 + x - 0.5x = 5 + 0.5x - 0.5x\n      3 + 0.5x = 5\n\n      Subtract 3 from both sides:\n\n      0.5x = 2\n\n      Divide both sides by 0.5:\n\n      x = 4\n\n      So, the chemist must add 4 liters of pure alcohol to the 10-liter solution that is 30% alcohol to make it 50% alcohol.\nDEBUG *****************************************************************  METRICS  ******************************************************************\nDEBUG * Tokens:                      input=461, output=467, total=928\nDEBUG * Time:                        2.0901s\nDEBUG * Tokens per second:           223.4313 tokens/s\nDEBUG * Time to first token:         0.4022s\nDEBUG * Additional metrics:          {'completion_time': 1.6981818180000001, 'prompt_time': 0.038433183, 'queue_time': 0.219108975, 'total_time': 1.736615001}\nDEBUG *****************************************************************  METRICS  ******************************************************************\nDEBUG ---------------------------------------------------------- Groq Response Stream End ----------------------------------------------------------\nDEBUG Added 2 Messages to AgentMemory\nDEBUG Added AgentRun to AgentMemory\nDEBUG Logging Agent Run\nDEBUG ******************************************** Agent Run End: 885e506d-f60c-478b-9886-36f5f3738ec3 *********************************************\n┏━ Message ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                                                                                                                ┃\n┃ A chemist has a 10-liter solution that is 30% alcohol. How much pure alcohol must she add to make the solution 50% alcohol?                                    ┃\n┃                                                                                                                                                                ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n┏━ Response (2.8s) ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                                                                                                                ┃\n┃                                                                                                                                                                ┃\n┃                                                                                                                                                                ┃\n┃ Let's start with what we know:                                                                                                                                 ┃\n┃ - The chemist has 10 liters of a solution that is 30% alcohol.                                                                                                 ┃\n┃ - The chemist wants to make the solution 50% alcohol by adding pure alcohol.                                                                                   ┃\n┃                                                                                                                                                                ┃\n┃ To find out how much pure alcohol must be added, we first need to calculate how much alcohol is currently in the 10-liter solution. Since the solution is 30%  ┃\n┃ alcohol, we can find the amount of alcohol in the solution by multiplying the total volume by the percentage of alcohol:                                       ┃\n┃                                                                                                                                                                ┃\n┃ Amount of alcohol in the solution = Total volume * Percentage of alcohol                                                                                       ┃\n┃ Amount of alcohol in the solution = 10 liters * 30%                                                                                                            ┃\n┃ Amount of alcohol in the solution = 10 liters * 0.30                                                                                                           ┃\n┃ Amount of alcohol in the solution = 3 liters                                                                                                                   ┃\n┃                                                                                                                                                                ┃\n┃ Now, let's say x liters of pure alcohol are added to the solution. The total volume of the solution will then be 10 + x liters. The chemist wants this new     ┃\n┃ solution to be 50% alcohol. The amount of alcohol in the new solution will be the initial amount of alcohol (3 liters) plus the amount of pure alcohol added   ┃\n┃ (x liters).                                                                                                                                                    ┃\n┃                                                                                                                                                                ┃\n┃ Amount of alcohol in the new solution = 3 liters + x liters                                                                                                    ┃\n┃                                                                                                                                                                ┃\n┃ The total volume of the new solution is 10 + x liters, and the chemist wants this to be 50% alcohol. So, we set up the equation for the new solution:          ┃\n┃                                                                                                                                                                ┃\n┃ Amount of alcohol in the new solution = Total volume of the new solution * Percentage of alcohol in the new solution                                           ┃\n┃ 3 + x = (10 + x) * 0.50                                                                                                                                        ┃\n┃                                                                                                                                                                ┃\n┃ Solving for x gives us the amount of pure alcohol that needs to be added:                                                                                      ┃\n┃                                                                                                                                                                ┃\n┃ 3 + x = 5 + 0.5x                                                                                                                                               ┃\n┃                                                                                                                                                                ┃\n┃ Subtract 0.5x from both sides:                                                                                                                                 ┃\n┃                                                                                                                                                                ┃\n┃ 3 + x - 0.5x = 5 + 0.5x - 0.5x                                                                                                                                 ┃\n┃ 3 + 0.5x = 5                                                                                                                                                   ┃\n┃                                                                                                                                                                ┃\n┃ Subtract 3 from both sides:                                                                                                                                    ┃\n┃                                                                                                                                                                ┃\n┃ 0.5x = 2                                                                                                                                                       ┃\n┃                                                                                                                                                                ┃\n┃ Divide both sides by 0.5:                                                                                                                                      ┃\n┃                                                                                                                                                                ┃\n┃ x = 4                                                                                                                                                          ┃\n┃                                                                                                                                                                ┃\n┃ So, the chemist must add 4 liters of pure alcohol to the 10-liter solution that is 30% alcohol to make it 50% alcohol.                                         ┃\n┃                                                                                                                                                                ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n```\n\nWhen OpenAi 4o-mini is used, then it seems to work but no reasoning is visible so I am not sure. Here is the run log with 4o-mini\n\n```\nDEBUG *********************************************** Agent ID: a4f40b69-fd82-4e3b-99db-88740bed072a ***********************************************\nDEBUG ********************************************** Session ID: f5e04e17-747b-4dbb-9d84-87389d6a7be3 **********************************************\nDEBUG ******************************************* Agent Run Start: 013fa17a-b698-46ac-9021-6210e95dca0e ********************************************\nDEBUG Processing tools for model\nDEBUG Added function google_search from googlesearch\nDEBUG ============================================================= Starting Reasoning =============================================================\nDEBUG =================================================================== Step 1 ===================================================================\nDEBUG *********************************************** Agent ID: 82514c73-64b4-4c36-99b2-29a09ea53224 ***********************************************\nDEBUG ********************************************** Session ID: e77196a2-1223-4cff-b204-7de6debe2b0d **********************************************\nDEBUG ******************************************* Agent Run Start: dc4c6a12-c26f-4274-9583-ca720bed85e0 ********************************************\nDEBUG Setting Model.response_format to Agent.response_model\nDEBUG Structured outputs: True\nDEBUG Processing tools for model\nDEBUG Added function google_search from googlesearch\nDEBUG ----------------------------------------------------------- OpenAI Response Start ------------------------------------------------------------\nDEBUG ------------------------------------------------------------- Model: gpt-4o-mini -------------------------------------------------------------\nDEBUG =================================================================== system ===================================================================\nDEBUG You are a meticulous, thoughtful, and logical Reasoning Agent who solves complex problems through clear, structured, step-by-step analysis.\n      <instructions>\n      Step 1 - Problem Analysis:\n      - Restate the user's task clearly in your own words to ensure full comprehension.\n      - Identify explicitly what information is required and what tools or resources might be necessary.\n\n      Step 2 - Decompose and Strategize:\n      - Break down the problem into clearly defined subtasks.\n      - Develop at least two distinct strategies or approaches to solving the problem to ensure thoroughness.\n\n      Step 3 - Intent Clarification and Planning:\n      - Clearly articulate the user's intent behind their request.\n      - Select the most suitable strategy from Step 2, clearly justifying your choice based on alignment with the user's intent and task constraints.\n      - Formulate a detailed step-by-step action plan outlining the sequence of actions needed to solve the problem.\n\n      Step 4 - Execute the Action Plan:\n      For each planned step, document:\n      1. **Title**: Concise title summarizing the step.\n      2. **Action**: Explicitly state your next action in the first person ('I will...').\n      3. **Result**: Execute your action using necessary tools and provide a concise summary of the outcome.\n      4. **Reasoning**: Clearly explain your rationale, covering:\n          - Necessity: Why this action is required.\n          - Considerations: Highlight key considerations, potential challenges, and mitigation strategies.\n          - Progression: How this step logically follows from or builds upon previous actions.\n          - Assumptions: Explicitly state any assumptions made and justify their validity.\n      5. **Next Action**: Clearly select your next step from:\n          - **continue**: If further steps are needed.\n          - **validate**: When you reach a potential answer, signaling it's ready for validation.\n          - **final_answer**: Only if you have confidently validated the solution.\n          - **reset**: Immediately restart analysis if a critical error or incorrect result is identified.\n      6. **Confidence Score**: Provide a numeric confidence score (0.0–1.0) indicating your certainty in the step’s correctness and its outcome.\n\n      Step 5 - Validation (mandatory before finalizing an answer):\n      - Explicitly validate your solution by:\n          - Cross-verifying with alternative approaches (developed in Step 2).\n          - Using additional available tools or methods to independently confirm accuracy.\n      - Clearly document validation results and reasoning behind the validation method chosen.\n      - If validation fails or discrepancies arise, explicitly identify errors, reset your analysis, and revise your plan accordingly.\n\n      Step 6 - Provide the Final Answer:\n      - Once thoroughly validated and confident, deliver your solution clearly and succinctly.\n      - Restate briefly how your answer addresses the user's original intent and resolves the stated task.\n\n      General Operational Guidelines:\n      - Ensure your analysis remains:\n          - **Complete**: Address all elements of the task.\n          - **Comprehensive**: Explore diverse perspectives and anticipate potential outcomes.\n          - **Logical**: Maintain coherence between all steps.\n          - **Actionable**: Present clearly implementable steps and actions.\n          - **Insightful**: Offer innovative and unique perspectives where applicable.\n      - Always explicitly handle errors and mistakes by resetting or revising steps immediately.\n      - Adhere strictly to a minimum of 1 and maximum of 10 steps to ensure effective task resolution.\n      - Execute necessary tools proactively and without hesitation, clearly documenting tool usage.\n      - Only create a single instance of ReasoningSteps for your response.\n      </instructions>\nDEBUG =================================================================== system ===================================================================\nDEBUG You are a helpful assistant who can solve math problems.\n      <instructions>\n      - If user input is not sufficent, ask user relevant questions / clarifications\n      - solve problems step by steps to find the answer. do not rush.\n      </instructions>\n\n      <additional_information>\n      - The current time is 2025-04-17 12:32:58.934938.\n      </additional_information>\nDEBUG ==================================================================== user ====================================================================\nDEBUG A chemist has a 10-liter solution that is 30% alcohol. How much pure alcohol must she add to make the solution 50% alcohol?\nDEBUG ================================================================= assistant ==================================================================\nDEBUG Tool Calls:\n        - ID: 'call_tkNEPMwJJfhOH5KVSvysdmIU'\n          Name: 'google_search'\n          Arguments: 'query: how to calculate concentration change in solution, max_results: 5, language: en'\n        - ID: 'call_x4c61rEsj3hN2Q4TLaF7oyA0'\n          Name: 'google_search'\n          Arguments: 'query: 30% alcohol solution how to calculate additional volume needed for higher concentration, max_results: 5, language: en'\nDEBUG *****************************************************************  METRICS  ******************************************************************\nDEBUG * Tokens:                      input=1258, output=81, total=1339\nDEBUG * Prompt tokens details:       {'audio_tokens': 0, 'cached_tokens': 0}\nDEBUG * Completion tokens details:   {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}\nDEBUG * Time:                        2.1317s\nDEBUG * Tokens per second:           37.9984 tokens/s\nDEBUG *****************************************************************  METRICS  ******************************************************************\nDEBUG Getting function google_search\nDEBUG Getting function google_search\nDEBUG Running: google_search(query=how to calculate concentration change in solution, max_results=5, language=en)\nDEBUG Searching Google [en] for: how to calculate concentration change in solution\nDEBUG Running: google_search(query=..., max_results=5, language=en)\nDEBUG Searching Google [en] for: 30% alcohol solution how to calculate additional volume needed for higher concentration\nDEBUG ==================================================================== tool ====================================================================\nDEBUG Tool call Id: call_tkNEPMwJJfhOH5KVSvysdmIU\nDEBUG [\n        {\n          \"title\": \"5.4: Concentration of solutions - Chemistry LibreTexts\",\n          \"url\":\n      \"https://chem.libretexts.org/Bookshelves/Introductory_Chemistry/Introduction_to_General_Chemistry_(Malik)/05%3A_Solutions/5.04%3A_Concentration_of_solutions\n      \",\n          \"description\": \" Apr 2, 2023  \\u00b7  Take a unit volume of a given solution and add enough solvent to increase the volume of the solution 10 times for\n      a logarithmic diluiton. \"\n        },\n        {\n          \"title\": \"How can we change the concentration of a solution? - Quora\",\n          \"url\": \"https://www.quora.com/How-can-we-change-the-concentration-of-a-solution\",\n          \"description\": \" May 13, 2017  \\u00b7  You can change the concentration by simply adding more solute to the solution, or evaporating the solvent until\n      there is more solute per liter. \"\n        },\n        {\n          \"title\": \"5 Easy Ways to Calculate the Concentration of a Solution - wikiHow\",\n          \"url\": \"https://www.wikihow.com/Calculate-the-Concentration-of-a-Solution\",\n          \"description\": \" Divide the mass of the solute by the total mass of the solution. Set up your equation so the concentration C = mass of the solute/total\n      mass of the solution. \"\n        },\n        {\n          \"title\": \"How to calculate concentration of solution when it's diluted? | Socratic\",\n          \"url\": \"https://socratic.org/questions/how-to-calculate-concentration-of-solution-when-its-diluted\",\n          \"description\": \" Feb 15, 2014  \\u00b7  To calculate the concentration of a diluted solution, you use the formula c1V1=c2V2. Example. Calculate the\n      concentration of NaCl if enough\\u00a0... \"\n        },\n        {\n          \"title\": \"Changing Concentrations - YouTube\",\n          \"url\": \"https://www.youtube.com/watch?v=Cx4bedn48t4\",\n          \"description\": \" Nov 5, 2021  \\u00b7  Comments1 ; Molarity, Molality, Volume & Mass Percent, Mole Fraction & Density - Solution Concentration Problems.\n      The Organic Chemistry Tutor\\u00a0... \"\n        }\n      ]\nDEBUG ***************************************************************  TOOL METRICS  ***************************************************************\nDEBUG * Time:                        0.4616s\nDEBUG ***************************************************************  TOOL METRICS  ***************************************************************\n\n... the main agent continues to make tool calls and never finishes - that is a separate issue.\n```\n  ",
      "state": "closed",
      "author": "gauravdhiman",
      "author_type": "User",
      "created_at": "2025-04-17T19:46:34Z",
      "updated_at": "2025-04-23T12:20:41Z",
      "closed_at": "2025-04-23T12:20:41Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2870/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2870",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2870",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:06.559041",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Thanks, taking a look!\n",
          "created_at": "2025-04-18T12:34:48Z"
        },
        {
          "author": "dirkbrnd",
          "body": "So just to explain what happens with `reasoning=true`:\n- We take your main model and do a chain-of-thought run where we ask it to return reasoning steps as structured output. We also provide the model's tools in case it is needed during this reasoning effort. Some models cannot do structured output ",
          "created_at": "2025-04-18T13:00:19Z"
        },
        {
          "author": "ashpreetbedi",
          "body": "Thank you @gauravdhiman for reporting this, as @dirkbrnd highlighted -- reasonong=True will trigger another reasoning agent that does CoT -- which requires solid structured outputs and tool calling capabilities combined.\n\nWould 100% recommend using [ReasoningTools](https://docs.agno.com/reasoning/re",
          "created_at": "2025-04-18T15:47:33Z"
        }
      ]
    },
    {
      "issue_number": 2030,
      "title": "Request for YandexGPT and GigaChat models",
      "body": "## Problem Description\nHere we have no access to OpenAI, Gemini and mostly others AI providers. Launching local LLM is always a pain because of VRAM requirements.\n\n## Proposed Solution\nThere are YandexGPT, with authorization by getting temporary token called IAM every 1-12 hours. And GigaChat with token authorization, but token needs to be generated by hashing client secret and client id. Moreover their API are a bit different of popular APIs.\n\n## Additional context\nhttps://developers.sber.ru/docs/ru/gigachat/api/overview\nhttps://yandex.cloud/en/services/yandexgpt\n\n## Would you like to work on this?\n**[ ] Yes, I’d love to work on it!**\n**[X] I’m open to collaborating but need guidance.**\n**[ ] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "mr-good-bye",
      "author_type": "User",
      "created_at": "2025-02-06T07:38:58Z",
      "updated_at": "2025-04-23T12:19:01Z",
      "closed_at": "2025-04-23T12:19:01Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 11,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2030/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2030",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2030",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:06.769748",
      "comments": [
        {
          "author": "Ayush0054",
          "body": "hey @mr-good-bye  thanks for this model recommendation , we have  registered this in  our community wishlist. and let us know if you are open to contribute on this ",
          "created_at": "2025-02-17T10:02:12Z"
        },
        {
          "author": "chiruu12",
          "body": "Hey, I would like to help with this issue! ",
          "created_at": "2025-02-19T22:01:48Z"
        },
        {
          "author": "mr-good-bye",
          "body": "> hey @mr-good-bye  thanks for this model recommendation , we have  registered this in  our community wishlist. and let us know if you are open to contribute on this \n\nHi there! Yeah, I am open to working on this features, but need some mentoring to help me figure out my week spots.\n\n",
          "created_at": "2025-02-19T22:12:54Z"
        },
        {
          "author": "chiruu12",
          "body": "Want to connect and start working on this issue?\n\n> > hey [@mr-good-bye](https://github.com/mr-good-bye)  thanks for this model recommendation , we have  registered this in  our community wishlist. and let us know if you are open to contribute on this\n> \n> Hi there! Yeah, I am open to working on thi",
          "created_at": "2025-02-21T01:23:06Z"
        },
        {
          "author": "mr-good-bye",
          "body": "> Want to connect and start working on this issue?\n> \n> > > hey [@mr-good-bye](https://github.com/mr-good-bye)  thanks for this model recommendation , we have  registered this in  our community wishlist. and let us know if you are open to contribute on this\n> > \n> > \n> > Hi there! Yeah, I am open to",
          "created_at": "2025-02-24T06:41:30Z"
        }
      ]
    },
    {
      "issue_number": 2635,
      "title": "[Bug] MCPTools tool call fails from print_response",
      "body": "# Description\nSomewhere inside of `agent.print_response()`, a tool is being called without `await`ing it. As a result, the returned `Message` dataclass is invalid. The behavior for `agent.aprint_response()` works fine.\n\nI'm not sure if using MCP tools is a necessary part of this, but it was how I originally produced this.\n\n## Steps to Reproduce\n\nclient.py\n```python\nimport asyncio\nfrom agno.models.openai import OpenAIChat\nfrom agno.tools.mcp import MCPTools\nfrom dotenv import load_dotenv\nfrom agno.agent import Agent\nfrom mcp import StdioServerParameters\n\n\nasync def amain():\n    load_dotenv()\n\n    async with MCPTools(\n        server_params=StdioServerParameters(\n            command=\"python\",\n            args=[\"./server.py\"],\n        )\n    ) as tools:\n        agent = Agent(\n            model=OpenAIChat(id=\"gpt-4o-mini\"),\n            tools=[tools],\n            debug_mode=True,\n            show_tool_calls=True,\n        )\n        \n        # TODO: This fails\n        agent.print_response(\n            \"what's in chapter1?\",\n            stream=True,\n            markdown=True,\n        )\n        \n        # This works as expected\n        await agent.aprint_response(\n            \"what's in chapter1?\",\n            stream=True,\n            markdown=True,\n        )\n\n\nif __name__ == \"__main__\":\n    asyncio.run(amain())\n```\n\nserver.py\n```python\nfrom mcp.server.fastmcp import FastMCP\n\nmcp = FastMCP(\"test_tool\")\n\n\n@mcp.tool()\ndef get_handbook_section(section: str) -> str:\n    return \"test\"\n\n\nif __name__ == \"__main__\":\n    mcp.run(transport=\"stdio\")\n```\n\n\n## Agent Configuration (if applicable)\nSee client.py above. Specific prompt question matters, since it will invoke a custom tool.\n\n## Expected Behavior\nAgent should call the `get_handbook_section` tool with some arg. Agent response should respond with something about \"chapter 1\" - doesn't matter what.\n\n## Actual Behavior\nRaises validation error.\n\nNote the validation error that passes in a `<coroutine>` type where a `str` or `list[any]` should be.\n\nAgent outputs:\n```\n...\nDEBUG Getting function get_handbook_section\nDEBUG Running: get_handbook_section(section=1)\nan error occurred during closing of asynchronous generator <async_generator object stdio_client at 0x000001A8A1848B40>\nasyncgen: <async_generator object stdio_client at 0x000001A8A1848B40>\n  + Exception Group Traceback (most recent call last):\n  |   File \"D:\\dev\\agno-mcp-bug-test\\.venv\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 772, in __aexit__\n  |     raise BaseExceptionGroup(\n  | exceptiongroup.BaseExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"D:\\dev\\agno-mcp-bug-test\\.venv\\lib\\site-packages\\mcp\\client\\stdio\\__init__.py\", line 173, in stdio_client\n    |     yield read_stream, write_stream\n    | GeneratorExit\n    +------------------------------------\n...SNIP...\n    | content.list[any]\n    |   Input should be a valid list [type=list_type, input_value=<coroutine object MCPTool...l at 0x000001A8A2EAA730>, input_type=coroutine]\n    |     For further information visit https://errors.pydantic.dev/2.11/v/list_type\n    | content.str\n    |   Input should be a valid string [type=string_type, input_value=<coroutine object MCPTool...l at 0x000001A8A2EAA730>, input_type=coroutine]\n    |     For further information visit https://errors.pydantic.dev/2.11/v/string_type\n    +------------------------------------\n```\n\n## Screenshots or Logs (if applicable)\nSee above for log.\n\n## Environment\n- OS: Windows 10\n- Agno Version: v1.2.6\n- External Dependency Versions: mcp v1.6.0\n- Additional Environment Details: Python v3.10.11\n\n## Possible Solutions\nStepping through with the debugger, I see the async coroutine object being returned as the tool call result at https://github.com/agno-agi/agno/blob/v1.2.6/libs/agno/agno/tools/function.py#L392 , and the actual error is raised at https://github.com/agno-agi/agno/blob/v1.2.6/libs/agno/agno/models/base.py#L803 when it tries to assign the wrong `output` type to `Message.content`.\n",
      "state": "closed",
      "author": "jpeirson",
      "author_type": "User",
      "created_at": "2025-04-01T22:08:23Z",
      "updated_at": "2025-04-23T11:31:34Z",
      "closed_at": "2025-04-23T11:31:33Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2635/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2635",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2635",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:06.983326",
      "comments": [
        {
          "author": "jpeirson",
          "body": "Note: tried latest, and issue still exists in 1.2.11",
          "created_at": "2025-04-07T15:00:02Z"
        },
        {
          "author": "dirkbrnd",
          "body": "I'll take a look!",
          "created_at": "2025-04-08T20:25:26Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @jpeirson \nI tried the following\n**server.py**\n```python\n\"\"\"\n`fastmcp` is required for this demo. \n\n`pip install fastmcp`\n\nRun this with `fastmcp run cookbook/tools/mcp/local_server/server.py`\n\"\"\"\n\nfrom fastmcp import FastMCP\n\nmcp = FastMCP(\"weather_tools\")\n\n\n@mcp.tool()\ndef get_weather(city: str",
          "created_at": "2025-04-17T10:53:06Z"
        },
        {
          "author": "dirkbrnd",
          "body": "And this worked for me. \nI could not find the `FastMCP` inside the `mcp` package like you had it? ",
          "created_at": "2025-04-17T10:54:33Z"
        },
        {
          "author": "jpeirson",
          "body": "I was using `mcp==1.6.0` if it makes any difference. Even with `fastmcp==2.2.1` and importing from `fastmcp` I still get the same error.\n\n@dirkbrnd if you specifically try `agent.print_response(message, stream=True)` does that reproduce the error for you? The bug is with the sync version of the meth",
          "created_at": "2025-04-21T13:34:28Z"
        }
      ]
    },
    {
      "issue_number": 2782,
      "title": "[Bug] Agents with built-in memory dont work in playground",
      "body": "# Description\nfollowing the instructions in [memory](https://docs.agno.com/agents/memory), I added add_history_to_messages=True, num_history_responses=5, and read_chat_history=True. the example code works well when executed in terminal but when run with Playground, the agent does not seem to be able to retrieve information from previous chat in the same session. I told my name and immediately asked the agent my name and the agent failed to answer. the problem is resolved when providing a persistent memory. \n\n## Steps to Reproduce\n```\nfrom agno.agent import Agent\nfrom agno.tools.duckduckgo import DuckDuckGoTools\nfrom agno.models.ollama import Ollama\nfrom agno.playground import Playground, serve_playground_app\n\nfrom agno.storage.sqlite import SqliteStorage\n\n\nagent = Agent(\n    model=Ollama(id=\"mistral-small3.1\"),\n    # model=Ollama(id=\"llama3.3\"),\n    tools=[DuckDuckGoTools()],\n    markdown=True,\n    show_tool_calls=True,\n    # debug_mode=True,\n    read_chat_history=True,\n    add_history_to_messages=True,\n    num_history_responses=5,\n    # storage=SqliteStorage(table_name=\"agent_sessions\", db_file=\"tmp/agent_storage.db\"),\n    # reasoning=True,\n    read_tool_call_history=True,\n    add_datetime_to_instructions=True,\n)\n\napp = Playground(agents=[agent]).get_app()\n\nif __name__ == \"__main__\":\n    serve_playground_app(\"vision_test_agno_playground:app\", reload=True)\n```\n\n",
      "state": "closed",
      "author": "JISockBBC",
      "author_type": "User",
      "created_at": "2025-04-11T11:48:50Z",
      "updated_at": "2025-04-23T11:31:01Z",
      "closed_at": "2025-04-23T11:30:59Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2782/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2782",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2782",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:07.162745",
      "comments": [
        {
          "author": "Ayush0054",
          "body": "hey @JISockBBC i tried this example on playground and it worked well with ollama ,\ncan you please share  debug logs after passing debug_mode in Agent .\nthanks 🙌 ",
          "created_at": "2025-04-14T11:50:15Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @JISockBBC \nClosing for now, please let us know if you still experiencing this on the latest version of Agno",
          "created_at": "2025-04-23T11:31:00Z"
        }
      ]
    },
    {
      "issue_number": 2715,
      "title": "[Bug] Unable to `pprint_run_response` when using team",
      "body": "# Description\nI'm using a team and multi-turn workflow where I kick off the team, catch the response, then enter a while loop to continue working on the task until it is complete and the team leader determines the task is complete. However I would still like to pprint the response but am unable to due to TeamRunResponse not being iterable. I attempted to typecast the TeamRunResponse into a RunResponse and that didn't work either.\n\n## Steps to Reproduce\n1. initialize an agent\n2. initialize a team\n3. run `team.run(<prompt>)` and store the result in a variable\n4. run `pprint_run_response(<previous team response>)`\n\n## Agent Configuration (if applicable)\nTeam in route mode\n\n## Expected Behavior\npprint should be able to pprint the team response the same as if you ran `team.print_result()`\n\n## Screenshots or Logs (if applicable)\n  File \"/home/ec2-user/repos/merlinx/plan_and_execute/agents.py\", line 87, in <module>\n    pprint_run_response(resp)\n  File \"/home/ec2-user/repos/merlinx/.venv/lib/python3.10/site-packages/agno/utils/pprint.py\", line 51, in pprint_run_response\n    for resp in run_response:\nTypeError: 'TeamRunResponse' object is not iterable\n\n## Environment\n- OS: Amazon Linux\n- Agno Version: 1.2.6\n- External Dependency Versions: None\n- Additional Environment Details: 3.10.16\n",
      "state": "closed",
      "author": "Decap1tator",
      "author_type": "User",
      "created_at": "2025-04-07T21:20:15Z",
      "updated_at": "2025-04-23T11:30:09Z",
      "closed_at": "2025-04-23T11:30:09Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2715/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2715",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2715",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:07.330543",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Hi @Decap1tator \nI'll release a fix for this asap!",
          "created_at": "2025-04-10T13:22:06Z"
        }
      ]
    },
    {
      "issue_number": 2940,
      "title": "Model Token Exceed Limit as an Agent Response instead of just try except",
      "body": "## Problem Description\n\nWe're using Agno via a FAST API backend which connects to the Chat UI. \nCurrently, there's a try-except for handling model errors. In case of Token Exceed Limit error, the try except handles the error but there's no response in the UI. Only upon checking the logs, we get to unsertand that it's because of token exceed error. \nThe model response is in a particular format. Hence, **returning** this error message from the invoke needs changes in the helper functions that does parsing and formatting before populating it as the assistant message. Hence, it'd be good to have it as an enhancement feature in the framework\n\n## Proposed Solution\nInstead of just handling the token exceed limit using try-except, it would be good to have it as an Agent response back to the UI. From the **invoke** method of the model, the error message can be passed as Agent response, so that we get to see it in the UI.\n\n",
      "state": "closed",
      "author": "dhineshprabakaran",
      "author_type": "User",
      "created_at": "2025-04-23T06:48:11Z",
      "updated_at": "2025-04-23T11:29:56Z",
      "closed_at": "2025-04-23T11:29:55Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2940/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2940",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2940",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:07.566567",
      "comments": [
        {
          "author": "dhineshprabakaran",
          "body": "\n**models.base.py**\n\n```python\ndef _process_model_response(\n    self,\n    messages: List[Message],\n    model_response: ModelResponse,\n) -> Tuple[Message, bool]:\n    \"\"\"Processes the model's response to create an assistant message and update the overall ModelResponse.\n\n    Args:\n        messages (Lis",
          "created_at": "2025-04-23T06:55:25Z"
        },
        {
          "author": "monali7-d",
          "body": "\nHey @dhineshprabakaran \nThank you so much for using Agno and for reaching out to us. \n\nWe've added your suggestion to our community wishlist. Since Agno is open-source, you're more than welcome to explore or even take a shot at building it yourself.If you decide to dive in and need any guidance alo",
          "created_at": "2025-04-23T11:29:55Z"
        }
      ]
    },
    {
      "issue_number": 2679,
      "title": "[Bug] An error occurs when calling Newspaper4kTools in the Team Coordinate mode: The function read_article was not found.",
      "body": "# Description\nAn error occurs when calling Newspaper4kTools in the Team Coordinate mode: The function read_article was not found.\n\n## Steps to Reproduce\n1. search_agent: Search topic using DuckDuckGoTools and return 5 urls.\n2. summarize_agent: Read 5 urls using Newspaper4kTools and summarize.\n\n## Agent Configuration (if applicable)\nsummarize_agent = Agent(\n    name=\"Summarize Agent\",\n    role=\"Summarizer\",\n    model=model_gpt4o,\n    instructions=[\n        \"Read and summarize the content of each provided website in turn\",\n        \"Finally, summarize the summaries of all websites and return the result.\",\n    ],\n    tools=[Newspaper4kTools(cache_results=True)],\n    add_datetime_to_instructions=True,\n    show_tool_calls=True,\n    markdown=True,\n)\n\n\n## Screenshots or Logs (if applicable)\n<img width=\"560\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/ea2c190f-4b79-4a33-a4f7-02832da3ef34\" />\n\n## Environment\n- OS: (e.g. macOS, Windows 11)\n- Browser (if relevant): (e.g. Chrome 108, Firefox 107)\n- Agno Version: (e.g. v1.0.0)\n- External Dependency Versions: (e.g., yfinance 0.2.52)\n- Additional Environment Details: (e.g., Python 3.10)\n",
      "state": "closed",
      "author": "freefish1218",
      "author_type": "User",
      "created_at": "2025-04-04T14:32:09Z",
      "updated_at": "2025-04-23T11:29:52Z",
      "closed_at": "2025-04-23T11:29:51Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2679/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2679",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2679",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:07.739757",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Hi @freefish1218 \nWe believe we fixed this issue in the latest 1.2.8 release? Would you mind checking if it works for you?\n\nOtherwise can you share your full example and we'll replicate it on our side.",
          "created_at": "2025-04-05T07:44:59Z"
        },
        {
          "author": "freefish1218",
          "body": "> Hi [@freefish1218](https://github.com/freefish1218) We believe we fixed this issue in the latest 1.2.8 release? Would you mind checking if it works for you?\n> \n> Otherwise can you share your full example and we'll replicate it on our side.\n\nThe ​read_article function is now working correctly. \nBut",
          "created_at": "2025-04-06T03:32:51Z"
        },
        {
          "author": "freefish1218",
          "body": "Why can't the method ​**transfer_task_to_member** be found?\n\n<img width=\"965\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/bce8a8dc-ce1e-4217-a0e1-bf20432cc6a7\" />",
          "created_at": "2025-04-13T14:18:18Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@freefish1218 On what version are you seeing this? I believe this has been resolved in the latest versions.",
          "created_at": "2025-04-17T13:51:58Z"
        },
        {
          "author": "beiluo",
          "body": "model=model_gpt4o,\nI think this is the result, you should be using the same model instance on multiple Agents or Teams, I recommend you to create multiple, I solved it this way.",
          "created_at": "2025-04-23T05:54:12Z"
        }
      ]
    },
    {
      "issue_number": 1626,
      "title": "Can phidata integrate vLLM model?",
      "body": "VLLM is also the openai specification interface, and my test case for phidata is a toolkit that does not call phidata.",
      "state": "closed",
      "author": "364378743",
      "author_type": "User",
      "created_at": "2024-12-23T05:19:54Z",
      "updated_at": "2025-04-23T11:24:46Z",
      "closed_at": "2025-04-23T11:24:46Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/1626/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/1626",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/1626",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:07.934343",
      "comments": [
        {
          "author": "manthanguptaa",
          "body": "Hey @364378743, we currently don't support vLLM but I will take that as a feature request! ",
          "created_at": "2024-12-25T08:12:27Z"
        },
        {
          "author": "maziyarpanahi",
          "body": "Hi @manthanguptaa \nThis issue has been closed as completed, does this mean there is a support for vLLM and TGI libraries? ",
          "created_at": "2025-02-02T22:28:42Z"
        }
      ]
    },
    {
      "issue_number": 2069,
      "title": "[Feature Request]: Add Log File Support to Agno for Easier Monitoring & Debugging",
      "body": "## Problem Description\nI was comparing the performance of normal chunking methods and agentic chunking methods. While evaluating different packages for production, I explored Agno to measure performance, token usage, and cost analysis. Unlike LangChain, which provides callbacks to track token usage, Agno primarily logs execution traces internally. This made it difficult to retrieve cost-related information directly.\n\nTo address this, I modified the `Timer`, `Metrics`, and `OpenAIChat.response()` functions to capture the total LLM calls and cost calculations. However, Agno currently does not provide an easy way for users to access logs.\n\nSince Agno logs everything internally, users should have the option to store logs in a configurable log file for debugging and cost analysis.\n\n## Proposed Solution\nTo improve usability and debugging, I propose adding a file-based logging mechanism to Agno’s logging system. This would allow users to:\n\nDefine a custom log file path using the ENV variable `AGNO_LOG_FILE`.\n\nIf no log file is explicitly set, store logs in the root directory where the package is used.\n\nCode: Modification path: `agno/libs/agno/agno/utils/log.py`\n\nProposed Updation Code:\n```\nimport logging\nfrom os import getenv\nfrom rich.logging import RichHandler\n\nLOGGER_NAME = \"agno\"\n\ndef get_logger(logger_name: str, log_file: str = None) -> logging.Logger:\n    \"\"\"\n    Creates and configures a logger with RichHandler for console output and optionally logs to a file.\n    \n    :param logger_name: Name of the logger.\n    :param log_file: Optional log file path to store logs.\n    :return: Configured logger instance.\n    \"\"\"\n    # Rich console handler\n    rich_handler = RichHandler(\n        show_time=False,\n        rich_tracebacks=False,\n        show_path=True if getenv(\"AGNO_API_RUNTIME\") == \"dev\" else False,\n        tracebacks_show_locals=False,\n    )\n    rich_handler.setFormatter(logging.Formatter(fmt=\"%(message)s\"))\n\n    _logger = logging.getLogger(logger_name)\n    _logger.setLevel(logging.INFO)\n    _logger.addHandler(rich_handler)\n\n    # If a log file is provided, add a file handler\n    if log_file:\n        file_handler = logging.FileHandler(log_file, mode=\"a\")  # Append mode\n        file_handler.setFormatter(logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\"))\n        _logger.addHandler(file_handler)\n\n    _logger.propagate = False\n    return _logger\n\n\n# Allow users to set a log file\nLOG_FILE_PATH = getenv(\"AGNO_LOG_FILE\", \"agno.log\")  # Default log file if not provided\nlogger: logging.Logger = get_logger(LOGGER_NAME, LOG_FILE_PATH)\n\n\ndef set_log_level_to_debug():\n    \"\"\"Set logger level to DEBUG.\"\"\"\n    _logger = logging.getLogger(LOGGER_NAME)\n    _logger.setLevel(logging.DEBUG)\n\n\ndef set_log_level_to_info():\n    \"\"\"Set logger level to INFO.\"\"\"\n    _logger = logging.getLogger(LOGGER_NAME)\n    _logger.setLevel(logging.INFO)\n```\n\n## Alternatives Considered\nAfter reviewing the package, I noticed Agno provides platform-based monitoring for cost and performance tracking. However, it does not expose callbacks for local debugging or detailed execution tracing, unlike **LangChain Callbacks** https://python.langchain.com/v0.1/docs/modules/callbacks/)\n\nBy enabling file-based logging, users can independently monitor token usage, execution time, and cost without relying solely on Agno’s platform.\n\n\n## Additional context\nInclude any extra information that might be helpful, such as:\n\n- **Langchain Callbacks** allows Customized Monitoring and Logging: https://python.langchain.com/v0.1/docs/modules/callbacks/ \n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n- [x] **Yes, I’d love to work on it!**\n- [x] **I’m open to collaborating but need guidance.**\n- [ ]  **No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "kolhesamiksha",
      "author_type": "User",
      "created_at": "2025-02-10T16:58:42Z",
      "updated_at": "2025-04-23T11:20:15Z",
      "closed_at": "2025-02-26T00:30:26Z",
      "labels": [
        "enhancement",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2069/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2069",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2069",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:08.109235",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hi @kolhesamiksha \n\nThank you so much for using Agno and sharing your valuable input! We've added your suggestion to our community wishlist. Our team will be coming together soon to discuss it, and we’ll be sure to keep you updated on any progress.",
          "created_at": "2025-02-11T06:41:56Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-02-26T00:30:25Z"
        },
        {
          "author": "RhysC",
          "body": "I would love to see some logging options, I'm just not sure file based is the best idea. Why not expose a std logging abstraction that defaults to the current implementation but can be overridden to file/std io etc?",
          "created_at": "2025-03-21T05:39:02Z"
        },
        {
          "author": "gyalpodongo",
          "body": "Would love to see this happening too",
          "created_at": "2025-04-11T23:45:31Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @gyalpodongo \nThank you so much for using Agno and for reaching out to us. \n\nWe've added your suggestion to our community wishlist. Since Agno is open-source, you're more than welcome to explore or even take a shot at building it yourself.If you decide to dive in and need any guidance along the ",
          "created_at": "2025-04-23T11:20:14Z"
        }
      ]
    },
    {
      "issue_number": 2134,
      "title": "[Question] Enabling Independent LLM Responses When Knowledge Base is Irrelevant",
      "body": "Hello,\n\nThank you for maintaining this great project. I’m developing an Agentic RAG application using the DocumentKnowledgeBase with PGVector.\n\nIn cases where the knowledge base contains no relevant information for a given prompt, I’d like the LLM to generate answers independently **without relying on retrieved documents**. While this can be partially addressed through prompting, is there a programmatic way to control this behavior—for example, by specifying a similarity threshold or distance value for retrieved documents?\n\nSpecifically:\n\nCould we introduce a threshold parameter (e.g., min_similarity or max_distance) to determine whether to use the knowledge base or bypass it entirely?\n\nIf such a parameter already exists, could you clarify how to configure it?\n\nThis would allow dynamic switching between knowledge-grounded and independent LLM responses based on retrieval relevance.",
      "state": "closed",
      "author": "ozbekburak",
      "author_type": "User",
      "created_at": "2025-02-15T07:57:05Z",
      "updated_at": "2025-04-23T11:19:09Z",
      "closed_at": "2025-04-23T11:19:07Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2134/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2134",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2134",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:08.316058",
      "comments": [
        {
          "author": "manthanguptaa",
          "body": "Hey @ozbekburak! We do have a reranker, but I totally understand that it doesn’t offer the level of granularity you're looking for. I really love your suggestion, though! I’ve added it as a feature request, and I’m excited to get it shipped. We’ll keep you in the loop and let you know as we make pro",
          "created_at": "2025-02-17T10:02:00Z"
        },
        {
          "author": "jesalg",
          "body": "I needed something similar, and I ended up writing a custom `PgVector` implementation that gave me this information. My code is super ugly, but I'll share it here in case it helps provide some inspiration:\n\n```py\n\"\"\"\nCustom PgVector implementation that preserves hybrid scores in document metadata.\n\"",
          "created_at": "2025-04-01T04:05:27Z"
        },
        {
          "author": "ozbekburak",
          "body": "> I needed something similar, and I ended up writing a custom `PgVector` implementation that gave me this information. My code is super ugly, but I'll share it here in case it helps provide some inspiration:\n> \n> \"\"\"\n> Custom PgVector implementation that preserves hybrid scores in document metadata.",
          "created_at": "2025-04-02T07:30:05Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @ozbekburak \nThank you so much for using Agno and for reaching out to us. \n\nWe've added your suggestion to our community wishlist. Since Agno is open-source, you're more than welcome to explore or even take a shot at building it yourself.If you decide to dive in and need any guidance along the w",
          "created_at": "2025-04-23T11:19:07Z"
        }
      ]
    },
    {
      "issue_number": 2250,
      "title": "[Feature Request] Support LlamaIndex Tool directly",
      "body": "Currently Agno agent can only uses LlamaIndex retrievers as knowledge bases.\nIt would be very handy if LlamaIndex Tool classes can be supported natively in Agno agents.\n\nhttps://github.com/run-llama/llama_index/blob/34184044a31d0f16bc7855b0ee2ed5ffc14829a8/llama-index-core/llama_index/core/tools/types.py\n",
      "state": "closed",
      "author": "sigren",
      "author_type": "User",
      "created_at": "2025-02-27T17:02:28Z",
      "updated_at": "2025-04-23T11:17:22Z",
      "closed_at": "2025-04-23T11:17:21Z",
      "labels": [
        "enhancement",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2250/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2250",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2250",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:08.521599",
      "comments": [
        {
          "author": "manthanguptaa",
          "body": "Hey @sigren! Are there any specific tools you’re looking for that Agno doesn’t support? I’d love to understand your needs better and see how we can help.",
          "created_at": "2025-02-28T08:23:12Z"
        },
        {
          "author": "sigren",
          "body": "The most useful would be \"query engine tools\" and \"retriever tools\".",
          "created_at": "2025-03-04T02:31:22Z"
        },
        {
          "author": "manthanguptaa",
          "body": "@sigren, can you please expand on it more? What does the query engine and retriever tool does exactly?",
          "created_at": "2025-03-08T03:39:36Z"
        },
        {
          "author": "sigren",
          "body": "The query engine tool accepts a query, potentially transforms the query on the fly before it's used against the knowledge base to return some result. The retriever tool is the same but excludes the query transformation part.\n\nThe way knowledge bases in LlamaIndex are used as tools for an agent is sh",
          "created_at": "2025-03-12T16:54:17Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-03-27T00:31:41Z"
        }
      ]
    },
    {
      "issue_number": 2303,
      "title": "[Feature Request] Support json schemas in Gemini client in addition to pydantic base model",
      "body": "## Problem Description\nI noticed that response_model parameter is defined as of BaseModel type. Likewise on Gemini code its parsing is \n\n```\n        if (\n            self.response_format is not None\n            and isinstance(self.response_format, type)\n            and issubclass(self.response_format, BaseModel)\n        ):\n            config[\"response_mime_type\"] = \"application/json\"  # type: ignore\n            config[\"response_schema\"] = self.response_format\n```\n\nThis implementation requires that schema is always expressed as pydantic's BaseModel and doesn't allow Gemini's native json schema dict. \n\n## Proposed Solution\nIn the above code there could be an alternative else branch checking if a dict is used instead.\n\n## Alternatives Considered\nRequires the use of pydantic ?\n\n\n## Additional context\n-\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[ ] Yes, I’d love to work on it!**\n**[X] I’m open to collaborating but need guidance.**\n**[ ] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "ghost",
      "author_type": "User",
      "created_at": "2025-03-05T21:55:44Z",
      "updated_at": "2025-04-23T11:13:51Z",
      "closed_at": "2025-04-23T11:13:49Z",
      "labels": [
        "enhancement",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2303/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2303",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2303",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:08.726105",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Hi @rjpereira \n[From their docs](https://ai.google.dev/gemini-api/docs/structured-output?lang=python) it looks like what we are doing is their support for JSON schema, or rather a Pydantic model. What native JSON schema do you refer to ? ",
          "created_at": "2025-03-07T12:48:50Z"
        },
        {
          "author": "ghost",
          "body": "In https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/control-generated-output there are reference to the specs:\n- \n- https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.cachedContents#Schema\n- https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/co",
          "created_at": "2025-03-07T16:28:47Z"
        },
        {
          "author": "ghost",
          "body": "Please see example below to illustrate the problem:\n\n\n```\n#!/usr/bin/env python\nimport os\n\nfrom typing import List\nfrom agno.agent import Agent\nfrom agno.models.google import Gemini\nfrom agno.tools.googlesearch import GoogleSearchTools\nfrom agno.workflow import RunResponse\nfrom pydantic import BaseM",
          "created_at": "2025-03-12T04:22:59Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-03-27T00:31:39Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @rjpereira \n\nThank you for using Agno and for reaching out to us.\nWe've added your suggestion to our community wishlist. Since Agno is open-source, you're welcome to explore or even attempt to build it yourself.\nIf you decide to dive in and need any guidance, we’d be happy to help.",
          "created_at": "2025-04-23T11:13:50Z"
        }
      ]
    },
    {
      "issue_number": 2383,
      "title": "AppleScript tooling",
      "body": "## Problem Description\nSimilar to OpenAI operator, a moonshot of AI is to have an independent agent using a machine to run tasks on ordinary programs such as Safari, Photoshop, etc.\n\n## Proposed Solution\nProvide AppleScript tooling in order to execute arbitrary commands on Mac and run AppleScript \n\n## Additional context\nObviously there are security concerns about running applescripts, one could imagine in the future to run this agent in an osx virtual machine.\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[ ] Yes, I’d love to work on it!**\n**[x] I’m open to collaborating but need guidance.**\n**[ ] No, I’m just sharing the idea.**\n\n## Prototype implementation\n\nThe following implementation works for the prompt I tested, however the  tool`get_applescript_dictionary_for_app ` needs to be improved, the agent should provide only the app name and the tool should attempt to find it, also because there are problems with builtin apps such as email located under /System/Applications/Mail.app instead of the path the agent suggested which is /Applications/Mail.app.\n\n```\n\n\nimport subprocess\nfrom agno.utils.log import logger\n\nfrom agno.agent import Agent\nfrom agno.models.ollama import Ollama\nfrom agno.models.openai import OpenAIChat\n\n\nMODEL = OpenAIChat(id=\"gpt-4o\")\n\ndef get_applescript_dictionary_for_app(app_path: str) -> str:\n    \"\"\"Use this function to run sdef over a diven app name.\n\n    Args:\n        app_path (str): application path such as /Applications/Safari.app.\n\n    Returns:\n        str: XML string of sdef response.\n    \"\"\"\n\n    try:\n        result = subprocess.run([\"sdef\", app_path], capture_output=True, text=True, check=True)\n        return result.stdout\n    except subprocess.CalledProcessError as e:\n        logger.error(f\"Error: {e.stderr}\")\n        return f\"Error: {e.stderr}\"\n\ndef run_applescript(script: str) -> str:\n    \"\"\"\n    Executes an AppleScript command string and returns its output.\n\n    Parameters:\n        script (str): The AppleScript code to execute.\n\n    Returns:\n        str: The output of the AppleScript execution.\n\n    Raises:\n        subprocess.CalledProcessError: If the AppleScript execution fails.\n    \"\"\"\n\n    logger.info(f\"Running applescript: {script}\")\n    try:\n        result = subprocess.run(\n            [\"osascript\", \"-e\", script],\n            capture_output=True,\n            text=True,\n            check=True\n        )\n        return result.stdout.strip()\n    except subprocess.CalledProcessError as e:\n        logger.error(f\"AppleScript Error: {e.stderr.strip()}\")\n        return f\"AppleScript Error: {e.stderr.strip()}\"\n\nagent = Agent(\n    model = MODEL,\n    tools=[get_applescript_dictionary_for_app, run_applescript],\n    show_tool_calls=True,\n    markdown=True,\n    instructions=(\n        \"1. Execution Strategy 🔍\",\n        \"   - When the user asks you to execute a command always ask for applescript dictionary first\",\n        \"   - Read the dictionary and figure out the right apple script command\",\n        \"   - Assume the user wants to do something on an app, so if the user asks to compose an email, open mail on osx, etc...\",\n    ),\n\n)\n\n\nif __name__ == \"__main__\":\n    import random\n\n    from rich.prompt import Prompt\n\n    # Fun example prompts to showcase the generator's versatility\n    example_prompts = [\n        \"Open google on safari\",\n        \"open email and create a draft about buying the milk\",\n        \"Add a reminder on my calendary to buy milk tomorrow morning\"\n    ]\n\n    # Get topic from user\n    topic = Prompt.ask(\n        \"[bold]Enter a command to execute[/bold] (or press Enter for a random example)\\n✨\",\n        default=random.choice(example_prompts),\n    )\n\n    agent.print_response(topic, stream=True)\n\n```",
      "state": "closed",
      "author": "riccardodivirgilio",
      "author_type": "User",
      "created_at": "2025-03-13T06:34:36Z",
      "updated_at": "2025-04-23T11:13:15Z",
      "closed_at": "2025-03-28T00:31:51Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2383/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2383",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2383",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:08.923482",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-03-28T00:31:50Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @riccardodivirgilio Thank you so much for using Agno and for reaching out to us. \n\nWe've added your suggestion to our community wishlist. Since Agno is open-source, you're more than welcome to explore or even take a shot at building it yourself.If you decide to dive in and need any guidance alon",
          "created_at": "2025-04-23T11:13:14Z"
        }
      ]
    },
    {
      "issue_number": 2452,
      "title": "[Feature Request]Adding \"Yolo Mode\" to ShellTools",
      "body": "# Feature Request: Adding \"Yolo Mode\" to ShellTools\n\n## Problem Description\nShellTools currently executes all shell commands immediately without confirmation when a command is entered. This is especially dangerous when performing destructive operations or making critical system changes, and increases the risk of data loss or system failure due to user error.\n\n## Proposed Solution\nWe propose to add a \"Yolo mode\" toggle feature to ShellTools. With this feature:\n\n- Enable safe mode by default and prompt for confirmation before executing potentially dangerous commands\n- Allow immediate execution of allowed commands without confirmation only if explicitly enabled in \"Yolo mode\"\n- Arguments allow customization of the default mode of operation and the list of allowed commands by command\n\n## Additional context\nMany package managers and tools have similar safety features:\n- Yolo mode for cursor and windsurf",
      "state": "closed",
      "author": "champaya",
      "author_type": "User",
      "created_at": "2025-03-19T07:54:06Z",
      "updated_at": "2025-04-23T11:12:57Z",
      "closed_at": "2025-03-20T08:11:09Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2452/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2452",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2452",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:09.113660",
      "comments": [
        {
          "author": "Ansub",
          "body": "Appreciate the suggestion @champaya! 'Yolo Mode' for Shell Tools has been added to our community wishlist. This could be a useful addition, and we’ll definitely keep it in mind for future updates!",
          "created_at": "2025-03-20T08:11:09Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @champaya \nThank you so much for using Agno and for reaching out to us. \n\nWe've added your suggestion to our community wishlist. Since Agno is open-source, you're more than welcome to explore or even take a shot at building it yourself.If you decide to dive in and need any guidance along the way",
          "created_at": "2025-04-23T11:12:56Z"
        }
      ]
    },
    {
      "issue_number": 2510,
      "title": "[Feature Request]Tool output directly, avoiding any agent modification during execution.",
      "body": "## Problem Description\nThe issue is that I need the output from the tool to be delivered directly, without being processed or modified by the agent (LLM).\n**Example:** *\"When I make a query like “Give me the sum of 2 and 3,” I have implemented a tool using the Python function `add_two_nums()` that generates the result in a specific format defined in its return statement. However, instead of providing the tool’s output directly, the result is being passed through the LLM, which modifies it before delivering it to me.”*\n\n## Proposed Solution\nIntroduce a parameter or mechanism that enables direct output from the tool, bypassing any inference or modification by the LLM. This would ensure that the tool’s response is returned exactly as intended.\n\n## Would you like to work on this?\n** No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "crawlerj1",
      "author_type": "User",
      "created_at": "2025-03-24T06:30:04Z",
      "updated_at": "2025-04-23T11:12:14Z",
      "closed_at": "2025-04-22T16:29:58Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2510/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2510",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2510",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:14.343089",
      "comments": [
        {
          "author": "DAW2100",
          "body": "I was also interested in this, so I had to dig into the source code and it turned out that such functionality is present.\nSomething like this:\n\n```\nfrom agno.tools import tool\n\ndef post_hook(fc: FunctionCall):\n    print(f\"post-hook: {fc.function.name}\")\n    print(f\"Arguments: {fc.arguments}\")\n    pr",
          "created_at": "2025-03-24T16:32:56Z"
        },
        {
          "author": "tusharleek",
          "body": "Hey @DAW2100 @crawlerj1 you have any idea how to add pydantic models as input of these functions. In my case whenever I am adding a pydantic object LLM is sending null params.",
          "created_at": "2025-03-24T21:51:58Z"
        },
        {
          "author": "DimRgs",
          "body": "I currently have the same need. And after my attempts, I found that when creating an agent, specifying `structured_outputs=True` and a `response_model` will cause the LLM to fail to call tools properly, just like the [issue ](https://github.com/agno-agi/agno/issues/2433) I raised. I hope this proble",
          "created_at": "2025-03-25T03:09:31Z"
        },
        {
          "author": "crawlerj1",
          "body": "> Hey [@DAW2100](https://github.com/DAW2100) [@crawlerj1](https://github.com/crawlerj1) you have any idea how to add pydantic models as input of these functions. In my case whenever I am adding a pydantic object LLM is sending null params.\n\ni have an idea but i dont think it is robust. However, you ",
          "created_at": "2025-03-25T05:29:08Z"
        },
        {
          "author": "tusharleek",
          "body": "Ohh thanks @crawlerj1 ",
          "created_at": "2025-03-25T07:19:35Z"
        }
      ]
    },
    {
      "issue_number": 2515,
      "title": "[Feature Request] Suggestion: Enhance Knowledge Base with QA Pairs for Improved Recall",
      "body": "Description:\n\nHi Agno Team,\n\nFirst of all, I want to commend you on the fantastic work you've done with Agno! It's truly impressive how the framework simplifies complex tasks and makes them more accessible.\n\nI’d like to suggest a potential enhancement that could further improve Agno's knowledge base capabilities. Inspired by frameworks like MaxKB and Vanna, I believe adding support for QA (Question-Answer) pairs could significantly enhance the recall and accuracy of the system.\n\nProposed Feature:\nQA Pair Integration: Allow users to manually add QA pairs to the knowledge base. These pairs could include DDL definitions, business logic descriptions, or any other relevant context.\nAutomatic Question Generation: Implement an optional feature where the system can automatically generate related questions for imported content, similar to how MaxKB does it.\nEnhanced Recall: During queries, the system could leverage these QA pairs to improve recall by matching user questions not just with direct content but also with pre-generated questions.\nWhy This Matters:\nBridging the Gap: Users often phrase questions differently from how content is expressed. QA pairs act as a bridge, ensuring relevant content is retrieved even if the phrasing differs.\nContextual Enhancement: Adding QA pairs can provide richer context, similar to how Vanna uses DDL definitions to improve SQL generation.\nFlexibility: Manual QA pair addition allows users to tailor the knowledge base to their specific needs, while automatic generation saves time.\nImplementation Ideas:\nAPI Endpoints: Add endpoints for CRUD operations on QA pairs.\nVectorization: Store both questions and answers as vectors to enable semantic search.\nQuery Processing: During queries, match user questions with both content and pre-generated questions, taking the highest similarity score for each result.\nI believe this feature could be a valuable addition to Agno, making it even more powerful and user-friendly. I’d be happy to discuss this further or provide more details if needed.\n\nThank you for considering this suggestion, and keep up the great work!\n\nBest regards,",
      "state": "closed",
      "author": "lemonhall",
      "author_type": "User",
      "created_at": "2025-03-24T12:21:07Z",
      "updated_at": "2025-04-23T11:11:27Z",
      "closed_at": "2025-04-23T11:11:26Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2515/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2515",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2515",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:14.519055",
      "comments": [
        {
          "author": "manthanguptaa",
          "body": "This is such a fantastic suggestion, @lemonhall! Thank you so much for sharing your ideas with us—we truly appreciate it. We’ll add this to our community wishlist and do our best to bring it to life. Since we’re a small team, it might take a little time to make its way up our priority list, but plea",
          "created_at": "2025-03-26T04:58:48Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-10T00:32:04Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @lemonhall Thank you so much for using Agno and for reaching out to us. \n\nWe've added your suggestion to our community wishlist. Since Agno is open-source, you're more than welcome to explore or even take a shot at building it yourself.If you decide to dive in and need any guidance along the way",
          "created_at": "2025-04-23T11:11:26Z"
        }
      ]
    },
    {
      "issue_number": 2675,
      "title": "[Feature Request]The current PDF knowledge base does not allow empty path initialization",
      "body": "## Problem Description\nThe current PDF knowledge base does not allow empty path initialization\n\n## Proposed Solution\nExplain your ideal solution. How should this feature work?\nBe as detailed as possible to help us understand your vision.\n\n## Alternatives Considered\n\n\n```\nfrom pathlib import Path\nfrom typing import AsyncIterator, Iterator, List, Union, Optional, Dict\nfrom agno.utils.log import log_info\nfrom pydantic import Field\nfrom agno.document import Document\nfrom agno.document.reader.pdf_reader import PDFImageReader, PDFReader\nfrom agno.knowledge.agent import AgentKnowledge\n\n\n\nclass PDFKnowledgeBase(AgentKnowledge):\n    path: Optional[Union[str, Path]] = None\n\n    exclude_files: List[str] = Field(default_factory=list)\n\n    reader: Union[PDFReader, PDFImageReader] = PDFReader()\n\n    @property\n    def document_lists(self) -> Iterator[List[Document]]:\n        \"\"\"Iterate over PDFs and yield lists of documents.\n        Each object yielded by the iterator is a list of documents.\n\n        Returns:\n            Iterator[List[Document]]: Iterator yielding list of documents\n        \"\"\"\n        if self.path is None:\n            return\n\n        _pdf_path: Path = Path(self.path) if isinstance(self.path, str) else self.path\n\n        if _pdf_path.exists() and _pdf_path.is_dir():\n            for _pdf in _pdf_path.glob(\"**/*.pdf\"):\n                if _pdf.name in self.exclude_files:\n                    continue\n                yield self.reader.read(pdf=_pdf)\n        elif _pdf_path.exists() and _pdf_path.is_file() and _pdf_path.suffix == \".pdf\":\n            if _pdf_path.name in self.exclude_files:\n                return\n            yield self.reader.read(pdf=_pdf_path)\n\n        else:\n            raise FileNotFoundError(f\"PDFKnowledgeBase: path `{self.path}` is not a valid PDF file or directory.\")\n\n    @property\n    async def async_document_lists(self) -> AsyncIterator[List[Document]]:\n        \"\"\"Iterate over PDFs and yield lists of documents.\n        Each object yielded by the iterator is a list of documents.\n\n        Returns:\n            Iterator[List[Document]]: Iterator yielding list of documents\n        \"\"\"\n        if self.path is None:\n            return\n\n        _pdf_path: Path = Path(self.path) if isinstance(self.path, str) else self.path\n\n        if _pdf_path.exists() and _pdf_path.is_dir():\n            for _pdf in _pdf_path.glob(\"**/*.pdf\"):\n                if _pdf.name in self.exclude_files:\n                    continue\n                yield await self.reader.async_read(pdf=_pdf)\n        elif _pdf_path.exists() and _pdf_path.is_file() and _pdf_path.suffix == \".pdf\":\n            if _pdf_path.name in self.exclude_files:\n                return\n            yield await self.reader.async_read(pdf=_pdf_path)\n\n        else:\n            raise FileNotFoundError(f\"PDFKnowledgeBase: `path` is not a valid PDF file or directory.\")\n\n    def load(\n            self,\n            recreate: bool = False,\n            upsert: bool = True,\n            skip_existing: bool = True,\n            filters: Optional[Dict[str, Union[str, int]]] = None,\n    ) -> None:\n        \"\"\"安全加载 PDF 到向量库（支持空 path，自动跳过）\"\"\"\n        if self.path is None:\n            log_info(\"PDFKnowledgeBase.load() Skipped: path not set, no document loaded.\")\n            return\n\n        super().load(\n            recreate=recreate,\n            upsert=upsert,\n            skip_existing=skip_existing,\n            filters=filters,\n        )\n```\n\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[ ] Yes, I’d love to work on it!**\n",
      "state": "closed",
      "author": "tangmingcheng",
      "author_type": "User",
      "created_at": "2025-04-04T11:50:39Z",
      "updated_at": "2025-04-23T11:09:58Z",
      "closed_at": "2025-04-23T11:09:57Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2675/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2675",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2675",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:14.713177",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-19T00:31:13Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @tangmingcheng \nThank you so much for using Agno and for reaching out to us. \n\nWe've added your suggestion to our community wishlist. Since Agno is open-source, you're more than welcome to explore or even take a shot at building it yourself.If you decide to dive in and need any guidance along th",
          "created_at": "2025-04-23T11:09:57Z"
        }
      ]
    },
    {
      "issue_number": 2681,
      "title": "Agno graph like structrure in langflow",
      "body": "**Summary**\nImplement a new workflow that mirrors the functionality of Langgraph to allow for fine-grained control over individual agents and groups (teams) of agents. This enhancement should leverage concepts found in the Agno documentation and Langgraph, providing a flexible and modular approach to managing agent behavior and interactions.\n\n**Motivation**\nEnhanced Control: Current workflows lack the ability to manage agents and teams at a granular level, limiting our ability to tailor interactions and behaviors.\n\n**Scalability:** As our system grows, the need for structured control and orchestration of multiple agents becomes critical.\n\n**Inspiration from Langgraph**: Langgraph provides an intuitive way to model workflows and interactions. Adopting similar strategies could improve both the user experience and system robustness.\n\nReference Documentation: This feature should draw upon established practices as described in the Agno docs and the Langgraph implementation.\n\n**Proposed Implementation**\n**Team Control**:\nSupport hierarchical team structures where sub-teams inherit properties or constraints from parent teams.\n\n**Workflow Configuration**:\n\nIntegrate a workflow builder similar to Langgraph that allows users to visually or programmatically define agent interactions and control flows.\n\nEnsure the builder supports branching logic, conditionals, and sequential execution patterns.\n\n",
      "state": "closed",
      "author": "sathyasubrahamanaya",
      "author_type": "User",
      "created_at": "2025-04-05T06:09:08Z",
      "updated_at": "2025-04-23T11:09:16Z",
      "closed_at": "2025-04-23T11:09:16Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2681/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2681",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2681",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:14.929599",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hey @sathyasubrahamanaya ,\nThanks so much for reaching out and for being a part of the Agno community!\nWe really appreciate you taking the time to suggest this feature. Since Agno is open source, feel free to take a stab at implementing it and raise a PR — we'd love to review and collaborate on it w",
          "created_at": "2025-04-07T06:30:23Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-22T00:33:19Z"
        }
      ]
    },
    {
      "issue_number": 2875,
      "title": "[Feature Request] Can we support one agent decomposing requirements and assigning tasks to multiple agents to initiate asynchronous requests",
      "body": "    asc_agent = Agent(\n        name=\"Auto Scene Generator Agent\",\n        role=\"Responsible for generating new scenario JSON files based on user requirements \\\n            and converting them to text files\",\n        model=MODEL,\n        tools=[FileTools(), AutoSceneTools()],\n        description=f\"\"\"\n        Based on user requirements, generates new scenario JSON files conforming to the SCENE_PROTO_SCHEMA, and converts them to text files.\n        SCENE_PROTO_SCHEMA:{SCENE_PROTO_SCHEMA}\n        \"\"\",\n        instructions=f\"\"\"\n        1. Read and interpret the user's requirements from the input JSON file and natural language instructions.\n           - Use `FileTools().read_file` to read the input JSON file.\n        2. Generate new scenario JSON files based on the extracted requirements, ensuring they conform to the SCENE_PROTO_SCHEMA.\n           - Use `FileTools().write_file` to save the generated JSON files to {OUTPUT_JSON_PATH}.\n        3. Convert each generated JSON file to a proto message and save it as a text file.\n           - Use `AutoSceneTools().transform_json_to_msg` to convert JSON files to proto messages.\n           - Use `AutoSceneTools().save_msg_to_txt` to save proto messages as text files in {OUTPUT_TXT_PATH}.\n        \"\"\",\n        user_id=user_id,\n        session_id=session_id,\n        storage=AGENT_STORAGE,\n        # search_knowledge=True,\n        add_datetime_to_instructions=True,\n        show_tool_calls=True,\n        # debug_mode=True,\n        memory=asc_agent_memory,\n        # TODO(mellon): will cause some llm models crash\n        # read_chat_history=True,\n        add_history_to_messages=True,\n        read_tool_call_history=True,\n        num_history_responses=3,\n        markdown=True,\n        retries=5,\n    )\n\nthis is my agent, is a agent to generate automotive simulation scenario.\nUsually I hope he can generate many scenes, such as adjusting the speed to 0~30 with an interval of 1m/s, which will result in 30 scenes. If one scene is generated one by one, it will be very slow. But I cannot create lots of intelligent agents in advance before running it. Is there any good way to implement it for this business scenario?",
      "state": "closed",
      "author": "baibingren",
      "author_type": "User",
      "created_at": "2025-04-18T11:09:13Z",
      "updated_at": "2025-04-23T11:07:39Z",
      "closed_at": "2025-04-23T11:07:38Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2875/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2875",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2875",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:15.139856",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hey @baibingren Thank you for reaching out and using Agno\nWe have this feature under Teams: https://docs.agno.com/teams/introduction\n\nLet us know incase you have any doubts\n",
          "created_at": "2025-04-23T11:07:38Z"
        }
      ]
    },
    {
      "issue_number": 2780,
      "title": "[Feature Request] Control tool execution via UI and/or input",
      "body": "## Problem Description\nTools can do arbitrary things. Most agent UIs ask the user for some sort of confirmation before using a tool. One can also often configure the need of confirmation for specific tools and auto-confirm for others. Neither the agno agent nor the agno UI allow this as far as I can tell.\n\n## Proposed Solution\nThe agno agent should accept something like `tool_execution_permissions` mapping tool names to an enum. The values could be akin to `ALWAYS_ALLOW`, `ALWAYS_ASK`, `ASK_ONCE_PER_CHAT`.\n\nThe agno-UI should also be adjusted to reflect this. A simple solution that doesn't require changes to the UI would be to only allow \"yes\" and \"no\" as answers to a tool-execution question and pass them to the tool-executor instead of the LLM. But a nicer solution with a button would be better, ofc.\n\n## Additional context\nClaude Desktop did this rather well.\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[ ] Yes, I’d love to work on it!**\n**[x] I’m open to collaborating but need guidance.**\n**[ ] No, I’m just sharing the idea.**\n\nI'm generally open for collaboration but I might nor find time for this very soon. Seems like an important issue to me though",
      "state": "closed",
      "author": "MischaPanch",
      "author_type": "User",
      "created_at": "2025-04-11T11:15:31Z",
      "updated_at": "2025-04-23T11:06:23Z",
      "closed_at": "2025-04-23T11:06:22Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2780/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2780",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2780",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:15.386895",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hey @MischaPanch \nThank you so much for raising this — really appreciate you taking the time to share your thoughts! I’ll add this to our community wishlist and bring it up with the team internally.\n\nAlso, since Agno is open source, if you feel excited about it, feel free to tag a GO and take a crac",
          "created_at": "2025-04-14T06:43:16Z"
        },
        {
          "author": "MischaPanch",
          "body": "Let me know what the team thinks. If they agree with the proposal, I will try to find time to give it a go",
          "created_at": "2025-04-14T06:50:24Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @MischaPanch \nThank you for your suggestion.  We are working on a new HITL feature that would cover this. Stay tuned",
          "created_at": "2025-04-23T11:06:22Z"
        }
      ]
    },
    {
      "issue_number": 2895,
      "title": "[Feature Request] add paging support when query sessions or other record list from db",
      "body": "## Problem Description\nAs the title says\n",
      "state": "closed",
      "author": "fwang2002",
      "author_type": "User",
      "created_at": "2025-04-20T08:09:13Z",
      "updated_at": "2025-04-23T11:05:15Z",
      "closed_at": "2025-04-23T11:04:35Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2895/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2895",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2895",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:15.595393",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hey @fwang2002 Thank you for reaching out and using Agno.\n\nAdding this to our community wishlist. We will take some time to discuss this internally and get back to you.\n\nThank you again for your inputs",
          "created_at": "2025-04-21T06:02:48Z"
        },
        {
          "author": "monali7-d",
          "body": " @fwang2002 Thanks again for sharing this! We're adding it to our roadmap.\nIf you're still interested, feel free to give it a go — we'd love to see what you come up with.\nAnd of course, if you run into any issues or have questions, don’t hesitate to reach out. We're here to help!",
          "created_at": "2025-04-23T11:05:14Z"
        }
      ]
    },
    {
      "issue_number": 2934,
      "title": "[Feature Request] Standardizing tool use messages across models",
      "body": "## Problem Description\nIt would be awesome to have a standard way to represent tool results messages in the history across all models. Right now, tool use is dependent on the model. \n\nClaude:\n\n```\n{\n  \"content\": [\n    {\n      \"type\": \"tool_result\",\n      \"tool_use_id\": \"toolu_01K8QfC1YsGH8D1njSRPrmik\",\n      \"content\": \"result\"\n    }\n  ],\n  \"from_history\": false,\n  \"stop_after_tool_call\": false,\n  \"role\": \"user\",\n  \"created_at\": 1745358214\n}\n```\n\nOpenAI:\n```\n{\n  \"content\": \"result\",\n  \"from_history\": false,\n  \"stop_after_tool_call\": false,\n  \"role\": \"tool\",\n  \"tool_call_id\": \"call_d6xsrMBe5TJpMBsDpuRzCTdQ\",\n  \"tool_name\": \"look_up_acronym\",\n  \"tool_args\": {\n    \"acronym\": \"ADBDBD\"\n  },\n  \"tool_call_error\": false,\n  \"metrics\": {\n    \"time\": 6.456603296101093e-05\n  },\n  \"created_at\": 1745358435\n}\n```\n\n## Proposed Solution\nThe message class should be consistent across models. It should be possible to feed the same message history to any model or switch models mid run. \n\n## Alternatives Considered\nAren't really good alternatives because it's very ambiguous right now. \n",
      "state": "closed",
      "author": "mkschreder",
      "author_type": "User",
      "created_at": "2025-04-22T21:48:24Z",
      "updated_at": "2025-04-23T11:04:10Z",
      "closed_at": "2025-04-23T11:04:08Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2934/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2934",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2934",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:15.807003",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hi @mkschreder \nThank you so much for using Agno and for reaching out to us. \n\nWe've added your suggestion to our community wishlist. Since Agno is open-source, you're more than welcome to explore or even take a shot at building it yourself.\nIf you decide to dive in and need any guidance along the w",
          "created_at": "2025-04-23T11:04:09Z"
        }
      ]
    },
    {
      "issue_number": 2774,
      "title": "[Feature Request] Support Enum type in function parameter",
      "body": "## Problem Description\n\nEnum type in function is not converted to JSON schema properly now. e.g.\n\n```python\n    class Sex(str, enum.Enum):\n        Male = \"male\"\n        Female = \"female\"\n\n    def get_sex(sex: Sex) -> Sex:\n        return sex\n\n    f = Function.from_callable(get_sex)\n    print(f.to_dict())\n```\n\nOutputs:\n\n```python\n{'name': 'get_sex', 'description': '', 'parameters': {'type': 'object', 'properties': {'sex': {'type': 'object', 'properties': {}, 'additionalProperties': False}}, 'required': ['sex']}}\n```\n\nThe enum variants information are missing. Maybe basic types like `number`, `string` etc. are supposed to be supported but enum types are usefule.\n\n## Proposed Solution\n\nParse Enum type properly in `get_json_schema`.\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[ ] Yes, I’d love to work on it!**\n**[ ] I’m open to collaborating but need guidance.**\n**[x] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "failable",
      "author_type": "User",
      "created_at": "2025-04-11T07:59:28Z",
      "updated_at": "2025-04-23T11:03:36Z",
      "closed_at": "2025-04-23T11:03:19Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2774/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2774",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2774",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:15.989298",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hey @failable ,\nThanks for sharing this! We're adding it to our roadmap.\n",
          "created_at": "2025-04-23T11:03:19Z"
        }
      ]
    },
    {
      "issue_number": 2778,
      "title": "[Feature Request] Multimodal RAG support for custom retrievers",
      "body": "## Problem Description\nAgno doesn't support multimodal rag out of the box in RAG, however users can implement custom retrievers but the issue with custom retrievers is that the current implementation doesn't handle non-text content types like images, audio, and video. This makes it difficult to build comprehensive retrieval pipelines that can process and retrieve multimodal information seamlessly.\n\n## Proposed Solution\nImplement multimodal RAG support for custom retrievers that can extract and process various media types (images, audio, video) from the knowledge base. The solution should:\n1. Provide a standardized interface for custom retrievers to access these media elements\n2. Allow the extracted media to be added to dedicated object list for the agent based on media type (images, audio, videos)\n3. Support vector embeddings for these media types to enable similarity search\n4. Ensure the retriever can return both the document context and the associated media elements in search results\n\nThe implementation should maintain backward compatibility with existing text-based retrieval systems while extending functionality to handle multimodal content.\n\n## Alternatives Considered\nI've explored a few workarounds but none provide a complete solution:\n\n1. Add non-text content as part of the metadata for the current `agno.document` setup. This approach keeps the document content as text-only while storing images, audio, or video as metadata. While this maintains backward compatibility, it creates an artificial separation between text and other modalities, making it difficult to treat all content types with equal importance in retrieval.\n\n2. Generalize the `agno.document` class to work for all modalities i.e., its member variable `content` can be any modality (text, image, audio, video). This approach would require significant refactoring of existing code that assumes content is text-based, potentially breaking compatibility with current implementations.\n\nBoth approaches present challenges in determining whether non-text content should be treated as primary content or supplementary metadata, making it difficult to choose a consistent approach that works well across different use cases.\n\n## Additional context\n\n## Would you like to work on this?\n**[ ] Yes, I'd love to work on it!**  \n**[x] I'm open to collaborating but need guidance.**  \n**[ ] No, I'm just sharing the idea.**",
      "state": "closed",
      "author": "DavidAkinpelu",
      "author_type": "User",
      "created_at": "2025-04-11T11:09:11Z",
      "updated_at": "2025-04-23T11:02:28Z",
      "closed_at": "2025-04-23T11:02:27Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2778/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2778",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2778",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:16.181882",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hey @DavidAkinpelu,\nThank you so much for raising this — really appreciate you taking the time to share your thoughts! I’ll add this to our community wishlist and bring it up with the team internally.\n\nAlso, since Agno is open source, if you feel excited about it, feel free to tag a GO and take a cr",
          "created_at": "2025-04-14T06:44:09Z"
        },
        {
          "author": "DavidAkinpelu",
          "body": "Hey @monali7-d \nI am open to contributing. There are different ways to go about this, just like I mentioned above. Let me know which approach the team prefers and I will make a PR.",
          "created_at": "2025-04-14T14:24:22Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @DavidAkinpelu,\nThanks again for sharing this! We're adding it to our roadmap.\nIf you're still interested, feel free to give it a go — we'd love to see what you come up with.\nAnd of course, if you run into any issues or have questions, don’t hesitate to reach out. We're here to help!",
          "created_at": "2025-04-23T11:02:27Z"
        }
      ]
    },
    {
      "issue_number": 2799,
      "title": "[Feature Request] GithubTools with Missing Proxy parameter",
      "body": "## Problem Description\n\nI'm following the code example in [github_tools.py](https://github.com/agno-agi/agno/blob/main/cookbook/tools/github_tools.py).\nCurrently GithubTools does not have proxy parameter, and executing it will resulted in error with company network:\n\n```markdown\nDEBUG HTTPSConnectionPool(host='api.github.com', port=443): Max retries exceeded with url: /repos/agno-agi/agno (Caused by         \n      ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x00000234AEC30A50>, 'Connection to api.github.com timed    \n      out. (connect timeout=15)'))    \n```\n\nWhereas other Tools have proxies parameter:\n\n```py\nagent_with_youtube_tools = Agent(\n    tools=[YouTubeTools(proxies=proxies)],\n    ...\n)\n\nagent_with_duckduckgo_tools = Agent(\n    tools=[DuckDuckGoTools(proxies=proxies)],\n    ...\n)\n```\n\nGitHubTools does not have proxies parameter:\n```py\nagent_with_github_tools = Agent(\n    tools=[GithubTools(proxies=proxies)], # will resulted in error `TypeError: Toolkit.__init__() got an unexpected keyword argument 'proxy'`\n    ...\n)\n```\n\n## Proposed Solution\nEnable proxy feature for GitHubTools\n\n## Would you like to work on this?\n**[ ] Yes, I’d love to work on it!**\n**[ ] I’m open to collaborating but need guidance.**\n**[X] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "KageyamaJie",
      "author_type": "User",
      "created_at": "2025-04-13T04:48:11Z",
      "updated_at": "2025-04-23T11:00:25Z",
      "closed_at": "2025-04-23T11:00:25Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2799/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2799",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2799",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:16.352670",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hi @KageyamaJie \nThank you so much for using Agno and for reaching out to us. \n\nWe've added your suggestion to our community wishlist. Since Agno is open-source, you're more than welcome to explore or even take a shot at building it yourself.\nIf you decide to dive in and need any guidance along the ",
          "created_at": "2025-04-23T11:00:24Z"
        }
      ]
    },
    {
      "issue_number": 2822,
      "title": "[Feature Request] Fully featured x.com tool / client",
      "body": "## Problem Description\nAt today the twitter / x.com support is ok but limited \n\n## Proposed Solution\nExtend the xtools to let the agent not only post but also access spaces, talk into the spaces, even do video in the spaces. Social Agents are already very important in the space. \nYou should take this tool to the next level and add all the missing features that will make AGNO shine on that specific field. \n\n\n",
      "state": "closed",
      "author": "AIFlowML",
      "author_type": "User",
      "created_at": "2025-04-14T10:05:13Z",
      "updated_at": "2025-04-23T10:58:07Z",
      "closed_at": "2025-04-23T10:58:07Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2822/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2822",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2822",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:16.530855",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hey @AIFlowML ,\nThank you so much for raising this — really appreciate you taking the time to share your thoughts! I’ll add this to our community wishlist and bring it up with the team internally.\n\nAlso, since Agno is open source, if you feel excited about it, feel free to tag a GO and take a crack ",
          "created_at": "2025-04-15T06:31:53Z"
        }
      ]
    },
    {
      "issue_number": 2722,
      "title": "[Feature Request] Integration Proposal: Dingo Data Quality Evaluation for Agno Agents",
      "body": "## Problem Description\nI'd like to propose integrating [Dingo](https://github.com/DataEval/dingo), a comprehensive data quality evaluation tool, with Agno. This integration would enhance Agno agents with data quality assessment capabilities, particularly beneficial for RAG systems and knowledge-based agents.\n\n\n## Proposed Solution\n**DingoTools Class**: Create a dedicated tools class that exposes Dingo's core functionality\n   ```python\n   from agno.agent import Agent\n   from agno.models.openai import OpenAIChat\n   from agno.tools.dingo import DingoTools\n   \n   agent = Agent(\n       model=OpenAIChat(id=\"gpt-4o\"),\n       tools=[DingoTools()],\n   )\n   ```\n\n## Alternatives Considered\nHave you found any workarounds or alternative solutions?\nShare other approaches you've tried or thought about.\n\n## Additional context\n1. Would this integration be of interest to the Agno community?\n2. Are there specific aspects of data quality that would be most valuable for Agno users?\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[x] Yes, I’d love to work on it!**\n**[ ] I’m open to collaborating but need guidance.**\n**[ ] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "e06084",
      "author_type": "User",
      "created_at": "2025-04-08T06:54:21Z",
      "updated_at": "2025-04-23T10:57:32Z",
      "closed_at": "2025-04-23T10:57:32Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2722/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2722",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2722",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:18.475126",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hey @e06084 \nThank you for raising this and for using Agno!\nWe're really happy to see the community requesting features like this—it helps us grow together. We've added your suggestion to our community wishlist and will be discussing it internally.\n\nSince Agno is open source, you're more than welcom",
          "created_at": "2025-04-09T06:14:30Z"
        }
      ]
    },
    {
      "issue_number": 2031,
      "title": "[Feature Request]",
      "body": "## Problem Description\nCan we have Azure server connection same as AWS, so that we can do realtime streaming.\n",
      "state": "closed",
      "author": "Sapna-Naga",
      "author_type": "User",
      "created_at": "2025-02-06T08:13:57Z",
      "updated_at": "2025-04-23T10:45:10Z",
      "closed_at": "2025-02-22T00:28:56Z",
      "labels": [
        "enhancement",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2031/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2031",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2031",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:18.659272",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hi @Sapna-Naga \n\nThank you for using Agno! I appreciate your suggestion and have added it to our community wishlist for internal discussion. We’ll review it and keep you updated on any developments.\n\nThanks again for your valuable input!",
          "created_at": "2025-02-07T04:12:53Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-02-22T00:28:55Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @Sapna-Naga , please elaborate? Do you mean a new model class for Azure server? So not Azure AI Foundry? \n",
          "created_at": "2025-04-23T10:45:09Z"
        }
      ]
    },
    {
      "issue_number": 2483,
      "title": "[Feature Request] lts version team support stream output step-by-step",
      "body": "According to the current team model, the final result is always given, and it is hoped that output can be obtained at every step so that it can be returned to the user, and each step supports streaming output",
      "state": "closed",
      "author": "CrankGentleman",
      "author_type": "User",
      "created_at": "2025-03-21T09:26:23Z",
      "updated_at": "2025-04-23T10:38:38Z",
      "closed_at": "2025-04-15T00:33:25Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2483/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2483",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2483",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:18.864805",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Can you elaborate about your request? The current team implementation does support streaming output",
          "created_at": "2025-03-21T15:15:38Z"
        },
        {
          "author": "CrankGentleman",
          "body": "![Image](https://github.com/user-attachments/assets/0caafae6-2287-4ea3-8c7f-c7976d1bcf2e)\n\nNow the final result will be output, but the result of each step cannot be output. I hope it can support the output result of the agent at which step. Now it will wait for the reason and answer to be returned,",
          "created_at": "2025-03-24T01:34:04Z"
        },
        {
          "author": "CrankGentleman",
          "body": "So what I want to say is.....em\n\nThe console prints the output of reason first\nThen the output of answer\nFinally the output is the result\n\nBut now only the result is output",
          "created_at": "2025-03-24T01:37:41Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Ah I see. \nAre you taking the `event` column into account? That should give you an indication of what event you are working with. And yes then the final response has everything, including the member responses.\nDo you want the member responses to be \"emitted\" as a single event when it is obtained? ",
          "created_at": "2025-03-27T07:06:03Z"
        },
        {
          "author": "x0day",
          "body": "@dirkbrnd YES！\n\nmaybe we can add `MemberToolCallStarted` `MemberToolCallCompleted` two events to enhance the stream mode. The current implementation of `arun_member_agents` does not allow stream mode.\n\nhttps://github.com/agno-agi/agno/blob/503aa13849071c637e9ec3d43db8adc1342fca02/libs/agno/agno/team",
          "created_at": "2025-03-31T09:30:24Z"
        }
      ]
    },
    {
      "issue_number": 2266,
      "title": "AsyncConsistency",
      "body": "## Problem Description\nCurrently, in the agent arun method, there may exist potential synchronous I/O calls, such as those involving database storage for sessions and knowledge bases.\n**Example:** \n* https://github.com/agno-agi/agno/blob/d3c321f7a18ecebe5e322b189ce00db0762d16d9/libs/agno/agno/agent/agent.py#L988\n* https://github.com/agno-agi/agno/blob/d3c321f7a18ecebe5e322b189ce00db0762d16d9/libs/agno/agno/agent/agent.py#L2123\n* https://github.com/agno-agi/agno/blob/d3c321f7a18ecebe5e322b189ce00db0762d16d9/libs/agno/agno/agent/agent.py#L1244\n\nthese potential synchronous blocking I/O calls could render the arun method of the agent meaningless.\n\n## Proposed Solution\nThese synchronous blocking I/O calls need to be implemented asynchronously accordingly.\n\n## Alternatives Considered\n\n\n## Additional context\n\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[ ] Yes, I’d love to work on it!**\n**[ ] I’m open to collaborating but need guidance.**\n**[ ] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "zhuofanxu",
      "author_type": "User",
      "created_at": "2025-03-01T08:08:42Z",
      "updated_at": "2025-04-23T10:28:13Z",
      "closed_at": "2025-04-02T00:32:34Z",
      "labels": [
        "stale"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2266/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2266",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2266",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:19.069226",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "@zhuofanxu this is something we are actively working on. We want to support async on all our internal classes where it makes sense\n",
          "created_at": "2025-03-03T15:43:17Z"
        },
        {
          "author": "MartinHanewald",
          "body": "I am just looking into agno's async capabilities. How I understand it, currently async tool calls are always awaited by the agent, correct? So the current benefit is only that multiple tools can run in parallel, but the final user output of the agent is still only returned once all tool calls resolv",
          "created_at": "2025-03-10T15:01:00Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @MartinHanewald \nThat could be a possibility. The problem is that in most cases the model needs the result of the tool call, to process that result and give you a processed answered. But we allow \"respond directly\", which skips that last step, so you would only need the addition of a \"run in the ",
          "created_at": "2025-03-18T07:20:27Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-02T00:32:33Z"
        }
      ]
    },
    {
      "issue_number": 2691,
      "title": "add cur running agent in team with route mode",
      "body": "## Problem Description\nWhen I use team with route mode and use stream to send msg to front， I want to know which agent is send msg to front. But I can't get this information in team now.\n\n## Proposed Solution\n-  I add a properties to team named: cur_running_agent。\n-  in `forward_task_to_member` function of team， need to add line: `self.cur_running_agent = member_agent   ` before running agent：`if stream: member_agent_run_response_stream = member_agent.run(....`\n- before `self.run_response = cast(TeamRunResponse, self.run_response)` add `self.cur_running_agent = None` to clear current running info after running.\n\nso I can get cur running agent with team.cur_running_agent before I `yield chunk ` to front.\n\n\n\n## Alternatives Considered\nNo\n\n## Additional context\nInclude any extra information that might be helpful, such as:\n\n<img width=\"683\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/1e1d78e8-e4ee-46de-a0b5-49e2574f2c6e\" />\n\n<img width=\"763\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/47287ecc-39c8-406b-a03c-42a82ead5600\" />\n\n<img width=\"878\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e0cc7e4a-f2af-41e2-86c8-7227166bf2c5\" />",
      "state": "closed",
      "author": "spcBackToLife",
      "author_type": "User",
      "created_at": "2025-04-05T14:39:15Z",
      "updated_at": "2025-04-23T10:14:30Z",
      "closed_at": "2025-04-23T10:14:29Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2691/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2691",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2691",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:19.298582",
      "comments": [
        {
          "author": "spcBackToLife",
          "body": "<img width=\"928\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/9c597ff0-6c8d-40de-8f0c-9021519c3d68\" />",
          "created_at": "2025-04-05T14:40:29Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-20T00:36:01Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @spcBackToLife \nIn general we want to solve the problem of having events for what is going on during the member execution, this would tell you the current running member. \nWe are tracking this issue\nhttps://github.com/agno-agi/agno/issues/2644\n\nClosing for duplicate, please tell me if I am misint",
          "created_at": "2025-04-23T10:14:29Z"
        }
      ]
    },
    {
      "issue_number": 2630,
      "title": "[Feature Request]: Enable Blockchain interactions ",
      "body": "## Problem Description\nTool to enable interaction with blockchain\n\n## Proposed Solution\nDevelop a tool that enables interaction with blockchain starting with EVM as 90% of blockchains are built on EVM and expand to other blockchains\n\n## Alternatives Considered\nHave you found any workarounds or alternative solutions?\nShare other approaches you've tried or thought about.\n\n## Additional context\nInclude any extra information that might be helpful, such as:\n- Screenshots\n- Examples of similar features elsewhere\n- Any relevant links or references\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[ x] Yes, I’d love to work on it!**\n**[ ] I’m open to collaborating but need guidance.**\n**[ ] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "akp111",
      "author_type": "User",
      "created_at": "2025-04-01T11:21:55Z",
      "updated_at": "2025-04-23T09:46:03Z",
      "closed_at": "2025-04-17T00:32:29Z",
      "labels": [
        "enhancement",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2630/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2630",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2630",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:19.522465",
      "comments": [
        {
          "author": "Ansub",
          "body": "Thanks for the suggestion, @akp111! Moving this to our internal tracker for better visibility. \n\n",
          "created_at": "2025-04-02T08:06:45Z"
        },
        {
          "author": "akp111",
          "body": "Hey @Ansub , I actually have raised a PR for it. I want able to link this pr to the issue so i mentioned it so that it doesnt get lost",
          "created_at": "2025-04-02T09:32:32Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-17T00:32:28Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @akp111 Thank you for your contribution. We will review it and get back to you.",
          "created_at": "2025-04-23T09:13:44Z"
        },
        {
          "author": "akp111",
          "body": "Thanks @monali7-d ",
          "created_at": "2025-04-23T09:46:01Z"
        }
      ]
    },
    {
      "issue_number": 2670,
      "title": "[Feature Request] Adding Serper.dev in tools( similar to tavily)",
      "body": "## Problem Description\nI use searches a lot like tavily, google search and i stumbled upon serper.dev from langchain and i wanted to implement it in agno since I prefer it over langchain\n\n## Proposed Solution\nJust similar to tavily search and helps users try out more searching toolkits. I have already implemented it locally too\n\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[ ] Yes, I’d love to work on it!**\n",
      "state": "closed",
      "author": "CoderOMaster",
      "author_type": "User",
      "created_at": "2025-04-04T07:17:35Z",
      "updated_at": "2025-04-23T09:20:13Z",
      "closed_at": "2025-04-20T00:36:04Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2670/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "CoderOMaster"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2670",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2670",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:19.708311",
      "comments": [
        {
          "author": "anuragts",
          "body": "Hey @CoderOMaster, serper.dev looks great. Since you already have it working locally, we welcome contributions — feel free to open a PR when you’re ready. If you need any assistance or have any questions along the way, don’t hesitate to reach out.",
          "created_at": "2025-04-04T08:22:29Z"
        },
        {
          "author": "CoderOMaster",
          "body": "@anuragts hey can you please check my pr?\nThanks",
          "created_at": "2025-04-05T06:47:52Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-20T00:36:02Z"
        },
        {
          "author": "anuragts",
          "body": "@CoderOMaster I have reviewed and tested your PR and its good to go, will be merged in sometime.\nThanks for contributing.",
          "created_at": "2025-04-23T09:20:12Z"
        }
      ]
    },
    {
      "issue_number": 2638,
      "title": "[Feature Request]目前ahno可以支持其他向量库或者数据库吗",
      "body": "目前ahno可以支持fassis向量库和mysql吗",
      "state": "closed",
      "author": "cckamiya",
      "author_type": "User",
      "created_at": "2025-04-02T07:48:45Z",
      "updated_at": "2025-04-23T09:13:08Z",
      "closed_at": "2025-04-23T09:13:06Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2638/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 1
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2638",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2638",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:19.891211",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-17T00:32:26Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @cckamiya \nThank you for reaching out and using Agno.\nWe currently don't support it\nWe're always open to valuable contributions—if you're still interested, feel free to go ahead and implement the feature. Raising a PR would be most welcome!",
          "created_at": "2025-04-23T09:13:06Z"
        }
      ]
    },
    {
      "issue_number": 2707,
      "title": "[Feature Request] Add GitHub models",
      "body": "## Problem Description\nI often find it frustrating when experimenting with AI models for quick proof‑of‑concepts because many hosted model providers require paid subscriptions or have restrictive rate limits. This creates a barrier for rapid prototyping and evaluation of different architectures.\n\n## Proposed Solution\nIntegrate GitHub Marketplace Models (https://github.com/marketplace/models) as an optional provider in our AI framework. These models are free to use and can be accessed directly via GitHub’s APIs. The feature would allow users to:\n- Browse available GitHub models from within our UI or CLI\n- Select a model and pull it into their workspace with a single command\n- Configure authentication (using GitHub tokens) seamlessly\n- Fall back to existing providers if a GitHub model isn’t available or suitable\n\n## Alternatives Considered\n- **Hugging Face free tier**: good selection but still rate‑limited and requires separate account setup.  \n- **Local open‑source models**: eliminates cost but demands heavy local compute and complex environment setup.  \n- **Paid API keys (OpenAI, Azure, etc.)**: easy integration but incurs costs and isn’t ideal for quick demos.\n\n## Would you like to work on this?\n**[ ] Yes, I’d love to work on it!**\n**[ x ] I’m open to collaborating but need guidance.**\n**[ ] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "ShivamGoyal03",
      "author_type": "User",
      "created_at": "2025-04-07T07:18:03Z",
      "updated_at": "2025-04-23T09:02:25Z",
      "closed_at": "2025-04-23T00:32:44Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2707/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2707",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2707",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:20.112291",
      "comments": [
        {
          "author": "kausmeows",
          "body": "Hey @ShivamGoyal03 adding this to community wishlist. If you wanna contribute please go ahead! We'll try to give directions wherever possible.",
          "created_at": "2025-04-08T06:54:07Z"
        },
        {
          "author": "ShivamGoyal03",
          "body": "> Hey [@ShivamGoyal03](https://github.com/ShivamGoyal03) adding this to community wishlist. If you wanna contribute please go ahead! We'll try to give directions wherever possible.\n\nPlease do so as a starting point, the steps that need to be followed. Will make amendments as requested",
          "created_at": "2025-04-08T10:08:32Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-23T00:32:42Z"
        },
        {
          "author": "ShivamGoyal03",
          "body": "Hi, any followup ",
          "created_at": "2025-04-23T08:18:12Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @ShivamGoyal03,\nThanks for the suggestion! We've added this to the Agno Roadmap.\nWe're always open to valuable contributions—if you're still interested, feel free to go ahead and implement the feature. Raising a PR would be most welcome!\n\nLet us know if you need any help",
          "created_at": "2025-04-23T09:02:24Z"
        }
      ]
    },
    {
      "issue_number": 2738,
      "title": "How to create the following workflow using workflows?",
      "body": "## Problem Description\nHow to create the following workflow using workflows?\n\n![Image](https://github.com/user-attachments/assets/849efc79-2dea-41f5-b124-f8969f03e4fd)",
      "state": "closed",
      "author": "ruidanwang",
      "author_type": "User",
      "created_at": "2025-04-09T08:10:37Z",
      "updated_at": "2025-04-23T08:57:36Z",
      "closed_at": "2025-04-09T08:38:37Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2738/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2738",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2738",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:20.336759",
      "comments": []
    },
    {
      "issue_number": 2739,
      "title": "Is there a concept of sub team or similar implementation",
      "body": "## Problem Description\nIs there a concept of sub team or similar implementation？my agents  often require group management\n",
      "state": "closed",
      "author": "ruidanwang",
      "author_type": "User",
      "created_at": "2025-04-09T08:35:10Z",
      "updated_at": "2025-04-23T08:57:22Z",
      "closed_at": "2025-04-09T08:39:06Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2739/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2739",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2739",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:20.336778",
      "comments": []
    },
    {
      "issue_number": 2801,
      "title": "[Feature Request] PDFUrlKnowledgeBase Missing Proxy parameter",
      "body": "## Problem Description\n\nI'm following the code example in [03_agent_with_knowledge.py](https://github.com/agno-agi/agno/blob/main/cookbook/getting_started/03_agent_with_knowledge.py).\nCurrently PDFUrlKnowledgeBase does not have proxy parameter, and executing it will resulted in error with company network:\n\n```markdown\nINFO Loading knowledge base\nINFO Reading: https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\nWARNING  Request failed, retrying in 1 seconds...\nWARNING  Request failed, retrying in 2 seconds...\nERROR    Failed to fetch PDF after 3 attempts: timed out\nTraceback (most recent call last):\n  File \"C:\\Projects\\agno\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 101, in map_httpcore_exceptions\n    yield\n  File \"C:\\Projects\\agno\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 250, in handle_request\n    resp = self._pool.handle_request(req)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Projects\\agno\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 256, in handle_request\n    raise exc from None\n  File \"C:\\Projects\\agno\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 236, in handle_request\n    response = connection.handle_request(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Projects\\agno\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 101, in handle_request\n    raise exc\n  File \"C:\\Projects\\agno\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 78, in handle_request\n    stream = self._connect(request)\n             ^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Projects\\agno\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 124, in _connect\n    stream = self._network_backend.connect_tcp(**kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Projects\\agno\\.venv\\Lib\\site-packages\\httpcore\\_backends\\sync.py\", line 207, in connect_tcp\n    with map_exceptions(exc_map):\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\<USERNAME>\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py\", line 158, in __exit__\n    self.gen.throw(value)\n  File \"C:\\Projects\\agno\\.venv\\Lib\\site-packages\\httpcore\\_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ConnectTimeout: timed out\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Projects\\agno\\run.py\", line 5, in <module>\n    from src.agent_with_knowledge import agent\n  File \"C:\\Projects\\agno\\src\\agent_with_knowledge.py\", line 86, in <module>\n    agent.knowledge.load()\n  File \"C:\\Projects\\agno\\.venv\\Lib\\site-packages\\agno\\knowledge\\agent.py\", line 116, in load\n    for document_list in self.document_lists:\n                         ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Projects\\agno\\.venv\\Lib\\site-packages\\agno\\knowledge\\pdf_url.py\", line 24, in document_lists\n    yield self.reader.read(url=url)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Projects\\agno\\.venv\\Lib\\site-packages\\agno\\document\\reader\\pdf_reader.py\", line 180, in read\n    response = httpx.get(url)\n               ^^^^^^^^^^^^^^\n  File \"C:\\Projects\\agno\\.venv\\Lib\\site-packages\\httpx\\_api.py\", line 195, in get\n    return request(\n           ^^^^^^^^\n  File \"C:\\Projects\\agno\\.venv\\Lib\\site-packages\\httpx\\_api.py\", line 109, in request\n    return client.request(\n           ^^^^^^^^^^^^^^^\n  File \"C:\\Projects\\agno\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 825, in request\n    return self.send(request, auth=auth, follow_redirects=follow_redirects)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Projects\\agno\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 914, in send\n    response = self._send_handling_auth(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Projects\\agno\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 942, in _send_handling_auth\n    response = self._send_handling_redirects(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Projects\\agno\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 979, in _send_handling_redirects\n    response = self._send_single_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Projects\\agno\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1014, in _send_single_request\n    response = transport.handle_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Projects\\agno\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 249, in handle_request\n    with map_httpcore_exceptions():\n         ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\<USERNAME>\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py\", line 158, in __exit__\n    self.gen.throw(value)\n  File \"C:\\Projects\\agno\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 118, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ConnectTimeout: timed out\n```\n\nPDFUrlKnowledgeBase does not have proxies parameter:\n```py\n    knowledge=PDFUrlKnowledgeBase(\n        urls=[\"https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n        proxy=<PROXY_HERE>, # the missing piece\n        vector_db=LanceDb(\n            uri=\"tmp/lancedb\",\n            table_name=\"recipe_knowledge\",\n            search_type=SearchType.hybrid,\n\n            ...omitted for readability\n        ),\n    ),\n```\n\n## Proposed Solution\nEnable proxy feature for PDFUrlKnowledgeBase\n\n## Would you like to work on this?\n**[ ] Yes, I’d love to work on it!**\n**[ ] I’m open to collaborating but need guidance.**\n**[X] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "KageyamaJie",
      "author_type": "User",
      "created_at": "2025-04-13T07:11:57Z",
      "updated_at": "2025-04-23T08:09:31Z",
      "closed_at": "2025-04-23T08:09:31Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2801/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2801",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2801",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:20.336785",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Thanks for the suggestion! We'll add it soon. Otherwise please feel free to make a contribution PR and we will review asap!",
          "created_at": "2025-04-15T10:08:28Z"
        }
      ]
    },
    {
      "issue_number": 2741,
      "title": "[Feature Request]How to use streaming output thinking？",
      "body": "Do not use the print_response method, I am not printing in the terminal. Please give me an example, thank you! ",
      "state": "closed",
      "author": "Rainismer",
      "author_type": "User",
      "created_at": "2025-04-09T08:54:01Z",
      "updated_at": "2025-04-23T08:05:36Z",
      "closed_at": "2025-04-23T08:05:36Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2741/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2741",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2741",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:20.577063",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @Rainismer ! You can directly use the [Agent.run](https://docs.agno.com/agents/run) method to get a response and stream from it by setting `stream=True`. Can you please share more about your use case and the thinking output you'd like to obtain? Happy to help",
          "created_at": "2025-04-10T03:05:20Z"
        },
        {
          "author": "Rainismer",
          "body": "@ysolanky Hello Ysolanky! I found that only the content can be streamed, but I also wanted the thought and code in the tool to be streamed, but they are not supported. \n\nThe code is as follows:\n\nfrom agno.agent import Agent, RunResponse\nfrom agno.models.azure import AzureOpenAI\nfrom agno.tools.think",
          "created_at": "2025-04-10T04:32:11Z"
        },
        {
          "author": "mishramonalisha76",
          "body": "Hi @Rainismer , Our team is working on new reasoning streaming which will allow you to stream the reason  and it should be released soon .",
          "created_at": "2025-04-14T09:13:13Z"
        },
        {
          "author": "Rainismer",
          "body": "@mishramonalisha76 This is so exciting! Please let me know as soon as it is released!",
          "created_at": "2025-04-14T09:17:27Z"
        },
        {
          "author": "Rainismer",
          "body": "Hi @mishramonalisha76, What's the progress?",
          "created_at": "2025-04-18T05:57:28Z"
        }
      ]
    },
    {
      "issue_number": 2740,
      "title": "Can teams be treated as nodes in workflows?",
      "body": "## Problem Description\nCan teams be treated as nodes in workflows?\n\n",
      "state": "closed",
      "author": "ruidanwang",
      "author_type": "User",
      "created_at": "2025-04-09T08:52:01Z",
      "updated_at": "2025-04-23T07:55:40Z",
      "closed_at": "2025-04-23T07:55:32Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2740/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "mishramonalisha76"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2740",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2740",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:20.796741",
      "comments": [
        {
          "author": "mishramonalisha76",
          "body": "Hi @ruidanwang , This is a really good question and yes it is completely possible with agno workflows . You can refer to the docs [here](https://docs.agno.com/examples/workflows/team-workflow) for an example model with team node.",
          "created_at": "2025-04-14T13:50:55Z"
        }
      ]
    },
    {
      "issue_number": 2628,
      "title": "[Feature Request] gpt researcher needed with AGNO, anyone implemented pls share",
      "body": "gpt researcher needed with AGNO, anyone implemented pls share\n\nneed to generate final research pdf also just like current \n\nhttps://github.com/assafelovic/gpt-researcher",
      "state": "closed",
      "author": "wns-saitej",
      "author_type": "User",
      "created_at": "2025-04-01T09:44:45Z",
      "updated_at": "2025-04-23T07:49:21Z",
      "closed_at": "2025-04-23T07:49:19Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2628/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2628",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2628",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:20.971082",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-16T00:33:19Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @wns-saitej,\nThanks for reaching out and for using Agno!\n\nThis feature isn’t currently implemented in Agno. If you’d like to see it added, feel free to open a PR—we’d love to review and collaborate on it.",
          "created_at": "2025-04-23T07:49:19Z"
        }
      ]
    },
    {
      "issue_number": 2860,
      "title": "[Bug] azure-ai-foundry for reasoner model",
      "body": "# Description\nHow to setup DeepSeek-R1 from azure-ai-foundry ?\n\nWhat is the id and name for that?\n\nWe only have instance's endpoint and API key. \n\nIf I pass the model to `reason_model`, it will throw an error.\n\n## Steps to Reproduce\nList the steps needed to encounter this bug or issue.\n\n## Agent Configuration (if applicable)\nProvide relevant agent configuration.\n\n## Expected Behavior\nWhat did you expect to happen?\n\n## Actual Behavior\nWhat actually happened instead?\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- OS: (e.g. macOS, Windows 11)\n- Browser (if relevant): (e.g. Chrome 108, Firefox 107)\n- Agno Version: (e.g. v1.0.0)\n- External Dependency Versions: (e.g., yfinance 0.2.52)\n- Additional Environment Details: (e.g., Python 3.10)\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "peiyaoli",
      "author_type": "User",
      "created_at": "2025-04-17T07:47:43Z",
      "updated_at": "2025-04-23T01:56:50Z",
      "closed_at": "2025-04-22T19:50:13Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2860/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2860",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2860",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:21.198831",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Hi @peiyaoli can you provide your sample code can I can try it? ",
          "created_at": "2025-04-17T10:25:51Z"
        },
        {
          "author": "peiyaoli",
          "body": "Hi, @dirkbrnd \n\nHere is the demo code:\n\n```python\nimport rootutils\nimport os\nfrom agno.agent import Agent\nfrom agno.models.azure import AzureOpenAI, AzureAIFoundry\nfrom textwrap import dedent\n\n\nroot = rootutils.setup_root(\n    __file__, indicator=\"README.md\", dotenv=True, pythonpath=True\n)\nagent = A",
          "created_at": "2025-04-18T01:01:07Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Great thanks, we recently made many improvements, testing if this now works\n",
          "created_at": "2025-04-22T11:35:29Z"
        },
        {
          "author": "dirkbrnd",
          "body": "I have a PR out to fix.",
          "created_at": "2025-04-22T11:46:19Z"
        },
        {
          "author": "peiyaoli",
          "body": "many thanks\n",
          "created_at": "2025-04-23T01:56:48Z"
        }
      ]
    },
    {
      "issue_number": 2898,
      "title": "[Bug] cannot import team : from agno.team.team import Team",
      "body": "input error team not found",
      "state": "closed",
      "author": "MohamedLahmeri01",
      "author_type": "User",
      "created_at": "2025-04-20T15:36:48Z",
      "updated_at": "2025-04-22T23:59:33Z",
      "closed_at": "2025-04-22T23:59:31Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2898/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2898",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2898",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:21.405473",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @MohamedLahmeri01 ! Can you please share which Agno version and cookbook you are using?\n\nYou might need to run: `pip install -U agno` ",
          "created_at": "2025-04-20T17:42:12Z"
        },
        {
          "author": "MohamedLahmeri01",
          "body": "agno 1.3.4 , also errors woth exception.py\r\n\r\nOn Sun, 20 Apr 2025, 18:42 Yash Pratap Solanky, ***@***.***>\r\nwrote:\r\n\r\n> Hello @MohamedLahmeri01 <https://github.com/MohamedLahmeri01> ! Can you\r\n> please share which Agno version and cookbook you are using?\r\n>\r\n> You might need to run: pip install -U a",
          "created_at": "2025-04-20T17:44:55Z"
        },
        {
          "author": "rahulb99",
          "body": "This bug is in Agno Playground right? @MohamedLahmeri01 ",
          "created_at": "2025-04-22T14:02:27Z"
        },
        {
          "author": "MohamedLahmeri01",
          "body": "> Hello [@MohamedLahmeri01](https://github.com/MohamedLahmeri01) ! Can you please share which Agno version and cookbook you are using?\n> \n> You might need to run: `pip install -U agno`\n\ndid it but error",
          "created_at": "2025-04-22T23:58:45Z"
        },
        {
          "author": "MohamedLahmeri01",
          "body": "> This bug is in Agno Playground right? [@MohamedLahmeri01](https://github.com/MohamedLahmeri01)\n\nno , in pure code",
          "created_at": "2025-04-22T23:59:05Z"
        }
      ]
    },
    {
      "issue_number": 2925,
      "title": "[Bug] The OpenAIChat model is not picking the API Key",
      "body": "There is a serious issue I discovered. The OpenAIChat class is not able to pick the OpenAI API key. I tried to put it in the .env file as well as via set OPEN_API_KEY.\n\nI would get the following error: \n\n<img width=\"925\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/534e7546-bc8a-48b9-b95a-cf6d05c31d28\" />\n\nBut when I hardcoded the API in that class, it worked. I am bringing this to your attention since I also faced this issue in production, and one of our features was not working.",
      "state": "closed",
      "author": "usmanafridi",
      "author_type": "User",
      "created_at": "2025-04-22T12:08:36Z",
      "updated_at": "2025-04-22T17:23:27Z",
      "closed_at": "2025-04-22T17:23:27Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2925/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2925",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2925",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:21.620631",
      "comments": [
        {
          "author": "rahulb99",
          "body": "@usmanafridi : The name of env variable should be `OPENAI_API_KEY`",
          "created_at": "2025-04-22T14:00:27Z"
        },
        {
          "author": "ysolanky",
          "body": "Hello @usmanafridi ! Yes, the env variable picked up by `OpenAIChat` is `OPENAI_API_KEY` for the api key.\n\nThanks @rahulb99 for the input",
          "created_at": "2025-04-22T14:13:35Z"
        },
        {
          "author": "usmanafridi",
          "body": "Sorry, there was a typo in the message. Yes, it was OPENAI_API_KEY, but for some reason, it was not getting picked up in the application. And also, the feature on our prod stopped working also. Thought it might have been because of some updates in the library. Thanks for the answer anyway.",
          "created_at": "2025-04-22T17:19:53Z"
        }
      ]
    },
    {
      "issue_number": 2926,
      "title": "[Feature Request] roaadmap",
      "body": "## Problem Description\nProvide a clear and concise explanation of the issue you're facing.\n**Example:** *\"I often find it frustrating when [...] because [...]”*\n\n## Proposed Solution\nExplain your ideal solution. How should this feature work?\nBe as detailed as possible to help us understand your vision.\n\n## Alternatives Considered\nHave you found any workarounds or alternative solutions?\nShare other approaches you've tried or thought about.\n\n## Additional context\nInclude any extra information that might be helpful, such as:\n- Screenshots\n- Examples of similar features elsewhere\n- Any relevant links or references\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[ ] Yes, I’d love to work on it!**\n**[ ] I’m open to collaborating but need guidance.**\n**[ ] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "monali7-d",
      "author_type": "User",
      "created_at": "2025-04-22T14:37:07Z",
      "updated_at": "2025-04-22T14:47:08Z",
      "closed_at": "2025-04-22T14:47:08Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2926/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2926",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2926",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:21.855755",
      "comments": []
    },
    {
      "issue_number": 2650,
      "title": "[Bug] Gemini Team with enable_agentic_context=True Fail",
      "body": "# Description\nif Team with gemini model and enable_agentic_context enabled response failed with 400 code\n\n## Agent Configuration (if applicable)\nhn_team = Team(\n    name=\"HackerNews Team\",\n    mode=\"coordinate\",\n    model=Gemini(id=\"gemini-2.0-flash-exp\"),\n    members=[hn_researcher, web_searcher, article_reader],\n    instructions=[\n        \"First, search hackernews for what the user is asking about.\",\n        \"Then, ask the article reader to read the links for the stories to get more information.\",\n        \"Important: you must provide the article reader with the links to read.\",\n        \"Then, ask the web searcher to search for each story to get more information.\",\n        \"Finally, provide a thoughtful and engaging summary.\",\n    ],\n    response_model=Article,\n    show_tool_calls=True,\n    markdown=True,\n    debug_mode=True,\n    show_members_responses=True,\n    enable_agentic_context=True,\n    use_json_mode=True,\n)\n\n\n## Actual Behavior\nERROR    Error from Gemini API: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Invalid value at                                                                \n         \\'tools[0].function_declarations[1].parameters.properties[0].value.type\\' (type.googleapis.com/google.ai.generativelanguage.v1beta.Type), \"\"', 'status':         \n         'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.BadRequest', 'fieldViolations': [{'field':                                             \n         'tools[0].function_declarations[1].parameters.properties[0].value.type', 'description': 'Invalid value at                                                        \n         \\'tools[0].function_declarations[1].parameters.properties[0].value.type\\' (type.googleapis.com/google.ai.generativelanguage.v1beta.Type), \"\"'}]}]}}              \n\n",
      "state": "closed",
      "author": "AduchiMergen",
      "author_type": "User",
      "created_at": "2025-04-03T00:56:03Z",
      "updated_at": "2025-04-22T11:45:21Z",
      "closed_at": "2025-04-22T11:45:20Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2650/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "mishramonalisha76"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2650",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2650",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:21.855775",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @AduchiMergen ! Sorry about that! We are looking into it",
          "created_at": "2025-04-04T06:05:03Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@AduchiMergen Thanks for raising, fix out! I'll release asap",
          "created_at": "2025-04-05T09:04:20Z"
        },
        {
          "author": "saitharunsai",
          "body": "@dirkbrnd  When will this be released ?",
          "created_at": "2025-04-08T06:36:03Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @saitharunsai its released. Please let us know incase you face any doubts.\nWe are here to help!\n\n",
          "created_at": "2025-04-22T11:45:20Z"
        }
      ]
    },
    {
      "issue_number": 2209,
      "title": "[Feature Request] Multi-Agent Patterns Enhancement",
      "body": "## Problem Description\n\nI found the Agent Team API  can not handle complicated workflow and Hierarchical, currently agent team is only instructions. \nKey Patterns like \n\n- Orchestrator-worker pattern\n- Hierarchical agent pattern\n- Blackboard pattern\n- Market-based pattern\n\n\n## Proposed Solution\n\nEnhance the Multi agents design pattern, rethinking from existing market implementation. \n\n- AutoGen based queue system  https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/design-patterns/concurrent-agents.html\n\n- Langraph based network graph https://networkx.org/documentation/stable/tutorial.html \n\n- CrewAI does not support advanced pattern only Sequential, Hierarchical, Consensual Process (Planned)  https://docs.crewai.com/concepts/processes\n\nI recommend  system implement base on event driven like autogen, it is much easy to adapt into distribution system with existing tools like message system  https://www.confluent.io/blog/event-driven-multi-agent-systems/\n\n## Alternatives Considered\n\nusing external message bus like kafka, agent listen on these topics. agno system can cross clouds providers, legacy system to integrate together. https://medium.com/data-science-collective/agentic-mesh-patterns-for-an-agent-ecosystem-ef13469b7cf7 \n\n## Additional context\nInclude any extra information that might be helpful, such as:\n\n<img width=\"948\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/430139b1-88cd-4eb9-8b9c-061cc70a3cd2\" />\n\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[x] Yes, I’d love to work on it!**\n**[x ] I’m open to collaborating but need guidance.**\n**[ ] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "wuqunfei",
      "author_type": "User",
      "created_at": "2025-02-23T07:52:20Z",
      "updated_at": "2025-04-22T11:30:34Z",
      "closed_at": "2025-04-22T11:30:33Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2209/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2209",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2209",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:22.031619",
      "comments": [
        {
          "author": "Harsh-2909",
          "body": "Thats a very good suggestion. I would love to work on this with you. Do tell if you need any help as I will need some guidance for this as well if i want to contribute.",
          "created_at": "2025-02-23T09:23:06Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @wuqunfei \nWe are actively working on an improved experience of teams in Agno. This is really valuable insight! I will make sure to incorporate it in our design",
          "created_at": "2025-02-23T18:52:30Z"
        },
        {
          "author": "wuqunfei",
          "body": "thanks @Harsh-2909  and @dirkbrnd  for your feedback, I am working in one biggest insurance company in Europe , these are enough open source/commeical agent frameworks, but no one is solving integration/patterns between agent very well and very easily manner. \n\nI do not think these agent framework w",
          "created_at": "2025-02-24T09:12:07Z"
        },
        {
          "author": "ashpreetbedi",
          "body": "this is an amazing recommendation @wuqunfei! reading thought and would love to meet with your team to get feedback as we're implementing!",
          "created_at": "2025-02-24T11:40:41Z"
        },
        {
          "author": "wuqunfei",
          "body": "I am living in GMT +1, German. Free to book a session next week in working day.  \n\nAnd if your team is busy, there are many powerful python stream libary you can integrate into your framework with less effort. \n\ne.g. \n-  https://faststream.airt.ai/latest/getting-started/subscription/ \n-  https://fau",
          "created_at": "2025-02-24T20:15:04Z"
        }
      ]
    },
    {
      "issue_number": 2883,
      "title": "[Bug] FirecrawlTools incompatible with the current Firecrawl API.",
      "body": "# Description\nThe `FirecrawlTools` class in agno 1.3.3 is incompatible with the current Firecrawl API. When attempting to use the `scrape_website` function, it fails with a 400 Bad Request error because of the use of a `params` key in the request body, which is no longer accepted by the Firecrawl API.\n\n## Steps to Reproduce\n1. Install agno version 1.3.3\n2. Install the latest firecrawl-py library\n3. Create a FirecrawlTools instance with `scrape=True`\n4. Call the `scrape_website` function with a URL\n5. Observe the 400 Bad Request error\n\n## Agent Configuration (if applicable)\n```python\nfrom agno.tools.firecrawl import FirecrawlTools\n\n# Initialize FirecrawlTools with scrape=True\nfirecrawl_tools = FirecrawlTools(scrape=True, crawl=False)\n\n# Try to scrape a URL\nresult = firecrawl_tools.scrape_website(url=\"https://example.com/file.csv\")\n```\n\n## Expected Behavior\nThe `scrape_website` function should successfully scrape the provided URL and return the contents.\n\n## Actual Behavior\nThe function fails with the following error:\n```\nUnexpected error during scrape URL: Status code 400. Bad Request - [{'code': 'unrecognized_keys', 'keys': ['params'], 'path': [], 'message': 'Unrecognized key in body -- please review the v1 API documentation for request body changes'}]\n```\n\n## Screenshots or Logs (if applicable)\n```\nWARNING  Could not run function scrape_website(url=...)                         \nERROR    Unexpected error during scrape URL: Status code 400. Bad Request -     \n         [{'code': 'unrecognized_keys', 'keys': ['params'], 'path': [],         \n         'message': 'Unrecognized key in body -- please review the v1 API       \n         documentation for request body changes'}]                              \n         Traceback (most recent call last):                                     \n           File                                                                 \n         \"/opt/hostedtoolcache/Python/3.11.12/x64/lib/python3.11/site-packages/a\n         gno/tools/function.py\", line 475, in execute                           \n```\n\n## Environment\n- OS: macOS/Linux (Docker container)\n- Agno Version: 1.3.3\n- External Dependency Versions: firecrawl-py (2.1.1)\n- Additional Environment Details: Python 3.11\n\n## Possible Solutions (optional)\nThe issue is in the `scrape_website` method in `firecrawl.py` where it calls `scrape_url` with a named parameter:\n\n```python\n# Line 71 in agno/tools/firecrawl.py\nscrape_result = self.app.scrape_url(url, params=params)\n```\n\nThe Firecrawl SDK and API expect the parameters to be passed directly, not in a \"params\" key. This line should be changed to:\n\n```python\nscrape_result = self.app.scrape_url(url, params)\n```",
      "state": "closed",
      "author": "jesalg",
      "author_type": "User",
      "created_at": "2025-04-18T22:59:42Z",
      "updated_at": "2025-04-21T18:54:15Z",
      "closed_at": "2025-04-21T18:54:15Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2883/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2883",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2883",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:22.263119",
      "comments": [
        {
          "author": "kausmeows",
          "body": "Hi @jesalg thanks for raising this, fixed in this PR- https://github.com/agno-agi/agno/pull/2888",
          "created_at": "2025-04-19T14:55:57Z"
        }
      ]
    },
    {
      "issue_number": 2014,
      "title": "[Bug]Keep reading the the pdf file again & again when i use PDFImageReader even when the pdf file already exist in database",
      "body": "# Description\nBriefly describe the issue you’re experiencing or the bug you’ve found.\n\n\n#### code \nimport os\nfrom dotenv import load_dotenv\nfrom agno.agent import Agent\nfrom agno.embedder.azure_openai import AzureOpenAIEmbedder\nfrom agno.knowledge.pdf import PDFKnowledgeBase, PDFImageReader, PDFReader\nfrom agno.vectordb.pgvector import PgVector, SearchType\nfrom agno.models.openai import OpenAIChat\nfrom agno.storage.agent.postgres import PostgresAgentStorage\nfrom sqlalchemy import create_engine, inspect, text\nfrom agno.vectordb.pgvector.index import Ivfflat, HNSW\nfrom agno.embedder.openai import OpenAIEmbedder\n#from langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom agno.document.chunking.recursive import RecursiveChunking\n\n# Load environment variables\nload_dotenv()\nprint(\"Environment variables loaded.\")\n\n# Fetch API keys and endpoint from environment variables\nAZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\nAZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\nOPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n\ndb_url = \"postgresql+psycopg://ai:ai@localhost:5532/ai\"\n\n# Function to check if the table exists\ndef check_table_exists(engine, schema, table_name):\n    print(f\"Checking if table '{table_name}' exists in schema '{schema}'...\")\n    inspector = inspect(engine)\n    exists = inspector.has_table(table_name, schema=schema)\n    print(f\"Table '{table_name}' exists: {exists}\")\n    return exists\n\n# Function to check if a PDF file is already in the database\ndef is_pdf_in_db(engine, schema, table_name, pdf_name):\n    pdf_name_no_ext = os.path.splitext(pdf_name)[0]  # Remove the .pdf extension\n    print(f\"Checking if PDF '{pdf_name_no_ext}' exists in table '{table_name}'...\")\n    with engine.connect() as connection:\n        result = connection.execute(\n            text(f\"SELECT 1 FROM {schema}.{table_name} WHERE name = :name\"),\n            {\"name\": pdf_name_no_ext}\n        )\n        exists = result.fetchone() is not None\n        print(f\"PDF '{pdf_name_no_ext}' exists in table '{table_name}': {exists}\")\n        return exists\n\n# Set up the PDF knowledge base with vector database\nprint(\"Setting up PDF knowledge base with vector database...\")\npdf_knowledge_base = PDFKnowledgeBase(\n    path=\"D:\\\\Projects\\\\agentic_new_rag\\\\pdfs\",\n    vector_db=PgVector(\n        table_name=\"updated_rag009\",\n        schema='ai',\n        db_url=db_url,\n        search_type=SearchType.hybrid,\n        vector_index=HNSW(),\n        embedder = OpenAIEmbedder(\n        api_key=OPENAI_API_KEY,\n        id=\"text-embedding-ada-002\",\n        dimensions=1536,\n        encoding_format=\"float\"\n    )\n    ),\n    reader=PDFImageReader(chunk=False),  # Use a default reader,\n    chunking_strategy=RecursiveChunking(chunk_size=4000,overlap = 800),\n    documents=3,\n)\n\n#chunking_strategy=RecursiveChunking(),\n\n# Define the PgAgentStorage with connection to database\n\n\n\n# Create a SQLAlchemy engine\nengine = create_engine(db_url)\n\n# Before loading, check if the table exists and create if not\nif not check_table_exists(engine, \"ai\", \"updated_rag009\"):\n    print(\"Table does not exist. Creating the table...\")\n    pdf_knowledge_base.load(recreate=True, upsert=True)  # Create the table\nelse:\n    print(\"Table exists. Skipping table creation...\")\n    pdf_knowledge_base.load(recreate=False, skip_existing=True)  # Skip existing table\n\n# Check if PDFs are already in the database and process accordingly\npdf_folder = \"D:\\\\Projects\\\\agentic_new_rag\\\\pdfs\"\nfor pdf_file in os.listdir(pdf_folder):\n    if pdf_file.endswith(\".pdf\"):\n        if not is_pdf_in_db(engine, \"ai\", \"updated_rag009\", pdf_file):\n            print(f\"Processing {pdf_file}...\")\n            # Process the PDF file with PDFImageReader\n            pdf_reader = PDFImageReader(chunk=True)\n            pdf_reader.read(os.path.join(pdf_folder, pdf_file))\n        else:\n            print(f\"Skipping {pdf_file}, already in database.\")\n\n# Initialize the RAG agent\nprint(\"Initializing RAG Agent...\")\nrag_agent = Agent(\n    name=\"Agentic RAG Application\",\n    agent_id=\"rag-agent\",\n    model=OpenAIChat(id=\"gpt-4o-mini\"),\n    knowledge=pdf_knowledge_base,\n    add_context=True,\n    search_knowledge=True,\n    read_chat_history=True,\n    debug_mode=True,\n    #storage=storage,\n    description=(\n        \"You are an intelligent retrieval assistant specialized in utilizing knowledge stored in \"\n        \"a curated set of documents related\"\n    ),\n    instructions=[\n        \"you have access of the documents and their corresponding file names are: \"\n     \n    ],\n    markdown=True\n)\n\nprint(\"RAG Agent initialized.\")\n\n# Print the agent's response to a query\nrag_agent.print_response(\"give me full Table 1. Volume 1 of DoDM 5200.01 Cancellation Actions of 520045m\", stream=True)\n\n## Steps to Reproduce\nList the steps needed to encounter this bug or issue.\n\n\n\n## Agent Configuration (if applicable)\nProvide relevant agent configuration.\n\nAgentic Rag configuration iam using \n\n## Expected Behavior\nWhat did you expect to happen?\n\nbased on the above code it should skip reading this pdf 520045m.pdf by PDFImageReader because  this 520045m.pdf already present in the pg_vector even though this pdf present 520045m in pgvector its keep reading everytime  when i run the code \n\nbut when i use PdfReader it starts skip reading the pdf when this 520045m pdf already got present in the pg vector \n\nthe issue is with PdfImageReader its not skipping reading the pdf files \n\nplease work on this issue\n\n## Actual Behavior\nWhat actually happened instead?\n \nit should skip reading the pdf file actually when the pdf name already exist in table  but its not skip reading the pdf by PdfImageReader\n\n\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n\n\n#### LOGS of PdfReader\nthese are the logs for PdfReader since 520045m is already present in the table it skipped reading\n\nPS D:\\Projects\\agentic_new_rag> & C:/Users/wel/anaconda3/envs/venv/python.exe \"d:/Projects/agentic_new_rag/final_Agentic_rag_UI.py\"\nEnvironment variables loaded.\nSetting up PDF knowledge base with vector database...\nPgAgentStorage initialized.\nChecking if table 'updated_rag009' exists in schema 'ai'...\nTable 'updated_rag009' exists: True\nTable exists. Skipping table creation...\nINFO     Creating collection\nINFO     Loading knowledge base\nINFO     Reading: 520045m\nINFO     Added 0 documents to knowledge base\nINFO     Reading: CMMC101\nINFO     Added 0 documents to knowledge base\nChecking if PDF '520045m' exists in table 'updated_rag009'...\nPDF '520045m' exists in table 'updated_rag009': True\nSkipping 520045m.pdf, already in database.\nChecking if PDF 'CMMC101' exists in table 'updated_rag009'...\nPDF 'CMMC101' exists in table 'updated_rag009': True\nSkipping CMMC101.pdf, already in database.\nInitializing RAG Agent...\nRAG Agent initialized. \n\n\n\n#### LOGS of PdfImageReader   1st run \n\nEnvironment variables loaded.\nSetting up PDF knowledge base with vector database...\nPgAgentStorage initialized.\nChecking if table 'updated_rag0990' exists in schema 'ai'...\nTable 'updated_rag0990' exists: False\nTable does not exist. Creating the table...\nINFO     Dropping collection\nINFO     Table 'ai.updated_rag0990' does not exist.\nINFO     Creating collection\nINFO     Loading knowledge base\nINFO     Reading: 520045m\nINFO     Upserted batch of 68 documents.\nINFO     Added 68 documents to knowledge base\nINFO     Reading: CMMC101\nINFO     Upserted batch of 21 documents.\nINFO     Added 21 documents to knowledge base\nChecking if PDF '520045m' exists in table 'updated_rag0990'...\nPDF '520045m' exists in table 'updated_rag0990': True\nSkipping 520045m.pdf, already in database.\nChecking if PDF 'CMMC101' exists in table 'updated_rag0990'...\nPDF 'CMMC101' exists in table 'updated_rag0990': True\nSkipping CMMC101.pdf, already in database.\nInitializing RAG Agent...\nRAG Agent initialized.\n\n\n#### LOGS of PdfImageReader   2nd run of the same code with same pdf file with PdfImageReader, even though it did not add the any documents to pg vector since pdf file already present in pg vectot  but it initially it took lot of time for reading the pdf file by PdfImageReader but for PdfReader as it neither read the pdf file nor added documents , \n\n\nEnvironment variables loaded.\nSetting up PDF knowledge base with vector database...\nPgAgentStorage initialized.\nChecking if table 'updated_rag0990' exists in schema 'ai'...\nTable 'updated_rag0990' exists: True\nTable exists. Skipping table creation...\nINFO     Creating collection\nINFO     Loading knowledge base\nINFO     Reading: 520045m\nINFO     Added 0 documents to knowledge base\nINFO     Reading: CMMC101\nINFO     Added 0 documents to knowledge base\nChecking if PDF '520045m' exists in table 'updated_rag0990'...\nPDF '520045m' exists in table 'updated_rag0990': True\nSkipping 520045m.pdf, already in database.\nChecking if PDF 'CMMC101' exists in table 'updated_rag0990'...\nPDF 'CMMC101' exists in table 'updated_rag0990': True\nSkipping CMMC101.pdf, already in database.\nInitializing RAG Agent...\nRAG Agent initialized.\n\n## Environment\n- OS: (e.g. macOS, Windows 11)\n- Browser (if relevant): (e.g. Chrome 108, Firefox 107)\n- Agno Version: (e.g. v1.0.0)\n- External Dependency Versions: (e.g., yfinance 0.2.52)\n- Additional Environment Details: (e.g., Python 3.10)\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\nsolve this issue as quick as possible ",
      "state": "closed",
      "author": "mahendra867",
      "author_type": "User",
      "created_at": "2025-02-05T11:08:25Z",
      "updated_at": "2025-04-21T09:31:02Z",
      "closed_at": "2025-02-24T15:57:49Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2014/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2014",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2014",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:22.457501",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "@mahendra867 \n1. The reader will always happen if you call \"load\", even with skip existing. Because it has to analyze the docs to get the chunks so it can confirm it is in the DB. We are working on making this async and run in parallel, so it will become much faster.\n2. `skip_existing` only skips in",
          "created_at": "2025-02-19T11:24:54Z"
        },
        {
          "author": "dirkbrnd",
          "body": "I'll close this issue for now. We are working on improving the experience of using this.",
          "created_at": "2025-02-24T15:57:49Z"
        },
        {
          "author": "KinonoChen",
          "body": "u dont need call “load” again if u sure the pdf has beed loaded",
          "created_at": "2025-04-21T09:31:01Z"
        }
      ]
    },
    {
      "issue_number": 2251,
      "title": "[Bug] Upserting 33k  JSON is very slow",
      "body": "# Description\nLoading this knowledge base of 760 JSON objects takes ~4.5 minutes. Much larger PDF files take much less than that.\n\n[historic_squares_with_counts.json](https://github.com/user-attachments/files/19014640/historic_squares_with_counts.json)\n\n## Steps to Reproduce\nLoading with this code:\n\n```python\nknowledge_base = JSONKnowledgeBase(\n    path=\"../src/assets/data/historic_squares_with_counts.json\",\n    vector_db=PgVector(\n        table_name=\"f1bingo_labels_used\",\n        db_url=db_url\n    ),\n)\n\nknowledge_base.load(upsert=True)\n```\n\n## Agent Configuration (if applicable)\nN/A\n\n## Expected Behavior\nMuch faster loading.\n\n## Actual Behavior\nLoading took ~4.5 minutes.\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- OS: Ubuntu 22.04 latest\n- Agno Version: 1.1.7\n- Additional Environment Details: 3.10.12\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "RobSpectre",
      "author_type": "User",
      "created_at": "2025-02-27T18:45:44Z",
      "updated_at": "2025-04-21T09:26:09Z",
      "closed_at": "2025-03-18T03:16:08Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2251/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2251",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2251",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:22.682885",
      "comments": [
        {
          "author": "mishramonalisha76",
          "body": "Hi @RobSpectre,  We're actively upgrading our knowledge base system to operate asynchronously and concurrently, which will significantly boost performance. So far, we've integrated these improvements for CSV processing, and our next focus is on implementing JSON support. Thanks for bringing this up.",
          "created_at": "2025-03-06T08:08:31Z"
        },
        {
          "author": "KinonoChen",
          "body": "> Hi [@RobSpectre](https://github.com/RobSpectre), We're actively upgrading our knowledge base system to operate asynchronously and concurrently, which will significantly boost performance. So far, we've integrated these improvements for CSV processing, and our next focus is on implementing JSON sup",
          "created_at": "2025-04-21T09:26:08Z"
        }
      ]
    },
    {
      "issue_number": 2477,
      "title": "[Bug]HuggingfaceCustomEmbedder Error upserting documents: (builtins.ValueError) expected 1536 dimensions, not 768",
      "body": "# Description\n\nHuggingfaceCustomEmbedder Error upserting documents: (builtins.ValueError) expected 1536 dimensions, not 768\n\nmy code\n\n`embeddings = HuggingfaceCustomEmbedder()\n\ndb_url = \"postgresql+psycopg://...\"\nknowledge_base = PDFUrlKnowledgeBase(\n    # Read PDF from this URL\n    urls=[\"https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n    # Store embeddings in the `ai.recipes` table\n    vector_db=PgVector(table_name=\"recipes\", db_url=db_url, search_type=SearchType.hybrid,embedder=embeddings),\n)\n# Load the knowledge base: Comment after first run\nknowledge_base.load(upsert=True)`\n\n## Steps to Reproduce\nList the steps needed to encounter this bug or issue.\n\n## Agent Configuration (if applicable)\nProvide relevant agent configuration.\n\n## Expected Behavior\nWhat did you expect to happen?\n\n## Actual Behavior\nWhat actually happened instead?\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- OS: (e.g. macOS, Windows 11)\n- Browser (if relevant): (e.g. Chrome 108, Firefox 107)\n- Agno Version: (e.g. v1.0.0)\n- External Dependency Versions: (e.g., yfinance 0.2.52)\n- Additional Environment Details: (e.g., Python 3.10)\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "ruidanwang",
      "author_type": "User",
      "created_at": "2025-03-21T03:52:10Z",
      "updated_at": "2025-04-21T09:18:25Z",
      "closed_at": "2025-03-21T04:02:41Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2477/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2477",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2477",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:22.861948",
      "comments": [
        {
          "author": "KinonoChen",
          "body": "You need to manually specify the dimension like this : embedder_=SentenceTransformerEmbedder(id=\"xxx\",dimensions=xxx)",
          "created_at": "2025-04-21T09:18:23Z"
        }
      ]
    },
    {
      "issue_number": 2855,
      "title": "[Bug] Content type not set on tool result messages",
      "body": "# Description\nThere seems to be an issue when making tool calls that for some reason results in content type not being set. \n\n## Steps to Reproduce\nHappens sporadically when using duck duck go tool for example.\n\n## Screenshots or Logs (if applicable)\n\n![Image](https://github.com/user-attachments/assets/a288e65f-4420-4594-af7c-1b86b0fa2d10)\n\n## Environment\n- Agno Version: main\n- Claud and OpenAI models\n",
      "state": "closed",
      "author": "mkschreder",
      "author_type": "User",
      "created_at": "2025-04-16T20:02:11Z",
      "updated_at": "2025-04-20T19:05:31Z",
      "closed_at": "2025-04-20T19:05:30Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2855/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2855",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2855",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:23.090487",
      "comments": [
        {
          "author": "pritipsingh",
          "body": "Hey @mkschreder I am unable to reproduce this- do you mind sharing your agent config. I am able to see the result in content. I also suggest upgrading your agno version using `pip install -U agno`\n\nHere's a screenshot of tool content\n\n![Image](https://github.com/user-attachments/assets/e4338a53-9449",
          "created_at": "2025-04-17T07:59:51Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@mkschreder I added a catch-all in Claude that should prevent it. But you say it happens for OpenAI as well??",
          "created_at": "2025-04-18T14:44:55Z"
        },
        {
          "author": "mkschreder",
          "body": "Closing this. Seems to work the last few days. ",
          "created_at": "2025-04-20T19:05:30Z"
        }
      ]
    },
    {
      "issue_number": 2500,
      "title": "[Bug] Redundant message history storage",
      "body": "# Description\nWhen set to use storage to create memories, summaries, etc agno tends to keep redundant copies of chat history leading to bloated storage and inefficient/slow response\n\n## Steps to Reproduce\nCreate an agent using all the storage features, have a lengthy chat and examine the agent sessions storage database entry. \n\n## Agent Configuration (if applicable)\nI'm using an agent with firestore storage for a nosql experience. I noticed this when firestore complained about the document being over the limit for firestore. \n\n```\n# agno chat agent\nchat_agent = Agent(\n    telemetry=False,\n    monitoring=False,\n    user_id=\"unknown\",\n    model=model_pro,\n    storage=FirestoreStorage(\n        collection_name=\"agent_sessions\",\n    ),\n    # Store memories in Firestore\n    memory=AgentMemory(\n        db=FirestoreMemoryDb(),\n        create_user_memories=True,\n        create_session_summary=True,\n        update_user_memories_after_run=True,\n        update_session_summary_after_run=True,\n        classifier=MemoryClassifier(model=model_flash),\n        summarizer=MemorySummarizer(model=model_flash),\n        manager=MemoryManager(model=model_flash),\n    ),\n    # Set add_history_to_messages=true to add the previous chat history to the messages sent to the Model.\n    add_history_to_messages=True,\n    # Number of historical responses to add to the messages.\n    num_history_responses=30,\n    read_chat_history=True,\n    create_default_user_message=False,\n    retries=3,\n    instructions=chat_agent_instructions,\n    additional_context=more_stuff,\n    markdown=True,\n)\n```\n\n\n## Expected Behavior\nI would expect agno to store a single copy of the messages in the chat and reference it when referring to the history. \n\n## Actual Behavior\nAgno appears to store: \n- memory.messages that holds a current  record of the conversation\n<img width=\"326\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/dddacb93-1cd0-42f9-9512-aaec181f736f\" />\n\n\n- memory.runs.response.messages that also holds a record of the conversation for each run of the agent\n\n<img width=\"536\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/d2aa90d7-43dc-4f3b-ba24-4d1ef356f375\" />\n\nWhen adding past conversation to the chat history; agno appears to use the latter and relies on the \"from_history\" field to weed out every copy of messages in all the runs to produce the same thing that the memory.messages list already holds.\nhttps://github.com/agno-agi/agno/blob/main/libs/agno/agno/memory/agent.py#L134\n\n\n## Possible Solutions (optional)\nI would think that: \n- memory.runs would not store message history\n- references to the chat history would only use the existing memory.messages list\n\n## Additional Context\nThis is particularly expensive when there are lengthy system instructions involved which are stored multiple times for each time the agent is run even though they aren't referenced. \n",
      "state": "closed",
      "author": "jeffbryner",
      "author_type": "User",
      "created_at": "2025-03-23T02:31:10Z",
      "updated_at": "2025-04-20T00:36:08Z",
      "closed_at": "2025-04-20T00:36:08Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 10,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2500/reactions",
        "total_count": 2,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 1,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2500",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2500",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:23.344018",
      "comments": [
        {
          "author": "jeffbryner",
          "body": "Also a little confusing that the num_history_responses parameter appears to mean how many messages you'd like to add to the chat history, but it actually controls how many 'runs' are considered. The number of runs doesn't impact the number of messages added to the history, since the entire history i",
          "created_at": "2025-03-23T02:58:17Z"
        },
        {
          "author": "ysolanky",
          "body": "Hello @jeffbryner! I am happy to answer any questions. \n\nIn `session[\"memory\"]`, all messages from every run of the session are stored. Meanwhile, `session[\"memory\"][\"response\"][\"runs\"]` specifically contains the messages that were sent to the model to generate a particular response. In your case, b",
          "created_at": "2025-03-26T05:06:52Z"
        },
        {
          "author": "jeffbryner",
          "body": "Hi @ysolanky , appreciate the response. \nI understand the need to show a complete conversation to the model and appreciate the call out of tool responses as an example. Seems like we could do this by just using the last run? \n\nIf I understand the code correctly; no matter now many runs you ask to be",
          "created_at": "2025-03-26T23:45:13Z"
        },
        {
          "author": "ysolanky",
          "body": "> Seems like we could do this by just using the last run?\n\nWe can do this if we were to simply add all past messages to the current message as history. This could work in some cases and could be something we can support in the future. The downside would be messages that cost a lot of tokens in a ses",
          "created_at": "2025-03-27T16:10:05Z"
        },
        {
          "author": "jeffbryner",
          "body": "I'm not sure I understand how the 'from_history' attribute is being used? \n\nI ran some code over a session with 3 user messages and 3 runs. \n\n```\nfor a_run in session['memory']['runs']:\n    print('----run ----')\n    for r in a_run['response']['messages']:\n        print(f\"role: {r['role']:>10}       ",
          "created_at": "2025-03-31T00:52:35Z"
        }
      ]
    },
    {
      "issue_number": 2604,
      "title": "Azure OpenAI not working",
      "body": "I'm trying to import the Azure OpenAI with Agno, but its not working. Look out below for the code and error:\n\nCode:\nfrom agno.agent import Agent\nfrom agno.models.azure import AzureOpenAI\nimport dotenv\n\ndotenv.load_dotenv()\n\nagent = Agent(\n    model=AzureOpenAI(id=\"gpt-4o\"),\n    description=\"You are an enthusiastic news reporter with a flair for storytelling!\",\n    markdown=True\n)\nagent.print_response(\"Tell me about a breaking news story from New York.\", stream=True)\n\n\n\n\nError Logs:\nkeyan@Dell MINGW64 ~/Desktop/Agno\n$ python basic_agent.py \nTraceback (most recent call last):\n  File \"C:\\Users\\keyan\\Desktop\\Agno\\basic_agent.py\", line 8, in <module>\n    model=AzureOpenAI(id=\"gpt-4o\"),\n          ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\keyan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\agno\\models\\azure\\__init__.py\", line 9, in __init__\n    raise ImportError(\"`openai` not installed. Please install it via `pip install openai`\")  \nImportError: `openai` not installed. Please install it via `pip install openai`\n",
      "state": "closed",
      "author": "itsmekeyan",
      "author_type": "User",
      "created_at": "2025-03-29T15:39:33Z",
      "updated_at": "2025-04-20T00:36:06Z",
      "closed_at": "2025-04-20T00:36:06Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2604/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "dirkbrnd"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2604",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2604",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:23.988050",
      "comments": [
        {
          "author": "srinivas365",
          "body": "@itsmekeyan AzureOpenAI requires openai package as well and it's suggesting you to install the same at the end. Are you facing the issue even after installing the openai package?",
          "created_at": "2025-03-29T16:18:34Z"
        },
        {
          "author": "itsmekeyan",
          "body": "Yes @srinivas365, I installed the openai and again too, I'm getting the same error. When I checked the code of importing azure openai, it hardcoded the raise error always. Can you check the code of it or if wanted I can share you them. ",
          "created_at": "2025-03-30T07:12:28Z"
        },
        {
          "author": "willemcdejongh",
          "body": "Hi @itsmekeyan Thanks for using Agno!\n Could you please share where the error is hardcoded to always get raised?\nYou can also check out this page in the docs to make sure you have setup Agno correctly 😄 \nhttps://docs.agno.com/introduction/agents\n",
          "created_at": "2025-03-31T14:27:30Z"
        },
        {
          "author": "itsmekeyan",
          "body": "@willemcdejongh Check this out... Pls note, I installed the openai already and its available. \n\n![Image](https://github.com/user-attachments/assets/64750f46-6a0d-4867-b8c4-ec8830ba3cc9)\n\n![Image](https://github.com/user-attachments/assets/22049a59-b813-46d4-97be-6092fb4f0621)",
          "created_at": "2025-04-01T11:03:40Z"
        },
        {
          "author": "GitMarco27",
          "body": "Hi! Upgrading from openai 1.61.1 to 1.70.0 fixed for me, for agno 1.2.10",
          "created_at": "2025-04-05T18:50:38Z"
        }
      ]
    },
    {
      "issue_number": 2475,
      "title": "[Bug]YFinanceTools bug",
      "body": "# Description\nDEBUG ================================== assistant ===================================                             \n---------------------------------------------------------------------------\nJSONDecodeError                           Traceback (most recent call last)\n[<ipython-input-20-eee051205a1a>](https://localhost:8080/#) in <cell line: 0>()\n     13     instructions=[\"Format your response using markdown and use tables to display data where possible.\"],\n     14 )\n---> 15 agent.print_response(\"分享京东美股股价和分析师建议\", stream=True)\n\n5 frames\n[/usr/lib/python3.11/json/decoder.py](https://localhost:8080/#) in decode(self, s, _w)\n    338         end = _w(s, end).end()\n    339         if end != len(s):\n--> 340             raise JSONDecodeError(\"Extra data\", s, end)\n    341         return obj\n    342 \n\nJSONDecodeError: Extra data: line 1 column 67 (char 66)\n\n",
      "state": "closed",
      "author": "ruidanwang",
      "author_type": "User",
      "created_at": "2025-03-21T01:57:51Z",
      "updated_at": "2025-04-19T00:31:26Z",
      "closed_at": "2025-04-19T00:31:26Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2475/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2475",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2475",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:24.193160",
      "comments": [
        {
          "author": "Kenshinhu",
          "body": "Could you share the detailed code? \nI tried it on my end, and it’s working fine.",
          "created_at": "2025-03-21T03:30:19Z"
        },
        {
          "author": "ruidanwang",
          "body": "from agno.agent import Agent\nfrom agno.tools.yfinance import YFinanceTools\nfrom agno.models.huggingface import HuggingFace\n\nagent = Agent(\n    model=HuggingFace(\n        id=\"Qwen/Qwen2.5-72B-Instruct\", max_tokens=4096, temperature=0\n    ),\n    tools=[YFinanceTools(stock_price=True, analyst_recommend",
          "created_at": "2025-03-21T04:34:06Z"
        },
        {
          "author": "pritipsingh",
          "body": "This seems like an issue with the language. It's working fine for me! @kausmeows can help you with this- he'll be working on supporting languages properly. Please help us if you're able to run this in english!",
          "created_at": "2025-03-25T17:02:18Z"
        },
        {
          "author": "kausmeows",
          "body": "Hey @ruidanwang I tested with Gemini and OpenAI model, gives me something like this-\n\nGemini-\n\n<img width=\"821\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/03242bc3-ada3-4294-bc96-4df7333b5f36\" />\n\nOpenAI-\n\n<img width=\"815\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/",
          "created_at": "2025-04-04T23:35:54Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-19T00:31:24Z"
        }
      ]
    },
    {
      "issue_number": 2596,
      "title": "[Bug] Behavior not matching with Docs",
      "body": "# Description\nAs per the docs about team `show_members_responses` should set the debug mode on for team and members, but in my experience, we also need to enable `debug_mode` else the member communication is not logged on console. Either update the docs or enable `debug_mode` internally, when `show_members_responses` is enabled\n\n![Image](https://github.com/user-attachments/assets/762a2a3d-2d52-4adf-ba7e-b82a70ac416d)\n\n\nWith both `debug_mode` and `show_members_responses` enabled:\n\n<img width=\"1346\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/dd41a96c-a026-4c81-8a1c-57a16067c18e\" />\n\nWith just `show_members_responses` enabled:\n\n![Image](https://github.com/user-attachments/assets/555ba633-79f6-4a0b-bd07-5283eda20a4b)",
      "state": "closed",
      "author": "gauravdhiman",
      "author_type": "User",
      "created_at": "2025-03-28T23:04:25Z",
      "updated_at": "2025-04-19T00:31:23Z",
      "closed_at": "2025-04-19T00:31:23Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2596/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "willemcdejongh"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2596",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2596",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:24.424706",
      "comments": [
        {
          "author": "blanklob",
          "body": "I have same issues guys?? \n\nprevent_hallucinations and other params not working \n\n```python\nline 16, in <module>\n    agent = Agent(\n            ^^^^^^\nTypeError: Agent.__init__() got an unexpected keyword argument 'limit_tool_access'\n```",
          "created_at": "2025-03-29T09:29:38Z"
        },
        {
          "author": "uriafranko",
          "body": "yep, some parameters in the docs are not really exists",
          "created_at": "2025-03-30T13:22:09Z"
        },
        {
          "author": "willemcdejongh",
          "body": "Hey @gauravdhiman \nThanks for raising. We agree, using `show_member_responses` should enable `debug_mode` automatically on teams. We are making the update and it will be included in the next release",
          "created_at": "2025-04-04T07:41:42Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-19T00:31:22Z"
        }
      ]
    },
    {
      "issue_number": 2663,
      "title": "[Bug] command ag ws create -e dev -t agent-api -n my_workspace returns error with exit code 128",
      "body": "# Description\nIt seems that the template directory is missing from expected location\n\n## Steps to Reproduce\nrun command ag ws create -e dev -t agent-api -n my_workspace\n\n## Agent Configuration (if applicable)\nstandard, all other ag ws commands work as expected \n\n## Expected Behavior\nTo create new workspace based on the agno codebase template\n\n## Actual Behavior\nReceived ERROR    Cmd('git') failed due to: exit code(128)                               \n           cmdline: git clone -v --progress --                                  \n         https://github.com/agno-agi/agent-app-template                         \n         /Users/redacted/my_workspace\n\n![Image](https://github.com/user-attachments/assets/94c5a579-7517-4bbd-b1da-56708ebc0167)\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- OS: MacOS latest\n- Agno Version: latest\n- Python: latest\n\n## Possible Solutions (optional)\nAdd the missing directory to the GitHub repository \n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "thlinna",
      "author_type": "User",
      "created_at": "2025-04-03T18:14:47Z",
      "updated_at": "2025-04-19T00:31:19Z",
      "closed_at": "2025-04-19T00:31:19Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2663/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2663",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2663",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:24.687750",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @thlinna ! From the screenshot it appears like your Agno version is not updated. The command `ag ws create  -t agent-app -n my_workspace` is supposed to clone the following repo: https://github.com/agno-agi/agent-app-aws not `agent-app-templdate`. Please run: `pip install -U agno` and try agai",
          "created_at": "2025-04-04T03:10:29Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-19T00:31:17Z"
        }
      ]
    },
    {
      "issue_number": 2665,
      "title": "Batch Processing With Agno - Best Practice?",
      "body": "Hi team,\n\nThis isn’t a bug or feature request — I’m looking for guidance on the best way to use Agno for a batch processing use case.\n\nI’m using a multi-agent setup to run research tasks and return structured outputs. I’d like to parallelize requests for speed, while respecting rate limits (e.g., OpenAI, Jina Reader). Are there any recommended patterns or best practices for this?\n\nI understand this may be outside the scope of the SDK, but I imagine it’s a common use case across industries. If your team has explored this — especially in a serverless or containerized environment like AWS Lambda — I’d love to hear your insights.",
      "state": "closed",
      "author": "mancunian1792",
      "author_type": "User",
      "created_at": "2025-04-03T20:31:38Z",
      "updated_at": "2025-04-19T00:31:17Z",
      "closed_at": "2025-04-19T00:31:17Z",
      "labels": [
        "stale"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2665/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2665",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2665",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:24.867056",
      "comments": [
        {
          "author": "kausmeows",
          "body": "Hey @mancunian1792, thanks for reaching out. Are you trying to process documents and pdfs, etc by some `vectordb/knowledge-base`. If yes we recently added an async support to all of these. You can check out some cookbooks here- \n- https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/kn",
          "created_at": "2025-04-04T07:41:18Z"
        },
        {
          "author": "mancunian1792",
          "body": "Nope.\n\nI’m working with a multi-agent research system that leverages various tools—including custom ones—to conduct detailed research on companies. I have a list of 10,000 companies and i want to determine whether I can simply pass these prompts as a list to the run method, or if I should implement ",
          "created_at": "2025-04-04T08:05:36Z"
        },
        {
          "author": "kausmeows",
          "body": "> Nope.\n> \n> I’m working with a multi-agent research system that leverages various tools—including custom ones—to conduct detailed research on companies. I have a list of 10,000 companies and i want to determine whether I can simply pass these prompts as a list to the run method, or if I should impl",
          "created_at": "2025-04-04T20:04:05Z"
        },
        {
          "author": "ysolanky",
          "body": "Hello @mancunian1792 !\n\nFor parallelization, I would recommend checking out this [example here ](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/async/gather_agents.py). \n\nRate limits with parallel execution can be a bit tricky. Ideally, you want agents running in parallel for bet",
          "created_at": "2025-04-04T21:03:46Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-19T00:31:15Z"
        }
      ]
    },
    {
      "issue_number": 2797,
      "title": "[Bug]",
      "body": "# Description\nBriefly describe the issue you’re experiencing or the bug you’ve found.\n\nWhen attempting to use DynamoDB storage for an agent, I got create table failed due to invalid parameter value\n\n## Steps to Reproduce\nList the steps needed to encounter this bug or issue.\n\nAttempt to instantiate an agent with ```DynamoDBStorage```\n\n## Agent Configuration (if applicable)\nProvide relevant agent configuration.\n```storage = DynamoDbStorage(table_name=\"agent_sessions\",)```\n\n## Expected Behavior\nWhat did you expect to happen?\nThe table to be created satisfactorily \n\n## Actual Behavior\nWhat actually happened instead?\n\nEncountered the error ```ClientError: An error occurred (ValidationException) when calling the CreateTable operation: One or more parameter values were invalid: Some AttributeDefinitions are not used. AttributeDefinitions: [session_id, created_at, agent_id, user_id, team_session_id], keys used: [agent_id, user_id, session_id, created_at```\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n```ClientError: An error occurred (ValidationException) when calling the CreateTable operation: One or more parameter values were invalid: Some AttributeDefinitions are not used. AttributeDefinitions: [session_id, created_at, agent_id, user_id, team_session_id], keys used: [agent_id, user_id, session_id, created_at```\n## Environment\n- OS: macOS / Linux\n- Agno Version: latest\n- External Dependency Versions: boto3 latest\n- Additional Environment Details: python3.12\n\n## Possible Solutions (optional)\nLinking PR: https://github.com/agno-agi/agno/pull/2798\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "jlonge4",
      "author_type": "User",
      "created_at": "2025-04-13T02:16:29Z",
      "updated_at": "2025-04-17T20:11:26Z",
      "closed_at": "2025-04-17T20:11:25Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2797/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2797",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2797",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:25.067182",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Merged your PR. Thanks for the contribution!",
          "created_at": "2025-04-17T20:11:25Z"
        }
      ]
    },
    {
      "issue_number": 2845,
      "title": "[Bug] Async tool calls not working with Agno",
      "body": "# Description\nI am unable to use async tools with Agno as they are not being awaited properly.\n\n## Steps to Reproduce\nWe can run the example code to reproduce this issue:\n```\nimport asyncio\nimport time\n\nfrom agno.agent import Agent\nfrom agno.models.openai import OpenAIChat\nfrom agno.utils.log import logger\n\n\nasync def atask1(delay: int):\n    \"\"\"Simulate a task that takes a random amount of time to complete\n    Args:\n        delay (int): The amount of time to delay the task\n    \"\"\"\n    logger.info(\"Task 1 has started\")\n    for _ in range(delay):\n        await asyncio.sleep(1)\n        logger.info(\"Task 1 has slept for 1s\")\n    logger.info(\"Task 1 has completed\")\n    return f\"Task 1 completed in {delay:.2f}s\"\n\n\nasync def atask2(delay: int):\n    \"\"\"Simulate a task that takes a random amount of time to complete\n    Args:\n        delay (int): The amount of time to delay the task\n    \"\"\"\n    logger.info(\"Task 2 has started\")\n    for _ in range(delay):\n        await asyncio.sleep(1)\n        logger.info(\"Task 2 has slept for 1s\")\n    logger.info(\"Task 2 has completed\")\n    return f\"Task 2 completed in {delay:.2f}s\"\n\n\nasync def atask3(delay: int):\n    \"\"\"Simulate a task that takes a random amount of time to complete\n    Args:\n        delay (int): The amount of time to delay the task\n    \"\"\"\n    logger.info(\"Task 3 has started\")\n    for _ in range(delay):\n        await asyncio.sleep(1)\n        logger.info(\"Task 3 has slept for 1s\")\n    logger.info(\"Task 3 has completed\")\n    return f\"Task 3 completed in {delay:.2f}s\"\n\n\nasync_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o-mini\"),\n    tools=[atask2, atask1, atask3],\n    show_tool_calls=True,\n    markdown=True,\n)\n\nasyncio.run(\n    async_agent.aprint_response(\"Please run all tasks with a delay of 3s\", stream=True)\n)\n```\n\n## Agent Configuration (if applicable)\nMentioned in code.\n\n## Expected Behavior\nI expected all 3 tool calls to run normally in an async behavior.\n\n## Actual Behavior\nI got an error saying:\n```\nTraceback (most recent call last):\n  File \"/home/prosekutor/projects/agno/async_example.py\", line 55, in <module>\n    asyncio.run(\n  File \"/usr/lib/python3.10/asyncio/runners.py\", line 44, in run\n    return loop.run_until_complete(main)\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 649, in run_until_complete\n    return future.result()\n  File \"/home/prosekutor/projects/agno/env/lib/python3.10/site-packages/agno/agent/agent.py\", line 4660, in aprint_response\n    async for resp in await self.arun(\n  File \"/home/prosekutor/projects/agno/env/lib/python3.10/site-packages/agno/agent/agent.py\", line 1213, in _arun\n    async for model_response_chunk in model_response_stream:  # type: ignore\n  File \"/home/prosekutor/projects/agno/env/lib/python3.10/site-packages/agno/models/base.py\", line 640, in aresponse_stream\n    async for function_call_response in self.arun_function_calls(\n  File \"/home/prosekutor/projects/agno/env/lib/python3.10/site-packages/agno/models/base.py\", line 1000, in arun_function_calls\n    function_call_result = self._create_function_call_result(\n  File \"/home/prosekutor/projects/agno/env/lib/python3.10/site-packages/agno/models/base.py\", line 819, in _create_function_call_result\n    return Message(\n  File \"/home/prosekutor/projects/agno/env/lib/python3.10/site-packages/pydantic/main.py\", line 193, in __init__\n    self.__pydantic_validator__.validate_python(data, self_instance=self)\npydantic_core._pydantic_core.ValidationError: 2 validation errors for Message\ncontent.list[any]\n  Input should be a valid list [type=list_type, input_value=<coroutine object atask1 at 0x7fa4323bf8b0>, input_type=coroutine]\n    For further information visit https://errors.pydantic.dev/2.8/v/list_type\ncontent.str\n  Input should be a valid string [type=string_type, input_value=<coroutine object atask1 at 0x7fa4323bf8b0>, input_type=coroutine]\n    For further information visit https://errors.pydantic.dev/2.8/v/string_type\nsys:1: RuntimeWarning: coroutine 'atask3' was never awaited\nsys:1: RuntimeWarning: coroutine 'atask2' was never awaited\nsys:1: RuntimeWarning: coroutine 'atask1' was never awaited\n```\n\n## Environment\n- OS: Ubuntu 22.04.3 LTS (WSL) on Windows 11 x86_64\n- Browser (if relevant): N/A\n- Agno Version: 1.3.1\n- External Dependency Versions: N/A\n- Additional Environment Details: Python 3.10.12\n\n## Additional Context\nNothing as of now. Please ask if needed.\n",
      "state": "closed",
      "author": "pluto-haris",
      "author_type": "User",
      "created_at": "2025-04-16T08:28:53Z",
      "updated_at": "2025-04-17T10:49:05Z",
      "closed_at": "2025-04-17T10:49:03Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2845/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2845",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2845",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:25.273694",
      "comments": [
        {
          "author": "kausmeows",
          "body": "Hey @pluto-haris , i tried the code and could not reproduce this. Its working as follows for me-\n\n![Image](https://github.com/user-attachments/assets/540499c3-646f-467e-a879-ea15e01293f7)",
          "created_at": "2025-04-17T07:10:35Z"
        },
        {
          "author": "pluto-haris",
          "body": "@kausmeows \nThis is strange. It does not work for me at all.\n\nNot even after upgrading to latest version of agno.\n\nMy project's main requirement is asynchronicity.",
          "created_at": "2025-04-17T08:24:32Z"
        },
        {
          "author": "dirkbrnd",
          "body": "This is definitely supported in Agno. I got the same result as @kausmeows.\nI thought this might be due to the version of Python, but I downgraded to 3.10 and also got the same result. \n\nIt must be something that is not the correct version or correct package? Can you maybe start with a fresh environm",
          "created_at": "2025-04-17T10:39:16Z"
        },
        {
          "author": "pluto-haris",
          "body": "You were right.\n\nThis was due to incorrect versioning of something. Starting with a fresh environment resolved this.",
          "created_at": "2025-04-17T10:49:03Z"
        }
      ]
    },
    {
      "issue_number": 2713,
      "title": "[Bug] Invalid API Key while using MemoryManager or MemoryClassifier when using AzureOpenAI model",
      "body": "I'm getting the Invalid API Key error even if I specify that I'm using AzureOpenAI while using `MemoryManager` and `MemoryClassifier`\n\n```\ndb_url = \"postgresql+psycopg2://Shekhar@localhost:5432/agno\"\n\nsession_id=\"11\"\nstorage = PostgresStorage(\n    table_name=\"sessions\", schema=\"session\", db_url=db_url\n)\nmemory = TeamMemory(\n    db=PgMemoryDb(\n        table_name=\"agent_team_memory\",\n        schema=\"sessions\",\n        db_url=db_url,\n    ),\n    user_id=\"1\",\n    create_user_memories=True,\n    update_user_memories_after_run=True,\n    manager=MemoryManager(model=AzureOpenAI(id=\"gpt-4o\", api_key=\"***\", api_version=\"2024-08-01-preview\", azure_endpoint=\"***\")),\n    classifier=MemoryClassifier(model=AzureOpenAI(id=\"gpt-4o\", api_key=\"fbaba473ff0746f0bb658cebd7962392\", api_version=\"2024-08-01-preview\", azure_endpoint=\"https://ey-innovationlab-openai-2.openai.azure.com/\"))\n)\n\nloan_upselling_team:Team = Team(\n    name=\"Loan Upselling team.\",\n    user_id=\"1\",\n    mode=\"coordinate\",\n    session_id=session_id,\n    storage=storage,\n    memory=memory,\n    model=AzureOpenAI(id=\"gpt-4o\", api_key=\"***\", api_version=\"2024-08-01-preview\", azure_endpoint=\"***\"),\n    members=[sales_agent, verification_agent, decision_making_agent],\n    description=\"A team of agents handling customer queries and loan processes at Horizon Financial.\",\n    instructions=[\n        \"This is a team of specialized agents at Horizon Financial.\",\n        \"Please route the user query to the agent which you think is responsible to handel that particular query\"\n        \"The Sales Assistant leads customer interactions and delegates tasks.\",\n        \"Collaborate to provide accurate, timely responses to customer queries.\",\n        \"Other agent can ask you to gather customer input on their behalf that they need to provide response to customer query.\",\n        \"After taking user input, please provide that user input back to that agent which has asked you to gather that from the user.\"\n    ],\n    success_criteria=\"\"\"\n    Following is the success criteria:\n    - customer is satisfied with the response and his query is resolved.\n    - customer has no further query to ask.\n    - customer no longer wishes to continue the conversation..\n    - customer is no longer interested in the loan offers.\n    - customer has filled the loan application form and will be updated later on about the application status.\n    \"\"\",\n    add_context=True,\n    add_state_in_messages=True,\n    add_datetime_to_instructions=True,\n    enable_agentic_context = True,\n    share_member_interactions= True,\n    read_team_history = True,\n    enable_team_history=True,\n    show_tool_calls=True,\n    # # markdown=True,\n    show_members_responses=True,\n    # tools = [UserInputToolkit()],\n    debug_mode=True,\n)\n\n\n\n   should_update_memory = force or self.should_update_memory(input=input)\n                                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n  File \"/Users/Shekhar/agno_ai_poc/venv/lib/python3.13/site-packages/agno/memory/agent.py\", line 256, in should_update_memory\n    classifier_response = self.classifier.run(input)\n  File \"/Users/Shekhar/agno_ai_poc/venv/lib/python3.13/site-packages/agno/memory/classifier.py\", line 79, in run\n    response = self.model.response(messages=messages_for_model)\n  File \"/Users/Shekhar/agno_ai_poc/venv/lib/python3.13/site-packages/agno/models/base.py\", line 175, in response\n    assistant_message, has_tool_calls = self._process_model_response(\n                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        messages=messages,\n        ^^^^^^^^^^^^^^^^^^\n        model_response=model_response,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/Shekhar/agno_ai_poc/venv/lib/python3.13/site-packages/agno/models/base.py\", line 311, in _process_model_response\n    response = self.invoke(messages=messages)\n  File \"/Users/Shekhar/agno_ai_poc/venv/lib/python3.13/site-packages/agno/models/openai/chat.py\", line 363, in invoke\n    raise ModelProviderError(message=str(e), model_name=self.name, model_id=self.id) from e\nagno.exceptions.ModelProviderError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n\n```",
      "state": "closed",
      "author": "MahorShekhar",
      "author_type": "User",
      "created_at": "2025-04-07T14:52:49Z",
      "updated_at": "2025-04-17T08:35:52Z",
      "closed_at": "2025-04-17T08:35:51Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2713/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2713",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2713",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:25.443078",
      "comments": [
        {
          "author": "monali7-d",
          "body": "hey @MahorShekhar \nWe have responded to your doubt on Discourse, closing this issue",
          "created_at": "2025-04-17T08:35:51Z"
        }
      ]
    },
    {
      "issue_number": 2572,
      "title": "[Bug] UnboundLocalError: cannot access local variable 'all_reasoning_steps' where it is not associated with a value",
      "body": "\nthere are no all_reasoning_steps in the function.\n\n<img width=\"663\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/c46b4298-4368-43e6-afa6-dd71a24e2a7b\" />",
      "state": "closed",
      "author": "jacksonw111",
      "author_type": "User",
      "created_at": "2025-03-27T08:54:40Z",
      "updated_at": "2025-04-17T00:32:31Z",
      "closed_at": "2025-04-17T00:32:31Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2572/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2572",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2572",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:27.348643",
      "comments": [
        {
          "author": "jacksonw111",
          "body": "BTW. Can we yield the reason steps?",
          "created_at": "2025-03-27T09:02:25Z"
        },
        {
          "author": "ysolanky",
          "body": "Hey @jacksonw111 ! Sorry about that! I have fixed the issue here https://github.com/agno-agi/agno/pull/2581. And yes, you can stream reasoning steps using the default reasoning. [Checkout this example](https://github.com/agno-agi/agno/blob/main/cookbook/reasoning/agents/is_9_11_bigger_than_9_9.py)",
          "created_at": "2025-03-27T19:07:23Z"
        },
        {
          "author": "Rainismer",
          "body": "@ysolanky Error occurred when I using the python tool.\n\nfrom agno.agent import Agent\nfrom agno.models.openai import OpenAIChat\nfrom agno.models.azure import AzureOpenAI\nfrom agno.tools.thinking import ThinkingTools\nfrom agno.tools.python import PythonTools\nfrom textwrap import dedent\nimport os\n\nos.e",
          "created_at": "2025-04-02T07:54:37Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-17T00:32:29Z"
        }
      ]
    },
    {
      "issue_number": 2296,
      "title": "[Bug] Async tools in team of agents not awaited properly, causing runtime errors",
      "body": "# Description\nWhen using a team of agents with async tools, the tools are called synchronously, resulting in errors such as \"coroutine was never awaited.\" This issue does not occur when the async tool is called directly from the main agent.\n\n## Steps to Reproduce\n1. Create a team of agents.\n2. Include an async tool in one of the agents.\n3. Call the tool through the team setup.\n4. Observe the error indicating that the coroutine was never awaited.\n\n## Expected Behavior\nThe async tool should be awaited and executed correctly when called through a team of agents.\n\n## Actual Behavior\nThe tool is called synchronously, resulting in a RuntimeWarning and a ValidationError indicating that the coroutine was never awaited.\n\n## Screenshots or Logs \n```\n  File \"/app/.venv/lib/python3.11/site-packages/pydantic/main.py\", line 214, in __init__\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\npydantic_core._pydantic_core.ValidationError: 2 validation errors for Message\ncontent.list[any]\n  Input should be a valid list [type=list_type, input_value=<coroutine object list_books at 0x7ffff627ca90>, input_type=coroutine]\n    For further information visit https://errors.pydantic.dev/2.10/v/list_type\ncontent.str\n  Input should be a valid string [type=string_type, input_value=<coroutine object list_books at 0x7ffff627ca90>, input_type=coroutine]\n    For further information visit https://errors.pydantic.dev/2.10/v/string_type\nsys:1: RuntimeWarning: coroutine 'list_books' was never awaited\n```\n\n## Environment\nOS: Ubuntu\nAgno Version: v1.1.8\nAdditional Environment Details: Python 3.11.11\n\n## Additional Context\nThe issue seems to be specific to the use of async tools within a team of agents. When the same tool is called directly from the main agent, it works as expected.",
      "state": "closed",
      "author": "mrtlopes",
      "author_type": "User",
      "created_at": "2025-03-05T16:56:26Z",
      "updated_at": "2025-04-16T08:15:45Z",
      "closed_at": "2025-04-07T20:21:19Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 23,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2296/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2296",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2296",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:27.562016",
      "comments": []
    },
    {
      "issue_number": 2834,
      "title": "[Bug] Error when show_result=True if tool returns something different than a string",
      "body": "# Description\nAfter adding a tool to an Agent, and calling to .arun method, I'm having this error:\n\nTraceback (most recent call last):\n  File \"/Users/dani/Developer/Happyforce/happyforce-ai/happyforce_hero/app/services/chat_service.py\", line 255, in handle_chat_command\n    async for response in agent.execute_command(\n    ...<6 lines>...\n        yield f\"data: {json.dumps({'content': response.content})}\\n\\n\"\n  File \"/Users/dani/Developer/Happyforce/happyforce-ai/happyforce_hero/app/agents/who_is_hero_agent.py\", line 109, in execute_command\n    async for response in run_response:\n        yield response\n  File \"/Users/dani/Developer/Happyforce/happyforce-ai/.venv/lib/python3.13/site-packages/agno/agent/agent.py\", line 1218, in _arun\n    model_response.content = (model_response.content or \"\") + model_response_chunk.content\n                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n**TypeError: can only concatenate str (not \"bool\") to str**\n\nThe tool is this:\n\n` @tool(\n            show_result=True,                               # Show result after function call\n            stop_after_tool_call=True,                      # Return the result immediately after the tool call and stop the agent\n            cache_results=False,                            # Enable caching of results\n        )\n        def verify_new_user(agent: Agent, user_id: str, session_id: str) -> bool:\n            \"\"\"\n            A tool to verify if it is the first time you see a user.\n            \n            Args:\n                agent: The agent making the verification\n                user_id: The user ID to verify\n                session_id: The current session ID\n                \n            Returns:\n                bool: True if the user is new, False otherwise\n            \"\"\"\n            return True\n        \n        return verify_new_user `\n\nIf I modify the tool to return a String, or I set **show_result** to False, it works.\n\n## Steps to Reproduce\n\n1. Define an agent, with a tool.\n2. Make the tool to return something different than a String, like a bool.\n3. Call to the agent via arun (I've not tested with other functions), with Stream=True.\n\n## Agent Configuration (if applicable)\n\nNothing relevant\n\n## Expected Behavior\n\nNo error or exception\n\n## Actual Behavior\n\nThe agent should work.\n\n## Screenshots or Logs (if applicable)\n\nFind attached above.\n\n## Environment\n- OS: macOS 15.3.1 \n- Agno Version: 1.3.1\n\n- Additional Environment Details: Python 3.13\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "DDani",
      "author_type": "User",
      "created_at": "2025-04-15T05:52:01Z",
      "updated_at": "2025-04-16T04:45:34Z",
      "closed_at": "2025-04-16T04:45:33Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2834/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2834",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2834",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:27.562034",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @DDani ! The default behaviour of any tool is to result a string. So, when a tool returns a bool value instead, it is expected for an error to be thrown.\n\nThis happens because model APIs expect the result of a tool call to be a string in the response message. Please let us know if you have any",
          "created_at": "2025-04-15T20:51:11Z"
        },
        {
          "author": "DDani",
          "body": "Understood! Thanks and sorry for the noise;\nRegarding this setting for tools:\n\nstop_after_tool_call=True # Return the result immediately after the tool call and stop the agent,\n\nAlso applies? \n\n\n    ",
          "created_at": "2025-04-16T04:45:33Z"
        }
      ]
    },
    {
      "issue_number": 2625,
      "title": "[Bug] Tool calls don't work with Ollama Models",
      "body": "# Description\nTool calls do not work with Ollama Models. This bug was likely introduced while fixing #2491\n\n## Steps to Reproduce\n\nRun this code:\n\n```python\nagent = Agent(\n        model=Ollama(id=\"mistral-nemo:latest\",show_tool_calls=True,tool_choice=\"auto\"),\n        name=\"Testagent\",\n        tools=[DuckDuckGoTools()],\n\n        description=dedent(\"\"\"\\\n        You are an elite news research assistant. Always call the duckduckgo_news tool!\n \n        \"\"\"),\n        instructions=dedent(\"\"\"\\\n            - Use the tool 'duckduckgo_news' to find articles on the topic provided by the user\n            **Do not make up information:** If you don't know the answer or cannot determine from the provided references, say 'I don't know'.\n        \"\"\"),\n        add_datetime_to_instructions=True,\n        tool_choice=\"auto\",\n        debug_mode=True,\n        show_tool_calls=True,\n    )\n\nagent.run(\"Artificial Intelligence\")\n```\n\n\n## Agent Configuration (if applicable)\nProvide relevant agent configuration.\n\n## Expected Behavior\nTool is called\n\n## Actual Behavior\nNo tool is called\n\n## Screenshots or Logs (if applicable)\n\n\n## Environment\n- OS: macOS\n- Agno Version: 1.2.6\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "gorootde",
      "author_type": "User",
      "created_at": "2025-03-31T20:24:22Z",
      "updated_at": "2025-04-16T00:33:23Z",
      "closed_at": "2025-04-16T00:33:23Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2625/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2625",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2625",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:27.756537",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @gorootde ! Since `tool_choice` is not supported by Ollama Client, it has been removed from the Agno Ollama Model class. Additionally, the following Agent config is able to make tool calls as expected.\n\n```python\nfrom agno.agent import Agent\nfrom agno.models.ollama import Ollama\nfrom agno.tool",
          "created_at": "2025-04-01T01:30:13Z"
        },
        {
          "author": "gorootde",
          "body": "Ok looks like I made my minimal example to minimal 😉 \n\nHere is the one that doesn't call the tool:\n\n```python\nclass NewsArticle(BaseModel):\n    title: str = Field(..., description=\"Title of the article.\")\n    url: str = Field(..., description=\"Link to the article.\")\n    summary: Optional[str] = Fiel",
          "created_at": "2025-04-01T18:33:29Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-16T00:33:22Z"
        }
      ]
    },
    {
      "issue_number": 2478,
      "title": "[Bug] Agent teams not working on OpenAI compatible API",
      "body": "# Description\nWe have using one-api(an AI gateway) as OpenAI compatible provider, the backend tested here is using Ollama.\nWhen using multi agent as teams, it failed with message:\n```\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/workspace/ai/agent.py\", line 48, in <module>\n    agent_team.print_response(\"What's happening in New York?\", stream=True)\n  File \"/workspace/.env/lib/python3.10/site-packages/agno/agent/agent.py\", line 3687, in print_response\n    for resp in self.run(\n  File \"/workspace/.env/lib/python3.10/site-packages/agno/agent/agent.py\", line 577, in _run\n    for model_response_chunk in self.model.response_stream(messages=run_messages.messages):\n  File \"/workspace/.env/lib/python3.10/site-packages/agno/models/base.py\", line 505, in response_stream\n    yield from self.process_response_stream(\n  File \"/workspace/.env/lib/python3.10/site-packages/agno/models/base.py\", line 476, in process_response_stream\n    for response_delta in self.invoke_stream(messages=messages):\n  File \"/workspace/.env/lib/python3.10/site-packages/agno/models/openai/chat.py\", line 466, in invoke_stream\n    raise ModelProviderError(\nagno.exceptions.ModelProviderError: json: cannot unmarshal array into Go struct field .tools.function.parameters.properties.type of type string (request id: 2025032106511432044855B0qG47mM)\n```\n\nand the Ollama running log output status: 400\n\n\n## Steps to Reproduce\n```\nos.environ[\"OPENAI_BASE_URL\"] = config.get(\"ai.base_url\")\nos.environ[\"OPENAI_API_KEY\"] = config.get(\"ai.api_key\")\n\nknowledge_agent = Agent(\n    model=OpenAIChat(id=\"qwen2.5:72b\"),\n    instructions=[],\n    markdown=True,\n)\n\nparameter_agent = Agent(\n    model=OpenAIChat(id=\"qwen2.5:72b\"),\n    instructions=[],\n    markdown=True,\n)\n\nagent_team = Agent(\n    team=[knowledge_agent, parameter_agent],\n    model=OpenAIChat(id=\"qwen2.5:72b\"),\n    instructions=[],\n    markdown=True,\n)\n\nagent_team.print_response(\"What's happening in New York?\", stream=True)\n```\n\n",
      "state": "closed",
      "author": "elvizlai",
      "author_type": "User",
      "created_at": "2025-03-21T06:58:34Z",
      "updated_at": "2025-04-15T00:33:27Z",
      "closed_at": "2025-04-15T00:33:27Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2478/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2478",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2478",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:27.939625",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Hi @elvizlai \nDo the individual agents work? I don't think this is specifically related to teams, because this looks like the OpenAI SDK itself is rejecting the responses from the Backend. If you are looking for Ollama support, we do have a Ollama model class that might work?\nIf you help me replicat",
          "created_at": "2025-03-21T07:09:29Z"
        },
        {
          "author": "elvizlai",
          "body": "Yes, the individual agents works(Using OpenAI compatible, the same example like knowledge_agent. print_response).\n\nAll my agents has nothing related about using tools.\n\nI'm not trying this using Ollama specifically because some of our model is provided by vLLM.\n\n",
          "created_at": "2025-03-21T07:16:42Z"
        },
        {
          "author": "elvizlai",
          "body": "using Raw Ollama works:\n```\nos.environ[\"OLLAMA_HOST\"] = \"http://127.0.0.1:11434\"\nmodel = Ollama(id=\"qwen2.5:72b\")\n\nknowledge_agent = Agent(\n    model=model,\n    instructions=[],\n    markdown=True,\n)\n\nparameter_agent = Agent(\n    model=model,\n    instructions=[],\n    markdown=True,\n)\n\n\nagent_team = A",
          "created_at": "2025-03-21T07:26:02Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Then it has to be related to an incompatibility between Ollama backend and OpenAILike. \n\nWe intend to support vllm soon!",
          "created_at": "2025-03-21T15:17:03Z"
        },
        {
          "author": "elvizlai",
          "body": "```\n{\"tools\": [{\"type\": \"function\", \"function\": {\"name\": \"transfer_task_to_agent_0\", \"description\": \"Use this function to transfer a task to agent_0\\nYou must provide a clear\nand concise description of the task the agent should achieve AND the expected output.\\nArgs:\\n    task_description (str): A c",
          "created_at": "2025-03-31T06:46:57Z"
        }
      ]
    },
    {
      "issue_number": 2570,
      "title": "[Bug]Session Memory getting duplicated even with different session ids",
      "body": "# Description\nEven with new session ids, old memory is getting added to new ones.\n\n## Steps to Reproduce\nCleared DB,\nLogged into my web application, initiated a chat. Session id was null. I said hi, it responded hello. I asked what things u know about me. It said it my name, email etc details it knows.\n\nNow there is one entry in session table.\n\nRefreshed browser.\n\nSend hi again with null session id. It responded hello.\n\nNow there are 2 entries in session table. When i inspected memory column for the second session id, it was big and had memories from 1st session \n\n## Agent Configuration (if applicable)\nteam = Team(\n        name=\"xxxxx\",\n        model=azure_model,\n        mode=\"route\",\n        members=[agent1,agnet2,agnent3],\n        show_members_responses=True,\n        enable_agentic_context=True,\n        share_member_interactions=True,\n        session_id= session_id,\n        show_tool_calls=show_tool_calls,\n        markdown=True,\n        enable_team_history=True,\n        debug_mode=agent_debug_mode,\n        storage=storage,\n        memory=memory,\n        instructions = dedent(\"\"\"\\\n            - xxxxxxxxxxxxx\n        \"\"\"),\n        description=\"\"\"xxxxxxxx \"\"\",\n        #read_team_history = True,\n        user_id = user_id\n    )\n\n## Expected Behavior\nit should start from fresh since its new session id\n\n## Actual Behavior\nit acts like im continuning with the old session id\n\n## Screenshots or Logs (if applicable)\n127.0.0.1 - - [27/Mar/2025 10:50:07] \"GET /img/fav-icon.ico HTTP/1.1\" 304 -\nDEBUG ************************** Team ID: 518df964-21a8-40c6-afa1-a0b58db2fd56 ***************************\nDEBUG ************************* Session ID: 6e44b728-bf1f-4066-bc7e-498061f813cc *************************\nDEBUG Memories loaded for user: 1\nDEBUG *********************** Team Run Start: 9ca15af7-73ef-4411-843f-fdd1bb8224fb ***********************\nDEBUG ****************************************** Mode: 'route' *******************************************\nDEBUG Processing tools for model\nDEBUG Included function forward_task_to_member\nDEBUG --------------------------------------- Azure Response Start ---------------------------------------\nDEBUG --------------------------------------- Model: not-provided ----------------------------------------\nDEBUG ============================================== system ==============================================\nDEBUG You are the leader of a team of AI Agents and possible Sub-Teams:\n       - Agent 1:\n        xxxxxxxxxxxxxx\n       - Agent 2:\n         xxxxxxxxxxxx\n       - Agent 3:\n         xxxxxxxxxxx\n\n      You can and should update the context of the team. Use the `set_team_context` tool to update the shared team\n      context.\n      Your name is: xxxxxxxxxxxxx.\n\n      <description>\n      xxxxxxxxx responsible for managing the overall process and directing tasks to the appropriate\n      sub-agent.\n      </description>\n\n      <instructions>\n      - Always introduce yourself at the beginning of the chat if user greets.\n\n      </instructions>\n\n      <additional_information>\n      - Use markdown to format your answers.\n      </additional_information>\nDEBUG =============================================== user ===============================================\nDEBUG hi\nDEBUG ============================================ assistant =============================================\nDEBUG Hello! I'm xxxxxx, your xxxxxxx. How can I assist you today?\nDEBUG ********************************************  METRICS  *********************************************\nDEBUG * Tokens:                      input=800, output=20, total=820\nDEBUG * Prompt tokens details:       {'audio_tokens': 0, 'cached_tokens': 0}\nDEBUG * Completion tokens details:   {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0,\n      'rejected_prediction_tokens': 0}\nDEBUG * Time:                        3.0730s\nDEBUG * Tokens per second:           6.5083 tokens/s\nDEBUG ********************************************  METRICS  *********************************************\nDEBUG ---------------------------------------- Azure Response End ----------------------------------------\nDEBUG Added 2 Messages to TeamMemory\nDEBUG *********** MemoryClassifier Start ***********\nDEBUG --------------------------------------- Azure Response Start ---------------------------------------\nDEBUG --------------------------------------- Model: not-provided ----------------------------------------\nDEBUG ============================================== system ==============================================\nDEBUG Your task is to identify if the user's message contains information that is worth remembering for future\n      conversations.\n      This includes details that could personalize ongoing interactions with the user, such as:\n        - Personal facts: name, age, occupation, location, interests, preferences, etc.\n        - Significant life events or experiences shared by the user\n        - Important context about the user's current situation, challenges or goals\n        - What the user likes or dislikes, their opinions, beliefs, values, etc.\n        - Any other details that provide valuable insights into the user's personality, perspective or needs\n      Your task is to decide whether the user input contains any of the above information worth remembering.\n      If the user input contains any information worth remembering for future conversations, respond with 'yes'.\n      If the input does not contain any important details worth saving, respond with 'no' to disregard it.\n      You will also be provided with a list of existing memories to help you decide if the input is new or already\n      known.\n      If the memory already exists that matches the input, respond with 'no' to keep it as is.\n      If a memory exists that needs to be updated or deleted, respond with 'yes' to update/delete it.\n      You must only respond with 'yes' or 'no'. Nothing else will be considered as a valid response.\n\n      Existing memories:\n      <existing_memories>\n        - Akhil MS's favorite flavor is chocolate.\n        - Akhil MS likes milkshakes.\n      </existing_memories>\nDEBUG =============================================== user ===============================================\nDEBUG hi\nDEBUG ============================================ assistant =============================================\nDEBUG no\nDEBUG ********************************************  METRICS  *********************************************\nDEBUG * Tokens:                      input=307, output=2, total=309\nDEBUG * Prompt tokens details:       {'audio_tokens': 0, 'cached_tokens': 0}\nDEBUG * Completion tokens details:   {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0,\n      'rejected_prediction_tokens': 0}\nDEBUG * Time:                        2.9913s\nDEBUG * Tokens per second:           0.6686 tokens/s\nDEBUG ********************************************  METRICS  *********************************************\nDEBUG ---------------------------------------- Azure Response End ----------------------------------------\nDEBUG *********** MemoryClassifier End ***********\nDEBUG Update memory: False\nDEBUG Memory update not required\nDEBUG Added TeamRun to TeamMemory\nDEBUG ************************ Team Run End: 9ca15af7-73ef-4411-843f-fdd1bb8224fb ************************\nDEBUG ************************** Team ID: 5c3fa378-52d3-4d3f-bffd-6265b3cdd735 ***************************\nDEBUG ************************* Session ID: 6e44b728-bf1f-4066-bc7e-498061f813cc *************************\nDEBUG -*- TeamSession loaded: 6e44b728-bf1f-4066-bc7e-498061f813cc\nDEBUG Memories loaded for user: 1\nDEBUG *********************** Team Run Start: 65d41a62-a622-4870-bf59-90cd413c6220 ***********************\nDEBUG ****************************************** Mode: 'route' *******************************************\nDEBUG Processing tools for model\nDEBUG Included function forward_task_to_member\nDEBUG Getting messages from previous runs: 2\nDEBUG Adding 2 messages from history\nDEBUG --------------------------------------- Azure Response Start ---------------------------------------\nDEBUG --------------------------------------- Model: not-provided ----------------------------------------\nDEBUG ============================================== system ==============================================\nDEBUG You are the leader of a team of AI Agents and possible Sub-Teams:\n       - Agent 1:\n         xxxxxxxxxxxxxxxxxxxxx\n       - Agent 2:\n         -xxxxxxxxxxxxxx\n       - Agent 3:\n         xxxxxxxxxxxxx\n\n      You can and should update the context of the team. Use the `set_team_context` tool to update the shared team\n      context.\n      Your name is: xxxxxx the xxxxxxx.\n\n      <description>\n      xxxxxx the xxxxxxx is responsible for managing the overall process and directing tasks to the appropriate\n      sub-agent.\n      </description>\n\n      <instructions>\n      - Always introduce yourself at the beginning of the chat if user greets.\n\n      </instructions>\n\n      <additional_information>\n      - Use markdown to format your answers.\n      </additional_information>\nDEBUG =============================================== user ===============================================\nDEBUG hi\nDEBUG ============================================ assistant =============================================\nDEBUG Hello! I'm xxxxxx, your xxxxxxx. How can I assist you today?\nDEBUG =============================================== user ===============================================\nDEBUG what things you know about me?\nDEBUG ============================================ assistant =============================================\nDEBUG Tool Calls:\n        - ID: 'call_7ht10hs8Xn6MjOOTSAzHP4I4'\n          Name: 'forward_task_to_member'\n          Arguments: 'agent_name: Help Desk Agent, expected_output: Your details like email ID, first name, and last\n      name.'\nDEBUG ********************************************  METRICS  *********************************************\nDEBUG * Tokens:                      input=833, output=37, total=870\nDEBUG * Prompt tokens details:       {'audio_tokens': 0, 'cached_tokens': 0}\nDEBUG * Completion tokens details:   {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0,\n      'rejected_prediction_tokens': 0}\nDEBUG * Time:                        3.0948s\nDEBUG * Tokens per second:           11.9556 tokens/s\nDEBUG ********************************************  METRICS  *********************************************\nDEBUG Getting function forward_task_to_member\nDEBUG Running: forward_task_to_member(agent_name=Help Desk Agent, expected_output=...)\nDEBUG ************************** Agent ID: df505d4b-6f86-46f3-be67-81d496d3b109 **************************\nDEBUG ************************* Session ID: f7584278-1962-48b9-9092-3e0b3fbe595b *************************\nDEBUG ********************** Agent Run Start: 825e0610-3214-4302-9fa1-c045657f28a3 ***********************\nDEBUG Processing tools for model\nDEBUG Included function get_current_user_details\nDEBUG Included function create_ticket\nDEBUG Included function get_ticket_details\nDEBUG Included function get_all_tickets_details\nDEBUG Included function get_leave_balance\nDEBUG Included function search_knowledge_base\nDEBUG Getting 5 relevant documents for query: what things you know about me?\n\n      <expected_output>\n      Your details like email ID, first name, and last name.\n      </expected_output>\nERROR    Error searching for documents: Unsupported query: Range query need to target a specific field.\nDEBUG Time to get references: 2.7144s\nDEBUG --------------------------------------- Azure Response Start ---------------------------------------\nDEBUG --------------------------------------- Model: not-provided ----------------------------------------\nDEBUG ============================================== system ==============================================\nDEBUG You are an agent that answers user queries related to organizational policies, helps with ticket creation to log\n      issues, fetches ticket details, shows employees details like leaves balance etc.\n\n      <your_role>\n      This agent answers user queries related to organizational policies, helps with ticket creation to log issues,\n      fetches ticket details, shows employees details like leaves balance etc.\n      </your_role>\n\n      <instructions>\n      - If user asks a policy-related question, please ask the user if there is any specific query on the topic.\n      - For policy-related questions, you have to refer knowledge base only to generate an answer.\n      - If user asks to create a ticket related to any kind of leave, ask for the dates on which ticket needs to be\n      created.\n      - If user asks to create a ticket, ask for the detailed description of issue on which ticket needs to be created.\n      - If user ask for details like leave balance, call the appropriate tools to fetch those informations.\n\n      - Do not provide answers beyond the scopes defined above.\n      - Do not generate assumptions or external information.\n      - All tickets should be submitted in a way that they appear to have been raised directly by the user, not by you.\n\n      - If required, reference the section or clause from the knowledge base for better clarity.\n      - Always show the Source details (filename and page number) in a new line at the end of the result if you used\n      knowledge base for answering.\n\n      </instructions>\n\n      <additional_information>\n      - Use markdown to format your answers.\n      - The current time is 2025-03-27 10:50:33.041741\n      </additional_information>\n\n      <expected_output>\n      {your response}\n\n      **References**\n      -{filename and page number if any}\n      </expected_output>\nDEBUG =============================================== user ===============================================\nDEBUG what things you know about me?\n\n      <expected_output>\n      Your details like email ID, first name, and last name.\n      </expected_output>\nDEBUG ============================================ assistant =============================================\nDEBUG Your details like email ID, first name, and last name.\nDEBUG ********************************************  METRICS  *********************************************\nDEBUG * Tokens:                      input=635, output=15, total=650\nDEBUG * Prompt tokens details:       {'audio_tokens': 0, 'cached_tokens': 0}\nDEBUG * Completion tokens details:   {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0,\n      'rejected_prediction_tokens': 0}\nDEBUG * Time:                        1.9932s\nDEBUG * Tokens per second:           7.5257 tokens/s\nDEBUG ********************************************  METRICS  *********************************************\nDEBUG ---------------------------------------- Azure Response End ----------------------------------------\nDEBUG Added 2 Messages to AgentMemory\nDEBUG Added AgentRun to AgentMemory\nDEBUG *********************** Agent Run End: 825e0610-3214-4302-9fa1-c045657f28a3 ************************\nDEBUG Updated team context with member name: Help Desk Agent\nDEBUG =============================================== tool ===============================================\nDEBUG Tool call Id: call_7ht10hs8Xn6MjOOTSAzHP4I4\nDEBUG Your details like email ID, first name, and last name.\nDEBUG ******************************************  TOOL METRICS  ******************************************\nDEBUG * Time:                        0.0018s\nDEBUG ******************************************  TOOL METRICS  ******************************************\nDEBUG ---------------------------------------- Azure Response End ----------------------------------------\nDEBUG Added 3 Messages to TeamMemory\nDEBUG *********** MemoryClassifier Start ***********\nDEBUG --------------------------------------- Azure Response Start ---------------------------------------\nDEBUG --------------------------------------- Model: not-provided ----------------------------------------\nDEBUG ============================================== system ==============================================\nDEBUG Your task is to identify if the user's message contains information that is worth remembering for future\n      conversations.\n      This includes details that could personalize ongoing interactions with the user, such as:\n        - Personal facts: name, age, occupation, location, interests, preferences, etc.\n        - Significant life events or experiences shared by the user\n        - Important context about the user's current situation, challenges or goals\n        - What the user likes or dislikes, their opinions, beliefs, values, etc.\n        - Any other details that provide valuable insights into the user's personality, perspective or needs\n      Your task is to decide whether the user input contains any of the above information worth remembering.\n      If the user input contains any information worth remembering for future conversations, respond with 'yes'.\n      If the input does not contain any important details worth saving, respond with 'no' to disregard it.\n      You will also be provided with a list of existing memories to help you decide if the input is new or already\n      known.\n      If the memory already exists that matches the input, respond with 'no' to keep it as is.\n      If a memory exists that needs to be updated or deleted, respond with 'yes' to update/delete it.\n      You must only respond with 'yes' or 'no'. Nothing else will be considered as a valid response.\n\n      Existing memories:\n      <existing_memories>\n        - Akhil MS's favorite flavor is chocolate.\n        - Akhil MS likes milkshakes.\n      </existing_memories>\nDEBUG =============================================== user ===============================================\nDEBUG what things you know about me?\nDEBUG ============================================ assistant =============================================\nDEBUG I know the following details about you:\n\n      1. Your name is Akhil MS.\n      2. Your favorite flavor is chocolate.\n      3. You like milkshakes.\n\n      Let me know if there's anything you'd like to add or update!\nDEBUG ********************************************  METRICS  *********************************************\nDEBUG * Tokens:                      input=563, output=48, total=611\nDEBUG * Prompt tokens details:       {'audio_tokens': 0, 'cached_tokens': 0}\nDEBUG * Completion tokens details:   {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0,\n      'rejected_prediction_tokens': 0}\nDEBUG * Time:                        1.6009s\nDEBUG * Tokens per second:           29.9825 tokens/s\nDEBUG ********************************************  METRICS  *********************************************\nDEBUG ---------------------------------------- Azure Response End ----------------------------------------\nDEBUG *********** MemoryClassifier End ***********\nDEBUG Update memory: False\nDEBUG Memory update not required\nDEBUG Added TeamRun to TeamMemory\nDEBUG ************************ Team Run End: 65d41a62-a622-4870-bf59-90cd413c6220 ************************\n127.0.0.1 - - [27/Mar/2025 10:50:54] \"GET /socket.io/?EIO=4&transport=websocket&sid=O6j2Kz6SSNImRebCAAAC HTTP/1.1\" 200 -\n127.0.0.1 - - [27/Mar/2025 10:50:54] \"POST / HTTP/1.1\" 200 -\n127.0.0.1 - - [27/Mar/2025 10:50:54] \"GET /css/bootstrap.css HTTP/1.1\" 304 -\n127.0.0.1 - - [27/Mar/2025 10:50:54] \"GET /css/style.css HTTP/1.1\" 304 -\n127.0.0.1 - - [27/Mar/2025 10:50:54] \"GET /css/animate.css HTTP/1.1\" 304 -\n127.0.0.1 - - [27/Mar/2025 10:50:54] \"GET /css/inputfield.css HTTP/1.1\" 304 -\n127.0.0.1 - - [27/Mar/2025 10:50:54] \"GET /css/multiple-select.css HTTP/1.1\" 304 -\n127.0.0.1 - - [27/Mar/2025 10:50:54] \"GET /css/multiplesearch.css HTTP/1.1\" 304 -\n127.0.0.1 - - [27/Mar/2025 10:50:54] \"GET /img/menublue.png HTTP/1.1\" 304 -\n127.0.0.1 - - [27/Mar/2025 10:50:54] \"GET /img/db-logo.png HTTP/1.1\" 304 -\n127.0.0.1 - - [27/Mar/2025 10:50:54] \"GET /img/cavatar.png HTTP/1.1\" 304 -\n127.0.0.1 - - [27/Mar/2025 10:50:54] \"GET /js/jquery.js HTTP/1.1\" 304 -\n127.0.0.1 - - [27/Mar/2025 10:50:54] \"GET /img/logoff.png HTTP/1.1\" 304 -\n127.0.0.1 - - [27/Mar/2025 10:50:54] \"GET /js/bootstrap.js HTTP/1.1\" 304 -\n127.0.0.1 - - [27/Mar/2025 10:50:54] \"GET /img/tcsFooter.png HTTP/1.1\" 304 -\n127.0.0.1 - - [27/Mar/2025 10:50:54] \"GET /js/main.js HTTP/1.1\" 304 -\n127.0.0.1 - - [27/Mar/2025 10:50:54] \"GET /js/multiple-select.js HTTP/1.1\" 304 -\n127.0.0.1 - - [27/Mar/2025 10:50:54] \"GET /js/multi-select.js HTTP/1.1\" 304 -\n127.0.0.1 - - [27/Mar/2025 10:50:54] \"GET /img/headerBG.png HTTP/1.1\" 304 -\n127.0.0.1 - - [27/Mar/2025 10:50:54] \"GET /socket.io/?EIO=4&transport=polling&t=PNM2zE8 HTTP/1.1\" 200 -\n127.0.0.1 - - [27/Mar/2025 10:50:54] \"POST /socket.io/?EIO=4&transport=polling&t=PNM2zEE&sid=kmvV8hTLX3b5fIF1AAAE HTTP/1.1\" 200 -\n127.0.0.1 - - [27/Mar/2025 10:50:54] \"GET /img/fav-icon.ico HTTP/1.1\" 304 -\n127.0.0.1 - - [27/Mar/2025 10:50:54] \"GET /socket.io/?EIO=4&transport=polling&t=PNM2zEF&sid=kmvV8hTLX3b5fIF1AAAE HTTP/1.1\" 200 -\nDEBUG ************************** Team ID: e172db2b-18e2-47f5-b488-c5498b27af5c ***************************\nDEBUG ************************* Session ID: db227128-5765-4de6-8800-4e0b498220c0 *************************\nDEBUG Memories loaded for user: 1\nDEBUG *********************** Team Run Start: 0abb7575-b803-4731-9d9d-c9d49f513834 ***********************\nDEBUG ****************************************** Mode: 'route' *******************************************\nDEBUG Processing tools for model\nDEBUG Included function forward_task_to_member\nDEBUG Getting messages from previous runs: 5\nDEBUG Adding 5 messages from history\nDEBUG --------------------------------------- Azure Response Start ---------------------------------------\nDEBUG --------------------------------------- Model: not-provided ----------------------------------------\nDEBUG ============================================== system ==============================================\nDEBUG You are the leader of a team of AI Agents and possible Sub-Teams:\n       - Agent 1:\n        xxxxxxx\n       - Agent 2:\n         xxxxxxx\n       - Agent 3:\n         xxxxxxx\n\n      You can and should update the context of the team. Use the `set_team_context` tool to update the shared team\n      context.\n      Your name is: xxxxxx the xxxxxxx.\n\n      <description>\n      xxxxxx the xxxxxxx is responsible for managing the overall process and directing tasks to the appropriate\n      sub-agent.\n      </description>\n\n      <instructions>\n      - Always introduce yourself at the beginning of the chat if user greets.\n\n      </instructions>\n\n      <additional_information>\n      - Use markdown to format your answers.\n      </additional_information>\nDEBUG =============================================== user ===============================================\nDEBUG hi\nDEBUG ============================================ assistant =============================================\nDEBUG Hello! I'm xxxxxx, your xxxxxxx. How can I assist you today?\nDEBUG =============================================== user ===============================================\nDEBUG what things you know about me?\nDEBUG ============================================ assistant =============================================\nDEBUG Tool Calls:\n        - ID: 'call_7ht10hs8Xn6MjOOTSAzHP4I4'\n          Name: 'forward_task_to_member'\n          Arguments: 'agent_name: Help Desk Agent, expected_output: Your details like email ID, first name, and last\n      name.'\nDEBUG =============================================== tool ===============================================\nDEBUG Tool call Id: call_7ht10hs8Xn6MjOOTSAzHP4I4\nDEBUG Your details like email ID, first name, and last name.\nDEBUG =============================================== user ===============================================\nDEBUG hi\nDEBUG ============================================ assistant =============================================\nDEBUG Hello again! I'm xxxxxx, your xxxxxxx. How can I assist you today?\nDEBUG ********************************************  METRICS  *********************************************\nDEBUG * Tokens:                      input=897, output=21, total=918\nDEBUG * Prompt tokens details:       {'audio_tokens': 0, 'cached_tokens': 0}\nDEBUG * Completion tokens details:   {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0,\n      'rejected_prediction_tokens': 0}\nDEBUG * Time:                        1.9927s\nDEBUG * Tokens per second:           10.5383 tokens/s\nDEBUG ********************************************  METRICS  *********************************************\nDEBUG ---------------------------------------- Azure Response End ----------------------------------------\nDEBUG Added 2 Messages to TeamMemory\nDEBUG *********** MemoryClassifier Start ***********\nDEBUG --------------------------------------- Azure Response Start ---------------------------------------\nDEBUG --------------------------------------- Model: not-provided ----------------------------------------\nDEBUG ============================================== system ==============================================\nDEBUG Your task is to identify if the user's message contains information that is worth remembering for future\n      conversations.\n      This includes details that could personalize ongoing interactions with the user, such as:\n        - Personal facts: name, age, occupation, location, interests, preferences, etc.\n        - Significant life events or experiences shared by the user\n        - Important context about the user's current situation, challenges or goals\n        - What the user likes or dislikes, their opinions, beliefs, values, etc.\n        - Any other details that provide valuable insights into the user's personality, perspective or needs\n      Your task is to decide whether the user input contains any of the above information worth remembering.\n      If the user input contains any information worth remembering for future conversations, respond with 'yes'.\n      If the input does not contain any important details worth saving, respond with 'no' to disregard it.\n      You will also be provided with a list of existing memories to help you decide if the input is new or already\n      known.\n      If the memory already exists that matches the input, respond with 'no' to keep it as is.\n      If a memory exists that needs to be updated or deleted, respond with 'yes' to update/delete it.\n      You must only respond with 'yes' or 'no'. Nothing else will be considered as a valid response.\n\n      Existing memories:\n      <existing_memories>\n        - Akhil MS's favorite flavor is chocolate.\n        - Akhil MS likes milkshakes.\n      </existing_memories>\nDEBUG =============================================== user ===============================================\nDEBUG hi\nDEBUG ============================================ assistant =============================================\nDEBUG no\nDEBUG ********************************************  METRICS  *********************************************\nDEBUG * Tokens:                      input=557, output=3, total=560\nDEBUG * Prompt tokens details:       {'audio_tokens': 0, 'cached_tokens': 0}\nDEBUG * Completion tokens details:   {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0,\n      'rejected_prediction_tokens': 0}\nDEBUG * Time:                        1.6886s\nDEBUG * Tokens per second:           1.7766 tokens/s\nDEBUG ********************************************  METRICS  *********************************************\nDEBUG ---------------------------------------- Azure Response End ----------------------------------------\nDEBUG *********** MemoryClassifier End ***********\nDEBUG Update memory: False\nDEBUG Memory update not required\nDEBUG Added TeamRun to TeamMemory\nDEBUG ************************ Team Run End: 0abb7575-b803-4731-9d9d-c9d49f513834 ************************\n\n## Environment\n- OS: (e.g. macOS, Windows 11)\n- Browser (if relevant): (e.g. Chrome 108, Firefox 107)\n- Agno Version: (e.g. v1.2.4)\n- External Dependency Versions: (e.g., yfinance 0.2.52)\n- Additional Environment Details: (e.g., Python 3.12)\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "AkhilmsAchu",
      "author_type": "User",
      "created_at": "2025-03-27T05:59:48Z",
      "updated_at": "2025-04-15T00:33:23Z",
      "closed_at": "2025-04-15T00:33:23Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2570/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2570",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2570",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:28.130332",
      "comments": [
        {
          "author": "AkhilmsAchu",
          "body": "found that this happens when i add memory to Agent/Team\nbelow is my memory declaration\n\n```\nfrom agno.memory.team import TeamMemory\nfrom agno.memory.classifier import MemoryClassifier\nfrom agno.memory.manager import MemoryManager\n\nmemory = TeamMemory(\n        classifier=MemoryClassifier(model=azure_",
          "created_at": "2025-03-27T10:00:18Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Thanks. You have helped us find some fundamental issues that we are addressing asap.",
          "created_at": "2025-03-31T08:50:15Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-15T00:33:22Z"
        }
      ]
    },
    {
      "issue_number": 2605,
      "title": "[Bug] Gemini Embedded Rate Limits",
      "body": "# Description\nBriefly describe the issue you’re experiencing or the bug you’ve found.\n\nThe Gemini Embeddings API rate limit is being exceeded when loading data into the vector database .\n\n## Agent Configuration\nProvide relevant agent configuration.\n```python\n# --- Configuration ---\nload_dotenv()\n\nGEMINI_API_KEY = os.environ[\"GEMINI_API_KEY\"]\nDB_URL = os.environ[\"DB_URL\"]\nTABLE_NAME = os.environ[\"TABLE_NAME\"]\nCSV_FILE_PATH = os.environ[\"CSV_FILE_PATH\"]\n\n# --- Initialize Components ---\nembedder = GeminiEmbedder(task_type=\"CLUSTERING\" , api_key=GEMINI_API_KEY)\nvector_db = PgVector(table_name=TABLE_NAME, db_url=DB_URL, embedder=embedder )\nknowledge_base = CSVKnowledgeBase(path=CSV_FILE_PATH, vector_db=vector_db)\nagent = Agent(knowledge=knowledge_base, search_knowledge=True)\n\n# --- Load Data and Generate Embeddings ---\nknowledge_base.load(recreate=False) # Set recreate=False after the first run\n\n```\n## Expected Behavior\nWhat did you expect to happen?\n\nThe knowledge_base.load() function should successfully process the CSV file, generate embeddings for the content using the Gemini Embeddings API, and store these embeddings in the PostgreSQL database via PgVector, without exceeding the API's rate limits.\n\n## Actual Behavior\nWhat actually happened instead?\n\n![Image](https://github.com/user-attachments/assets/a9bb4b0c-201e-459b-9a5f-6f0e48a9600f)\n\n\n## Possible Solutions\nSuggest any ideas you might have to fix or address the issue.\n\nIntroduce a parameter within the PgVector.insert method (and potentially exposed through CSVKnowledgeBase.load) to control the rate of embedding calls. This could involve adding a delay_seconds parameter that introduces a pause between processing batches or even between individual document embeddings. This would allow users to configure the embedding process to respect the Gemini API rate limits.\n",
      "state": "closed",
      "author": "prathamskk",
      "author_type": "User",
      "created_at": "2025-03-29T15:44:08Z",
      "updated_at": "2025-04-15T00:33:21Z",
      "closed_at": "2025-04-15T00:33:21Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2605/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2605",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2605",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:28.339170",
      "comments": [
        {
          "author": "willemcdejongh",
          "body": "Hi @prathamskk \n\nThank you for reaching out. I can see in the error output you provided, that the quota limit was reached. Are you using free tier of Gemini? Could you possibly provide some more info on the CSV file you are using? How large is the file. If the info is not sensitive, feel free to sha",
          "created_at": "2025-03-31T14:43:29Z"
        },
        {
          "author": "prathamskk",
          "body": "[conversation_data.csv](https://github.com/user-attachments/files/19537180/conversation_data.csv)\nIts 11.7MB \n\nYes i am using the free tier of Gemini API. \n\nThe rate limit is 150 documents per min\n \nas soon as 1 batch of documents is converted to embeddings and inserted. it immediately starts workin",
          "created_at": "2025-03-31T15:10:13Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-15T00:33:19Z"
        }
      ]
    },
    {
      "issue_number": 2616,
      "title": "[Bug]Installation error",
      "body": "# Description\nI ran the following script \"pip install -U groq agno duckduckgo-search\" facing  a build dependency error.\n\n\n## Steps to Reproduce\nI created a virtual environment and then ran the installation command\n\n![Image](https://github.com/user-attachments/assets/36b5f0b2-b33f-4893-be85-656f31f25fec)\n![Image](https://github.com/user-attachments/assets/bc943481-a7d5-4a66-9452-2092bdd15bf5)\n![Image](https://github.com/user-attachments/assets/8a6e1c78-0571-4876-a843-78de7a2ae24c)\n![Image](https://github.com/user-attachments/assets/725d8fdc-97c3-4933-be4d-87037138ca0b)\n![Image](https://github.com/user-attachments/assets/f18156f7-1e7e-4ff7-bf99-b651fd7b9764)\n\n## Agent Configuration (if applicable)\nProvide relevant agent configuration.\n\n## Expected Behavior\nWhat did you expect to happen?\n\n## Actual Behavior\nWhat actually happened instead?\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "AggarwalShourya",
      "author_type": "User",
      "created_at": "2025-03-30T17:34:30Z",
      "updated_at": "2025-04-15T00:33:19Z",
      "closed_at": "2025-04-15T00:33:19Z",
      "labels": [
        "question",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2616/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "willemcdejongh"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2616",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2616",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:28.519282",
      "comments": [
        {
          "author": "willemcdejongh",
          "body": "Hi @AggarwalShourya \n\nThanks for reaching out and using Agno!\nDid you setup your env correctly?\nThere are some instructions in this doc that might help you resolve this\nhttps://docs.agno.com/introduction/agents",
          "created_at": "2025-03-31T14:38:57Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-15T00:33:17Z"
        }
      ]
    },
    {
      "issue_number": 2769,
      "title": "[Bug] LiteLLM model can't properly handle the tool-calling when streaming",
      "body": "# Description\nWhen using stream mode with sync & async mode in LiteLLM model, the tool calling is not properly handled streamed tool calling, caused crash.\n\n## Steps to Reproduce\nExample code\n\n```python\nimport os\nfrom textwrap import dedent\nimport time\n\nfrom agno.agent import Agent\nfrom agno.agent import Agent\nfrom agno.models.litellm import LiteLLM\n\n# Define a tool that increments our counter and returns the new value\ndef increment_counter(agent: Agent, step: int, fast_mode: bool = False) -> str:\n    \"\"\"Increment the session counter and return the new value.\"\"\"\n    if not fast_mode:\n        time.sleep(1)\n    agent.session_state[\"count\"] += step\n    return f\"The count is now {agent.session_state['count']}, step {step}, fast_mode {fast_mode}\"\n\nmodel = LiteLLM(\n    id=\"openrouter/anthropic/claude-3.7-sonnet\",\n    api_key=os.environ.get(\"OPENROUTER_API_KEY\"),\n)\n\n# Create a State Manager Agent that maintains state\nagent = Agent(\n    model=model,\n    # Initialize the session state with a counter starting at 0\n    session_state={\"count\": 0},\n    tools=[increment_counter],\n    # You can use variables from the session state in the instructions\n    instructions=dedent(\"\"\"\\\n        You are the State Manager, an enthusiastic guide to state management! 🔄\n        Your job is to help users understand state management through a simple counter example.\n\n        Follow these guidelines for every interaction:\n        1. Always acknowledge the current state (count) when relevant\n        2. Use the increment_counter tool to modify the state\n        3. Explain state changes in a clear and engaging way\n\n        Structure your responses like this:\n        - Current state status\n        - State transformation actions\n        - Final state and observations\n\n        Starting state (count) is: {count}\\\n    \"\"\"),\n    show_tool_calls=True,\n    markdown=True,\n    debug_mode=True,\n)\n\nagent.print_response(\n    \"Increase the state by 3, using fast_mode=True\",\n    stream=True,\n)\n\nprint(f\"Final session state: {agent.session_state}\")\n\n```\n\nError message\n\n```\nDEBUG *********************************** Agent ID: a723f53a-f74d-4777-8a20-025f793d594c **********************************              \nDEBUG ********************************** Session ID: 887de372-e8ee-4206-9944-83a609a72dac *********************************              \nDEBUG ******************************* Agent Run Start: 6d5ec4ff-eb46-47ef-8ad6-ea4016a42ff8 *******************************              \nDEBUG Processing tools for model                                                                                                         \nDEBUG Added function increment_counter                                                                                                   \nDEBUG ------------------------------------------- LiteLLM Response Stream Start -------------------------------------------              \nDEBUG ------------------------------------------ Model: openrouter/openai/gpt-4o ------------------------------------------              \nDEBUG ======================================================= system ======================================================              \nDEBUG <instructions>                                                                                                                     \n      You are the State Manager, an enthusiastic guide to state management! 🔄                                                           \n      Your job is to help users understand state management through a simple counter example.                                            \n                                                                                                                                         \n      Follow these guidelines for every interaction:                                                                                     \n      1. Always acknowledge the current state (count) when relevant                                                                      \n      2. Use the increment_counter tool to modify the state                                                                              \n      3. Explain state changes in a clear and engaging way                                                                               \n                                                                                                                                         \n      Structure your responses like this:                                                                                                \n      - Current state status                                                                                                             \n      - State transformation actions                                                                                                     \n      - Final state and observations                                                                                                     \n                                                                                                                                         \n      Starting state (count) is: {count}                                                                                                 \n      </instructions>                                                                                                                    \n                                                                                                                                         \n      <additional_information>                                                                                                           \n      - Use markdown to format your answers.                                                                                             \n      </additional_information>                                                                                                          \nDEBUG ======================================================== user =======================================================              \nDEBUG Increase the state by 3                                                                                                            \nDEBUG ===================================================== assistant =====================================================              \nDEBUG ### Current State Status                                                                                                           \n      - The current count is: **0**                                                                                                      \n                                                                                                                                         \n      ### State Transformation Actions                                                                                                   \n      Let's increase the count by **3**.                                                                                                 \n                                                                                                                                         \n      ### Final State and Observations                                                                                                   \n      I'll perform the increment now...                                                                                                  \n▰▰▰▰▰▰▱ Thinking...\n┏━ Message ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                                                                                       ┃\n┃ Increase the state by 3                                                                                                               ┃\n┃                                                                                                                                       ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n┏━ Response (2.9s) ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                                                                                       ┃\n┃                                                         Current State Status                                                          ┃\n┃                                                                                                                                       ┃\n┃  • The current count is: 0                                                                                                            ┃\n┃                                                                                                                                       ┃\n┃                                                     State Transformation Actions                                                      ┃\n┃                                                                                                                                       ┃\n┃ Let's increase the count by 3.                                                                                                        ┃\n┃                                                                                                                                       ┃\n┃                                                     Final State and Observations                                                      ┃\n┃                                                                                                                                       ┃\n┃ I'll perform the increment now...                                                                                                     ┃\n┃                                                                                                                                       ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\nTraceback (most recent call last):\n  File \"/Users/brikerman/codes/yodo1/y-agent/agno/libs/agno/demo.py\", line 60, in <module>\n    agent.print_response(\n  File \"/Users/brikerman/codes/yodo1/y-agent/agno/libs/agno/agno/agent/agent.py\", line 3850, in print_response\n    for resp in self.run(\n  File \"/Users/brikerman/codes/yodo1/y-agent/agno/libs/agno/agno/agent/agent.py\", line 583, in _run\n    for model_response_chunk in self.model.response_stream(messages=run_messages.messages):\n  File \"/Users/brikerman/codes/yodo1/y-agent/agno/libs/agno/agno/models/base.py\", line 533, in response_stream\n    assistant_message.log(metrics=True)\n  File \"/Users/brikerman/codes/yodo1/y-agent/agno/libs/agno/agno/models/message.py\", line 323, in log\n    arguments = \", \".join(f\"{k}: {v}\" for k, v in json.loads(tool_call_arguments).items())\n                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'int' object has no attribute 'items'\n```\n\n## Environment\n- agno 1.2.15\n- Python 3.12\n\n## Possible Solutions (optional)\n\nThis is caused by when calling tool in stream mode, not all the detail about tool calling is return at once. The params splitted into multiple chunk delta.\n\nHere is the details.\n\n```\nDelta(provider_specific_fields=None, reasoning=None, content='#', role='assistant', function_call=None, tool_calls=None, audio=None)\nDelta(provider_specific_fields=None, reasoning=None, content=' Current State Status\\nCurrently, our counter state is at', role=None, function_call=None, \ntool_calls=None, audio=None)\nDelta(provider_specific_fields=None, reasoning=None, content=\" **0**.\\n\\nI'll help you increment\", role=None, function_call=None, tool_calls=None, audio=None)\nDelta(provider_specific_fields=None, reasoning=None, content=' the state by 3 using fast', role=None, function_call=None, tool_calls=None, audio=None)\nDelta(provider_specific_fields=None, reasoning=None, content=' mode as requested!\\n\\n# State Transformation Action', role=None, function_call=None, tool_calls=None,\naudio=None)\nDelta(provider_specific_fields=None, reasoning=None, content='\\nLet me increment the counter by 3 with', role=None, function_call=None, tool_calls=None, audio=None)\nDelta(provider_specific_fields=None, reasoning=None, content=' fast mode enabled:', role=None, function_call=None, tool_calls=None, audio=None)\nDelta(provider_specific_fields=None, reasoning=None, content=None, role='assistant', function_call=None, \ntool_calls=[ChatCompletionDeltaToolCall(id='toolu_vrtx_01KRTCSe6LPw5WqmVTj4GXHi', function=Function(arguments='', name='increment_counter'), type='function', \nindex=0)], audio=None)\nDelta(provider_specific_fields=None, reasoning=None, content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionDeltaToolCall(id=None, \nfunction=Function(arguments='', name=None), type='function', index=0)], audio=None)\nDelta(provider_specific_fields=None, reasoning=None, content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionDeltaToolCall(id=None, \nfunction=Function(arguments='{\"step', name=None), type='function', index=0)], audio=None)\nDelta(provider_specific_fields=None, reasoning=None, content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionDeltaToolCall(id=None, \nfunction=Function(arguments='\": ', name=None), type='function', index=0)], audio=None)\nDelta(provider_specific_fields=None, reasoning=None, content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionDeltaToolCall(id=None, \nfunction=Function(arguments='3', name=None), type='function', index=0)], audio=None)\nDelta(provider_specific_fields=None, reasoning=None, content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionDeltaToolCall(id=None, \nfunction=Function(arguments=', \"fa', name=None), type='function', index=0)], audio=None)\nDelta(provider_specific_fields=None, reasoning=None, content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionDeltaToolCall(id=None, \nfunction=Function(arguments='st_mode\": ', name=None), type='function', index=0)], audio=None)\nDelta(provider_specific_fields=None, reasoning=None, content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionDeltaToolCall(id=None, \nfunction=Function(arguments='true}', name=None), type='function', index=0)], audio=None)\nDelta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None)\n```\n\nI will push the PR with in 30 mins for this.\n",
      "state": "closed",
      "author": "BrikerMan",
      "author_type": "User",
      "created_at": "2025-04-11T03:07:33Z",
      "updated_at": "2025-04-14T08:57:36Z",
      "closed_at": "2025-04-14T08:57:36Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2769/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2769",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2769",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:28.735697",
      "comments": [
        {
          "author": "BrikerMan",
          "body": "Here is another implementation, https://github.com/agno-agi/agno/pull/2765. Will close after this PR merged.",
          "created_at": "2025-04-11T06:24:11Z"
        },
        {
          "author": "kausmeows",
          "body": "#2765 is merged now! @BrikerMan ",
          "created_at": "2025-04-14T08:57:34Z"
        }
      ]
    },
    {
      "issue_number": 2806,
      "title": "[Feature Request] Firecrawl search tool",
      "body": "## Problem Description\nFrom my experience, [Firecrawl](https://www.firecrawl.dev/extract) provides the best service for extracting data from websites for LLM consumption (specifically with their \"extract\" service)\n\n## Proposed Solution\nSimilar to some of the other search tools, but with the underlying provider being Firecrawl/ Firecrawl Extract. They already provide integrations with other frameworks, so it is possible reaching out to them would be another approach here (https://docs.firecrawl.dev/integrations)\n\n## Alternatives Considered\nThere exist multiple alternatives within the official Agno toolset, but I have had better eval input with the information able to be extracted with Firecrawl\n\n## Would you like to work on this?\n\nMainly sharing the idea, but not adverse to implementing it myself. If there is additional buy-in/interest I would place this higher on my list of priorities. ",
      "state": "closed",
      "author": "alec-drw",
      "author_type": "User",
      "created_at": "2025-04-13T17:31:29Z",
      "updated_at": "2025-04-14T06:22:52Z",
      "closed_at": "2025-04-14T06:22:52Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2806/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2806",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2806",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:28.912365",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hey @alec-drw \nWe have a integration with Firecrawl\nPlease refer: https://docs.agno.com/tools/toolkits/firecrawl#firecrawl",
          "created_at": "2025-04-14T06:22:51Z"
        }
      ]
    },
    {
      "issue_number": 2479,
      "title": "[Bug] Inconsistent AgenticChunking results",
      "body": "# Description\nThis is not a bug explicitly but more of an improvement tbh. The current implementation of the agent-based chunking logic relies solely on an LLM to determine a numeric breakpoint at the character level within the first max_chunk_size characters. This approach is not robust, I feel, or unreliable in production use cases because LLMs are inherently stochastic and not ideal for this granular/precise counting task/ numerical arithmetic task, although this being said with more powerful models the scope of error or inconsistency in counting reduces.. Due to this implementation, the chunk boundaries may fall in the middle of words, sentences, or paragraphs, leading to a loss of semantic integrity or completeness of the chunk.\n\n\n## Steps to Reproduce\nhttps://colab.research.google.com/drive/14UcHZqsfm6LkDvYfhbkc6yITgUoWs4Vu?usp=sharing\n\n## Agent Configuration (if applicable)\nProvide relevant agent configuration.\n\n## Expected Behavior\n- sentence-level chunking with each chunk being independently coherent and complete\n\n## Actual Behavior\n- character level chunking with breakpoints encountered in between sentences/words leading to a loss in semantic coherence and completeness of the chunk.\n\n## Screenshots or Logs (if applicable)\n\n![Image](https://github.com/user-attachments/assets/09c46829-34b5-4a7b-bc65-995efa643958)\n\n## Environment\n- OS: (e.g. macOS)\n- Agno Version: (1.1.14)\n\n## Possible Solutions (optional)\nI gave a thought on how the logic can be improved, sharing them here:\n- First is to replace character level break points with sentence level breakpoints ( this will require some tuning in the prompt and string slicing logic IMO)\n- Second is rather than asking the LLM to return breakpoints, we can leverage structured outputs to return a list of coherent chunks in the llm output, however with this approach I see some tradeoffs w.r.t llm inference cost.\n- Third is using something called Propositional chunking ( inspired from [this paper](https://arxiv.org/pdf/2312.06648) ) or can refer to [this](https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb)\n\n## Additional Context\nPlease lemme know your thoughts on this or if I did anything wrong or if there are some gaps in my understanding, would really be grateful!",
      "state": "closed",
      "author": "AbhishekRP2002",
      "author_type": "User",
      "created_at": "2025-03-21T07:29:23Z",
      "updated_at": "2025-04-14T00:35:06Z",
      "closed_at": "2025-04-14T00:35:06Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2479/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2479",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2479",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:29.124784",
      "comments": [
        {
          "author": "AbhishekRP2002",
          "body": "if this feels like a good improvement scope to the existing logic, I would love to contribute to this. \ncc: @ysolanky @ashpreetbedi ",
          "created_at": "2025-03-21T07:30:23Z"
        },
        {
          "author": "ysolanky",
          "body": "Hey @AbhishekRP2002 ! Thanks for suggesting improvements. I do like the first and the third approach. Please feel free to create a PR. Happy to review it asap. Let me know if you have any questions ",
          "created_at": "2025-03-26T05:15:21Z"
        },
        {
          "author": "AbhishekRP2002",
          "body": "sure, will do thank you. here is what i am thinking wrt implementation:\n\nfirst approach:\n\nthere are two ways for first approach again, mentioning in increasing order of complexity:\n\n1st method:\n- modify the prompt so that the LLM returns a sentence-level separator position—essentially the boundary o",
          "created_at": "2025-03-30T08:13:48Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-14T00:35:04Z"
        }
      ]
    },
    {
      "issue_number": 2040,
      "title": "[Feature Request] Implement BitBucket Cloud API as Tools",
      "body": "## Problem Description\nAdding Bitbucket APIs as tools so that Agno can have agentic workflows with Bitbucket Repos, PRs and pipelines.\nAPI Docs: https://developer.atlassian.com/cloud/bitbucket/rest/intro\n\n\n## Would you like to work on this?\n**Yes, I’d love to work on it!**\n",
      "state": "closed",
      "author": "Harsh-2909",
      "author_type": "User",
      "created_at": "2025-02-07T10:33:17Z",
      "updated_at": "2025-04-13T15:41:53Z",
      "closed_at": "2025-02-26T00:30:28Z",
      "labels": [
        "enhancement",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2040/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "Harsh-2909"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2040",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2040",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:29.335684",
      "comments": [
        {
          "author": "Harsh-2909",
          "body": "I will start working on this implementation this weekend. Will first see if there is a python sdk for Bitbucket Cloud APIs or should we just integrate the REST API. Found the official one here: https://atlassian-python-api.readthedocs.io/index.html\nAlso, there are too many APIs, so need to check whi",
          "created_at": "2025-02-07T10:36:33Z"
        },
        {
          "author": "Harsh-2909",
          "body": "Ok so after hours of debugging issues with atlassian python api, the conclusion is that it just doesn't work properly with Bitbucket Cloud v2.0 API. After making everything work, i got struck at the JSON serialization issue. The classes from that package are not JSON Serializable. I don't want to im",
          "created_at": "2025-02-11T14:39:04Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-02-26T00:30:27Z"
        },
        {
          "author": "fenoloco",
          "body": "@anuragts \nHi, we starting a project using agno and this feature will be needed for us, are you planning to include this PR soon, or is better for us to create our own tool to connect bitbucket. ",
          "created_at": "2025-04-11T18:14:01Z"
        },
        {
          "author": "Harsh-2909",
          "body": "Hi @fenoloco \nI will try to add the tests and update the pr within the next few days. I completely forgot about this.\nIn the meantime, you can check the PR for this feature if it is needed urgently. The PR has the proper implementation. Just need to add tests.\n\n",
          "created_at": "2025-04-13T15:41:52Z"
        }
      ]
    },
    {
      "issue_number": 2793,
      "title": "[Bug] Gemini unable to delegate tasks to team members",
      "body": "# Description\nUsing a Team with gemini doesn't work.\n\n## Steps to Reproduce\nCreate a new project and run this code\n\n## Agent Configuration (if applicable)\n```python\nfrom agno.agent import Agent\nfrom agno.models.google import Gemini\nfrom agno.team.team import Team\nfrom dotenv import load_dotenv\nfrom typing import List\nfrom pydantic import BaseModel, Field\n\nload_dotenv()\nclass MovieScript(BaseModel):\n    setting: str = Field(..., description=\"Provide a nice setting for a blockbuster movie.\")\n    ending: str = Field(..., description=\"Ending of the movie. If not available, provide a happy ending.\")\n    genre: str = Field(\n        ..., description=\"Genre of the movie. If not available, select action, thriller or romantic comedy.\"\n    )\n    name: str = Field(..., description=\"Give a name to this movie\")\n    characters: List[str] = Field(..., description=\"Name of characters for this movie.\")\n    storyline: str = Field(..., description=\"3 sentence storyline for the movie. Make it exciting!\")\n\n# Agent that uses JSON mode\njson_mode_agent = Agent(\n    model=Gemini(id=\"gemini-2.0-flash\"),\n    role=\"You write movie scripts.\",\n    response_model=MovieScript,\n    use_json_mode=True,\n)\nagent = Team(\n    name=\"Agent\",\n    mode=\"route\",\n    model=Gemini(id=\"gemini-2.5-pro-exp-03-25\"),\n    members=[json_mode_agent],\n    description=\"Given a topic, ask the json_mode_agent to return a structured movie script\",\n    add_datetime_to_instructions=True,\n    enable_agentic_context=True,  # Allow the agent to maintain a shared context and send that to members.\n    share_member_interactions=True,  # Share all member responses with subsequent member requests.\n    show_members_responses=True,\n    markdown=True,\n    debug_mode=True,\n)\n\nagent.print_response(\"New York\")\n```\n\n## Expected Behavior\nResponse with script in structured format\n\n## Actual Behavior\nTeam attempts to call json_mode_agent but can't.\n\n## Screenshots or Logs (if applicable)\n\n![Image](https://github.com/user-attachments/assets/90bd1a2c-f0b0-468b-8bc1-cdf354f76504)\n\n![Image](https://github.com/user-attachments/assets/6db14886-8f00-4de4-bde7-903b3fb83401)\n\n## Environment\n- OS: Windows 11\n- Agno Version: 1.2.16\n- Additional Environment Details: 3.11\n\n",
      "state": "closed",
      "author": "thismart595",
      "author_type": "User",
      "created_at": "2025-04-12T16:11:43Z",
      "updated_at": "2025-04-13T13:04:53Z",
      "closed_at": "2025-04-13T13:04:52Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2793/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2793",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2793",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:29.660665",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Hi @thismart595 \nYou have to give your agent a name for the delegation to work, because the agent ID is derived from the name. I will make a change to make this easier.",
          "created_at": "2025-04-12T20:58:21Z"
        }
      ]
    },
    {
      "issue_number": 2443,
      "title": "No thinking output with deepseek!",
      "body": "No thinking output with deepseek!\n\n![Image](https://github.com/user-attachments/assets/e6e5d4e8-bfc1-4a08-ba09-a7603d1f8b47)\n\n![Image](https://github.com/user-attachments/assets/a841fd9f-8e9d-4a2c-bfc6-ca280dc56eda)",
      "state": "closed",
      "author": "shenshouer",
      "author_type": "User",
      "created_at": "2025-03-18T06:10:32Z",
      "updated_at": "2025-04-13T00:58:30Z",
      "closed_at": "2025-04-13T00:58:30Z",
      "labels": [
        "stale"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2443/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2443",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2443",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:29.913788",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Hi @shenshouer \nI don't think the default deepseek model (i.e. `deepseek-chat`) does reasoning by default. I believe you need to set `DeepSeek(id=\"deepseek-reasoner\")`",
          "created_at": "2025-03-19T09:46:26Z"
        },
        {
          "author": "shenshouer",
          "body": "@dirkbrnd Thank you very much for your point out, I indeed forgot to specify the specific model ID. But I set the model ID to `deepseek-reasoner` according to your hint, and there is still no content output of thinking process in the console.\n\n![Image](https://github.com/user-attachments/assets/4c20",
          "created_at": "2025-03-19T10:18:13Z"
        },
        {
          "author": "IATkachenko",
          "body": "@dirkbrnd, hello!\n\nHave same issue with `deepseek-r1-distill-qwen-14b`: model (via `LMStudio`, that goes from `OpenAILike`, same as `DeepSeek`) is sending `reasoning_content` in `delta` part of response (just checked with wireshark/tcpdump), but it does not shown in console.\n\nMy configuration is\n```",
          "created_at": "2025-03-30T00:48:24Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-13T00:58:29Z"
        }
      ]
    },
    {
      "issue_number": 2595,
      "title": "[Bug] Agent Teams - Orchestration Issue",
      "body": "# Description\nUsing content cookbook with different models:\nHere is the agent script:\n```\nimport dotenv\nfrom openai import OpenAI\ndotenv.load_dotenv()\n\nfrom agno.agent.agent import Agent\nfrom agno.models.openai.chat import OpenAIChat\nfrom agno.models.google.gemini import Gemini\nfrom agno.models.openrouter.openrouter import OpenRouter\nfrom agno.team.team import Team\nfrom agno.tools.duckduckgo import DuckDuckGoTools\n\n# Create individual specialized agents\nresearcher = Agent(\n    name=\"Researcher\",\n    role=\"Expert at finding information\",\n    tools=[DuckDuckGoTools()],\n    model=OpenRouter(id=\"mistralai/mistral-small-3.1-24b-instruct:free\"),\n    show_tool_calls=True\n)\n\nwriter = Agent(\n    name=\"Writer\",\n    role=\"Expert at writing clear, engaging content\",\n    model=OpenRouter(id=\"mistralai/mistral-small-3.1-24b-instruct:free\"),\n)\n\n# Create a team with these agents\ncontent_team = Team(\n    name=\"Content Team\",\n    mode=\"coordinate\",\n    members=[researcher, writer],\n    instructions=\"You are a team of researchers and writers that work together to create high-quality content.\",\n    model=OpenRouter(id=\"google/gemini-2.5-pro-exp-03-25:free\"),\n    debug_mode=True\n)\n\n# Run the team with a task\ncontent_team.print_response(\"Create a short article about quantum computing\")\n```\n\n## Steps to Reproduce\nList the steps needed to encounter this bug or issue.\n\n## Agent Configuration (if applicable)\nProvide relevant agent configuration.\n\n## Expected Behavior\nTo have the script create the article.\n\n## Actual Behavior\nOn running script it fails with weird behaviour, If you see below, the Researcher agent fails to make successful tool call, but it does not retry and the team agent simply says it has scheduled things and comes out of agent loop.\n\n```\n❯ python agents/content-agent.py\nDEBUG ************************************************************* Team ID: 0774ece8-81ca-456d-8d96-894d1901f064 **************************************************************              \nDEBUG ************************************************************ Session ID: c506cd9c-21f5-4975-8f68-2a390a8e9913 ************************************************************              \nDEBUG ********************************************************** Team Run Start: ffa52a6a-1a69-4e38-b199-2eda049eea95 **********************************************************              \nDEBUG *************************************************************************** Mode: 'coordinate' ***************************************************************************              \nDEBUG Processing tools for model                                                                                                                                                              \nDEBUG Included function transfer_task_to_member                                                                                                                                               \nDEBUG ----------------------------------------------------------------------- OpenRouter Response Start ------------------------------------------------------------------------              \nDEBUG -------------------------------------------------------------- Model: google/gemini-2.5-pro-exp-03-25:free ---------------------------------------------------------------              \nDEBUG ================================================================================= system =================================================================================              \nDEBUG You are the leader of a team of AI Agents and possible Sub-Teams:                                                                                                                       \n       - Agent 1:                                                                                                                                                                             \n         - Name: Researcher                                                                                                                                                                   \n         - Role: Expert at finding information                                                                                                                                                \n         - Available tools:                                                                                                                                                                   \n          - duckduckgo_search: Use this function to search DuckDuckGo for a query.                                                                                                            \n          - duckduckgo_news: Use this function to get the latest news from DuckDuckGo.                                                                                                        \n       - Agent 2:                                                                                                                                                                             \n         - Name: Writer                                                                                                                                                                       \n         - Role: Expert at writing clear, engaging content                                                                                                                                    \n                                                                                                                                                                                              \n      - You can either respond directly or transfer tasks to other Agents in your team depending on the tools available to them and their roles.                                              \n      - If you transfer a task to another Agent, make sure to include:                                                                                                                        \n        - agent_name (str): The name of the Agent to transfer the task to.                                                                                                                    \n        - task_description (str): A clear description of the task.                                                                                                                            \n        - expected_output (str): The expected output.                                                                                                                                         \n      - You can pass tasks to multiple members at once.                                                                                                                                       \n      - You must always validate the output of the other Agents before responding to the user.                                                                                                \n      - Evaluate the response from other agents. If you feel the task has been completed, you can stop and respond to the user.                                                               \n      - You can re-assign the task if you are not satisfied with the result.                                                                                                                  \n                                                                                                                                                                                              \n      Your name is: Content Team.                                                                                                                                                             \n                                                                                                                                                                                              \n      <instructions>                                                                                                                                                                          \n      You are a team of researchers and writers that work together to create high-quality content.                                                                                            \n      </instructions>                                                                                                                                                                         \nDEBUG ================================================================================== user ==================================================================================              \nDEBUG Create a short article about quantum computing                                                                                                                                          \nDEBUG =============================================================================== assistant ================================================================================              \nDEBUG Okay, I can help with that. First, I need the Researcher to gather some key information.                                                                                                \n                                                                                                                                                                                              \n                                                                                                                                                                                              \nDEBUG Tool Calls:                                                                                                                                                                             \n        - ID: 'tool_0_transfer_task_to_member'                                                                                                                                                \n          Name: 'transfer_task_to_member'                                                                                                                                                     \n          Arguments: 'expected_output: A concise summary of key facts about quantum computing: definition, simple explanation of qubits/superposition/entanglement, potential applications    \n      (2-3 examples), and current challenges (1-2 examples)., task_description: Research the basics of quantum computing. Find a simple definition, explain key concepts like qubits,         \n      superposition, and entanglement in layman's terms, list 2-3 potential applications, and mention 1-2 current challenges., agent_name: Researcher'                                        \nDEBUG *******************************************************************************  METRICS  ********************************************************************************              \nDEBUG * Tokens:                      input=461, output=137, total=598                                                                                                                         \nDEBUG * Time:                        7.6959s                                                                                                                                                  \nDEBUG * Tokens per second:           17.8018 tokens/s                                                                                                                                         \nDEBUG *******************************************************************************  METRICS  ********************************************************************************              \nDEBUG Getting function transfer_task_to_member                                                                                                                                                \nDEBUG Running: transfer_task_to_member(expected_output=..., task_description=..., agent_name=Researcher)                                                                                      \nDEBUG ************************************************************* Agent ID: 3208eaf1-8657-4cf8-bace-08479ece1719 *************************************************************              \nDEBUG ************************************************************ Session ID: cb121f05-a636-4f76-a077-1d5042a289b0 ************************************************************              \nDEBUG ********************************************************* Agent Run Start: 693a387e-effa-4086-9c14-2034fd5ab94f **********************************************************              \nDEBUG Processing tools for model                                                                                                                                                              \nDEBUG Included function duckduckgo_search from duckduckgo                                                                                                                                     \nDEBUG Included function duckduckgo_news from duckduckgo                                                                                                                                       \nDEBUG ----------------------------------------------------------------------- OpenRouter Response Start ------------------------------------------------------------------------              \nDEBUG ---------------------------------------------------------- Model: mistralai/mistral-small-3.1-24b-instruct:free ----------------------------------------------------------              \nDEBUG ================================================================================= system =================================================================================              \nDEBUG <your_role>                                                                                                                                                                             \n      Expert at finding information                                                                                                                                                           \n      </your_role>                                                                                                                                                                            \nDEBUG ================================================================================== user ==================================================================================              \nDEBUG You are a member of a team of agents. Your goal is to complete the following task:                                                                                                      \n                                                                                                                                                                                              \n      Research the basics of quantum computing. Find a simple definition, explain key concepts like qubits, superposition, and entanglement in layman's terms, list 2-3 potential             \n      applications, and mention 1-2 current challenges.                                                                                                                                       \n                                                                                                                                                                                              \n      <expected_output>                                                                                                                                                                       \n      A concise summary of key facts about quantum computing: definition, simple explanation of qubits/superposition/entanglement, potential applications (2-3 examples), and current         \n      challenges (1-2 examples).                                                                                                                                                              \n      </expected_output>                                                                                                                                                                      \nDEBUG =============================================================================== assistant ================================================================================              \nDEBUG Tool Calls:                                                                                                                                                                             \n        - ID: '1S9oGT5GT'                                                                                                                                                                     \n          Name: 'duckduckgo_search'                                                                                                                                                           \n          Arguments: 'Invalid JSON format'                                                                                                                                                    \nDEBUG *******************************************************************************  METRICS  ********************************************************************************              \nDEBUG * Tokens:                      input=357, output=34, total=391                                                                                                                          \nDEBUG * Time:                        1.6178s                                                                                                                                                  \nDEBUG * Tokens per second:           21.0163 tokens/s                                                                                                                                         \nDEBUG *******************************************************************************  METRICS  ********************************************************************************              \nDEBUG Getting function duckduckgo_search                                                                                                                                                      \nERROR    Unable to decode function arguments:                                                                                                                                                 \n         {\"query\": \"quantum computing basics, \"max_results\": 1{\"query\": \"quantum computing basics\", \"max_results\": 1}                                                                         \n         Error: Expecting ',' delimiter: line 1 column 39 (char 38)                                                                                                                           \nDEBUG =============================================================================== assistant ================================================================================              \nDEBUG *******************************************************************************  METRICS  ********************************************************************************              \nDEBUG * Tokens:                      input=365, total=365                                                                                                                                     \nDEBUG * Time:                        1.3202s                                                                                                                                                  \nDEBUG *******************************************************************************  METRICS  ********************************************************************************              \nDEBUG ------------------------------------------------------------------------ OpenRouter Response End -------------------------------------------------------------------------              \nDEBUG Added 4 Messages to AgentMemory                                                                                                                                                         \nDEBUG Added AgentRun to AgentMemory                                                                                                                                                           \nDEBUG Logging Agent Run                                                                                                                                                                       \nDEBUG ********************************************************** Agent Run End: 693a387e-effa-4086-9c14-2034fd5ab94f ***********************************************************              \nDEBUG Updated team context with member name: Researcher                                                                                                                                       \nDEBUG ================================================================================== tool ==================================================================================              \nDEBUG Tool call Id: tool_0_transfer_task_to_member                                                                                                                                            \nDEBUG *****************************************************************************  TOOL METRICS  *****************************************************************************              \nDEBUG * Time:                        0.0015s                                                                                                                                                  \nDEBUG *****************************************************************************  TOOL METRICS  *****************************************************************************              \nDEBUG =============================================================================== assistant ================================================================================              \nDEBUG Okay, I've assigned the research task to the Researcher. I'll let you know once I have the information and the Writer has drafted the article.                                          \nDEBUG *******************************************************************************  METRICS  ********************************************************************************              \nDEBUG * Tokens:                      input=621, output=32, total=653                                                                                                                          \nDEBUG * Time:                        3.3268s                                                                                                                                                  \nDEBUG * Tokens per second:           9.6189 tokens/s                                                                                                                                          \nDEBUG *******************************************************************************  METRICS  ********************************************************************************              \nDEBUG ------------------------------------------------------------------------ OpenRouter Response End -------------------------------------------------------------------------              \nDEBUG Added 4 Messages to TeamMemory                                                                                                                                                          \nDEBUG Added TeamRun to TeamMemory                                                                                                                                                             \nDEBUG --**-- Logging Team Run                                                                                                                                                                 \nDEBUG *********************************************************** Team Run End: ffa52a6a-1a69-4e38-b199-2eda049eea95 ***********************************************************              \n┏━ Message ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                                                                                                                                            ┃\n┃ Create a short article about quantum computing                                                                                                                                             ┃\n┃                                                                                                                                                                                            ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n┏━ Team Tool Calls ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                                                                                                                                            ┃\n┃ • transfer_task_to_member(expected_output=A concise summary of key facts about quantum computing: definition,                                                                              ┃\n┃   simple explanation of qubits/superposition/entanglement, potential applications (2-3 examples), and current                                                                              ┃\n┃   challenges (1-2 examples)., task_description=Research the basics of quantum computing. Find a simple                                                                                     ┃\n┃   definition, explain key concepts like qubits, superposition, and entanglement in layman's terms, list 2-3                                                                                ┃\n┃   potential applications, and mention 1-2 current challenges., agent_name=Researcher)                                                                                                      ┃\n┃                                                                                                                                                                                            ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n┏━ Response (14.6s) ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                                                                                                                                            ┃\n┃ Okay, I can help with that. First, I need the Researcher to gather some key information.                                                                                                   ┃\n┃                                                                                                                                                                                            ┃\n┃ Okay, I've assigned the research task to the Researcher. I'll let you know once I have the information and the Writer has drafted the article.                                             ┃\n┃                                                                                                                                                                                            ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n\n````\n\nHere is another run in which  writer agent writes the article team agent is not showing the same to user but somehow looks like it is summarizing it and then showing. I was very explicitly in team agent instructions to show the written article to user.\n\nhttps://paste.ofcode.org/wpjkBLFawRtuWZwGenTy6K\n\nTo me team agent is a big black box (abstraction) which I can not control to behave properly. I think it needs a lot of testing with different models and prompts.\n\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- OS: (e.g. macOS, Windows 11)\n- Browser (if relevant): (e.g. Chrome 108, Firefox 107)\n- Agno Version: (e.g. v1.0.0)\n- External Dependency Versions: (e.g., yfinance 0.2.52)\n- Additional Environment Details: (e.g., Python 3.10)\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "gauravdhiman",
      "author_type": "User",
      "created_at": "2025-03-28T22:29:37Z",
      "updated_at": "2025-04-12T06:30:46Z",
      "closed_at": "2025-04-08T14:59:08Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2595/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "dirkbrnd"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2595",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2595",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:35.106465",
      "comments": [
        {
          "author": "shamy1997",
          "body": "I face the same thing. Hope to it will be fixed soon.",
          "created_at": "2025-04-05T13:53:54Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@gauravdhiman @shamy1997 I'm digging into this!",
          "created_at": "2025-04-08T11:46:03Z"
        },
        {
          "author": "dirkbrnd",
          "body": "I have a PR out that would hopefully address it.\n\nIt only happens with some weaker models that don't provide a \"final response\", so we can then make sure that we rather use the tool calls as the response.",
          "created_at": "2025-04-08T12:06:33Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Please let me know if the latest release is working for you.",
          "created_at": "2025-04-08T16:08:10Z"
        },
        {
          "author": "dirkbrnd",
          "body": "I pushed another release that should also make improvements to how the teams respond. ",
          "created_at": "2025-04-12T06:30:45Z"
        }
      ]
    },
    {
      "issue_number": 2553,
      "title": "[while using openai like llms,  invalid value: `json_schema`, supported values are: `json_object` and `text`]",
      "body": "{'error': {'code': 'InvalidParameter', 'message': 'The parameter `response_format.type` specified \n         in the request are not valid: invalid value: `json_schema`, supported values are: `json_object` and `text`. Request id:                               \n         021742961050484e54042c903da3a08a41d73404311af537b7310', 'param': 'response_format.type', 'type': 'BadRequest'}} ",
      "state": "closed",
      "author": "happynoom",
      "author_type": "User",
      "created_at": "2025-03-26T03:53:43Z",
      "updated_at": "2025-04-12T00:31:44Z",
      "closed_at": "2025-04-12T00:31:44Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2553/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2553",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2553",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:35.337827",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @happynoom ! Can you please share your Agent config and/or which cookbook example you are facing this issue in? ",
          "created_at": "2025-03-26T04:00:11Z"
        },
        {
          "author": "happynoom",
          "body": "I use non openai official llm models. I config my llm like this\n```\n  llm_model = OpenAILike(id=self.name,\n                          name=self.name,\n                          api_key=self.api_key,\n                          base_url=self.base_url)\n\nAgent(\n            name=\"name\",\n            descript",
          "created_at": "2025-03-28T04:06:52Z"
        },
        {
          "author": "happynoom",
          "body": "I think it is because \"json_schema\" is not supported in non openai official apis. Would you adapt this parameter? Thanks very much. ",
          "created_at": "2025-03-28T04:08:44Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-12T00:31:43Z"
        }
      ]
    },
    {
      "issue_number": 2579,
      "title": "[Bug]agno.exceptions.ModelProviderError: Missing required parameter: 'messages[3].content[0].type'",
      "body": "def excel_reader_tool(file_path: str) -> pd.DataFrame:\n\"\"\"\nRead an Excel file from the given file path and return the data in JSON format.\n\"\"\"\ndf = pd.read_excel(file_path, sheet_name=0)\n\nreturn df\n\n#######################################################################################\n\nWhy must the return data type of a custom tool be a string? I want to return a DataFrame type, how can I do this?",
      "state": "closed",
      "author": "Rainismer",
      "author_type": "User",
      "created_at": "2025-03-27T13:15:35Z",
      "updated_at": "2025-04-12T00:31:42Z",
      "closed_at": "2025-04-12T00:31:42Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2579/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2579",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2579",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:35.690096",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @Rainismer ! The result of the function call is sent to the model provider API. And currently the only acceptable return type for a function is string. [More info here](https://platform.openai.com/docs/guides/function-calling#formatting-results). This is consistent across other providers. Plea",
          "created_at": "2025-03-27T18:06:05Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-12T00:31:41Z"
        }
      ]
    },
    {
      "issue_number": 2753,
      "title": "[Bug]agentic_rag example app encounters sqlalchemy.exc.IntegrityError when adding a file to the knowledge base, causing a red error screen.",
      "body": "# Description\nagentic_rag example app encounters sqlalchemy.exc.IntegrityError when adding a file to the knowledge base, causing a red error screen.\n\n## Steps to Reproduce\ngit clone the agno repo, then run the agentic_reg example app following the the docs as  https://docs.agno.com/examples/apps/agentic-rag\n\nthen in browser http://localhost:8501/ adding a txt file or a url, it shows error.\n\n\n## Screenshots or Logs (if applicable)\n`sqlalchemy.exc.IntegrityError: (psycopg.errors.NotNullViolation) null value in column \"id\" of relation \"agentic_rag_documents\" violates not-null constraint DETAIL: Failing row contains (null, null, {}, {}, null, null, null, 2025-04-10 03:19:11.529953+00, null, null). [SQL: INSERT INTO ai.agentic_rag_documents DEFAULT VALUES ON CONFLICT (id) DO UPDATE SET name = excluded.name, meta_data = excluded.meta_data, filters = excluded.filters, content = excluded.content, embedding = excluded.embedding, usage = excluded.usage, content_hash = excluded.content_hash] (Background on this error at: https://sqlalche.me/e/20/gkpj)\nTraceback:\n\nFile \"/Users/Libin/Projects/agno/cookbook/examples/apps/agentic_rag/app.py\", line 317, in <module>\n    main()\nFile \"/Users/Libin/Projects/agno/cookbook/examples/apps/agentic_rag/app.py\", line 213, in main\n    agentic_rag_agent.knowledge.load_documents(docs, upsert=True)\nFile \"/Users/Libin/Projects/agno/.venv/lib/python3.12/site-packages/agno/knowledge/agent.py\", line 213, in load_documents\n    self.vector_db.upsert(documents=documents, filters=filters)\nFile \"/Users/Libin/Projects/agno/.venv/lib/python3.12/site-packages/agno/vectordb/pgvector/pgvector.py\", line 397, in upsert\n    sess.execute(upsert_stmt)\nFile \"/Users/Libin/Projects/agno/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py\", line 2365, in execute\n    return self._execute_internal(\n           ^^^^^^^^^^^^^^^^^^^^^^^\nFile \"/Users/Libin/Projects/agno/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py\", line 2260, in _execute_internal\n    result = conn.execute(\n             ^^^^^^^^^^^^^\nFile \"/Users/Libin/Projects/agno/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py\", line 1416, in execute\n    return meth(\n           ^^^^^\nFile \"/Users/Libin/Projects/agno/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py\", line 523, in _execute_on_connection\n    return connection._execute_clauseelement(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile \"/Users/Libin/Projects/agno/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py\", line 1638, in _execute_clauseelement\n    ret = self._execute_context(\n          ^^^^^^^^^^^^^^^^^^^^^^\nFile \"/Users/Libin/Projects/agno/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py\", line 1843, in _execute_context\n    return self._exec_single_context(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile \"/Users/Libin/Projects/agno/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py\", line 1983, in _exec_single_context\n    self._handle_dbapi_exception(\nFile \"/Users/Libin/Projects/agno/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py\", line 2352, in _handle_dbapi_exception\n    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e\nFile \"/Users/Libin/Projects/agno/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py\", line 1964, in _exec_single_context\n    self.dialect.do_execute(\nFile \"/Users/Libin/Projects/agno/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py\", line 945, in do_execute\n    cursor.execute(statement, parameters)\nFile \"/Users/Libin/Projects/agno/.venv/lib/python3.12/site-packages/psycopg/cursor.py\", line 97, in execute\n    raise ex.with_traceback(None)`\n\n## Environment\n- OS: macOS\n- Browser:  Firefox\n- Agno Version:  v1.2.13\n- External Dependency Versions: psycopg-binary:3.2.6\n- Additional Environment Details: Python 3.12.2\n\n## Additional Context\ni installed the psycopg-binary package instead of psycopg to resolve a \"ImportError: no pq wrapper available.\" error.\n",
      "state": "closed",
      "author": "pinkli",
      "author_type": "User",
      "created_at": "2025-04-10T04:08:05Z",
      "updated_at": "2025-04-11T04:29:36Z",
      "closed_at": "2025-04-11T04:29:35Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2753/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kausmeows"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2753",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2753",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:36.111467",
      "comments": [
        {
          "author": "kausmeows",
          "body": "Hey @pinkli thanks for reaching out, wasn't able to replicate this, are you using this code and instructions here- https://github.com/agno-agi/agno/tree/main/cookbook/examples/apps/agentic_rag\n\nif not can you first try with that. If yes, can you try with a different vector db (let's say `Qdrant`) an",
          "created_at": "2025-04-10T16:26:13Z"
        },
        {
          "author": "pinkli",
          "body": "I tried the Qdrant vectordb and it works OK, and figured out that the pgvector issue is related to my local proxy settings.\nWhen I turn off the proxy, it works as expected.\nSo I'll close the issue. Thank you for the help.",
          "created_at": "2025-04-11T04:29:35Z"
        }
      ]
    },
    {
      "issue_number": 2504,
      "title": "[Bug] Google Embedder for Agentic RAG",
      "body": "```\nERROR    Error searching for documents: Unexpected Response: 400 (Bad Request)                                                                                                                            \n         Raw response content:                                                                                                                                                                            \n         b'{\"status\":{\"error\":\"Wrong input: Vector dimension error: expected dim: 1536, got 768\"},\"time\":0.000600541}'   \n```\n\nFixed it #2503 ",
      "state": "closed",
      "author": "lucifertrj",
      "author_type": "User",
      "created_at": "2025-03-23T10:48:25Z",
      "updated_at": "2025-04-11T00:32:40Z",
      "closed_at": "2025-04-11T00:32:40Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2504/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2504",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2504",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:36.274016",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Thank you for your contribution @lucifertrj \nWe will review the PR soon.\n",
          "created_at": "2025-03-24T04:46:37Z"
        },
        {
          "author": "Ayush0054",
          "body": "hey @lucifertrj  i couldnt replicate the issue \nand 768 is default param , we can set it to 1536 while initializing agent :   \n```\n  vector_db=PgVector(\n        db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\",\n        table_name=\"gemini_embeddings\",\n        embedder=GeminiEmbedder(dimensions=1",
          "created_at": "2025-03-25T11:52:13Z"
        },
        {
          "author": "ysolanky",
          "body": "@lucifertrj you might need to drop your table or set a new name for the table to make sure the dimensions are updated ",
          "created_at": "2025-03-26T04:19:49Z"
        },
        {
          "author": "lucifertrj",
          "body": "> [@lucifertrj](https://github.com/lucifertrj) you might need to drop your table or set a new name for the table to make sure the dimensions are updated\n\nI get the error when I use Qdrant+ Gemini Embedder, can you try it with Qdrant as the vectordb? ",
          "created_at": "2025-03-27T18:13:37Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-11T00:32:39Z"
        }
      ]
    },
    {
      "issue_number": 2557,
      "title": "[Bug] Error retrieving sessions: SqliteStorage.get_all_sessions() got an unexpected keyword argument 'workflow_id'",
      "body": "# Description\nError retrieving sessions: SqliteStorage.get_all_sessions() got an unexpected keyword argument 'workflow_id'\n\n## Steps to Reproduce\nIm trying to hit async workflow get_sessions api\ni.e http://localhost:5670/v1/playground/workflows/{workflow-name}/sessions?user_id={user-id}\ngetting this error  SqliteStorage.get_all_sessions() got an unexpected keyword argument 'workflow_id'\n\n\n\n## Environment\n- OS: (e.g.Ubuntu 20.04)\n- Browser (if relevant): Chrome\n- Agno Version: v1.2.3\n\n## Possible Solutions\n\nThis code needs to be updated to latest function update of get_all_sessions by removing workflow_id and add entity_id. im using async workflow as in async_router.py file\n```   \n        try:\n            all_workflow_sessions: List[WorkflowSession] = workflow.storage.get_all_sessions(\n                user_id=user_id, workflow_id=workflow_id\n            )  # type: ignore\n        except Exception as e:\n            raise HTTPException(status_code=500, detail=f\"Error retrieving sessions: {str(e)}\")\n```",
      "state": "closed",
      "author": "AjayVarmaK",
      "author_type": "User",
      "created_at": "2025-03-26T11:09:09Z",
      "updated_at": "2025-04-11T00:32:38Z",
      "closed_at": "2025-04-11T00:32:38Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2557/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2557",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2557",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:36.505986",
      "comments": [
        {
          "author": "willemcdejongh",
          "body": "Hi @AjayVarmaK \n\nThanks for raising this bug. We will include a fix in the next release.",
          "created_at": "2025-03-27T07:03:53Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-11T00:32:37Z"
        }
      ]
    },
    {
      "issue_number": 2755,
      "title": "[Bug] AttributeError: 'expected_output' attribute has no 'strip' method in get_system_message()",
      "body": "\n# Description  \nWhen calling `structured_output_agent.print_response(\"Dubai 2050\", stream=True)`, an `AttributeError` is raised because `self.expected_output` does not support the `.strip()` method in the `get_system_message()` function. This suggests that `expected_output` is either `None` or an unexpected type.\n\n---\n\nmy code ->\n```python\nimport os\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\ngroq_api_key = os.environ.get('GROQ_API_KEY')\n# Set the environment variables\nos.environ['GROQ_API_KEY'] = groq_api_key\n\nfrom textwrap import dedent\nfrom agno.agent import Agent, RunResponse\nfrom agno.models.groq import Groq\nfrom typing import List\nfrom pydantic import BaseModel, Field\n\nclass MovieScript(BaseModel):\n    setting: str = Field(\n        ...,\n        description=\"A richly detailed, atmospheric description of the movie's primary location and time period. Include sensory details and mood.\",\n    )\n    ending: str = Field(\n        ...,\n        description=\"The movie's powerful conclusion that ties together all plot threads. Should deliver emotional impact and satisfaction.\",\n    )\n    genre: str = Field(\n        ...,\n        description=\"The film's primary and secondary genres (e.g., 'Sci-fi Thriller', 'Romantic Comedy'). Should align with setting and tone.\",\n    )\n    name: str = Field(\n        ...,\n        description=\"An attention-grabbing, memorable title that captures the essence of the story and appeals to target audience.\",\n    )\n    characters: List[str] = Field(\n        ...,\n        description=\"4-6 main characters with distinctive names and brief role descriptions (e.g., 'Sarah Chen - brilliant quantum physicist with a dark secret').\",\n    )\n    storyline: str = Field(\n        ...,\n        description=\"A compelling three-sentence plot summary: Setup, Conflict, and Stakes. Hook readers with intrigue and emotion.\",\n    )\n    \n# Agent Json Mode\njson_mode_agent = Agent(\n    model=Groq(\n        id='meta-llama/llama-4-scout-17b-16e-instruct',\n    ),\n    description=dedent(\"\"\"\\\n        You are an acclaimed Hollywood screenwriter known for creating unforgettable blockbusters! 🎬\n        With the combined storytelling prowess of Christopher Nolan, Aaron Sorkin, and Quentin Tarantino,\n        you craft unique stories that captivate audiences worldwide.\n\n        Your specialty is turning locations into living, breathing characters that drive the narrative.\\\n    \"\"\"),\n    instructions=dedent(\"\"\"\\\n        When crafting movie concepts, follow these principles:\n\n        1. Settings should be characters:\n           - Make locations come alive with sensory details\n           - Include atmospheric elements that affect the story\n           - Consider the time period's impact on the narrative\n\n        2. Character Development:\n           - Give each character a unique voice and clear motivation\n           - Create compelling relationships and conflicts\n           - Ensure diverse representation and authentic backgrounds\n\n        3. Story Structure:\n           - Begin with a hook that grabs attention\n           - Build tension through escalating conflicts\n           - Deliver surprising yet inevitable endings\n\n        4. Genre Mastery:\n           - Embrace genre conventions while adding fresh twists\n           - Mix genres thoughtfully for unique combinations\n           - Maintain consistent tone throughout\n\n        Transform every location into an unforgettable cinematic experience!\\\n    \"\"\"),\n    response_model=MovieScript,\n)\n\n# Structured Output Agent\n\nstructured_output_agent = Agent(\n    model=Groq(\n        id='meta-llama/llama-4-scout-17b-16e-instruct',\n    ),\n    description=dedent(\"\"\"\\\n        You are an acclaimed Hollywood screenwriter known for creating unforgettable blockbusters! 🎬\n        With the combined storytelling prowess of Christopher Nolan, Aaron Sorkin, and Quentin Tarantino,\n        you craft unique stories that captivate audiences worldwide.\n\n        Your specialty is turning locations into living, breathing characters that drive the narrative.\\\n    \"\"\"),\n    instructions=dedent(\"\"\"\\\n        When crafting movie concepts, follow these principles:\n\n        1. Settings should be characters:\n           - Make locations come alive with sensory details\n           - Include atmospheric elements that affect the story\n           - Consider the time period's impact on the narrative\n\n        2. Character Development:\n           - Give each character a unique voice and clear motivation\n           - Create compelling relationships and conflicts\n           - Ensure diverse representation and authentic backgrounds\n\n        3. Story Structure:\n           - Begin with a hook that grabs attention\n           - Build tension through escalating conflicts\n           - Deliver surprising yet inevitable endings\n\n        4. Genre Mastery:\n           - Embrace genre conventions while adding fresh twists\n           - Mix genres thoughtfully for unique combinations\n           - Maintain consistent tone throughout\n\n        Transform every location into an unforgettable cinematic experience!\\\n    \"\"\"),\n    expected_output=MovieScript,\n)\n\n# json_mode_agent.print_response(\"Dubai 2050\", stream=True)\nstructured_output_agent.print_response(\"Dubai 2050\", stream=True)\n```\n\n![Image](https://github.com/user-attachments/assets/29268750-1b3a-449a-b46b-3c384f85cfe4)\n\n## Steps to Reproduce  \n1. Run the script located at `structured_output.py`.  \n2. Call `structured_output_agent.print_response(\"Dubai 2050\", stream=True)` inside the script.  \n3. Observe the traceback output showing an `AttributeError`.\n\n---\n\n## Agent Configuration (if applicable)  \n```python\nstructured_output_agent = StructuredOutputAgent(\n    # Configuration params (if known)\n)\n```\n\n---\n\n## Expected Behavior  \nThe system should format and include the `expected_output` content in the system message if present, or skip gracefully if not.\n\n---\n\n## Actual Behavior  \nAn `AttributeError` is thrown:\n```\nAttributeError: strip\n\nFile \"agent.py\", line 2268, in get_system_message\nsystem_message_content += f\"<expected_output>\\n{self.expected_output.strip()}\\n</expected_output>\\n\\n\"\n```\n\n---\n\n## Screenshots or Logs (if applicable)  \n```python\nTraceback (most recent call last):\n  File \"/media/nafiz/NewVolume/ai-agent-x/Agno Agents/structured_output.py\", line 124, in <module>\n    structured_output_agent.print_response(\"Dubai 2050\", stream=True)\n  File \"/home/nafiz/miniconda3/lib/python3.12/site-packages/agno/agent/agent.py\", line 3850, in print_response\n    for resp in self.run(\n  File \"/home/nafiz/miniconda3/lib/python3.12/site-packages/agno/agent/agent.py\", line 552, in _run\n    run_messages: RunMessages = self.get_run_messages(\n  File \"/home/nafiz/miniconda3/lib/python3.12/site-packages/agno/agent/agent.py\", line 2487, in get_run_messages\n    system_message = self.get_system_message()\n  File \"/home/nafiz/miniconda3/lib/python3.12/site-packages/agno/agent/agent.py\", line 2268, in get_system_message\n    system_message_content += f\"<expected_output>\\n{self.expected_output.strip()}\\n</expected_output>\\n\\n\"\nAttributeError: strip\n```\n\n---\n\n## Environment  \n- **OS**: Ubuntu Linux 22.04  \n- **Browser**: N/A  \n- **Agno Version**: (e.g. v1.0.0 or as installed)  \n- **External Dependency Versions**:  \n  - Python: 3.12  \n  - pydantic: (version used by Agno, likely 2.x)  \n- **Additional Environment Details**:  \n  - Running via `miniconda3`  \n  - File location: `/media/nafiz/NewVolume/ai-agent-x/Agno Agents/structured_output.py`\n\n---\n",
      "state": "closed",
      "author": "ahammadnafiz",
      "author_type": "User",
      "created_at": "2025-04-10T05:40:39Z",
      "updated_at": "2025-04-10T10:54:14Z",
      "closed_at": "2025-04-10T10:54:13Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2755/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2755",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2755",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:36.710428",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @ahammadnafiz !\n\nPlease update `expected_output=MovieScript,` to: `response_model=MovieScript,`. [Some docs for reference](https://docs.agno.com/agents/structured-output)\n",
          "created_at": "2025-04-10T05:49:42Z"
        }
      ]
    },
    {
      "issue_number": 2367,
      "title": "[Bug] FileNotFoundError: [WinError 2] The system cannot find the file specified",
      "body": "# Description\nI am trying to run the Agno MCP cookbook for all the files, such as github.py and filesystem.py, and I am getting an error: FileNotFoundError: [WinError 2] The system cannot find the file specified\n\n## Steps to Reproduce\nList the steps needed to encounter this bug or issue.\n\n## Agent Configuration (if applicable)\nProvide relevant agent configuration.\n\n## Expected Behavior\nWhat did you expect to happen?\n\n## Actual Behavior\nWhat actually happened instead?\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n![Image](https://github.com/user-attachments/assets/3864b6a2-99ef-4a64-84eb-267723cadb1f)\n\n\n## Environment\n- OS: (e.g. macOS, Windows 11)\n- Browser (if relevant): (e.g. Chrome 108, Firefox 107)\n- Agno Version: (e.g. v1.0.0)\n- External Dependency Versions: (e.g., yfinance 0.2.52)\n- Additional Environment Details: (e.g., Python 3.10)\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "shubhamchau222",
      "author_type": "User",
      "created_at": "2025-03-11T17:46:33Z",
      "updated_at": "2025-04-10T00:32:12Z",
      "closed_at": "2025-04-10T00:32:12Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2367/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2367",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2367",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:36.958621",
      "comments": [
        {
          "author": "kausmeows",
          "body": "Hi @shubhamchau222, thanks for trying out agno. To get this right I'll need a bit more information-\n1. do you have `node` and `npm/npx` installed in your system globally?\n2. Are they added in your system PATH?  \n\nlet me know this first",
          "created_at": "2025-03-14T19:57:48Z"
        },
        {
          "author": "anihitk07",
          "body": "I was trying this out today, got the same error with https://github.com/agno-agi/agno/blob/main/cookbook/examples/teams/coordinate/travel_planner_mcp_team.py. I have node/nvm/npm/npx all installed and configured at PATH.",
          "created_at": "2025-03-26T19:46:56Z"
        },
        {
          "author": "anihitk07",
          "body": "Got it working!! \n# working piece on WSL Ubuntu\n\n    # airbnb_server_params = StdioServerParameters(\n    #     command=\"npx\",\n    #     args=[\"-y\", \"@openbnb/mcp-server-airbnb\", \"--ignore-robots-txt\"],\n    #     env=env,\n    # )\n\n    airbnb_server_params = StdioServerParameters(\n        command=\"/bi",
          "created_at": "2025-03-26T22:17:05Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-10T00:32:10Z"
        }
      ]
    },
    {
      "issue_number": 2446,
      "title": "[Bug] Workflow/Agent `run_id` consistency",
      "body": "# Description\n\n `run_id`s aren't staying consistent between a workflow and it's agents. \n\n`Workflow._run()` updates `RunResponse` instances returned from agent runs with its own `run_id`, but at that point the agent has already written itself to storage. In memory things are synced but storage is not.  The agent will `read_from_storage` on its next run and in-memory state while be out of sync too.\n\n## Steps to Reproduce\n\nExecute more than one run in a workflow and note that:\n\n- in memory, all `run_id`s bar the last are no longer consistent\n- in storage, no `run_id`s are consistent\n\n## Workaround \n\nManually write each agent to storage after a run.\n\n## Possible Solutions \n\nI won't have spent as much time thinking about these things as the authors but it seems like a design problem to me, and solutions will come from reconsidering or reworking either:\n\n- the relationship between Workflow and Agent \n- or the approach to storage\n\nWorkflow seems to have a few areas where it improved in terms of being a collection of agents, like a better mechanism for aggregating `RunResponse`s from agents.\n\nThere are a lot of reads and writes to storage in Agno and there is a lot of redundant data stored, which I expect will both either have some motivation or be on a list of things to revisit.\n\n",
      "state": "closed",
      "author": "mediumchris",
      "author_type": "User",
      "created_at": "2025-03-18T15:50:03Z",
      "updated_at": "2025-04-10T00:32:10Z",
      "closed_at": "2025-04-10T00:32:10Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2446/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2446",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2446",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:37.154062",
      "comments": [
        {
          "author": "isikepalaku",
          "body": "> # Description\n> `run_id`s aren't staying consistent between a workflow and it's agents.\n> \n> `Workflow._run()` updates `RunResponse` instances returned from agent runs with its own `run_id`, but at that point the agent has already written itself to storage. In memory things are synced but storage ",
          "created_at": "2025-03-20T21:30:15Z"
        },
        {
          "author": "ysolanky",
          "body": "Hello @mediumchris ! We are currently working on updating the Workflow class which should resolve this inconsistency. Sorry about this. Hoping to share updates soon! ",
          "created_at": "2025-03-26T04:30:00Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-10T00:32:08Z"
        }
      ]
    },
    {
      "issue_number": 2509,
      "title": "[Bug]OpenAI Like  User preferences and conversation summaries bug",
      "body": "When I use OpenAI Like to do User preferences and conversation summaries, the code keeps looping through add_cemory without stopping. What happened and what should I do？\n\n![Image](https://github.com/user-attachments/assets/7ca3073d-37fc-4108-8374-b8e6dc1f9166)\n\n\n",
      "state": "closed",
      "author": "ruidanwang",
      "author_type": "User",
      "created_at": "2025-03-24T05:58:55Z",
      "updated_at": "2025-04-10T00:32:08Z",
      "closed_at": "2025-04-10T00:32:08Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2509/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2509",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2509",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:37.367293",
      "comments": [
        {
          "author": "manthanguptaa",
          "body": "Hey @ruidanwang! Can you please share your code so that we can help you debug?",
          "created_at": "2025-03-26T06:25:52Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-10T00:32:06Z"
        }
      ]
    },
    {
      "issue_number": 2551,
      "title": "how can i custom model llm",
      "body": "how can i custom model llm",
      "state": "closed",
      "author": "ngoc85672912341998N",
      "author_type": "User",
      "created_at": "2025-03-26T00:53:03Z",
      "updated_at": "2025-04-10T00:32:04Z",
      "closed_at": "2025-04-10T00:32:04Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2551/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2551",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2551",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:37.557412",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @ngoc85672912341998N ! You can use any of the supported model providers with Agno Agents. Here are some docs regarding the currently supported [models](https://docs.agno.com/models/introduction). Please let me know if this answered your question",
          "created_at": "2025-03-26T04:01:52Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-10T00:32:02Z"
        }
      ]
    },
    {
      "issue_number": 2712,
      "title": "Empty anthropic responses generated but these are invalid when sent back to the model",
      "body": "# Description\nAnthropic model sometimes responds with empty assistant messages (empty content) with tool calls. However sending these back in results in an error.\n\nValueError: Bad response code, expected 200: {'status_code': 400, 'headers': {':exception-type': 'validationException', ':content-type': 'application/json', ':message-type': 'exception'}, 'body': b'{\"message\":\"messages: text content blocks must contain non-whitespace text\"}'}\n\n## Steps to Reproduce\nShould be reproducible on any anthropic model. \n\n## Expected Behavior\nI guess we need to find the right way to handle empty whitespace or newline messages from the model. Maybe we should replace the empty message with a dot? \n\n## Actual Behavior\nThis crashes the agent because empty content messages are invalid with anthropic.\n\n## Screenshots or Logs (if applicable)\n\n![Image](https://github.com/user-attachments/assets/7ce0fb62-f18c-497c-8cba-bdcb975513b6)\n\n## Environment\n- Anthropic Claude 3.7 on bedrock. \n",
      "state": "closed",
      "author": "mkschreder",
      "author_type": "User",
      "created_at": "2025-04-07T12:54:47Z",
      "updated_at": "2025-04-09T18:50:47Z",
      "closed_at": "2025-04-08T15:07:18Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2712/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2712",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2712",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:37.799376",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @mkschreder ! This has been fixed and will be a part of the next release. Thank you! ",
          "created_at": "2025-04-08T15:07:18Z"
        },
        {
          "author": "mkschreder",
          "body": " @ysolanky does this need to be fixed in models/aws/claude.py as well? ",
          "created_at": "2025-04-09T18:50:46Z"
        }
      ]
    },
    {
      "issue_number": 2352,
      "title": "[Bug]Agent Response coming blank",
      "body": "# Description\nI was building a multi agent system with one agent having access to knowledge base. I asked a query to main agent, it called the sub agent and generated response, but at the end agent.run returned empty Response.  \n\n## Steps to Reproduce\nList the steps needed to encounter this bug or issue.\n\n## Agent Configuration (if applicable)\nUsing Azure model gpt 4o. Didn't had this isssue with Gemini flash\n\n## Expected Behavior\nIt was supposed to return below text\nThe company offers the following types of leave as per the HR Policy Manual:\n\n         1. **Casual Leave**\n            - 8 days per calendar year.\n            - Not more than 5 days can be taken at a time.\n            - Can be combined with Special Casual Leave but not with other types of leave.\n\n         2. **Earned Leave**\n            - Details regarding eligibility and accrual are specified in the HR Policy Manual.\n\n         3. **Half Pay Leave**\n            - Specifics on accrual and usage available in the policy.\n\n         4. **Commuted Leave**\n            - Conversion of Half Pay Leave into full pay leave under certain conditions.\n\n         5. **Extraordinary Leave**\n            - Granted in special circumstances, typically without pay.\n\n         6. **Maternity Leave**\n            - Provided for female employees; detailed conditions apply.\n\n         7. **Paternity Leave**\n            - Granted to male employees for newborn care.\n\n         8. **Leave for Female Employees on Child Adoption**\n            - Leave provisions for female employees upon adoption of a child.\n\n         **References**\n         - HR Policy Manual 2023, Page 7, 69-74\n\n## Actual Behavior\nBut returned blank\n\n## Screenshots or Logs (if applicable)\nDEBUG    ============== user ==============\nDEBUG    what types of leaves we have in our company?\nDEBUG    ============== assistant ==============\nDEBUG    Tool Calls: [\n           {\n             \"id\": \"call_a5yFsLpzncDQg1WMCIqEBy6D\",\n             \"function\": {\n               \"arguments\": \"{\\\"task_description\\\":\\\"Provide details about the types of leaves available in the\n         company.\\\",\\\"expected_output\\\":\\\"A comprehensive list of leave types offered by the\n         company.\\\",\\\"additional_information\\\":null}\",\n               \"name\": \"transfer_task_to_policy_query_agent\"\n             },\n             \"type\": \"function\"\n           }\n         ]\nDEBUG    **************** METRICS ****************\nDEBUG    * Input tokens:                2278\nDEBUG    * Output tokens:               48\nDEBUG    * Total tokens:                2326\nDEBUG    * Prompt tokens details:       {'audio_tokens': 0, 'cached_tokens': 0}\nDEBUG    * Completion tokens details:   {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0,\n         'rejected_prediction_tokens': 0}\nDEBUG    * Time:                        4.6795s\nDEBUG    * Tokens per second:           10.2576 tokens/s\nDEBUG    **************** METRICS ******************\nDEBUG    ============== tool ==============\nDEBUG    Tool call Id: call_a5yFsLpzncDQg1WMCIqEBy6D\nDEBUG    The company offers the following types of leave as per the HR Policy Manual:\n\n         1. **Casual Leave**\n            - 8 days per calendar year.\n            - Not more than 5 days can be taken at a time.\n            - Can be combined with Special Casual Leave but not with other types of leave.\n\n         2. **Earned Leave**\n            - Details regarding eligibility and accrual are specified in the HR Policy Manual.\n\n         3. **Half Pay Leave**\n            - Specifics on accrual and usage available in the policy.\n\n         4. **Commuted Leave**\n            - Conversion of Half Pay Leave into full pay leave under certain conditions.\n\n         5. **Extraordinary Leave**\n            - Granted in special circumstances, typically without pay.\n\n         6. **Maternity Leave**\n            - Provided for female employees; detailed conditions apply.\n\n         7. **Paternity Leave**\n            - Granted to male employees for newborn care.\n\n         8. **Leave for Female Employees on Child Adoption**\n            - Leave provisions for female employees upon adoption of a child.\n\n         **References**\n         - HR Policy Manual 2023, Page 7, 69-74\n\nDEBUG    **************** METRICS ****************\nDEBUG    * Time:                        0.0029s\nDEBUG    **************** METRICS ******************\nDEBUG    ============== assistant ==============\nDEBUG    **************** METRICS ****************\nDEBUG    * Input tokens:                2250\nDEBUG    * Output tokens:               233\nDEBUG    * Total tokens:                2483\nDEBUG    * Prompt tokens details:       {'audio_tokens': 0, 'cached_tokens': 0}\nDEBUG    * Completion tokens details:   {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0,\n         'rejected_prediction_tokens': 0}\nDEBUG    * Time:                        3.9572s\nDEBUG    * Tokens per second:           58.8795 tokens/s\nDEBUG    **************** METRICS ******************\nDEBUG    ---------- Azure Response End ----------\nDEBUG    Added 4 Messages to AgentMemory\nDEBUG    Added AgentRun to AgentMemory\nDEBUG    *********** Agent Run End: 926ae350-fad2-42c2-88c0-127ff39a3d38 ***********\n╭──╮\n│  │\n╰──╯\n\n## Environment\n- OS: (e.g. macOS, Windows 11)\n- Browser (if relevant): (e.g. Chrome 108, Firefox 107)\n- Agno Version: 1.1.9\n- Additional Environment Details: Python 3.12\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "AkhilmsAchu",
      "author_type": "User",
      "created_at": "2025-03-10T17:10:28Z",
      "updated_at": "2025-04-09T00:32:08Z",
      "closed_at": "2025-04-09T00:32:08Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 23,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2352/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2352",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2352",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:37.976259",
      "comments": []
    },
    {
      "issue_number": 2417,
      "title": "[Bug]  Issue Connecting Workflow to Playground – Errors Fetching Workflow Input Fields & Sessions",
      "body": "# Description\nI am encountering difficulties when trying to connect my workflow to the Agno Playground. The workflow appears in the UI, but when I click on it, I receive errors such as:\n\n\"Failed to fetch workflow input fields.\"\n\"Failed to fetch the session.\"\n\nI am unsure where to look to resolve this issue.\n\nLogs from the api\n```\nINFO:     127.0.0.1:56782 - \"GET /v1/playground/workflows/None HTTP/1.1\" 404 Not Found\nINFO:     127.0.0.1:56782 - \"GET /v1/playground/workflows/None/sessions?user_id=c271759c-d52a-4bce-badd-eb95235bee33 HTTP/1.1\" 404 Not Found\nINFO:     127.0.0.1:56782 - \"GET /v1/playground/workflows/None HTTP/1.1\" 404 Not Found\n```\n\n## Steps to Reproduce\nBelow is the relevant portion of my code configuring the Playground:\n\n```\n# Access the underlying agent objects\nagent_analyzer: Agent = transaction_agent.agent # get the Agno source Agent\nagent_check: Agent = enrichment_check.agent # get the Agno source Agent\n\n# Create workflow\nworkflow = TransactionWorkflow(\n    transaction_agent=transaction_agent, #wrapper \n    check_agent=check_agent, # wrapper\n    debug=False\n)\n\n# Set up playground\nsettings = PlaygroundSettings(env=\"dev\")\napp = Playground(\n    agents=[agent_analyzer, agent_check],\n    workflows=[workflow],\n    settings=settings\n).get_app(use_async=False)\n\nif __name__ == \"__main__\":\n    serve_playground_app(\"src.playground_agents:app\", reload=True)\n```\n\n## Agent Configuration (if applicable)\nProvide relevant agent configuration.\n\n## Expected Behavior\nWhat did you expect to happen?\n\n\n\n## Environment\n- Python3.11 with latest Agno version (1.1.13)\n\nCould you please provide guidance on how to resolve this issue? Let me know if you need additional information.\n\n",
      "state": "closed",
      "author": "lironesamoun",
      "author_type": "User",
      "created_at": "2025-03-14T16:55:52Z",
      "updated_at": "2025-04-09T00:32:06Z",
      "closed_at": "2025-04-09T00:32:06Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2417/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2417",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2417",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:37.976286",
      "comments": [
        {
          "author": "manthanguptaa",
          "body": "Hey @lironesamoun! Is it possible to share the code for `TransactionWorkflow`? Here is a doc by the way to help you write your workflow, which might help you debug as well. Right now I am not sure how you are defining TransactionWorkflow which might be the problem in this case",
          "created_at": "2025-03-16T16:12:13Z"
        },
        {
          "author": "lironesamoun",
          "body": "Yes, this is part of the code with name variable modification\n\n\n```\nclass TransactionWorkflow(Workflow):\n    \"\"\"\n    Workflow\n    \"\"\"\n\n    def __init__(self, agent_analyzer, agent_check, debug: bool = False, **kwargs):\n\n        super().__init__(**kwargs)\n        self.agent_analyzer = agent_analyzer\n",
          "created_at": "2025-03-17T08:41:35Z"
        },
        {
          "author": "AijazPro",
          "body": "I am also facing same issue \nINFO:     127.0.0.1:51949 - \"GET /v1/playground/agents/rag_local_agent/sessions?user_id=ajazahmadit_1add HTTP/1.1\" 404 Not Found",
          "created_at": "2025-03-25T16:38:08Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-09T00:32:05Z"
        }
      ]
    },
    {
      "issue_number": 2422,
      "title": "[Bug]",
      "body": "# Description\nThe fw does not support Czech characters.\n\n## Steps to Reproduce\nSet the names of the agents with Czech characters in names of the agents.\n\n```\nagents: List[AgentModel] = [\n    # AgentModel(\n    #     id=\"1\",\n    #     name=\"Researcher\",\n    #     role=\"You are a researcher that can search the web for information.\",\n    #     instructions=\"Research the web for information needed to fulfill the task.\"\n    # ),\n    # AgentModel(\n    #     id=\"2\",\n    #     name=\"Writer\",\n    #     role=\"You are a writer that can write a blog post.\",\n    #     instructions=\"Write a blog post based on the information found by the researcher.\"\n    # ),\n    AgentModel(\n        id=\"3\",\n        name=\"Jana Hodná\",\n        role=\"Jste kreativní člověk, který dokáže vytvořit jména pro firmu.\",\n        instructions=\"Vytvořte 5 názvů společnosti. Buďte kreativní a hrajte si se slovy a různě je míchejte.\"\n    ),\n    AgentModel(\n        id=\"4\",\n        name=\"David Vomáčka\",\n        role=\"Jste odborník na vyhledávání dostupných domén.\",\n        instructions=\"Jste odborník na vyhledávání dostupných domén.Ověřte dostupnost domén a uveďte mi cenu domény. Vždy buďte struční a ujistěte se, že vracíte správné ceny a ne nedostupné domény. K dispozici k nákupu jsou pouze domény, které mají zadáno purchaseable=true a cenu.\"\n    )\n\n]\n```\n\n## Agent Configuration (if applicable)\nabove\n\n## Expected Behavior\nrun successfully\n\n## Actual Behavior\n```\n^CTraceback (most recent call last):\n  File \"/Users/prokop/repos/_ai/sf_demo_legal/run.basic.py\", line 75, in <module>\n    response = start(msg)\n               ^^^^^^^^^^\n  File \"/Users/prokop/repos/_ai/sf_demo_legal/src/basic/start.py\", line 58, in start\n    response = team_agent.run(msg.task.instructions, stream=False)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/prokop/repos/_ai/sf_demo_legal/.venv/lib/python3.12/site-packages/agno/agent/agent.py\", line 869, in run\n    return next(resp)\n           ^^^^^^^^^^\n  File \"/Users/prokop/repos/_ai/sf_demo_legal/.venv/lib/python3.12/site-packages/agno/agent/agent.py\", line 592, in _run\n    model_response = self.model.response(messages=run_messages.messages)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/prokop/repos/_ai/sf_demo_legal/.venv/lib/python3.12/site-packages/agno/models/anthropic/claude.py\", line 521, in response\n    response: AnthropicMessage = self.invoke(messages=messages)\n                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/prokop/repos/_ai/sf_demo_legal/.venv/lib/python3.12/site-packages/agno/models/anthropic/claude.py\", line 304, in invoke\n    return self.get_client().messages.create(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/prokop/repos/_ai/sf_demo_legal/.venv/lib/python3.12/site-packages/anthropic/_utils/_utils.py\", line 275, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/prokop/repos/_ai/sf_demo_legal/.venv/lib/python3.12/site-packages/anthropic/resources/messages/messages.py\", line 904, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/Users/prokop/repos/_ai/sf_demo_legal/.venv/lib/python3.12/site-packages/anthropic/_base_client.py\", line 1289, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/prokop/repos/_ai/sf_demo_legal/.venv/lib/python3.12/site-packages/anthropic/_base_client.py\", line 966, in request\n    return self._request(\n           ^^^^^^^^^^^^^^\n  File \"/Users/prokop/repos/_ai/sf_demo_legal/.venv/lib/python3.12/site-packages/anthropic/_base_client.py\", line 1002, in _request\n    response = self._client.send(\n               ^^^^^^^^^^^^^^^^^^\n  File \"/Users/prokop/repos/_ai/sf_demo_legal/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n    response = self._send_handling_auth(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/prokop/repos/_ai/sf_demo_legal/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n    response = self._send_handling_redirects(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/prokop/repos/_ai/sf_demo_legal/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n    response = self._send_single_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/prokop/repos/_ai/sf_demo_legal/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n    response = transport.handle_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/prokop/repos/_ai/sf_demo_legal/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n    resp = self._pool.handle_request(req)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/prokop/repos/_ai/sf_demo_legal/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 256, in handle_request\n    raise exc from None\n  File \"/Users/prokop/repos/_ai/sf_demo_legal/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 236, in handle_request\n    response = connection.handle_request(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/prokop/repos/_ai/sf_demo_legal/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py\", line 103, in handle_request\n    return self._connection.handle_request(request)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/prokop/repos/_ai/sf_demo_legal/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py\", line 136, in handle_request\n    raise exc\n  File \"/Users/prokop/repos/_ai/sf_demo_legal/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py\", line 106, in handle_request\n    ) = self._receive_response_headers(**kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/prokop/repos/_ai/sf_demo_legal/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py\", line 177, in _receive_response_headers\n    event = self._receive_event(timeout=timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/prokop/repos/_ai/sf_demo_legal/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py\", line 217, in _receive_event\n    data = self._network_stream.read(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/prokop/repos/_ai/sf_demo_legal/.venv/lib/python3.12/site-packages/httpcore/_backends/sync.py\", line 128, in read\n    return self._sock.recv(max_bytes)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/prokop/.local/share/uv/python/cpython-3.12.8-macos-aarch64-none/lib/python3.12/ssl.py\", line 1232, in recv\n    return self.read(buflen)\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/prokop/.local/share/uv/python/cpython-3.12.8-macos-aarch64-none/lib/python3.12/ssl.py\", line 1105, in read\n    return self._sslobj.read(len)\n```\n\n## Environment\n- OS: (e.g. macOS 15.4)\n- Agno Version: (e.g. v1.0.0)\n```\nsdist = { url = \"https://files.pythonhosted.org/packages/65/40/5697c93c8ec8d09ed057ecb179b5c580b5bf34c22971a5bb94f4b7f45f6f/agno-1.0.8.tar.gz\", hash = \"sha256:48306365ffaafa7d9ce206a0e6d403e28cfcd828f03ea2a97e3471748441cc2c\", size = 355309 }\n```\n\n- Additional Environment Details: (e.g., Python 3.10)\n- `3.12`\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\nunicode chars\n\n`from unidecode import unidecode`",
      "state": "closed",
      "author": "prokopsimek",
      "author_type": "User",
      "created_at": "2025-03-14T21:23:54Z",
      "updated_at": "2025-04-09T00:32:05Z",
      "closed_at": "2025-04-09T00:32:04Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2422/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2422",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2422",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:38.253266",
      "comments": [
        {
          "author": "pritipsingh",
          "body": "Hey @prokopsimek Thank you for reaching out and sorry about it. You're right - we're not doing very good with languages other than English but @kausmeows is working on fixing it as we get some time from the launch week. But we're open source and if you've some bandwidth- feel free to contribute :)",
          "created_at": "2025-03-25T12:43:15Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-09T00:32:03Z"
        }
      ]
    },
    {
      "issue_number": 2476,
      "title": "[Bug]Structured Output no response data",
      "body": "# Description\n**when i use huggingface,no any response date**\n\nstructured_output_agent = Agent(\n    model=HuggingFace(\n        id=\"Qwen/Qwen2.5-72B-Instruct\", max_tokens=4096, temperature=0\n    ),\n    description=\"You write movie scripts.\",\n    response_model=MovieScript,\n    # stream=True,\n    # debug_mode=True,\n)\n\n▰▰▰▰▱▱▱ Thinking...\n┏━ Message ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                                                                 ┃\n┃ New York                                                                                                        ┃\n┃                                                                                                                 ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n▰▰▰▰▱▱▱ Thinking...\n┏━ Message ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                                                                 ┃\n┃ New York                                                                                                        ┃\n┃                                                                                                                 ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n\n## Steps to Reproduce\nList the steps needed to encounter this bug or issue.\n\n## Agent Configuration (if applicable)\nProvide relevant agent configuration.\n\n## Expected Behavior\nWhat did you expect to happen?\n\n## Actual Behavior\nWhat actually happened instead?\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- OS:colab\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "ruidanwang",
      "author_type": "User",
      "created_at": "2025-03-21T03:11:46Z",
      "updated_at": "2025-04-09T00:32:03Z",
      "closed_at": "2025-04-09T00:32:03Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2476/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2476",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2476",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:38.464230",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Hi!\nSo I just ran the following\n```\nclass MovieScript(BaseModel):\n    script: str = Field(..., description=\"The script of the movie.\")\n    name: str = Field(..., description=\"Give a name to this movie\")\n    characters: List[str] = Field(..., description=\"Name of characters for this movie.\")\n\n\nstruct",
          "created_at": "2025-03-21T07:12:21Z"
        },
        {
          "author": "ruidanwang",
          "body": "Name: agno\nVersion: 1.1.14\nSummary: Agno: a lightweight framework for building multi-modal Agents\nHome-page: https://agno.com/\nAuthor: \nAuthor-email: Ashpreet Bedi <[ashpreet@agno.com](mailto:ashpreet@agno.com)>\nLicense: Copyright (c) Agno, Inc.",
          "created_at": "2025-03-21T07:37:54Z"
        },
        {
          "author": "pritipsingh",
          "body": "Hey @ruidanwang Please upgrade to the latest version and let us know if it works for you! ",
          "created_at": "2025-03-25T15:50:33Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-09T00:32:02Z"
        }
      ]
    },
    {
      "issue_number": 2610,
      "title": "[Bug] Gemini API Error: Invalid Type in Function Declarations with Multiple Tools (Vertex AI)",
      "body": "# Description\nI'm encountering an error when trying to use Gemini with multiple tools in Agno using the Vertex AI API. The error occurs specifically with function declarations and parameter types in the Gemini API.\n\n\n## Steps to Reproduce\nCreate a new Python file with the following imports:\n```\nfrom agno.agent import Agent\nfrom agno.models.google import Gemini\nfrom agno.tools.duckduckgo import DuckDuckGoTools\nfrom agno.tools.exa import ExaTools\n```\n\nCreate an agent with multiple tools using Vertex AI:\n```\nagent = Agent(\n    name=\"Test Agent\",\n    model=Gemini(\n        id=\"gemini-2.0-flash-exp\",\n        vertexai=True,  # Using Vertex AI API\n        project_id=\"your-project-id\",\n        location=\"us-central1\"\n    ),\n    tools=[DuckDuckGoTools(), ExaTools()]\n)\n```\n\n\nTry to use the agent with a simple query:\n`await agent.aprint_response(\"What is the best way to learn to ride a boat?\")`\n\n## Agent Configuration (if applicable)\n```\nagent = Agent(\n    name=\"Test Agent\",\n    model=Gemini(\n        id=\"gemini-2.0-flash-exp\",\n        vertexai=True,  # Using Vertex AI API\n        project_id=\"your-project-id\",\n        location=\"us-central1\"\n    ),\n    tools=[DuckDuckGoTools(), ExaTools()]\n)\n```\n\n## Expected Behavior\nThe agent should successfully use the provided tools to search and return results using Gemini's function calling API through Vertex AI.\n\n## Actual Behavior\nThe Vertex AI API returns a 400 INVALID_ARGUMENT error:\n`Invalid value at 'tools[0].function_declarations[1].parameters.properties[0].value.type' (type.googleapis.com/google.cloud.aiplatform.v1beta1.Type), \"\"`\n\n## Screenshots or Logs (if applicable)\n```\nError: 400 INVALID_ARGUMENT\nDetails: Invalid value at 'tools[0].function_declarations[1].parameters.properties[0].value.type' (type.googleapis.com/google.cloud.aiplatform.v1beta1.Type), \"\"\n```\n\n![Image](https://github.com/user-attachments/assets/91b50a4d-1b81-4654-961d-beb1d6281388)\n\n## Environment\n- OS: macOS Sequoia Version 15.3.2\n- Agno Version: 1.2.6\n- Google Cloud:\n- [ ] Project configured\n- [ ] Vertex AI API enabled\n- [ ] Using Vertex AI's Gemini model (not the Google AI studio Gemini API)\n\n## Dependencies:\n-     google-genai: 1.8.0\n-     duckduckgo-search: 7.5.5\n-     googlesearch-python: 1.3.0\n-     pycountry: 24.6.1\n-     pypdf: 5.4.0\n-     arxiv: 2.1.3\n-     Python: 3.13.0\n\n## Possible Solutions (optional)\n\n1. Update the tool declarations to use proper Vertex AI types\n2. Modify the Gemini model implementation to handle tool declarations internally\n3. Add explicit type conversion in the tool classes\n4. Consider using a different model version that better handles function calling\n5. Consider switching to direct Gemini API instead of Vertex AI if the issue persists\n\n## Additional Context\n- The error occurs specifically with multiple tools\n- Single tool usage works fine\n- The error suggests an issue with parameter type definitions in the function declarations\nI've tried various approaches including:\n- Adding explicit type hints\n- Creating tool schemas\n- Using different model versions\n- Removing optional parameters\nThe error is specific to Vertex AI's implementation of Gemini's function calling API\n",
      "state": "closed",
      "author": "aovabo",
      "author_type": "User",
      "created_at": "2025-03-30T07:44:12Z",
      "updated_at": "2025-04-08T20:25:07Z",
      "closed_at": "2025-04-08T20:25:06Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2610/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2610",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2610",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:38.704022",
      "comments": [
        {
          "author": "MischaPanch",
          "body": "I have the same problem, very frustrating. Gemini is currently the strongest model, would be great if this could be fixed soon.\n\nInterestingly, the error is not happening for all tools - only for some, among them those without parameters.\n\nIt might not be purely on agno's side - this issue for googl",
          "created_at": "2025-03-30T21:27:45Z"
        },
        {
          "author": "ysolanky",
          "body": "Hello @aovabo and @MischaPanch ! I agree, Gemini is a key model for us and I would love to fix his issue asap. But I am having trouble recreating this error. I tested with the following Agent config but the Agent is working as expected with and without vertexai\n\n``` python\nfrom agno.agent import Age",
          "created_at": "2025-03-31T00:17:23Z"
        },
        {
          "author": "MischaPanch",
          "body": "Hi @ysolanky, thanks for the quick response. The problem happens with optional types:\n\n```python\nfrom agno.agent import Agent\nfrom agno.models.google import Gemini\nfrom dotenv import load_dotenv\n\ndef tool_with_optional_input(input_optional_str: str | None) -> str:\n    \"\"\"Test the Vertexai API\"\"\"\n   ",
          "created_at": "2025-04-01T09:31:35Z"
        },
        {
          "author": "Nathwoo",
          "body": "Hello,\nI am running into the same problem using the team agent and figured out the conversion of the tool schema is failing with certain types.\n\nThe _convert_schema() from agno.models.google.gemini doesn't support multiple types of input for one argument of a function.\nHere is an example of  two too",
          "created_at": "2025-04-01T14:28:39Z"
        },
        {
          "author": "MischaPanch",
          "body": "Yes, there are multiple problems in that schema. Also the required field is not set correctly for args with defaults. Google's schema also does not have a null type, so optional types need special treatment. We (@opcode81) patched the conversion function in our code to deal with the absence of null ",
          "created_at": "2025-04-01T15:15:51Z"
        }
      ]
    },
    {
      "issue_number": 2692,
      "title": "[Bug] Latest versions of Agno not working with latest version of Chroma",
      "body": "# Description\nChroma has updates to a new version and using the new version of Agno togther with it throws an error\n\n## Steps to Reproduce\npip install the new versions of each package using python use the module `from agno.vectordb.chroma import ChromaDb` and an error occurs stating \n\n```\nImportError                               Traceback (most recent call last)\n[/usr/local/lib/python3.11/dist-packages/agno/vectordb/chroma/chromadb.py](https://localhost:8080/#) in <module>\n      8     from chromadb.api.models.Collection import Collection\n----> 9     from chromadb.api.types import GetResult, IncludeEnum, QueryResult\n     10 \n\nImportError: cannot import name 'IncludeEnum' from 'chromadb.api.types' (/usr/local/lib/python3.11/dist-packages/chromadb/api/types.py)\n\nDuring handling of the above exception, another exception occurred:\n\nImportError                               Traceback (most recent call last)\n2 frames\n[/usr/local/lib/python3.11/dist-packages/agno/vectordb/chroma/chromadb.py](https://localhost:8080/#) in <module>\n     10 \n     11 except ImportError:\n---> 12     raise ImportError(\"The `chromadb` package is not installed. Please install it via `pip install chromadb`.\")\n     13 \n     14 from agno.document import Document\n\nImportError: The `chromadb` package is not installed. Please install it via `pip install chromadb`. \n```\nNote chroma is installed within the envrionment. Code base worked before Chroma and Agno updated their packages. \n\n## Agent Configuration (if applicable)\nProvide relevant agent configuration.\n\n## Expected Behavior\nWhat did you expect to happen?\n\n## Actual Behavior\nWhat actually happened instead?\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- OS: (e.g. macOS, Windows 11)\n- Browser (if relevant): Arc (60953)\n- Agno Version: 1.2.9\n- External Dependency Versions: \n- Additional Environment Details: Google Colab on Python 3.11.11\n\n## Possible Solutions (optional)\nUpdate Agno to work with the new version of Chroma\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "skelleex",
      "author_type": "User",
      "created_at": "2025-04-05T16:36:56Z",
      "updated_at": "2025-04-08T12:12:27Z",
      "closed_at": "2025-04-08T12:12:27Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2692/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2692",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2692",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:38.892368",
      "comments": []
    },
    {
      "issue_number": 2344,
      "title": "[Bug] MongoDB index creation always uses default embedding dim",
      "body": "The MongoDB index creation takes the embedding dimension from the embedder as\n```py\nembedding_dim = getattr(self.embedder, \"embedding_dim\", 1536)\n```\n\nBut the dimension attribute in the `Embedder` class is named `dimensions` and so it always goes to the default value.\n\nI tried changing the embed dimension just on a whim and it started giving errors saying the index dim and the query dim don't match. I spent way too long in the night trying to debug this. But seems this was the problem. \nOr rather I hope this was the problem. I think? \n",
      "state": "closed",
      "author": "KalpeshManandhar",
      "author_type": "User",
      "created_at": "2025-03-10T07:16:50Z",
      "updated_at": "2025-04-08T00:31:56Z",
      "closed_at": "2025-04-08T00:31:56Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2344/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2344",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2344",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:40.645417",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @KalpeshManandhar ! After you changed the dimensions, can you please try again after dropping the table. Or alternatively, use a new table name. In your Agent config, you need to set `knowledge.load(recreate=True)`",
          "created_at": "2025-03-17T05:14:21Z"
        },
        {
          "author": "KalpeshManandhar",
          "body": "Hello @ysolanky ! Sorry I should have been more descriptive in my original issue, my bad. \nHere is my code.\n```py\nfrom agno.knowledge.pdf import PDFKnowledgeBase, PDFReader\nfrom agno.vectordb.mongodb import MongoDb\nfrom agno.embedder.huggingface import HuggingfaceCustomEmbedder\nfrom agno.agent impor",
          "created_at": "2025-03-17T07:10:16Z"
        },
        {
          "author": "KalpeshManandhar",
          "body": "I guess I could open a pull request for this, if this is an actual issue and I have not been hallucinating.",
          "created_at": "2025-03-17T07:15:58Z"
        },
        {
          "author": "amanverma10081",
          "body": "@KalpeshManandhar, I was also encountering similar issue while using Ollama embedder, just wanted to check is your issue resolved? In my case I got temporary fix by changing base Embedder class dimension from default 1536",
          "created_at": "2025-03-24T11:03:43Z"
        },
        {
          "author": "KalpeshManandhar",
          "body": "Hello @amanverma10081 I am currently caught up with some other things so I haven't revisited this issue, and is unlikely that I will for some time. But as far as I understand, the fix is essentially what I described in the comments above, if you're encountering the same error as me. All the best!",
          "created_at": "2025-03-24T11:09:31Z"
        }
      ]
    },
    {
      "issue_number": 2666,
      "title": "[Feature Request] Add timezone for datetime instruction",
      "body": "## Problem Description\nIt would be useful to be able to specify what timezone's the Agno Agent operates in\n\n## Proposed Solution\nExplain your ideal solution. How should this feature work?\nBe as detailed as possible to help us understand your vision.\n\nUsing `zoneinfo` and following the timezone format from the TZ database, we can set the datetime instruction provided to Agno for a specific timezone.\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[x] Yes, I’d love to work on it!**\n**[ ] I’m open to collaborating but need guidance.**\n**[ ] No, I’m just sharing the idea.**\n\nCompleted here #2648 and would love a review! Thanks!",
      "state": "closed",
      "author": "aandyw",
      "author_type": "User",
      "created_at": "2025-04-03T21:17:35Z",
      "updated_at": "2025-04-07T20:29:57Z",
      "closed_at": "2025-04-07T20:29:56Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2666/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2666",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2666",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:40.840247",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Thank you for your contribution @aandyw ! I left some suggestions on the PR",
          "created_at": "2025-04-04T21:09:35Z"
        },
        {
          "author": "dirkbrnd",
          "body": "This was merged!",
          "created_at": "2025-04-07T20:29:56Z"
        }
      ]
    },
    {
      "issue_number": 2700,
      "title": "[Feature Request] Include (AI) answer for Exa search response",
      "body": "## Problem Description\nSimilar to Tavliy, Exa also provides AI-generated answers. We should add that feature to our Exa tools. \n\n## Additional context\nExample from Exa docs:\n- https://github.com/exa-labs/exa-py/blob/master/examples/answer_example.py\n\nHere's the developer dashboard: https://dashboard.exa.ai/playground\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[ ] Yes, I’d love to work on it!**\n**[ ] I’m open to collaborating but need guidance.**\n**[x] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "arsaboo",
      "author_type": "User",
      "created_at": "2025-04-06T13:33:53Z",
      "updated_at": "2025-04-07T17:08:20Z",
      "closed_at": "2025-04-07T17:08:19Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2700/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2700",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2700",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:41.032003",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hey @arsaboo,\nThanks so much for reaching out and for being a part of the Agno community!\nWe really appreciate you taking the time to suggest this feature. Since Agno is open source, feel free to take a stab at implementing it and raise a PR — we'd love to review and collaborate on it with you!",
          "created_at": "2025-04-07T06:24:49Z"
        },
        {
          "author": "arsaboo",
          "body": "Looks like this was added in #2078 \n\nMy apologies for the confusion. ",
          "created_at": "2025-04-07T17:08:19Z"
        }
      ]
    },
    {
      "issue_number": 2508,
      "title": "[Bug] AttributeError in Team Agent Memory when retrieving previous messages from database",
      "body": "# Description\nA `TeamMemory` bug in the Agno library causing an `AttributeError` when trying to access `run.response.messages` because `run.response` is a dictionary, not an object with attributes.\n\n## Steps to Reproduce\n1. Create a `Team` with `TeamMemory` using a database backend\n2. Perform a run with the team using `arun()`\n3. Perform another run, which triggers loading historical messages\n4. Error occurs in `get_messages_from_last_n_runs` when trying to access messages from previous runs\n\n## Agent Configuration (if applicable)\n```python\nteam = Team(\n    name=self.team_name,\n    team_id=self.team_id,\n    user_id=self.user_id,\n    mode=\"route\",\n    model=OpenAIChat(\n        id=\"gpt-4o\",\n        max_tokens=4096,\n        temperature=0,\n        seed=42,\n    ),\n    members=[agent1, agent2],\n    storage=PostgresAgentStorage(\n        table_name=\"agent_team_sessions\",\n        db_engine=engine,\n        schema=\"public\",\n    ),\n    memory=TeamMemory(\n        db=PgMemoryDb(\n            table_name=\"agent_team_memory\",\n            db_engine=engine,\n            schema=\"public\",\n        ),\n        user_id=user_id,\n        create_user_memories=True,\n        update_user_memories_after_run=True,\n    ),\n    enable_team_history=True,\n)\n```\n\n## Expected Behavior\nThe `get_messages_from_last_n_runs` method should properly handle serialized `run.response` objects. When a response is retrieved from storage, it's returned as a dictionary, so the code should either:\n\n1. Access the messages using dictionary syntax (`run.response[\"messages\"]`) instead of attribute syntax (`run.response.messages`), or\n2. Properly reconstruct the `TeamRunResponse` object from the dictionary before accessing its attributes\n\nThe bug is caused by a mismatch between how data is serialized for storage (converted to dictionary) and how it's accessed after retrieval (treated as if it were still an object).\n\n## Actual Behavior\nThe method fails with `AttributeError: 'dict' object has no attribute 'messages'` because it tries to access `run.response.messages` when `run.response` is a dictionary stored in the database.\n\n## Screenshots or Logs (if applicable)\n```\nTraceback (most recent call last):\n  File \"/workspace/src/services/ai/agents/team_agent.py\", line 314, in generate_response\n    response = await self.team.arun(\n               ^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/venv/lib/python3.11/site-packages/agno/team/team.py\", line 1101, in arun\n    run_messages: RunMessages = self.get_run_messages(\n                                ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/venv/lib/python3.11/site-packages/agno/team/team.py\", line 3373, in get_run_messages\n    history: List[Message] = self.memory.get_messages_from_last_n_runs(\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/venv/lib/python3.11/site-packages/agno/memory/team.py\", line 220, in get_messages_from_last_n_runs\n    if not (run.response and run.response.messages):\n                             ^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'dict' object has no attribute 'messages'\n```\n\nResponse dictionary structure in memory:\n```json\n{\n  \"response\": {\n    \"event\": \"RunResponse\",\n    \"model\": \"gpt-4o\",\n    \"messages\": [\n      {\n        \"role\": \"system\",\n        \"content\": \"...\",\n        \"created_at\": 1742784102,\n        \"from_history\": false,\n        \"stop_after_tool_call\": false\n      }\n    ],\n    \"created_at\": 1742783994,\n    \"session_id\": \"1742784094.196249\",\n    \"content_type\": \"str\"\n  }\n}\n```\n\n## Environment\n- OS: Linux (Ubuntu)\n- Agno Version: 1.1.15\n- External Dependency Versions: SQLAlchemy 2.0.36\n- Additional Environment Details: Python 3.11\n\n## Possible Solutions (optional)\nWhen loading TeamRun from storage, convert dictionary responses back to TeamRunResponse objects:\n\n```\n# In TeamRun deserialization logic\nif isinstance(response_dict, dict):\n    return TeamRunResponse(**response_dict)\n```\n\n## Additional Context\nThis issue occurs because of a serialization/deserialization mismatch. When `TeamRunResponse` objects are stored in the database, they're serialized to dictionaries. When retrieved, they remain as dictionaries but the code tries to access them as if they were objects with attributes.",
      "state": "closed",
      "author": "jesalg",
      "author_type": "User",
      "created_at": "2025-03-24T03:01:39Z",
      "updated_at": "2025-04-07T14:51:08Z",
      "closed_at": "2025-03-24T20:41:00Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2508/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2508",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2508",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:41.299924",
      "comments": [
        {
          "author": "jesalg",
          "body": "Potentially also causing https://github.com/agno-agi/agno/issues/2497",
          "created_at": "2025-03-24T03:07:39Z"
        },
        {
          "author": "AkhilmsAchu",
          "body": "Same here😕",
          "created_at": "2025-03-24T05:38:49Z"
        },
        {
          "author": "kasem-io",
          "body": "> Potentially also causing [#2497](https://github.com/agno-agi/agno/issues/2497)\n\nIndeed! this is very likely the root cause\n",
          "created_at": "2025-03-24T10:07:07Z"
        },
        {
          "author": "dirkbrnd",
          "body": "I have a PR out that could be the fix.",
          "created_at": "2025-03-24T15:58:16Z"
        },
        {
          "author": "kasem-io",
          "body": "> I have a PR out that could be the fix.\n\nThank you!\n\nTo try your fix, I started integrating the new memory system using TeamMemory as follows:\n\n```\nmemory = TeamMemory(\n    db=PgMemoryDb(\n        table_name=\"agent_team_memory\",\n        db_url=os.getenv(\"AGENT_DB_URL\")\n    ),\n    user_id=user_messag",
          "created_at": "2025-03-24T18:10:09Z"
        }
      ]
    },
    {
      "issue_number": 2340,
      "title": "[Bug] print_response not printing response in notebook",
      "body": "Is there a reason why print_response is not printing response in notebook file?",
      "state": "closed",
      "author": "FahriBilici",
      "author_type": "User",
      "created_at": "2025-03-09T16:53:19Z",
      "updated_at": "2025-04-06T00:34:47Z",
      "closed_at": "2025-04-06T00:34:47Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2340/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2340",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2340",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:41.621455",
      "comments": [
        {
          "author": "manthanguptaa",
          "body": "@FahriBilici can you please help me with the code you are trying to run? Also notebook file here means google colab (ipynb file) or something else?",
          "created_at": "2025-03-10T02:51:14Z"
        },
        {
          "author": "FahriBilici",
          "body": "@manthanguptaa `agent.print_response(\"something\")` . I am using vscode/cursor notebook file (ipynb)",
          "created_at": "2025-03-10T18:23:52Z"
        },
        {
          "author": "ysolanky",
          "body": "Hello @FahriBilici that is definitely not an expected outcome. Can you please share your output? Also, please trying settings `agent.print_response(\"something\", Stream=True)` and trying ",
          "created_at": "2025-03-14T04:20:47Z"
        },
        {
          "author": "FahriBilici",
          "body": "<img width=\"804\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/59ba875c-ce2b-4ed7-ae38-18a1fa7b9385\" />\n\nwith stream it prints without a problem",
          "created_at": "2025-03-14T10:49:48Z"
        },
        {
          "author": "dirkbrnd",
          "body": "I think it Rich not working nicely with Jupyter Notebooks.",
          "created_at": "2025-03-14T14:05:13Z"
        }
      ]
    },
    {
      "issue_number": 2651,
      "title": "[Bug] Gemini Team structured output failed",
      "body": "Description\nif Team with gemini model and structured output enabled response failed with 400 code\n\nAgent Configuration (if applicable)\nhn_team = Team(\nname=\"HackerNews Team\",\nmode=\"coordinate\",\nmodel=Gemini(id=\"gemini-2.0-flash-exp\"),\nmembers=[hn_researcher, web_searcher, article_reader],\ninstructions=[\n\"First, search hackernews for what the user is asking about.\",\n\"Then, ask the article reader to read the links for the stories to get more information.\",\n\"Important: you must provide the article reader with the links to read.\",\n\"Then, ask the web searcher to search for each story to get more information.\",\n\"Finally, provide a thoughtful and engaging summary.\",\n],\nresponse_model=Article,\nshow_tool_calls=True,\nmarkdown=True,\ndebug_mode=True,\nshow_members_responses=True,\n)\n\nActual Behavior\nERROR    Error from Gemini API: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': \"For controlled generation of only function calls (forced function calling),     \n         please set 'tool_config.function_calling_config.mode' field to ANY instead of populating 'response_mime_type' and 'response_schema' fields. For more details,    \n         see: https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling#tool-config\", 'status': 'INVALID_ARGUMENT'}}                              \n",
      "state": "closed",
      "author": "AduchiMergen",
      "author_type": "User",
      "created_at": "2025-04-03T01:02:22Z",
      "updated_at": "2025-04-05T08:28:12Z",
      "closed_at": "2025-04-05T08:28:11Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2651/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "mishramonalisha76"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2651",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2651",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:41.970445",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @AduchiMergen ! Gemini models currently do not work with structured outputs and tools together. This is a limitation from the API. Teams use tools under the hood so that is why you are experiencing this error. \n\nPlease add the following to your Team config: `use_json_mode=True`. Json mode work",
          "created_at": "2025-04-04T06:00:44Z"
        },
        {
          "author": "AduchiMergen",
          "body": "please handle this and rise exception if use_json_mode not set for gemini in team",
          "created_at": "2025-04-04T13:07:37Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @AduchiMergen \nWith the next release (1.2.9) we show a warning for this.",
          "created_at": "2025-04-05T08:28:11Z"
        }
      ]
    },
    {
      "issue_number": 2652,
      "title": "[Bug]I encountered an error when using the Python tool for inference",
      "body": "from agno.agent import Agent\nfrom agno.models.openai import OpenAIChat\nfrom agno.models.azure import AzureOpenAI\nfrom agno.tools.thinking import ThinkingTools\nfrom agno.tools.python import PythonTools\nfrom textwrap import dedent\nimport os\n\nos.environ[\"OPENAI_API_KEY\"] = \"sk-proj-xxxxxxxxxx\"\n\nreasoning_agent = Agent(\nmodel=OpenAIChat(\"gpt-4o\"),\nreasoning=True,\nmarkdown=True,\ntools=[PythonTools()],\ninstructions=\"推理过程用中文\"\n)\n\nreasoning_agent.print_response(\"文件路径：C:\\Users\\bozhum\\Desktop\\Companys.csv，哪些是中国的公司\", stream=True, show_full_reasoning=True)\n\n![Image](https://github.com/user-attachments/assets/f3215c2f-3669-4cf5-8f95-2439ace69ed0)",
      "state": "closed",
      "author": "Rainismer",
      "author_type": "User",
      "created_at": "2025-04-03T01:54:34Z",
      "updated_at": "2025-04-05T08:11:29Z",
      "closed_at": "2025-04-05T08:11:28Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2652/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2652",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2652",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:42.213156",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Hi @Rainismer \nI tried to replicate this on the latest version and could not. Which version of `agno` are you on? ",
          "created_at": "2025-04-03T07:03:26Z"
        },
        {
          "author": "Rainismer",
          "body": "@dirkbrnd 1.2.7",
          "created_at": "2025-04-03T07:30:55Z"
        },
        {
          "author": "Rainismer",
          "body": "@dirkbrnd If I don't use the tool, it runs fine, but as soon as I use the Python tool, an error occurs.",
          "created_at": "2025-04-03T07:35:15Z"
        },
        {
          "author": "mishramonalisha76",
          "body": "Hi @Rainismer , Our team fixed the issue and it should be out in the next sdk version . Thanks for pointing out the issue ",
          "created_at": "2025-04-03T11:37:41Z"
        },
        {
          "author": "Rainismer",
          "body": "@mishramonalisha76 Thank you for your reply! Looking forward to using the new version soon!",
          "created_at": "2025-04-03T15:04:59Z"
        }
      ]
    },
    {
      "issue_number": 2433,
      "title": "[bug]How can I structured output in a specified response_model after calling the search tool",
      "body": "## Problem Description\nHow can I make the Agent generate structured output in a specified response_model after calling the search tool?\n\nI have implemented a response_model class as follows:\n```\n    class SearcherOutput(BaseModel):\n\n        results: str = Field(..., title=\"字符串表示的查询结果（json格式）\")\n```\nAnd I have written a toolkits named 'KnowledgeSearchTools' that contains various search functions, each of which returns the search result as a string in JSON format.\n\nThen I created an agent as follows:\n```\n    searcher: Agent = Agent(\n        model = Ollama(\n            id=config['Ollama']['llm_model'],\n            host=config['Ollama']['generate_url'],\n        ),\n        description=\"Search information such as XXX using the tool and organize the results into a JSON format for the response.\",\n        tools=[KnowledgeSearchTools(\n            vector_db=Clickhouse(\n                table_name=\"recipe_documents\",\n                host=config['Clickhouse']['host'],\n                port=config['Clickhouse']['port'],\n                username=config['Clickhouse']['username'],\n                password=config['Clickhouse']['password'],\n                embedder=OllamaEmbedder(\n                    id=config['Ollama']['embed_model'],\n                    host=config['Ollama']['embed_url'],\n                )\n            )\n        )],\n        response_model=SearcherOutput,\n        show_tool_calls=True,\n        instructions=dedent(\"\"\"\\\n           You can use the KnowledgeSearchTools to query the following information:\n            1.XXX information\n            2.XXX information\n            3.XXX information\n            4.XXX information\n            5.XXX information\n            6.XXX information\n            Select one or more search tools based on the content you want to search, and directly convert the search \n results into JSON for the response. Do not provide any summaries, analyses, or other additional content.\\\n        \"\"\"),\n        read_chat_history = True,\n        debug_mode=True\n    )\n```\nIn the code above, XXX represents a certain type of knowledge data.\n\nI have already specified the `response_model`, and I have also required the agent in the prompt to return in JSON format. The debugging information for the prompt given to the searcher is as follows:\n\n```\nDEBUG    Search information such as XXX using the tool and organize the results into a JSON format for the response.                                                                                            \n                                                                                                                                                                                           \n         <instructions>                                                                                                                                                                    \n         You can use the KnowledgeSearchTools to query the following information:\n            XXX information\n            XXX information\n            XXX information\n            XXX information\n            XXX information\n            XXX information\n            Select one or more search tools based on the content you want to search, and directly convert the search \n results into JSON for the response. Do not provide any summaries, analyses, or other additional content.。                                                       \n         </instructions>                                                                                                                                                                   \n                                                                                                                                                                                           \n         Provide your output as a JSON containing the following fields:                                                                                                                    \n         <json_fields>                                                                                                                                                                     \n         [\"results\"]                                                                                                                                                                       \n         </json_fields>                                                                                                                                                                    \n                                                                                                                                                                                           \n         Here are the properties for each field:                                                                                                                                           \n         <json_field_properties>                                                                                                                                                           \n         {                                                                                                                                                                                 \n           \"results\": {                                                                                                                                                                    \n             \"type\": \"string\"                                                                                                                                                              \n           }                                                                                                                                                                               \n         }                                                                                                                                                                                 \n         </json_field_properties>                                                                                                                                                          \n         Start your response with `{` and end it with `}`.                                                                                                                                 \n         Your output will be passed to json.loads() to convert it to a Python object.                                                                                                      \n         Make sure it only contains valid JSON.               \n```\nThis agent correctly invoked the tools, and these tools returned correct query results as follows:\n```\nDEBUG    ============== tool ==============                                                                                                                                                \nDEBUG    {\"漏洞信息：\": [\"{\\\"cnnvd_number\\\": \\\"CNNVD-199703-008\\\", \\\"content_column_name\\\": \\\"content\\\", \\\"create_time\\\": \\\"2024-07-10 10:15:03\\\", \\\"created\\\": \\\"2023/11/28 19:15\\\",      \n         \\\"cve_number\\\": \\\"CVE-1999-0299\\\", \\\"file_name\\\": \\\"vulnerability.jsonl\\\", \\\"id\\\": \\\"03f2f3e3-d0cf-4967-bcca-6c78aa2805b8\\\", \\\"manufacturer\\\": \\\"freebsd\\\", \\\"name\\\": \\\"FreeBSD   \n         lpd缓冲区错误漏洞\\\", \\\"note\\\": \\\"\\\", \\\"patch_file\\\": \\\"\\\", \\\"release_date\\\": \\\"2007/7/13 0:00\\\", \\\"source\\\": \\\"cnnvd\\\", \\\"table_id\\\": 3287, \\\"update_date\\\": \\\"2007/7/13 0:00\\\",  \n         \\\"introduction\\\": \\\"FreeBSD lpd存在超长DNS主机名缓冲区溢出漏洞。\\\"}\", \"{\\\"cnnvd_number\\\": \\\"CNNVD-200912-140\\\", \\\"content_column_name\\\": \\\"content\\\", \\\"create_time\\\":            \n         \\\"2024-07-10 10:15:03\\\", \\\"created\\\": \\\"2023/11/28 19:15\\\", \\\"cve_number\\\": \\\"CVE-2009-4265\\\", \\\"file_name\\\": \\\"vulnerability.jsonl\\\", ……]}\n```\n\nHowever, after obtaining the query results from the tools, the agent analyzed and organized the information, ignoring my prompt requirements, including returning in JSON format and not adding any analytical or summarizing content. The result is as follows:\n```\n⠦ Working...DEBUG    ============== assistant ==============                                                                                                                                           \nDEBUG    Based on the queried information, here is a list of several representative CVEs and their brief introductions：                                                                                                                     \n                                                                                                                                                                                           \n         1. **CVE-2001-1093**                                                                                                                                                              \n            - Related software：Digital Unix MSGCHK                                                                                                                                                \n            - Vendor：Compaq                                                                                                                                                               \n            - description：The vulnerability exists in msgchk of Digital UNIX 4.0G and earlier versions, where there is a buffer overflow issue. Local users can exploit this vulnerability to execute arbitrary code.。                                                        \n                                                                                                                                                                                           \n         2. **CVE-2009-2460**                                                                                                                                                              \n            - XXX                                                                                                                                       \n            - XXX                                                                                                                                                              \n            - XXX。                                                                              \n                                                                                                                                                                                           \n         3.XXX                                                                                                                                                             \n                                                                       \n         The above examples demonstrate various security issues and their impacts in different software. This information can help identify potential threats in systems and take appropriate measures to mitigate or fix these issues. It is recommended to regularly update applications and patches to ensure system security.\n```\n\nThis ultimately leads to the following error when I process the agent's result.\n```\nWARNING  Failed to parse cleaned JSON: 1 validation error for SearcherOutput                                                                                                               \n           Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='Based on the queried information, ...applications and patches to ensure system security.', input_type=str]                                            \n             For further information visit https://errors.pydantic.dev/2.10/v/json_invalid      \n```\n\nHowever, when I input the prompt directly into the large model (qwen2.5:14b from ollama) used by the agent, combining the above prompt, tool query results, and user input, I get a result in JSON format as expected.\n\nSo, how should I set it up to make the `searcher` agent generate structured JSON output as I require?\n\nNote: The code itself outputs in Chinese. For convenience, I translated the results into English and included them in this issue. The large model used is Qwen 2.5:14b. The agno version is 1.1.10\n",
      "state": "closed",
      "author": "DimRgs",
      "author_type": "User",
      "created_at": "2025-03-17T07:25:55Z",
      "updated_at": "2025-04-05T00:31:22Z",
      "closed_at": "2025-04-05T00:31:22Z",
      "labels": [
        "enhancement",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2433/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2433",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2433",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:42.447955",
      "comments": [
        {
          "author": "kausmeows",
          "body": "Hi @DimRgs, did  you also try passing `structured_outputs=True` during the agent invocation?\nCan you try referring this doc if it helps- https://docs.agno.com/agents/structured-output#structured-output\n\nlet me know if the issue still persists",
          "created_at": "2025-03-17T17:53:17Z"
        },
        {
          "author": "DimRgs",
          "body": "@kausmeows Thank you for your reply.\nI tried specifying `structured_outputs=True` when creating the `searcher`, as follows.\n```\nsearcher: Agent = Agent(\n        model = Ollama(\n            id=config['Ollama']['llm_model'],\n            host=config['Ollama']['generate_url'],\n        ),\n        descrip",
          "created_at": "2025-03-18T07:11:32Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-05T00:31:21Z"
        }
      ]
    },
    {
      "issue_number": 2459,
      "title": "[Bug] Tool calls not returning values depending on output string",
      "body": "# Description\nI am experiencing a really erratic, but reproducible behavior regarding tool calls with some of the models (confirmed with Gemini and Amazon Nova). I have simple tools without parameters just returning some text. Depending on some slight variation of the text, the output is either registered correctly or registered as empty by the model.\n\n## Steps to Reproduce\nI have a minimal reproducible example. The text is in german, but it captures the behavior. Both tools return an almost similar text, the second one just omitting the second paragraph. Now running those tools with GPT-4o works fine. With Gemini or Nova, the second tool just has an empty response {}. Funnily, if you remove the first paragraph instead, it also yields a proper response, so it cannot be a problem with a weird token or such. Just the combination of both paragraphs fail.\n\n```python\nfrom agno.models.openrouter.openrouter import OpenRouter\nfrom agno.agent.agent import Agent\nfrom textwrap import dedent\nfrom dotenv import load_dotenv\nload_dotenv(\".env\")\n\ndef tool1() -> str:\n    \"\"\"\n    Get some text.\n    \"\"\"\n    return dedent(\"\"\"\n„(1) Ein Zentralverwahrer ermittelt Quellen des internen und externen operationellen Risikos und hält deren Auswirkungen durch den Einsatz angemessener IKT-Tools, Verfahren und Strategien, die gemäß der Verordnung (EU) 2022/2554 des Europäischen Parlaments und des Rates (*3) eingerichtet und verwaltet werden, sowie durch alle anderen relevanten angemessenen Instrumente, Kontrollen und Verfahren für andere Arten operationeller Risiken, auch für alle von ihm betriebenen Wertpapierliefer- und -abrechnungssysteme, so gering wie möglich.\n(*3) Verordnung (EU) 2022/2554 des Europäischen Parlaments und des Rates vom 14. Dezember 2022 über die digitale operationale Resilienz im Finanzsektor und zur Änderung der Verordnungen (EG) Nr. 1060/2009, (EU) Nr. 648/2012, (EU) Nr. 600/2014, (EU) Nr. 909/2014 und (EU) 2016/1011 (ABl. L 333 vom 27.12.2022, S. 1).“\"\n\n2. Absatz 2 wird gestrichen\n\"\"\")\n\ndef tool2() -> str:\n    \"\"\"\n    Get some text.\n    \"\"\"\n    return dedent(\"\"\"\"\n„(1) Ein Zentralverwahrer ermittelt Quellen des internen und externen operationellen Risikos und hält deren Auswirkungen durch den Einsatz angemessener IKT-Tools, Verfahren und Strategien, die gemäß der Verordnung (EU) 2022/2554 des Europäischen Parlaments und des Rates (*3) eingerichtet und verwaltet werden, sowie durch alle anderen relevanten angemessenen Instrumente, Kontrollen und Verfahren für andere Arten operationeller Risiken, auch für alle von ihm betriebenen Wertpapierliefer- und -abrechnungssysteme, so gering wie möglich.\n(*3) Verordnung (EU) 2022/2554 des Europäischen Parlaments und des Rates vom 14. Dezember 2022 über die digitale operationale Resilienz im Finanzsektor und zur Änderung der Verordnungen (EG) Nr. 1060/2009, (EU) Nr. 648/2012, (EU) Nr. 600/2014, (EU) Nr. 909/2014 und (EU) 2016/1011 (ABl. L 333 vom 27.12.2022, S. 1).“\"\n\"\"\")\n\n# OpenAI can handle both tools\nagent = Agent(\n        debug_mode=False,\n        name=\"ToolAgent\",\n        description=\"You are an agent and can call tools.\",\n        model=OpenRouter(id=\"gpt-4o\", temperature=1),\n        markdown=True,\n        tools=[\n            tool1, tool2\n        ],\n        show_tool_calls=True\n        )\nagent.print_response(\"Run two tools and return their values\", stream=True)\n\n# This one works with Gemini\nagent = Agent(\n        debug_mode=False,\n        name=\"ToolAgent\",\n        description=\"You are an agent and can call tools.\",\n        model=OpenRouter(id=\"google/gemini-2.0-flash-001\", temperature=1),\n        markdown=True,\n        tools=[\n            tool2  # running tool2 only\n        ],\n        show_tool_calls=True\n        )\nagent.print_response(\"Run tool and return value\", stream=True)\n\n# This one fails with Gemini (tool returns {})\nagent = Agent(\n        debug_mode=False,\n        name=\"ToolAgent\",\n        description=\"You are an agent and can call tools.\",\n        model=OpenRouter(id=\"google/gemini-2.0-flash-001\", temperature=1),\n        markdown=True,\n        tools=[\n            tool1 # running tool1 only\n        ],\n        show_tool_calls=True\n        )\nagent.print_response(\"Run tool and return value\", stream=True)\n```\n## Expected Behavior\nI expect both tool calls to properly return their values so the model can work with it.\n\n## Actual Behavior\nOnly tool2 returns a value. Tool1 returns {}.\n\n## Screenshots or Logs (if applicable)\n\n<img width=\"1976\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/dba46003-9909-4e9a-bef8-72ab21ded42f\" />\n\n## Environment\n- OS: macOS\n- Agno Version: 1.1.13\n- Additional Environment Details: Python 3.11.11\n\n",
      "state": "closed",
      "author": "MartinHanewald",
      "author_type": "User",
      "created_at": "2025-03-19T19:41:28Z",
      "updated_at": "2025-04-05T00:31:20Z",
      "closed_at": "2025-04-05T00:31:20Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2459/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2459",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2459",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:42.656253",
      "comments": [
        {
          "author": "MartinHanewald",
          "body": "Ok, I now accidentally found a workaround for the problem. If I wrap the failing text in a dict with key \"result\" and dump it as json it works.\n\n```python\ndef tool1() -> dict:\n    \"\"\"\n    Get some text.\n    \"\"\"\n    return json.dumps({\"result\":dedent(\"\"\"\n„(1) Ein Zentralverwahrer ermittelt Quellen de",
          "created_at": "2025-03-19T20:04:08Z"
        },
        {
          "author": "ysolanky",
          "body": "Hello @MartinHanewald ! This is really odd. Since the tools are returning a string it should work with any model that supports function calling. I was not able to replicate your error either. Here is the output of an Agent with Gemini and tool1:\n\n![Image](https://github.com/user-attachments/assets/0",
          "created_at": "2025-03-20T20:22:52Z"
        },
        {
          "author": "MartinHanewald",
          "body": "Wow, that really is weird, @ysolanky. Have you used the same version of Gemini?",
          "created_at": "2025-03-20T20:32:46Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@MartinHanewald I was able to reproduce with your exact example. I can confirm we are definitely sending the result to OpenRouter and the response that comes back after the tool call is the actual string `{}`. So that is how OpenRouter responds... it is either them or the model, but I agree that is ",
          "created_at": "2025-03-21T07:23:11Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-05T00:31:19Z"
        }
      ]
    },
    {
      "issue_number": 2474,
      "title": "[Feature Request]Is there an offline version of Playground available? Can't I verify successfully here, or is there any alternative solution?",
      "body": "## Problem Description\n\n**Is there an offline version of Playground available? Can't I verify successfully here, or is there any alternative solution?*\n\n\n",
      "state": "closed",
      "author": "ruidanwang",
      "author_type": "User",
      "created_at": "2025-03-21T00:34:59Z",
      "updated_at": "2025-04-05T00:31:19Z",
      "closed_at": "2025-04-05T00:31:19Z",
      "labels": [
        "enhancement",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2474/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2474",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2474",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:42.922646",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hi @ruidanwang,\nThank you for using Agno and reaching out\nWe are going to release this super soon, like super soon. \n\n",
          "created_at": "2025-03-21T01:43:53Z"
        },
        {
          "author": "ruidanwang",
          "body": "I'm looking forward to ...",
          "created_at": "2025-03-21T02:03:54Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-05T00:31:18Z"
        }
      ]
    },
    {
      "issue_number": 2606,
      "title": "Documentation Error: Incorrect Docker Command for PgVector",
      "body": "# Description\nBriefly describe the issue you’re experiencing or the bug you’ve found.\n\nThe documentation should provide the correct Docker command to run the PgVector container, which is `agnohg/pgvector`.\n\nThe documentation currently shows the following incorrect Docker command:\n\nhttps://docs.agno.com/agents/knowledge\n\n![Image](https://github.com/user-attachments/assets/e247ec9b-f95c-4d32-b2fb-19e4660e625c)\n\n\n",
      "state": "closed",
      "author": "prathamskk",
      "author_type": "User",
      "created_at": "2025-03-29T15:57:39Z",
      "updated_at": "2025-04-04T23:27:40Z",
      "closed_at": "2025-04-04T23:27:40Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2606/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2606",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2606",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:43.163305",
      "comments": [
        {
          "author": "kausmeows",
          "body": "hi @prathamskk What is wrong in the command?\nWorks for me\n\n<img width=\"1061\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/ba3d0138-dd8a-4abb-9539-5b75b5696991\" />",
          "created_at": "2025-03-30T14:10:27Z"
        },
        {
          "author": "prathamskk",
          "body": "@kausmeows  yeah you used the correct one \n\ni was pointing out that in the documentation its mentioned \"agno\" and not \"agnohg\"\n\nhttps://docs.agno.com/agents/knowledge\n\n![Image](https://github.com/user-attachments/assets/7da70d0d-9f33-46ef-933b-cb2b2446b6e5)",
          "created_at": "2025-03-30T14:56:11Z"
        },
        {
          "author": "willemcdejongh",
          "body": "Hi @prathamskk \n\nThanks for raising. We will update the docs accordingly.",
          "created_at": "2025-03-31T06:19:02Z"
        }
      ]
    },
    {
      "issue_number": 2623,
      "title": "[Bug] TeamMemory.__init__() got an unexpected keyword argument 'create_session_summary' - Migrations to new team pattern",
      "body": "# Description\nI was using Agent with team and it was working fine, I am migrating to the new Team (TeamAgent) pattern where I am getting unexpected behavior after few conversation. It response okay for few back and forth for the session but after few conversation (It is very random when it will happen) it throws error TeamMemory.__init__() got an unexpected keyword argument 'create_session_summary',\n\n## Steps to Reproduce\nUse new Team to create Team Agent with SQLite Storage.\n\n## Agent Configuration (if applicable)\n\n### Team config\n![Image](https://github.com/user-attachments/assets/bebda70e-0155-49a6-ad39-47d099c17e1d)\n\n### Agent Storage\n\n![Image](https://github.com/user-attachments/assets/84ee84cc-10eb-4e87-88fe-87d9d2a9eee3)\n\n## Expected Behavior\nShould response without any error.\n\n## Actual Behavior\nAfter few back and forth in conversation, it throws following error. When I enable debug mode, it does not log anything means it must had happen during the initialization of Team Agent.\n\n## Screenshots or Logs (if applicable)\n```\nINFO:app.utils.logger:Preparing team for chat room; c2cba121-84a4-4a79-9fc3-fdf3bf3a05e4\nDEBUG ********** Team ID: 2c2963b3-d417-4876-8d79-806be5b837be **********              \nDEBUG ********* Session ID: c2cba121-84a4-4a79-9fc3-fdf3bf3a05e4 ********              \n     ERROR   Exception in ASGI application\n  + Exception Group Traceback (most recent call last):\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 409, in run_asgi\n  |     result = await app(  # type: ignore[func-returns-value]\n  |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n  |     return await self.app(scope, receive, send)\n  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/fastapi/applications.py\", line 1054, in __call__\n  |     await super().__call__(scope, receive, send)\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/starlette/applications.py\", line 112, in __call__\n  |     await self.middleware_stack(scope, receive, send)\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/starlette/middleware/errors.py\", line 187, in __call__\n  |     raise exc\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n  |     await self.app(scope, receive, _send)\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n  |     await self.simple_response(scope, receive, send, request_headers=headers)\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n  |     await self.app(scope, receive, send)\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n  |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n  |     raise exc\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n  |     await app(scope, receive, sender)\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/starlette/routing.py\", line 714, in __call__\n  |     await self.middleware_stack(scope, receive, send)\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/starlette/routing.py\", line 734, in app\n  |     await route.handle(scope, receive, send)\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/starlette/routing.py\", line 288, in handle\n  |     await self.app(scope, receive, send)\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/starlette/routing.py\", line 76, in app\n  |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n  |     raise exc\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n  |     await app(scope, receive, sender)\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/starlette/routing.py\", line 74, in app\n  |     await response(scope, receive, send)\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/sse_starlette/sse.py\", line 230, in __call__\n  |     async with anyio.create_task_group() as task_group:\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 772, in __aexit__\n  |     raise BaseExceptionGroup(\n  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/sse_starlette/sse.py\", line 233, in cancel_on_finish\n    |     await coro()\n    |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/sse_starlette/sse.py\", line 154, in _stream_response\n    |     async for data in self.body_iterator:\n    |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/app/services/agents/team_agent.py\", line 228, in generate_response_stream\n    |     for response in report_stream:\n    |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/app/services/agents/team_agent.py\", line 145, in run\n    |     response_stream: Iterator[RunResponse] = self.team_agent.run(\n    |                                              ^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/agno/team/team.py\", line 448, in run\n    |     self.read_from_storage()\n    |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/agno/team/team.py\", line 4935, in read_from_storage\n    |     self.load_team_session(session=self.team_session)\n    |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/agno/team/team.py\", line 5046, in load_team_session\n    |     self.memory = TeamMemory(**self.memory)\n    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n    | TypeError: TeamMemory.__init__() got an unexpected keyword argument 'create_session_summary'\n    +------------------------------------\nERROR:uvicorn.error:Exception in ASGI application\n  + Exception Group Traceback (most recent call last):\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 409, in run_asgi\n  |     result = await app(  # type: ignore[func-returns-value]\n  |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n  |     return await self.app(scope, receive, send)\n  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/fastapi/applications.py\", line 1054, in __call__\n  |     await super().__call__(scope, receive, send)\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/starlette/applications.py\", line 112, in __call__\n  |     await self.middleware_stack(scope, receive, send)\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/starlette/middleware/errors.py\", line 187, in __call__\n  |     raise exc\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n  |     await self.app(scope, receive, _send)\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n  |     await self.simple_response(scope, receive, send, request_headers=headers)\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n  |     await self.app(scope, receive, send)\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n  |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n  |     raise exc\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n  |     await app(scope, receive, sender)\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/starlette/routing.py\", line 714, in __call__\n  |     await self.middleware_stack(scope, receive, send)\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/starlette/routing.py\", line 734, in app\n  |     await route.handle(scope, receive, send)\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/starlette/routing.py\", line 288, in handle\n  |     await self.app(scope, receive, send)\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/starlette/routing.py\", line 76, in app\n  |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n  |     raise exc\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n  |     await app(scope, receive, sender)\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/starlette/routing.py\", line 74, in app\n  |     await response(scope, receive, send)\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/sse_starlette/sse.py\", line 230, in __call__\n  |     async with anyio.create_task_group() as task_group:\n  |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 772, in __aexit__\n  |     raise BaseExceptionGroup(\n  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/sse_starlette/sse.py\", line 233, in cancel_on_finish\n    |     await coro()\n    |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/sse_starlette/sse.py\", line 154, in _stream_response\n    |     async for data in self.body_iterator:\n    |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/app/services/agents/team_agent.py\", line 228, in generate_response_stream\n    |     for response in report_stream:\n    |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/app/services/agents/team_agent.py\", line 145, in run\n    |     response_stream: Iterator[RunResponse] = self.team_agent.run(\n    |                                              ^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/agno/team/team.py\", line 448, in run\n    |     self.read_from_storage()\n    |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/agno/team/team.py\", line 4935, in read_from_storage\n    |     self.load_team_session(session=self.team_session)\n    |   File \"/home/pradeept95/azure-ai-chat/ai-chat-backend/.venv/lib/python3.12/site-packages/agno/team/team.py\", line 5046, in load_team_session\n    |     self.memory = TeamMemory(**self.memory)\n    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n    | TypeError: TeamMemory.__init__() got an unexpected keyword argument 'create_session_summary'\n    +------------------------------------\n```\n\n## Environment\n- OS: All - Linux. MacOS, Windows \n- Browser (if relevant): NA\n- Agno Version: v1.2.6\n- External Dependency Versions: (Name: SQLAlchemy Version: 2.0.40)\n- Additional Environment Details: Python 3.12.3\n\n## Possible Solutions (optional)\nNA\n\n## Additional Context\nTeam have 6 agents with respective tools. All agents have basic configuration in identical setup. Here is the one agent for ref:\n\n![Image](https://github.com/user-attachments/assets/28b4a3c0-c5b5-404b-86fa-6ed3789d1a81)\n",
      "state": "closed",
      "author": "pradeept95",
      "author_type": "User",
      "created_at": "2025-03-31T16:18:49Z",
      "updated_at": "2025-04-04T19:52:40Z",
      "closed_at": "2025-04-04T19:52:40Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2623/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kausmeows"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2623",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2623",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:43.364689",
      "comments": [
        {
          "author": "kausmeows",
          "body": "Hi @pradeept95 thanks for reaching out, would it be possible for you to share with me the exact code you are using in a github gist?\n\nSo that i can try and reproduce this at my end",
          "created_at": "2025-04-01T06:14:01Z"
        },
        {
          "author": "pradeept95",
          "body": "Hi @kausmeows, thank you for your response. I was digging little more and found I was setting session_id in both Team and Agent which causing issue. I removed those and seems everything working as expected.",
          "created_at": "2025-04-04T18:03:40Z"
        },
        {
          "author": "kausmeows",
          "body": "Nice @pradeept95 ",
          "created_at": "2025-04-04T19:52:33Z"
        }
      ]
    },
    {
      "issue_number": 2677,
      "title": "[Bug] - Jira Agno Documentation is not correct",
      "body": "# Description\nThe documentation mention a env variable that is not used on the code\n\n## Steps to Reproduce\nCheck agno documentation https://docs.agno.com/tools/toolkits/jira that mention env name  JIRA_API_TOKEN but  the jira agno tool code https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/jira.py get JIRA_TOKEN variable \n\n\n",
      "state": "closed",
      "author": "fenoloco",
      "author_type": "User",
      "created_at": "2025-04-04T13:18:53Z",
      "updated_at": "2025-04-04T16:33:47Z",
      "closed_at": "2025-04-04T16:33:30Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2677/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2677",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2677",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:43.537307",
      "comments": [
        {
          "author": "anuragts",
          "body": "Hey @fenoloco thanks for spotting the typo, we just pushed the fix in the docs.\nThanks",
          "created_at": "2025-04-04T16:33:30Z"
        }
      ]
    },
    {
      "issue_number": 2569,
      "title": "[Bug]agno.exceptions.ModelProviderError: Your request is not valid!",
      "body": "from agno.agent import Agent\nfrom agno.models.openai import OpenAIChat\n\nllm = OpenAIChat(\n    temperature=0,\n    id=\"gpt-4o\",\n    api_key=\"xxxxxxxxxxxxxxxxxxx=\",\n    base_url=\"http://10.100.100.100:30000/v1\",\n)\n\nagent = Agent(\n    model=llm,\n    description=\"You are an enthusiastic news reporter with a flair for storytelling!\",\n    markdown=True\n)\nagent.print_response(\"Tell me about a breaking news story from New York.\", stream=True)\n\n####################################################################################\n\nERROR    API status error from OpenAI API: Error code: 400 - {'error': {'message': 'Your request is not valid!', 'details': 'The      \n         following errors were detected during validation.\\n - The input field is required.\\n - Role developer not supported.\\n',     \n         'data': {}, 'validationErrors': [{'message': 'The input field is required.', 'members': ['input']}, {'message': 'Role        \n         developer not supported.', 'members': ['$.messages[0]']}]}}\n▰▰▰▰▱▱▱ Thinking...\n┏━ Message ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓┃                                                                                                                                    ┃┃ Tell me about a breaking news story from New York.                                                                                 ┃┃                                                                                                                                    ┃┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛Traceback (most recent call last):\n  File \"D:\\AIGC\\idataai_py\\venv\\Lib\\site-packages\\agno\\models\\openai\\chat.py\", line 441, in invoke_stream\n    yield from self.get_client().chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\AIGC\\idataai_py\\venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 279, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\AIGC\\idataai_py\\venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 914, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"D:\\AIGC\\idataai_py\\venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1242, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\AIGC\\idataai_py\\venv\\Lib\\site-packages\\openai\\_base_client.py\", line 919, in request\n    return self._request(\n           ^^^^^^^^^^^^^^\n  File \"D:\\AIGC\\idataai_py\\venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1023, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': 'Your request is not valid!', 'details': 'The following errors were detected during validation.\\n - The input field is required.\\n - Role developer not supported.\\n', 'data': {}, 'validationErrors': [{'message': 'The input field is required.', 'members': ['input']}, {'message': 'Role developer not supported.', 'members': ['$.messages[0]']}]}}\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"d:\\AIGC\\idataai_py\\test\\monica.py\", line 26, in <module>\n    agent.print_response(\"Tell me about a breaking news story from New York.\", stream=True)\n  File \"D:\\AIGC\\idataai_py\\venv\\Lib\\site-packages\\agno\\agent\\agent.py\", line 3692, in print_response\n    for resp in self.run(\n  File \"D:\\AIGC\\idataai_py\\venv\\Lib\\site-packages\\agno\\agent\\agent.py\", line 578, in _run\n    for model_response_chunk in self.model.response_stream(messages=run_messages.messages):\n  File \"D:\\AIGC\\idataai_py\\venv\\Lib\\site-packages\\agno\\models\\base.py\", line 500, in response_stream\n    yield from self.process_response_stream(\n  File \"D:\\AIGC\\idataai_py\\venv\\Lib\\site-packages\\agno\\models\\base.py\", line 472, in process_response_stream\n    for response_delta in self.invoke_stream(messages=messages):\n  File \"D:\\AIGC\\idataai_py\\venv\\Lib\\site-packages\\agno\\models\\openai\\chat.py\", line 476, in invoke_stream\n    raise ModelProviderError(\nagno.exceptions.ModelProviderError: Your request is not valid!",
      "state": "closed",
      "author": "Rainismer",
      "author_type": "User",
      "created_at": "2025-03-27T05:39:18Z",
      "updated_at": "2025-04-04T12:56:27Z",
      "closed_at": "2025-04-04T12:56:27Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2569/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "willemcdejongh"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2569",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2569",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:43.696361",
      "comments": [
        {
          "author": "revanthbhuvanagiri",
          "body": "Getting the same Issue I'm using the Gemini API",
          "created_at": "2025-04-02T09:48:27Z"
        },
        {
          "author": "willemcdejongh",
          "body": "Hi @Rainismer Thank you for using Agno and reaching out with your issue. \nCan you tell me more about the model URL you are using here? If this is a hosted model that supports the OpenAI protocol, it would be better to use the OpenAILike model class, instead of OpenAI. Using OpenAIChat sets the `deve",
          "created_at": "2025-04-04T06:38:10Z"
        },
        {
          "author": "Rainismer",
          "body": "@willemcdejongh I see, thank you for your reply!",
          "created_at": "2025-04-04T12:56:21Z"
        }
      ]
    },
    {
      "issue_number": 2640,
      "title": "[Bug] LiteLLM bug duplicate call Tool when using Agent",
      "body": "# Description\nDEBUG =========================== user ===========================              \nDEBUG Xin chào, cho tôi thời gian hiện tại                                      \nDEBUG ======================== assistant =========================              \nDEBUG Chào bạn,                                                                 \n                                                                                \n      Tôi sẽ kiểm tra thời gian hiện tại cho bạn.                               \nDEBUG Tool Calls:                                                               \n        - ID: 'tooluse_dD5IwDFXS6-70g_lsf9KAg'                                  \n          Name: 'get_current_time'                                              \n          Arguments: ''                                                         \n        - ID: 'tooluse_dD5IwDFXS6-70g_lsf9KAg'                                  \n          Name: 'get_current_time'                                              \n          Arguments: ''                                                         \nDEBUG ************************  METRICS  *************************              \nDEBUG * Tokens:                      input=3196, output=64, total=3260          \nDEBUG * Time:                        3.8820s                                    \nDEBUG * Tokens per second:           16.4862 tokens/s                           \nDEBUG * Time to first token:         3.1274s                                    \nDEBUG ************************  METRICS  *************************              \nDEBUG Getting function get_current_time                                         \nDEBUG Getting function get_current_time                                         \nDEBUG Running: get_current_time()                                               \nDEBUG Running: get_current_time()                                               \nDEBUG =========================== tool ===========================              \nDEBUG Tool call Id: tooluse_dD5IwDFXS6-70g_lsf9KAg                              \nDEBUG 17:26 02/04/2025, Local time zone: Asia/Ho_Chi_Minh                       \nDEBUG **********************  TOOL METRICS  **********************              \nDEBUG * Time:                        0.0007s                                    \nDEBUG **********************  TOOL METRICS  **********************              \nDEBUG =========================== tool ===========================              \nDEBUG Tool call Id: tooluse_dD5IwDFXS6-70g_lsf9KAg                              \nDEBUG 17:26 02/04/2025, Local time zone: Asia/Ho_Chi_Minh                       \nDEBUG **********************  TOOL METRICS  **********************              \nDEBUG * Time:                        0.0005s                                    \nDEBUG **********************  TOOL METRICS  **********************              \n\n# Error\nagno.exceptions.ModelProviderError: litellm.BadRequestError: BedrockException - {\"message\":\"The toolUse blocks at messages.2.content contain duplicate Ids: tooluse_dD5IwDFXS6-70g_lsf9KAg\"}. Received Model Group=bedrock-claude-3-5-sonnet-v2\n\n\n# Model\nclaude-3-5-sonnet-v2\n\n# Proxy\nLiteLLM\n\n# OS\nMac m3\n\n# Version agno: \n1.2.6\n\n# Verson LiteLLM:\n1.63.8",
      "state": "closed",
      "author": "liem-buithanh3",
      "author_type": "User",
      "created_at": "2025-04-02T10:31:40Z",
      "updated_at": "2025-04-04T04:13:58Z",
      "closed_at": "2025-04-04T04:13:57Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2640/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "kausmeows"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2640",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2640",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:43.881317",
      "comments": [
        {
          "author": "kausmeows",
          "body": "Hi @liem-buithanh3 i tried the following code with `claude 3.5 sonnet` but couldn't reproduce this error-\n```py\nfrom agno.agent import Agent\nfrom agno.models.litellm import LiteLLM\nfrom agno.tools.yfinance import YFinanceTools\n\nopenai_agent = Agent(\n    model=LiteLLM(\n        id=\"claude-3-5-sonnet-2",
          "created_at": "2025-04-03T07:25:29Z"
        },
        {
          "author": "liem-buithanh3",
          "body": "Hi @kausmeows, here is my code:\n\n# Code\n```\nfrom agno.agent import Agent\nfrom agno.models.litellm import LiteLLMOpenAI\nfrom agno.tools.yfinance import YFinanceTools\nfrom tools import SMETools\n\n\nopenai_agent = Agent(\n    model=LiteLLMOpenAI(\n    id=\"bedrock-claude-3-5-sonnet-v2\",\n    base_url=\"http:/",
          "created_at": "2025-04-03T09:20:39Z"
        },
        {
          "author": "kausmeows",
          "body": "Hey @liem-buithanh3 i dont have a key for `bedrock-claude-3-5-sonnet-v2` but i tested it with `claude-3-5-sonnet-20241022`, here's how you can do it.\n\nfollowing this doc, first you have to start a proxy server for that given model-id.\nhttps://docs.agno.com/models/litellm_openai\n\nLike this-\n```bas\nli",
          "created_at": "2025-04-03T10:13:05Z"
        },
        {
          "author": "liem-buithanh3",
          "body": "Hi @kausmeows, can you give me versions using:\n- Agno\n- LiteLLM",
          "created_at": "2025-04-03T10:27:15Z"
        },
        {
          "author": "kausmeows",
          "body": "> Hi [@kausmeows](https://github.com/kausmeows), can you give me versions using:\n> \n> * Agno\n> * LiteLLM\n\njust do `pip install -U agno` - 1.2.6 or 1.2.7 should be fine\nand also do `pip install 'litellm[proxy]'`\nLiteLLM: Current Version = 1.63.14\n\nhttps://docs.agno.com/models/litellm_openai - should ",
          "created_at": "2025-04-03T10:33:46Z"
        }
      ]
    },
    {
      "issue_number": 2642,
      "title": "[Bug] created_at field is NULL when creating workflow session",
      "body": "# Description  \nWhen a workflow session is created and stored in the database, the `created_at` field is set to `NULL` and never updated. However, the `updated_at` field is correctly populated at the end of the workflow.\n\n## Steps to Reproduce  \n1. Run a workflow.  \n2. After completion, check the database entry for the workflow session.  \n3. Observe that the `created_at` value is `NULL`.\n\n## Expected Behavior  \nThe `created_at` field should be populated with the correct timestamp when the workflow session is created.\n\n## Actual Behavior  \nThe `created_at` field remains `NULL` after the workflow is completed.\n\n## Environment  \n- OS: macOS  \n- Agno Version: 1.2.6  \n- Python Version: 3.11.11\n",
      "state": "closed",
      "author": "NTTLuke",
      "author_type": "User",
      "created_at": "2025-04-02T13:11:50Z",
      "updated_at": "2025-04-03T12:54:39Z",
      "closed_at": "2025-04-03T12:54:38Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2642/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2642",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2642",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:44.097856",
      "comments": [
        {
          "author": "mishramonalisha76",
          "body": "Hi @NTTLuke Thanks for sharing the issue . \nI was not able to replicate this issue on my end , I got the data for created_at for a workflow session . \nCan you please check with the latest version of the [sdk](https://github.com/agno-agi/agno/releases/tag/v1.2.7) ?\n",
          "created_at": "2025-04-03T07:31:26Z"
        },
        {
          "author": "NTTLuke",
          "body": "Even when using version 1.2.7 I'm still experiencing the same issue. I'll investigate further and provide more information about this. ",
          "created_at": "2025-04-03T12:22:35Z"
        },
        {
          "author": "NTTLuke",
          "body": "Found the issue .. my mistake. ",
          "created_at": "2025-04-03T12:54:38Z"
        }
      ]
    },
    {
      "issue_number": 2611,
      "title": "When using groq in Team coordinate mode, groq.BadRequestError: Error code: 400 often occurs",
      "body": "# Description\nWhen using groq in Team coordinate mode, groq.BadRequestError: Error code: 400 often occurs\n\n## Steps to Reproduce\n`task = \"Tell me something about ThaiRecipes.pdf from knowledge base\" \nagent_team.print_response(task , stream=False)\n`\n\n## Agent Configuration (if applicable)\nagno==1.2.6\nmodel=Groq(id='qwen-qwq-32b',timeout=60)\ntask = \"Tell me something about ThaiRecipes.pdf from knowledge base\"\n\n## Expected Behavior\nNo 400 errors occur at any time\n\n## Actual Behavior\nagno.exceptions.ModelProviderError: {\"error\":{\"message\":\"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\",\"type\":\"invalid_request_error\",\"code\":\"tool_u\nse_failed\",\"failed_generation\":\"\\u003ctool_call\\u003e\\n{\\\"name\\\": \\\"transfer_task_to_member\\\", \\\"arguments\\\": \\\"{\\\\\\\"agent_name\\\\\\\": \\\\\\\"Knowledge Agent\\\\\\\", \\\\\\\"task_description\\\\\\\": \\\\\\\"Retrieve information about ThaiRecipes.pdf from the knowledge base\\\\\\\", \\\\\\\"expected_output\\\\\\\": \\\\\\\"Content summary or key details contained in the ThaiRecipes.pdf document.\\\\\\\"}\\\"}\\n\\u003c/tool_call\\u003e\"}} \n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- OS: (e.g. macOS, Windows 11)\n- Browser (if relevant): (e.g. Chrome 108, Firefox 107)\n- Agno Version: 1.2.6\n- Model provider: Groq\n- Model:qwen-qwq-32b\n- Python 3.13\n\n## Possible Solutions (optional)\n\nPrompt will induce the model to generate forged tools to call the structure into the content field,\n\n## Additional Context\nI hope this problem can be solved. Thanks for your contribution to the open source project.\n",
      "state": "closed",
      "author": "tangmingcheng",
      "author_type": "User",
      "created_at": "2025-03-30T11:37:52Z",
      "updated_at": "2025-04-03T09:38:28Z",
      "closed_at": "2025-04-03T09:38:28Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2611/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "dirkbrnd"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2611",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2611",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:44.280038",
      "comments": [
        {
          "author": "willemcdejongh",
          "body": "Hi @tangmingcheng Thank you for using Agno!\nUnfortunately this can happen with Groq. We can recommend to either use `exponential_backoff` on the agent to see if that mitigates the issue or trying another model that might be better at tool calling.",
          "created_at": "2025-03-31T14:14:19Z"
        },
        {
          "author": "tangmingcheng",
          "body": "I switched to the GPT-4O model and the problem no longer exists",
          "created_at": "2025-04-01T13:01:57Z"
        }
      ]
    },
    {
      "issue_number": 2291,
      "title": "[Bug]",
      "body": "# Description\nWhen loading PDF documents containing mathematical formulas into the knowledge base, agno's PDF processing fails to handle Unicode surrogate characters, resulting in UnicodeEncodeError exceptions at multiple points in the processing pipeline.\n\n## Steps to Reproduce\n\n1. Create a PDFKnowledgeBase with a PgVector\n2. Add PDFs containing mathematical formulas or special symbols\n3. Call the knowledge_base.load() method\n4. Observe the encoding errors during document processing\n\n## Agent Configuration (if applicable)\n\n```\nfrom agno.knowledge.pdf import PDFKnowledgeBase\nfrom agno.vectordb.pgvector import PgVector\nfrom agno.agent import Agent\nfrom agno.models.openai import OpenAIChat\n\ndl_knowledge_base = PDFKnowledgeBase(\n    path=\"data/pdf/deep_learning\",\n    vector_db=PgVector(\n        table_name=\"pdf_documents\",\n        db_url=os.getenv(\"VECTOR_DB_URI\"),\n    ),\n)\n\nagent = Agent(\n    name=\"My Agent\",\n    model=OpenAIChat(\"gpt-4o\"),\n    knowledge=dl_knowledge_base,\n    search_knowledge=True,\n)\nagent.knowledge.load(recreate=False) \n```\n## Expected Behavior\nThe PDFs containing mathematical symbols and formulas should be loaded into the knowledge base without encoding errors, properly handling any Unicode characters.\n\n## Actual Behavior\nLoading fails with multiple Unicode encoding errors:\n\n## Screenshots or Logs (if applicable)\n```\nINFO     Loading knowledge base                                                \nINFO     Reading: Deep Learning from Scratch                                   \nTraceback (most recent call last):\n  File \"C:\\Users\\DELL\\Desktop\\work_projects\\________\\main.py\", line 6, in <module>\n    from router import prep_router,dashboard_router,chat_router\n  File \"C:\\Users\\DELL\\Desktop\\work_projects\\________\\router\\__init__.py\", line 3, in <module>\n    from .chat import chat_router\n  File \"C:\\Users\\DELL\\Desktop\\work_projects\\________\\router\\chat.py\", line 3, in <module>\n    from core.chat_core import chat_core\n  File \"C:\\Users\\DELL\\Desktop\\work_projects\\________\\core\\chat_core.py\", line 53, in <module>\n    One_gate_agent.knowledge.load(recreate=False)\n  File \"C:\\Users\\DELL\\Desktop\\work_projects\\________\\venv\\Lib\\site-packages\\agno\\knowledge\\agent.py\", line 101, in load\n    if doc.content not in seen_content and not self.vector_db.doc_exists(doc):\n                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\DELL\\Desktop\\work_projects\\________\\venv\\Lib\\site-packages\\agno\\vectordb\\pgvector\\pgvector.py\", line 237, in doc_exists\n    content_hash = md5(cleaned_content.encode()).hexdigest()\n                       ^^^^^^^^^^^^^^^^^^^^^^^^\nUnicodeEncodeError: 'utf-8' codec can't encode character '\\ud835' in position 879: surrogates not allowed\n\n```\n## Environment\n\n- OS: Windows\n- Agno Version: 1.1.8\n- External Dependencies: none\n- Additional Environment Details: Python 3.11\n\n## Possible Solutions (optional)\nThe doc_exists method in PgVector currently only handles null bytes but not Unicode surrogate characters. It could be improved by adding exception handling for UnicodeEncodeError\n\n## Additional Context\nnone",
      "state": "closed",
      "author": "tariksghiouri",
      "author_type": "User",
      "created_at": "2025-03-05T11:14:31Z",
      "updated_at": "2025-04-03T00:31:45Z",
      "closed_at": "2025-04-03T00:31:45Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2291/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2291",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2291",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:44.462990",
      "comments": [
        {
          "author": "mishramonalisha76",
          "body": "Hi @tariksghiouri , Thanks for reaching out .\nUnfortunately, I was unable to replicate the issue on my end , Is it possible to send the pdf you are using , so that I can check the issue?",
          "created_at": "2025-03-19T09:04:45Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-03T00:31:44Z"
        }
      ]
    },
    {
      "issue_number": 2410,
      "title": "[Feature Request] How to create a team with agents including mcp-tooled agents",
      "body": "Hello.\n\nIs it possible to create a team of agents with some of them been mcp-tooled ?\n\nDoes the inherent and specific mcp tools mechanism (ClientSession, StdioServerParameters, mcp.client.stdio import stdio_client) prevents the creation / execution of a hybrid (mcp tools / non mcp tools) team of agents ?\n\nMaybe only possible through workflows ?\n\nIf not, could you provide an example on how to do that ?\n\n\n\nThanks a lot !\nRegards\n\n",
      "state": "closed",
      "author": "jmtemmos",
      "author_type": "User",
      "created_at": "2025-03-14T11:42:39Z",
      "updated_at": "2025-04-03T00:31:43Z",
      "closed_at": "2025-04-03T00:31:43Z",
      "labels": [
        "enhancement",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2410/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2410",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2410",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:44.696193",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Hi @jmtemmos \nNo it should be perfectly possible. You can instantiate a specific member agent with the MCP tools, while the others doesn't need to have it.",
          "created_at": "2025-03-19T09:43:07Z"
        },
        {
          "author": "jmtemmos",
          "body": "> Hi [@jmtemmos](https://github.com/jmtemmos) No it should be perfectly possible. You can instantiate a specific member agent with the MCP tools, while the others doesn't need to have it.\n\nThanks, but it seams no trivial because of the required following part for mcp :\n```    async with stdio_client",
          "created_at": "2025-03-19T16:29:37Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-03T00:31:42Z"
        }
      ]
    },
    {
      "issue_number": 2429,
      "title": "[Bug] in https://docs.agno.com/examples/workflows/startup-idea-validator \"STARTUP IDEA VALIDATOR\"",
      "body": "   Bug Report:\n   \n   1. Library Version Conflict:\n   - agno.tools.googlesearch is using deprecated/changed parameters\n   - Affected parameters: 'num_results' (should be 'num') and 'advanced'\n   \n   2. Current Workaround:\n   - Created CustomGoogleSearch class to bypass these issues\n   - Removed 'advanced' parameter\n   - Changed 'num_results' to 'num'\n   \n   3. Suggested Solutions:\n   a) Update agno.tools.googlesearch to match current googlesearch-python API\n   b) Pin googlesearch-python to a specific version (e.g., 1.0.1) that matches the tool's implementation\n   c) Document the required googlesearch-python version in dependencies\n   \n   4. Error Messages:\n   - TypeError: search() got an unexpected keyword argument 'num_results'\n   - TypeError: search() got an unexpected keyword argument 'advanced'",
      "state": "closed",
      "author": "Shivam909058",
      "author_type": "User",
      "created_at": "2025-03-17T05:13:28Z",
      "updated_at": "2025-04-03T00:31:42Z",
      "closed_at": "2025-04-03T00:31:41Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2429/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2429",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2429",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:44.869685",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "1. The version of `googlesearch-python` I am using has `num_results`, not `num`, and `advanced` as an allowed parameter for `search`.\n\nDid you try updating `googlesearch-python` with `uv pip install -U googlesearch-python`? ",
          "created_at": "2025-03-19T11:15:38Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-03T00:31:40Z"
        }
      ]
    },
    {
      "issue_number": 1919,
      "title": "Unable to read history while using playground",
      "body": "Using version *2.7.8*.\n\nThe following is how my Playground is setup.\n```\nduckDb = DuckDbTools(db_path=(\"/tmp/foo.db\"))\nagent = PythonAgent(\n    name=\"My Agent\",\n    add_datetime_to_instructions=True,\n    add_history_to_messages=True,\n    num_history_responses=3,\n    base_dir=tmp,\n    tools=[\n      duckDb\n    ],\n    description=\"...\",\n    instructions=[\n      \"Use tables to display data\",\n      \"...\"\n    ],\n    pip_install=True,\n    show_tool_calls=False,\n    markdown=True,\n    debug_mode=True\n)\n\napp = Playground(agents=[agent]).get_app()\nif __name__ == \"__main__\":\n    serve_playground_app(\"my_agent:app\", reload=True)\n```\n\nWhen invoking two consecutive messages, I see the following logs:\n```\nDEBUG    **************** METRICS END ******************                                                                             \nDEBUG    ---------- OpenAI Async Response End ----------                                                                             \nDEBUG    Added 2 Messages to AgentMemory                                                                                             \nDEBUG    Added AgentRun to AgentMemory                                                                                               \nDEBUG    --**-- Logging Agent Run (Async)                                                                                            \nDEBUG    *********** Async Agent Run End: 05c52ccf-67da-4587-a07e-34a5d7be91fe ***********                                           \nDEBUG    AgentRunRequest: <my question> d512153f-5407-4c6f-bd20-0b2f4fc83d11 rk           \n         aa21a13c-77ec-427a-b47e-b75f43ce7f6a                                                                                        \nDEBUG    Continuing session: d512153f-5407-4c6f-bd20-0b2f4fc83d11                                                                    \nWARNING  Failed to deepcopy field: tools - cannot pickle 'PyCapsule' object                                                          \nDEBUG    *********** Agent ID: 48cd3094-4beb-4cad-b27b-f0f651a29c9a ***********                                                      \nDEBUG    *********** Session ID: d512153f-5407-4c6f-bd20-0b2f4fc83d11 ***********                                                    \nDEBUG    Debug logs enabled                                                                                                          \nDEBUG    Created new Agent: agent_id: 48cd3094-4beb-4cad-b27b-f0f651a29c9a | session_id: d512153f-5407-4c6f-bd20-0b2f4fc83d11        \nINFO:     127.0.0.1:55588 - \"POST /v1/playground/agent/run HTTP/1.1\" 200 OK\nDEBUG    *********** Async Agent Run Start: 09f69f78-e07e-45e2-830e-ea247b1e153c ***********                                         \nDEBUG    Function show_tables from duckdb_tools added to model.                                                                      \nDEBUG    Function describe_table from duckdb_tools added to model.                                                                   \nDEBUG    Function run_query from duckdb_tools added to model.                                                                        \nDEBUG    Function create_table_from_path from duckdb_tools added to model.                                                           \nDEBUG    Function summarize_table from duckdb_tools added to model.                                                                  \nDEBUG    Function save_to_file_and_run from python_tools added to model.                                                             \nDEBUG    Function pip_install_package from python_tools added to model.                                                              \nDEBUG    Function get_tool_call_history added to model.                                                                              \nDEBUG    Building the system prompt for the PythonAgent.                                                                             \nDEBUG    Getting messages from last 3 runs                                                                                           \nDEBUG    Messages from last 3 runs: 0                                                                                                \nDEBUG    ---------- OpenAI Async Response Start ----------   \n```\n\nIn the logs above, I see:\n```\nDEBUG    Added 2 Messages to AgentMemory\nDEBUG    Added AgentRun to AgentMemory\n````\nfor the first run.\nBut, for the second run, I see:\n```\nDEBUG    Getting messages from last 3 runs\nDEBUG    Messages from last 3 runs: 0\n```\n\nIs this a known issue?",
      "state": "closed",
      "author": "rk-yen",
      "author_type": "User",
      "created_at": "2025-01-29T04:12:33Z",
      "updated_at": "2025-04-02T10:23:38Z",
      "closed_at": "2025-02-21T07:06:02Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/1919/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/1919",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/1919",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:45.067167",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @rk-yen No, this is not a known issue, starting today, we have rebranded to Agno. The new library includes a number of improvements. Can you [please migrate](https://docs.agno.com/how-to/phidata-to-agno) your code to Agno and then try again. Thank you!",
          "created_at": "2025-01-31T00:35:01Z"
        },
        {
          "author": "rk-yen",
          "body": "@ysolanky ... I migrated to agno. And, see similar behavior.\n```\nDEBUG    ---------- OpenAI Async Response End ----------                                                                     \nDEBUG    ---------- OpenAI Async Response End ----------                                                     ",
          "created_at": "2025-01-31T05:24:10Z"
        },
        {
          "author": "rk-yen",
          "body": "@ysolanky ... any thoughts here?",
          "created_at": "2025-02-03T11:22:54Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@rk-yen I'm sorry to ask you to upgrade again, but I just tested on our latest version (1.1.0) and could not replicate the issue using your code from above. I asked the agent to write some python code and then to run it. Perhaps share what prompts you were trying?",
          "created_at": "2025-02-12T20:28:01Z"
        },
        {
          "author": "manthanguptaa",
          "body": "Closing this issue due to inactivity",
          "created_at": "2025-02-21T07:06:02Z"
        }
      ]
    },
    {
      "issue_number": 2601,
      "title": "Groq Agent with Tools  Example (Same as in docs) having inconsistent behaviour",
      "body": "# Description\nThe exact example given for Groq Agent with tools is not wroking properly .\nGetting some unexpected errors.\n\n## Steps to Reproduce\nCopy the example given on the following page \nhttps://docs.agno.com/examples/models/groq/tool_use\n```py\n\nfrom agno.agent import Agent\nfrom agno.models.groq import Groq\nfrom agno.tools.duckduckgo import DuckDuckGoTools\nfrom agno.tools.newspaper4k import Newspaper4kTools\n\nagent = Agent(\n    model=Groq(id=\"llama-3.3-70b-versatile\"),\n    tools=[DuckDuckGoTools(), Newspaper4kTools()],\n    description=\"You are a senior NYT researcher writing an article on a topic.\",\n    instructions=[\n        \"For a given topic, search for the top 5 links.\",\n        \"Then read each URL and extract the article text, if a URL isn't available, ignore it.\",\n        \"Analyse and prepare an NYT worthy article based on the information.\",\n    ],\n    markdown=True,\n    show_tool_calls=True,\n    add_datetime_to_instructions=True,\n)\nagent.print_response(\"Simulation theory\", stream=True)\n(\n```\n\n## Agent Configuration (if applicable)\n```py\nagent = Agent(\n    model=Groq(id=\"llama-3.3-70b-versatile\"),\n    tools=[DuckDuckGoTools(), Newspaper4kTools()],\n    description=\"You are a senior NYT researcher writing an article on a topic.\",\n    instructions=[\n        \"For a given topic, search for the top 5 links.\",\n        \"Then read each URL and extract the article text, if a URL isn't available, ignore it.\",\n        \"Analyse and prepare an NYT worthy article based on the information.\",\n    ],\n    markdown=True,\n    show_tool_calls=True,\n    add_datetime_to_instructions=True,\n)\nagent.print_response(\"Simulation theory\", stream=True)\n\n```\n\n## Expected Behavior\nOutput should be an article on particluar topic.\n\n## Actual Behavior\n```bash\ngroq.APIError: Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\n```\n\n\n## Screenshots or Logs (if applicable)\n\n![Image](https://github.com/user-attachments/assets/1e868430-c2d2-4f07-8cbb-b3abd639a6b9)\n\n## Environment\n```bash\nOS: Linux 6.8.0-56-generic\nPython Version: 3.12.3\ngroq==0.20.0\nduckduckgo-search==7.5.5\nnewspaper4k==0.9.3.1\nlxml-html-clean==0.4.1\nagno==1.2.6\n```\n## Possible Solutions (optional)\n\n## Additional Context\nI tried other examples mentioned in groq such as \"with structured output\" one, it worked perfectly.\nSo maybe there's some issue with Tool calling.  ",
      "state": "closed",
      "author": "Ansumanbhujabal",
      "author_type": "User",
      "created_at": "2025-03-29T10:54:53Z",
      "updated_at": "2025-04-01T17:09:53Z",
      "closed_at": "2025-04-01T17:05:54Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2601/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2601",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2601",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:45.263506",
      "comments": [
        {
          "author": "willemcdejongh",
          "body": "Hi @Ansumanbhujabal \nThanks for reaching out and using Agno!\nIt is possible that the model you are using is not handling tool calling all that well. You mentioned that you have used structured outputs and that works well. So perhaps the next debugging step would be to use the same tools, but a diffe",
          "created_at": "2025-03-31T14:36:45Z"
        },
        {
          "author": "tangmingcheng",
          "body": "You can try switching to the QWQ-32b model. It works well when adding tools with only a single agent, but I also get a 400 error when assigning tasks to it as a leader model in the team's coordinate mode. The reason is that the model puts its tool call into the content field, which causes an error w",
          "created_at": "2025-04-01T04:59:55Z"
        },
        {
          "author": "Ansumanbhujabal",
          "body": "Yes , with changed model the example works perfectly . Seems `llama-3.3-70b-versatile` is unable to handle the tool calling for the particlular example .\nWorked perfectly with \n\n```py\nmodel=Groq(id=\"llama-3.1-8b-instant\")\n```\n\nI'm raising a PR  for changing the docs for smoother learning experience ",
          "created_at": "2025-04-01T17:05:54Z"
        }
      ]
    },
    {
      "issue_number": 2620,
      "title": "[Bug] Agent when using thinking model, error [cannot access local variable 'all_reasoning_steps' where it is not associated with a value]",
      "body": "# Description\nUsing an Agent with a reasoning_model (any native reasoning model) would raise a python error\n\n> cannot access local variable 'all_reasoning_steps' where it is not associated with a value\n\n## Steps to Reproduce\n1. Creating an agent with a reasoning_model (can be of DeepSeek/deepseek-reasoner, Groq/deepseek, OpenAIChat/o3-..., OpenAILike/deepseek-r1 - the allowed native reasoning models list to not fall into the _use_default_reasoning_ category)\n2. Run the agent\n\n## Agent Configuration (if applicable)\n```\nrag = Agent(\n        model = gemini,\n        reasoning_model=deepseek,\n        reasoning=True,\n)\n```\n\n## Screenshots or Logs (if applicable)\n> cannot access local variable 'all_reasoning_steps' where it is not associated with a value\n\n## Environment\n- Agno Version: (e.g. v1.2.6)\n\n## Possible Solutions (optional)\n```\nif reasoning_model_provided:\n    ...\n# If no reasoning model is provided, use the default reasoning approach\nelse:\n    use_default_reasoning = True\n\nif use_default_reasoning:\n    ...\n   all_reasoning_steps: List[ReasoningStep] = []\n   ...\n# Yield the final reasoning completed event\nif self.stream_intermediate_steps:\n    yield self.create_run_response(\n        content=ReasoningSteps(reasoning_steps=all_reasoning_steps),\n        content_type=ReasoningSteps.__class__.__name__,\n        event=RunEvent.reasoning_completed,\n    )\n```\nThe _all_reasoning_steps_ in the final if block is out-of-scope since it is defined in the _if use_default_reasoning_ block.\npossible solution: add _if self.stream_intermediate_steps_ block back into the _if use_default_reasoning_ block\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "pvmtrang",
      "author_type": "User",
      "created_at": "2025-03-31T04:21:18Z",
      "updated_at": "2025-04-01T02:16:33Z",
      "closed_at": "2025-04-01T02:16:31Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2620/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2620",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2620",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:45.471213",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @pvmtrang ! This issue was resolved in https://github.com/agno-agi/agno/pull/2581. Can you please make sure you are on v1.2.6 by running `pip install -U agno` and then try running your Agent again?",
          "created_at": "2025-03-31T14:34:48Z"
        },
        {
          "author": "pvmtrang",
          "body": "Oh it's my fault, maybe it wasn't updated correctly. I see it now. Thanks for your time!!!",
          "created_at": "2025-04-01T02:16:31Z"
        }
      ]
    },
    {
      "issue_number": 2384,
      "title": "[Bug] Ollama : can't get reproductible results",
      "body": "# Description\nWhen trying to run example code, without 'show_tool_calls', the LLM output is about its capability to perform this task for me.\n\n## Steps to Reproduce\n```python\nfrom agno.agent import Agent\nfrom agno.models.ollama import Ollama\nfrom agno.tools.duckduckgo import DuckDuckGoTools\nfrom ollama import Client\nimport os\n\nos.environ[\"AGNO_TELEMETRY\"]  = str(False)\n\nollama_sync_client = Client(\n    host    = OLLAMA_BASE_URL,\n    headers = {\n        'temperature': '0',\n        'seed': '1234567890'\n    }\n)\n\ndef query_agno_tools(query:str, model:str):\n    agent = Agent(\n        model                 = OllamaTools(id=model, client=ollama_sync_client),\n        tools                 = [AgnoGetWeatherTool()],\n        name                  = 'Agno_Weather_Agent',\n        agent_id              = '123123',\n        #memory                = \"\",\n        markdown              = True,\n        show_tool_calls       = True,\n        exponential_backoff   = True,\n        retries               = 10,\n        delay_between_retries = 2,\n        read_tool_call_history= True,\n        #read_chat_history     = True,\n        debug_mode            = False,\n        add_datetime_to_instructions = True,\n        add_name_to_instructions     = True,\n        #add_history_to_messages      = True,\n        #num_history_responses        = 5,\n        description                  = \"You are a helpful assistant tasked to fetch weather informations, with the available tool.\",\n    )\n    logger.info(YELLOW + model + RESET)\n    return agent.print_response(query, markdown=True, stream=True)\n\nfor model in agno_compatible_model_list:\n    print(query_agno_tools(query, model))\n```\n\n## Screenshots or Logs (if applicable)\n\n![Image](https://github.com/user-attachments/assets/9cbfb9d6-e401-4ac9-a18b-02172eb620f9)\n\n![Image](https://github.com/user-attachments/assets/a20a6ef1-90ea-44f8-a7c4-4c155b7cc82b)\n\n## Environment\n- OS: Debian 12\n- Agno Version: 1.1.10\n- Python 3.11.2 x64\n",
      "state": "closed",
      "author": "lemassykoi",
      "author_type": "User",
      "created_at": "2025-03-13T08:12:45Z",
      "updated_at": "2025-04-01T00:37:03Z",
      "closed_at": "2025-04-01T00:37:03Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2384/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2384",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2384",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:45.684190",
      "comments": [
        {
          "author": "lemassykoi",
          "body": "this looks to be a bit random, as for the next tests, all my three calls were successful, but not for the next 3:\n\n\n![Image](https://github.com/user-attachments/assets/7dab030b-443a-469c-9035-d03c2cec55c2)\n\n\n![Image](https://github.com/user-attachments/assets/c2814349-5a2f-4e6c-ab7c-bd7bb3e3d8f5)",
          "created_at": "2025-03-13T08:14:04Z"
        },
        {
          "author": "manthanguptaa",
          "body": "Hey @lemassykoi! It's usually due to the model you are using that is hallucinating in making the tool calls. ",
          "created_at": "2025-03-13T08:34:44Z"
        },
        {
          "author": "lemassykoi",
          "body": "Thanks for answer.\n\nHow can I check to be sure? This model is one of the ones with which I have the best results with `create_react_agent` from langgraph",
          "created_at": "2025-03-13T08:44:18Z"
        },
        {
          "author": "lemassykoi",
          "body": "I'm ok to believe this is from model used, but here with the latest Phi4-mini, llm output is in japanese:\n\n![Image](https://github.com/user-attachments/assets/d2314c76-4112-42b4-88b5-4da41cb5c80c)\n\ncode used:\n\n```python\nfrom ollama import Client\nfrom agno.agent import Agent\nfrom agno.models.ollama i",
          "created_at": "2025-03-13T09:07:06Z"
        },
        {
          "author": "lemassykoi",
          "body": "with Ollama, I'm getting very bad results with almost every model (about 20).\nI can't get reproductible results, even when setting temperature and seed for Ollama client.\n\nI read [https://community.agno.com/t/ollama-lessons-learned-and-recommendations/368/8](url) and changed from `Ollama` to `Ollama",
          "created_at": "2025-03-13T11:07:23Z"
        }
      ]
    },
    {
      "issue_number": 2403,
      "title": "[Feature Request]Universal Reasoning Mode Support: Extending reasoning_mode to Support All Models with think Tags",
      "body": "## Problem Description\nCurrently, the framework's reasoning_mode feature only supports specific models (such as deepseek and groq), which severely limits users' flexibility when choosing reasoning models. Although there are many excellent reasoning models on platforms like ollama, they cannot be utilized due to framework limitations. Most reasoning models use <think></think> tags to distinguish the reasoning process, providing a unified identification method, but the existing framework fails to fully leverage this feature.\n\n## Proposed Solution\nWe propose extending the reasoning_mode functionality to a universal implementation that supports any model using <think></think> tags:\n1. Modify the existing reasoning_mode implementation to identify based on tags in model output rather than model name\n2. Add configuration options allowing users to specify custom reasoning tags (default to <think></think>)\n3. Implement a detection mechanism to automatically identify whether reasoning tags exist in model output\n4. Add specific support for Ollama models, including documentation and examples\nThis implementation will make the framework more flexible, allowing users to leverage any model that supports reasoning mode without being limited to specific providers.\n\n## Alternatives Considered\nCurrent alternatives are very limited:\n1. Use already supported deepseek or groq models, giving up other models that might be more suitable for specific tasks\n2. Manually process model output to extract reasoning processes, which requires additional code and processing logic\n3. Modify model output format to match framework expectations, but this method is inefficient and error-prone\n\n## Additional context\nMany open-source models (such as Llama, Mistral, etc. deployed through Ollama) support reasoning process output but cannot be fully utilized in the current framework. A universal solution would allow these models to integrate seamlessly with the framework, greatly expanding the range of available models.\n",
      "state": "closed",
      "author": "CrankGentleman",
      "author_type": "User",
      "created_at": "2025-03-14T01:16:10Z",
      "updated_at": "2025-04-01T00:37:01Z",
      "closed_at": "2025-04-01T00:37:01Z",
      "labels": [
        "enhancement",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2403/reactions",
        "total_count": 2,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 2,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2403",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2403",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:45.870871",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @CrankGentleman !\n\nThis is a great feature request—really appreciate the suggestion! We're getting started on it and will share an update once we make progress.",
          "created_at": "2025-03-17T05:16:38Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-04-01T00:37:00Z"
        }
      ]
    },
    {
      "issue_number": 2585,
      "title": "[Bug]  print_response for reasoning Model + response Model method fails in both streaming and non-streaming modes",
      "body": "# Description\nThe `print_response` method has two issues:\n1. In streaming mode (`stream=True`), it fails with an UnboundLocalError when trying to access the `resp` loop variable after the streaming loop completes\n2. In non-streaming mode (`stream=False`), it fails to produce any response at all\n\n\n## Steps to Reproduce\n1. Create an Agent instance with reasoning Model + response Model.\n2. Call `print_response` with `stream=True`\n3. The method fails when trying to process citations after the streaming loop\n\nThis is the code used to trigger it:\n```python\nfrom agno.agent import Agent\nfrom agno.models.groq import Groq\nfrom agno.models.ollama import Ollama\n\n\nreasoning_thing = Agent(\n    model=Ollama(id=\"llama3.1:8b-text-q8_0\"),    \n    reasoning_model=Groq(\n        id=\"deepseek-r1-distill-llama-70b\", temperature=0.6, max_tokens=1024, top_p=0.95\n    ),\n)\n\nreasoning_thing.print_response(\"9.11 and 9.9 -- which is bigger?\", stream=False)\nreasoning_thing.print_response(\"9.11 and 9.9 -- which is bigger?\", stream=True)\n```\n\n\n## Current Behavior\n- Streaming mode: Crashes with UnboundLocalError when trying to process citations\n- Non-streaming mode: Silent failure with no response\n\n## Expected Behavior\n- Streaming mode: Should properly handle responses and citations throughout and after the streaming process\n- Non-streaming mode: Should produce a complete response\n\n## Screenshots or Logs (if applicable)\n```\nTraceback (most recent call last):\n  File \"agno_playtest/reason_reason.py\", line 15, in <module>\n    reasoning_thing.print_response(\"9.11 and 9.9 -- which is bigger?\", stream=True)\n  File \"agno_playtest/.venv/lib/python3.12/site-packages/agno/agent/agent.py\", line 3805, in print_response\n    if isinstance(resp, RunResponse) and resp.citations is not None and resp.citations.urls is not None:\n                  ^^^^\nUnboundLocalError: cannot access local variable 'resp' where it is not associated with a valu\n```\n\n## Environment\n- Agno Version: 1.2.4\n- External Dependency Versions:\n  - ollama==0.4.7\n  - groq==0.20.0\n- Additional Environment Details:\n  - Python 3.12.3\n\n## Possible Solutions (optional)\nTrack the last received response in a separate variable throughout the streaming process, and use that for the final citations handling.\n\nMaybe something like (agent.py  line nr:3702) for reference:\n```\n        if isinstance(resp, RunResponse):\n            last_response = resp  # Track the last response\n            if resp.event == RunEvent.run_response:\n\n<snip>\n\n# Use last_response instead of resp after the loop\n    if (\n        last_response is not None \n        and last_response.citations is not None \n        and last_response.citations.urls is not None\n    ):\n        md_content = \"\\n\".join(\n            f\"{i + 1}. [{citation.title or citation.url}]({citation.url})\"\n            for i, citation in enumerate(last_response.citations.urls)\n            if citation.url\n        )\n```\n",
      "state": "closed",
      "author": "ivanvza",
      "author_type": "User",
      "created_at": "2025-03-28T08:12:00Z",
      "updated_at": "2025-03-31T07:43:00Z",
      "closed_at": "2025-03-31T07:43:00Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2585/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "ysolanky"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2585",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2585",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:46.091337",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @ivanvza ! I looked into it and the main issue here is that `llama3.1` refuses to return an output when provided with a previous message that includes reasoning. For example, the following agent with `qwen2.5:latest` works great.\n\n```python\nagent = Agent(\n    model=Ollama(id=\"qwen2.5:latest\"),",
          "created_at": "2025-03-28T18:39:17Z"
        }
      ]
    },
    {
      "issue_number": 2328,
      "title": "[Bug] API Connection Timeout with Agno’s Together Integration",
      "body": "# Description\nWhen deploying the Together API locally, everything works fine. However, when running Agno’s Together integration (python agent/agno/together.py), I encounter a connection timeout error. The API request fails due to an SSL handshake timeout, preventing successful communication with Together’s API.\n\n## Error Log\n\n`ERROR    API connection error from OpenAI API: Request timed out.                                                 \nWARNING  Attempt 1/1 failed: Request timed out.                                                                   \nERROR    Failed after 1 attempts. Last error using Together(meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo)          \n▰▰▰▱▱▱▱ Thinking...\n┏━ Message ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                                                                ┃\n┃ Share a 2 sentence horror story                                                                                ┃\n┃                                                                                                                ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\nTraceback (most recent call last):\n  File \"/home/xmyu/anaconda3/envs/web/lib/python3.10/site-packages/httpx/_transports/default.py\", line 101, in map_httpcore_exceptions\n    yield\n  File \"/home/xmyu/anaconda3/envs/web/lib/python3.10/site-packages/httpx/_transports/default.py\", line 250, in handle_request\n    resp = self._pool.handle_request(req)\n  File \"/home/xmyu/anaconda3/envs/web/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py\", line 256, in handle_request\n    raise exc from None\n  File \"/home/xmyu/anaconda3/envs/web/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py\", line 236, in handle_request\n    response = connection.handle_request(\n  File \"/home/xmyu/anaconda3/envs/web/lib/python3.10/site-packages/httpcore/_sync/http_proxy.py\", line 316, in handle_request\n    stream = stream.start_tls(**kwargs)\n  File \"/home/xmyu/anaconda3/envs/web/lib/python3.10/site-packages/httpcore/_sync/http11.py\", line 376, in start_tls\n    return self._stream.start_tls(ssl_context, server_hostname, timeout)\n  File \"/home/xmyu/anaconda3/envs/web/lib/python3.10/site-packages/httpcore/_backends/sync.py\", line 154, in start_tls\n    with map_exceptions(exc_map):\n  File \"/home/xmyu/anaconda3/envs/web/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/home/xmyu/anaconda3/envs/web/lib/python3.10/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ConnectTimeout: _ssl.c:990: The handshake operation timed out\n`\n## Steps to Reproduce\nSet up and run Together API locally – works fine.\nExecute the following command:\npython agent/agno/together.py\nThe request fails with a timeout error.\n\n## Expected Behavior\nThe API request should complete successfully without timing out.",
      "state": "closed",
      "author": "Stardust-y",
      "author_type": "User",
      "created_at": "2025-03-08T06:19:01Z",
      "updated_at": "2025-03-31T00:34:17Z",
      "closed_at": "2025-03-31T00:34:17Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2328/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2328",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2328",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:46.296049",
      "comments": [
        {
          "author": "manthanguptaa",
          "body": "Hey @Stardust-y! I tried running this cookbook https://github.com/agno-agi/agno/blob/main/cookbook/models/together/basic.py and wasn't able to replicate the issue. Can you share your code so that I can try to replicate it on my end?",
          "created_at": "2025-03-16T16:26:58Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-03-31T00:34:16Z"
        }
      ]
    },
    {
      "issue_number": 2332,
      "title": "knowledge questions",
      "body": "The data has been stored in the vector database when it is used for the first time. When the agent is created later, is it possible to only pass the ID in the vector database for retrieval without passing the file?",
      "state": "closed",
      "author": "ljj314zz",
      "author_type": "User",
      "created_at": "2025-03-08T15:07:12Z",
      "updated_at": "2025-03-31T00:34:15Z",
      "closed_at": "2025-03-31T00:34:15Z",
      "labels": [
        "stale"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2332/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2332",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2332",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:46.480898",
      "comments": [
        {
          "author": "manthanguptaa",
          "body": "Hey @ljj314zz! I didn't understand your question. Can you please explain a little more on what you are trying to achieve?",
          "created_at": "2025-03-16T16:23:06Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-03-31T00:34:14Z"
        }
      ]
    },
    {
      "issue_number": 2418,
      "title": "[Bug]issue with the cal.com",
      "body": "# Description\nIn cal.com i cannot set my event id so i could not make a booking \nso someone help me to find out it \nthis is my https://github.com/senthilkumaranT/AGNO \n",
      "state": "closed",
      "author": "senthilkumaranT",
      "author_type": "User",
      "created_at": "2025-03-14T18:28:19Z",
      "updated_at": "2025-03-31T00:34:12Z",
      "closed_at": "2025-03-31T00:34:12Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2418/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2418",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2418",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:46.667683",
      "comments": [
        {
          "author": "manthanguptaa",
          "body": "Hey @senthilkumaranT! Did you follow the steps mentioned in this doc?\nhttps://docs.agno.com/tools/toolkits/calcom",
          "created_at": "2025-03-16T16:08:01Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-03-31T00:34:11Z"
        }
      ]
    },
    {
      "issue_number": 2613,
      "title": "[Bug] Can not make mcp example works",
      "body": "# Description\nI tried mcp examples in the cookbook but none of them works\n\n## Steps to Reproduce\ncd agno/cookbook/tools/mcp\npython filesystem.py\n\noutput:\ncommand not found: [path]\n\n\n## Environment\n- OS: Ubuntu20.04\n- Agno Version: 1.2.5\n",
      "state": "closed",
      "author": "vankhoa21991",
      "author_type": "User",
      "created_at": "2025-03-30T13:10:18Z",
      "updated_at": "2025-03-30T17:02:39Z",
      "closed_at": "2025-03-30T17:02:39Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2613/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2613",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2613",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:46.882057",
      "comments": [
        {
          "author": "kausmeows",
          "body": "Hi @vankhoa21991 thanks for trying Agno, can you provide the exact error that you got on the terminal, maybe a screenshot or something.\n- did you make a seperate python virtual environment and ran the file inside that?\n- `output:\ncommand not found: [path]` what command is not found? did the terminal",
          "created_at": "2025-03-30T14:03:54Z"
        },
        {
          "author": "vankhoa21991",
          "body": "Yes, the script is run in a virtualenv, looks like it stuck at await mcp_tools.initialize(). It only shows command not found in the terminal",
          "created_at": "2025-03-30T14:07:14Z"
        },
        {
          "author": "vankhoa21991",
          "body": "![Image](https://github.com/user-attachments/assets/572f3941-1f1a-407d-9d7e-bd7b8641ddd5)\nIt doesn't exist the script also.",
          "created_at": "2025-03-30T14:09:31Z"
        },
        {
          "author": "kausmeows",
          "body": "@vankhoa21991 i tested, cannot reproduce the error. Are you inside the agno folder here?\ncan you make sure you have the file\n`ls -la cookbook/tools/mcp/filesystem.py`\n\nIf you are in some other folder, copy paste the content of `filesystem.py` into a fresh file let's say `test.py`\nand run-\n```py\npyth",
          "created_at": "2025-03-30T14:18:02Z"
        },
        {
          "author": "vankhoa21991",
          "body": "Yes I have that file:\n\"\"\"📁 MCP Filesystem Agent - Your Personal File Explorer!\n\nThis example shows how to create a filesystem agent that uses MCP to explore,\nanalyze, and provide insights about files and directories. The agent leverages the Model\nContext Protocol (MCP) to interact with the filesyste",
          "created_at": "2025-03-30T14:31:02Z"
        }
      ]
    },
    {
      "issue_number": 2531,
      "title": "[Bug] Team with mode=\"route\" is getting into an infinite loop with tool call get_team_history",
      "body": "# Description\nTeam with mode=\"route\" is getting into an infinite loop with tool call get_team_history\n\n## Steps to Reproduce\nsend  a hi and it will loop infinitely \n\n## Agent Configuration (if applicable)\nTeam(\n        name=\"xxx\",\n        model=azure_model,\n        mode=\"route\",\n        members=[tool1,tool2,tool3],\n        show_members_responses=True,\n        enable_agentic_context=True,\n        share_member_interactions=True,\n        session_id= session_id,\n        show_tool_calls=show_tool_calls,\n        markdown=True,\n        enable_team_history=True,\n        debug_mode=agent_debug_mode,\n        storage=storage,\n        memory=team_memory,\n        instructions = dedent(\"\"\"xxx\"\"\"),\n        description=\"\"\"xxxx\"\"\",\n        read_team_history = True,\n        telemetry=False,\n        user_id = user_id\n    )\n## Expected Behavior\nShould respond back with hello response\n\n## Actual Behavior\nno response and gets stuck in a loop\n\n## Screenshots or Logs (if applicable)\n`DEBUG ******************************************** Team ID: bee9d1b8-5652-4c3a-93b6-bd95a6a5b3a1 *********************************************\nDEBUG ******************************************* Session ID: 00b00089-968f-4c7b-91cf-a0517f70a541 *******************************************\nDEBUG Table does not exist: team_sessions\nDEBUG Creating table: team_sessions\nDEBUG Creating index: ix_team_sessions_user_id\nDEBUG Index ix_team_sessions_user_id already exists, skipping creation\nDEBUG Creating index: ix_team_sessions_agent_id\nDEBUG Index ix_team_sessions_agent_id already exists, skipping creation\nDEBUG Creating index: ix_team_sessions_team_session_id\nDEBUG Index ix_team_sessions_team_session_id already exists, skipping creation\nDEBUG Creating index: ix_team_sessions_team_id\nDEBUG Index ix_team_sessions_team_id already exists, skipping creation\nDEBUG Creating index: ix_team_sessions_team_session_id\nDEBUG Index ix_team_sessions_team_session_id already exists, skipping creation\nDEBUG Creating index: ix_team_sessions_team_id\nDEBUG Index ix_team_sessions_team_id already exists, skipping creation\nDEBUG Creating index: ix_team_sessions_user_id\nDEBUG Index ix_team_sessions_user_id already exists, skipping creation\nDEBUG Creating index: ix_team_sessions_user_id\nDEBUG Index ix_team_sessions_user_id already exists, skipping creation\nDEBUG Creating index: ix_team_sessions_team_session_id\nDEBUG Index ix_team_sessions_team_session_id already exists, skipping creation\nDEBUG Memories loaded for user: 1\nDEBUG ***************************************** Team Run Start: a6d8b55c-1a7c-4eca-af2e-1ad6a7734778 *****************************************\nDEBUG ************************************************************ Mode: 'route' *************************************************************\nDEBUG Processing tools for model\nDEBUG Included function get_team_history\nDEBUG Included function forward_task_to_member\nDEBUG --------------------------------------------------------- Azure Response Start ---------------------------------------------------------\nDEBUG --------------------------------------------------------- Model: not-provided ----------------------------------------------------------\nDEBUG ================================================================ system ================================================================\nDEBUG You are the leader of a team of AI Agents and possible Sub-Teams:\n       \n       xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n       xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n       xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n\n      <additional_information>\n      - Use markdown to format your answers.\n      </additional_information>\nDEBUG ================================================================= user =================================================================\nDEBUG hi\nDEBUG ============================================================== assistant ===============================================================\nDEBUG Tool Calls:\n        - ID: 'call_n35IGAx0OpyMhaatksnFiN9r'\n          Name: 'get_team_history'\n          Arguments: 'num_chats: 5'\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG * Tokens:                      input=987, output=16, total=1003\nDEBUG * Prompt tokens details:       {'audio_tokens': 0, 'cached_tokens': 0}\nDEBUG * Completion tokens details:   {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}\nDEBUG * Time:                        2.1406s\nDEBUG * Tokens per second:           7.4746 tokens/s\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG Getting function get_team_history\nDEBUG Running: get_team_history(num_chats=5)\nDEBUG ================================================================= tool =================================================================\nDEBUG Tool call Id: call_n35IGAx0OpyMhaatksnFiN9r\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG * Time:                        0.0028s\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG ============================================================== assistant ===============================================================\nDEBUG Tool Calls:\n        - ID: 'call_aS4sZuQCOprytkAD0qi2Hnzw'\n          Name: 'get_team_history'\n          Arguments: 'num_chats: 1'\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG * Tokens:                      input=1013, output=16, total=1029\nDEBUG * Prompt tokens details:       {'audio_tokens': 0, 'cached_tokens': 0}\nDEBUG * Completion tokens details:   {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}\nDEBUG * Time:                        0.7831s\nDEBUG * Tokens per second:           20.4325 tokens/s\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG Getting function get_team_history\nDEBUG Running: get_team_history(num_chats=1)\nDEBUG ================================================================= tool =================================================================\nDEBUG Tool call Id: call_aS4sZuQCOprytkAD0qi2Hnzw\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG * Time:                        0.0018s\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG ============================================================== assistant ===============================================================\nDEBUG Tool Calls:\n        - ID: 'call_a8ah43EgXLXEgqcyZVGyoPhR'\n          Name: 'get_team_history'\n          Arguments: 'num_chats: 1'\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG * Tokens:                      input=1039, output=16, total=1055\nDEBUG * Prompt tokens details:       {'audio_tokens': 0, 'cached_tokens': 0}\nDEBUG * Completion tokens details:   {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}\nDEBUG * Time:                        0.7408s\nDEBUG * Tokens per second:           21.5989 tokens/s\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG Getting function get_team_history\nDEBUG Running: get_team_history(num_chats=1)\nDEBUG ================================================================= tool =================================================================\nDEBUG Tool call Id: call_a8ah43EgXLXEgqcyZVGyoPhR\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG * Time:                        0.0023s\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG ============================================================== assistant ===============================================================\nDEBUG Tool Calls:\n        - ID: 'call_0TaDunz7cPyXaLKQNbswS4zL'\n          Name: 'get_team_history'\n          Arguments: 'num_chats: 1'\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG * Tokens:                      input=1065, output=16, total=1081\nDEBUG * Prompt tokens details:       {'audio_tokens': 0, 'cached_tokens': 0}\nDEBUG * Completion tokens details:   {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}\nDEBUG * Time:                        0.7664s\nDEBUG * Tokens per second:           20.8776 tokens/s\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG Getting function get_team_history\nDEBUG Running: get_team_history(num_chats=1)\nDEBUG ================================================================= tool =================================================================\nDEBUG Tool call Id: call_0TaDunz7cPyXaLKQNbswS4zL\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG * Time:                        0.0031s\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG ============================================================== assistant ===============================================================\nDEBUG Tool Calls:\n        - ID: 'call_4yKBT6C731cMSgNJ8ZHyzOPi'\n          Name: 'get_team_history'\n          Arguments: 'num_chats: 1'\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG * Tokens:                      input=1091, output=16, total=1107\nDEBUG * Prompt tokens details:       {'audio_tokens': 0, 'cached_tokens': 0}\nDEBUG * Completion tokens details:   {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}\nDEBUG * Time:                        1.2077s\nDEBUG * Tokens per second:           13.2482 tokens/s\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG Getting function get_team_history\nDEBUG Running: get_team_history(num_chats=1)\nDEBUG ================================================================= tool =================================================================\nDEBUG Tool call Id: call_4yKBT6C731cMSgNJ8ZHyzOPi\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG * Time:                        0.0025s\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG ============================================================== assistant ===============================================================\nDEBUG Tool Calls:\n        - ID: 'call_2JHfzHt2kuskELsYzwpPmKlL'\n          Name: 'get_team_history'\n          Arguments: 'num_chats: 1'\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG * Tokens:                      input=1117, output=16, total=1133\nDEBUG * Prompt tokens details:       {'audio_tokens': 0, 'cached_tokens': 1024}\nDEBUG * Completion tokens details:   {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}\nDEBUG * Time:                        1.7483s\nDEBUG * Tokens per second:           9.1519 tokens/s\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG Getting function get_team_history\nDEBUG Running: get_team_history(num_chats=1)\nDEBUG ================================================================= tool =================================================================\nDEBUG Tool call Id: call_2JHfzHt2kuskELsYzwpPmKlL\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG * Time:                        0.0014s\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG ============================================================== assistant ===============================================================\nDEBUG Tool Calls:\n        - ID: 'call_Qz1e05Z4omQ8Z3BV02vb6Ep7'\n          Name: 'get_team_history'\n          Arguments: 'num_chats: 1'\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG * Tokens:                      input=1143, output=16, total=1159\nDEBUG * Prompt tokens details:       {'audio_tokens': 0, 'cached_tokens': 0}\nDEBUG * Completion tokens details:   {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}\nDEBUG * Time:                        0.6974s\nDEBUG * Tokens per second:           22.9430 tokens/s\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG Getting function get_team_history\nDEBUG Running: get_team_history(num_chats=1)\nDEBUG ================================================================= tool =================================================================\nDEBUG Tool call Id: call_Qz1e05Z4omQ8Z3BV02vb6Ep7\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG * Time:                        0.0006s\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG ============================================================== assistant ===============================================================\nDEBUG Tool Calls:\n        - ID: 'call_TC8OCzW2aOKVwWLPGIPgMSj2'\n          Name: 'get_team_history'\n          Arguments: 'num_chats: 1'\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG * Tokens:                      input=1169, output=16, total=1185\nDEBUG * Prompt tokens details:       {'audio_tokens': 0, 'cached_tokens': 0}\nDEBUG * Completion tokens details:   {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}\nDEBUG * Time:                        0.9539s\nDEBUG * Tokens per second:           16.7732 tokens/s\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG Getting function get_team_history\nDEBUG Running: get_team_history(num_chats=1)\nDEBUG ================================================================= tool =================================================================\nDEBUG Tool call Id: call_TC8OCzW2aOKVwWLPGIPgMSj2\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG * Time:                        0.0020s\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG ============================================================== assistant ===============================================================\nDEBUG Tool Calls:\n        - ID: 'call_i4KQDv4j8kUzsrbicAk28rwK'\n          Name: 'get_team_history'\n          Arguments: 'num_chats: 1'\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG * Tokens:                      input=1195, output=16, total=1211\nDEBUG * Prompt tokens details:       {'audio_tokens': 0, 'cached_tokens': 1024}\nDEBUG * Completion tokens details:   {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}\nDEBUG * Time:                        0.6934s\nDEBUG * Tokens per second:           23.0757 tokens/s\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG Getting function get_team_history\nDEBUG Running: get_team_history(num_chats=1)\nDEBUG ================================================================= tool =================================================================\nDEBUG Tool call Id: call_i4KQDv4j8kUzsrbicAk28rwK\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG * Time:                        0.0021s\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG ============================================================== assistant ===============================================================\nDEBUG Tool Calls:\n        - ID: 'call_1s7YYjK6B5Cwd0x41N1Ou17v'\n          Name: 'get_team_history'\n          Arguments: 'num_chats: 1'\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG * Tokens:                      input=1221, output=16, total=1237\nDEBUG * Prompt tokens details:       {'audio_tokens': 0, 'cached_tokens': 1152}\nDEBUG * Completion tokens details:   {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}\nDEBUG * Time:                        0.7655s\nDEBUG * Tokens per second:           20.9026 tokens/s\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG Getting function get_team_history\nDEBUG Running: get_team_history(num_chats=1)\nDEBUG ================================================================= tool =================================================================\nDEBUG Tool call Id: call_1s7YYjK6B5Cwd0x41N1Ou17v\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG * Time:                        0.0005s\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG ============================================================== assistant ===============================================================\nDEBUG Tool Calls:\n        - ID: 'call_EsMoCZLhxaHYRa3FIg72Aj53'\n          Name: 'get_team_history'\n          Arguments: 'num_chats: 1'\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG * Tokens:                      input=1247, output=16, total=1263\nDEBUG * Prompt tokens details:       {'audio_tokens': 0, 'cached_tokens': 0}\nDEBUG * Completion tokens details:   {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}\nDEBUG * Time:                        1.0055s\nDEBUG * Tokens per second:           15.9121 tokens/s\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG Getting function get_team_history\nDEBUG Running: get_team_history(num_chats=1)\nDEBUG ================================================================= tool =================================================================\nDEBUG Tool call Id: call_EsMoCZLhxaHYRa3FIg72Aj53\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG * Time:                        0.0032s\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG ============================================================== assistant ===============================================================\nDEBUG Tool Calls:\n        - ID: 'call_gNeoMTM97adIZtFgF3KDaHnw'\n          Name: 'get_team_history'\n          Arguments: 'num_chats: 1'\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG * Tokens:                      input=1273, output=16, total=1289\nDEBUG * Prompt tokens details:       {'audio_tokens': 0, 'cached_tokens': 0}\nDEBUG * Completion tokens details:   {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}\nDEBUG * Time:                        1.1709s\nDEBUG * Tokens per second:           13.6653 tokens/s\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG Getting function get_team_history\nDEBUG Running: get_team_history(num_chats=1)\nDEBUG ================================================================= tool =================================================================\nDEBUG Tool call Id: call_gNeoMTM97adIZtFgF3KDaHnw\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG * Time:                        0.0020s\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG ============================================================== assistant ===============================================================\nDEBUG Tool Calls:\n        - ID: 'call_MaOqHP06upk7ztyL2WdPf8DA'\n          Name: 'get_team_history'\n          Arguments: 'num_chats: 1'\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG * Tokens:                      input=1299, output=16, total=1315\nDEBUG * Prompt tokens details:       {'audio_tokens': 0, 'cached_tokens': 1024}\nDEBUG * Completion tokens details:   {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}\nDEBUG * Time:                        2.3289s\nDEBUG * Tokens per second:           6.8701 tokens/s\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG Getting function get_team_history\nDEBUG Running: get_team_history(num_chats=1)\nDEBUG ================================================================= tool =================================================================\nDEBUG Tool call Id: call_MaOqHP06upk7ztyL2WdPf8DA\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG * Time:                        0.0005s\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG ============================================================== assistant ===============================================================\nDEBUG Tool Calls:\n        - ID: 'call_5RmvOI4jiBiJESdKgCNl8uVs'\n          Name: 'get_team_history'\n          Arguments: 'num_chats: 1'\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG * Tokens:                      input=1325, output=16, total=1341\nDEBUG * Prompt tokens details:       {'audio_tokens': 0, 'cached_tokens': 1152}\nDEBUG * Completion tokens details:   {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}\nDEBUG * Time:                        0.7708s\nDEBUG * Tokens per second:           20.7589 tokens/s\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG Getting function get_team_history\nDEBUG Running: get_team_history(num_chats=1)\nDEBUG ================================================================= tool =================================================================\nDEBUG Tool call Id: call_5RmvOI4jiBiJESdKgCNl8uVs\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG * Time:                        0.0027s\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG ============================================================== assistant ===============================================================\nDEBUG Tool Calls:\n        - ID: 'call_GfUsZClKibvqKCYqtTqKEtd4'\n          Name: 'get_team_history'\n          Arguments: 'num_chats: 1'\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG * Tokens:                      input=1351, output=16, total=1367\nDEBUG * Prompt tokens details:       {'audio_tokens': 0, 'cached_tokens': 0}\nDEBUG * Completion tokens details:   {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}\nDEBUG * Time:                        0.7489s\nDEBUG * Tokens per second:           21.3647 tokens/s\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG Getting function get_team_history\nDEBUG Running: get_team_history(num_chats=1)\nDEBUG ================================================================= tool =================================================================\nDEBUG Tool call Id: call_GfUsZClKibvqKCYqtTqKEtd4\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG * Time:                        0.0007s\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG ============================================================== assistant ===============================================================\nDEBUG Tool Calls:\n        - ID: 'call_7cQEC780oulFG2UmZqW9R9lB'\n          Name: 'get_team_history'\n          Arguments: 'num_chats: 1'\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG * Tokens:                      input=1377, output=16, total=1393\nDEBUG * Prompt tokens details:       {'audio_tokens': 0, 'cached_tokens': 1280}\nDEBUG * Completion tokens details:   {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}\nDEBUG * Time:                        1.3754s\nDEBUG * Tokens per second:           11.6328 tokens/s\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG Getting function get_team_history\nDEBUG Running: get_team_history(num_chats=1)\nDEBUG ================================================================= tool =================================================================\nDEBUG Tool call Id: call_7cQEC780oulFG2UmZqW9R9lB\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG * Time:                        0.0027s\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG ============================================================== assistant ===============================================================\nDEBUG Tool Calls:\n        - ID: 'call_bX3oEVD3KDo0giNIfLQzqDOQ'\n          Name: 'get_team_history'\n          Arguments: 'num_chats: 1'\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG * Tokens:                      input=1403, output=16, total=1419\nDEBUG * Prompt tokens details:       {'audio_tokens': 0, 'cached_tokens': 1280}\nDEBUG * Completion tokens details:   {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}\nDEBUG * Time:                        0.7189s\nDEBUG * Tokens per second:           22.2567 tokens/s\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG Getting function get_team_history\nDEBUG Running: get_team_history(num_chats=1)\nDEBUG ================================================================= tool =================================================================\nDEBUG Tool call Id: call_bX3oEVD3KDo0giNIfLQzqDOQ\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG * Time:                        0.0024s\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG ============================================================== assistant ===============================================================\nDEBUG Tool Calls:\n        - ID: 'call_mC6kTCbbuD2OkCGn8Zax1JYO'\n          Name: 'get_team_history'\n          Arguments: 'num_chats: 1'\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG * Tokens:                      input=1429, output=16, total=1445\nDEBUG * Prompt tokens details:       {'audio_tokens': 0, 'cached_tokens': 1280}\nDEBUG * Completion tokens details:   {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}\nDEBUG * Time:                        0.7090s\nDEBUG * Tokens per second:           22.5684 tokens/s\nDEBUG **************************************************************  METRICS  ***************************************************************\nDEBUG Getting function get_team_history\nDEBUG Running: get_team_history(num_chats=1)\nDEBUG ================================================================= tool =================================================================\nDEBUG Tool call Id: call_mC6kTCbbuD2OkCGn8Zax1JYO\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG * Time:                        0.0020s\nDEBUG ************************************************************  TOOL METRICS  ************************************************************\nDEBUG ======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================== assistant =========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================\nDEBUG Tool Calls:\n        - ID: 'call_DVxJMEa0RqCwup6Z0ELfzyNc'\n          Name: 'get_team_history'\n          Arguments: 'num_chats: 1'\nDEBUG ********************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************  METRICS  *********************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\nDEBUG * Tokens:                      input=1455, output=16, total=1471\nDEBUG * Prompt tokens details:       {'audio_tokens': 0, 'cached_tokens': 1280}\nDEBUG * Completion tokens details:   {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}\nDEBUG * Time:                        0.7823s\nDEBUG * Tokens per second:           20.4521 tokens/s\nDEBUG ********************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************  METRICS  *********************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\nDEBUG Getting function get_team_history\nDEBUG Running: get_team_history(num_chats=1)\nDEBUG =========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================== tool ===========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================\nDEBUG Tool call Id: call_DVxJMEa0RqCwup6Z0ELfzyNc\nDEBUG ******************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************  TOOL METRICS  ******************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\nDEBUG * Time:                        0.0020s\nDEBUG ******************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************  TOOL METRICS  ******************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\n^C\n`\n## Environment\n- OS: (, Windows 11)\n- Browser (if relevant): (e.g. Chrome )\n- Agno Version: (e.g. v1.2.3)\n- Additional Environment Details: (e.g., Python 3.12)\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "AkhilmsAchu",
      "author_type": "User",
      "created_at": "2025-03-25T06:02:05Z",
      "updated_at": "2025-03-29T02:08:27Z",
      "closed_at": "2025-03-29T02:07:41Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 19,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2531/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2531",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2531",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:47.070858",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "@AkhilmsAchu What model did you use? I can't replicate this with examples I am trying.",
          "created_at": "2025-03-25T07:42:51Z"
        },
        {
          "author": "AkhilmsAchu",
          "body": "@dirkbrnd Azure gpt 4o",
          "created_at": "2025-03-25T07:56:15Z"
        },
        {
          "author": "dirkbrnd",
          "body": "I tried every which way and couldn't replicate it. I am using AzureAIFoundry(\"gpt-4o\") as well.\n\nWhat else could be different here?",
          "created_at": "2025-03-25T09:11:31Z"
        },
        {
          "author": "AkhilmsAchu",
          "body": "i'm using sqlite db and this is how i initiate storage \n\n`storage = SqliteAgentStorage(\n        table_name=\"team_sessions\", db_file=\"database/database.db\"\n    )`",
          "created_at": "2025-03-25T09:47:45Z"
        },
        {
          "author": "AkhilmsAchu",
          "body": "@dirkbrnd bro i have some doubts regarding this new teams. Currently i have  3 agents forming a team with a master agent. suppose  if ask master to create a JD, it will gather all requirements and sent it to the jd creator agent. but even though the jd creator agent creates and returns the JD to mas",
          "created_at": "2025-03-25T10:35:52Z"
        }
      ]
    },
    {
      "issue_number": 2345,
      "title": "[Bug]Error when reading PDF with inline images",
      "body": "# Description\nHey, when loading pdf docs in MilvusDB I get following error:\n\n```\nDoc Reader length: 209\nPage: 1\nPage: 2\nPage: 3\nPage: 4\nPage: 5\nPage: 6\nPage: 7\nPage: 8\nPage: 9\nTraceback (most recent call last):\n  File \"/media/alaap/PF_bkp/LLM/HakiSenseMain/iter2/HakiSense/src/engines/financial_report_workflow.py\", line 49, in <module>\n    class FinancialReportWorkflow(Workflow):\n  File \"/media/alaap/PF_bkp/LLM/HakiSenseMain/iter2/HakiSense/src/engines/financial_report_workflow.py\", line 69, in FinancialReportWorkflow\n    report_knowledge.load(recreate=True, upsert=True)\n  File \"/home/alaap/miniconda3/envs/envPy310/lib/python3.10/site-packages/agno/knowledge/agent.py\", line 116, in load\n    for document_list in self.document_lists:\n  File \"/home/alaap/miniconda3/envs/envPy310/lib/python3.10/site-packages/agno/knowledge/pdf.py\", line 33, in document_lists\n    yield self.reader.read(pdf=_pdf)\n  File \"/home/alaap/miniconda3/envs/envPy310/lib/python3.10/site-packages/agno/document/reader/pdf_reader.py\", line 123, in read\n    content=page.extract_text(),\n  File \"/home/alaap/miniconda3/envs/envPy310/lib/python3.10/site-packages/pypdf/_page.py\", line 2391, in extract_text\n    return self._extract_text(\n  File \"/home/alaap/miniconda3/envs/envPy310/lib/python3.10/site-packages/pypdf/_page.py\", line 2086, in _extract_text\n    for operands, operator in content.operations:\n  File \"/home/alaap/miniconda3/envs/envPy310/lib/python3.10/site-packages/pypdf/generic/_data_structures.py\", line 1421, in operations\n    self._parse_content_stream(BytesIO(self._data))\n  File \"/home/alaap/miniconda3/envs/envPy310/lib/python3.10/site-packages/pypdf/generic/_data_structures.py\", line 1309, in _parse_content_stream\n    ii = self._read_inline_image(stream)\n  File \"/home/alaap/miniconda3/envs/envPy310/lib/python3.10/site-packages/pypdf/generic/_data_structures.py\", line 1346, in _read_inline_image\n    filtr = filtr[0]  # used forencoding\nIndexError: list index out of range\n```\n\n## Steps to Reproduce\nIt seems like pdf reader is having trouble in reading docs with images in it\n\n## Agent Configuration (if applicable)\nJust doing this alone will lead to error:\n\n```\nreport_knowledge: ClassVar[PDFKnowledgeBase] = PDFKnowledgeBase(\n        path=\"downloads\",\n        num_documents=6,\n        # chunking_strategy=ChunkingStrategy.recursive,\n        chunking_strategy=DocumentChunking(overlap=200),\n\n        vector_db=Milvus(\n            collection=\"financial_reports\",\n            uri='src/knowledge/Milvus/financial_reports.db',\n            search_type=SearchType.hybrid,\n            embedder=OpenAIEmbedder(id=\"text-embedding-3-small\")\n        )\n    )\n\n    report_knowledge.load(recreate=True, upsert=True)\n```\n## Expected Behavior\nIt should be able to load any type of PDF\nUsingg ubuntu and latest version of Agno\n\n## Additional Context\nI'll upload the pdf as well for reproducibility:\n[Annual Report](https://www.bseindia.com/stockinfo/AnnPdfOpen.aspx?Pname=\\f037482d-c91e-4f82-a782-3096ecd5375a.pdf)",
      "state": "closed",
      "author": "alaap001",
      "author_type": "User",
      "created_at": "2025-03-10T08:04:46Z",
      "updated_at": "2025-03-29T00:31:40Z",
      "closed_at": "2025-03-29T00:31:39Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2345/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2345",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2345",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:47.294128",
      "comments": [
        {
          "author": "manthanguptaa",
          "body": "Hey @alaap001! Is your PDF a mix of images and text?",
          "created_at": "2025-03-10T10:46:34Z"
        },
        {
          "author": "alaap001",
          "body": "Yes, it's like a financial report of a company. The agent's job is to analyze it. \nWeirdly, it works on some similar Financial reports just fine but fails on some. I have attached the link to PDF as well for your reference, ",
          "created_at": "2025-03-10T10:52:03Z"
        },
        {
          "author": "ysolanky",
          "body": "Hello @alaap001 ! Can you please try using `PDFImageReader` instead? The `PDFImageReader` uses `rapidocr_onnxruntime` under the hood and generally performs better at extracting information from PDFs that are image dominant ",
          "created_at": "2025-03-14T04:19:23Z"
        },
        {
          "author": "alaap001",
          "body": "I tried but I still got this error:\n\n```\nERROR    Error loading reports: list index out of range                                                                                                                                                                                                 \nERROR    E",
          "created_at": "2025-03-14T18:22:38Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-03-29T00:31:38Z"
        }
      ]
    },
    {
      "issue_number": 2402,
      "title": "[Feature Request] Load JSON/CSV and conduct time-series analysis",
      "body": "## Problem Description\nCurrently they loaded as vectordb...which is nonesense in that context...\n\n\n## Proposed Solution\nadd support to load it as sql and then query it..\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[ ] Yes, I’d love to work on it!**\n**[ ] I’m open to collaborating but need guidance.**\n**[ X] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "barshag",
      "author_type": "User",
      "created_at": "2025-03-14T00:55:49Z",
      "updated_at": "2025-03-29T00:31:38Z",
      "closed_at": "2025-03-29T00:31:38Z",
      "labels": [
        "enhancement",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2402/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2402",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2402",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:47.508000",
      "comments": [
        {
          "author": "manthanguptaa",
          "body": "Hey @barshag! \nI really appreciate you suggesting this feature. It's always great to explore new possibilities! Could you help me understand the value this would bring? I know that vector databases aren’t typically used for time-series analysis, so I’d love to hear your perspective on how this could",
          "created_at": "2025-03-14T13:16:39Z"
        },
        {
          "author": "barshag",
          "body": "The value? the ability to make data analysis on time series...BTW currently\r\nyour suggestion on your mainpage is  a bit misleading. I was sure that you\r\nare going to support querying that kind of data; but when I got into the\r\ndocs I understood that I need to wait to use your lib.\r\n\r\nI mean the agen",
          "created_at": "2025-03-14T13:46:15Z"
        },
        {
          "author": "manthanguptaa",
          "body": "We do have SQL tool that might fit the bill \nhttps://docs.agno.com/tools/toolkits/sql\nLet me know if you are looking for this?",
          "created_at": "2025-03-14T14:03:14Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-03-29T00:31:36Z"
        }
      ]
    },
    {
      "issue_number": 2405,
      "title": "[Bug]agno/memory/agent.py:should_update_memory need match wider",
      "body": "# Description\nWhen using \"gpt-4\" as memory classifier, it always return \"Yes\".\nBut the code is:\n    if classifier_response == \"yes\":\n\nPlease at least make it case-incensitive",
      "state": "closed",
      "author": "Priezt",
      "author_type": "User",
      "created_at": "2025-03-14T08:05:02Z",
      "updated_at": "2025-03-29T00:31:36Z",
      "closed_at": "2025-03-29T00:31:36Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2405/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2405",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2405",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:47.822814",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-03-29T00:31:35Z"
        }
      ]
    },
    {
      "issue_number": 2592,
      "title": "[Bug] Gemini 2.5 Pro - Tool Calling - Blocking issue",
      "body": "# Description\nI am running the test agent with Mistral small 24B (through OpenRouter, not using GPT-4o): https://github.com/agno-agi/agno/blob/main/cookbook/examples/teams/coordinate/content_team.py\nHere is the detailed output: https://paste.ofcode.org/EqbdC64KtXaLcEb2yVYYBr\n\nThe err is thrown at this line: https://github.com/agno-agi/agno/blob/fbc7bdab165afa9472ae0a9ac064654b991cdee5/libs/agno/agno/models/google/gemini.py#L465\n\nI printed the message for which the error is thrown, it looks like this:\n```\nMessage >>>>  role='assistant' content='Okay, I will research the basics of quantum computing using the available tools.\\n\\n**Step 1: Define Quantum Computing**\\n' name=None \ntool_call_id=None tool_calls=[{'type': 'function', 'function': {'name': 'duckduckgo_search', 'arguments': '{\"query\": \"What is quantum computing definition\"}'}}] audio=None images=None \nvideos=None files=None audio_output=None thinking=None redacted_thinking=None provider_data=None citations=None reasoning_content=None tool_name=None tool_args=None tool_call_error=None \nstop_after_tool_call=False add_to_agent_memory=True from_history=False metrics=MessageMetrics(input_tokens=290, output_tokens=47, total_tokens=337, prompt_tokens=0, completion_tokens=0, \nprompt_tokens_details=None, completion_tokens_details=None, additional_metrics=None, time=3.2384749999910127, time_to_first_token=None, timer=<agno.utils.timer.Timer object at 0x111633f80>) \nreferences=None created_at=1743197361\n```\n\n## Steps to Reproduce\nList the steps needed to encounter this bug or issue.\n\n## Agent Configuration (if applicable)\nUse this: https://github.com/agno-agi/agno/blob/main/cookbook/examples/teams/coordinate/content_team.py\nReplace `gpt-4o` call with gemini 2.5 pro call `model=Gemini(\"gemini-2.5-pro-exp-03-25\"),` in all three agents and then run.\n\nHere is the test agent script:\n```\nimport dotenv\nfrom openai import OpenAI\ndotenv.load_dotenv()\n\nfrom agno.agent.agent import Agent\nfrom agno.models.openai.chat import OpenAIChat\nfrom agno.models.google.gemini import Gemini\nfrom agno.models.openrouter.openrouter import OpenRouter\nfrom agno.team.team import Team\nfrom agno.tools.duckduckgo import DuckDuckGoTools\n\n# Create individual specialized agents\nresearcher = Agent(\n    name=\"Researcher\",\n    role=\"Expert at finding information\",\n    tools=[DuckDuckGoTools()],\n    model=Gemini(\"gemini-2.5-pro-exp-03-25\"),\n    show_tool_calls=True\n)\n\nwriter = Agent(\n    name=\"Writer\",\n    role=\"Expert at writing clear, engaging content\",\n    model=Gemini(\"gemini-2.5-pro-exp-03-25\"),\n)\n\n# Create a team with these agents\ncontent_team = Team(\n    name=\"Content Team\",\n    mode=\"coordinate\",\n    members=[researcher, writer],\n    instructions=\"You are a team of researchers and writers that work together to create high-quality content.\",\n    model=Gemini(\"gemini-2.5-pro-exp-03-25\"),\n    debug_mode=True\n)\n\n# Run the team with a task\ncontent_team.print_response(\"Create a short article about quantum computing\")\n```\n\n## Expected Behavior\nIt should run fine\n\n## Actual Behavior\nFailing with err. Complete output: https://paste.ofcode.org/EqbdC64KtXaLcEb2yVYYBr\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- OS: (e.g. macOS, Windows 11)\n- Browser (if relevant): (e.g. Chrome 108, Firefox 107)\n- Agno Version: (e.g. v1.0.0)\n- External Dependency Versions: (e.g., yfinance 0.2.52)\n- Additional Environment Details: (e.g., Python 3.10)\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "gauravdhiman",
      "author_type": "User",
      "created_at": "2025-03-28T21:45:21Z",
      "updated_at": "2025-03-28T22:05:02Z",
      "closed_at": "2025-03-28T22:05:02Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2592/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2592",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2592",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:49.817334",
      "comments": [
        {
          "author": "gauravdhiman",
          "body": "I think this issue is same as https://github.com/agno-agi/agno/issues/2589\nMarking it as duplicate.",
          "created_at": "2025-03-28T22:04:53Z"
        }
      ]
    },
    {
      "issue_number": 2571,
      "title": "[Bug] Playground endpoint localhost:7777 not available however running in my terminal",
      "body": "# Description\nI did ag setup etc... \nuv run -m agents.test\n\n\nINFO Starting playground on http://localhost:7777\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ Agent Playground ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃                                                                             ┃\n┃                                                                             ┃\n┃  Playground URL: https://app.agno.com/playground?endpoint=localhost%3A7777  ┃\n┃                                                                             ┃\n┃                                                                             ┃\n┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\nINFO:     Will watch for changes in these directories: ['dev/numenbit/numen/hub']\nINFO:     Uvicorn running on http://localhost:7777 (Press CTRL+C to quit)\nINFO:     Started reloader process [83219] using StatReload\nprinting out response...\nprinting out response...\nINFO:     Started server process [83239]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\n\n\n\n\n\n## Screenshots or Logs (if applicable)\n\n![Image](https://github.com/user-attachments/assets/03840965-ee47-4ec1-b90c-dd5fbd8924ca)\n\n![Image](https://github.com/user-attachments/assets/556b716c-ff26-4db9-97cd-668c58112973)\n\n## Environment\n- OS: Mac\n- Browser: Safari\n- Python 3.12\n\n\n",
      "state": "closed",
      "author": "numenbit",
      "author_type": "User",
      "created_at": "2025-03-27T06:40:35Z",
      "updated_at": "2025-03-28T01:53:04Z",
      "closed_at": "2025-03-28T01:53:03Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2571/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2571",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2571",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:50.011974",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @numenbit ! There might have been an issue authenticating your CLI with Safari. Can you please try exporting the API key? [Here are the steps](https://docs.agno.com/faq/cli-auth). Please let us know in case you face any issues",
          "created_at": "2025-03-27T19:12:19Z"
        },
        {
          "author": "numenbit",
          "body": "> Hello [@numenbit](https://github.com/numenbit) ! There might have been an issue authenticating your CLI with Safari. Can you please try exporting the API key? [Here are the steps](https://docs.agno.com/faq/cli-auth). Please let us know in case you face any issues\n\nYou are correct however, I did ex",
          "created_at": "2025-03-27T21:16:06Z"
        },
        {
          "author": "numenbit",
          "body": "Ok this was definitely a safari issue.    However took me a while to get it work with chrome as its not my default browser then refresh etc.. anyway would be nice to fix for safari. \n\nGood job anyway looks promising.  Will use more. ",
          "created_at": "2025-03-28T01:53:03Z"
        }
      ]
    },
    {
      "issue_number": 2362,
      "title": "[Tutorial required] How to integrate reasoner model into workflow?",
      "body": "Hi, I want to know is there any tutorial about integration of reasoner into research workflow? Like some other deep-research?",
      "state": "closed",
      "author": "peiyaoli",
      "author_type": "User",
      "created_at": "2025-03-11T08:52:57Z",
      "updated_at": "2025-03-28T00:31:56Z",
      "closed_at": "2025-03-28T00:31:56Z",
      "labels": [
        "stale"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2362/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2362",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2362",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:50.176424",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Hi @peiyaoli \nYou can use a [reasoning agent ](https://docs.agno.com/agents/reasoning) as one of the agents in your workflow, you can then take the output from that agent that should have `reasoning_content` and use that in the message to other agents. If that is your goal",
          "created_at": "2025-03-13T09:47:37Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-03-28T00:31:55Z"
        }
      ]
    },
    {
      "issue_number": 2370,
      "title": "[Bug]Agent Team's SubAgent with reasoning_model doesn't output thinking part",
      "body": "# Description\nWhen using an Agent Team, the reasoning_model set for a SubAgent doesn't correctly output the thinking part. Even when show_full_reasoning=True is set when calling ROUTER_AGENT, the reasoning process of the SubAgent (AFS_AGENT) is not displayed.\n\n## Steps to Reproduce\n1. Create an Agent Team structure, such as the ROUTER_AGENT in the example code\n2. Add a SubAgent (like AFS_AGENT) to the Team, and set a reasoning_model for that SubAgent\n3. Call the run or print_response method for the main Agent (ROUTER_AGENT) with the show_full_reasoning=True parameter\n4. Observe the output results and notice that the SubAgent's reasoning process is not displayed\n\n\n## Agent Configuration (if applicable)\n```python\n# Main Agent (ROUTER_AGENT) configuration\nROUTER_AGENT = Agent(\n    name=\"router_agent\",\n    role=\"Query Routing Expert\",\n    description=\"Responsible for understanding user query intent and routing queries to the most appropriate team member to ensure each question receives the most accurate answer\",\n    instructions=[...],\n    team=[AFS_AGENT],\n    markdown=True,\n    stream=True,\n    debug_mode=debug_mode,\n    add_datetime_to_instructions=add_datetime_to_instructions\n)\n\n# SubAgent (AFS_AGENT) configuration\nAFS_AGENT = Agent(\n    name=\"afs_expert_agent\",\n    role=\"AFS Project Expert Advisor\",\n    description=\"An expert with comprehensive knowledge of the AFS project, capable of answering various user questions about the AFS project, providing accurate and detailed information and professional guidance\",\n    instructions=[...],\n    model=OPENAI_MODEL,\n    reasoning_model=GROQ_MODEL,  # reasoning_model is set here\n    markdown=True,\n    stream=True,\n    debug_mode=debug_mode,\n    add_datetime_to_instructions=add_datetime_to_instructions,\n)\n\n# Call method\nagent = ROUTER_AGENT\nagent.print_response(\"In AFS, how to check if a link has ads\", stream=True, show_full_reasoning=True)\n```\n\n## Expected Behavior\nWhen calling an Agent Team with the show_full_reasoning=True parameter, the reasoning process of the SubAgent, especially when the SubAgent has a dedicated reasoning_model set.\n\n## Actual Behavior\nIn reality, while the SubAgent's (AFS_AGENT) reasoning process is not shown, despite it having a dedicated reasoning_model (GROQ_MODEL) set.\n\n## Screenshots or Logs (if applicable)\n\n<img width=\"1183\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/834f450a-f59f-40c9-93a3-57db92636614\" />\n\n## Environment\n- OS: macOS\n- Agno Version: lts\n- Python Version: 3.13\n\n## Possible Solutions (optional)\n1. Add support for SubAgent's reasoning_model in the Agent Team implementation to ensure the show_full_reasoning=True parameter is recursively applied to all SubAgents\n2. Add a new parameter for Agent, such as show_team_reasoning=True, specifically to control whether to display the reasoning process of team members\n\n## Additional Context\nThis issue affects developers' ability to visualize and debug the thinking process of each SubAgent in an Agent Team, especially in complex scenarios using different LLM models as reasoning models. Fixing this issue is crucial for developing high-quality Agent Systems.\n\n## Other\nI previously submitted an issue regarding the lack of streaming support for the thinking/reasoning part. When fixing this current issue, it would be beneficial to also incorporate streaming support for the thinking part, allowing for real-time visualization of the reasoning process across all agents in the team hierarchy. This would greatly enhance the debugging experience and provide more immediate feedback during agent development.\n[2264](https://github.com/agno-agi/agno/issues/2264)",
      "state": "closed",
      "author": "CrankGentleman",
      "author_type": "User",
      "created_at": "2025-03-12T03:16:32Z",
      "updated_at": "2025-03-28T00:31:54Z",
      "closed_at": "2025-03-28T00:31:54Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2370/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2370",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2370",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:50.413408",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Hi @CrankGentleman \nThat is a known issue. We are releasing an update to teams soon and I will make sure this is resolved there.",
          "created_at": "2025-03-13T14:02:14Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-03-28T00:31:53Z"
        }
      ]
    },
    {
      "issue_number": 2371,
      "title": "[Bug] Using AzureOpenAI requires installation of Azure AI Foundry and Anthropic dependencies",
      "body": "# Description\nI am using the AzureOpenAI model but I am forced to install anthropic and azure ai foundry as dependencies for this. This should not be the behaviour. There should be separate modules for Azure OpenAI and Azure AI Foundry\n\n## Steps to Reproduce\nJust import the AzureOpenAI\n`from agno.models.azure import AzureOpenAI` and you will be met with errors for missing module for anthropic then azure-ai-foundry\n\n## Expected Behavior\nThere should be separate modules for Azure OpenAI and Azure AI Foundry. For example, \n```\nfrom agno.models.azure_openai import AzureOpenAI\nfrom agno.models.azure_ai_foundry import AzureAIFoundry\n``` \nOR\n```\nfrom agno.models.azure.azure_openai import AzureOpenAI\nfrom agno.models.azure.azure_ai_foundry import AzureAIFoundry\n```\n\n\n## Screenshots or Logs (if applicable)\n```\nFile \"/home/samaksh/Desktop/presales-researcher/backend/app/services/ai/researcher_workflow.py\", line 6, in <module>\n    from agno.models.azure import AzureOpenAI\n  File \"/home/samaksh/Desktop/presales-researcher/.venv/lib/python3.11/site-packages/agno/models/azure/__init__.py\", line 1, in <module>\n    from agno.models.azure.ai_foundry import AzureAIFoundry\n  File \"/home/samaksh/Desktop/presales-researcher/.venv/lib/python3.11/site-packages/agno/models/azure/ai_foundry.py\", line 7, in <module>\n    from anthropic import BaseModel\nModuleNotFoundError: No module named 'anthropic'\n```\n\n```\n  File \"/home/samaksh/Desktop/presales-researcher/.venv/lib/python3.11/site-packages/agno/models/azure/ai_foundry.py\", line 17, in <module>\n    from azure.ai.inference import ChatCompletionsClient\nModuleNotFoundError: No module named 'azure.ai'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"/home/samaksh/Desktop/presales-researcher/backend/app/services/ai/researcher_workflow.py\", line 6, in <module>\n    from agno.models.azure import AzureOpenAI\n  File \"/home/samaksh/Desktop/presales-researcher/.venv/lib/python3.11/site-packages/agno/models/azure/__init__.py\", line 1, in <module>\n    from agno.models.azure.ai_foundry import AzureAIFoundry\n  File \"/home/samaksh/Desktop/presales-researcher/.venv/lib/python3.11/site-packages/agno/models/azure/ai_foundry.py\", line 30, in <module>\n    raise ImportError(\nImportError: `azure-ai-inference` not installed. Please install it via `pip install azure-ai-inference aiohttp`.\n```\n\n## Environment\n- OS: Ubuntu 20.04\n- Agno Version: 1.1.9\n- Additional Environment Details: Python 3.11.10\n",
      "state": "closed",
      "author": "samaksh-khatri-simform",
      "author_type": "User",
      "created_at": "2025-03-12T06:31:34Z",
      "updated_at": "2025-03-28T00:31:53Z",
      "closed_at": "2025-03-28T00:31:53Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2371/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2371",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2371",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:50.610035",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Thanks for raising, I have a PR out with a fix. ",
          "created_at": "2025-03-13T13:08:36Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-03-28T00:31:52Z"
        }
      ]
    },
    {
      "issue_number": 2386,
      "title": "[Bug] rag add chinese support",
      "body": "import os\nimport uuid\nfrom dataclasses import dataclass\n\nfrom agno.agent import Agent\n\nfrom agno.knowledge.pdf import PDFKnowledgeBase, PDFReader\nfrom agno.vectordb.pgvector import PgVector, SearchType\nfrom agno.embedder.base import Embedder\nfrom agno.utils.log import logger\nfrom typing import Any, Dict, List, Optional, Tuple\nfrom agno.document import Document\nfrom agno.models.openai.like import OpenAILike\nfrom agno.document.chunking.agentic import AgenticChunking\n\nfrom agno.document.chunking.document import DocumentChunking\n\n@dataclass\nclass OllamaEmbedder(Embedder):\n    id: str = \"openhermes\"\n    dimensions: int = 1024  # Changed to 1024 for BGE-M3\n    host: Optional[str] = None\n    timeout: Optional[Any] = None\n    options: Optional[Any] = None\n    client_kwargs: Optional[Dict[str, Any]] = None\n    ollama_client: Optional[Any] = None\n\n    @property\n    def client(self):\n        if self.ollama_client:\n            return self.ollama_client\n\n        try:\n            from ollama import Client as OllamaClient\n        except ImportError:\n            raise ImportError(\"Ollama not installed. Install with `pip install ollama`\")\n\n        _ollama_params: Dict[str, Any] = {\n            \"host\": self.host,\n            \"timeout\": self.timeout,\n        }\n        _ollama_params = {k: v for k, v in _ollama_params.items() if v is not None}\n        if self.client_kwargs:\n            _ollama_params.update(self.client_kwargs)\n        self.ollama_client = OllamaClient(**_ollama_params)\n        return self.ollama_client\n\n    def _response(self, text: str) -> Dict[str, Any]:\n        kwargs: Dict[str, Any] = {}\n        if self.options is not None:\n            kwargs[\"options\"] = self.options\n\n        response = self.client.embed(input=text, model=self.id, **kwargs)\n        if response and \"embeddings\" in response:\n            embeddings = response[\"embeddings\"]\n            if isinstance(embeddings, list) and len(embeddings) > 0 and isinstance(embeddings[0], list):\n                return {\"embeddings\": embeddings[0]}\n            elif isinstance(embeddings, list) and all(isinstance(x, (int, float)) for x in embeddings):\n                return {\"embeddings\": embeddings}\n        return {\"embeddings\": []}\n\n    def get_embedding(self, text: str) -> List[float]:\n        try:\n            response = self._response(text=text)\n            embedding = response.get(\"embeddings\", [])\n            if len(embedding) != self.dimensions:\n                logger.warning(f\"Expected embedding dimension {self.dimensions}, but got {len(embedding)}\")\n                return []\n            return embedding\n        except Exception as e:\n            logger.warning(e)\n            return []\n\n    def get_embedding_and_usage(self, text: str) -> Tuple[List[float], Optional[Dict]]:\n        embedding = self.get_embedding(text=text)\n        usage = None\n        return embedding, usage\n\n# 配置 LLM 模型\n# model = OpenAIChat(\n#     id=\"gpt-4o\",\n#     base_url=\"http://127.0.0.1:3001/v1\",\n#     api_key='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'\n# )\n\n# model = OpenAILike(\n#     id=\"qwen2.5:32b\",\n#     api_key=\"\",\n#     base_url=\"http://10.10.0.3:11434/v1\",\n#     temperature=0.1\n# )\nmodel = OpenAILike(\n    id=\"gpt-4o\",\n    api_key=\"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\",\n    base_url=\"http://127.0.0.1:3001/v1\",\n    temperature=0.1\n)\n\n# model = OpenAILike(\n#     id=\"gpt-4o\",\n#     api_key=\"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\",\n#     base_url=\"http://49.232.175.13:3001/v1\",\n#     temperature=0.1\n# )\n# 修改 role_map\nmodel.role_map = {\n    \"system\": \"system\",\n    \"user\": \"user\",\n    \"assistant\": \"assistant\",\n    \"tool\": \"tool\"\n}\n\n# 配置 Ollama 嵌入模型\nembedder = OllamaEmbedder(\n    host=\"http://10.10.0.3:11434\",\n    id=\"bge-m3\",\n    dimensions=1024\n)\n\n# 配置数据库连接\ndb_url = \"postgresql+psycopg://postgres:postgres@192.168.12.73:5433/vectordb\"\n\n# db_url = \"postgresql+psycopg://ai:ai@localhost:5532/ai\"\n\n# Force recreate the table with the correct dimensions\ntry:\n    # First, connect to the database and drop the existing table if it exists\n    from sqlalchemy import create_engine, text\n    engine = create_engine(db_url)\n    with engine.connect() as connection:\n        # Drop the existing table completely\n        connection.execute(text(\"DROP TABLE IF EXISTS ai.recipes CASCADE;\"))\n        connection.commit()\n        print(\"Dropped the existing table\")\nexcept Exception as e:\n    print(f\"Error dropping table: {e}\")\n\n# Configure vector database with proper embedding dimensions\nvector_db = PgVector(\n    table_name=\"en_chunking\",\n    db_url=db_url,\n    search_type=SearchType.hybrid,\n    schema=\"ai\",\n    embedder=embedder  # This will set the correct dimensions (1024)\n)\n\n# Create the table with the correct dimensions\ntry:\n    print(\"Creating table with correct dimensions...\")\n    vector_db.create()\nexcept Exception as e:\n    print(f\"Error creating table: {e}\")\n\n# Configure knowledge base with document processor\nknowledge_base = PDFKnowledgeBase(\n    path=\"/Users/andy/Documents/ThaiRecipes.pdf\",\n    reader=PDFReader(chunk=True),\n    vector_db=vector_db,\n    embedder=embedder,\n    chunking_strategy=DocumentChunking(),\n)\n\n# Create the agent\nagent = Agent(\n    model=model,\n    knowledge=knowledge_base,\n    show_tool_calls=True,\n    add_references=True,\n    search_knowledge=True,\n    markdown=True,\n\n\n)\n\n\n\n# Load the knowledge base\ntry:\n    print(\"Loading knowledge base...\")\n    knowledge_base.load(recreate=False)\n    print(\"Knowledge base loaded successfully!\")\nexcept Exception as e:\n    print(f\"Error loading knowledge base: {e}\")\n    print(\"Attempting to query existing knowledge base...\")\n\n\nif __name__ == '__main__':\n\n# Query\n    agent.print_response(\"为什么选择Cursor\")\nfind openai requests \n\n<img width=\"1633\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/cac08892-ed0f-4d4b-947d-e9b5fbb53a74\" />    Because the model cannot recognize Chinese garbled content, RAG is unable to answer the original question",
      "state": "closed",
      "author": "tx991020",
      "author_type": "User",
      "created_at": "2025-03-13T09:59:56Z",
      "updated_at": "2025-03-28T00:31:50Z",
      "closed_at": "2025-03-28T00:31:49Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2386/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2386",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2386",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:50.805529",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-03-28T00:31:48Z"
        }
      ]
    },
    {
      "issue_number": 2391,
      "title": "[Bug] Passing information between 2 agent is cumbersome",
      "body": "Can you please share some simple minimalistic examples so that we can learn how to pass output of one agent to another in a workflow.\nI had tried multiple ways but everytime there is an error.\nIf i am passing whole list  there is a Rate Limit error and if i want to pass each element, there are multiple errors.\n",
      "state": "closed",
      "author": "ieea",
      "author_type": "User",
      "created_at": "2025-03-13T13:14:40Z",
      "updated_at": "2025-03-28T00:31:48Z",
      "closed_at": "2025-03-28T00:31:48Z",
      "labels": [
        "stale"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2391/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2391",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2391",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:51.015977",
      "comments": [
        {
          "author": "ieea",
          "body": "The example in cookbook are complex from learning perspective.",
          "created_at": "2025-03-13T13:15:20Z"
        },
        {
          "author": "manthanguptaa",
          "body": "Hey @ieea! \nCan you share your code so that I can help you fix it?",
          "created_at": "2025-03-13T13:51:03Z"
        },
        {
          "author": "ieea",
          "body": "from agno.workflow import Workflow, RunResponse\nfrom agno.agent import Agent\nimport json\nfrom agno.models.azure import AzureAIFoundry\nfrom agno.models.azure import AzureOpenAI\nfrom agno.utils.pprint import pprint_run_response\nfrom agno.utils.log import logger\nfrom agno.tools.duckduckgo import DuckDu",
          "created_at": "2025-03-13T14:59:27Z"
        },
        {
          "author": "ieea",
          "body": "Hi @manthanguptaa , Shared the details and I used BlogPostgenerator,  as a initial example.",
          "created_at": "2025-03-13T15:00:06Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-03-28T00:31:47Z"
        }
      ]
    },
    {
      "issue_number": 2548,
      "title": "[Bug] PostgresAgentStorage auto_upgrade_schema fails to add team_session_id column when using team mode",
      "body": "# Description\nThe `PostgresAgentStorage` with `auto_upgrade_schema=True` and `mode=\"team\"` fails to properly upgrade the database schema, resulting in a \"column team_session_id does not exist\" error when trying to insert data into the `agent_sessions` table.\n\n## Steps to Reproduce\n1. Initially use the `agent_sessions` table with a non-team agent (default mode)\n2. Later, switch to using team mode \n3. The agent will initialize `PostgresAgentStorage` with:\n   ```python\n   storage = PostgresAgentStorage(\n       table_name=\"agent_sessions\",\n       db_engine=engine,\n       schema=\"public\",\n       auto_upgrade_schema=True,\n       mode=\"team\"\n   )\n   ```\n4. Try to use the team agent to process a message\n5. The error occurs when trying to insert data into the existing `agent_sessions` table because it's missing the required `team_session_id` column\n\n## Expected Behavior\nThe `auto_upgrade_schema=True` parameter should automatically add the required `team_session_id` column to the `agent_sessions` table when initializing the storage with `mode=\"team\"`.\n\n## Actual Behavior\nDespite having `auto_upgrade_schema=True`, the storage fails to add the required column, resulting in a PostgreSQL error:\n```\nWARNING  Exception upserting into table: (psycopg2.errors.UndefinedColumn)      \n         column \"team_session_id\" of relation \"agent_sessions\" does not exist\n```\n\n## Logs\n```\nDEBUG Table 'public.agent_sessions' does exist                                  \nWARNING  Exception upserting into table: (psycopg2.errors.UndefinedColumn)      \n         column \"team_session_id\" of relation \"agent_sessions\" does not exist   \n         LINE 1: ...er_id, memory, session_data, extra_data, team_id,           \n         team_sessi...                                                          \n                                                                      ^         \n                                                                                \n         [SQL: INSERT INTO public.agent_sessions (session_id, user_id, memory,  \n         session_data, extra_data, team_id, team_session_id, team_data) VALUES  \n         (%(session_id)s, %(user_id)s, %(memory)s::JSONB,                       \n         %(session_data)s::JSONB, %(extra_data)s::JSONB, %(team_id)s,           \n         %(team_session_id)s, %(team_data)s::JSONB) ON CONFLICT (session_id) DO \n         UPDATE SET user_id = %(param_1)s, memory = %(param_2)s::JSONB,         \n         session_data = %(param_3)s::JSONB, extra_data = %(param_4)s::JSONB,    \n         updated_at = %(param_5)s, team_id = %(param_6)s, team_session_id =     \n         %(param_7)s, team_data = %(param_8)s::JSONB]                           \n         [parameters: {'session_id': '1742940057.553979', 'user_id':            \n         'a1004271-5a3a-40ad-98fb-7f57869acded', 'memory':                      \n         '{\"update_system_message_on_change\": true, \"create_user_memories\":     \n         true, \"update_user_memories_after_run\": true, \"user_id\":               \n         \"a1004271-5a3a-40ad-98fb-7 ... (21952 characters truncated) ... \": \"A  \n         friendly greeting response to the user.\"}, \"tool_call_error\": false,   \n         \"metrics\": {\"time\": 0.0013079569907858968}, \"created_at\":              \n         1742940412}]}}]}', 'session_data': '{\"session_metrics\":                \n         {\"input_tokens\": 1195, \"output_tokens\": 33, \"total_tokens\": 1228,      \n         \"prompt_tokens\": 1195, \"completion_tokens\": 33, \"prompt_tokens_ ...    \n         (141 characters truncated) ... ng_tokens\": 0,                          \n         \"rejected_prediction_tokens\": 0}, \"additional_metrics\": null, \"time\":  \n         1.0890115209913347, \"time_to_first_token\": null, \"timer\": null}}',     \n         'extra_data': 'null', 'team_id':                                       \n         'team-c60c3921-3e63-4bf2-ac54-64b0e3f3e2ee', 'team_session_id': None,  \n         'team_data': '{\"name\": \"Team A\", \"team_id\":                    \n         \"team-c60c3921-3e63-4bf2-ac54-64b0e3f3e2ee\", \"model\": {\"provider\":     \n         \"OpenAI\", \"id\": \"gpt-4o\", \"name\": \"OpenAICha ... (966 characters       \n         truncated) ... The expected output from the agent.\"}},                 \n         \"additionalProperties\": false, \"required\": [\"agent_name\",              \n         \"expected_output\"]}}}], \"tool_choice\": \"required\"}}', 'param_1':       \n         'a1004271-5a3a-40ad-98fb-7f57869acded', 'param_2':                     \n         '{\"update_system_message_on_change\": true, \"create_user_memories\":     \n         true, \"update_user_memories_after_run\": true, \"user_id\":               \n         \"a1004271-5a3a-40ad-98fb-7 ... (21952 characters truncated) ... \": \"A  \n         friendly greeting response to the user.\"}, \"tool_call_error\": false,   \n         \"metrics\": {\"time\": 0.0013079569907858968}, \"created_at\":              \n         1742940412}]}}]}', 'param_3': '{\"session_metrics\": {\"input_tokens\":    \n         1195, \"output_tokens\": 33, \"total_tokens\": 1228, \"prompt_tokens\": 1195,\n         \"completion_tokens\": 33, \"prompt_tokens_ ... (141 characters truncated)\n         ... ng_tokens\": 0, \"rejected_prediction_tokens\": 0},                   \n         \"additional_metrics\": null, \"time\": 1.0890115209913347,                \n         \"time_to_first_token\": null, \"timer\": null}}', 'param_4': 'null',      \n         'param_5': 1742940413, 'param_6':                                      \n         'team-c60c3921-3e63-4bf2-ac54-64b0e3f3e2ee', 'param_7': None,          \n         'param_8': '{\"name\": \"Team A\", \"team_id\":                      \n         \"team-c60c3921-3e63-4bf2-ac54-64b0e3f3e2ee\", \"model\": {\"provider\":     \n         \"OpenAI\", \"id\": \"gpt-4o\", \"name\": \"OpenAICha ... (966 characters       \n         truncated) ... The expected output from the agent.\"}},                 \n         \"additionalProperties\": false, \"required\": [\"agent_name\",              \n         \"expected_output\"]}}}], \"tool_choice\": \"required\"}}'}]                 \n         (Background on this error at: https://sqlalche.me/e/20/f405)           \nWARNING  A table upgrade might be required, please review these docs for more   \n         information: https://agno.link/upgrade-schema         \n```\n\n## Environment\n- OS: Linux 6.13.7 (OrbStack)\n- Python Version: 3.11\n- Database: PostgreSQL\n- Agno Version: 1.2.4\n\n## Possible Solutions\nThe schema upgrade logic might need to be fixed to properly handle team mode columns\n\n## Additional Context\nWe want to use the same `agent_sessions` table for both team and non-team agents to maintain a unified session history. Is this approach supported? ",
      "state": "closed",
      "author": "jesalg",
      "author_type": "User",
      "created_at": "2025-03-25T22:21:00Z",
      "updated_at": "2025-03-27T16:28:23Z",
      "closed_at": "2025-03-27T16:28:22Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2548/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2548",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2548",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:51.184973",
      "comments": [
        {
          "author": "manthanguptaa",
          "body": "Hey @jesalg! I think this is because of the `extra_data` column, which was decommissioned in one of our past releases. Can you please confirm if the `agent_sessions` table has already existing data that was created long ago or this is a completely brand new table?",
          "created_at": "2025-03-26T05:29:32Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@jesalg \nSo the upgrade would only happen in `agent` mode because it is required for agent tables. This happens because you are using your existing agents table with `team` mode. Can I suggest you change the table name to `team_session`? This would create a new table for your team sessions, which ha",
          "created_at": "2025-03-26T09:11:45Z"
        },
        {
          "author": "jesalg",
          "body": "@manthanguptaa @dirkbrnd This is an existing table with existing data. I was hoping to use the same table because we had built some downstream dependencies on this data. Different table will mean having to duplicate and update some downstream code so that it can work with both of these tables. \n\nI w",
          "created_at": "2025-03-26T19:34:46Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @jesalg \nYou are welcome to keep your existing `agent_sessions` table for agent sessions, but the new `Team` implementation has a different schema for sessions, so it unfortunately needs a new table. It can be the same DB, just 2 different tables. \nDo you have previous implementations of `Agent.t",
          "created_at": "2025-03-27T10:16:17Z"
        },
        {
          "author": "jesalg",
          "body": "Understood, we will plan for the two table strategy. The tricky thing to migrate will be the downstream connections. We will need to ensure they look at both tables instead of one.",
          "created_at": "2025-03-27T16:28:22Z"
        }
      ]
    },
    {
      "issue_number": 2550,
      "title": "[Bug] Agent Tool Call Fails with 'Missing Required Parameter' Error",
      "body": "\nI wasn't able to comment on or reopen #2424 , but the issue was marked as closed when it is still an active bug. The reason it's a bug is:\n1. This behavior is not documented\n2. There is not sufficient error handling for tools that don't return strings.\n\nBut the issues could very easily be solved with some simple type checking on agno's side. If the result of the tool call is anything other than a string, dump it to a string. Is there any reason why it's not implemented this way?",
      "state": "closed",
      "author": "SethTurin",
      "author_type": "User",
      "created_at": "2025-03-25T23:56:02Z",
      "updated_at": "2025-03-27T10:17:15Z",
      "closed_at": "2025-03-27T10:17:15Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2550/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2550",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2550",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:51.383597",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @SethTurin ! Sorry about that! I think that this is a valuable addition to the framework and something we should have documented on our docs. I am noting it down as a feature request and I agree with you, we can add type checking to make sure the tools return a string. ",
          "created_at": "2025-03-26T04:13:16Z"
        },
        {
          "author": "SethTurin",
          "body": "Thanks! And for what it's worth, this quirk aside, I just started working\r\nwith agno and it is so far the best agent framework I've ever used. Great\r\nwork!\r\n\r\nOn Wed, Mar 26, 2025, 12:13 AM Yash Pratap Solanky ***@***.***>\r\nwrote:\r\n\r\n> Hello @SethTurin <https://github.com/SethTurin> ! Sorry about th",
          "created_at": "2025-03-26T18:33:08Z"
        }
      ]
    },
    {
      "issue_number": 2491,
      "title": "[Bug] Team doesn't work with Ollama",
      "body": "# Description\nTeam class doesn't work with Ollama models. The error returned is `TypeError: Client.chat() got an unexpected keyword argument 'tool_choice'`\n\n## Steps to Reproduce\nRun this code:\n\n```\nfrom agno.agent.agent import Agent\nfrom agno.team.team import Team\nfrom agno.models.ollama.chat import Ollama\n\necho_agent = Agent(\n    model=Ollama(id=\"qwen2.5:32b\"),\n    instructions=[\"Always respond with 'Hello world!!!'\"]\n)\nhello_world_team = Team(\n    model=Ollama(id=\"qwen2.5:32b\"),\n    members=[echo_agent],\n    mode=\"coordinate\",\n)\n\nhello_world_team.print_response(\"Hello?\")\n```\n\n## Agent Configuration (if applicable)\n\n\n## Expected Behavior\nTeam executes\n\n## Actual Behavior\nError `TypeError: Client.chat() got an unexpected keyword argument 'tool_choice'` when running the team. However, single agents work.\n\n\n## Environment\n- OS: macOS\n- Agno Version: 1.1.15\n",
      "state": "closed",
      "author": "gorootde",
      "author_type": "User",
      "created_at": "2025-03-21T20:26:08Z",
      "updated_at": "2025-03-27T10:16:58Z",
      "closed_at": "2025-03-26T15:59:09Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2491/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2491",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2491",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:51.565194",
      "comments": [
        {
          "author": "jknitey",
          "body": "I also got this error when trying to use ollama with the discussion_team.py example.\n`TypeError: AsyncClient.chat() got an unexpected keyword argument 'tool_choice'`",
          "created_at": "2025-03-21T23:07:14Z"
        },
        {
          "author": "alber70g",
          "body": "I added in `agno/models/ollama/chat.py` the following ~~(line 204)~~ (line 120)\n\nBetter solution:\n\n```diff\n                    for _, obj in tool[\"function\"][\"parameters\"].get(\"properties\", {}).items():  # type: ignore\n                        if \"type\" in obj and isinstance(obj[\"type\"], list) and le",
          "created_at": "2025-03-23T21:04:06Z"
        },
        {
          "author": "pritipsingh",
          "body": "Sorry about that @gorootde - Our team is looking into this and we should have it resolved by next release!",
          "created_at": "2025-03-26T04:29:55Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@jknitey That was fixed in the latest release 1.2.4\n\n@gorootde In addition I can recommend giving the member agent a name. We are adding a warning to make it clearer.\n\n@alber70g Thanks, we are also dealing with this issue in the next release",
          "created_at": "2025-03-26T12:19:56Z"
        },
        {
          "author": "dirkbrnd",
          "body": "I'll release the fix today!",
          "created_at": "2025-03-27T10:16:57Z"
        }
      ]
    },
    {
      "issue_number": 2298,
      "title": "[Bug]Gemini message role with function response may be incorrect",
      "body": "# Description\nNoticed a discrepancy in the way roles are used in messages for the gemini model\n\n## Steps to Reproduce\nCalling a simple function in the python-genai library the roles are always model/user as per the sdk\nhttps://googleapis.github.io/python-genai/genai.html#genai.types.Content.role\n\n    field role: Optional[str] = None\n\n    Optional. The producer of the content. Must be either ‘user’ or ‘model’. Useful to set for multi-turn conversations, otherwise can be left blank or unset. If role is not specified, SDK will determine the role.\n\n```\ndef day_of_week() -> str:\n    \"\"\"Get the current day of the week.\n    Example:\n        {{time.dayOfWeek}} => Sunday\n    \"\"\"\n    now = datetime.datetime.now()\n    return now.strftime(\"%A\")\n\nresponse = client.models.generate_content(\n    model=\"gemini-2.0-flash-exp\",\n    contents=\"What day is it today?\",\n    config=types.GenerateContentConfig(\n        tools=[day_of_week,],\n    ),\n)\npretty.pprint(response)\nGenerateContentResponse(\n│   candidates=[\n│   │   Candidate(\n│   │   │   content=Content(\n│   │   │   │   parts=[\n│   │   │   │   │   Part(\n│   │   │   │   │   │   video_metadata=None,\n│   │   │   │   │   │   thought=None,\n│   │   │   │   │   │   code_execution_result=None,\n│   │   │   │   │   │   executable_code=None,\n│   │   │   │   │   │   file_data=None,\n│   │   │   │   │   │   function_call=None,\n│   │   │   │   │   │   function_response=None,\n│   │   │   │   │   │   inline_data=None,\n│   │   │   │   │   │   text='Today is Tuesday.\\n'\n│   │   │   │   │   )\n│   │   │   │   ],\n│   │   │   │   role='model'\n│   │   │   ),\n│   │   │   citation_metadata=None,\n│   │   │   finish_message=None,\n│   │   │   token_count=None,\n│   │   │   avg_logprobs=-0.00011472310870885849,\n│   │   │   finish_reason=<FinishReason.STOP: 'STOP'>,\n│   │   │   grounding_metadata=None,\n│   │   │   index=None,\n│   │   │   logprobs_result=None,\n│   │   │   safety_ratings=None\n│   │   )\n│   ],\n│   model_version='gemini-2.0-flash-exp',\n│   prompt_feedback=None,\n│   usage_metadata=GenerateContentResponseUsageMetadata(\n│   │   cached_content_token_count=None,\n│   │   candidates_token_count=5,\n│   │   prompt_token_count=106,\n│   │   total_token_count=111\n│   ),\n│   automatic_function_calling_history=[\n│   │   Content(\n│   │   │   parts=[\n│   │   │   │   Part(\n│   │   │   │   │   video_metadata=None,\n│   │   │   │   │   thought=None,\n│   │   │   │   │   code_execution_result=None,\n│   │   │   │   │   executable_code=None,\n│   │   │   │   │   file_data=None,\n│   │   │   │   │   function_call=None,\n│   │   │   │   │   function_response=None,\n│   │   │   │   │   inline_data=None,\n│   │   │   │   │   text='What day is it today?'\n│   │   │   │   )\n│   │   │   ],\n│   │   │   role='user'\n│   │   ),\n│   │   Content(\n│   │   │   parts=[\n│   │   │   │   Part(\n│   │   │   │   │   video_metadata=None,\n│   │   │   │   │   thought=None,\n│   │   │   │   │   code_execution_result=None,\n│   │   │   │   │   executable_code=None,\n│   │   │   │   │   file_data=None,\n│   │   │   │   │   function_call=FunctionCall(id=None, args={}, name='day_of_week'),\n│   │   │   │   │   function_response=None,\n│   │   │   │   │   inline_data=None,\n│   │   │   │   │   text=None\n│   │   │   │   )\n│   │   │   ],\n│   │   │   role='model'\n│   │   ),\n│   │   Content(\n│   │   │   parts=[\n│   │   │   │   Part(\n│   │   │   │   │   video_metadata=None,\n│   │   │   │   │   thought=None,\n│   │   │   │   │   code_execution_result=None,\n│   │   │   │   │   executable_code=None,\n│   │   │   │   │   file_data=None,\n│   │   │   │   │   function_call=None,\n│   │   │   │   │   function_response=FunctionResponse(\n│   │   │   │   │   │   id=None,\n│   │   │   │   │   │   name='day_of_week',\n│   │   │   │   │   │   response={'result': 'Tuesday'}\n│   │   │   │   │   ),\n│   │   │   │   │   inline_data=None,\n│   │   │   │   │   text=None\n│   │   │   │   )\n│   │   │   ],\n│   │   │   role='user'\n│   │   )\n│   ],\n│   parsed=None\n)\n```\nHowever in agno the messages with tools have the role as 'tool'\n\n```\nfrom agno.agent import Agent\nfrom agno.models.google import Gemini\nfrom google.genai import types\nimport google.auth\nimport datetime\nfrom rich import pretty\n\ncredentials, PROJECT_ID = google.auth.default()\nGEMINI_PRO = \"gemini-1.5-pro\"\nGEMINI_FLASH = \"gemini-1.5-flash\"\nLOCATION = \"us-central1\"\n\ngeneration_config = types.GenerateContentConfig(\n    temperature=0,\n    top_p=0.1,\n    top_k=1,\n    max_output_tokens=4096,\n)\n\nsafety_settings = [\n    types.SafetySetting(\n        category=types.HarmCategory.HARM_CATEGORY_UNSPECIFIED,\n        threshold=types.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n    ),\n    types.SafetySetting(\n        category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n        threshold=types.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n    ),\n    types.SafetySetting(\n        category=types.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n        threshold=types.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n    ),\n    types.SafetySetting(\n        category=types.HarmCategory.HARM_CATEGORY_HARASSMENT,\n        threshold=types.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n    ),\n    types.SafetySetting(\n        category=types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n        threshold=types.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n    ),\n]\n\nmodel_choice = Gemini(\n    id=GEMINI_PRO,\n    vertexai=True,\n    project_id=PROJECT_ID,\n    location=LOCATION,\n    generation_config=generation_config,\n    safety_settings=safety_settings,\n)\n\ndef day_of_week() -> str:\n    \"\"\"Get the current day of the week.\n    Example:\n        {{time.dayOfWeek}} => Sunday\n    \"\"\"\n    now = datetime.datetime.now()\n    return now.strftime(\"%A\")\n\nagent = Agent(\n    model=model_choice,\n    tools=[\n       day_of_week\n    ],\n    markdown=True,\n    show_tool_calls=True,\n\n)\nresponse=agent.run(\"What day is it\")\npretty.pprint(response)\n\nRunResponse(\n│   content=' - Running: day_of_week()\\n\\nToday is Wednesday.',\n│   content_type='str',\n│   thinking=None,\n│   event='RunResponse',\n│   messages=[\n│   │   Message(\n│   │   │   role='system',\n│   │   │   content='<additional_information>\\n- Use markdown to format your answers.\\n</additional_information>',\n│   │   │   name=None,\n│   │   │   tool_call_id=None,\n│   │   │   tool_calls=None,\n│   │   │   audio=None,\n│   │   │   images=None,\n│   │   │   videos=None,\n│   │   │   audio_output=None,\n│   │   │   thinking=None,\n│   │   │   redacted_thinking=None,\n│   │   │   provider_data=None,\n│   │   │   reasoning_content=None,\n│   │   │   tool_name=None,\n│   │   │   tool_args=None,\n│   │   │   tool_call_error=None,\n│   │   │   stop_after_tool_call=False,\n│   │   │   add_to_agent_memory=True,\n│   │   │   from_history=False,\n│   │   │   metrics=MessageMetrics(\n│   │   │   │   input_tokens=0,\n│   │   │   │   output_tokens=0,\n│   │   │   │   total_tokens=0,\n│   │   │   │   prompt_tokens=0,\n│   │   │   │   completion_tokens=0,\n│   │   │   │   prompt_tokens_details=None,\n│   │   │   │   completion_tokens_details=None,\n│   │   │   │   additional_metrics=None,\n│   │   │   │   time=None,\n│   │   │   │   time_to_first_token=None,\n│   │   │   │   timer=None\n│   │   │   ),\n│   │   │   references=None,\n│   │   │   created_at=1741206393\n│   │   ),\n│   │   Message(\n│   │   │   role='user',\n│   │   │   content='What day is it',\n│   │   │   name=None,\n│   │   │   tool_call_id=None,\n│   │   │   tool_calls=None,\n│   │   │   audio=None,\n│   │   │   images=None,\n│   │   │   videos=None,\n│   │   │   audio_output=None,\n│   │   │   thinking=None,\n│   │   │   redacted_thinking=None,\n│   │   │   provider_data=None,\n│   │   │   reasoning_content=None,\n│   │   │   tool_name=None,\n│   │   │   tool_args=None,\n│   │   │   tool_call_error=None,\n│   │   │   stop_after_tool_call=False,\n│   │   │   add_to_agent_memory=True,\n│   │   │   from_history=False,\n│   │   │   metrics=MessageMetrics(\n│   │   │   │   input_tokens=0,\n│   │   │   │   output_tokens=0,\n│   │   │   │   total_tokens=0,\n│   │   │   │   prompt_tokens=0,\n│   │   │   │   completion_tokens=0,\n│   │   │   │   prompt_tokens_details=None,\n│   │   │   │   completion_tokens_details=None,\n│   │   │   │   additional_metrics=None,\n│   │   │   │   time=None,\n│   │   │   │   time_to_first_token=None,\n│   │   │   │   timer=None\n│   │   │   ),\n│   │   │   references=None,\n│   │   │   created_at=1741206393\n│   │   ),\n│   │   Message(\n│   │   │   role='assistant',\n│   │   │   content=None,\n│   │   │   name=None,\n│   │   │   tool_call_id=None,\n│   │   │   tool_calls=[{'type': 'function', 'function': {'name': 'day_of_week', 'arguments': '{}'}}],\n│   │   │   audio=None,\n│   │   │   images=None,\n│   │   │   videos=None,\n│   │   │   audio_output=None,\n│   │   │   thinking=None,\n│   │   │   redacted_thinking=None,\n│   │   │   provider_data=None,\n│   │   │   reasoning_content=None,\n│   │   │   tool_name=None,\n│   │   │   tool_args=None,\n│   │   │   tool_call_error=None,\n│   │   │   stop_after_tool_call=False,\n│   │   │   add_to_agent_memory=True,\n│   │   │   from_history=False,\n│   │   │   metrics=MessageMetrics(\n│   │   │   │   input_tokens=37,\n│   │   │   │   output_tokens=5,\n│   │   │   │   total_tokens=42,\n│   │   │   │   prompt_tokens=0,\n│   │   │   │   completion_tokens=0,\n│   │   │   │   prompt_tokens_details=None,\n│   │   │   │   completion_tokens_details=None,\n│   │   │   │   additional_metrics=None,\n│   │   │   │   time=0.9987560000008671,\n│   │   │   │   time_to_first_token=None,\n│   │   │   │   timer=<agno.utils.timer.Timer object at 0x10cc1cfd0>\n│   │   │   ),\n│   │   │   references=None,\n│   │   │   created_at=1741206393\n│   │   ),\n│   │   Message(\n│   │   │   role='tool',\n│   │   │   content=['Wednesday'],\n│   │   │   name=None,\n│   │   │   tool_call_id=None,\n│   │   │   tool_calls=[{'tool_name': 'day_of_week', 'content': 'Wednesday'}],\n│   │   │   audio=None,\n│   │   │   images=None,\n│   │   │   videos=None,\n│   │   │   audio_output=None,\n│   │   │   thinking=None,\n│   │   │   redacted_thinking=None,\n│   │   │   provider_data=None,\n│   │   │   reasoning_content=None,\n│   │   │   tool_name=None,\n│   │   │   tool_args=None,\n│   │   │   tool_call_error=None,\n│   │   │   stop_after_tool_call=False,\n│   │   │   add_to_agent_memory=True,\n│   │   │   from_history=False,\n│   │   │   metrics=MessageMetrics(\n│   │   │   │   input_tokens=0,\n│   │   │   │   output_tokens=0,\n│   │   │   │   total_tokens=0,\n│   │   │   │   prompt_tokens=0,\n│   │   │   │   completion_tokens=0,\n│   │   │   │   prompt_tokens_details=None,\n│   │   │   │   completion_tokens_details=None,\n│   │   │   │   additional_metrics=None,\n│   │   │   │   time=0.0005137909902259707,\n│   │   │   │   time_to_first_token=None,\n│   │   │   │   timer=None\n│   │   │   ),\n│   │   │   references=None,\n│   │   │   created_at=1741206394\n│   │   ),\n│   │   Message(\n│   │   │   role='assistant',\n│   │   │   content='Today is Wednesday.',\n│   │   │   name=None,\n│   │   │   tool_call_id=None,\n│   │   │   tool_calls=None,\n│   │   │   audio=None,\n│   │   │   images=None,\n│   │   │   videos=None,\n│   │   │   audio_output=None,\n│   │   │   thinking=None,\n│   │   │   redacted_thinking=None,\n│   │   │   provider_data=None,\n│   │   │   reasoning_content=None,\n│   │   │   tool_name=None,\n│   │   │   tool_args=None,\n│   │   │   tool_call_error=None,\n│   │   │   stop_after_tool_call=False,\n│   │   │   add_to_agent_memory=True,\n│   │   │   from_history=False,\n│   │   │   metrics=MessageMetrics(\n│   │   │   │   input_tokens=49,\n│   │   │   │   output_tokens=4,\n│   │   │   │   total_tokens=53,\n│   │   │   │   prompt_tokens=0,\n│   │   │   │   completion_tokens=0,\n│   │   │   │   prompt_tokens_details=None,\n│   │   │   │   completion_tokens_details=None,\n│   │   │   │   additional_metrics=None,\n│   │   │   │   time=0.8252798750036163,\n│   │   │   │   time_to_first_token=None,\n│   │   │   │   timer=<agno.utils.timer.Timer object at 0x10dd48b20>\n│   │   │   ),\n│   │   │   references=None,\n│   │   │   created_at=1741206394\n│   │   )\n│   ],\n│   metrics={\n│   │   'input_tokens': [37, 49],\n│   │   'output_tokens': [5, 4],\n│   │   'total_tokens': [42, 53],\n│   │   'prompt_tokens': [0, 0],\n│   │   'completion_tokens': [0, 0],\n│   │   'time': [0.9987560000008671, 0.8252798750036163]\n│   },\n│   model='gemini-1.5-pro',\n│   run_id='b940c876-4330-4351-8c91-02e7376b8d88',\n│   agent_id='04d43c2a-f041-43ba-bed9-633d9afaeb8b',\n│   session_id='8a1743d1-74ad-47dc-8560-ed86908017a1',\n│   workflow_id=None,\n│   tools=[\n│   │   {\n│   │   │   'content': 'Wednesday',\n│   │   │   'tool_call_id': None,\n│   │   │   'tool_name': 'day_of_week',\n│   │   │   'tool_args': {},\n│   │   │   'tool_call_error': False,\n│   │   │   'metrics': MessageMetrics(\n│   │   │   │   input_tokens=0,\n│   │   │   │   output_tokens=0,\n│   │   │   │   total_tokens=0,\n│   │   │   │   prompt_tokens=0,\n│   │   │   │   completion_tokens=0,\n│   │   │   │   prompt_tokens_details=None,\n│   │   │   │   completion_tokens_details=None,\n│   │   │   │   additional_metrics=None,\n│   │   │   │   time=0.0005137909902259707,\n│   │   │   │   time_to_first_token=None,\n│   │   │   │   timer=None\n│   │   │   ),\n│   │   │   'created_at': 1741206394\n│   │   }\n│   ],\n│   images=None,\n│   videos=None,\n│   audio=None,\n│   response_audio=None,\n│   extra_data=None,\n│   created_at=1741206332\n)\n```\n\n## Agent Configuration (if applicable)\nAs above\n\n## Expected Behavior\nI would expect role to follow the gemini spec and be either user or model\n\n## Actual Behavior\nIn testing, I got an error from gemini complaining about an invalid role. I didn't have message logging enabled and could not capture the set of actual messages.\n\n## Environment\n- Agno Version: v1.1.8\n- Additional Environment Details: gemini via vertex\n\n## Possible Solutions (optional)\nI've taken a look at the gemini code, but cannot determine if 'role' is sent as 'tool' to gemini, but would encourage an audit to ensure it does not receive an inappropriate role\n\n\n",
      "state": "closed",
      "author": "jeffbryner",
      "author_type": "User",
      "created_at": "2025-03-05T20:33:10Z",
      "updated_at": "2025-03-27T09:28:37Z",
      "closed_at": "2025-03-27T09:28:36Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2298/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "msaadg"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2298",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2298",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:51.734078",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @jeffbryner ! You are correct, we are using role=tool for function call results. And I also agree that we should be following the Gemini spec for the same. Can you please help me replicate the error that you observed? ",
          "created_at": "2025-03-05T23:02:54Z"
        },
        {
          "author": "jeffbryner",
          "body": "It has been hard to duplicate.\n\nI was able to capture a sample message series before it went to gemini with an errant role type by adding this to here https://github.com/agno-agi/agno/blob/main/libs/agno/agno/models/google/gemini.py#L365\n```\nlogger.info(f\"Starting Gemini API stream with MESSAGES {fo",
          "created_at": "2025-03-06T01:08:45Z"
        },
        {
          "author": "ysolanky",
          "body": "Hey @jeffbryner ! Yes, looks like currently Gemini does not throw an error with role set to tool. But regardless, we should not be using the \"tool\" role as it not officially supported. I am going to update the model class. Thanks for this catch! We really appreciate it ",
          "created_at": "2025-03-14T19:48:22Z"
        },
        {
          "author": "msaadg",
          "body": "Hey @ysolanky if there's not much progress, can I have a go at this? Happy to be assigned this issue!",
          "created_at": "2025-03-16T10:56:12Z"
        }
      ]
    },
    {
      "issue_number": 2442,
      "title": "[Feature Request] Cookbooks for search types",
      "body": "## Problem Description\nCreate cookbooks to demonstrate use of different `search_type` for PgVector \n\n## Proposed Solution\nIn the `cookbook/agent_concepts/knowledge` directory create a new folder `search_type` and populate it with different `search_type` examples using PgVector\n\n[Docs on how to get started\n](https://docs.agno.com/vectordb/pgvector)",
      "state": "closed",
      "author": "ysolanky",
      "author_type": "User",
      "created_at": "2025-03-17T20:35:53Z",
      "updated_at": "2025-03-27T04:36:20Z",
      "closed_at": "2025-03-27T04:36:20Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2442/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lakshdhamija"
      ],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2442",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2442",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:51.937175",
      "comments": [
        {
          "author": "lakshdhamija",
          "body": "Hey @ysolanky can I work on this?",
          "created_at": "2025-03-17T20:37:10Z"
        }
      ]
    },
    {
      "issue_number": 2540,
      "title": "[Bug] TypeError: Client.chat() got an unexpected keyword argument 'tool_choice'",
      "body": "agno==1.2.3\nollama==0.4.7\n\nI am getting the below while using team using Ollama engine run models. I am not sure what changes to be done here to fix this. Need help.\n\n`**TypeError: Client.chat() got an unexpected keyword argument 'tool_choice'**`\n\n**Mocked code:**\n\n```\nfrom agno.agent import Agent\nfrom agno.models.ollama import Ollama\nfrom agno.team import Team\n\nfoo = Agent(\n    name=\"foo\",\n    role=\"testing\",\n    model=Ollama(\n        id=\"qwen2.5:32b\",\n        options={\n            'temperature': 0.2,  \n            'top_k': 30,\n            'top_p': 0.3,\n            'repeat_penalty': 1.1,\n            'seed': 42,\n            'system': \"bla bla\",\n        }\n    ),\n    knowledge=None,\n    description=\"\"\"\n            bla bla\n        \"\"\",\n    instructions=\"\"\"\n            bla bla          \n        \"\"\",\n    markdown=True,\n    search_knowledge=False\n)\n\nboo = Agent(\n    name=\"boo\",\n    role=\"bla bla\",\n    model=Ollama(\n        id=\"qwen2.5:32b\",\n        options={\n            'temperature': 0.2, \n            'top_k': 30,\n            'top_p': 0.3,\n            'repeat_penalty': 1.1,\n            'seed': 42,\n            'system': \"bla bla\",\n        }\n    ),\n    knowledge=None,\n    description=\"\"\"bla bla\n        \"\"\",\n    instructions=\"\"\"bla bla\n        \"\"\",\n    markdown=True,\n    search_knowledge=False\n)\n\nteamm = Team(\n    name=\"teamm\",\n    model=Ollama(\n        id=\"qwen2.5:32b\"\n    ),\n    members=[foo,\n             boo],\n    description=\"bla bla\",\n    markdown=True,\n    show_members_responses=True,\n)\n\nif __name__ == \"__main__\":\n\n    test = \"\"\"bla bla\n                \"\"\"\n\n    result = teamm.run(test)\n    print(result)\n```\n",
      "state": "closed",
      "author": "prasadautomationtesting",
      "author_type": "User",
      "created_at": "2025-03-25T13:03:18Z",
      "updated_at": "2025-03-26T17:53:08Z",
      "closed_at": "2025-03-26T17:53:07Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2540/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2540",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2540",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:52.104463",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @prasadautomationtesting ! A fix for this has been merged and will be out with the next release! Thank you for reporting 🖖 ",
          "created_at": "2025-03-26T17:53:07Z"
        }
      ]
    },
    {
      "issue_number": 2338,
      "title": "Cached Google/DDG-Search to reduce rate limit penalty",
      "body": "## Problem Description\nWhen I try to run an example invoking search, I get hit by DDG and google by a rate limit penalty. Example: \n_cookbook/workflows/mistral_workflows/blog_post_generator.py_\nDuring developement and experimental time, I will run the query about cats and their domination multiple times.  Actually, the blog post example expects the web search and the agent to fail and retries 3 times. When (not if) the web search works fine, but the subsequent json is malformed, DDG will hit its rate limit. Google follows some time later, but still I grind to a halt. \n\n## Proposed Solution\nSimilar to the blog post-cache in the same blog_post_generator, we can provide a CachedGoogleSearchTools. It will store the queries and replies in a cache. This will make developement and reproduction of issues easier.\n\n## Alternatives Considered\n\n- I already switched from DuckDuckGo to the Google search, as DDG hits the rate limit pretty early. \n- We could also use mocks for testing, but during developement, I would like to see a realistic example. \n- Another possibility is a cooldown time. \n- I am not sure, if this is suitable in a real usage - I would expect to run different, not cached queries.\n\n## Additional context\nInclude any extra information that might be helpful, such as:\n- Examples of similar features elsewhere: I adapted the cache from cookbook/workflows/mistral_workflows/blog_post_generator.py \n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[x ] Yes, I’d love to work on it!** - I actually have a solution that \"works for me\"\n**[ ] I’m open to collaborating but need guidance.**\n**[ ] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "janpdevops",
      "author_type": "User",
      "created_at": "2025-03-09T14:51:59Z",
      "updated_at": "2025-03-26T17:21:26Z",
      "closed_at": "2025-03-26T17:21:25Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2338/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2338",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2338",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:52.303320",
      "comments": [
        {
          "author": "Ayush0054",
          "body": "hey @janpdevops Enabling cache on duckduckgo or search tool is a really good suggestion , we have added this in our community wishlist . and let us know if you are open to contribute on this 🙌 ",
          "created_at": "2025-03-12T07:41:40Z"
        },
        {
          "author": "janpdevops",
          "body": "Hello @Ayush0054, thanks for your interest. I get my git setup straight and come back to you.",
          "created_at": "2025-03-16T22:54:09Z"
        },
        {
          "author": "ysolanky",
          "body": "Hello @janpdevops ! We have added the ability to cache search results. Please checkout this [example](https://github.com/agno-agi/agno/blob/fdca10060a824cf190a301dd6548786d69dc138e/cookbook/agent_concepts/other/cache_tool_calls.py#L10)",
          "created_at": "2025-03-26T17:21:25Z"
        }
      ]
    },
    {
      "issue_number": 2454,
      "title": "[Bug] Reasoning does not seem to work with non-reasoning models. \"Adding manual CoT\" does not seem to do anything. ",
      "body": "# Description\nI might be wrong but... When passing a \"regular\" model such 4o-mini as a reasoning model to the agent.reasoning_model argument, the logger.info() message claims to be \"adding manual CoT\" but the code appears to not do anything. \n\nLine 2960 in agent.py\nelse:\n    logger.info(\n        f\"Reasoning model: {reasoning_model.__class__.__name__} is not a native reasoning model, adding manual CoT\"\n    )\n\n## Steps to Reproduce\n    task = (\n        \"Three missionaries and three cannibals need to cross a river. \"\n        \"They have a boat that can carry up to two people at a time. \"\n        \"If, at any time, the cannibals outnumber the missionaries on either side of the river, the cannibals will eat the missionaries. \"\n        \"How can all six people get across the river safely? Provide a step-by-step solution and show the solutions as an ascii diagram\"\n    )\n\n    reasoning_agent = Agent(\n        model=OpenAIChat(id=\"gpt4omini20240718\", client=client),\n        reasoning=True,\n        reasoning_model = OpenAIChat(id=\"gpt4omini20240718\", client=client),\n        markdown=True,\n        structured_outputs=True,\n        telemetry=False,\n        debug_mode=True\n    )\n    reasoning_agent.print_response(task, stream=True, show_full_reasoning=True)\n\n## Agent Configuration (if applicable)\nSee above\n\n## Expected Behavior\nAgent either rejects configuration as incompatible model is provided or actually adds CoT\n\n## Actual Behavior\nInfo message is output that CoT is added but does not appear to do so in practice and code does not appear to have any such functionality\n\n## Screenshots or Logs (if applicable)\n\n![Image](https://github.com/user-attachments/assets/77877aed-ec1d-4618-bd82-417173cf2fbe)\n\n## Environment\n\n\n## Possible Solutions (optional)\nReject configuration (short term fix) to be less misleading and implement CoT (medium term fix) to add the actual functionality. \n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "ekovanda",
      "author_type": "User",
      "created_at": "2025-03-19T10:27:18Z",
      "updated_at": "2025-03-26T09:30:50Z",
      "closed_at": "2025-03-26T09:30:50Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2454/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2454",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2454",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:52.492052",
      "comments": [
        {
          "author": "pritipsingh",
          "body": "Hey @ekovanda Thank you for bringing this to attention- we've fixed this in this [PR](https://github.com/agno-agi/agno/pull/2545) and it should be released soon!",
          "created_at": "2025-03-25T16:58:32Z"
        }
      ]
    },
    {
      "issue_number": 2497,
      "title": "[Bug] Team agent loses context across REST API calls despite consistent session_id and user_id",
      "body": "# Description\nWhen using the Team agent with enable_team_history=True, the system correctly preserves and recalls previous context in a console (stateful) session. However, when using the exact same setup via REST API, the agent loses all context across messages — even though the same session_id and user_id are passed in both cases.\n\nThis issue breaks the experience entirely in web-based or stateless deployments.\n\n\n## Steps to Reproduce\n1. Initialize a Team agent using multiple sub-agents with storage enabled:\n\n```\nself.storage = PostgresStorage(\n    table_name=\"agent_chats\",\n    db_url=os.getenv(\"AGENT_DB_URL\"),\n    auto_upgrade_schema=True\n)\n```\n2. Set enable_team_history=True and pass session_id and user_id.\n3. Run a multi-turn conversation using the console app — works perfectly and recalls context.\n4. Do the same via REST API, passing the same session_id and user_id.\n5. Observe that the second and subsequent calls fail to preserve any memory or context.\n\n## Agent Configuration (if applicable)\n```\nagent = Team(\n    name=\"Orchestrator\",\n    members=[appointment_agent, calories_agent, summary_agent, companion_agent],\n    model=model,\n    mode=\"route\",\n    instructions=[\n        \"Route messages to the correct agent.\",\n        \"Only use the Welcome agent for greetings or unclear tasks.\",\n        \"Avoid direct responses — always route.\",\n        \"Respond in the user’s language (Arabic or English).\"\n    ],\n    enable_team_history=True,\n    num_of_interactions_from_history=5,\n    add_datetime_to_instructions=True,\n    markdown=True,\n)\n```\nAll sub-agents are initialized with storage using PostgresStorage.\n\n\n## Expected Behavior\nSubsequent requests via REST API should retain session context and history as they do in the console version — allowing seamless multi-turn conversations.\n\n## Actual Behavior\nEvery REST request is treated as a new conversation with no prior memory, even with the same session_id and user_id.\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n\n- OS: Ubuntu 22.04 (local + containerized environments)\n- Agno Version: 1.1.15\n- Storage: Postgres via PostgresStorage\n- API Platform: FastAPI\n- Model: OpenAILike, Llama 3, using OpenAI-compatible wrapper\n- Other: Session ID and User ID are explicitly passed and consistent\n\n## Possible Solutions (optional)\n\n- Ensure Team agent can persist and retrieve memory across REST calls using session_id as expected.\n- Allow user-defined context resolvers for team mode if not yet supported.\n- Confirm that internal agent histories are merged or accessible to Team.\n\n\n## Additional Context\nThis is a critical issue for real deployments — our production setup relies on REST APIs, not console mode. Without persistent context in API mode, the Team orchestration agent becomes unusable for multi-turn interactions.\n\nAppreciate your urgent feedback and guidance.\n\nThank you! 🙏\n\n",
      "state": "closed",
      "author": "kasem-io",
      "author_type": "User",
      "created_at": "2025-03-22T13:49:49Z",
      "updated_at": "2025-03-26T08:46:43Z",
      "closed_at": "2025-03-26T08:46:43Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2497/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2497",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2497",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:52.658733",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "@kasem-io this should be resolved with the latest version `1.2.3`",
          "created_at": "2025-03-25T08:13:49Z"
        }
      ]
    },
    {
      "issue_number": 2529,
      "title": "[Bug] JSON Schema and ModelProviderError when using todoist tools",
      "body": "# Description\nI am trying to use the [Todoist tools](https://docs.agno.com/examples/concepts/tools/todoist), but am getting a 400 error due to the JSON schema definitions in the tools\n\n## Steps to Reproduce\nFollow the steps listed on https://docs.agno.com/examples/concepts/tools/todoist. I encountered the error when using Gemini models or Claude models (and I made sure to use models that support function calling).\n\n## Agent Configuration (if applicable)\nAs shown on https://docs.agno.com/examples/concepts/tools/todoist.\n\n## Expected Behavior\nI expected the agent to make function calls to Todoist API.\n\n## Actual Behavior\nThe agent throws a 400 error when enabling `tools=[TodoistTools()]`.\n\n## Environment\n- OS: macOS 15.3.2\n- Agno Version: 1.2.3\n- Additional Environment Details: Python 3.12\n\n## Screenshots or Logs (if applicable)\n```\nDEBUG Can you list all of my tasks?\n\n/Users/koverholt/miniforge3/lib/python3.12/site-packages/google/genai/_common.py:232: UserWarning:  is not a valid Type\n  warnings.warn(f\"{value} is not a valid {cls.__name__}\")\nERROR    Error from Gemini API: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Invalid value at\n         \\'tools[0].function_declarations[2].parameters.properties[1].value.type\\'\n         (type.googleapis.com/google.ai.generativelanguage.v1beta.Type), \"\"', 'status': 'INVALID_ARGUMENT',\n         'details': [{'@type': 'type.googleapis.com/google.rpc.BadRequest', 'fieldViolations': [{'field':\n         'tools[0].function_declarations[2].parameters.properties[1].value.type', 'description': 'Invalid\n         value at \\'tools[0].function_declarations[2].parameters.properties[1].value.type\\'\n         (type.googleapis.com/google.ai.generativelanguage.v1beta.Type), \"\"'}]}]}}\nWARNING  Attempt 1/1 failed: <Response [400]>\nERROR    Failed after 1 attempts. Last error using Gemini(gemini-2.0-flash)\n2025-03-24 23:21:52.602 Uncaught app execution\nTraceback (most recent call last):\n  File \"/Users/koverholt/miniforge3/lib/python3.12/site-packages/agno/models/google/gemini.py\", line 339, in invoke\n    return self.get_client().models.generate_content(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/koverholt/miniforge3/lib/python3.12/site-packages/google/genai/models.py\", line 5164, in generate_content\n    response = self._generate_content(\n               ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/koverholt/miniforge3/lib/python3.12/site-packages/google/genai/models.py\", line 4239, in _generate_content\n    response_dict = self._api_client.request(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/koverholt/miniforge3/lib/python3.12/site-packages/google/genai/_api_client.py\", line 553, in request\n    response = self._request(http_request, stream=False)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/koverholt/miniforge3/lib/python3.12/site-packages/google/genai/_api_client.py\", line 467, in _request\n    return self._request_unauthorized(http_request, stream)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/koverholt/miniforge3/lib/python3.12/site-packages/google/genai/_api_client.py\", line 490, in _request_unauthorized\n    errors.APIError.raise_for_response(response)\n  File \"/Users/koverholt/miniforge3/lib/python3.12/site-packages/google/genai/errors.py\", line 115, in raise_for_response\n    raise ClientError(status_code, response)\ngoogle.genai.errors.ClientError: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Invalid value at \\'tools[0].function_declarations[2].parameters.properties[1].value.type\\' (type.googleapis.com/google.ai.generativelanguage.v1beta.Type), \"\"', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.BadRequest', 'fieldViolations': [{'field': 'tools[0].function_declarations[2].parameters.properties[1].value.type', 'description': 'Invalid value at \\'tools[0].function_declarations[2].parameters.properties[1].value.type\\' (type.googleapis.com/google.ai.generativelanguage.v1beta.Type), \"\"'}]}]}}\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/koverholt/miniforge3/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 121, in exec_func_with_error_handling\n    result = func()\n             ^^^^^^\n  File \"/Users/koverholt/miniforge3/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 593, in code_to_exec\n    exec(code, module.__dict__)\n  File \"/Users/koverholt/Repos/life/Services/chat/app.py\", line 154, in <module>\n    response = todoist_agent.run(prompt)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/koverholt/miniforge3/lib/python3.12/site-packages/agno/agent/agent.py\", line 1009, in run\n    f\"Failed after {num_attempts} attempts. Last error using {last_exception.model_name}({last_exception.model_id})\"\n    ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/koverholt/miniforge3/lib/python3.12/site-packages/agno/agent/agent.py\", line 979, in run\n    **kwargs,\n       ^^^^^^^\n  File \"/Users/koverholt/miniforge3/lib/python3.12/site-packages/agno/agent/agent.py\", line 694, in _run\n    else:\n\n  File \"/Users/koverholt/miniforge3/lib/python3.12/site-packages/agno/models/base.py\", line 175, in response\n    assistant_message, has_tool_calls = self._process_model_response(\n                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/koverholt/miniforge3/lib/python3.12/site-packages/agno/models/base.py\", line 311, in _process_model_response\n    response = self.invoke(messages=messages)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/koverholt/miniforge3/lib/python3.12/site-packages/agno/models/google/gemini.py\", line 346, in invoke\n    raise ModelProviderError(\nagno.exceptions.ModelProviderError: <Response [400]>\n```",
      "state": "closed",
      "author": "koverholt",
      "author_type": "User",
      "created_at": "2025-03-25T04:24:21Z",
      "updated_at": "2025-03-26T08:44:43Z",
      "closed_at": "2025-03-25T15:30:07Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2529/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2529",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2529",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:52.885538",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Fix incoming!",
          "created_at": "2025-03-25T08:12:00Z"
        },
        {
          "author": "koverholt",
          "body": "Confirming that the Todoist tool is working as expected now in 1.2.4. Thanks for the quick fix and the awesome agent lib! ❤ ",
          "created_at": "2025-03-26T03:14:52Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Thanks for confirming!\n",
          "created_at": "2025-03-26T08:44:42Z"
        }
      ]
    },
    {
      "issue_number": 1974,
      "title": "[Feature Request] firestore agent memory",
      "body": "## Problem Description\nI'd like to use serverless databases for agent memory. Being in a google environment, firestore is ideal.\n\n## Proposed Solution\nProvide a firestore provider (agno/db/memory/firestore)\n\n## Alternatives Considered\nUsing other providers requires a server or a file store (sqlite)\n\n## Would you like to work on this?\nI'll fork and provide a pull request.\n",
      "state": "closed",
      "author": "jeffbryner",
      "author_type": "User",
      "created_at": "2025-02-01T18:38:26Z",
      "updated_at": "2025-03-26T06:47:46Z",
      "closed_at": "2025-03-26T06:47:45Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/1974/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/1974",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/1974",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:53.050844",
      "comments": [
        {
          "author": "manthanguptaa",
          "body": "Thank you so much @jeffbryner for working on this issue. I will review the PR shortly",
          "created_at": "2025-02-03T04:19:49Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-02-18T00:29:36Z"
        },
        {
          "author": "jeffbryner",
          "body": "re-open?",
          "created_at": "2025-02-18T01:21:52Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @jeffbryner,\n\nWe're in the midst of a busy launch week, so we haven’t had a chance to review your PR yet. The team will share feedback and any required changes directly in the PR thread.\n\nAppreciate your patience! Closing this issue for now",
          "created_at": "2025-03-26T06:47:45Z"
        }
      ]
    },
    {
      "issue_number": 1977,
      "title": "[Feature Request] Firestore agent session storage",
      "body": "## Problem Description\nI'd like to be able to use firestore to store agent session information\n\n## Proposed Solution\nI'll create a class based on the mongo class that uses firestore instead.\n\n## Alternatives Considered\nFirestore allows you to avoid having a server and is simpler to start up and maintain.\n\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[x] Yes, I’d love to work on it!**\n\nI'll send a PR to add the class\n",
      "state": "closed",
      "author": "jeffbryner",
      "author_type": "User",
      "created_at": "2025-02-02T00:07:45Z",
      "updated_at": "2025-03-26T06:47:10Z",
      "closed_at": "2025-03-26T06:47:09Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/1977/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/1977",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/1977",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:53.240256",
      "comments": [
        {
          "author": "manthanguptaa",
          "body": "Thanks @jeffbryner! This was something on our roadmap, and I was going to work on it. Thank you so much for taking this up and raising a PR. I will review it soon",
          "created_at": "2025-02-03T04:19:10Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-02-18T00:29:35Z"
        },
        {
          "author": "jeffbryner",
          "body": "re-open?",
          "created_at": "2025-02-18T01:22:08Z"
        },
        {
          "author": "jeffbryner",
          "body": "Still interested?",
          "created_at": "2025-03-01T20:30:53Z"
        },
        {
          "author": "monali7-d",
          "body": "Hey @jeffbryner,  \n\nWe're in the midst of a busy launch week, so we haven’t had a chance to review your PR yet. The team will share feedback and any required changes directly in the PR thread.  \n\nAppreciate your patience! Closing this issue for now. ",
          "created_at": "2025-03-26T06:47:09Z"
        }
      ]
    },
    {
      "issue_number": 2057,
      "title": "[Bug] User memory imported to session memory",
      "body": "# Description\nThere is the concept of storage and the concept of memory. There appears to be an unintended overlap between them which pulls user memories into session storage even if the conversation or tasks are unrelated.\n\n## Steps to Reproduce\nCreate an agent using storage and memory with multiple chat sessions. \nIf a session results in 'user' memory being updated that update will be pulled into sessions as 'session memory'.\n\n## Agent Configuration (if applicable)\n```\nagent = Agent(\n    telemetry=False,\n    user_id=\"0x7eff@jeffbryner.com\",\n    model=Gemini(\n        id=model,\n        generation_config=generation_config,\n        safety_settings=safety_settings,\n        system_prompt=system_prompt,\n    ),\n    storage=FirestoreAgentStorage(\n        collection_name=\"agent_sessions\",\n    ),\n    # Store memories in Firestore, options off\n    memory=AgentMemory(\n        db=FirestoreMemoryDb(),\n        create_user_memories=True,\n        create_session_summary=True,\n        update_user_memories_after_run=True,\n        update_session_summary_after_run=True,\n        classifier=MemoryClassifier(model=Gemini(id=\"gemini-1.5-pro\")),\n        summarizer=MemorySummarizer(model=Gemini(id=\"gemini-1.5-pro\")),\n        manager=MemoryManager(model=Gemini(id=\"gemini-1.5-pro\")),\n    ),\n    # Set add_history_to_messages=true to add the previous chat history to the messages sent to the Model.\n    add_history_to_messages=True,\n    # Number of historical responses to add to the messages.\n    num_history_responses=10,\n    create_default_user_message=False,\n    retries=3,\n    instructions=system_prompt,\n    markdown=True,\n)\n```\n\n## Expected Behavior\nI expected the user memory store to updated with key facts about the user (name, interests, etc) and the session memory store to remain relevant to the session. \n\n## Actual Behavior\nThe user memory store was updated according to a conversation in a session. That session included the memories. \nWhen starting another conversation in a different session, the memories from the user were imported into this session but we not relevant. \n\n## Screenshots or Logs (if applicable)\n### User memory after a conversation about beer:\n![User memory storing facts](https://github.com/user-attachments/assets/f692f353-13fa-4707-a5d0-385154fe9b29)\n\n### Session data object after the same conversation:\n![Session data object for a conversation about beer](https://github.com/user-attachments/assets/344c868f-943e-470d-87c5-4d7f2db223d8)\n\n### Session data after a subsequent conversation about whiskey:\n![Session data object for a conversation about whiskey](https://github.com/user-attachments/assets/91acc95f-616a-49b2-a9cc-5babc294ea23)\n\n## Environment\n- OS: (container: python3.10-slim)\n- External Dependency Versions: (firestore storage PRs https://github.com/agno-agi/agno/pull/1978 https://github.com/agno-agi/agno/pull/1977)\n- Additional Environment Details: (Python 3.10 in cloudrun)\n\n## Possible Solutions (optional)\nI believe this is happening due to the agent.get_agent_session pulling in memories from the user memory store\nhttps://github.com/agno-agi/agno/blob/main/libs/agno/agno/agent/agent.py#L1453\n\n'Memory' is stored and retrieved by user id. https://github.com/agno-agi/agno/blob/main/libs/agno/agno/memory/db/mongodb.py#L71\n'Session' storage is by session ID and user idbut due to the call above in get_agent_session it imports user memories. https://github.com/agno-agi/agno/blob/main/libs/agno/agno/storage/agent/mongodb.py#L61\n\nLater when the agent saves it's information to storage, this is used as 'memories' in the session data object. \n\nCould there be a flag to not store user memory in the session? This would make it clear that they are only related to the user and not the session.\nCould there be a better prompt for user memory such that it is less about the conversation and more about the facts (name, likes, etc)? This way it would be less likely to influence the session conversation.\n\n## Additional Context\nThis could lead to confusing inferences from the model if it stores data in one context, but uses it in another session inappropriately. \n",
      "state": "closed",
      "author": "jeffbryner",
      "author_type": "User",
      "created_at": "2025-02-09T18:57:17Z",
      "updated_at": "2025-03-26T06:45:50Z",
      "closed_at": "2025-03-26T06:45:50Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2057/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2057",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2057",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:53.469248",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-02-24T00:31:28Z"
        },
        {
          "author": "jeffbryner",
          "body": "are there planned bugs? 🤪\r\n\r\nOn Sun, Feb 23, 2025, 4:31 PM github-actions[bot] ***@***.***>\r\nwrote:\r\n\r\n> Closed #2057 <https://github.com/agno-agi/agno/issues/2057> as not\r\n> planned.\r\n>\r\n> —\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/agno-agi/agno/issues/2057#event-16",
          "created_at": "2025-02-24T01:15:56Z"
        },
        {
          "author": "manthanguptaa",
          "body": "Hey @jeffbryner! Thanks so much for bringing this up. I really appreciate it. I'll take a close look at it soon and will have a fix pushed as soon as possible. Thanks for your patience! ",
          "created_at": "2025-02-28T06:36:51Z"
        }
      ]
    },
    {
      "issue_number": 2230,
      "title": "[Bug] Boto Session doesn't support Session Token",
      "body": "# Description\nBoto Session doesn't support Session Token\n\n## Steps to Reproduce\n\n~/.aws/credentials\n```\n[my_profile]\naws_access_key_id = XXXXXX\naws_secret_access_key = XXXXXX\naws_session_token = XXXXXXXXXXXXXXXXXXXXXXXX\naws_security_token = XXXXXXXXXXXXXXXXXXXXXXXX\nx_security_token_expires = 2025-02-25T21:22:42+00:00\n```\n\n```python\nimport boto3\n\nfrom agno.agent import Agent\nfrom agno.models.aws.claude import Claude\n\nsession = boto3.Session(profile_name=\"my_profile\")\n\nmodel_id = \"us.anthropic.claude-3-5-haiku-20241022-v1:0\"\nmodel = Claude(id=model_id, session=session)\n\nagent = Agent(\n    model=model,\n    instructions=\"You are a Claude model trained on haiku. Write a haiku about the current weather.\",\n    markdown=True,\n    stream=True,\n)\n\nagent.print_response(\"The sun is shining\", stream=True)\n```\n\n## Agent Configuration (if applicable)\nProvide relevant agent configuration.\n\n## Expected Behavior\n\n<img width=\"1063\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/26b8f377-ab6a-4de7-814a-7383f9b38128\" />\n\n## Actual Behavior\n\n<img width=\"1060\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/6a03f1dc-18bc-47c4-ba03-e2eaf71c90aa\" />\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- OS: macOS 15.3\n- Browser (if relevant): N/A\n- Agno Version: v1.1.6\n- External Dependency Versions:\n       boto3==1.37.0\n- Additional Environment Details: Python 3.12\n\n## Possible Solutions (optional)\nI have tested adding `aws_session_token` param to client_params and it worked, then I realized that Claude class doesn't support session token at all. I could find the problem but I don't have much with python to submit a pull request and make sure I'm not breaking anything.\n<img width=\"672\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/18eeff70-21ea-4a7c-9b2c-8398590e0a03\" />\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "FelipeCCSacramento",
      "author_type": "User",
      "created_at": "2025-02-25T21:41:56Z",
      "updated_at": "2025-03-26T05:26:17Z",
      "closed_at": "2025-03-26T05:26:17Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2230/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2230",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2230",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:53.739274",
      "comments": [
        {
          "author": "pritipsingh",
          "body": "Thanks for letting us know @FelipeCCSacramento ! We're working on this!",
          "created_at": "2025-02-27T12:57:22Z"
        }
      ]
    },
    {
      "issue_number": 2334,
      "title": "[Bug] Azure URL is wrong",
      "body": "# Description\nI'm using Azure OpenAI API, base URL format is: \nhttps://myproject.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-10-21\nIf I use the base URL:\nhttps://myproject..openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions\nAgno tried to connect to:\nhttps://jarvis-openai-eastus.openai.azure.com/openai/deployments/gpt-4o-mini/openai/chat/completions?api-version=2024-10-21\nAdding the openai into the path for some reason?\n\n## Steps to Reproduce\nSet AZURE_OPENAI_ENDPOINT=https://myproject..openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions\n\n## Agent Configuration (if applicable)\n`agent = Agent(\n        model=AzureOpenAI(\n            id=os.getenv(\"AZURE_DEPLOYMENT\"),\n            api_version=os.getenv(\"AZURE_API_VERSION\"),\n            )`\n\n## Expected Behavior\nIt was meant to connect, instead I get \"HTTP/1.1 404 Resource Not Found\"\n\n## Actual Behavior\nWhat actually happened instead?\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- OS: (e.g. macOS, Windows 11)\n- Browser (if relevant): (e.g. Chrome 108, Firefox 107)\n- Agno Version: (e.g. v1.0.0)\n- External Dependency Versions: (e.g., yfinance 0.2.52)\n- Additional Environment Details: (e.g., Python 3.10)\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "yusufk",
      "author_type": "User",
      "created_at": "2025-03-08T17:58:27Z",
      "updated_at": "2025-03-26T05:19:34Z",
      "closed_at": "2025-03-26T05:19:33Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2334/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2334",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2334",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:54.005330",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @yusufk !\n\nThe api key, endpoint and deployment are picked up from the following env variables: \n```python\nself.api_key = self.api_key or getenv(\"AZURE_OPENAI_API_KEY\")\nself.azure_endpoint = self.azure_endpoint or getenv(\"AZURE_OPENAI_ENDPOINT\")\nself.azure_deployment = self.azure_deployment or",
          "created_at": "2025-03-10T17:12:59Z"
        },
        {
          "author": "yusufk",
          "body": "Thanks, I've tried that and all variants of keys. It seems to \"fall back\" on OPENAI. I suspect that there is some confusion between Azure OpenAI and Foundry, as some of my deployments were migrated. ",
          "created_at": "2025-03-14T04:31:10Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@yusufk are you on the latest version of agno? I am unable to replicate the issue",
          "created_at": "2025-03-14T10:26:38Z"
        },
        {
          "author": "dirkbrnd",
          "body": "The bedrock and openai implementations are completely separate.",
          "created_at": "2025-03-14T10:26:58Z"
        },
        {
          "author": "dirkbrnd",
          "body": "I would also recommend not setting `id=os.getenv(\"AZURE_DEPLOYMENT\")` because `id` refers to the model ID, so it could be that inside the OpenAI library it is building up a URL.\n\nI can recommend not padding AZURE_OPENAI_API_KEY and AZURE_OPENAI_ENDPOINT via the Model itself but just setting the envi",
          "created_at": "2025-03-14T10:29:32Z"
        }
      ]
    },
    {
      "issue_number": 2207,
      "title": "[Bug] Passing the api_key to OpenAIEmbedder does not work",
      "body": "# Description\nPassing the api_key to OpenAIEmbedder does not work\n\n## Steps to Reproduce\nOpenAIEmbedder(api_key=\"<api_key>\")\n\n## Agent Configuration (if applicable)\nKnowledgeBase with pgVector\n\n## Expected Behavior\nWhat did you expect to happen?\nIt should use the api_key passed as parameter, instead of depending on env variable\n\n## Actual Behavior\nWhat actually happened instead?\nIt throws an error that api_key is not set\n\n## Screenshots or Logs (if applicable)\n```\nUserWarning: Failed to load OpenAIEmbeddings: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable. Falling back to default <class 'chonkie.embeddings.openai.OpenAIEmbeddings'> model\n```\n## Environment\n- OS: Fedora 41\n- Browser (if relevant): (e.g. Chrome 108, Firefox 107)\n- Agno Version: 1.1.4\n- External Dependency Versions: OpenAI - 1.64.0\n- Additional Environment Details: Python 3.13)\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "kidrahdev",
      "author_type": "User",
      "created_at": "2025-02-23T00:04:13Z",
      "updated_at": "2025-03-26T05:18:46Z",
      "closed_at": "2025-03-26T05:18:45Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2207/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2207",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2207",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:54.244199",
      "comments": [
        {
          "author": "mishramonalisha76",
          "body": "Hi @kidrahdev , Thanks for reaching out. Unfortunately we are not able to replicate the issue on our end. Can you please confirm once that you have not set your ` OPENAI_API_KEY`  to empty or something else?",
          "created_at": "2025-02-24T10:40:25Z"
        },
        {
          "author": "kidrah-bhq",
          "body": "I can confirm that, if I set it to env variables my code works but if I don't set anything and pass the same key as a parameter the above error is thrown",
          "created_at": "2025-02-25T06:50:53Z"
        },
        {
          "author": "willemcdejongh",
          "body": "Hi @kidrah-bhq  Perhaps share a snippet of your usage please.\nI just tested it and working as expected.",
          "created_at": "2025-03-19T09:24:27Z"
        },
        {
          "author": "ysolanky",
          "body": "Closing due to inactivity ",
          "created_at": "2025-03-26T05:18:45Z"
        }
      ]
    },
    {
      "issue_number": 2401,
      "title": "Support for Gemini File API",
      "body": "As far as I can tell, there is not yet support for the Gemini File API. \n\nI noticed the latest 1.1.11 changes that added the File type to Gemini and Anthropic models support direct url downloads, which is insufficient for the file URI object that the Gemini File API returns.\n\nGemini File API reference: https://ai.google.dev/api/files#example-request\nGemini File API cookbook from Google: https://github.com/google-gemini/cookbook/blob/main/quickstarts/file-api/sample.py\n\nThe Gemini File API is hugely useful for large volumes of PDF, and images and videos too. \n\nIs Gemini File API support part of the roadmap?\n\nThank you",
      "state": "closed",
      "author": "DavidZachariahWC",
      "author_type": "User",
      "created_at": "2025-03-13T21:25:25Z",
      "updated_at": "2025-03-26T05:17:22Z",
      "closed_at": "2025-03-26T05:17:22Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2401/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2401",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2401",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:54.511741",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @DavidZachariahWC ! Our implementation of Gemini File upload is not just limited to Pdfs. You can add any of the supported [mimetypes](https://ai.google.dev/gemini-api/docs/document-processing?lang=python) and provide it to the Agent. For example:\n\n```python\nfrom agno.agent import Agent\nfrom a",
          "created_at": "2025-03-14T04:04:55Z"
        }
      ]
    },
    {
      "issue_number": 2541,
      "title": "[Bug]Basic usage of Ollama not working",
      "body": "# Description\nI tried the example of https://github.com/agno-agi/agno/blob/main/cookbook/models/ollama/basic.py, but it didn't work. See the error as shown in the image file\n\n## Steps to Reproduce\nI used the steps as described in the documentation. You can see that ollama is running, but it shows ConnectionError. Is there anything that I am missing？\n![Image](https://github.com/user-attachments/assets/3e95314f-6ff4-46d9-9550-e12571dfd467)\n\n## Agent Configuration (if applicable)\nI used the steps as described in the documentation\n\n## Expected Behavior\nI used the steps as described in the documentation.\n\n## Actual Behavior\nSee the image attatched.\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- OS: (e.g. macOS, Windows 11) Windows 11\n- Browser (if relevant): (e.g. Chrome 108, Firefox 107)\n- Agno Version: (e.g. v1.0.0)\n- External Dependency Versions: (e.g., yfinance 0.2.52)\n- Additional Environment Details: (e.g., Python 3.10)\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "ClusterA-DragReduction",
      "author_type": "User",
      "created_at": "2025-03-25T14:12:19Z",
      "updated_at": "2025-03-26T04:17:09Z",
      "closed_at": "2025-03-26T04:17:09Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2541/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2541",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2541",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:54.705698",
      "comments": [
        {
          "author": "Ayush0054",
          "body": "Hey @ClusterA-DragReduction, just a quick check — is Ollama currently running?\nIf not, kindly start the model using: \n\n```ollama run llama3.1:8b``` \n\nOnce it’s up and running, please re-run the Python file. Thanks! 😊\n\n\n<img width=\"1692\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e25",
          "created_at": "2025-03-25T14:41:43Z"
        },
        {
          "author": "ClusterA-DragReduction",
          "body": "Yes, I am pretty sure ollama is running. You can see from my screenshot, before the error message, \"ollama ps\" command showed what model was running. \n\n![Image](https://github.com/user-attachments/assets/5028fadf-98af-43f5-bc2a-0eaedf31c2cf)",
          "created_at": "2025-03-26T01:28:48Z"
        },
        {
          "author": "ClusterA-DragReduction",
          "body": "I found the problem. Earlier I set OLLAMA_HOST to 0.0.0.0:11434 so that the apps in the same network can access ollama server. When I used the code, client_params returns None in ollama\\chat.py. I switched 0.0.0.0:11434 to localhost:11434, now it is working. See the snapshot. I guess some clarificat",
          "created_at": "2025-03-26T03:32:18Z"
        },
        {
          "author": "ysolanky",
          "body": "Hey @ClusterA-DragReduction sorry about that. Yes, we will update the docs with this insight. Thank you! ",
          "created_at": "2025-03-26T04:17:09Z"
        }
      ]
    },
    {
      "issue_number": 2313,
      "title": "[Bug] MCP on Windows not working",
      "body": "# Description\nHey I am getting this error:\n```\n(.venv) PS C:\\Users\\jawei\\mcp-test> python .\\filesystem.py\nTraceback (most recent call last):\n  File \"C:\\Users\\jawei\\mcp-test\\filesystem.py\", line 75, in <module>\n    asyncio.run(run_agent(\"What is the license for this project?\"))\n  File \"C:\\Users\\jawei\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\runners.py\", line 44, in run\n    return loop.run_until_complete(main)\n  File \"C:\\Users\\jawei\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 649, in run_until_complete\n    return future.result()\n  File \"C:\\Users\\jawei\\mcp-test\\filesystem.py\", line 66, in run_agent\n    async with stdio_client(server_params) as (read, write):\n  File \"C:\\Users\\jawei\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py\", line 199, in __aenter__\n    return await anext(self.gen)\n  File \"C:\\Users\\jawei\\mcp-test\\.venv\\lib\\site-packages\\mcp\\client\\stdio.py\", line 100, in stdio_client\n    process = await anyio.open_process(\n  File \"C:\\Users\\jawei\\mcp-test\\.venv\\lib\\site-packages\\anyio\\_core\\_subprocesses.py\", line 184, in open_process\n    return await get_async_backend().open_process(\n  File \"C:\\Users\\jawei\\mcp-test\\.venv\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2552, in open_process\n    process = await asyncio.create_subprocess_exec(\n  File \"C:\\Users\\jawei\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\subprocess.py\", line 218, in create_subprocess_exec\n    transport, protocol = await loop.subprocess_exec(\n  File \"C:\\Users\\jawei\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1681, in subprocess_exec\n    transport = await self._make_subprocess_transport(\n  File \"C:\\Users\\jawei\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\windows_events.py\", line 399, in _make_subprocess_transport\n    transp = _WindowsSubprocessTransport(self, protocol, args, shell,\n  File \"C:\\Users\\jawei\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_subprocess.py\", line 36, in __init__     \n    self._start(args=args, shell=shell, stdin=stdin, stdout=stdout,\n  File \"C:\\Users\\jawei\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\windows_events.py\", line 901, in _start       \n    self._proc = windows_utils.Popen(\n  File \"C:\\Users\\jawei\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\windows_utils.py\", line 153, in __init__      \n    super().__init__(args, stdin=stdin_rfd, stdout=stdout_wfd,\n  File \"C:\\Users\\jawei\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py\", line 971, in __init__\n    self._execute_child(args, executable, preexec_fn, close_fds,\n  File \"C:\\Users\\jawei\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py\", line 1456, in _execute_child\n    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\nFileNotFoundError: [WinError 2] The system cannot find the file specified\n```\n## Steps to Reproduce\nFollowing this example:\n`https://github.com/agno-agi/agno/blob/main/cookbook/tools/mcp/README.md`\n\nSpecifically getting error on filesystem.py\n\n## Environment\n- OS: Windows 11\n- Browser (if relevant): (e.g. Chrome 108, Firefox 107)\n- Agno Version: v1.1.9",
      "state": "closed",
      "author": "jacobweiss2305",
      "author_type": "User",
      "created_at": "2025-03-06T18:57:53Z",
      "updated_at": "2025-03-26T00:31:34Z",
      "closed_at": "2025-03-26T00:31:34Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2313/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2313",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2313",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:54.881471",
      "comments": [
        {
          "author": "SabaPivot",
          "body": "Were you able to install `mcp` by `pip install agno mcp openai`?\n\n`pip install mcp` actually gives error for me.\n",
          "created_at": "2025-03-07T03:01:07Z"
        },
        {
          "author": "senthilkumaranT",
          "body": "> Were you able to install `mcp` by `pip install agno mcp openai`?\n> \n> `pip install mcp` actually gives error for me.\n\nif you update your agno using \"pip install --upgrade agno\" . you maynot get any error ",
          "created_at": "2025-03-07T05:18:22Z"
        },
        {
          "author": "SabaPivot",
          "body": "Team Agno has not updated the pip package yet. \n\nYou should manually write agno.tools.mcp.py to your local project.\n\nhere is the link:\nhttps://github.com/agno-agi/agno/blob/f5b49641b4b5660fab773c8f2cdb71eef1613e64/libs/agno/agno/tools/mcp.py#L4\n\n> > Were you able to install `mcp` by `pip install agn",
          "created_at": "2025-03-07T08:55:33Z"
        },
        {
          "author": "senthilkumaranT",
          "body": "> Team Agno has not updated the pip package yet.\n> \n> You should manually write agno.tools.mcp.py to your local project.\n> \n> here is the link:\n> \n> [agno/libs/agno/agno/tools/mcp.py](https://github.com/agno-agi/agno/blob/f5b49641b4b5660fab773c8f2cdb71eef1613e64/libs/agno/agno/tools/mcp.py#L4)\n> \n> ",
          "created_at": "2025-03-07T10:03:55Z"
        },
        {
          "author": "jacobweiss2305",
          "body": "@ysolanky can you give this a look when you get a min please",
          "created_at": "2025-03-07T16:54:01Z"
        }
      ]
    },
    {
      "issue_number": 2511,
      "title": "[Bug] multi mcp server",
      "body": "Does agno support multi mcp servers?\n\nlike:\n\nserver_params1 = StdioServerParameters(\n        command=\"uvx\",\n        args=[\"terminal_controller\"],\n    )\n\nserver_params2 = StdioServerParameters(\n        command=\"uvx\",\n        args=[\"python_controller\"],\n    )\n\nasync with stdio_client([server_params1 ,server_params2]) as (read, write):\n        async with ClientSession(read, write) as session:",
      "state": "closed",
      "author": "SokeWang",
      "author_type": "User",
      "created_at": "2025-03-24T07:27:11Z",
      "updated_at": "2025-03-25T03:24:55Z",
      "closed_at": "2025-03-24T15:14:10Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2511/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2511",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2511",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:55.095372",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Hi! I am releasing a new way to do this today! ",
          "created_at": "2025-03-24T08:23:49Z"
        },
        {
          "author": "dirkbrnd",
          "body": "https://github.com/agno-agi/agno/releases/tag/v1.2.0 contains some examples.\n\nSome docs:\nhttps://docs.agno.com/tools/mcp#multiple-mcp-servers",
          "created_at": "2025-03-24T15:14:10Z"
        },
        {
          "author": "SokeWang",
          "body": "AMAZING AGNO!!!",
          "created_at": "2025-03-25T03:24:54Z"
        }
      ]
    },
    {
      "issue_number": 2346,
      "title": "[Feature Request] Agent Monitoring & Orchestration for Agno",
      "body": "## Problem Description\n\nI would like to monitor my agents more precisely, similar to how [AgentOps](https://www.agentops.ai/) provides insights and management tools. However, AgentOps does not currently support Agno.\n\nDo you have any plans to develop a native monitoring and orchestration platform for Agno? It would be great. If so, is there an estimated timeline for its release?\n\nThis feature would greatly enhance observability and control over agents, making Agno more robust for production use.\n\nThanks for your time and consideration!\n\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[ ] Yes, I’d love to work on it!**\n**[ ] I’m open to collaborating but need guidance.**\n**[x] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "lironesamoun",
      "author_type": "User",
      "created_at": "2025-03-10T09:33:09Z",
      "updated_at": "2025-03-25T00:31:54Z",
      "closed_at": "2025-03-25T00:31:54Z",
      "labels": [
        "enhancement",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2346/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2346",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2346",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:55.267246",
      "comments": [
        {
          "author": "manthanguptaa",
          "body": "Hey @lironesamoun, we do have a platform that you can access here https://app.agno.com/\nWe would love your feedback on it",
          "created_at": "2025-03-10T10:45:46Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-03-25T00:31:53Z"
        }
      ]
    },
    {
      "issue_number": 2489,
      "title": "[Bug] Can not use Azure OpenAI to create an agent",
      "body": "# Description\nI am using agno version `1.1.15` and when trying to use a simple agent using Azure OpenAI I am getting this error:\n```\nModuleNotFoundError: No module named 'anthropic'\n```\n\n## Steps to Reproduce\nCreate a simple agent like this:\n```python\nfrom agno.agent import Agent\nfrom agno.models.azure import AzureOpenAI\n\nmodel = AzureOpenAI(\n    id=\"gpt-4o-mini\",\n    api_key=\"...\",\n    api_version=\"...\",\n    azure_endpoint=\"...\",\n    azure_deployment=\"gpt-4o-mini\",\n)\n\nagent = Agent(\n    model=model,\n    description=\"You are an enthusiastic news reporter with a flair for storytelling!\",\n    markdown=True\n)\nagent.print_response(\"Tell me about a breaking news story from New York.\", stream=True)\n```\nIf you try to run it you get the error above.\n\n## Agent Configuration (if applicable)\nPlease check the steps to reproduce\n\n## Expected Behavior\nIf I have all the necessary credentials for Azure OpenAI I should be able to use it just like any other model.\n\n## Actual Behavior\nThe sample code fails with module not found error and for whatever reason it mentions Antropic.\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- OS: Mac OS\n- Agno Version: 1.1.15\n- External Dependency Versions: None\n- Additional Environment Details: Python 3.10\n\n## Possible Solutions (optional)\nI have investigated the issue and I think there are two issues here:\n- We should probably remove the reference to `AzureAIFoundry` from here: https://github.com/agno-agi/agno/blob/main/libs/agno/agno/models/azure/__init__.py#L1. Otherwise we force users to install Azure AI Foundry dependencies for no good reason, while they are interested in Azure OpenAI chat\n- We should remove the reference to Anthropic from here: https://github.com/agno-agi/agno/blob/main/libs/agno/agno/models/azure/ai_foundry.py#L7. It should be an easy fix, but it is not clear how `BaseModel` should be used or if there is  need for a more sophisticated fix.\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "artur-ciocanu",
      "author_type": "User",
      "created_at": "2025-03-21T19:47:32Z",
      "updated_at": "2025-03-24T19:25:53Z",
      "closed_at": "2025-03-24T19:25:51Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2489/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2489",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2489",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:55.480837",
      "comments": [
        {
          "author": "artur-ciocanu",
          "body": "The issue has been fixed in PR #2492 ",
          "created_at": "2025-03-24T19:25:51Z"
        }
      ]
    },
    {
      "issue_number": 2514,
      "title": "[Bug] ModuleNotFoundError: No module named 'agno.team'",
      "body": "# Description\n\nTrying to run an Example app on local env [https://github.com/agno-agi/agno/tree/main/cookbook/examples/apps/chess_team](https://github.com/agno-agi/agno/tree/main/cookbook/examples/apps/chess_team)\n\nModuleNotFoundError: No module named 'agno.team'\n\n## Steps to Reproduce\nRun this code\n\n`from agno.agent import Agent\nfrom agno.models.anthropic import Claude\nfrom agno.models.google import Gemini\nfrom agno.models.groq import Groq\nfrom agno.models.openai import OpenAIChat\nfrom agno.team.team import `Team`\n\n## Agent Configuration (if applicable)\n\n## Expected Behavior\nTeam executes\n\n## Actual Behavior\n\nModuleNotFoundError: No module named 'agno.team'\n\n## Screenshots or Logs (if applicable)\n\n## Environment\n- OS: (e.g. macOS, Windows 11)\n- Browser (if relevant): (e.g. Chrome 108, Firefox 107)\n- Agno Version: (e.g. v1.0.0)\n- External Dependency Versions: (e.g., yfinance 0.2.52)\n- Additional Environment Details: (e.g., Python 3.10)\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "mallesh-sourcefuse",
      "author_type": "User",
      "created_at": "2025-03-24T11:58:58Z",
      "updated_at": "2025-03-24T15:13:34Z",
      "closed_at": "2025-03-24T15:13:34Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2514/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2514",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2514",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:55.672573",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Apologies, fix coming. You can upgrade your version of `agno` to 1.1.17, but I am making it updated by default.",
          "created_at": "2025-03-24T13:34:32Z"
        },
        {
          "author": "dirkbrnd",
          "body": "This has been resolved\nhttps://github.com/agno-agi/agno/releases/tag/v1.2.0",
          "created_at": "2025-03-24T15:13:32Z"
        }
      ]
    },
    {
      "issue_number": 2516,
      "title": "[Bug]ollama._types.ResponseError: registry.ollama.ai/library/deepseek-r1:latest does not support tools (status code: 400)",
      "body": "# Description\nRunning the agent with knowlege example code with Ollama(id=\"deepseek-r1:latest\") cause the error \n\n## Steps to Reproduce\n\nfrom agno.agent import Agent\nfrom agno.models.openai import OpenAIChat\nfrom agno.embedder.openai import OpenAIEmbedder\nfrom agno.tools.duckduckgo import DuckDuckGoTools\nfrom agno.knowledge.pdf_url import PDFUrlKnowledgeBase\nfrom agno.vectordb.lancedb import LanceDb, SearchType\nfrom agno.models.ollama import Ollama\nagent = Agent(\n    model=Ollama(id=\"deepseek-r1:latest\"),\n    description=\"You are a Thai cuisine expert!\",\n    instructions=[\n        \"Search your knowledge base for Thai recipes.\",\n        \"If the question is better suited for the web, search the web to fill in gaps.\",\n        \"Prefer the information in your knowledge base over the web results.\"\n    ],\n    knowledge=PDFUrlKnowledgeBase(\n        urls=[\"https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n        vector_db=LanceDb(\n            uri=\"tmp/lancedb\",\n            table_name=\"recipes\",\n            search_type=SearchType.hybrid,\n            embedder=OpenAIEmbedder(id=\"text-embedding-3-small\"),\n        ),\n    ),\n    tools=[DuckDuckGoTools()],\n    show_tool_calls=True,\n    markdown=True\n)\n\nif agent.knowledge is not None:\n    agent.knowledge.load()\n\nagent.print_response(\"How do I make chicken and galangal in coconut milk soup\", stream=True)\nagent.print_response(\"What is the history of Thai curry?\", stream=True)\n\n##Error : \n\nraise ResponseError(e.response.text, e.response.status_code) from None\nollama._types.ResponseError: registry.ollama.ai/library/deepseek-r1:latest does not support tools (status code: 400)\n\n\n\n## Environment\n- OS:  Windows 11\n- Agno Version:  \nName: agno\nVersion: 1.1.17\nSummary: Agno: a lightweight framework for building multi-modal Agents\nHome-page: https://agno.com\nAuthor:\nAuthor-email: Ashpreet Bedi <ashpreet@agno.com>\nLicense: Copyright (c) Agno, Inc.\n\n",
      "state": "closed",
      "author": "HongQuanVu",
      "author_type": "User",
      "created_at": "2025-03-24T12:38:27Z",
      "updated_at": "2025-03-24T14:34:10Z",
      "closed_at": "2025-03-24T14:34:10Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2516/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2516",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2516",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:55.887558",
      "comments": [
        {
          "author": "HongQuanVu",
          "body": "I found the root cause : need to use the model which support \"tool\"",
          "created_at": "2025-03-24T14:33:33Z"
        }
      ]
    },
    {
      "issue_number": 2139,
      "title": "Docker tool to handle all the commands related to docker running in host computer?",
      "body": "I may be wrong. But I saw this old phidata tool to control docker instance, control container and general stuffs with docker from old docs somewhere on the internet.\n\n### See this image\n[Source](https://www.restack.io/p/phidata-answer-docker-integration-cat-ai)\n\n![Image](https://github.com/user-attachments/assets/0d4360b6-0cf2-4ef6-a2b4-daeec4e763b6)\n\nWhat was the original usecase of this? Was it completely controlling docker?\n\nI think if there is some agentic tool that can work with dockers containers running in the host computer, that would be awesome.\nLike: docker compose up, interact with the container in interactive shell mode, close compose, run and stop dockerfile,.\n\nBasically, a tool that handles major docker tasks on behalf of host.\n\nThis will also also run code generated by agent in an isolated container environment.\n\n\nI think you can do this currently with shell command as well but we would require more guardrails and for that a separate dockertool make sense.\n\nWhat are your thoughts on this guys? I think it would be a solid tool and a true new agentic workflow unlock. 😀",
      "state": "closed",
      "author": "samyogdhital",
      "author_type": "User",
      "created_at": "2025-02-15T18:08:58Z",
      "updated_at": "2025-03-24T12:58:27Z",
      "closed_at": "2025-03-24T12:58:27Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2139/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2139",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2139",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:56.078552",
      "comments": [
        {
          "author": "samyogdhital",
          "body": "https://pypi.org/project/docker/\nThere is literally docker package for python that lets you do everything `docker` command lets you do.",
          "created_at": "2025-02-15T18:11:54Z"
        },
        {
          "author": "manthanguptaa",
          "body": "Thanks so much, @samyogdhital! I've added this as a feature request to our community wishlist. We’re definitely planning to include it, so stay tuned! I really appreciate your input, and feel free to reach out anytime if you have more thoughts or questions. We're here to help!",
          "created_at": "2025-02-17T09:32:12Z"
        }
      ]
    },
    {
      "issue_number": 2451,
      "title": "[Bug]CombinedKnowledgeBase(contain WebsiteKnowledgeBase ) does not update when agent use WebsiteTools",
      "body": "# Description\nCombinedKnowledgeBase(contain WebsiteKnowledgeBase ) does not update when agent use WebsiteTools\n\n## Steps to Reproduce\nWhen use WebsiteTools to update WebsiteKnowledgeBase (e.g., Search web page :'http://'), CombinedKnowledgeBase does not automatically reflect the changes. The combined_documents table remains outdated, while website_documents is updated.\n\n## Agent Configuration (if applicable)\n```\nknowledge_base = CombinedKnowledgeBase(\n    sources=[\n        url_pdf_knowledge_base,\n        website_knowledge_base,\n        local_pdf_knowledge_base,\n    ],\n    vector_db=PgVector(\n        table_name=\"combined_documents\",\n        db_url=db_url,\n        search_type=SearchType.hybrid,\n        embedder=embedder,\n    ),\n)\nimplement_agent = Agent(\n    model=model,\n    tools=[ WebsiteTools(knowledge_base=website_knowledge_base),\n    ],\n)\n```\n\n## Expected Behavior\nSynchronous update\n\n## Actual Behavior\nCombinedKnowledgeBase does not update when agent use WebsiteTools\n\n## Screenshots or Logs (if applicable)\n\n\n## Environment\n- Agno Version: (1.1.13)\n\n## Possible Solutions (optional)\n\n```\nimport json\nfrom typing import List, Optional\n\nfrom agno.document import Document\nfrom agno.knowledge.website import WebsiteKnowledgeBase\nfrom agno.knowledge.combined import CombinedKnowledgeBase  #  # New import\nfrom agno.tools import Toolkit\nfrom agno.utils.log import logger\n\n\nclass WebsiteTools(Toolkit):\n    def __init__(\n        self,\n        knowledge_base: Optional[WebsiteKnowledgeBase] = None,\n        combined_knowledge_base: Optional[CombinedKnowledgeBase] = None,  # New arg\n    ):\n        super().__init__(name=\"website_tools\")\n        self.knowledge_base: Optional[WebsiteKnowledgeBase] = knowledge_base\n        self.combined_knowledge_base: Optional[CombinedKnowledgeBase] = combined_knowledge_base  # New arg\n\n        if self.knowledge_base is not None and isinstance(self.knowledge_base, WebsiteKnowledgeBase):\n            self.register(self.add_website_to_knowledge_base)\n        else:\n            self.register(self.read_url)\n\n    def add_website_to_knowledge_base(self, url: str) -> str:\n        \"\"\"This function adds a website's content to the knowledge base.\n        NOTE: The website must start with https:// and should be a valid website.\n\n        USE THIS FUNCTION TO GET INFORMATION ABOUT PRODUCTS FROM THE INTERNET.\n\n        :param url: The URL of the website to add.\n        :return: 'Success' if the website was added to the knowledge base.\n        \"\"\"\n        if self.knowledge_base is None:\n            return \"Knowledge base not provided\"\n\n        logger.debug(f\"Adding to knowledge base: {url}\")\n        self.knowledge_base.urls.append(url)\n\n        logger.debug(\"Loading website knowledge base.\")\n        self.knowledge_base.load(recreate=False)\n\n        # if configure CombinedKnowledgeBase\n        if self.combined_knowledge_base is not None:\n            logger.debug(\"Updating combined knowledge base after website update.\")\n            self.combined_knowledge_base.load(recreate=True)  \n\n        return \"Success\"\n\n    def read_url(self, url: str) -> str:\n        \"\"\"This function reads a URL and returns the content.\n\n        :param url: The URL of the website to read.\n        :return: Relevant documents from the website.\n        \"\"\"\n        from agno.document.reader.website_reader import WebsiteReader\n\n        website = WebsiteReader()\n\n        logger.debug(f\"Reading website: {url}\")\n        relevant_docs: List[Document] = website.read(url=url)\n        return json.dumps([doc.to_dict() for doc in relevant_docs])\n\n```\n\n## Additional Context\nThank you for the great work on this projrct! Looking forward to a fix or claeification\n",
      "state": "closed",
      "author": "tangmingcheng",
      "author_type": "User",
      "created_at": "2025-03-19T01:34:10Z",
      "updated_at": "2025-03-24T08:24:10Z",
      "closed_at": "2025-03-20T13:45:55Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2451/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2451",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2451",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:27:56.244252",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Thanks for reporting! I have an alternative suggested solution.\nhttps://github.com/agno-agi/agno/pull/2456",
          "created_at": "2025-03-19T12:17:22Z"
        },
        {
          "author": "tangmingcheng",
          "body": "> Thanks for reporting! I have an alternative suggested solution.\n> https://github.com/agno-agi/agno/pull/2456\n\nOK, I'll try it after updating the code.",
          "created_at": "2025-03-20T09:01:51Z"
        },
        {
          "author": "dirkbrnd",
          "body": "This has been released",
          "created_at": "2025-03-24T08:24:09Z"
        }
      ]
    },
    {
      "issue_number": 2498,
      "title": "[Bug]OpenAILike not support User preferences and conversation summaries",
      "body": "\nUser preferences and conversation summaries are currently only compatible with OpenAI and OpenAILike models. While Persistent Memory is compatible with all model providers.In fact, it doesn't work,I use vllm as a OpenAILike\n\n![Image](https://github.com/user-attachments/assets/804845f3-3917-45b1-a9e8-55ca364a6c6b)\n\n\n\n",
      "state": "closed",
      "author": "ruidanwang",
      "author_type": "User",
      "created_at": "2025-03-22T14:11:46Z",
      "updated_at": "2025-03-24T00:03:06Z",
      "closed_at": "2025-03-24T00:03:06Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2498/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2498",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2498",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:28:01.413151",
      "comments": [
        {
          "author": "ruidanwang",
          "body": "If I  commented out the AgentMemory code, and it worked",
          "created_at": "2025-03-22T14:12:56Z"
        }
      ]
    },
    {
      "issue_number": 2194,
      "title": "[Bug] The perplexity in agno lost import  citations ",
      "body": "# Description\nThe [perplexity](https://docs.agno.com/models/perplexity) in [agno](https://github.com/agno-agi/agno) lost import content: **citations**\n\n\n\n## Steps to Reproduce\n```\nfrom agno.agent import Agent, RunResponse\nfrom agno.models.perplexity import Perplexity\n\nagent = Agent(model=Perplexity(id=\"sonar-pro\"), markdown=True)\n\n# Print the response in the terminal\ntestp = agent.run(\"Share a 2 sentence horror story\")\n\n```\n```\nprint(testp.citations)\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[16], line 1\n----> 1 testp.citations\n\nAttributeError: 'RunResponse' object has no attribute 'citations'\n```\n\n\n## Agent Configuration (if applicable)\nProvide relevant agent configuration.\n\n## Expected Behavior\nKeep the **citations**, like using openai\n\n```\nimport os\nfrom openai import OpenAI\n\nclient = OpenAI(\n \n    api_key=os.getenv(\"PERPLEXITY_API_KEY\"),  \n    base_url=\"https://api.perplexity.ai\",\n)\n\ncompletion = client.chat.completions.create(\n    model=\"sonar-reasoning\",   \n    messages=[\n        {'role': 'user', 'content': \"Share a 2 sentence horror story\"}\n        ]\n)\ncompletion.citations\n```\n```\n['https://www.kidzsearch.com/questions/23489/if-you-like-a-good-scare-read-these-2-sentence-stories',\n 'https://www.boredpanda.com/short-scary-two-sentence-horror-stories/',\n 'https://itslitteaching.com/two-sentence-horror-stories/',\n 'https://absolutewrite.com/forums/index.php?threads%2Fhorror-stories-in-just-two-sentences.287177%2F',\n 'https://library.phoenix.edu/blogs/keeping-up-with-the-librarians/Share-Your-Stories']\n```\n\n## Actual Behavior\nlost **citations**\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- OS: Linux\n- Agno Version: v1.1.4\n- Additional Environment Details:  Python 3.10 \n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "huang-sh",
      "author_type": "User",
      "created_at": "2025-02-20T09:47:57Z",
      "updated_at": "2025-03-22T08:11:54Z",
      "closed_at": "2025-03-18T03:12:16Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2194/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2194",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2194",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:28:01.612337",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "@huang-sh We have yet to implement citations in Perplexity. That will come.",
          "created_at": "2025-02-20T11:59:35Z"
        },
        {
          "author": "huang-sh",
          "body": "> [@huang-sh](https://github.com/huang-sh) We have yet to implement citations in Perplexity. That will come.\n\nThanks! that is great!",
          "created_at": "2025-02-20T12:19:52Z"
        },
        {
          "author": "ysolanky",
          "body": "@huang-sh we have added citations as of v 1.1.13. Please do test them out and let us know in case of any questions ",
          "created_at": "2025-03-20T15:05:56Z"
        },
        {
          "author": "huang-sh",
          "body": "@ysolanky Yes,thanks! it works.",
          "created_at": "2025-03-22T08:11:53Z"
        }
      ]
    },
    {
      "issue_number": 2464,
      "title": "[Bug]Failed to load resource: the server responded with a status of 404 ()",
      "body": "# Description\n**Failed to load resource: the server responded with a status of 404 ()**\n\n## Steps to Reproduce\njust run demo  AI Finance Agent Team with Web Access\n\n## Agent Configuration (if applicable)\nProvide relevant agent configuration.\n\n## Expected Behavior\nWhat did you expect to happen?\n\n## Actual Behavior\nWhat actually happened instead?\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- OS: Cloud Shell Editor\n- Browser (if relevant): (e.g. Chrome 108, Firefox 107)\n- Agno Version: (e.g. v1.0.0)\n- External Dependency Versions: (e.g., yfinance 0.2.52)\n- Additional Environment Details:ngrok\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "ruidanwang",
      "author_type": "User",
      "created_at": "2025-03-20T08:59:59Z",
      "updated_at": "2025-03-21T13:51:54Z",
      "closed_at": "2025-03-21T13:51:54Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2464/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2464",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2464",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:28:01.819691",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @ruidanwang ! I was not able to replicate your issue, can you please try running `Finance Agent Team` and share your Agent config and debug logs?",
          "created_at": "2025-03-20T20:05:55Z"
        },
        {
          "author": "ruidanwang",
          "body": "Traceback (most recent call last):\nFile \"/content/agno1/finance_agent_team.py\", line 44, in\napp = Playground(agents=[agent_team]).get_app()\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile \"/usr/local/lib/python3.11/dist-packages/agno/playground/playground.py\", line 32, in init\nself.settings: PlaygroundSettings",
          "created_at": "2025-03-21T00:28:19Z"
        },
        {
          "author": "anuragts",
          "body": "Hey @ruidanwang can you also share your agent config.",
          "created_at": "2025-03-21T05:44:22Z"
        },
        {
          "author": "ruidanwang",
          "body": "code ：\nfrom agno.agent import Agent\n# from agno.models.openai import OpenAIChat\nfrom agno.playground import Playground, serve_playground_app\nfrom agno.storage.agent.sqlite import SqliteAgentStorage\nfrom agno.tools.duckduckgo import DuckDuckGoTools\nfrom agno.tools.yfinance import YFinanceTools\nfrom a",
          "created_at": "2025-03-21T06:46:21Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @ruidanwang \nDo you perhaps have `ENV=/root/.bashrc` exported somewhere? If you do `echo $ENV` you should see that. I can suggest you do `unset ENV`",
          "created_at": "2025-03-21T07:16:10Z"
        }
      ]
    },
    {
      "issue_number": 2482,
      "title": "[Bug]OpenAILike is supports vllm?",
      "body": "# Description\ncode\n`from rich.pretty import pprint\nfrom agno.agent import Agent, RunResponse\nfrom agno.models.openai.like import OpenAILike\n\n\nfrom agno.agent import Agent, AgentMemory\nfrom agno.models.openai import OpenAIChat\nfrom agno.memory.db.postgres import PgMemoryDb\nfrom agno.storage.agent.postgres import PostgresAgentStorage\n\ndb_url = \"postgresql+psycopg://postgres:postgres@127.0.0.1:5432/\"\nagent = Agent(\n    model=OpenAILike(\n      id=\"Qwen/Qwen2.5-1.5B-Instruct\",\n      api_key=\"EMPTY\",\n      base_url=\"http://localhost:8000/v1\",),\n    # Store the memories and summary in a database\n    memory=AgentMemory(\n        db=PgMemoryDb(table_name=\"agent_memory\", db_url=db_url), create_user_memories=True, create_session_summary=True\n    ),\n    # add_history_to_messages=True,\n    # Store agent sessions in a database\n    storage=PostgresAgentStorage(table_name=\"personalized_agent_sessions\", db_url=db_url),\n    # Show debug logs so you can see the memory being created\n    # debug_mode=True,\n)\n\nagent.print_response(\"Tell me about a breaking news story from New York.\", stream=True)`\n\n\n-----------------------------------------------------------------------\n\nERROR    API status error from OpenAI API: Error code: 400 - {'object': 'error', 'message': '\"auto\" tool choice    \n         requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': \n         None, 'code': 400}                                                                                        \n---------------------------------------------------------------------------\nBadRequestError                           Traceback (most recent call last)\n[/usr/local/lib/python3.11/dist-packages/agno/models/openai/chat.py](https://localhost:8080/#) in invoke_stream(self, messages)\n    433         try:\n--> 434             yield from self.get_client().chat.completions.create(\n    435                 model=self.id,\n\n10 frames\nBadRequestError: Error code: 400 - {'object': 'error', 'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}\n\nThe above exception was the direct cause of the following exception:\n\nModelProviderError                        Traceback (most recent call last)\n[/usr/local/lib/python3.11/dist-packages/agno/models/openai/chat.py](https://localhost:8080/#) in invoke_stream(self, messages)\n    464                 else error_message\n    465             )\n--> 466             raise ModelProviderError(\n    467                 message=error_message,\n    468                 status_code=e.response.status_code,\n\nModelProviderError: Unknown model error\n\n-----------------------------------------------------------------------------------------------\n\n![Image](https://github.com/user-attachments/assets/3684d075-b828-4541-9be0-a546d0814c8d)\n\n\n## Steps to Reproduce\nList the steps needed to encounter this bug or issue.\n\n## Agent Configuration (if applicable)\nProvide relevant agent configuration.\n\n## Expected Behavior\nWhat did you expect to happen?\n\n## Actual Behavior\nWhat actually happened instead?\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- OS: (e.g. macOS, Windows 11)\n- Browser (if relevant): (e.g. Chrome 108, Firefox 107)\n- Agno Version: (e.g. v1.0.0)\n- External Dependency Versions: (e.g., yfinance 0.2.52)\n- Additional Environment Details: (e.g., Python 3.10)\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "ruidanwang",
      "author_type": "User",
      "created_at": "2025-03-21T08:49:25Z",
      "updated_at": "2025-03-21T11:53:00Z",
      "closed_at": "2025-03-21T11:53:00Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2482/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2482",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2482",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:28:03.809330",
      "comments": []
    },
    {
      "issue_number": 1955,
      "title": "[Feature Request] Add support for OpenSearch as a Vector Database",
      "body": "## Problem Description\nI often find it frustrating when I cannot use OpenSearch as a vector database in Agno because it limits my ability to leverage OpenSearch's robust search and analytics capabilities for handling vector data.\n\n## Proposed Solution\nIntegrate OpenSearch as a vector database option within Agno. This feature should allow users to store and query vector data using OpenSearch seamlessly. Ensure compatibility with existing features such as memory management, knowledge stores, and multi-agent support. Provide comprehensive documentation and examples to help users get started with OpenSearch.\n\nI have considered using other vector databases supported by Agno, but they do not offer the same level of performance and scalability as OpenSearch. Additionally, using a different vector database would require significant changes to my existing infrastructure, which is already optimized for OpenSearch.\n\nI’m open to collaborating but need guidance on what functions are needed and how they will be integrated with agents.\n",
      "state": "closed",
      "author": "sushantgundla7",
      "author_type": "User",
      "created_at": "2025-01-31T08:36:53Z",
      "updated_at": "2025-03-21T09:56:53Z",
      "closed_at": "2025-02-25T00:30:43Z",
      "labels": [
        "enhancement",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 10,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/1955/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/1955",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/1955",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:28:03.809359",
      "comments": [
        {
          "author": "ashpreetbedi",
          "body": "Thank you @sushantgundla7, agree we should support opensearch! would you be open to working with us to add it as a vector store? ",
          "created_at": "2025-01-31T09:42:52Z"
        },
        {
          "author": "ashpreetbedi",
          "body": "Since you're a heavy user, it would be great to get your expertise as well",
          "created_at": "2025-01-31T09:43:05Z"
        },
        {
          "author": "Dev79844",
          "body": "Hey @sushantgundla7,\nI would like to collaborate on this issue.",
          "created_at": "2025-02-02T07:40:54Z"
        },
        {
          "author": "sushantgundla7",
          "body": "@ashpreetbedi \nI would love to work on this, But I would need some guidance.\n\n@Dev79844 Sure! :) ",
          "created_at": "2025-02-03T06:13:08Z"
        },
        {
          "author": "Dev79844",
          "body": "I will push the basic code for the opensearch wrapper and leave few function signatures which you can implement. Also refer to the implementation of other vectordbs in the codebase, you will get an idea on how vectordbs are integrated.",
          "created_at": "2025-02-04T01:58:08Z"
        }
      ]
    },
    {
      "issue_number": 2166,
      "title": "Issue with LiiteLLM model calls. Unable to get proper response frorm proxies.",
      "body": "# Description\ni tried to use Ollama qwen7b model for a basic task. It is working fine when I use Ollama backend in Agno. \nHoowever when I dddo the same thing with LiiteLLM it fails. This generally happens when I use tools. \n\n## Steps to Reproduce\nHere is a basic chatbot implementation of LiteLLM using OpenAILike\n\n## This is my code:\n```\n\"\"\"🤖 Basic Chatbot Workflow - Simple Conversational Agent\n\nThis implements a basic chatbot using the Agno framework:\n\n1. Handles continuous conversation\n2. Maintains conversation history\n3. Uses local model via OpenAILike\n4. Simple error handling\n\nRun with:\npython cookbook/workflows/testChat.py\n\"\"\"\n\nfrom typing import Iterator\nfrom agno.agent import Agent\nfrom agno.workflow import Workflow, RunResponse\nfrom agno.models.openai.like import OpenAILike\nfrom agno.tools.duckduckgo import DuckDuckGoTools\nfrom dotenv import load_dotenv\nfrom agno.models.ollama import Ollama\nfrom agno.models.openai import OpenAIChat\n\nload_dotenv()\n\nclass ChatbotWorkflow(Workflow):\n    \"\"\"Basic conversational chatbot workflow\"\"\"\n    \n    description: str = \"Simple chatbot for casual conversation\"\n    \n    chat_agent: Agent = Agent(\n        model=OpenAILike(\n            id=\"ollama/qwen2.5:7b-instruct\",\n            base_url=\"http://0.0.0.0:4000\",\n        ),\n        # model=Ollama(id=\"qwen2.5:1.5b\"),\n        # model=OpenAIChat(id=\"gpt-4o-mini\", temperature=0.1), \n        description=\"Friendly Conversational Assistant\",\n        # tools=[DuckDuckGoTools()],\n        instructions=[\n            \"You are a friendly chatbot named Clippy\",\n            \"Prioritize answering from your own knowledge for general questions\",\n            \"Only use web search when:\",\n            \"- Asked about current events/news\",\n            \"- Question requires real-time data (sports scores, stock prices, etc)\",\n            \"- Explicitly asked to look up information\",\n            \"- Unsure of the answer to factual questions\",\n            \"When searching:\",\n            \"1. Perform focused DuckDuckGo search\",\n            \"2. Extract key facts\",\n            \"3. Summarize findings concisely\",\n            \"4. Always maintain conversational tone\",\n            \"Keep responses under 3 sentences unless complex topic\",\n            \"Acknowledge if info comes from web search\",\n            \"Maintain context across messages\",\n            \"Ask clarifying questions if request is ambiguous\"\n        ],\n        add_datetime_to_instructions=True,\n        # search_knowledge=False,\n        # add_references=True,\n        markdown=True,\n    )\n\n    def run(self, initial_message: str = None) -> Iterator[RunResponse]:\n        print(\"Chatbot initialized. Type 'exit' to end the conversation.\\n\")\n        \n        while True:\n            try:\n                user_input = input(\"You: \")\n                if user_input.lower() in ['exit', 'quit']:\n                    break\n                \n                response = self.chat_agent.run(user_input)\n                print(f\"\\nBot: {response.content}\\n\")\n                \n            except Exception as e:\n                print(f\"Error: {str(e)}\")\n                break\n\n        yield RunResponse(content=\"Conversation ended\", event=\"complete\")\n\nif __name__ == \"__main__\":\n    bot = ChatbotWorkflow()\n    list(bot.run())  # Start the conversation\n\n```\n\n## Expected Behavior\nFor a query as basic as \"hey\" returns an error, when all I expect is:\n\n```\nBot: Hi there! How can I help you today? 😊\n\nYou: \n```\n\nI get above response when using Ollama() backend but when using LiteLLM I get below error:\n\n## Actual Behavior\nIt gives me this error and doesn't respond properly:\n\n**Lite LLM logs**\n```\n06:33:31 - LiteLLM Proxy:ERROR: proxy_server.py:3706 - litellm.proxy.proxy_server.chat_completion(): Exception occured - litellm.APIConnectionError: 'name'\nTraceback (most recent call last):\n  File \"/usr/lib/python3.13/site-packages/litellm/main.py\", line 467, in acompletion\n    response = await init_response\n               ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.13/site-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 182, in async_completion\n    return provider_config.transform_response(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        model=model,\n        ^^^^^^^^^^^^\n    ...<8 lines>...\n        encoding=encoding,\n        ^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/usr/lib/python3.13/site-packages/litellm/llms/ollama/completion/transformation.py\", line 263, in transform_response\n    \"name\": function_call[\"name\"],\n            ~~~~~~~~~~~~~^^^^^^^^\nKeyError: 'name'\n. Received Model Group=ollama/qwen2.5:7b-instruct\nAvailable Model Group Fallbacks=None LiteLLM Retried: 1 times, LiteLLM Max Retries: 2\nTraceback (most recent call last):\n  File \"/usr/lib/python3.13/site-packages/litellm/main.py\", line 467, in acompletion\n    response = await init_response\n               ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.13/site-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 182, in async_completion\n    return provider_config.transform_response(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        model=model,\n        ^^^^^^^^^^^^\n    ...<8 lines>...\n        encoding=encoding,\n        ^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/usr/lib/python3.13/site-packages/litellm/llms/ollama/completion/transformation.py\", line 263, in transform_response\n    \"name\": function_call[\"name\"],\n            ~~~~~~~~~~~~~^^^^^^^^\nKeyError: 'name'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.13/site-packages/litellm/proxy/proxy_server.py\", line 3593, in chat_completion\n    responses = await llm_responses\n                ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.13/site-packages/litellm/router.py\", line 907, in acompletion\n    raise e\n  File \"/usr/lib/python3.13/site-packages/litellm/router.py\", line 883, in acompletion\n    response = await self.async_function_with_fallbacks(**kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.13/site-packages/litellm/router.py\", line 3078, in async_function_with_fallbacks\n    raise original_exception\n  File \"/usr/lib/python3.13/site-packages/litellm/router.py\", line 2892, in async_function_with_fallbacks\n    response = await self.async_function_with_retries(*args, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.13/site-packages/litellm/router.py\", line 3267, in async_function_with_retries\n    raise original_exception\n  File \"/usr/lib/python3.13/site-packages/litellm/router.py\", line 3160, in async_function_with_retries\n    response = await self.make_call(original_function, *args, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.13/site-packages/litellm/router.py\", line 3276, in make_call\n    response = await response\n               ^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.13/site-packages/litellm/router.py\", line 1045, in _acompletion\n    raise e\n  File \"/usr/lib/python3.13/site-packages/litellm/router.py\", line 1004, in _acompletion\n    response = await _response\n               ^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.13/site-packages/litellm/utils.py\", line 1394, in wrapper_async\n    raise e\n  File \"/usr/lib/python3.13/site-packages/litellm/utils.py\", line 1253, in wrapper_async\n    result = await original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.13/site-packages/litellm/main.py\", line 486, in acompletion\n    raise exception_type(\n          ~~~~~~~~~~~~~~^\n        model=model,\n        ^^^^^^^^^^^^\n    ...<3 lines>...\n        extra_kwargs=kwargs,\n        ^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/usr/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2202, in exception_type\n    raise e\n  File \"/usr/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2178, in exception_type\n    raise APIConnectionError(\n    ...<8 lines>...\n    )\nlitellm.exceptions.APIConnectionError: litellm.APIConnectionError: 'name'\nTraceback (most recent call last):\n  File \"/usr/lib/python3.13/site-packages/litellm/main.py\", line 467, in acompletion\n    response = await init_response\n               ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.13/site-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 182, in async_completion\n    return provider_config.transform_response(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        model=model,\n        ^^^^^^^^^^^^\n    ...<8 lines>...\n        encoding=encoding,\n        ^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/usr/lib/python3.13/site-packages/litellm/llms/ollama/completion/transformation.py\", line 263, in transform_response\n    \"name\": function_call[\"name\"],\n            ~~~~~~~~~~~~~^^^^^^^^\nKeyError: 'name'\n. Received Model Group=ollama/qwen2.5:7b-instruct\nAvailable Model Group Fallbacks=None LiteLLM Retried: 1 times, LiteLLM Max Retries: 2\n06:33:31 - LiteLLM Proxy:DEBUG: proxy_server.py:3713 - An error occurred: litellm.APIConnectionError: 'name'\nTraceback (most recent call last):\n  File \"/usr/lib/python3.13/site-packages/litellm/main.py\", line 467, in acompletion\n    response = await init_response\n               ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.13/site-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 182, in async_completion\n    return provider_config.transform_response(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        model=model,\n        ^^^^^^^^^^^^\n    ...<8 lines>...\n        encoding=encoding,\n        ^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/usr/lib/python3.13/site-packages/litellm/llms/ollama/completion/transformation.py\", line 263, in transform_response\n    \"name\": function_call[\"name\"],\n            ~~~~~~~~~~~~~^^^^^^^^\nKeyError: 'name'\n. Received Model Group=ollama/qwen2.5:7b-instruct\nAvailable Model Group Fallbacks=None LiteLLM Retried: 1 times, LiteLLM Max Retries: 2 None\n\n Debug this by setting `--debug`, e.g. `litellm --model gpt-3.5-turbo --debug`\n06:33:31 - LiteLLM Proxy:INFO: proxy_server.py:3159 - {\"event\": \"giveup\", \"exception\": \"\"}\n06:33:31 - LiteLLM Proxy:ERROR: _common.py:120 - Giving up chat_completion(...) after 1 tries (litellm.proxy._types.ProxyException)\nINFO:     127.0.0.1:33404 - \"POST /chat/completions HTTP/1.1\" 500 Internal Server Error\n^CINFO:     Shutting down\n```\n\n**AGNO logs**\n\n```\nDEBUG    Tool Calls: [                                                                                                                                                                                                                                  \n           {                                                                                                                                                                                                                                            \n             \"id\": \"call_b77bb961-bf27-4535-941c-5e2a91a982f6\",                                                                                                                                                                                         \n             \"function\": {                                                                                                                                                                                                                              \n               \"arguments\": \"{\\\"query\\\": \\\"hi meaning\\\", \\\"max_results\\\": 5}\",                                                                                                                                                                          \n               \"name\": \"duckduckgo_search\"                                                                                                                                                                                                              \n             },                                                                                                                                                                                                                                         \n             \"type\": \"function\"                                                                                                                                                                                                                         \n           }                                                                                                                                                                                                                                            \n         ]                                                                                                                                                                                                                                              \nDEBUG    **************** METRICS ****************                                                                                                                                                                                                      \nDEBUG    * Input tokens:                1267                                                                                                                                                                                                            \nDEBUG    * Output tokens:               26                                                                                                                                                                                                              \nDEBUG    * Total tokens:                1293                                                                                                                                                                                                            \nDEBUG    * Time:                        0.6338s                                                                                                                                                                                                         \nDEBUG    * Tokens per second:           41.0254 tokens/s                                                                                                                                                                                                \nDEBUG    **************** METRICS ******************                                                                                                                                                                                                    \nDEBUG    ============== tool ==============                                                                                                                                                                                                             \nDEBUG    Tool call Id: call_b77bb961-bf27-4535-941c-5e2a91a982f6                                                                                                                                                                                        \nDEBUG    [                                                                                                                                                                                                                                              \n           {                                                                                                                                                                                                                                            \n             \"title\": \"HI | English meaning - Cambridge Dictionary\",                                                                                                                                                                                    \n             \"href\": \"https://dictionary.cambridge.org/dictionary/english/hi\",                                                                                                                                                                          \n             \"body\": \"HI definition: 1. used as an informal greeting, usually to people who you know: 2. written abbreviation for the\\u2026. Learn more.\"                                                                                               \n           },                                                                                                                                                                                                                                           \n           {                                                                                                                                                                                                                                            \n             \"title\": \"Hi Definition & Meaning - Merriam-Webster\",                                                                                                                                                                                      \n             \"href\": \"https://www.merriam-webster.com/dictionary/hi\",                                                                                                                                                                                   \n             \"body\": \"The meaning of HI is \\u2014used especially as a greeting. How to use hi in a sentence. \\u2014used especially as a greeting\\u2026 See the full definition. Games; Word of the Day; Grammar; Wordplay; New Slang; Rhymes; Word      \n         Finder; Thesaurus; Join MWU; More. Games; Word of the Day; Grammar; Wordplay; Slang;\"                                                                                                                                                          \n           },                                                                                                                                                                                                                                           \n           {                                                                                                                                                                                                                                            \n             \"title\": \"hi - Wiktionary, the free dictionary\",                                                                                                                                                                                           \n             \"href\": \"https://en.wiktionary.org/wiki/hi\",                                                                                                                                                                                               \n             \"body\": \"Hi and ho cannot be used together with the same verb, nor can two his be used together. It is sometimes stated that hi is never used to replace a complement beginning with de. This is not completely accurate, as hi can replace\n         adverbial phrases such as de pressa, de sobte, etc. Declension.\"                                                                                                                                                                               \n           },                                                                                                                                                                                                                                           \n           {                                                                                                                                                                                                                                            \n             \"title\": \"HI definition in American English | Collins English Dictionary\",                                                                                                                                                                 \n             \"href\": \"https://www.collinsdictionary.com/us/dictionary/english/hi\",                                                                                                                                                                      \n             \"body\": \"HI definition: an expression used to attract attention | Meaning, pronunciation, translations and examples in American English\"                                                                                                   \n           },                                                                                                                                                                                                                                           \n           {                                                                                                                                                                                                                                            \n             \"title\": \"Hi - Definition, Meaning & Synonyms | Vocabulary.com\",                                                                                                                                                                           \n             \"href\": \"https://www.vocabulary.com/dictionary/hi\",                                                                                                                                                                                        \n             \"body\": \"Hi is a common greeting, more casual than \\\"hello.\\\" When you walk down the street in a small town, it might seem like everyone you pass says \\\"hi.\\\"\"                                                                            \n           }                                                                                                                                                                                                                                            \n         ]                                                                                                                                                                                                                                              \nDEBUG    **************** METRICS ****************                                                                                                                                                                                                      \nDEBUG    * Time:                        2.2611s                                                                                                                                                                                                         \nDEBUG    **************** METRICS ******************                                                                                                                                                                                                    \nDEBUG    ============== assistant ==============                                                                                                                                                                                                        \nDEBUG    Tool Calls: [                                                                                                                                                                                                                                  \n           {                                                                                                                                                                                                                                            \n             \"id\": \"call_23589f3d-8252-4783-9d59-84251a7bba50\",                                                                                                                                                                                         \n             \"function\": {                                                                                                                                                                                                                              \n               \"arguments\": \"{\\\"query\\\": \\\"hi definition\\\"}\",                                                                                                                                                                                           \n               \"name\": \"duckduckgo_search\"                                                                                                                                                                                                              \n             },                                                                                                                                                                                                                                         \n             \"type\": \"function\"                                                                                                                                                                                                                         \n           }                                                                                                                                                                                                                                            \n         ]                                                                                                                                                                                                                                              \nDEBUG    **************** METRICS ****************                                                                                                                                                                                                      \nDEBUG    * Input tokens:                1729                                                                                                                                                                                                            \nDEBUG    * Output tokens:               19                                                                                                                                                                                                              \nDEBUG    * Total tokens:                1748                                                                                                                                                                                                            \nDEBUG    * Time:                        0.6083s                                                                                                                                                                                                         \nDEBUG    * Tokens per second:           31.2337 tokens/s                                                                                                                                                                                                \nDEBUG    **************** METRICS ******************                                                                                                                                                                                                    \nDEBUG    ============== tool ==============                                                                                                                                                                                                             \nDEBUG    Tool call Id: call_23589f3d-8252-4783-9d59-84251a7bba50                                                                                                                                                                                        \nDEBUG    [                                                                                                                                                                                                                                              \n           {                                                                                                                                                                                                                                            \n             \"title\": \"HI | English meaning - Cambridge Dictionary\",                                                                                                                                                                                    \n             \"href\": \"https://dictionary.cambridge.org/dictionary/english/hi\",                                                                                                                                                                          \n             \"body\": \"HI definition: 1. used as an informal greeting, usually to people who you know: 2. written abbreviation for the\\u2026. Learn more.\"                                                                                               \n           },                                                                                                                                                                                                                                           \n           {                                                                                                                                                                                                                                            \n             \"title\": \"Hi Definition & Meaning - Merriam-Webster\",                                                                                                                                                                                      \n             \"href\": \"https://www.merriam-webster.com/dictionary/hi\",                                                                                                                                                                                   \n             \"body\": \"The meaning of HI is \\u2014used especially as a greeting. How to use hi in a sentence.\"                                                                                                                                           \n           },                                                                                                                                                                                                                                           \n           {                                                                                                                                                                                                                                            \n             \"title\": \"HI definition in American English | Collins English Dictionary\",                                                                                                                                                                 \n             \"href\": \"https://www.collinsdictionary.com/us/dictionary/english/hi\",                                                                                                                                                                      \n             \"body\": \"HI definition: an expression used to attract attention | Meaning, pronunciation, translations and examples in American English\"                                                                                                   \n           },                                                                                                                                                                                                                                           \n           {                                                                                                                                                                                                                                            \n             \"title\": \"Hi - Definition, Meaning & Synonyms | Vocabulary.com\",                                                                                                                                                                           \n             \"href\": \"https://www.vocabulary.com/dictionary/hi\",                                                                                                                                                                                        \n             \"body\": \"Hi is a common greeting, more casual than \\\"hello.\\\" When you walk down the street in a small town, it might seem like everyone you pass says \\\"hi.\\\"\"                                                                            \n           },                                                                                                                                                                                                                                           \n           {                                                                                                                                                                                                                                            \n             \"title\": \"Hi Definition & Meaning - YourDictionary\",                                                                                                                                                                                       \n             \"href\": \"https://www.yourdictionary.com/hi\",                                                                                                                                                                                               \n             \"body\": \"Learn the definition, origin, and usage of the interjection hi, which can be a friendly greeting, an exclamation, or an abbreviation. Find out how to say hi in different contexts and languages.\"                                \n           }                                                                                                                                                                                                                                            \n         ]                                                                                                                                                                                                                                              \nDEBUG    **************** METRICS ****************                                                                                                                                                                                                      \nDEBUG    * Time:                        0.8890s                                                                                                                                                                                                         \nDEBUG    **************** METRICS ******************                                                                                                                                                                                                    \nERROR    API status error from OpenAI API: Error code: 500 - {'error': {'message': 'litellm.APIConnectionError: \\'name\\'\\nTraceback (most recent call last):\\n  File \"/usr/lib/python3.13/site-packages/litellm/main.py\", line 467, in acompletion\\n    \n         response = await init_response\\n               ^^^^^^^^^^^^^^^^^^^\\n  File \"/usr/lib/python3.13/site-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 182, in async_completion\\n    return provider_config.transform_response(\\n  \n         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\\n        model=model,\\n        ^^^^^^^^^^^^\\n    ...<8 lines>...\\n        encoding=encoding,\\n        ^^^^^^^^^^^^^^^^^^\\n    )\\n    ^\\n  File                                                             \n         \"/usr/lib/python3.13/site-packages/litellm/llms/ollama/completion/transformation.py\", line 263, in transform_response\\n    \"name\": function_call[\"name\"],\\n            ~~~~~~~~~~~~~^^^^^^^^\\nKeyError: \\'name\\'\\n. Received Model             \n         Group=ollama/qwen2.5:7b-instruct\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '500'}}                                                                                                                          \nWARNING  Attempt 1/1 failed: Error code: 500 - {'error': {'message': 'litellm.APIConnectionError: \\'name\\'\\nTraceback (most recent call last):\\n  File \"/usr/lib/python3.13/site-packages/litellm/main.py\", line 467, in acompletion\\n    response =    \n         await init_response\\n               ^^^^^^^^^^^^^^^^^^^\\n  File \"/usr/lib/python3.13/site-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 182, in async_completion\\n    return provider_config.transform_response(\\n             \n         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\\n        model=model,\\n        ^^^^^^^^^^^^\\n    ...<8 lines>...\\n        encoding=encoding,\\n        ^^^^^^^^^^^^^^^^^^\\n    )\\n    ^\\n  File                                                             \n         \"/usr/lib/python3.13/site-packages/litellm/llms/ollama/completion/transformation.py\", line 263, in transform_response\\n    \"name\": function_call[\"name\"],\\n            ~~~~~~~~~~~~~^^^^^^^^\\nKeyError: \\'name\\'\\n. Received Model             \n         Group=ollama/qwen2.5:7b-instruct\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '500'}}                                                                                                                          \nError: Failed after 1 attempts. Last error using OpenAILike(ollama/qwen2.5:7b-instruct): Error code: 500 - {'error': {'message': 'litellm.APIConnectionError: \\'name\\'\\nTraceback (most recent call last):\\n  File \"/usr/lib/python3.13/site-packages/litellm/main.py\", line 467, in acompletion\\n    response = await init_response\\n               ^^^^^^^^^^^^^^^^^^^\\n  File \"/usr/lib/python3.13/site-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 182, in async_completion\\n    return provider_config.transform_response(\\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\\n        model=model,\\n        ^^^^^^^^^^^^\\n    ...<8 lines>...\\n        encoding=encoding,\\n        ^^^^^^^^^^^^^^^^^^\\n    )\\n    ^\\n  File \"/usr/lib/python3.13/site-packages/litellm/llms/ollama/completion/transformation.py\", line 263, in transform_response\\n    \"name\": function_call[\"name\"],\\n            ~~~~~~~~~~~~~^^^^^^^^\\nKeyError: \\'name\\'\\n. Received Model Group=ollama/qwen2.5:7b-instruct\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '500'}}\nDEBUG    Added WorkflowRun to WorkflowMemory                      \n```\n\n## Environment\n- OS: Ubuntu\n- Agno Version: 1.1.3\n\n## Additional Context\nBasic chat works but when I include a simple web search tool I got below error.\nSame model works when using normal Ollama backend but doesn't when using Lite LLM backend with OpenAILike.\n\nThanks for the great work.",
      "state": "closed",
      "author": "alaap001",
      "author_type": "User",
      "created_at": "2025-02-18T06:44:23Z",
      "updated_at": "2025-03-21T07:24:34Z",
      "closed_at": "2025-03-08T03:31:36Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2166/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2166",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2166",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:28:03.993898",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "@alaap001 In this case did you build the LiteLLM model? \n\nIt looks like function results are not being communicated to it correctly? ",
          "created_at": "2025-02-20T14:30:15Z"
        },
        {
          "author": "alaap001",
          "body": "No I just ran Ollama server, and used that with litellm. \n\nhere is the LiteLLM config:\n```\nmodel_list:\n  - model_name: qwen2.5:7b-instruct\n    litellm_params:\n      model: ollama/qwen2.5:7b-instruct\n      # api_base: os.environ/OPENROUTER_API_KEY\n      # api_key: \"os.environ/OPENROUTER_API_KEY\"\n```\n",
          "created_at": "2025-02-20T15:44:24Z"
        },
        {
          "author": "alaap001",
          "body": "@dirkbrnd  any update?\n\nDo you need more info on this from me?",
          "created_at": "2025-02-25T06:36:51Z"
        },
        {
          "author": "dirkbrnd",
          "body": "Hi @alaap001 \nWe don't officially support LiteLLM, and we have the Ollama model class because Ollama also doesn't exactly mirror the OpenAI interface. Especially with tool calling. I can only recommend that you use the Ollama backend if that is possible for you.",
          "created_at": "2025-02-26T08:30:45Z"
        },
        {
          "author": "dirkbrnd",
          "body": "This was released recently!",
          "created_at": "2025-03-21T07:24:32Z"
        }
      ]
    },
    {
      "issue_number": 2465,
      "title": "[Bug]agno.exceptions.ModelProviderError: Input length 69053 exceeds the maximum length 65536. Request id: 0217424634794591614df5c6ac175b99b2192e77a1fc39df2f34e",
      "body": "# Description\n\nWhen use ExaTools to search web before ask model ,may cause Input length exceeds\n\n## Steps to Reproduce\n\n run example/travel_agent.py,  use Question  such as \"I have 5 friends want travel to hongkong at 5.1-5.3, within 10k HKD each, please suggest me a journey\"\n\n\n## Agent Configuration (if applicable)\n\n\ntravel_agent = Agent(\n    name=\"Globe Hopper\",\n    # model=OpenAIChat(id=\"gpt-4o\"),\n    model=DeepSeek(id=\"xxxx\",\n                   api_key=\"xxxx\",\n                   base_url=\"xxxx\"),\n    tools=[ExaTools()],\n    markdown=True, monitoring=True,\n\n\n## Expected Behavior\n\n\n## Actual Behavior\n\n\n## Screenshots or Logs (if applicable)\n\n\n\n  File \"/Users/xupeng/workspace/git/agno/cookbook/.venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1023, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'code': 'InvalidParameter', 'message': 'Input length 69053 exceeds the maximum length 65536. Request id: 0217424634794591614df5c6ac175b99b2192e77a1fc39df2f34e', 'param': '', 'type': 'BadRequest'}}\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/xupeng/workspace/git/agno/cookbook/examples/agents/travel_planner.py\", line 162, in <module>\n    travel_agent.print_response(\n  File \"/Users/xupeng/workspace/git/agno/cookbook/.venv/lib/python3.11/site-packages/agno/agent/agent.py\", line 3612, in print_response\n    for resp in self.run(\n  File \"/Users/xupeng/workspace/git/agno/cookbook/.venv/lib/python3.11/site-packages/agno/agent/agent.py\", line 548, in _run\n    for model_response_chunk in self.model.response_stream(messages=run_messages.messages):\n  File \"/Users/xupeng/workspace/git/agno/cookbook/.venv/lib/python3.11/site-packages/agno/models/base.py\", line 484, in response_stream\n    yield from self.process_response_stream(\n  File \"/Users/xupeng/workspace/git/agno/cookbook/.venv/lib/python3.11/site-packages/agno/models/base.py\", line 457, in process_response_stream\n    for response_delta in self.invoke_stream(messages=messages):\n  File \"/Users/xupeng/workspace/git/agno/cookbook/.venv/lib/python3.11/site-packages/agno/models/openai/chat.py\", line 463, in invoke_stream\n    raise ModelProviderError(\nagno.exceptions.ModelProviderError: Input length 69053 exceeds the maximum length 65536. Request id: 0217424634794591614df5c6ac175b99b2192e77a1fc39df2f34e\n\n\n\n\n## Environment\n- OS: (macOS)\n- Agno Version: 1.1.13\n-\n## Possible Solutions (optional)\n\n## Additional Context\n",
      "state": "closed",
      "author": "ZHAMoonlight",
      "author_type": "User",
      "created_at": "2025-03-20T09:47:00Z",
      "updated_at": "2025-03-21T07:13:51Z",
      "closed_at": "2025-03-21T07:13:51Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2465/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2465",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2465",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:28:04.180275",
      "comments": [
        {
          "author": "ysolanky",
          "body": "Hello @ZHAMoonlight !\n\nThis error occurs because the input length exceeds the maximum limit. The allowed input size depends on the model being used, and this example works great with gpt-4o. Additionally, exa tends to generate lengthy responses, contributing to the issue. To fix this, try limiting t",
          "created_at": "2025-03-20T20:04:08Z"
        }
      ]
    },
    {
      "issue_number": 1980,
      "title": "[Bug] Doubao LLM for running the agent team demo",
      "body": "# Description\n\nWhen replacing the LLM models with Doubao, an error occurs.\nHowever, it runs well when using the Phidata.\n\nDoubao llm is created by `from agno.models.openai.like import OpenAILike`.\n\n## Error\n```\nopenai.BadRequestError: Error code: 400 - {'error': {'code': 'InvalidParameter', 'message': 'One or more parameters specified in the request are not valid. Request id: 02173850780234684bae976ab37fc49f95f8882bb751870475bb0', 'param': '', 'type': 'BadRequest'}}\n```\n\n## Steps to Reproduce\n### code\n```\nfrom agno.agent import Agent\nfrom agno.models.openai import OpenAIChat\nfrom agno.tools.hackernews import HackerNewsTools\nfrom agno.tools.duckduckgo import DuckDuckGoTools\nfrom agno.tools.newspaper4k import Newspaper4kTools\nfrom LLMPool.LLMManager import LLMModelManager\n\nhn_researcher = Agent(\n    name=\"HackerNews Researcher\",\n    model=LLMModelManager().get_llm_model(\"doubao\"),\n    role=\"Gets top stories from hackernews.\",\n    tools=[HackerNewsTools()],\n)\n\nweb_searcher = Agent(\n    name=\"Web Searcher\",\n    model=LLMModelManager().get_llm_model(\"doubao\"),\n    role=\"Searches the web for information on a topic\",\n    tools=[DuckDuckGoTools()],\n    add_datetime_to_instructions=True,\n)\n\narticle_reader = Agent(\n    name=\"Article Reader\",\n    model=LLMModelManager().get_llm_model(\"doubao\"),\n    role=\"Reads articles from URLs.\",\n    tools=[Newspaper4kTools()],\n)\n\nhn_team = Agent(\n    name=\"Hackernews Team\",\n    model=LLMModelManager().get_llm_model(\"doubao\"),\n    team=[hn_researcher, web_searcher, article_reader],\n    instructions=[\n        \"First, search hackernews for what the user is asking about.\",\n        \"Then, ask the article reader to read the links for the stories to get more information.\",\n        \"Important: you must provide the article reader with the links to read.\",\n        \"Then, ask the web searcher to search for each story to get more information.\",\n        \"Finally, provide a thoughtful and engaging summary.\",\n    ],\n    show_tool_calls=True,\n    markdown=True,\n)\nhn_team.print_response(\"Write an article about the top 2 stories on hackernews\", stream=False)\n```\n",
      "state": "closed",
      "author": "JokerHB",
      "author_type": "User",
      "created_at": "2025-02-02T14:57:23Z",
      "updated_at": "2025-03-21T03:37:10Z",
      "closed_at": "2025-02-18T00:29:34Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/1980/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/1980",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/1980",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:28:04.362549",
      "comments": [
        {
          "author": "manthanguptaa",
          "body": "Hey @JokerHB! Can you help with the steps on how you configured Doubao?",
          "created_at": "2025-02-03T04:05:25Z"
        },
        {
          "author": "JokerHB",
          "body": "> Hey [@JokerHB](https://github.com/JokerHB)! Can you help with the steps on how you configured Doubao?\n\nThanks a lot. \n\nHere is the code for using Doubao to run the demo. Additionally, I added \"introduce yourself\" instructions for all agents and the agent team. For individual agents, it works well,",
          "created_at": "2025-02-03T04:32:13Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-02-18T00:29:33Z"
        },
        {
          "author": "Hwangkop",
          "body": "@JokerHB I have the same problem, how did you solve it?",
          "created_at": "2025-03-19T15:17:02Z"
        },
        {
          "author": "JokerHB",
          "body": "> [@JokerHB](https://github.com/JokerHB) I have the same problem, how did you solve it?\n\nChange the LLM model from Doubao to Qwen.",
          "created_at": "2025-03-21T03:37:08Z"
        }
      ]
    },
    {
      "issue_number": 2470,
      "title": "[Bug] AgentMemory: OPENAI_API_KEY not set. Please set the OPENAI_API_KEY environment variable.",
      "body": "# Description\nI'm trying to use a simple agent with AgentMemory but it always throws \"OPENAI_API_KEY not set. Please set the OPENAI_API_KEY environment variable.\" even if I set the MemoryClassifier and its api_key\n\n## Steps to Reproduce\n```\nmodel = OpenAIChat(\n    id=\"openai/gpt-4o\",\n    api_key=\"myapikey\",\n    base_url=\"https://openrouter.ai/api/v1/\"\n)\n\na = Agent(\n    model=model,\n    memory=AgentMemory(\n        create_user_memories=True,\n        db=PgMemoryDb(\n            table_name=\"agent_memory\",\n            schema=\"public\",\n            db_url=\"postgresql+psycopg://postgres:postgres@localhost:5432/my_agents\"\n        ),\n        classifier=MemoryClassifier(\n            model=model\n        )\n    )\n)\n\nfull_response = \"\"\n\nrun_response = await a.arun(\n    message=\"Hi! My name is jonh\",\n    stream=True\n)\n\nasync for chunk in run_response:\n    if chunk.content is not None:\n        full_response += chunk.content\n        yield chunk.content\n```\n\n## Expected Behavior\nShould not throws exception, since the MemoryClassifier instance has the model property with api_key settled\n\n## Actual Behavior\nIt throws exception even if I set the API Key on the MemoryClassifier model\n\n## Environment\n- OS: macOS\n- Agno Version: 1.1.14\n- Additional Environment Details: Python 3.13\n\n## Additional Context\nThe agent works if I set create_user_memories=False, it's something on AgentMemory\n",
      "state": "closed",
      "author": "alexandrereyes",
      "author_type": "User",
      "created_at": "2025-03-20T21:16:46Z",
      "updated_at": "2025-03-20T21:44:29Z",
      "closed_at": "2025-03-20T21:44:29Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2470/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2470",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2470",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:28:04.618011",
      "comments": [
        {
          "author": "alexandrereyes",
          "body": "I was missing the MemoryManager.",
          "created_at": "2025-03-20T21:44:29Z"
        }
      ]
    },
    {
      "issue_number": 2285,
      "title": "[Bug] Mistral Models are not working",
      "body": "# Description\nmistral models are not working\n\n## Steps to Reproduce\nList the steps needed to encounter this bug or issue.\n\n## Agent Configuration (if applicable)\n\nfrom agno.agent import Agent, RunResponse\nfrom agno.models.openai.like import OpenAILike\nfrom agno.models.groq import Groq\nfrom agno.models.mistral import MistralChat\nfrom google.colab import userdata\nfrom agno.tools.duckduckgo import DuckDuckGoTools\n\nagent = Agent(\n    model=MistralChat(\n        id=\"mistral-large-latest\",\n        api_key=userdata.get('MISTRAL_API_KEY'),\n         #base_url=\"https://api.mistral.ai/v1\",\n    ),\n    reasoning_model=Groq(\n        id=\"deepseek-r1-distill-llama-70b\",\n        api_key=userdata.get('GROQ_API_KEY'),\n        #base_url=\"https://api.groq.com/openai/v1\",\n    ),\n    tools=[DuckDuckGoTools()],\n    show_tool_calls=True,\n    markdown=True,\n    #reasoning=True,\n)\n\nagent.print_response(\"Search for latest news\", stream=True)\n\n## Expected Behavior\nan answer from the agent\n\n## Actual Behavior\nERROR    SDKError from Mistral: API error occurred: Status 400                                                     \n         {\"object\":\"error\",\"message\":\"Expected last role User or Tool (or Assistant with prefix True) for serving  \n         but got assistant\",\"type\":\"invalid_request_error\",\"param\":null,\"code\":null}                               \n---------------------------------------------------------------------------\nSDKError                                  Traceback (most recent call last)\n[/usr/local/lib/python3.11/dist-packages/agno/models/mistral/mistral.py](https://localhost:8080/#) in invoke_stream(self, messages)\n    283         try:\n--> 284             stream = self.get_client().chat.stream(\n    285                 model=self.id,\n\n6 frames\nSDKError: API error occurred: Status 400\n{\"object\":\"error\",\"message\":\"Expected last role User or Tool (or Assistant with prefix True) for serving but got assistant\",\"type\":\"invalid_request_error\",\"param\":null,\"code\":null}\n\nThe above exception was the direct cause of the following exception:\n\nModelProviderError                        Traceback (most recent call last)\n[/usr/local/lib/python3.11/dist-packages/agno/models/mistral/mistral.py](https://localhost:8080/#) in invoke_stream(self, messages)\n    293         except SDKError as e:\n    294             logger.error(f\"SDKError from Mistral: {e}\")\n--> 295             raise ModelProviderError(message=str(e), model_name=self.name, model_id=self.id) from e\n    296 \n    297     async def ainvoke(self, messages: List[Message]) -> Union[ChatCompletionResponse, ParsedChatCompletionResponse]:\n\nModelProviderError: API error occurred: Status 400\n{\"object\":\"error\",\"message\":\"Expected last role User or Tool (or Assistant with prefix True) for serving but got assistant\",\"type\":\"invalid_request_error\",\"param\":null,\"code\":null}\n\n## Screenshots or Logs (if applicable)\n\n![Image](https://github.com/user-attachments/assets/9fcb54cc-9f52-46c4-8be8-53fbe7f8c0ca)\n\n## Environment\n- OS: (e.g. macOS, Windows 11) \nWindows 11\n- Browser (if relevant): (e.g. Chrome 108, Firefox 107)\n- Agno Version: (e.g. v1.0.0)\nagno-1.1.8\n- External Dependency Versions: (e.g., yfinance 0.2.52)\n- Additional Environment Details: (e.g., Python 3.10)\nagno-1.1.8 deprecation-2.1.0 duckduckgo-search-7.5.0 eval-type-backport-0.2.2 exa-py-1.8.9 feedparser-6.0.11 groq-0.18.0 jsonpath-python-1.0.6 lancedb-0.20.0 lxml_html_clean-0.4.1 mistralai-1.5.0 mypy-extensions-1.0.0 newspaper4k-0.9.3.1 overrides-7.7.0 primp-0.14.0 pydantic-settings-2.8.1 pylance-0.23.2 pypdf-5.3.1 python-dotenv-1.0.1 python-multipart-0.0.20 requests-file-2.1.0 sgmllib3k-1.0.0 tantivy-0.22.0 tldextract-5.1.3 tomli-2.2.1 typing-inspect-0.9.0\n\n## Possible Solutions (optional)\nmaybe something related to this: https://github.com/crewAIInc/crewAI/issues/2194\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "Malaga82",
      "author_type": "User",
      "created_at": "2025-03-04T15:01:52Z",
      "updated_at": "2025-03-20T11:04:57Z",
      "closed_at": "2025-03-06T08:51:02Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 11,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2285/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2285",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2285",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:28:04.783448",
      "comments": [
        {
          "author": "Malaga82",
          "body": "tried using OpenAILike, same issues.",
          "created_at": "2025-03-04T15:03:22Z"
        },
        {
          "author": "janpdevops",
          "body": "### Reproduction:\n\nI can reproduce the bug, it presents itself in the cookbook-examples for mistral. Only the most basic.py works.\n\n### Probable reason:\nIt seems, mistral is picky about the roles, as in the cross-referenced bug https://github.com/crewAIInc/crewAI/issues/2194 \n\n### Workaround:\n\n- Sen",
          "created_at": "2025-03-05T00:11:11Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@Malaga82 That is indeed what is happening, Mistral doesn't like that another assistant made a message before (i.e. the reasoning model). \n\n@janpdevops I also don't know if that is a viable solution, because it would make message history (i.e. a multi-message exchange) be incorrect.\n\nI'm coming up w",
          "created_at": "2025-03-05T08:40:11Z"
        },
        {
          "author": "Malaga82",
          "body": "@janpdevops thanks for the update and fixing tries, i'll give it a try.\nI think this issue with mistralAI is common across many other frameworks, as we observed in crewAI.\ni mainly do tests on colab, will try on local.\n@dirkbrnd what i found doing some tests is that it's doesn't like the reasoning_m",
          "created_at": "2025-03-05T10:21:39Z"
        },
        {
          "author": "Malaga82",
          "body": "@dirkbrnd I tried your PR and it doesn't give errors now, both with or without reasoning_model, BUT with reasoning_model it doesn't use tools.\nHaven't tried other combinations, just mistral-large-latest and groq deepseek-r1-distill-llama-70b",
          "created_at": "2025-03-05T11:01:05Z"
        }
      ]
    },
    {
      "issue_number": 2463,
      "title": "[Bug]Failed to load resource: the server responded with a status of 404 ()",
      "body": "# Description\nBriefly describe the issue you’re experiencing or the bug you’ve found.\n\n## Steps to Reproduce\nList the steps needed to encounter this bug or issue.\n\n## Agent Configuration (if applicable)\nProvide relevant agent configuration.\n\n## Expected Behavior\nWhat did you expect to happen?\n\n## Actual Behavior\nWhat actually happened instead?\n\n## Screenshots or Logs (if applicable)\nInclude any relevant screenshots or error logs that demonstrate the issue.\n\n## Environment\n- OS: (e.g. macOS, Windows 11)\n- Browser (if relevant): (e.g. Chrome 108, Firefox 107)\n- Agno Version: (e.g. v1.0.0)\n- External Dependency Versions: (e.g., yfinance 0.2.52)\n- Additional Environment Details: (e.g., Python 3.10)\n\n## Possible Solutions (optional)\nSuggest any ideas you might have to fix or address the issue.\n\n## Additional Context\nAdd any other context or details about the problem here.\n",
      "state": "closed",
      "author": "ruidanwang",
      "author_type": "User",
      "created_at": "2025-03-20T08:56:56Z",
      "updated_at": "2025-03-20T08:57:42Z",
      "closed_at": "2025-03-20T08:57:42Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2463/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2463",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2463",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:28:04.996379",
      "comments": []
    },
    {
      "issue_number": 2444,
      "title": "[Bug] With Gemini models team agents are giving AttributeError: type object 'tuple' has no attribute 'raw_function'",
      "body": "# Description\nRecreating the examples provided [here](https://docs.agno.com/agents/teams) with Gemini models are resulting in  AttributeError: type object 'tuple' has no attribute 'raw_function'\nand a warning Could not parse args for transfer_task_to_<agent name>: name 'Optional' is not \n         defined \n\n## Steps to Reproduce\nUse google gemini model instead of Chat openAI and run\n\n## Code (if applicable)\nThis is an example code\n```\nfrom agno.agent import Agent\nfrom agno.models.google import Gemini\n\nduckduckgo_agent = Agent(\n    name='DuckDuckGo Agent',\n    model=Gemini(api_key=GEMINI_API_KEY, id=\"gemini-2.0-flash\"),\n    role='You are equipped with DuckDuckGo tools to help with searching business info on the web',\n    tools=[DuckDuckGoTools()],\n    show_tool_calls=True,\n    debug_mode=True\n)\n\nteam_agent = Agent(\n    model=Gemini(api_key=GEMINI_API_KEY, id=\"gemini-2.0-flash\"),\n    team=[duckduckgo_agent],\n    add_history_to_messages=True,\n    # add_transfer_instructions=True,\n    description=dedent('''\n    You are now connected to the **DuckDuckGo Agent**.\n\n The **DuckDuckGo Agent** will help you fill in any missing information about businesses\n    '''),\n    instructions=[dedent('''\n    Use the DuckDuckGo Agent to fill any missing information about businesses.\n    ''')],\n    # expected_output=expected_output,\n    markdown=True,\n    show_tool_calls=True,\n    reasoning=True,\n    debug_mode=True,\n    structured_outputs=True,\n    tool_choice=\"auto\", \n)\n```\n\n## Screenshots or Logs (if applicable)\n\n/myenv/lib/python3.12/site-packages/pydantic/_internal/_validate_call.py\", line 153, in __eq__\n    (self.raw_function == other.raw_function)\n                          ^^^^^^^^^^^^^^^^^^\nAttributeError: type object 'tuple' has no attribute 'raw_function'\n",
      "state": "closed",
      "author": "bhuwan-nw18",
      "author_type": "User",
      "created_at": "2025-03-18T08:25:12Z",
      "updated_at": "2025-03-19T12:44:38Z",
      "closed_at": "2025-03-19T12:44:37Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2444/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2444",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2444",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:28:04.996398",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Hi @bhuwan-nw18 \nI am unable to replicate this with your example. What version of `agno` are you using? ",
          "created_at": "2025-03-19T10:12:17Z"
        },
        {
          "author": "bhuwan-nw18",
          "body": "> Hi [@bhuwan-nw18](https://github.com/bhuwan-nw18) I am unable to replicate this with your example. What version of `agno` are you using?\n\nagno (1.1.13)",
          "created_at": "2025-03-19T10:18:40Z"
        },
        {
          "author": "dirkbrnd",
          "body": "I ran that exact example code and it worked. Can you share a longer error stacktrace? I want to see where the error stems from",
          "created_at": "2025-03-19T11:12:39Z"
        },
        {
          "author": "bhuwan-nw18",
          "body": "> I ran that exact example code and it worked. Can you share a longer error stacktrace? I want to see where the error stems from\n\nSure, Here it is.\n(EDIT : stacktrace added from agno run  )\n\n```\nWARNING  Could not parse args for transfer_task_to_duckduckgo_agent:   \n         name 'Optional' is not d",
          "created_at": "2025-03-19T11:19:07Z"
        },
        {
          "author": "dirkbrnd",
          "body": "I still can't replicate, but I can add a try-except to prevent this issue. I just won't be able to test it. \n\nWhat version of pydantic do you have? \n",
          "created_at": "2025-03-19T12:38:02Z"
        }
      ]
    },
    {
      "issue_number": 2424,
      "title": "[Bug] Agent Tool Call Fails with 'Missing Required Parameter' Error",
      "body": "# Description\nI have created an agent that includes a tool for making HTTPS requests to a public F1 API. Below is the tool definition:\n```\n@tool(name=\"get_driver_info\", description=\"Get information about a F1 driver\")\ndef get_driver_info(driver_number: int):\n    \"\"\"Get information about a F1 driver.\"\"\"\n    return F1API.get_driver_info(driver_number)\n```\n\nThe tool is then passed to the agent as follows:\n\n```\nagent = Agent(\n            model=self.model,\n            tools=[get_driver_info],\n            ...\n        )\n```\n\nThe agent correctly identifies the need for a tool call and executes it. However, I encounter the following error:\n\n```\nraise ModelProviderError(\nagno.exceptions.ModelProviderError: Missing required parameter: 'messages[3].content[0].type'.\n```\n\nNotably, the API being called is functioning correctly, so the issue is not with the API itself. I have tested the tool both with and without the @ tool decorator, but the error persists.\n\n## Expected Behavior\nThe agent should:\n\n- Recognize the tool\n- Execute the tool call\n- Return the tool call result successfully\n\n## Actual Behavior\n\nInstead, the following error occurs:\n```\nraise ModelProviderError(\nagno.exceptions.ModelProviderError: Missing required parameter: 'messages[3].content[0].type'.\n```\n\n## Environment\n- Agno Version: lastest",
      "state": "closed",
      "author": "martimfasantos",
      "author_type": "User",
      "created_at": "2025-03-16T02:30:12Z",
      "updated_at": "2025-03-19T12:43:25Z",
      "closed_at": "2025-03-17T09:56:59Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2424/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2424",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2424",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:28:05.279046",
      "comments": [
        {
          "author": "manthanguptaa",
          "body": "Hey @martimfasantos! What model are you using?",
          "created_at": "2025-03-16T13:23:23Z"
        },
        {
          "author": "martimfasantos",
          "body": "> Hey [@martimfasantos](https://github.com/martimfasantos)! What model are you using? \n\nI am using `AzureOpenAI` with a deployment of `gpt-4o-mini`.  \n\nP.S. I tested it with other agent frameworks, and I believe the issue isn’t with the model.\n\n",
          "created_at": "2025-03-16T14:23:44Z"
        },
        {
          "author": "manthanguptaa",
          "body": "I saw that you are using `@tool` decorator, which isn't recognised in the Agno SDK. Here are some docs to help you make your own custom tools.\nhttps://docs.agno.com/tools/functions\nhttps://docs.agno.com/tools/custom-toolkits",
          "created_at": "2025-03-16T16:05:33Z"
        },
        {
          "author": "martimfasantos",
          "body": "@manthanguptaa As mentioned in the issue, I also attempted implementing the tool this way:\n\n```\n# tool\ndef get_driver_info(driver_number: int, session_key: int = 9158) -> str:\n\t\"\"\"Useful function to get f1 driver information.\"\"\"\n\timport requests \n\t\n\turl = f\"https://api.openf1.org/v1/drivers?driver_n",
          "created_at": "2025-03-16T16:24:07Z"
        },
        {
          "author": "manthanguptaa",
          "body": "So, I was able to run it using this snippet \n```\nfrom agno.agent import Agent\n\n\ndef get_driver_info(driver_number: int, session_key: int = 9158) -> str:\n    \"\"\"Useful function to get f1 driver information.\"\"\"\n    import requests\n    import json\n\n    url = f\"https://api.openf1.org/v1/drivers?driver_n",
          "created_at": "2025-03-16T16:33:26Z"
        }
      ]
    },
    {
      "issue_number": 2441,
      "title": "[Bug] Toolkits error out with new type annotation scheme",
      "body": "# Description\nThere's a _newish_ syntax for type annotating unions (with `|` instead of `Union`) which are supported officially (and recommended) by Python 3.10 onwards.\n\nHowever, their type is currently returned as `types.UnionType`, which doesn't match `Union`, and thus fail converting the tool params to JSON schema.\n\nPR #2379 fixes this issue (and a few others I identified, described in the PR).\n",
      "state": "closed",
      "author": "kepler",
      "author_type": "User",
      "created_at": "2025-03-17T18:27:45Z",
      "updated_at": "2025-03-19T11:11:42Z",
      "closed_at": "2025-03-19T11:11:42Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2441/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2441",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2441",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:28:05.561304",
      "comments": []
    },
    {
      "issue_number": 2447,
      "title": "[Bug] AttributeError: VALID_MIME_TYPES",
      "body": "# Description\nThe current Pydantic validation of mime types for File media fails with an attribute error because the validator tries to use `cls.VALID_MIME_TYPES`, making it impossible to instantiate a `File` with `mime_type`.\n\n## Environment\n- OS: macOS\n- Agno Version: 1.1.10\n\n## Possible Solutions (optional)\n\nPR https://github.com/agno-agi/agno/pull/2445 proposes a fix.\n",
      "state": "closed",
      "author": "kepler",
      "author_type": "User",
      "created_at": "2025-03-18T15:53:26Z",
      "updated_at": "2025-03-18T17:13:00Z",
      "closed_at": "2025-03-18T17:12:59Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2447/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2447",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2447",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:28:05.561325",
      "comments": [
        {
          "author": "dirkbrnd",
          "body": "Thanks for the fix!",
          "created_at": "2025-03-18T17:12:59Z"
        }
      ]
    },
    {
      "issue_number": 2003,
      "title": "[Bug] Can't login for playground and monitoring",
      "body": "I try to use playground and monitoring but can't login anyway i try both way to login  which is `ag setup` and directly with api key when try with ag setup the error occurs \n\n<img width=\"358\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/06859376-b147-4b28-bbce-b6516e6fa7f0\" />\n\nthere isn't exist error at api key but it is not working  because when i try the playground example at the documentation and its not working \n\n<img width=\"1760\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/41339545-29f2-46b7-be4c-9dbb01b5be23\" />\n\n<img width=\"1786\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/68f3960a-db98-48b6-a43c-5c74e6e92a84\" />\n\nand ` http://localhost:7777/` return \n\n`{\"detail\":\"Not Found\"}`",
      "state": "closed",
      "author": "emirhanyagci",
      "author_type": "User",
      "created_at": "2025-02-04T11:15:17Z",
      "updated_at": "2025-03-18T12:01:13Z",
      "closed_at": "2025-03-18T12:01:13Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 17,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2003/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2003",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2003",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:28:05.770366",
      "comments": [
        {
          "author": "emirhanyagci",
          "body": "tried at safari and brave browser",
          "created_at": "2025-02-04T11:19:57Z"
        },
        {
          "author": "emirhanyagci",
          "body": "working on chrome , can you fix this ?",
          "created_at": "2025-02-04T11:22:41Z"
        },
        {
          "author": "ysolanky",
          "body": "Hello @emirhanyagci !\n\nThis is a known issue. Here is some more [context](https://docs.agno.com/faq/cli-auth). Unfortunately this is not something we can currently fix. Can you please export your `AGNO_API_KEY ` instead?",
          "created_at": "2025-02-05T21:20:20Z"
        },
        {
          "author": "emirhanyagci",
          "body": "i already tried with api key just working at google browser",
          "created_at": "2025-02-11T08:06:32Z"
        },
        {
          "author": "LeonidShamis",
          "body": "Hi,\nI have the same issue. I tested it on Google Chrome and Brave browsers with the same result - I get error:\n\n>The endpoint is not available\n>Choose a different endpoint\n\nI'm sure that the endpoint is working fine and I configured and used the AGNO_API_KEY from the [Playground](https://app.agno.co",
          "created_at": "2025-02-12T03:34:41Z"
        }
      ]
    },
    {
      "issue_number": 2440,
      "title": "[Bug] Async summarizer breaks for some models",
      "body": "# Description\nSome models like Claude require at least one user message, but the async summarizer method only sends a system message.\n\nPR https://github.com/agno-agi/agno/pull/2439 applies a previous fix that was applied to the sync method.",
      "state": "closed",
      "author": "kepler",
      "author_type": "User",
      "created_at": "2025-03-17T18:21:49Z",
      "updated_at": "2025-03-18T09:57:01Z",
      "closed_at": "2025-03-18T09:57:01Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2440/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2440",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2440",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:28:05.970115",
      "comments": []
    },
    {
      "issue_number": 2318,
      "title": "[Feature Request] Support Markdown Files as KnowledgeBase",
      "body": "## Problem Description\nBesides text files a wanna use markdown files as knowledge base.\n\n## Proposed Solution\nclass MarkdownKnowledgeBase needs to be implemented\n\n## Alternatives Considered\nWorkaround is not using agno for this :'-(\n\n## Additional context\n.\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[ ] Yes, I’d love to work on it!**\n**[x ] I’m open to collaborating but need guidance.**\n**[ ] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "researchk8",
      "author_type": "User",
      "created_at": "2025-03-07T10:16:31Z",
      "updated_at": "2025-03-18T03:22:40Z",
      "closed_at": "2025-03-18T03:22:40Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2318/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2318",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2318",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:28:05.970136",
      "comments": []
    },
    {
      "issue_number": 2295,
      "title": "[Feature Request] Use SQL DB or FAISS index as a knowledge base",
      "body": "## Problem Description\nI would like to know:\n- If it's possible to plug directly an SQL db to the agent instead of embedding vector\n- Or at least, attached an index of embedding generated by FAISS\nIndeed, I have a huge amount of embedding already calculated and indexed by FAISS and I would like to take advantage of that to give it to my agent for knowledge base.\n\nIs it possible to do that ? Should I extend the AgentKnowledge that load an index and search on it ?\n\n## Would you like to work on this?\nWe welcome contributions! Let us know if you’d like to help implement this feature.\n**[ ] Yes, I’d love to work on it!**\n**[x] I’m open to collaborating but need guidance.**\n**[x] No, I’m just sharing the idea.**\n",
      "state": "closed",
      "author": "lironesamoun",
      "author_type": "User",
      "created_at": "2025-03-05T16:26:36Z",
      "updated_at": "2025-03-18T03:19:15Z",
      "closed_at": "2025-03-18T03:19:15Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2295/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2295",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2295",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:28:05.970144",
      "comments": [
        {
          "author": "mishramonalisha76",
          "body": "Hi @lironesamoun Thanks for reaching out .\nWe currently offer a SQL [tool](https://docs.agno.com/tools/toolkits/sql) that provides direct SQL access to the agent. However, its functionality is somewhat limited, so developing a custom SQL tool specifically tailored for the model would be a more effec",
          "created_at": "2025-03-06T08:21:39Z"
        }
      ]
    },
    {
      "issue_number": 2279,
      "title": "[Bug] Multi User Setup - Data Security Issues",
      "body": "We need to have the user_id in a toolkit function in order to get the right data when a user calls an agent.\nWe have a multi-user setup for agent system to handle permissions and data access.\nSo basically we create one agent per user:\n\n\n\n### main function\n```\n# Cache to store agent instances\n_agent_cache = {}\n\ndef get_agent_for_user(user: User):\n    # Check if agent exists in cache\n    if user.id in _agent_cache:\n        return _agent_cache[user.id]\n\n    # Create toolkit instances with user metadata\n    personal_toolkit = PersonalTools()\n    # Create new agent\n    agent = Agent(\n        session_id=session_id,\n        user_id=user_id,\n        tools=[personal_toolkit]\n    )\n\n    # Cache the agent instance\n    _agent_cache[user.id] = agent\n    \n    return agent\n\n```\n\n### toolkit\n```\nclass PersonalToolkit(Toolkit)\n...\n  async def get_personal_data(self,  agent: Agent) -> str:\n     user_id = agent.user_id\n      # performs db lookup for the data with the user_id\n     return personal_data\n...\n```\n\n\n\n\nBut we are facing issues with that topic: A multi user setup is not document and it seems like not supported as a first class citizen. We did find the agent parameter in the toolkit only by looking at the code.\n\nWe are now facing the issue, that when we have many users, **we get the wrong user ids** by the agent.\n\nThis caused us **significant data privacy leaks and security issues**.\n\nHow can we develop a secure multi user setup using your framework?\n\n\n",
      "state": "closed",
      "author": "flobaader",
      "author_type": "User",
      "created_at": "2025-03-03T19:55:37Z",
      "updated_at": "2025-03-18T03:18:11Z",
      "closed_at": "2025-03-18T03:18:11Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 11,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2279/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2279",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2279",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:28:06.147829",
      "comments": [
        {
          "author": "flobaader",
          "body": "@dirkbrnd could you help me with that? We are currently evaluating our agent frameworks, because we have the feeling that there are still many bugs and issues in this library for a production setup, because we really faced some nasty bugs during the last 4 weeks of production.\nOn the other side I se",
          "created_at": "2025-03-03T19:57:50Z"
        },
        {
          "author": "ItsRoy69",
          "body": "I guess for handling this multi user secure setup setting up user isolation where each user gets their own agent instance and adding a context validation before accessing the data is needed",
          "created_at": "2025-03-04T03:57:36Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@flobaader It is an issue with state management in the agent. Your use-case is of course valid. I'll replicate from my side and see what we can do.",
          "created_at": "2025-03-04T07:03:40Z"
        },
        {
          "author": "dirkbrnd",
          "body": "@flobaader Are you using the same session ID across the agents? ",
          "created_at": "2025-03-04T07:05:25Z"
        },
        {
          "author": "flobaader",
          "body": "We use session_id = user_id + platform_id \n\nPlatform can be WhatsApp or Teams \n\n@dirkbrnd ",
          "created_at": "2025-03-04T07:15:13Z"
        }
      ]
    },
    {
      "issue_number": 2236,
      "title": "Enhanced PDF Extraction: Improved Support for Images, Tables, and Figures",
      "body": "\n\n\n**Problem Description:**  \nOur current PDF extraction functionality is limited to basic text extraction. The custom extractor in place struggles with advanced elements—namely images, tables, and figures—because it relies on a proprietary vector-based scheme. This limitation not only prevents proper extraction of these graphic elements but also affects downstream processes, especially in workflows that depend on contextual data extraction (e.g., Retrieval-Augmented Generation, or RAG).\n\n**Proposed Solution:**  \n- Integrate support for robust libraries, such as *PyMuPDF* or *PyMuPDFLLM*, which natively handle image, table, and figure extraction from PDFs.  \n- Ensure that any new extraction module maintains compatibility with existing vector-based search capabilities and allows for seamless incorporation into RAG workflows.  \n- Consider extending support to include additional frameworks (e.g., KAG) that could further enhance data retrieval and processing capabilities.  \n\n**Participation Statement:**  \nI am sharing this idea to address a common pain point with current PDF extraction tools. Although I currently do not have the technical capacity to implement these changes, I believe this proposal could serve as a solid foundation for further development.\n",
      "state": "closed",
      "author": "RelightEvasion",
      "author_type": "User",
      "created_at": "2025-02-26T18:26:10Z",
      "updated_at": "2025-03-18T03:14:55Z",
      "closed_at": "2025-03-18T03:14:55Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2236/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2236",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2236",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:28:06.416267",
      "comments": [
        {
          "author": "RelightEvasion",
          "body": "and forget to say is that when trying to make own extraction tool It cant uses custom vectorbase table scheme what is also annoying so basically images , figures , tables are not possible ",
          "created_at": "2025-02-26T18:33:20Z"
        },
        {
          "author": "leosilberg",
          "body": "+1 for pdf extraction using [docling](https://github.com/DS4SD/docling) ",
          "created_at": "2025-02-27T21:26:25Z"
        },
        {
          "author": "mishramonalisha76",
          "body": "@RelightEvasion Thanks for your suggestion! This would be a valuable enhancement to our PDF extraction module, and we truly appreciate your input. We’ll definitely consider it as we plan our next set of priorities and move forward accordingly.",
          "created_at": "2025-02-28T06:32:56Z"
        }
      ]
    },
    {
      "issue_number": 2206,
      "title": "[Feature Request] Workflow as a graph",
      "body": "Would it be possible to have workflows as graphs, so that we can have e.g. loops. This is supported by CrewAI and LangGraph.",
      "state": "closed",
      "author": "smortezah",
      "author_type": "User",
      "created_at": "2025-02-22T19:27:12Z",
      "updated_at": "2025-03-18T03:12:41Z",
      "closed_at": "2025-03-18T03:12:41Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2206/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 1,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2206",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2206",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:28:06.607632",
      "comments": [
        {
          "author": "pritipsingh",
          "body": "Thank you for the request! You should be able to create this with some external support since workflows are highly customizable. However, for native support, we'll definitely look into it. CrewAI and LangGraph have solid implementations, and we want to ensure Agno not only supports similar capabilit",
          "created_at": "2025-02-24T16:19:09Z"
        }
      ]
    },
    {
      "issue_number": 2137,
      "title": "[Question] Support for Russian Language in Agents and Vector Databases",
      "body": "When creating agents with prompts in Russian or when building a vector database using Russian-language data, the system does not function as expected. The agents fail to process the prompts correctly, and the vector database does not handle Russian text appropriately.",
      "state": "closed",
      "author": "colegero",
      "author_type": "User",
      "created_at": "2025-02-15T13:11:02Z",
      "updated_at": "2025-03-18T03:11:10Z",
      "closed_at": "2025-03-18T03:11:10Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2137/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 1,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2137",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2137",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:28:06.799288",
      "comments": [
        {
          "author": "monali7-d",
          "body": "Hey @colegero, thank you so much for your wonderful suggestion! I’ve happily added it to our Community Wishlist. Our team is excited to discuss it internally, and we’ll be sure to keep you updated on any progress. We really appreciate your input!",
          "created_at": "2025-02-17T06:26:08Z"
        }
      ]
    },
    {
      "issue_number": 2419,
      "title": "[Feature Request] Agents with Multi-Domain knowledge",
      "body": "Being able to add multiple knowledge_bases to the same agent or introducing retriever tools\n\n**Result**: Agents that are able to search for knowledge from different domains",
      "state": "closed",
      "author": "martimfasantos",
      "author_type": "User",
      "created_at": "2025-03-14T18:59:07Z",
      "updated_at": "2025-03-16T16:18:44Z",
      "closed_at": "2025-03-16T16:18:44Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2419/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2419",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2419",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:28:07.014419",
      "comments": [
        {
          "author": "manthanguptaa",
          "body": "Hey @martimfasantos! You can use https://docs.agno.com/knowledge/combined this to give your agent multiple knowledge bases",
          "created_at": "2025-03-16T16:06:48Z"
        }
      ]
    },
    {
      "issue_number": 2254,
      "title": "[Bug] `ag ws create` command still create some of the files with `phi` lib reference",
      "body": "# Description\nCreated the workspace using `ag ws create` command. It created the workspace but there are some files that refer to `phi` package in place of `agno`, so when I run `ag ws up dev`, it fails with errors saying `ModuleNotFoundError: No module named 'phi'`\n\n## Steps to Reproduce\nIn blank project (where agno package is already installed), run `ag ws create` and then run `ag ws up dev` command.\n\n## Expected Behavior\n`ag ws up dev` should run successfully and there should not be any reference to `phi` in created workspace.\n\n## Actual Behavior\nAfter creating the fresh workspace in new project, `ag ws up dev` command fails with error `ModuleNotFoundError: No module named 'phi'`, as there are some files that refer to older package name `phi`\n\n## Screenshots or Logs (if applicable)\n![Image](https://github.com/user-attachments/assets/50fa88e3-1c3a-4cd0-90b4-b6df88ec5474)\n\n## Environment\n- OS: mac\n- Browser (if relevant): Chrome\n- Agno Version: 1.1.7\n- Additional Environment Details: Python 3.12.4\n\n## Possible Solutions (optional)\nNo file in freshly created workspace should refer `phi` package.\n",
      "state": "closed",
      "author": "gauravdhiman",
      "author_type": "User",
      "created_at": "2025-02-27T23:08:08Z",
      "updated_at": "2025-03-15T00:30:49Z",
      "closed_at": "2025-03-15T00:30:49Z",
      "labels": [
        "bug",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2254/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2254",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2254",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:28:07.199065",
      "comments": [
        {
          "author": "gauravdhiman",
          "body": "Even `requirements.txt` is installing `phidata==2.5.3` and not `agno`, `agno-aws` and `agno-docker` packages.",
          "created_at": "2025-02-27T23:24:17Z"
        },
        {
          "author": "ashpreetbedi",
          "body": "Hi @gauravdhiman, you are correct -- this is being updated as we speak and should be ready for use early next week",
          "created_at": "2025-02-28T14:50:46Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been automatically marked as stale due to 14 days of inactivity and will now be closed.",
          "created_at": "2025-03-15T00:30:47Z"
        }
      ]
    },
    {
      "issue_number": 2267,
      "title": "[Bug] `AgentMemory.get_message_pairs()` returns repeated messages when `Agent.add_history_to_messages = True`",
      "body": "Hi,\nI found this bug which effects the summarizer results.\n\nWhen using `AgentMemory.summarizer()`, it uses `AgentMemory.get_message_pairs()`, but when the `Agent.add_history_to_messages = True`, The messages in each `RunResponse` are updated whith history.\nSo the result of  the `get_message_pairs` is the first two messages of the history!\nSo  in `get_message_pairs`  the condition `message.from_history == False` must be added to each for loop I guess.\n",
      "state": "closed",
      "author": "mehrzadai",
      "author_type": "User",
      "created_at": "2025-03-01T09:38:46Z",
      "updated_at": "2025-03-14T19:16:45Z",
      "closed_at": "2025-03-14T19:16:45Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/agno-agi/agno/issues/2267/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/agno-agi/agno/issues/2267",
      "api_url": "https://api.github.com/repos/agno-agi/agno/issues/2267",
      "repository": "agno-agi/agno",
      "extraction_date": "2025-06-21T23:28:07.407650",
      "comments": []
    }
  ]
}