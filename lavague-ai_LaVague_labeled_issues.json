{
  "repository": "lavague-ai/LaVague",
  "repository_info": {
    "repo": "lavague-ai/LaVague",
    "stars": 6080,
    "language": "Python",
    "description": "Large Action Model framework to develop AI Web Agents",
    "url": "https://github.com/lavague-ai/LaVague",
    "topics": [
      "ai",
      "browser",
      "large-action-model",
      "llm",
      "oss",
      "rag"
    ],
    "created_at": "2024-02-26T23:40:23Z",
    "updated_at": "2025-06-21T12:10:05Z",
    "search_query": "ai agent language:python stars:>3 -framework",
    "total_issues_estimate": 92,
    "labeled_issues_estimate": 12,
    "labeling_rate": 13.5,
    "sample_labeled": 5,
    "sample_total": 37,
    "has_issues": true,
    "repo_id": 763795053,
    "default_branch": "main",
    "size": 100444
  },
  "extraction_date": "2025-06-22T00:36:58.825551",
  "extraction_type": "LABELED_ISSUES_ONLY",
  "total_labeled_issues": 190,
  "issues": [
    {
      "issue_number": 547,
      "title": "Documentation for integration with Ollama",
      "body": "I couldn't find any documentation how to configure lavague with ollama.\n\nTo support or document  ollama tool calling with lavague\n\nCan do something similar with crewai and selenium but it needs some advanced programming and customisation",
      "state": "open",
      "author": "myrulezzz",
      "author_type": "User",
      "created_at": "2024-08-06T16:48:55Z",
      "updated_at": "2025-03-09T06:54:05Z",
      "closed_at": null,
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/547/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/547",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/547",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:25.202068",
      "comments": [
        {
          "author": "lyie28",
          "body": "Hi @myrulezzz,\r\n\r\nYou can pass LlamaIndex model instances to LaVague. So you can:\r\n\r\n1. Refer to LlamaIndex's docs on Ollama for details of how to create Ollama model instance:\r\n- For llms: https://docs.llamaindex.ai/en/stable/api_reference/llms/ollama/\r\n- For embedding models: https://docs.llamaind",
          "created_at": "2024-08-07T10:45:34Z"
        },
        {
          "author": "VKumar555",
          "body": "Hi @lyie28, I am interested in Ollama default Context integration. I am trying to automate web and mobile application test cases using LaVague agent. It will be beneficial for me if you can create Ollama default context",
          "created_at": "2024-09-10T09:50:30Z"
        },
        {
          "author": "suryakumaran2611",
          "body": "@lyie28  Yes that would be nice to have a default context for ollama",
          "created_at": "2025-03-09T06:54:04Z"
        }
      ]
    },
    {
      "issue_number": 48,
      "title": "Add LiteLLM support so that we can use 100+ Different LLM's easily with this project ",
      "body": "Litellm is open source project you can read about them if you want https://github.com/BerriAI/litellm\r\nMany projects are integrating with it because with this we can use easily 100+ different LLMs as it helps in creating local proxy server which api structure is open ai compatible and with one apo structure it becomes easy to change model and api key and use easily without additional configurations and reading and implementing from individual llm docs so please think about it",
      "state": "closed",
      "author": "Greatz08",
      "author_type": "User",
      "created_at": "2024-03-20T15:25:37Z",
      "updated_at": "2024-10-14T19:17:52Z",
      "closed_at": "2024-04-02T07:45:45Z",
      "labels": [
        "help wanted"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/48/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/48",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/48",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:25.393600",
      "comments": [
        {
          "author": "dhuynh95",
          "body": "We can do an integration with them.\r\n\r\nCould you have a look at how we do [integrations ](https://github.com/lavague-ai/LaVague/tree/main/examples/api)and integrate [Llama(index's integration of LiteLLM](https://docs.llamaindex.ai/en/stable/examples/llm/litellm.html#litellm)?",
          "created_at": "2024-03-21T22:47:10Z"
        },
        {
          "author": "isaac-chung",
          "body": "Just started a draft to gauge if I'm in the right direction. I imagine we'd also need to add a notebook under docs/docs/integrations?",
          "created_at": "2024-03-26T11:49:16Z"
        },
        {
          "author": "emrgnt-cmplxty",
          "body": "Alternatively, you could use this as an opportunity to migrate to a easier to maintain/simpler RAG system like R2R (which is powered by LiteLLM) -  https://github.com/SciPhi-AI/R2R.\r\n\r\nI would be happy to help with the migration if there is any interest.",
          "created_at": "2024-04-01T18:56:09Z"
        },
        {
          "author": "tomlavez",
          "body": "I'm trying to replicate the azure example using LiteLLM but i'm facing a 404, probably because my endpoint is being messed up at some point. It should make a request at \"<my-link>\" but it is instead making at \"<my-link>/openai/deployments/gpt-4o/chat/completions?api-version=2023-07-01-preview\" which",
          "created_at": "2024-10-14T19:17:50Z"
        }
      ]
    },
    {
      "issue_number": 563,
      "title": "Handle action code that exceeds the max_tokens by truncating code after last full action and adding three backticks.",
      "body": "If the LLM generates an action that is longer than max tokens it will be cut off and not have the final three ticks to end the yaml code, which leads to an error.\r\n\r\nTo handle this, we can:\r\n\r\nIn extractors.py:\r\n\r\n1) Change the `DynamicExtractor` `get_type` to return the type `yaml, json, etc.` not only where there is ```yaml  ```, but also when there is ```yaml and at least one action - even if there is not three ending backticks\r\n\r\n2) In at least YamlFromMarkdownExtractor - as this is the most frequently used extractor - but logic could be applied to others as well:\r\n\r\nModify `extract` method so that if there is three opening backticks but not three ending ones - it will truncate the text after the last full action & then add three backticks, before continuing as normal to return the action text.",
      "state": "open",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-08-09T15:55:10Z",
      "updated_at": "2024-09-21T21:15:05Z",
      "closed_at": null,
      "labels": [
        "bug",
        "enhancement",
        "help wanted",
        "good first issue"
      ],
      "label_count": 4,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/563/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/563",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/563",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:25.672158",
      "comments": [
        {
          "author": "stanikeva",
          "body": "Hello @lyie28 ! I would really like to contribute on the project. Could you please share more information about the issue?",
          "created_at": "2024-09-21T21:15:04Z"
        }
      ]
    },
    {
      "issue_number": 272,
      "title": "Exploration of Phi-3 Medium Vision and Text for fully local agent",
      "body": "Lots of people have asked to have a local version working that is not reliant on OpenAI.\r\n\r\nSo far OSS models have seemed to not be good enough but [Phi-3](https://huggingface.co/microsoft/Phi-3-vision-128k-instruct) might make it.\r\n\r\nIt could be interesting if someone replace the `mm_llm` and `llm` in both the `WorldModel` and `ActionEngine` to see if it is performant enough.",
      "state": "open",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-05-29T09:26:23Z",
      "updated_at": "2024-09-13T10:22:02Z",
      "closed_at": null,
      "labels": [
        "help wanted",
        "core",
        "ActionEngine",
        "Agent",
        "HighPrio"
      ],
      "label_count": 5,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/272/reactions",
        "total_count": 5,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 5,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/272",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/272",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:25.879685",
      "comments": [
        {
          "author": "dhuynh95",
          "body": "@catyung is exploring this currently. Here are some exchanges on the Discord : \r\n\r\n> I'm working on this. \r\nVLM : Phi-3-Vision \r\nLLM : Codestral \r\nEmbedding : BGE-M3 \r\nBascially, still not able to run through the agent.run() , run it separately and edit some prompt is necessary \r\nI tried to use ONNX",
          "created_at": "2024-06-16T14:22:24Z"
        },
        {
          "author": "catyung",
          "body": "Here is the code that I use for using fully open-source models as world model, action engine, embedding model \r\n\r\n# LOAD LLM MODELS\r\n```\r\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\r\nimport torch\r\nfrom transformers import BitsAndBytesConfig\r\nfrom llama_index.core.prompts import Prom",
          "created_at": "2024-07-13T11:07:34Z"
        },
        {
          "author": "dhuynh95",
          "body": "That's great! I will have a look. How good are performances?",
          "created_at": "2024-07-13T11:17:32Z"
        },
        {
          "author": "catyung",
          "body": "As discussed previously, the world model needs to have strong reasoning capability in order to give \"instruction\" to the action engine. \r\n\r\nThe major problem is on Phi-3-vision as the world model, for sure, its not comparable to GPT-4o to understand complicated prompt instruction and reasoning, henc",
          "created_at": "2024-07-13T13:05:39Z"
        },
        {
          "author": "VKumar555",
          "body": "Hi @catyung , could you please share the requirements.txt file to resolve all the dependencies to get this code work on my local",
          "created_at": "2024-09-13T10:22:00Z"
        }
      ]
    },
    {
      "issue_number": 433,
      "title": "Add documentation for latest features",
      "body": "- [x] Document SQLite logs usage\r\n- [x] Document token count feature\r\n- [x] Document cost estimation feature\r\n- [x] Create a matrix of supported features per driver\r\n- [x] WebAgent#run(step_by_step=True) and WebAgent#run_step methods to debug single step\r\n- [x] Selenium driver tool to highlight elements ",
      "state": "closed",
      "author": "adeprez",
      "author_type": "User",
      "created_at": "2024-07-11T10:59:07Z",
      "updated_at": "2024-09-05T14:31:35Z",
      "closed_at": "2024-07-22T12:24:13Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/433/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "paulpalmieri"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/433",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/433",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:26.101714",
      "comments": [
        {
          "author": "paulpalmieri",
          "body": "A few notes: \r\n- SQLite docs is ready, waiting for PR merge to fix a bug before\r\n- Token count and cost seems broken: https://github.com/run-llama/llama_index/issues/13146 we get weird results like 0 embedding_tokens and 0.11 llm_completitions_token",
          "created_at": "2024-07-12T15:49:41Z"
        },
        {
          "author": "dhuynh95",
          "body": "@paulpalmieri we no longer use embeddings for the retriever for Navigation, we do use it if we search for information with the current text of the page.\r\nThe LLM completion tokens being 0.11 is an issue though",
          "created_at": "2024-07-13T06:45:24Z"
        },
        {
          "author": "paulpalmieri",
          "body": "llm_completions_token issue fixed by #439 ",
          "created_at": "2024-07-15T09:06:56Z"
        },
        {
          "author": "paulpalmieri",
          "body": "For documenting the new debug features. \r\n<img width=\"1216\" alt=\"image\" src=\"https://github.com/user-attachments/assets/fa087b67-1785-4efd-a28c-f6be05104c1b\">\r\n\r\nhttps://github.com/lavague-ai/LaVague/pull/443\r\n",
          "created_at": "2024-07-15T15:23:08Z"
        },
        {
          "author": "timreddick-8451",
          "body": "@paulpalmieri\r\n\r\n![image](https://github.com/user-attachments/assets/56fbd151-5d58-4b24-94b6-fe28497ded9f)\r\n![image](https://github.com/user-attachments/assets/9a9b2ac9-d5eb-42d7-b022-d268cdb269ce)\r\n\r\nI'm running lavague-core==0.2.35. Seems there is no step-by-step keyword when initializing WebAgent",
          "created_at": "2024-09-05T12:19:43Z"
        }
      ]
    },
    {
      "issue_number": 469,
      "title": "Waterfall chart to understand Agent bottleneck latency issues",
      "body": "We provide logs in our agents through the `agent.logger` that can be used after each run but it can be hard to read the CSV we get from `agent.logger.return_pandas()`\r\n\r\nCould be cool to have some waterfall graph like this \r\n![image](https://github.com/user-attachments/assets/6775d297-a2e0-4d80-9f09-07395546a564)\r\n\r\nbut instead we see the time it takes on each step, and the decomposition (World model, rephrase, retriever, LLM, etc.).\r\n\r\nMaybe we could have something like `agent.logger.plot()` to do that",
      "state": "closed",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-07-24T04:17:30Z",
      "updated_at": "2024-08-27T12:22:06Z",
      "closed_at": "2024-08-27T12:22:06Z",
      "labels": [
        "new feature",
        "AI-performance"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/469/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "paulpalmieri"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/469",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/469",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:26.325341",
      "comments": [
        {
          "author": "paulpalmieri",
          "body": "@dhuynh95 agent-ops does that https://docs.agentops.ai/v1/usage/dashboard-info",
          "created_at": "2024-07-24T08:05:04Z"
        },
        {
          "author": "lyie28",
          "body": "@jashuajoy What do you think of this idea? Would you be interested in working on this since you know our logger system pretty well :)",
          "created_at": "2024-07-24T08:10:24Z"
        },
        {
          "author": "jashuajoy",
          "body": "@lyie28 I can implement this. I guess 'world_model_inference_time' can be utilized for this.",
          "created_at": "2024-07-25T03:28:50Z"
        },
        {
          "author": "paulpalmieri",
          "body": "@jashuajoy I'll take this issue as we are prioritising observability at the moment. ",
          "created_at": "2024-08-19T12:01:11Z"
        },
        {
          "author": "paulpalmieri",
          "body": "@adeprez @dhuynh95 agent-ops provides waterfall chats out of the box. It's free for 1,000 events per month. \r\n\r\nWhat do you want in terms of UX ? \r\n\r\nWe could attempt to activate it by default if an agentops API key is detected in the env ? This way we don't add yet another parameter to the agent.\r\n",
          "created_at": "2024-08-19T12:07:06Z"
        }
      ]
    },
    {
      "issue_number": 588,
      "title": "Handle where max tokens exceeded in Python Engine / Python Engine with default OpenAI LLM",
      "body": "If we extract a large text section with an LLM which doesn't have a big enough max tokens - it results in a un-extractable JSON object in response. We should find the best way to handle this so we can still get a confidence score and also get as much of the text as possible - while avoiding an extraction error:\r\n\r\nhttps://github.com/lavague-ai/LaVague/actions/runs/10564929524/job/29268391288\r\n\r\nI tested the Python Engine with Gemini: https://github.com/lavague-ai/LaVague/blob/main/examples/notebooks/lavague-tests-comaprison.ipynb - but we need to make sure it is robust with the OpenAI default LLM.\r\n\r\n\r\n\r\n",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-08-26T18:58:39Z",
      "updated_at": "2024-08-27T10:42:29Z",
      "closed_at": "2024-08-27T10:42:29Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/588/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "adeprez"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/588",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/588",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:26.544583",
      "comments": []
    },
    {
      "issue_number": 560,
      "title": "Add log_to_db option to `demo()`",
      "body": "The Agent `log_to_db` option was added to `run()` but not to `demo()` - I suggest we replicate the `log_to_db` option for `demo()`",
      "state": "open",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-08-08T09:03:43Z",
      "updated_at": "2024-08-22T03:09:18Z",
      "closed_at": null,
      "labels": [
        "help wanted",
        "good first issue"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/560/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/560",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/560",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:26.544609",
      "comments": [
        {
          "author": "phershbe",
          "body": "I would like to work on this if you are open to a new contributor.\r\n\r\nI am really inexperienced, but I would assume that it is the same option where you check `log_to_db: bool = is_flag_true(\"LAVAGUE_LOG_TO_DB\")` and then call `insert_logs()` from `LocalDBLogger()` at the end of the function if it i",
          "created_at": "2024-08-10T04:43:58Z"
        },
        {
          "author": "lyie28",
          "body": "Yes, exactly. And then just test locally that this works as expected by installing the package from local (pip install -e ./lavague-core). You can refer to the docs on the SQLite logger to see how to check the dB logs: https://docs.lavague.ai/en/latest/docs/module-guides/local-log/",
          "created_at": "2024-08-13T08:47:29Z"
        },
        {
          "author": "lyie28",
          "body": "@phershbe feel free to ping me on Discord if you have any questions/issues while working on it - lyie7069",
          "created_at": "2024-08-13T09:00:28Z"
        },
        {
          "author": "phershbe",
          "body": "@lyie28 I added you on Discord. I got the environment set up: I cloned the repository, got an Open AI api key, upgraded the account so that it could use GPT-4o, set up the virtual environment using `Poetry`, and got `run()` to create a `db` file by passing in `log_to_db=True` as a parameter.\r\n\r\nI go",
          "created_at": "2024-08-22T03:09:17Z"
        }
      ]
    },
    {
      "issue_number": 575,
      "title": "Agent should not destroy the driver upon run completion",
      "body": "Therefore this line should be removed:\r\n\r\nhttps://github.com/lavague-ai/LaVague/blob/7d6a3d37ac8ed639410780c21e64872048fd84f9/lavague-core/lavague/core/agents.py#L523C13-L523C34\r\n\r\nIt might impact `BrowserbaseRemoteConnection` ; make sure when using it that driver is properly destroyed afterwards.",
      "state": "closed",
      "author": "adeprez",
      "author_type": "User",
      "created_at": "2024-08-19T14:28:22Z",
      "updated_at": "2024-08-19T16:14:10Z",
      "closed_at": "2024-08-19T16:14:10Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/575/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "paulpalmieri"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/575",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/575",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:26.735742",
      "comments": []
    },
    {
      "issue_number": 529,
      "title": "add `origin` to telemetry to better measure usage",
      "body": "As we launch different tools like Gradio or `lavague-qa` CLI, we should measure usage of those interfaces with LaVague. \r\n\r\n- add `origin` to WebAgent and telemetry\r\n- default: \"default\"\r\n\r\nThen we can start WebAgent with `WebAgent(origin=\"lavague-qa\")` or `WebAgent(origin=\"gradio\")`\r\n\r\nThis won't give us complete observability of LaVague QA (because it continues beyond agents) but will atleast measure basic usage of the tool. \r\n\r\n@adeprez what do you think ? ",
      "state": "closed",
      "author": "paulpalmieri",
      "author_type": "User",
      "created_at": "2024-08-02T09:19:00Z",
      "updated_at": "2024-08-19T12:53:35Z",
      "closed_at": "2024-08-19T12:53:34Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/529/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/529",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/529",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:26.735761",
      "comments": [
        {
          "author": "paulpalmieri",
          "body": "#543 ",
          "created_at": "2024-08-19T12:53:34Z"
        }
      ]
    },
    {
      "issue_number": 414,
      "title": "Add tooling to record, replay and step in agent runs",
      "body": "It is sometimes necessary to stop an agent and step in to provide guidance. There is little tooling yet to facilitate that. One might also want to replay an agent run up to a point, and modify it.\r\n\r\nI see the following features to be developed to enable it:\r\n- [ ] Register agent steps in an execution graph\r\n- [ ] Provide tooling to replay the graph up to a point / fully. We could replay it without any LLM call if all navigation steps perform correctly, but if we observe a failure in navigation, we could call the `NavigationEngine` to step in and heal the pipeline\r\n- [ ] Provide tools for users to step in to help the agent\r\n\r\nRegarding the user provided assistance to the agent, we want something:\r\n- **Easy for users to do**. For instance either providing a prompt themselves to the `NavigationEngine` or just doing the action and we record before action, the action, and after, and deduce what the intent was and generate an example (or several) until this step is taken properly (intent classification and example generation can be done by LLMs)\r\n- **Boost performance long term**.  As mentioned before, we could create observations based on this help and add that to the `WorldModel` knowledge with `world_model.add_knowledge`",
      "state": "open",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-07-07T05:46:11Z",
      "updated_at": "2024-08-15T13:26:08Z",
      "closed_at": null,
      "labels": [
        "new feature",
        "Agent",
        "HighPrio"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/414/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "adeprez"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/414",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/414",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:26.921321",
      "comments": []
    },
    {
      "issue_number": 413,
      "title": "Create datasets of static pages with Single File for static evaluation of websites",
      "body": "Current evaluation data for static actions, aka checking if instruction (e.g. \"Click on X\") actually produced the right action (e.g. Selenium code) do not contain all the HTML required to well render the page for later evaluation.\r\nThey mostly contain part of the HTML, but not the CSS and JS to render the page in a fully offline manner for reproducibility.\r\n\r\nWe can see that on [Mind2web ](https://huggingface.co/datasets/osunlp/Mind2Web?row=0)or on [TheWave](https://huggingface.co/datasets/BigAction/the-wave-250), which is data we collected from telemetry, because we simply used `driver.page_source`.\r\n\r\n![image](https://github.com/lavague-ai/LaVague/assets/36925557/049a67a5-1eb0-4a75-9777-643054191f05)\r\n\r\nBecause we don't properly gather everything, some metrics, such as Intersection over Union, cannot be used, to compare the ground truth element to interact with, and the element the Action Model identifies.\r\n\r\nWe could however use tools [Single File CLI](https://github.com/gildas-lormeau/single-file-cli) to automatically condense all the information of a page into a single file for later reproducible testing.\r\n\r\nThis could be helpful for us to collect large scale evaluation data where we can evaluate an Agent that interacts on the DOM and/or vision to take action, but also help users collect their own evaluation data for their use case to see if their Agent is able to perform well.\r\n\r\nHow to do it: [Single File](https://github.com/gildas-lormeau/SingleFile) could be used in a Chrome with extension activated and we call the API of Single FIle using CDP. Here are [OpenAI two cents on the topic](https://chatgpt.com/share/9635382f-c1e4-48bc-952f-ef1aabfd147b).\r\n\r\nWe could just call Single File and add it to the logs:\r\n\r\n```python\r\nfrom seleniumwire import webdriver\r\nfrom selenium.webdriver.chrome.service import Service\r\nfrom webdriver_manager.chrome import ChromeDriverManager\r\nimport time\r\n\r\n# Path to the unpacked Chrome extension\r\nextension_path = '/path/to/unpacked/extension'\r\n\r\n# Set up Chrome options to load the extension\r\nchrome_options = webdriver.ChromeOptions()\r\nchrome_options.add_argument(f'--load-extension={extension_path}')\r\n\r\n# Initialize the Chrome driver with Selenium Wire\r\ndriver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\r\n\r\n# Wait for the extension to load properly\r\ntime.sleep(5)\r\n\r\n# Example: Call a function from the extension's background script and get the result\r\ntry:\r\n    # Execute a script that sends a message to the extension and gets a response\r\n    output = driver.execute_script(\"\"\"\r\n        return new Promise((resolve) => {\r\n            chrome.runtime.sendMessage({greeting: 'hello'}, function(response) {\r\n                resolve(response);\r\n            });\r\n        });\r\n    \"\"\")\r\n    # Print the output\r\n    print('Response from extension:', output)\r\nexcept Exception as e:\r\n    print(\"An error occurred:\", e)\r\n\r\n# Close the driver\r\ndriver.quit()\r\n\r\n```",
      "state": "closed",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-07-06T13:48:25Z",
      "updated_at": "2024-08-15T13:23:55Z",
      "closed_at": "2024-08-15T13:23:55Z",
      "labels": [
        "Datasets"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/413/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "mbrunel"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/413",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/413",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:26.921339",
      "comments": []
    },
    {
      "issue_number": 538,
      "title": "Create Browserbase integration",
      "body": "We'd like to have an easy integration with browserbase. A code example is provided here: https://docs.lavague.ai/en/latest/docs/examples/medical_appointment_booking/",
      "state": "closed",
      "author": "adeprez",
      "author_type": "User",
      "created_at": "2024-08-05T08:48:07Z",
      "updated_at": "2024-08-15T13:23:08Z",
      "closed_at": "2024-08-15T13:23:08Z",
      "labels": [
        "Integrations"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/538/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "paulpalmieri"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/538",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/538",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:26.921346",
      "comments": [
        {
          "author": "paulpalmieri",
          "body": "A few questions: \r\n- Do we want this to work with the playwright driver ?\r\n- We could make it a argument to the driver like so (provided the user has set an api key. What do you think ?\r\n```py\r\nselenium_driver = SeleniumDriver(browserbase=True)\r\n```",
          "created_at": "2024-08-06T09:02:15Z"
        },
        {
          "author": "adeprez",
          "body": "It can be done with playwright too: https://docs.browserbase.com/quickstart/playwright\r\n\r\nWe can accept a new `remote_connection` argument of type `selenium.webdriver.remote.remote_connection.RemoteConnection`, then provide and document an implementation for BrowserbaseRemoteConnection.\r\n\r\n`Browserb",
          "created_at": "2024-08-06T09:16:37Z"
        },
        {
          "author": "paulpalmieri",
          "body": "@adeprez What's the purpose of the following code in the driver init: \r\n\r\n```py\r\nself.driver.execute_cdp_cmd(\r\n    \"Page.addScriptToEvaluateOnNewDocument\",\r\n    {\"source\": JS_SETUP_GET_EVENTS},\r\n)\r\n```\r\n\r\nSeems like `the webdriver.Remote` doesn't support this and browserbase can't start if it's run ",
          "created_at": "2024-08-06T10:39:18Z"
        },
        {
          "author": "paulpalmieri",
          "body": "@adeprez added a basic implementation for `SeleniumDriver` on `538-browserbase-integration`\r\n\r\nAs I understand we should reuse the following Browserbase code for Playwright\r\n```py\r\ndef create_session():\r\n    url = 'https://www.browserbase.com/v1/sessions'\r\n    headers = {'Content-Type': 'application",
          "created_at": "2024-08-06T11:04:26Z"
        },
        {
          "author": "adeprez",
          "body": "> @adeprez What's the purpose of the following code in the driver init:\r\n> \r\n> ```python\r\n> self.driver.execute_cdp_cmd(\r\n>     \"Page.addScriptToEvaluateOnNewDocument\",\r\n>     {\"source\": JS_SETUP_GET_EVENTS},\r\n> )\r\n> ```\r\n> \r\n> Seems like `the webdriver.Remote` doesn't support this and browserbase c",
          "created_at": "2024-08-06T12:18:24Z"
        }
      ]
    },
    {
      "issue_number": 447,
      "title": "Enhance University Form-Filling Process with Conversational AI",
      "body": "We face challenges with students providing incorrect or incomplete information in forms, leading to delays and inaccuracies. Following up manually is inefficient and frustrating.\r\n\r\n\r\nIntegrate a conversational AI interface for real-time interaction. The AI should prompt students for missing or incorrect details, allowing changes directly in the conversation. It should use an LLM to understand natural language, update fields, validate information, and provide feedback.\r\n\r\n\r\nWe considered sending follow-up emails or messages, but this is time-consuming and lacks immediate feedback. Strict validation checks within the form also don't offer a conversational, interactive experience.\r\n\r\nAdditional context\r\n\r\nA student enters an incorrect date of birth (e.g., \"31/02/2000\").\r\nThe AI prompts: \"The date of birth you entered seems incorrect. Could you provide the correct date?\"\r\nStudent responds: \"It's 28/02/2000.\"\r\nAI updates: \"Thank you! I've updated your date of birth to 28/02/2000.\"\r\nFor missing phone number: \"Could you provide your contact number?\"\r\nStudent: \"Sure, it's 555-123-4567.\"\r\nAI updates: \"Great, I've added your phone number as 555-123-4567.\"",
      "state": "open",
      "author": "kevin4801",
      "author_type": "User",
      "created_at": "2024-07-16T16:24:38Z",
      "updated_at": "2024-08-14T09:17:16Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "help wanted",
        "community-assigned"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 10,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/447/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/447",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/447",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:27.159365",
      "comments": [
        {
          "author": "ChaikhiBelaid",
          "body": "@kevin4801 Hello, I can work on this feature. I have similar experience working on this type of project. ",
          "created_at": "2024-07-19T09:53:04Z"
        },
        {
          "author": "lyie28",
          "body": "@adeprez This is the same idea as #445 - do you want to discuss with @ChaikhiBelaid about this :)",
          "created_at": "2024-07-22T13:49:32Z"
        },
        {
          "author": "lyie28",
          "body": "@ChaikhiBelaid If you'd like to take a look at this, we would probably recommend implementing this as an optional additional engine. How the agent asks for additional data could be extensive & require many integrations - so can grow and involve many contributors\r\n\r\nDo you want to discuss further on ",
          "created_at": "2024-07-22T14:14:16Z"
        },
        {
          "author": "kevin4801",
          "body": "Hello, Iâ€™m interested in working on this feature for my startup. I have relevant experience and am excited about the potential for collaboration. Let's work together to build this.\r\n\r\n@lyie28 @ChaikhiBelaid @adeprez \r\n\r\n",
          "created_at": "2024-07-22T15:53:13Z"
        },
        {
          "author": "ChaikhiBelaid",
          "body": "Hello, Yes of corse I am excited to work on such a feature together. \r\n@lyie28 @kevin4801 @adeprez ",
          "created_at": "2024-07-22T16:02:51Z"
        }
      ]
    },
    {
      "issue_number": 557,
      "title": "Gradio in Colab error: `PIL.UnidentifiedImageError: cannot identify image file '/tmp/gradio/[folder_name]/image.webp'`",
      "body": "When using `agent.demo()` in Google Colab with the following example I get the following error which comes from Gradio.\r\n\r\nThis seems to come from Gradio saving a temp file in webp format when calling `preprocess()` which is causing a bug in Colab only.\r\n\r\nI have tried playing with the format & filepath options for gr.Image() to avoid using the webp format but so far the file is still generated in `webp` so this still needs to be looked at further.\r\n\r\n```\r\nfrom llama_index.llms.gemini import Gemini\r\nfrom llama_index.multi_modal_llms.gemini import GeminiMultiModal\r\nfrom llama_index.llms.mistralai import MistralAI\r\nfrom lavague.core import WorldModel, ActionEngine\r\nfrom lavague.core.agents import WebAgent\r\nfrom lavague.core.context import Context\r\nfrom lavague.drivers.selenium import SeleniumDriver\r\nfrom llama_index.embeddings.huggingface import HuggingFaceEmbedding\r\nfrom llama_index.core import Settings\r\n\r\nimport os\r\nfrom google.colab import userdata\r\napi_key = userdata.get('GOOGLE_API_KEY')\r\nos.environ[\"HF_TOKEN\"] = userdata.get('HF_TOKEN')\r\n\r\nllm = Gemini(model_name=\"models/gemini-1.5-flash\", api_key=api_key)\r\nmm_llm =  GeminiMultiModal(model_name=\"models/gemini-1.5-pro\", api_key=api_key)\r\nSettings.embed_model = HuggingFaceEmbedding(\r\n    model_name=\"BAAI/bge-small-en-v1.5\"\r\n)\r\nembedding = Settings.embed_model\r\n\r\ncontext = Context(llm, mm_llm, embedding)\r\n\r\n# Initialize the Selenium driver\r\nselenium_driver = SeleniumDriver()\r\n\r\n# Initialize a WorldModel and ActionEnginem passing them the custom context\r\nworld_model = WorldModel.from_context(context)\r\naction_engine = ActionEngine.from_context(context, selenium_driver)\r\n\r\n# Create your agent\r\nagent = WebAgent(world_model, action_engine)\r\n\r\nagent.get(\"https://docs.google.com/forms/d/e/1FAIpQLSdv5N6nzvmTSu2aJ-B1Li2DWgiC5VICy2keWP28gaR0qM3hZg/viewform?usp=pp_url\")\r\n\r\n\r\ninstruction = \"\"\"\r\nWrite Hello in the message box\r\n\"\"\"\r\n\r\nagent.demo(objective=instruction)\r\n```",
      "state": "open",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-08-07T16:43:18Z",
      "updated_at": "2024-08-07T16:43:25Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/557/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/557",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/557",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:27.420109",
      "comments": []
    },
    {
      "issue_number": 546,
      "title": "CLI option to plug `lavague-qa` into existing brower session",
      "body": "- [ ] Update CLI `lavague-qa/lavague/qa/cli.py` to accept `chrome_debugger_address` and `chrome_user_data_dir`\r\n- [ ] Update `lavague-qa/lavague/qa/generator.py` to use the `user_data_dir` and `options`\r\n- [ ] Add documentation for these new options\r\n\r\n```python\r\ndef _run_lavague_agent(self):\r\n        selenium_driver = SeleniumDriver(headless=self.headless, user_data_dir=self.user_data_dir, options=self.options)\r\n```",
      "state": "open",
      "author": "adeprez",
      "author_type": "User",
      "created_at": "2024-08-06T16:28:36Z",
      "updated_at": "2024-08-06T16:29:46Z",
      "closed_at": null,
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/546/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/546",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/546",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:29.099855",
      "comments": []
    },
    {
      "issue_number": 523,
      "title": "Handle navigation engine failure",
      "body": "Navigation engine often fail with generic error messages, such as \"Element not found\" when the retrieval is failing.\r\n\r\nWe'd like to have more precise errors raised so we can backtrack through the retrieval pipeline and adjust parameters.\r\n\r\nFAIL action is too generic. We can identity 3 kinds of failure :\r\n- The provided elements are ambiguous (LLM) ;\r\n- There is no element matching the request (LLM) ;\r\n- The xpath was hallucinated (LLM output check).\r\n\r\nEach case must raise a different error with a common NavigationError superclass.",
      "state": "closed",
      "author": "adeprez",
      "author_type": "User",
      "created_at": "2024-08-01T09:12:41Z",
      "updated_at": "2024-08-06T12:27:32Z",
      "closed_at": "2024-08-06T12:27:32Z",
      "labels": [
        "enhancement",
        "ActionEngine"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/523/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "adeprez"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/523",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/523",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:29.099880",
      "comments": []
    },
    {
      "issue_number": 530,
      "title": "Prevent BACK command if it would lead to blank page",
      "body": "We should raise an error if BACK command would lead to blank page.\r\n\r\nMake sure an observation is made so the World Model is aware he cannot go back anymore.",
      "state": "closed",
      "author": "adeprez",
      "author_type": "User",
      "created_at": "2024-08-02T11:09:33Z",
      "updated_at": "2024-08-02T12:19:53Z",
      "closed_at": "2024-08-02T12:19:53Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/530/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "adeprez"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/530",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/530",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:29.099894",
      "comments": []
    },
    {
      "issue_number": 473,
      "title": "\"BACK\" navigation control instruction used on first step leading to crash",
      "body": "I had a dumb bug where the World Model couldn't find the information it wanted so it tried to go back straight away which caused LaVague to crash - I think because it was the first step so it couldn't go back. \r\n\r\nMaybe we can add a protection so it won't crash if the back fails but continues",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-07-24T14:21:43Z",
      "updated_at": "2024-08-01T10:30:07Z",
      "closed_at": "2024-08-01T10:30:07Z",
      "labels": [
        "bug",
        "help wanted",
        "good first issue"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/473/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "adeprez"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/473",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/473",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:29.099899",
      "comments": [
        {
          "author": "lyie28",
          "body": "I had another crash related to the BACK command today in a different context @adeprez - haven't had time to debug yet.\r\n\r\n```\r\nNext engine: Navigation Controls\r\nInstruction: BACK\r\n2024-07-25 15:39:33,846 - ERROR - Error while running the agent: Message: unknown error: unhandled inspector error: {\"co",
          "created_at": "2024-07-25T13:41:14Z"
        },
        {
          "author": "lyie28",
          "body": "This is also a common error I & another user have seen with BACK the past few days @adeprez \r\n\r\n```\r\nNext engine: Navigation Controls\r\nInstruction: BACK\r\n2024-07-30 09:46:20,493 - ERROR - Error while running the agent: 'NoneType' object has no attribute 'replace'\r\n```",
          "created_at": "2024-07-30T08:21:45Z"
        },
        {
          "author": "lyie28",
          "body": "I think this last error happens when we go BACK but we never navigated to another page, we then call `get_obs` which calls `get_current_screenshot` which will run: \r\n\r\n```python\r\ncurrent_url = url.replace(\"://\", \"_\").replace(\"/\", \"_\")\r\n                  ^^^^^^^^^^^\r\nAttributeError: 'NoneType' object",
          "created_at": "2024-07-31T10:42:52Z"
        }
      ]
    },
    {
      "issue_number": 474,
      "title": "Feature suggestion: Add LAVAGUE_LOG_TO_DB environment variable for automatic logging to db without need for option",
      "body": "@adeprez @jashuajoy @mbrunel Maybe it is a bit annoying to have to set log_to_db to true each time if you always want to log to DB, so what would you think of adding an environment variable or config file in a default location or something like this where we can set it to true permanently if we like?",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-07-24T14:25:13Z",
      "updated_at": "2024-07-31T14:43:38Z",
      "closed_at": "2024-07-31T14:43:38Z",
      "labels": [
        "enhancement",
        "community-assigned"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/474/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/474",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/474",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:29.307595",
      "comments": [
        {
          "author": "adeprez",
          "body": "Good idea, the default value could come from an env variable\r\n\r\nSomething like\r\n```python\r\nlog_to_db: bool = os.getenv(\"LAVAGUE_LOG_TO_DB\", \"False\") in (\"true\", \"1\", \"y\", \"yes\")\r\n```",
          "created_at": "2024-07-24T14:59:42Z"
        },
        {
          "author": "jashuajoy",
          "body": "@lyie28 Good idea, will implement this.",
          "created_at": "2024-07-25T04:31:02Z"
        },
        {
          "author": "paulpalmieri",
          "body": "@jashuajoy FYI I've made a few changes to the DB log logic following your initial implementation: https://github.com/lavague-ai/LaVague/commit/772357f4f3dcb28969f3edd3252974de418f1722\r\n",
          "created_at": "2024-07-25T08:47:50Z"
        },
        {
          "author": "jashuajoy",
          "body": "@lyie28 opened pull request #486",
          "created_at": "2024-07-26T15:50:36Z"
        },
        {
          "author": "paulpalmieri",
          "body": "What about keeping the argument in `Agent.run()` ? \r\nWould could check the presence of the argument and if it's not here, look at the env variable.\r\n\r\nSometimes I want to turn on/off logging momentarily and having to change an env variable would be cumbersome.\r\n\r\nAlso we might need to check the docs",
          "created_at": "2024-07-26T15:55:53Z"
        }
      ]
    },
    {
      "issue_number": 432,
      "title": "Validate LLM output",
      "body": "Object structures extracted from LLM outputs cannot be 100% trusted. Therefore, they must be validated before being handed over to engines.\r\n\r\n- [ ] Define a validator for LLM output\r\n- [ ] Raise an error when extraction doesn't match the expected shape",
      "state": "closed",
      "author": "adeprez",
      "author_type": "User",
      "created_at": "2024-07-11T10:54:40Z",
      "updated_at": "2024-07-31T08:06:41Z",
      "closed_at": "2024-07-31T08:06:41Z",
      "labels": [
        "good first issue",
        "ActionEngine"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/432/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/432",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/432",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:29.539296",
      "comments": [
        {
          "author": "Apetun",
          "body": "Hey! I would like to help with this. Can you help me with how to get started?",
          "created_at": "2024-07-11T14:23:43Z"
        },
        {
          "author": "dhuynh95",
          "body": "Thanks @Apetun for the help! \r\n\r\nIt might be overkill and different/complementary to what @adeprez proposed, but one way would be to add a small open-LLM, like Phi-3, with [outlines ](https://github.com/outlines-dev/outlines) to ensure a specific format. It is heavy though to use, so I don't know if",
          "created_at": "2024-07-11T15:30:30Z"
        },
        {
          "author": "dhuynh95",
          "body": "Maybe what I just mentioned should in another issue, and @adeprez you present what you had in mind? ^^",
          "created_at": "2024-07-11T15:30:51Z"
        },
        {
          "author": "adeprez",
          "body": "Thank you, Apetun!\r\n\r\nThis task focuses on ensuring that the action returned by the extractor has the correct format, rather than addressing the model output itself.\r\n\r\nIn the navigation engine, we extract the JSON code block from the LLM output to determine the appropriate action. We currently take",
          "created_at": "2024-07-11T16:23:18Z"
        },
        {
          "author": "Apetun",
          "body": "Thank you for the clarification. I will look into it.",
          "created_at": "2024-07-11T17:13:52Z"
        }
      ]
    },
    {
      "issue_number": 513,
      "title": "Unify Navigation Controls and Navigation Engine action representation for better replay",
      "body": "We have introduced safe navigation where the Navigation Engine outputs a specific Navigation control with the right arguments, something like {\"action\": \"click\", \"XPath\": \"...\"} and we then call the proper pre-defined function to execute the action.\r\n\r\nThis enables easy replay of actions as well.\r\n\r\nSo for instance, here is what logs of the Navigation Engine look like:\r\n\r\n![image](https://github.com/user-attachments/assets/f00566b7-3abc-4e87-9371-079be34b4d0a)\r\n\r\nHowever, the Navigation Controls outputs action in a different format \r\n\r\n![image](https://github.com/user-attachments/assets/01195406-de45-4c20-87cf-d5cdc752f655)\r\n\r\n![image](https://github.com/user-attachments/assets/4f8b0b4c-678b-4e97-8eee-89ced36118cc)\r\n\r\nIt would be great if we could have the Navigation Controls output things in a compatible manner with the Navigation Engine, so that we have a unified way to execute and replay trajectories\r\n",
      "state": "open",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-07-31T07:00:34Z",
      "updated_at": "2024-07-31T07:00:35Z",
      "closed_at": null,
      "labels": [
        "help wanted",
        "good first issue",
        "ActionEngine"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/513/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/513",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/513",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:29.763495",
      "comments": []
    },
    {
      "issue_number": 487,
      "title": "Add more detailed token consumption output to `lavague-tests`",
      "body": "In order to do more detailed benchmarks and comparison, having more details than just the total number of consumed tokens would be helpful. \r\n\r\nIdeally a breakdown by input/output tokens with the type of llms, show the name of the models used as well. \r\n\r\n```\r\nsuccess rate (%)\r\ninput | output\r\nllm\r\nmm_llm\r\nembedding\r\n```",
      "state": "closed",
      "author": "paulpalmieri",
      "author_type": "User",
      "created_at": "2024-07-26T16:25:19Z",
      "updated_at": "2024-07-30T13:14:56Z",
      "closed_at": "2024-07-30T13:14:56Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/487/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "paulpalmieri"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/487",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/487",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:29.763522",
      "comments": []
    },
    {
      "issue_number": 402,
      "title": "Wait for action completion",
      "body": "When the navigation engine performs some action, there is usually a delay before the page enters a stable state. It can be due to heavy DOM changes, animations or network processing. We want to wait for action completion.\r\n- [ ] Using MutationObserver, wait for the DOM to become stable\r\n- [ ] Wait for network to become idle\r\n\r\n[perform action request] -> register observer for DOM changes + register observer for network -> perform actual action -> wait until (DOM stop emitting changes and network requests completion) or timeout reached -> [complete]",
      "state": "closed",
      "author": "adeprez",
      "author_type": "User",
      "created_at": "2024-07-02T15:28:41Z",
      "updated_at": "2024-07-30T13:03:00Z",
      "closed_at": "2024-07-30T13:03:00Z",
      "labels": [
        "enhancement",
        "ActionEngine",
        "Driver"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/402/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "adeprez"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/402",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/402",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:29.763533",
      "comments": []
    },
    {
      "issue_number": 504,
      "title": "lavague-test feature request to be able to specify X number of sites",
      "body": "It is a bit limiting to be able to only run one specified site with --site OR all sites in sites.\r\n\r\nI would like to see either a --n_tests argument which allows you to say, let's run 5 tests for example. This could be particularly useful if we add many tests into sites as people may or may not want to run all the tests.\r\n\r\nWhile you can specify one site with --site, you can't specify multiple, so it's a bit limiting.",
      "state": "open",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-07-30T07:54:21Z",
      "updated_at": "2024-07-30T09:29:22Z",
      "closed_at": null,
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/504/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/504",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/504",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:29.763541",
      "comments": [
        {
          "author": "adeprez",
          "body": "`--site` argument can be repeated so you can test multiple sites:\r\n\r\n```\r\nlavague-test -s examples -s hugginface.co -s reddit.com\r\n```\r\n\r\nHaving an additional --n_tests to automatically pick sites is feasible too if you think it's relevant. In this case would you expect `lavague-test` to pick `n` we",
          "created_at": "2024-07-30T09:17:52Z"
        },
        {
          "author": "lyie28",
          "body": "Ah, yes! I forgot to repeat the `-s` - I think it could still be interesting to have a `--n_tests` as the number of site examples grows to avoid having to write out X number of tests.\r\n\r\nGood question - I think the deterministic approach is preferable for comparisons.",
          "created_at": "2024-07-30T09:29:20Z"
        }
      ]
    },
    {
      "issue_number": 502,
      "title": "Retry when structured LLM output is invalid",
      "body": "When we expect some structured output and the LLM fails to generate it, we should retry a few times to give it a chance to succeed. For instance it happens for yaml action list generation.",
      "state": "open",
      "author": "adeprez",
      "author_type": "User",
      "created_at": "2024-07-29T15:28:36Z",
      "updated_at": "2024-07-29T16:18:10Z",
      "closed_at": null,
      "labels": [
        "ActionEngine"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/502/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/502",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/502",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:29.967291",
      "comments": [
        {
          "author": "lyie28",
          "body": "I had this bug with this command:\r\n```bash\r\nlavague-test -c lavague-tests/contexts/anthropic_context.py -s nytimes.com\r\n```\r\n\r\nAnd also within the docs CI - when running:\r\n```bash\r\npython .github/extract-python-code.py docs/docs/use-cases/forms.md\r\npython extracted_code_forms.py\r\n```",
          "created_at": "2024-07-29T16:17:52Z"
        }
      ]
    },
    {
      "issue_number": 496,
      "title": "Pricing ambiguity for same model names from different providers in TokenCounter",
      "body": "I think as we add more models to our built-in pricing info, we will have some issues between how we know the pricing of a model name that is provided by two different providers with different pricing as sometimes the model name/tag is exactly the same. For example, we may need to know if we should use pricing from OpenAI or Azure for the model name 'gpt4-o'\r\n\r\nIt might also be better if instead of hardcoding our own list of pricing, we could integrate more directly the Lite-llm dict: https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json so we can fetch pricing from here -> this could also help resolve the ambiguity issue\r\n\r\n@paulpalmieri @adeprez ",
      "state": "open",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-07-29T10:36:08Z",
      "updated_at": "2024-07-29T11:56:47Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "help wanted",
        "good first issue"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/496/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/496",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/496",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:30.201719",
      "comments": [
        {
          "author": "paulpalmieri",
          "body": "Agreed, here are some other improvements that could lead to better token cost estimations\r\n- Use more precise tokenizers instead of a [default one for everything ](https://github.com/lavague-ai/LaVague/blob/5147bfd3504eaa6808afa42c39f738440f53fa39/lavague-core/lavague/core/token_counter.py#L29)\r\n   ",
          "created_at": "2024-07-29T11:47:24Z"
        }
      ]
    },
    {
      "issue_number": 465,
      "title": "TokenCounter only supports OpenAI models",
      "body": "### Context\r\n\r\n- To listen to API calls and count tokens we use `TokenCountingHandler` from `llama-index`\r\n- `TokenCountingHandler` class requires a `tokenizer`. \r\n- We currently use `tiktoken` as our only tokenizer. \r\n- `tiktoken` only supports OpenAI models. \r\n\r\n### Impact\r\n- All token counting and cost estimation is currently limited to OpenAI models supported by both `tiktoken` and `llama-index`\r\n\r\n### Notes\r\n- There seem to be no general purpose tokenizers out there. \r\n- There is `vertexai.preview.tokenization` for Gemini\r\n\r\n### Potential solutions\r\n- Let user define the `tokenizer`\r\n    - Only the following models are supported `Supported models: gemini-1.0-pro-001, gemini-1.0-pro-002, gemini-1.5-pro-001, gemini-1.5-flash-001.`\r\n",
      "state": "closed",
      "author": "paulpalmieri",
      "author_type": "User",
      "created_at": "2024-07-22T15:37:33Z",
      "updated_at": "2024-07-29T11:37:35Z",
      "closed_at": "2024-07-29T11:37:35Z",
      "labels": [
        "bug",
        "enhancement"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/465/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/465",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/465",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:30.375359",
      "comments": [
        {
          "author": "paulpalmieri",
          "body": "Few issues here: \r\n1. instantiating two llamaindex `TokenCountingHandler` to count calls from different models doesn't seem to function. Only one of those catches events. \r\n2. In the case of passing a tokenizer from the `vertexai.preview` lib, we get this error inside llamaindex's token counting mod",
          "created_at": "2024-07-23T08:50:11Z"
        },
        {
          "author": "paulpalmieri",
          "body": "Here's some tokenizer comparison: \r\n```\r\nprompt: 14517\r\n--------------------\r\ngpt: 4522\r\ncl100k: 4680\r\no200k: 4522\r\np50k: 5925\r\nr50k: 6082\r\ngpt2: 6082\r\n-> gemini flash: 5201\r\n-> gemini pro 1.5: 5201\r\n```\r\n\r\nSince we can't support the real gemini tokenizer, what do you think about using `gpt` tokeniz",
          "created_at": "2024-07-23T10:00:24Z"
        },
        {
          "author": "paulpalmieri",
          "body": "Temporary fix by PR: #467 \r\n- we'll use a default tokenizer and approximate Gemini tokens with a multiplier defined in the pricing config. ",
          "created_at": "2024-07-25T08:51:17Z"
        },
        {
          "author": "lyie28",
          "body": "Can we close this now then @paulpalmieri ?",
          "created_at": "2024-07-26T12:08:48Z"
        }
      ]
    },
    {
      "issue_number": 489,
      "title": "Provide option to record static pages for later debugging",
      "body": "# Problem\r\n\r\nThe current [Logger](https://docs.lavague.ai/en/latest/docs/learn/local-log/) does not save the HTML of the page being interacted with.\r\n\r\nIf the issue is due to the [Navigation Engine ](https://docs.lavague.ai/en/latest/docs/learn/navigation-engine/) it could be great to be able to replay this specific step and debug the page without having to recreate the whole process.\r\n\r\nFor instance, I have some issue in the 4th step of an onboarding form of a bank, and navigation failed. I don't want to redo the whole thing.\r\n\r\n![image](https://github.com/user-attachments/assets/7a3d90b0-9317-47ea-879b-10e789ca6146)\r\n\r\n# Proposed solution\r\n\r\nI think we could have something like `agent.run(objective, record_html=True)` to add to the logger the ability to save the both the real DOM and the frozen in the logs.\r\n\r\n@mbrunel ",
      "state": "open",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-07-27T05:20:11Z",
      "updated_at": "2024-07-27T05:21:56Z",
      "closed_at": null,
      "labels": [
        "help wanted",
        "good first issue",
        "new feature"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/489/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "mbrunel"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/489",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/489",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:30.567459",
      "comments": [
        {
          "author": "dhuynh95",
          "body": "FYI @mbrunel it's important to have the real DOM to test some things on it, but also the frozen one to highlight elements to debug",
          "created_at": "2024-07-27T05:21:55Z"
        }
      ]
    },
    {
      "issue_number": 421,
      "title": "Make node filtering process configurable",
      "body": "PR #410 introduces a filtering process in the retriever to exclude non-interactive nodes. While this is a significant enhancement, it needs extensive testing on a variety of websites to ensure comprehensive web coverage. To facilitate tests and allow for a more flexible filtering approach, we propose making this filtering process optional.\r\n\r\nProposal:\r\n- [ ] Create an abstract `NodeFilter` class in charge to pre filter nodes to retrieve\r\n- [ ] Make the current code the default implementation in a `InteractiveNodeFilter` class",
      "state": "closed",
      "author": "adeprez",
      "author_type": "User",
      "created_at": "2024-07-08T08:44:49Z",
      "updated_at": "2024-07-24T11:24:56Z",
      "closed_at": "2024-07-24T11:24:56Z",
      "labels": [
        "good first issue",
        "ActionEngine"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/421/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/421",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/421",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:30.763421",
      "comments": [
        {
          "author": "adeprez",
          "body": "Done with retriever pipeline in #466",
          "created_at": "2024-07-24T11:24:56Z"
        }
      ]
    },
    {
      "issue_number": 452,
      "title": "Restrain elements retrieval to viewport only",
      "body": "The current retriever gathers interactive elements from the entire page, including those outside the viewport. This can result in retrieving elements that are less relevant (e.g. footer ones). We want to test if performance improves by filtering out elements that are not visible in the viewport, allowing the retriever to concentrate on visible elements.\r\n\r\nThe option to retrieve all elements should remain available for the agent when it performs a full-page scan.\r\n\r\nTo do so, `the get_possible_interactions` Driver method should accept a parameter to filter out elements outside viewport.",
      "state": "closed",
      "author": "adeprez",
      "author_type": "User",
      "created_at": "2024-07-17T13:42:02Z",
      "updated_at": "2024-07-24T10:38:32Z",
      "closed_at": "2024-07-24T10:38:32Z",
      "labels": [
        "AI-performance",
        "ActionEngine"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/452/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "adeprez"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/452",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/452",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:30.952751",
      "comments": [
        {
          "author": "adeprez",
          "body": "Could be integrated with something like this:\r\n```javascript\r\ndef process_viewport_visible_elements(driver: BaseDriver):\r\n    js_script = \"\"\"\r\n    function getVisibleElementsFromXPaths(xpaths) {\r\n        return xpaths.map(xpath => {\r\n            try {\r\n                const element = document.evalua",
          "created_at": "2024-07-17T14:00:03Z"
        },
        {
          "author": "adeprez",
          "body": "Restrain has been done in #466",
          "created_at": "2024-07-24T08:39:26Z"
        }
      ]
    },
    {
      "issue_number": 412,
      "title": "Provide empirical tips on how to use LaVague ",
      "body": "Someone tried to log in using LaVague using the following command:\r\n\r\n```python\r\nfrom lavague.core import  WorldModel, ActionEngine\r\nfrom lavague.core.agents import WebAgent\r\nfrom lavague.drivers.selenium import SeleniumDriver\r\n\r\nurl = ...\r\n\r\nselenium_driver = SeleniumDriver(headless=False)\r\nworld_model = WorldModel()\r\naction_engine = ActionEngine(selenium_driver)\r\nagent = WebAgent(world_model, action_engine)\r\nagent.get(url)\r\nagent.run(\"Enter '123@gmail.com' as username \")\r\nagent.run(\"Enter '123' as Password \")\r\nagent.run(\"Click on Login button\") .\r\n```\r\n\r\nIt did not work because the retriever did not fetch enough nodes so the retrieved elements were not sufficient to do what was required.\r\n\r\nHere is the correct code:\r\n\r\n```python\r\nfrom lavague.core import  WorldModel, ActionEngine\r\nfrom lavague.core.agents import WebAgent\r\nfrom lavague.drivers.selenium import SeleniumDriver\r\n\r\nurl = ...\r\n\r\nselenium_driver = SeleniumDriver(headless=False)\r\nworld_model = WorldModel()\r\naction_engine = ActionEngine(selenium_driver)\r\n\r\n# Increase the number of retrieved elements\r\naction_engine.navigation_engine.retriever.top_k = 10\r\n\r\nagent = WebAgent(world_model, action_engine)\r\nagent.get(url)\r\n\r\nobjective = \"\"\"\r\nEnter '123@gmail.com' as username\r\nEnter '123' as Password\r\nClick on Login button\"\"\"\r\n\r\nagent.run(objective)\r\n```\r\n\r\nTwo tips:\r\n- Don't do 3 three `agent.run()`, it's expensive and slow\r\n- Increase the retriever.top_k parameter if the right nodes were not in the retrieved nodes. \r\n\r\n@lyie28 : Can you add these info in some part of the docs? I guess we should explain the tradeoff of higher top_k : higher can solve navigation errors (aka element not found) but with higher cost and latency as we provide more context to LLM\r\n\r\nI guess we could add other tips.",
      "state": "open",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-07-06T08:18:18Z",
      "updated_at": "2024-07-23T15:30:19Z",
      "closed_at": null,
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/412/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/412",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/412",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:31.135370",
      "comments": [
        {
          "author": "paulpalmieri",
          "body": "@dhuynh95 how about a Tips page in the quickstart ? \r\n\r\nCould contain stuff like: \r\n- make sure to update your lavague version often\r\n- we recommend using remote models as local models haven't been performant enough\r\n- you can tweak some parameters like top_k\r\n- pass the complete objective to agent.",
          "created_at": "2024-07-19T08:38:08Z"
        },
        {
          "author": "lyie28",
          "body": "A lot of this information is already in the docs. I will add anything missing but mainly I am reorganizing the information so it will be easier to find.",
          "created_at": "2024-07-23T15:30:18Z"
        }
      ]
    },
    {
      "issue_number": 427,
      "title": "Integration with the new BM25s",
      "body": "A new BM25 (called [BM25s](https://github.com/xhluca/bm25s)) has been developed recently.\r\n\r\nWe leverage BM25 a lot in our pipeline. It could be interesting to see if we could integrate it.\r\n\r\nEasiest way would be to make BM25s integration with Llama Index ([opened issue there](https://github.com/run-llama/llama_index/issues/14650)) and then we integrate it in LaVague.",
      "state": "open",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-07-09T08:46:11Z",
      "updated_at": "2024-07-22T14:29:58Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "help wanted",
        "good first issue",
        "ActionEngine",
        "Integrations"
      ],
      "label_count": 5,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/427/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/427",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/427",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:31.311334",
      "comments": [
        {
          "author": "KartikeyBartwal",
          "body": "I would like to take on this issue. Waiting for your approval.",
          "created_at": "2024-07-22T14:29:57Z"
        }
      ]
    },
    {
      "issue_number": 423,
      "title": "Switch from JSON to YAML for navigation actions",
      "body": "When requesting structured data output from Language Models (LLMs), it is preferable to use YAML instead of JSON. YAML uses fewer tokens, making the process faster and more cost-effective.\r\n\r\nCurrently, safe navigation actions are represented as JSON objects when interaction with LLM. We want to represent them as YAML instead.",
      "state": "closed",
      "author": "adeprez",
      "author_type": "User",
      "created_at": "2024-07-08T13:25:53Z",
      "updated_at": "2024-07-22T13:42:58Z",
      "closed_at": "2024-07-22T13:42:58Z",
      "labels": [
        "ActionEngine"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/423/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/423",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/423",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:31.510067",
      "comments": []
    },
    {
      "issue_number": 444,
      "title": "TokenCountingHandler records WorldModel prompt twice leading to wrong cost evaluations",
      "body": "When bumping `llama-index` to `0.10.55`, we fix the issue of not counting the WorldModel prompt (#442)\r\n\r\nHowever, it now counts it twice. Notice the different call stacks, different ids but exact same content\r\n\r\n### First time\r\n![image](https://github.com/user-attachments/assets/30262f49-1c73-481b-aefb-3d171414e33d)\r\n\r\n\r\n### Second time\r\n![image](https://github.com/user-attachments/assets/a9e827b2-b827-4ead-b53d-adc1a4a77e06)\r\n\r\n\r\n## To reproduce: \r\n\r\n1. Bump version of llama-index to 0.10.55\r\n2. Create a debug config (launch.json in vscode). Set `\"justMyCode\"` to  `false` to be able to trigger breakpoints in llama-index code\r\n```json\r\n{\r\n    \"version\": \"0.2.0\",\r\n    \"configurations\": [\r\n        {\r\n            \"name\": \"Python Debugger: Current File\",\r\n            \"type\": \"debugpy\",\r\n            \"request\": \"launch\",\r\n            \"program\": \"${file}\",\r\n            \"console\": \"integratedTerminal\",\r\n            \"justMyCode\": false\r\n        }\r\n    ]\r\n}\r\n```\r\n3. Put breakpoints in `llama_index/core/callbacks/token_counting.py` at line 157 to see Events that are about to be recorded by the `TokenCountingHandler`\r\n4. Create a Python file containing a token counter, make sure to initialize the token counter as the very first step in your code. \r\n```python\r\ntk_counter = init_token_counter()\r\n# ... more init code ...\r\nagent = WebAgent(world_model, action_engine, token_counter=tk_counter)\r\n```\r\n5. Launch this file in Debug in VsCode\r\n",
      "state": "closed",
      "author": "paulpalmieri",
      "author_type": "User",
      "created_at": "2024-07-15T15:17:41Z",
      "updated_at": "2024-07-22T13:35:00Z",
      "closed_at": "2024-07-22T13:35:00Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/444/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "adeprez"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/444",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/444",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:33.349512",
      "comments": [
        {
          "author": "paulpalmieri",
          "body": "We could: \r\n- investigate further to understand why two events are triggered for a single call\r\n- let this run normally and deduplicate this WorldModel prompt counter twice before we save them to logs",
          "created_at": "2024-07-15T15:20:23Z"
        },
        {
          "author": "paulpalmieri",
          "body": "Temporary fix #446: removes elements counted twice",
          "created_at": "2024-07-19T08:34:51Z"
        }
      ]
    },
    {
      "issue_number": 388,
      "title": "Error while running the agent: string indices must be integers, not 'str'",
      "body": "Have seen this error `Error while running the agent: string indices must be integers, not 'str'` frequently when testing various HF local and models accessed via remote api - need to debug the issue\r\n\r\nDefintely had it with the following models:\r\n1.  HuggingFaceInferenceAPI(model_name=\"HuggingFaceH4/zephyr-7b-alpha\")\r\n2. HuggingFace Local LLM with Phi-3-medium-128k-instruct\r\n3. HuggingFace Local LLM with llama3-8b",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-06-25T23:14:40Z",
      "updated_at": "2024-07-22T13:34:00Z",
      "closed_at": "2024-07-22T13:34:00Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/388/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/388",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/388",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:33.566030",
      "comments": [
        {
          "author": "dhuynh95",
          "body": "I think it's because they malformed something that breaks our pipeline\r\nWe have to look at the raw output of the LLM. \r\nImportant question: is it at the rewritter or code gen? ",
          "created_at": "2024-06-27T05:32:17Z"
        },
        {
          "author": "lyie28",
          "body": "Problem comes from the rephraser LLM call. It is not outputing the expected code, which means our list_instructions list of action objects does not contain the appropriate objects. This is then causing errors when we try to access action[\"action\"] or action[\"query\"].",
          "created_at": "2024-06-27T12:10:22Z"
        },
        {
          "author": "lyie28",
          "body": "Code to replicate bug:\r\n\r\n```python\r\nfrom lavague.core import WorldModel, ActionEngine\r\nfrom lavague.core.agents import WebAgent\r\nfrom lavague.drivers.selenium import SeleniumDriver\r\nfrom llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\r\n\r\nselenium_driver = SeleniumDriver(headless=Tru",
          "created_at": "2024-06-27T12:14:03Z"
        },
        {
          "author": "lyie28",
          "body": "I think some testing will need to be done on how to phrase the rephraser prompt in a way that is succesful with a maximum number of models. This fixed the problem when I tested with Mixtral-8x7B-Instruct-v0.1, but not necessarily other models. We might need to think about which models we expect it t",
          "created_at": "2024-06-27T12:56:24Z"
        },
        {
          "author": "adeprez",
          "body": "Here is some exemple of output of the rephraser:\r\n\r\n```\r\n[{'query':'button\"PEFT\"', 'action':'Click on \"PEFT\"'}]\r\n\r\nText instruction: Click on the 'Sign Up' button on the homepage.\r\nStandardized instruction: [{'query':'button\"Sign Up\"', 'action':'Click on \"Sign Up\"'}]\r\n\r\nText instruction: Click on th",
          "created_at": "2024-06-27T13:32:49Z"
        }
      ]
    },
    {
      "issue_number": 211,
      "title": "Add optional feature to Gradio for users to evaluate actions",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-05-10T14:25:55Z",
      "updated_at": "2024-07-22T13:18:48Z",
      "closed_at": "2024-07-22T13:18:48Z",
      "labels": [
        "AI-performance"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/211/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/211",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/211",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:33.758412",
      "comments": []
    },
    {
      "issue_number": 454,
      "title": "Enable token logging by default",
      "body": "To count tokens, a user currently needs to pass a `TokenCounter` to the `WebAgent`. \r\n\r\nHowever this `TokenCounter` needs to be defined as the very first module for llama-index callbacks to register properly. \r\n\r\nImprovements: \r\n- token counting and cost logging should be enabled by default, all llms calls should be recorded. \r\n- token cost should only be logged if pricing data is available in `pricing_config.yaml`\r\n- update docs (quickstart section) + readme.md",
      "state": "open",
      "author": "paulpalmieri",
      "author_type": "User",
      "created_at": "2024-07-18T13:17:28Z",
      "updated_at": "2024-07-22T10:44:22Z",
      "closed_at": null,
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/454/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/454",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/454",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:33.758438",
      "comments": []
    },
    {
      "issue_number": 436,
      "title": "Adding a Visual Navigation Engine using Set of Marks to possible Navigation Engine",
      "body": "[Recent discussion](https://discordapp.com/channels/1216089456134586388/1216091478581968958/1261063677365321771) with the community highlighted the interest in having a Navigation Engine able to choose elements from visual inputs.\r\n\r\nAs a reminder from our [docs](https://docs.lavague.ai/en/latest/docs/learn/architecture/), we proceed in two ways today:\r\n\r\n![image](https://github.com/user-attachments/assets/bc38a8a2-4688-411b-aee6-0afeee8f74bc)\r\n\r\n1. The user's global objective is handled by the World Model. It considers this objective along with the state of the webpage through screenshots and HTML code, and generate the next step, aka. text instruction, needed to achieve this objective.\r\n\r\n2. This instruction is sent to the ActionEngine, which then generates the automation code needed to perform this step and executes it.\r\n\r\n3. The World Model then receives new text and image data, aka. a new screenshot and the updated source code, to reflect the updated state of the web page. With this information, it is able to generate the next instruction needed to achieve the objective.\r\n\r\n4. This process repeats until the objective is achieved.\r\n\r\nToday, the [Action Engine](https://docs.lavague.ai/en/latest/docs/learn/action-engine/) has 3 parts:\r\n\r\n![image](https://github.com/user-attachments/assets/0f05bf3e-b2f4-4689-a82f-79e99bff9af6)\r\n\r\n1. ðŸš„ Navigation Engine: Generates and executes Selenium code to perform an action on a web page\r\n2. ðŸ Python Engine: Generates and executes code for tasks that do not involve navigating or interacting with a web page, such as extracting information\r\n3. ðŸ•¹ï¸ Navigation Control: Performs frequently required navigation tasks without needing to make any extra LLM calls. So far we cover: scroll up, scroll down & wait\r\n\r\nThe current Navigation Engine, which does the bulk of the effort, use RAG on the current DOM to generate the next action.\r\n\r\nFollowing the proposal, we could split this in two:\r\n- DOM Navigation Engine: the current one\r\n- Visual Navigation Engine: the proposed one that uses Set of Marks where we highlight interactive elements and ask a MLLM to choose the right one\r\n\r\n@adeprez : this seems fairly straightforward. We already have code to get the interactive elements. We should just provide a screenshot after we highlight all of those and then ask a MLLM to output the ID.\r\n\r\nCan you share more details for others to take this one?\r\n\r\nTo do:\r\n- [ ] Provide code to get a screenshot of all interactive elements with ID\r\n- [ ] Ask MLLM to choose which one is the best\r\n- [ ] Map the ID to an action",
      "state": "open",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-07-12T05:53:55Z",
      "updated_at": "2024-07-22T10:42:16Z",
      "closed_at": null,
      "labels": [
        "new feature",
        "ActionEngine"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/436/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 1,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/436",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/436",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:33.758446",
      "comments": [
        {
          "author": "adeprez",
          "body": "Currently, the drivers offer a `get_possible_interactions` method that returns a dictionary. In this dictionary, the keys are xpaths, and the values are lists of interaction names (CLICK / TYPE / HOVER). We can use this feature to map each xpath to a unique ID. This ID can then be added to the outpu",
          "created_at": "2024-07-12T07:02:51Z"
        },
        {
          "author": "dhuynh95",
          "body": "I ran this code which gave me highlighted elements on the screen on https://orcid.org/0000-0001-6102-7846:\r\n\r\n```python\r\nfrom lavague.core.base_driver import BaseDriver\r\n\r\ndef highlight_element(element, driver: BaseDriver):\r\n    driver.execute_script(\r\n        \"arguments[0].setAttribute('style', arg",
          "created_at": "2024-07-13T07:17:00Z"
        },
        {
          "author": "dhuynh95",
          "body": "Update: Added numbering of elements:\r\n\r\n```python\r\nfrom lavague.core.base_driver import BaseDriver\r\n\r\ndef highlight_element(element, driver: BaseDriver):\r\n    driver.execute_script(\r\n        \"arguments[0].setAttribute('style', arguments[1]);\",\r\n        element,\r\n        \"border: 2px solid red;\",\r\n  ",
          "created_at": "2024-07-13T07:36:23Z"
        }
      ]
    },
    {
      "issue_number": 355,
      "title": "Add LLM telemetry to track cost when using API",
      "body": "@paulpalmieri mentioned we lack today visibility on the current consumption of LLMs.\r\n\r\nSome LLMOps tooling exists, such as https://github.com/AgentOps-AI/agentops \r\n\r\nI think it would be great to integrate such a tool to know how much a run costs, and maybe also use their tooling to debug agents more easily",
      "state": "closed",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-06-16T17:12:01Z",
      "updated_at": "2024-07-22T10:36:57Z",
      "closed_at": "2024-07-22T10:36:57Z",
      "labels": [
        "help wanted",
        "good first issue",
        "new feature"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/355/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/355",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/355",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:33.982522",
      "comments": []
    },
    {
      "issue_number": 275,
      "title": "Add Images for In Context Learning for World Model",
      "body": "The examples in our world model have only text while there is a way to add images too.\r\n\r\nRecent paper (https://arxiv.org/abs/2405.09798) shows that it can greatly help MM LLMs to boost performance.\r\n\r\nThey have a GitHub where they show to do it: https://github.com/stanfordmlgroup/ManyICL/blob/main/ManyICL/LMM.py \r\n\r\nWe would have to look into [Llama Index Multi Modal](https://docs.llamaindex.ai/en/stable/module_guides/models/multi_modal/) to see how we can adapt it to provide order so we can show (screenshot, objective) -> (instruction) to the World Model. ",
      "state": "closed",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-05-29T12:27:18Z",
      "updated_at": "2024-07-22T10:36:34Z",
      "closed_at": "2024-07-22T10:36:34Z",
      "labels": [
        "help wanted",
        "good first issue",
        "new feature",
        "AI-performance",
        "WorldModel",
        "research"
      ],
      "label_count": 6,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/275/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/275",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/275",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:33.982548",
      "comments": [
        {
          "author": "Mecel1147",
          "body": "Iâ€˜m trying to work on that",
          "created_at": "2024-06-06T12:12:36Z"
        }
      ]
    },
    {
      "issue_number": 264,
      "title": "[Requests] Docker and API Keys",
      "body": "Could you provide internal methods to utilize docker, like autogen and other LLM tools that execute code? Figuring out how to wrap LaVague externally doesn't make me confident in helping secure execution of code. \r\n\r\nAPI Keys are currently provided only through environ, which is not the best method for parallel services (where users use their own keys). Please provide a method to input the OpenAI API key as a param, like in Llama-Index itself. \r\n\r\n\r\n",
      "state": "open",
      "author": "WAS-PlaiLabs",
      "author_type": "User",
      "created_at": "2024-05-27T16:41:04Z",
      "updated_at": "2024-07-22T10:35:48Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Integrations"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/264/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/264",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/264",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:34.197029",
      "comments": [
        {
          "author": "dhuynh95",
          "body": "We could technically export the code to be rerun elsewhere but the issue is that due to the interactive notion of Agents, we would have to do every execution in a sandbox.\r\nNot impossible of course but a bit involved.\r\n\r\nWe are aware it's not perfect and we do have it in the roadmap. \r\n\r\nCould you p",
          "created_at": "2024-05-27T18:07:30Z"
        },
        {
          "author": "WAS-PlaiLabs",
          "body": "So in Autogen they have a flag param for the LLM config `use_docker` which would then use docker if running and configured correctly. You can provide a custom image name in this flag apparently as well (say you needed specific tools installed for the LLMs).\r\n\r\nhttps://microsoft.github.io/autogen/blo",
          "created_at": "2024-05-27T19:33:40Z"
        },
        {
          "author": "lyie28",
          "body": "This would be great to have.",
          "created_at": "2024-05-28T09:00:50Z"
        },
        {
          "author": "dukedorje",
          "body": "OpenDevin has an action loop for coding that runs completely Dockerized. Might be worth borrowing some of the methods there! https://github.com/OpenDevin/OpenDevin",
          "created_at": "2024-06-04T06:24:42Z"
        },
        {
          "author": "WAS-PlaiLabs",
          "body": "That looks pretty cool. Though would it be viable for a service?\r\n\r\nOn Mon, Jun 3, 2024, 11:25â€¯PM Duke Jones ***@***.***> wrote:\r\n\r\n> OpenDevin has an action loop for coding that runs completely Dockerized.\r\n> Might be worth borrowing some of the methods there!\r\n> https://github.com/OpenDevin/OpenDe",
          "created_at": "2024-06-04T14:49:18Z"
        }
      ]
    },
    {
      "issue_number": 296,
      "title": "Wait until page load to take screenshot",
      "body": "On certain sites, LaVague takes a screenshot too early on a page that hasn't finished loading. LaVague should wait until the page has fully loaded before taking a screenshot. ",
      "state": "closed",
      "author": "paulpalmieri",
      "author_type": "User",
      "created_at": "2024-06-04T13:11:24Z",
      "updated_at": "2024-07-22T10:34:45Z",
      "closed_at": "2024-07-22T10:34:45Z",
      "labels": [
        "help wanted",
        "good first issue"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/296/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/296",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/296",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:34.471426",
      "comments": [
        {
          "author": "jashuajoy",
          "body": "Could you pls provide url for a site this is happening?",
          "created_at": "2024-06-13T20:57:59Z"
        },
        {
          "author": "paulpalmieri",
          "body": "Hey @jashuajoy, check out this site: https://speedmonitor.io/topsites \r\n\r\nI guess https://cnn.com would be the first to try haha",
          "created_at": "2024-06-14T16:01:58Z"
        },
        {
          "author": "paulpalmieri",
          "body": "I've actually had trouble replicating this behavior, I'll do some more tests next week. Let me know if you're able to replicate :)\r\n",
          "created_at": "2024-06-14T16:02:50Z"
        }
      ]
    },
    {
      "issue_number": 297,
      "title": "Better handling of cookies and logins",
      "body": "Users would like LaVague to handle cookies and logins. How could we manage that better ?\r\n\r\nWhile I'll write more docs to show how one can run LaVague from a personal Chrome session (already logged in to sites, cookies only need to be accepted once). \r\n\r\nHowever, bot all agents can be run from personal chrome user session and we should think about a more systematic way of handling cookies and login. \r\n\r\n",
      "state": "closed",
      "author": "paulpalmieri",
      "author_type": "User",
      "created_at": "2024-06-04T13:30:31Z",
      "updated_at": "2024-07-22T10:34:07Z",
      "closed_at": "2024-07-22T10:34:07Z",
      "labels": [
        "help wanted"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/297/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "paulpalmieri"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/297",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/297",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:34.715131",
      "comments": [
        {
          "author": "lyie28",
          "body": "Hi! Why do you say not all agents can be run from personal chrome user sessions? What kind of use case do you have in mind when you say that? The other way around it currently is to enforce a pause to do manual log ins, or like a manual accept cookie or whatever, and then have your program continue ",
          "created_at": "2024-06-10T16:12:53Z"
        }
      ]
    },
    {
      "issue_number": 242,
      "title": "Handle new tabs",
      "body": "![invoice_dl_lavague](https://github.com/lavague-ai/LaVague/assets/22163205/08372372-8472-48f2-a436-a12961065456)\r\n\r\nI was trying to download my OpenAI invoices using LaVague with objective \"Download all my invoices\" starting from url \"https://platform.openai.com/settings/organization/billing/overview\". I bind the driver to Chrome in debug mode in order to avoid bot protections. \r\n\r\nIssue: \r\n- When LaVague clicks a link that opens a new tab, it always switches back to the first tab. \r\n- LaVague should be able to handle new tabs and proceed from there. \r\n\r\n",
      "state": "closed",
      "author": "paulpalmieri",
      "author_type": "User",
      "created_at": "2024-05-21T09:36:10Z",
      "updated_at": "2024-07-22T10:33:12Z",
      "closed_at": "2024-07-22T10:33:12Z",
      "labels": [
        "enhancement",
        "help wanted",
        "good first issue",
        "ActionEngine",
        "WorldModel",
        "Agent",
        "Driver"
      ],
      "label_count": 7,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/242/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/242",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/242",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:34.977116",
      "comments": [
        {
          "author": "dhuynh95",
          "body": "If someone is interested in taking that one we would be happy to receive help :)",
          "created_at": "2024-05-29T11:51:37Z"
        }
      ]
    },
    {
      "issue_number": 403,
      "title": "Add token count to track cost of each run",
      "body": "We have developped a [logger](https://docs.lavague.ai/en/latest/docs/learn/local-log/) to make it easier to track each run.\r\n\r\nWhile we keep the full prompt, inference time and so on, we do not have information about the number of tokens actually sent to the LLM (whether local or through an API).\r\n\r\nI think it would be great to have this to help people understand how much each run costs. \r\n\r\nThis should not be too hard, as we are using LlamaIndex LLM[ ](https://docs.llamaindex.ai/en/stable/module_guides/models/llms/)and [MultiModal LLM](https://docs.llamaindex.ai/en/stable/module_guides/models/multi_modal/) classes, which seem to support several [observability ](https://docs.llamaindex.ai/en/stable/module_guides/observability/)tools. When one looks at those, for instance [Arize Phoenix](https://docs.llamaindex.ai/en/stable/module_guides/observability/#arize-phoenix), it does seem that token count is recorded locally.\r\n\r\n![image](https://github.com/lavague-ai/LaVague/assets/36925557/e3ad1cd9-ad41-42e4-897e-4a9315fa5f42)\r\n\r\nSo technically there is something to record that, we just need to find out where, and add that to our logs.",
      "state": "closed",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-07-02T15:28:53Z",
      "updated_at": "2024-07-19T08:07:55Z",
      "closed_at": "2024-07-19T08:07:55Z",
      "labels": [
        "good first issue",
        "new feature"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/403/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "jashuajoy"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/403",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/403",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:35.248789",
      "comments": [
        {
          "author": "lyie28",
          "body": "Perhaps as well as this, we could also add it to the ActionResult object returned by agent.run() ?\r\n\r\n```python\r\nclass ActionResult:\r\n    \"\"\"Represent the result of executing an instruction\"\"\"\r\n\r\n    instruction: str\r\n    code: str\r\n    success: bool\r\n    output: Any\r\n    total_tokens: int/float\r\n `",
          "created_at": "2024-07-04T09:54:38Z"
        },
        {
          "author": "jashuajoy",
          "body": "Hi @dhuynh95 @lyie28, \r\nthese are 2 ways, I've found out, to get token count:\r\n1. There is a 'usage' property in the raw response for every world model request. It contains all the token information. I have added demo code to look at the returned response's 'usage'.\r\n2. Using 'Token Counting Handler",
          "created_at": "2024-07-05T05:06:42Z"
        },
        {
          "author": "jashuajoy",
          "body": "If 2nd approach is better for you, I can implement it.",
          "created_at": "2024-07-05T05:07:43Z"
        },
        {
          "author": "dhuynh95",
          "body": "That's super cool! Thanks a lot @jashuajoy! \nI guess the second is more systematic. \nDo you think you could add it in the logs we have? ",
          "created_at": "2024-07-05T05:11:10Z"
        },
        {
          "author": "dhuynh95",
          "body": "@lyie28 : this is a super important feature. Let's not close the issue until we also have documentation on it (might as well add the GPT cache experiment to see how many tokens we save with caching on the same page) ",
          "created_at": "2024-07-05T05:14:18Z"
        }
      ]
    },
    {
      "issue_number": 442,
      "title": "WorldModel is not counted by the token counter",
      "body": "It seems that the WorldModel prompt does not get recorded by the `TokenCountingHandler`. \r\n\r\nAfter review with @adeprez, we think it's because multimodal models are not supported as part of the current implementation of this module by LlamaIndex. \r\n\r\nWill investigate further. ",
      "state": "closed",
      "author": "paulpalmieri",
      "author_type": "User",
      "created_at": "2024-07-15T11:20:44Z",
      "updated_at": "2024-07-17T17:02:32Z",
      "closed_at": "2024-07-17T17:02:32Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/442/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "adeprez"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/442",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/442",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:35.728078",
      "comments": [
        {
          "author": "paulpalmieri",
          "body": "Can be fixed by a version bump of `llama-index` to `0.10.55`. Will let @JoFrost or @adeprez handle this ^^\r\n\r\nWarning: bumping the version fixes this issue but now the `TokenCountingHandler` counts the tokens twice ðŸ« ",
          "created_at": "2024-07-15T15:11:04Z"
        }
      ]
    },
    {
      "issue_number": 420,
      "title": "Tooling to highlight interactive elements for debugging",
      "body": "To enhance the debugging process and make it easier to identify interactive elements, we would like to have a feature to highlight them. It will use the driver function `get_possible_interactions` from #410 to list elements, and add an outline to all of them.",
      "state": "closed",
      "author": "adeprez",
      "author_type": "User",
      "created_at": "2024-07-08T08:38:22Z",
      "updated_at": "2024-07-17T15:21:59Z",
      "closed_at": "2024-07-17T15:21:59Z",
      "labels": [
        "good first issue",
        "ActionEngine",
        "Driver"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/420/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "adeprez"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/420",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/420",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:35.922838",
      "comments": []
    },
    {
      "issue_number": 330,
      "title": "LaVague unable to correctly target input elements",
      "body": "If you try using LaVague with Google when you are not signed in, LaVague can't handle the 'continue without singing in' pop-up and when you are signed in, LaVague is unable to locate/click on the search bar - could be interesting to debug why",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-06-10T15:22:37Z",
      "updated_at": "2024-07-17T15:21:38Z",
      "closed_at": "2024-07-17T15:21:37Z",
      "labels": [
        "bug",
        "AI-performance",
        "HighPrio"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/330/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "JoFrost",
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/330",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/330",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:35.922862",
      "comments": [
        {
          "author": "paulpalmieri",
          "body": "I can confirm that the search bar cannot be targeted. When you manually extract the XPath, it is `//*[@id=\"APjFqb\"]`\r\n\r\nI will check again tomorrow to see if this XPath changes. I suspect that Google might dynamically change the page structure to prevent bots.",
          "created_at": "2024-06-12T13:08:13Z"
        },
        {
          "author": "paulpalmieri",
          "body": "We originally looked at Google, but discovered that the issue is more widespread. LaVague struggles at targeting inputs (search bars) on many different websites (Bing, Google, Reddit, Apple, Nike, Puma)\n\nThe instruction we used is \"Search for LaVague\" but you can put anything with a purpose of targe",
          "created_at": "2024-06-19T15:23:11Z"
        },
        {
          "author": "adeprez",
          "body": "When we try a search on google, the retriever fails to locate the search bar. The given XPath matches no DOM element.\r\n\r\nWhen the searchbar is being targeted, the XPath found is `/html/body/div[1]/div[3]/form/div[1]/div[1]/div[2]/div[4]/div[6]/center/input[1]` (no match) but it should be `/html/body",
          "created_at": "2024-06-28T15:49:45Z"
        },
        {
          "author": "adeprez",
          "body": "Closing as resolved",
          "created_at": "2024-07-17T15:21:37Z"
        }
      ]
    },
    {
      "issue_number": 390,
      "title": "LaVague fails to compute the correct XPath",
      "body": "Identitied on : https://colab.research.google.com/drive/1zjO_VVw5NnrzzNPaodPPWvWn8tuAkBb7#scrollTo=IgXVnJ5MWab5\r\n\r\nWhen you log in Tableau, a Welcome modal appears. It usually should be dismissed, but LaVague fails to click the \"Continue button\" because the XPath retrieved is invalid.\r\n\r\n- XPath found : /html/body/div/div/form/div[6]/div[2]/div[1]/input (no element matches)\r\n- Expected XPath : /html/body/div[4]/div/div/div[4]/div[2]/div/button",
      "state": "closed",
      "author": "adeprez",
      "author_type": "User",
      "created_at": "2024-06-27T07:07:24Z",
      "updated_at": "2024-07-17T15:21:13Z",
      "closed_at": "2024-07-17T15:21:13Z",
      "labels": [
        "bug",
        "ActionEngine",
        "HighPrio"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/390/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/390",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/390",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:36.102988",
      "comments": []
    },
    {
      "issue_number": 378,
      "title": "Perform automatic tests on websites",
      "body": "# Automating tests for websites\r\n\r\nTo be run on CI or locally\r\n\r\n## Goal\r\nDevelop a system to perform automated tests on different websites, whether they are hosted online, static, or run locally. The system should:\r\n- List tasks to be completed for each test.\r\n- Specify the expected output.\r\n- Generate a report showing actual performance and coverage.\r\n\r\nIt will enable us to monitor performance and coverage improvements over time. Contributors can submit use cases to ensure they remain supported, allowing for continuous enhancement.\r\n\r\n## Proposal\r\nThe testing framework can be organized within a tests directory inside the repository. Each website or web application to be tested will have its own subdirectory containing a configuration file and any necessary assets.\r\n\r\n\r\n```text\r\ntests\r\n   |___ google.com\r\n        |___ config.json\r\n   |___ iframe\r\n        |___ config.json\r\n        |___ iframe.html\r\n```\r\n#### **`/tests/google.com/test.json`**\r\n```json\r\n{\r\n  \"url\": \"https://google.com\",\r\n  \"tasks\": [{\r\n    \"prompt\": \"Go to LaVague AI\",\r\n    \"expect\": {\r\n      \"end_url\": \"https://www.lavague.ai/\"\r\n    }\r\n  }]\r\n}\r\n```\r\n#### **`/tests/iframe/test.json`**\r\n```json\r\n{\r\n  \"start\": \"python -m http.server 8080\"\r\n  \"url\": \"http://localhost:8080\",\r\n  \"tasks\": [  ]\r\n}\r\n```",
      "state": "closed",
      "author": "adeprez",
      "author_type": "User",
      "created_at": "2024-06-24T09:54:27Z",
      "updated_at": "2024-07-16T16:02:11Z",
      "closed_at": "2024-07-16T16:02:11Z",
      "labels": [
        "CI/CD",
        "AI-performance"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/378/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "adeprez"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/378",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/378",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:36.103013",
      "comments": [
        {
          "author": "adeprez",
          "body": "Top websites we can start testing on:\r\n\r\n- Google\r\n- YouTube\r\n- Facebook\r\n- Wikipedia\r\n- X\r\n- Yahoo\r\n- ChatGPT\r\n- Reddit\r\n- Amazon\r\n- Outlook",
          "created_at": "2024-06-25T07:06:46Z"
        },
        {
          "author": "adeprez",
          "body": "It might be interesting to look at https://github.com/web-arena-x/visualwebarena",
          "created_at": "2024-06-30T08:26:43Z"
        }
      ]
    },
    {
      "issue_number": 440,
      "title": "Separate action execution from action generation ",
      "body": "Today the engines under the `ActionEngine` generate and execute the code.\r\nThis is not great for two reasons:\r\n- It's harder to follow what is being executed and where, it's easier to have them go through the same module for better observability\r\n- Execution might happen elsewhere, so it might be better to have execution be done in a module specifically for execution, like `Executor` that would be below the `Agent`\r\n\r\nSomething like this:\r\n\r\n![mermaid-diagram-2024-07-14-135529](https://github.com/user-attachments/assets/48607f6e-f3a2-4d41-8062-4e4851abd6c8)\r\n\r\nIt's not much and we don't need to do it yet but I propose:\r\n- [ ] All `BaseEngine` just have a method `generate_action` instead of `execute_instruction`\r\n- [ ] The actions are fed to the `ActionEngine` for observability, then sent to the `Agent`\r\n- [ ] `Agent` dispatches the actions to the `Executor` for execution",
      "state": "open",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-07-14T12:00:44Z",
      "updated_at": "2024-07-14T12:00:44Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "core",
        "Agent"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/440/reactions",
        "total_count": 2,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 2,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/440",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/440",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:36.318492",
      "comments": []
    },
    {
      "issue_number": 428,
      "title": "Estimate run cost",
      "body": "#415 introduces a method to count tokens. We would like to extend this functionality to estimate the cost of a run based on the token count. The pricing model should be configurable to accommodate different rates for different token types or services.\r\n\r\n",
      "state": "closed",
      "author": "adeprez",
      "author_type": "User",
      "created_at": "2024-07-09T13:48:48Z",
      "updated_at": "2024-07-12T07:31:22Z",
      "closed_at": "2024-07-12T07:31:21Z",
      "labels": [
        "help wanted",
        "good first issue"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/428/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/428",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/428",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:36.318507",
      "comments": [
        {
          "author": "jashuajoy",
          "body": "Hi @adeprez, currently there is no API endpoint for openai token pricing. One has to do it manually. If it is ok, I can implement this functionality. Pricing data needs to be updated manually in a separate file (json or yaml).",
          "created_at": "2024-07-09T14:38:23Z"
        },
        {
          "author": "adeprez",
          "body": "Hi, it would be great if you want to help with this! An estimation using a formula / config file sounds like a good idea.",
          "created_at": "2024-07-09T15:22:23Z"
        },
        {
          "author": "jashuajoy",
          "body": "Hi @adeprez, opened a pr #430. Pls check it out.",
          "created_at": "2024-07-09T17:21:21Z"
        },
        {
          "author": "adeprez",
          "body": "Thank you for your contribution! Your changes have been merged",
          "created_at": "2024-07-12T07:31:21Z"
        }
      ]
    },
    {
      "issue_number": 419,
      "title": "Pre-scan enhancements",
      "body": "Currently, during a single run, the agent collects new screenshots but retains those from previous steps. This leads to an increase in compute time and potential misunderstandings regarding the current state of the page. \r\n\r\nTo address this issue, before taking new screenshots, the navigation engine should:\r\n- [ ] Scroll the page to top\r\n- [ ] Clean the scan directory\r\n",
      "state": "closed",
      "author": "adeprez",
      "author_type": "User",
      "created_at": "2024-07-08T07:59:09Z",
      "updated_at": "2024-07-09T16:37:02Z",
      "closed_at": "2024-07-09T16:37:02Z",
      "labels": [
        "enhancement",
        "ActionEngine"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/419/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "dhuynh95"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/419",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/419",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:36.550455",
      "comments": []
    },
    {
      "issue_number": 408,
      "title": "Create observation when a file is downloaded",
      "body": "Add a feature to create an observation whenever a new file appears in the download directory of the filesystem. This will prevent the world model from entering a loop due to uncertainty about the successful download of a file.\r\n\r\n- [ ] Setup the driver to set the download directory to an agent-specific location\r\n- [ ] Continuously monitor the specified download directory for any new files\r\n- [ ] When a new file is detected in the download directory, create a corresponding observation in the world model\r\n- [ ] The observation should include the file name\r\n- [ ] On the chrome extension, make use of `chrome.downloads.onChanged` to detect file download",
      "state": "open",
      "author": "adeprez",
      "author_type": "User",
      "created_at": "2024-07-05T10:15:35Z",
      "updated_at": "2024-07-09T16:34:41Z",
      "closed_at": null,
      "labels": [
        "help wanted",
        "good first issue",
        "Agent",
        "Driver"
      ],
      "label_count": 4,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/408/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/408",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/408",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:36.550475",
      "comments": []
    },
    {
      "issue_number": 405,
      "title": "Not making use of embedding ",
      "body": "The BM25Retriever is used for finding the top k DOM elements which doesn't utilizing embeddings; however, The indexing process incorporates embeddings\r\n\r\n[https://github.com/lavague-ai/LaVague/blob/5862028ebcadaa26269e07af2e530358e02a91cf/lavague-core/lavague/core/retrievers.py#L228](https://github.com/lavague-ai/LaVague/blob/5862028ebcadaa26269e07af2e530358e02a91cf/lavague-core/lavague/core/retrievers.py#L228)",
      "state": "closed",
      "author": "Indirajith-jithu",
      "author_type": "User",
      "created_at": "2024-07-04T07:59:29Z",
      "updated_at": "2024-07-09T11:31:21Z",
      "closed_at": "2024-07-09T11:31:21Z",
      "labels": [
        "question",
        "AI-performance"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/405/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "dhuynh95",
        "HiImMadness"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/405",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/405",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:36.550484",
      "comments": [
        {
          "author": "lyie28",
          "body": "Hi @Indirajith-jithu,\r\n\r\nThanks for this.\r\n\r\nSo just to check, your point is that a BM25Retriever is incompatible with an index using embeddings?\r\n\r\nLet me bring in our AI team @dhuynh95 @HiImMadness ",
          "created_at": "2024-07-04T08:44:50Z"
        },
        {
          "author": "Indirajith-jithu",
          "body": "Yes \r\n\r\n[https://github.com/run-llama/llama_index/blob/589b3054e22535fc7a43baa2bbd52aacc439b4f7/llama-index-integrations/retrievers/llama-index-retrievers-bm25/llama_index/retrievers/bm25/base.py#L82](https://github.com/run-llama/llama_index/blob/589b3054e22535fc7a43baa2bbd52aacc439b4f7/llama-index-",
          "created_at": "2024-07-04T11:51:27Z"
        }
      ]
    },
    {
      "issue_number": 362,
      "title": "LaVague fails to access and interact with iframe content",
      "body": "## Inability of LaVague to Interact with Content Inside Iframes\r\n\r\n### Description\r\n\r\nLaVague cannot interact with content inside iframes. \r\n\r\nWhen we compare the output of `get_html()` in the `get_obs()` function in `base_driver.py` with the actual page content, it is clear that LaVague lacks access to iframe content.\r\n\r\nLaVague should be able to interact with all elements in the DOM, including iframes and nested iframes, once the page has fully loaded.\r\n\r\n### Steps to Reproduce\r\n\r\n1. Visit `https://selectorshub.com/iframe-scenario/` where you will see three nested iframes.\r\n2. Launch LaVague with an objective to fill the three input fields, such as \"Enter foobar in the three inputs.\"\r\n3. Observe LaVague's repeated attempts and failures to select these fields.\r\n\r\n### Attachments\r\n\r\n- Text output of the run with a `print(html)` in `get_obs()`\r\n[test_iframe.txt](https://github.com/user-attachments/files/15883950/test_iframe.txt)\r\n",
      "state": "closed",
      "author": "paulpalmieri",
      "author_type": "User",
      "created_at": "2024-06-18T09:46:00Z",
      "updated_at": "2024-07-09T11:31:20Z",
      "closed_at": "2024-07-09T11:31:20Z",
      "labels": [
        "bug",
        "ActionEngine",
        "HighPrio"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/362/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "mbrunel"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/362",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/362",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:36.829787",
      "comments": [
        {
          "author": "lyie28",
          "body": "Proposed solution:\r\nEither, the World Model or Action Engine detect if there is an iframe present - difficulty being it may take a second or two to load and be captured in the screenshot.\r\n\r\nIf there is:\r\n- get the ID for the iframe form the normal HTML source code and switch context to the iframe\r\n",
          "created_at": "2024-06-18T14:58:40Z"
        },
        {
          "author": "paulpalmieri",
          "body": "Other findings: \n- This table booking widget is in an iframe: https://www.chezlivio.com/\n- Cookies banners are often found in iframes, especially on popular medias like (bbc.com, lemonde.fr, lefigaro, thetimes, theguardian, courrierinternational). Lifting iframe limitations should also help us handl",
          "created_at": "2024-06-19T16:11:10Z"
        },
        {
          "author": "mbrunel",
          "body": "and shadow-dom if possible",
          "created_at": "2024-07-01T14:13:07Z"
        }
      ]
    },
    {
      "issue_number": 348,
      "title": "Leverage the accessibility tree for the Navigation Engine",
      "body": "Someone rightly pointed yesterday that we could use the accessibility tree during the webinar.\r\nGot to say I heard of it but haven't checked.\r\n\r\nI think this is something where the community could help.\r\n\r\nWe will draw the details of implementation with @mbrunel and @HiImMadness and share the steps to implement it here",
      "state": "closed",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-06-14T05:53:33Z",
      "updated_at": "2024-07-09T11:31:20Z",
      "closed_at": "2024-07-09T11:31:20Z",
      "labels": [
        "enhancement",
        "help wanted",
        "good first issue",
        "ActionEngine"
      ],
      "label_count": 4,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/348/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "adeprez",
        "mbrunel",
        "HiImMadness"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/348",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/348",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:37.029867",
      "comments": [
        {
          "author": "adeprez",
          "body": "In the same vein we can use the `for` attribute to enrich element context even when `aria-label` is absent.\n\n```html\n<label for=\"abc\">Search</label>\n<input id=\"abc\" />\n```\n`input#abc` has no information itself, but we can infer a \"Search\" label.",
          "created_at": "2024-06-21T09:04:30Z"
        }
      ]
    },
    {
      "issue_number": 426,
      "title": "Unification of action space for better evaluation and reproducibility with benchmarks like Web Arena",
      "body": "Today our action space is a bit heterogenous and hard to read.\r\n\r\nIdeally we want a good abstraction, like what they propose in [Work Arena](https://arxiv.org/abs/2403.07718) (which is similar to [Web Arena](https://arxiv.org/abs/2307.13854))\r\n\r\n![image](https://github.com/lavague-ai/LaVague/assets/36925557/4f329676-cfcb-4e01-8573-e5ad9758a625)\r\n\r\nwhere the big families of actions are:\r\n- Action using element id (e.g. Click(element_id))\r\n- Action using coordinates (e.g. Click(x,y))\r\n- Action in the form of Python code exec (Tool or arbitrary code)",
      "state": "open",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-07-09T08:37:32Z",
      "updated_at": "2024-07-09T08:37:32Z",
      "closed_at": null,
      "labels": [
        "ActionEngine",
        "HighPrio",
        "research"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/426/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/426",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/426",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:37.217514",
      "comments": []
    },
    {
      "issue_number": 424,
      "title": "Provide notification capabilities for agent",
      "body": "A big use case of Web Agents is to fetch information for users (\"The web is your API\" should be our slogan), from fetching or acting on a SaaS portal (payroll, Cloud platform, appointment) to scrapping information on public / private sources (Crunchbase, docs, etc.).\r\n\r\nI think therefore we should think about providing a feature to setup notification / trigger LaVague on a specific basis (like daily) to run the agent and send a notification (Gmail, Slack, etc.).\r\n\r\nI guess this would make sense once we have a native app on the client side so that we can schedule Agent runs and send information then.",
      "state": "open",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-07-08T13:35:26Z",
      "updated_at": "2024-07-08T13:35:26Z",
      "closed_at": null,
      "labels": [
        "new feature",
        "Agent",
        "HighPrio"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/424/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/424",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/424",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:37.217535",
      "comments": []
    },
    {
      "issue_number": 406,
      "title": "Add custom file upload action",
      "body": "Since Selenium cannot interact with a file upload dialog, I believe we'll need to create a custom action to handle file uploads correctly.\r\n\r\nIf the site uses an element is an input element with type file, we can usually send it a file path to upload like this:\r\n\r\n```python\r\nelem = driver.find_element(By.CSS_SELECTOR, \"input[type='file']\")\r\nelem.send_keys(file_path)\r\ndriver.find_element(By.ID, \"file-submit\").click()\r\n```\r\n\r\nHowever this does not work on all sites, so we we need to think how we can come up with something that works across a maximum amount of sites.",
      "state": "open",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-07-04T14:35:46Z",
      "updated_at": "2024-07-05T10:52:13Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "help wanted",
        "new feature"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/406/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/406",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/406",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:37.217543",
      "comments": [
        {
          "author": "lyie28",
          "body": "For any potential contributors, just to add details on how to modify the driver source code to add custom actions. You can do so with the following steps:\r\n\r\n1. Open the `base.py` file for your driver, e.g `lavague-integrations/drivers/lavague-drivers-selenium/lavague/drivers/selenium/base.py`\r\n\r\n2.",
          "created_at": "2024-07-04T14:38:44Z"
        },
        {
          "author": "adeprez",
          "body": "Your solution with `send_keys(file_path)` seems to work. Do you have examples of websites where it fails so we can explore alternatives?",
          "created_at": "2024-07-05T10:45:04Z"
        },
        {
          "author": "lyie28",
          "body": "I think I tried 5 sites - and it worked on 3/5. It didn't work for `WeTransfer` and the use case I shared with you that I've been working on this week",
          "created_at": "2024-07-05T10:52:12Z"
        }
      ]
    },
    {
      "issue_number": 352,
      "title": "Navigation Engine switch from arbitrary code exec to outputting XPath, type of action and other arguments",
      "body": "The `NavigationEngine` currently does arbitrary code execution, which is a bad practice and is no longer needed (we did it at the beginning because we wanted to provide the ability to invoke tools if needed, but things are well separated now in the `PythonEngine` who is specialized in calling tools).\r\n\r\nWe therefore should revamp the current Navigation Engine to output things like:\r\n```python\r\n[\r\n    {\"Action\": \"Click\",\r\n     \"XPath\": \"...\"\r\n     },\r\n]\r\n```\r\n\r\nThen we provide specific code for each different driver, Selenium, Playwright or Chrome Extension.",
      "state": "closed",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-06-14T08:57:38Z",
      "updated_at": "2024-07-05T10:32:07Z",
      "closed_at": "2024-07-05T10:32:07Z",
      "labels": [
        "new feature",
        "core",
        "HighPrio",
        "Security"
      ],
      "label_count": 4,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/352/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "JoFrost",
        "mbrunel"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/352",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/352",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:37.389266",
      "comments": []
    },
    {
      "issue_number": 243,
      "title": "LaVague often tries to click on non-interactable elements",
      "body": "**Describe the bug**\nLaVague tends to attempt clicking elements that can't be interacted with. \n\n**To Reproduce**\nHere's the code I was running (note that I'm starting Chrome in debug mode and attaching the driver after)\n```python\nfrom lavague.core import WebAgent, WorldModel, ActionEngine\nfrom lavague.contexts.gemini import GeminiContext\nfrom lavague.drivers.selenium import SeleniumDriver\n\nselenium_driver = SeleniumDriver(headless=False, chrome_user_dir=\"/Users/palmi/Library/Application Support/Google/Chrome\")\naction_engine = ActionEngine(selenium_driver)\nworld_model = WorldModel.from_local(\"./examples/knowledge/restaurant_booking.txt\")\n\nagent = WebAgent(action_engine, world_model)\nagent.get(\"https://www.opentable.com/r/trace-paris\")\nagent.run(input(), display=False)\n\n```\n\n**Expected behavior**\nLaVague should always target interactable elements. \n\n**Screenshots**\n<img width=\"1800\" alt=\"image\" src=\"https://github.com/lavague-ai/LaVague/assets/22163205/62a475cf-0369-419f-bdee-c30e7a571e06\">\n\n**URL**\nURL: https://www.opentable.com/booking/specials?availabilityToken=eyJ2IjoyLCJtIjowLCJwIjowLCJjIjo2LCJzIjowLCJuIjowfQ&correlationId=35c9d29c-18b1-468a-99f3-019910b8ea5c&creditCardRequired=true&dateTime=2024-05-21T20:30:00&experienceIds=264190,208651,180373&partySize=2&points=100&pointsType=Standard&resoAttribute=default&rid=215430&slotHash=610078860&isModify=false&isMandatory=true&cfe=true&tableCategory=default&diningAreaId=1",
      "state": "closed",
      "author": "paulpalmieri",
      "author_type": "User",
      "created_at": "2024-05-21T10:11:10Z",
      "updated_at": "2024-07-05T10:31:50Z",
      "closed_at": "2024-07-05T10:31:50Z",
      "labels": [
        "bug",
        "AI-performance",
        "HighPrio"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/243/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "mbrunel"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/243",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/243",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:37.389293",
      "comments": [
        {
          "author": "paulpalmieri",
          "body": "To add to this issue: \n- The error I encounter the most is \"Element not interactable\"\n- This seems to be a widespread issue and prevents LaVague from executing basic commands like the one in the example below. \n\nHere's another use case to reproduce: \n- For simplicity, we add `chrome_options.add_expe",
          "created_at": "2024-06-21T11:03:51Z"
        }
      ]
    },
    {
      "issue_number": 209,
      "title": "Create evaluation for World Model",
      "body": null,
      "state": "open",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-05-10T14:25:47Z",
      "updated_at": "2024-07-05T10:02:26Z",
      "closed_at": null,
      "labels": [
        "AI-performance"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/209/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "HiImMadness"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/209",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/209",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:37.608219",
      "comments": []
    },
    {
      "issue_number": 376,
      "title": "Local DB integration for logs",
      "body": "Current we have an `AgentLogger` which stores a log of info for the last agent run in memory which can be retrieved with the `agent.logging.return_pandas()` method.\r\n\r\nWe also have a `LocalLogger` option that stores the log for the last run in a local file.\r\n\r\nWe would like to add an integration where you can set an option when using `agent.run()` to add the info from the logger info a local database with SQLlite. I had in mind something like this, but open to ideas:\r\n`agent.run(objective=objective, url=url, log_to_db=True)`\r\n\r\nMore details about the logger is available in the docs:\r\nhttps://docs.lavague.ai/en/latest/docs/learn/local-log/\r\n\r\nOr in the logger.py file: https://github.com/lavague-ai/LaVague/blob/main/lavague-core/lavague/core/logger.py",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-06-24T09:07:24Z",
      "updated_at": "2024-07-04T14:42:01Z",
      "closed_at": "2024-07-04T14:42:00Z",
      "labels": [
        "help wanted"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/376/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/376",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/376",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:37.608236",
      "comments": [
        {
          "author": "jashuajoy",
          "body": "Hi @lyie28, I might be able to help you with this. \r\nA quick question: Should the local DB store all the log data(like the data being returned when agent.logging.return_pandas() is run)?",
          "created_at": "2024-06-25T19:31:58Z"
        },
        {
          "author": "lyie28",
          "body": "Good question. @adeprez @dhuynh95 I had assumed we would pass all the log data to the database - is there anything you think we should drop?",
          "created_at": "2024-06-26T13:06:56Z"
        },
        {
          "author": "adeprez",
          "body": "I support passing all the logs to the database, if any data needs to be filtered out, it should be removed before being collected in the logs",
          "created_at": "2024-06-26T16:00:04Z"
        },
        {
          "author": "lyie28",
          "body": "Do you still want to work on this one @jashuajoy? Shall I assign it to you?",
          "created_at": "2024-06-28T12:15:51Z"
        },
        {
          "author": "jashuajoy",
          "body": "Yes @lyie28. I have a few follow up questions. Will ping you in discord.",
          "created_at": "2024-06-28T12:48:05Z"
        }
      ]
    },
    {
      "issue_number": 380,
      "title": "Allow Customization of User-Agent",
      "body": "Some websites block page loads when they detect a headless user-agent. This can prevent LaVague from functioning correctly when interacting with these sites. To address this, we need to allow customization of the user-agent string. Additionally, we should provide a default user-agent that mimics a standard browser to avoid detection.\r\n\r\nRequired for Selenium and Playwright drivers. Not needed for Chrome extension driver.\r\n\r\nHow to reproduce:\r\n\r\n```python\r\nfrom lavague.drivers.selenium import SeleniumDriver\r\nfrom selenium.webdriver.common.by import By\r\nfrom time import sleep\r\n\r\nselenium_driver = SeleniumDriver(headless=False)\r\ndriver = selenium_driver.driver\r\ndriver.get(\"https://www.opentable.com/r/trace-paris\")\r\nsleep(6)\r\nelem = driver.find_element(By.XPATH, \"/html/body/div[1]/div/div/main/div\")\r\nprint(elem.get_dom_attribute(\"class\"))\r\n```",
      "state": "closed",
      "author": "adeprez",
      "author_type": "User",
      "created_at": "2024-06-24T14:44:43Z",
      "updated_at": "2024-07-02T10:27:18Z",
      "closed_at": "2024-07-02T10:27:18Z",
      "labels": [
        "Driver"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/380/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "mbrunel"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/380",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/380",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:37.793482",
      "comments": []
    },
    {
      "issue_number": 399,
      "title": "Add flag for remote debugging to share issues with the team",
      "body": "Some people encounter issues with LaVague, and our team has to be involved. We sometimes require advanced access, such as to screens, raw code, and all.\r\n\r\nWe collect anonymized telemetry (objective, URLs browsed) but it could be helpful for those who encounter issue to activate advanced telemetry, which would share more data (screenshots, full HTML of the current page), to make debugging easier.\r\n\r\nI propose that when we set [telemetry ](https://docs.lavague.ai/en/latest/docs/advanced/telemetry/) to 'HIGH' (`TELEMETRY_VAR`), the following happens: \r\n- [ ] A warning is displayed when launching LaVague to make sure people are aware telemetry is set to high\r\n- [ ] A unique ID is displayed, which is consistent across multiple agent runs, to have a consistent ID to share with our team\r\n- [ ] Extra data is recorded to facilitate improvement on our side, such as screenshots and full HTML",
      "state": "open",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-07-01T14:00:07Z",
      "updated_at": "2024-07-01T14:00:07Z",
      "closed_at": null,
      "labels": [
        "new feature"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/399/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/399",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/399",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:37.793498",
      "comments": []
    },
    {
      "issue_number": 265,
      "title": "Support with e2b.dev sandboxed environments",
      "body": "Hey!\r\n\r\nJust opening the idea here as you advise to run agents in sandboxed envs...\r\n\r\n-->\r\nIntegrate LaVague with e2b.dev sandboxed environments (as they're basically dedicated to this vp) to enhance the capabilities of LaVague by allowing AI Web Agents developed with the framework to execute code securely in isolated environments.",
      "state": "closed",
      "author": "kecyf",
      "author_type": "User",
      "created_at": "2024-05-27T21:29:22Z",
      "updated_at": "2024-06-28T16:16:31Z",
      "closed_at": "2024-06-28T15:16:51Z",
      "labels": [
        "help wanted",
        "Security"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/265/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/265",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/265",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:37.793503",
      "comments": [
        {
          "author": "lyie28",
          "body": "It's a nice idea to have an integration for a sandboxed env. @dhuynh95 what do you think? It could be something to open as a help-wanted issue for community contributors?",
          "created_at": "2024-05-28T08:59:27Z"
        },
        {
          "author": "lyie28",
          "body": "Hey @kecyf, we have instead tackled the security aspect by integrating safeguards around which actions can be run. The agent can now only run some pre-defined actions.",
          "created_at": "2024-06-28T15:16:51Z"
        },
        {
          "author": "kecyf",
          "body": "hey @lyie28, nice! thanks for your feedback, i'll check this out!",
          "created_at": "2024-06-28T16:16:29Z"
        }
      ]
    },
    {
      "issue_number": 164,
      "title": "Documentation should not say to run setup.sh with sudo",
      "body": "**Describe the bug**\r\n\r\nDocumentation in multiple places tells us to run ``sudo bash setup.sh``.  This doesn't work.  It will try to install the Python module as the root user.  The script includes ``sudo`` calls when required and is clearly not intended to be run as root.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to <https://docs.lavague.ai/en/latest/>\r\n2. Follow the installation instructions\r\n3. The LaVague command won't run for me\r\n\r\nThis might be specifically broken on Ubuntu because it doesn't allow system installs through pip.  It looks like it should work generally if you activate your virtualenv before running the script.\r\n\r\n**Expected behavior**\r\n\r\nI think it should install the package into a virtualenv.  If I fix the ownership of the different things that were downloaded as root and run ``pip install -e LaVague`` that works.\r\n\r\nAs the last step is to change directory, it might be that this script is intended to be sourced rather than run.\r\n\r\nOne other thing: when it fails I don't expect it to tell me it was successful.  The setup script should have a ``set -e`` at the top\r\n",
      "state": "closed",
      "author": "gbreed",
      "author_type": "User",
      "created_at": "2024-04-26T09:30:01Z",
      "updated_at": "2024-06-28T15:56:50Z",
      "closed_at": "2024-06-28T15:56:39Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 10,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/164/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/164",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/164",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:38.010406",
      "comments": [
        {
          "author": "dhuynh95",
          "body": "Thanks for pointing that out.\r\n@JoFrost could you have a look?",
          "created_at": "2024-04-27T18:34:09Z"
        },
        {
          "author": "lyie28",
          "body": "Hi @gbreed,\r\n\r\nThanks for reporting this and your suggestions.\r\n\r\nI have:\r\n- Removed sudo from instructions for running the script in the docs\r\n- Added a set -e and an error message into the setup script\r\n- Changed from install from GH repo to install from pypi package (originally we installed from ",
          "created_at": "2024-04-30T10:50:36Z"
        },
        {
          "author": "gbreed",
          "body": "It solves the issue of installing the Python module.  If I run it I still get this:\r\n\r\n{{{\r\nError: Invalid value for '--instructions' / '-i': Path 'examples/instructions/huggingface.yaml' does not exist.\r\n}}}\r\n\r\nI'm trying to use huggingface because I can get a free key for testing.  There are a num",
          "created_at": "2024-04-30T16:49:52Z"
        },
        {
          "author": "lyie28",
          "body": "Hi @gbreed, I suspect this means you are not at the root of the repo. The path is always relative from your current location, so from the root of the LaVague repo you should have a file 'examples/instructions/huggingface.yaml' which contains the huggingface home page URL and some demo instructions t",
          "created_at": "2024-04-30T17:30:15Z"
        },
        {
          "author": "lyie28",
          "body": "@gbreed - actually it just occured to me that since I changed to a pip install in the script, we won't necessary have the GH repo with demo config + instructions files downloaded - sorry about that, will need to update the docs on that.\r\n\r\nYou can do the following instead if you don't want to clone ",
          "created_at": "2024-04-30T17:39:51Z"
        }
      ]
    },
    {
      "issue_number": 353,
      "title": "Selector issue on responsive sites and hidden elements",
      "body": "**Description:**\r\nWhen running LaVague on `in.puma.com/` with an instruction that should lead to targeting the search icon, LaVague encounters a selector issue. \r\n\r\n**Problem:**\r\nLaVague is incorrectly selecting the search button intended for larger screens, even when the window size triggers the responsive (mobile) version of the site. It attempts to select the wrong button multiple times, causing our run to repeat then fail.\r\n\r\n**Selenium Code Produced:**\r\n```python\r\n# Let's think step by step\r\n\r\n# First, we notice that the query asks us to click on the button labeled \"Search\".\r\n\r\n# In the provided HTML, we can see two button elements with the text \"Search\".\r\n\r\n# We need to identify the correct button labeled \"Search\".\r\n\r\n# Upon examining the HTML structure, we see that the button with the text \"Search\" is located within a specific hierarchy.\r\n\r\n# The correct button is located within a div element with a specific class and role attribute, which helps us ensure that we are targeting the right element.\r\n\r\n# Specifically, for the \"Search\" button, there is a button element with a unique data-test-id 'search-button-nav' which contains a div with the text 'Search'.\r\n\r\n# We observe that this button element has the following XPath:\r\n# /html/body/div[1]/div[1]/div[1]/nav/div/div/button[1]\r\n\r\n# Thus, we believe this is the correct element to be interacted with:\r\nsearch_button = driver.find_element(By.XPATH, \"/html/body/div[1]/div[1]/div[1]/nav/div/div/button[1]\")\r\n\r\n# Then we can click on the button\r\nsearch_button.click()\r\n```\r\n\r\n**Correct Element:**\r\nThe correct element for the responsive version is:\r\n```python\r\nsearch_button = driver.find_element(By.XPATH, \"/html/body/div[1]/div[1]/div[1]/nav/div/div/button[2]\")\r\n```\r\n\r\n**Temporary Workaround:**\r\nManually zooming out the page to switch to the larger screen layout allows LaVague to target the correct search button.\r\n\r\n**Notes:**\r\n- The issue arises because LaVague does not correctly handle the responsive elements of the PUMA site (it always chooses the button made for larger screens)\r\n- Adding a wait and manually adjusting the zoom (or maximizing the window) resolves the issue temporarily, but this is not a viable long-term solution.\r\n\r\n\r\n\r\n**Steps to Reproduce:**\r\n1. Run the following commands:\r\n   ```python\r\n   agent.get(\"https://in.puma.com/\")\r\n   agent.run(\"Search for shoes using the search icon\")\r\n   ```\r\n2. Observe that LaVague attempts to click the search button for larger screens multiple times.\r\n\r\n**Expected Behavior:**\r\nLaVague should know that the button for larger screens is hidden and not interactable. It should handle the responsive layout and select the correct search button for the current screen size\r\n\r\n\r\nIn the following screenshot, the highlighted button should be targeted. But it's the HTML element right above that is being targeted. \r\n\r\n<img width=\"1800\" alt=\"Screenshot 2024-06-14 at 11 20 14\" src=\"https://github.com/lavague-ai/LaVague/assets/22163205/649d8c4e-c74d-4f26-85f8-08f2feb87460\">\r\n\r\n\r\n### **Some other examples of produced Selenium code**\r\n\r\n\r\nAttempt 2\r\n```python\r\n# Let's think step by step\r\n\r\n# First, we notice that the query asks us to click on the button labeled \"Search\".\r\n\r\n# In the provided HTML, we can see two button elements with the text \"Search\".\r\n\r\n# We need to identify the correct button to interact with.\r\n\r\n# Upon examining the HTML structure, we see that the first button is for larger screens (xl:flex) and the second button is for smaller screens (xl:hidden).\r\n\r\n# We will target the first button for larger screens as it is more likely to be visible in a standard desktop view.\r\n\r\n# The correct button is located within a div element with a specific class and role attribute, which helps us ensure that we are targeting the right element.\r\n\r\n# Specifically, for the \"Search\" button, there is a button element with the data-test-id 'search-button-nav' which contains a div with the text 'Search'.\r\n\r\n# We observe that this button element has the following XPath:\r\n# /html/body/div[1]/div[1]/div[1]/nav/div/div/button[1]\r\n\r\n# Thus, we believe this is the correct element to be interacted with:\r\nsearch_button = driver.find_element(By.XPATH, \"/html/body/div[1]/div[1]/div[1]/nav/div/div/button[1]\")\r\n\r\n# Then we can click on the button\r\nsearch_button.click()\r\n```\r\n\r\n\r\nAttempt 3 \r\n```python\r\n# Let's think step by step\r\n\r\n# First, we notice that the query asks us to click on the button labeled \"Search\".\r\n\r\n# In the provided HTML, we can see two button elements that are related to the search functionality.\r\n\r\n# The first button is visible on larger screens (xl:flex) and contains the text \"Search\".\r\n# The second button is visible on smaller screens (xl:hidden) and also contains the text \"Search\".\r\n\r\n# We need to ensure that we are clicking the correct button based on the screen size.\r\n\r\n# For this example, let's assume we are targeting the button visible on larger screens.\r\n\r\n# The correct button is located within a div element with a specific class and contains a div with the text \"Search\".\r\n\r\n# Specifically, for the \"Search\" button, there is a button element with the following XPath:\r\n# /html/body/div[1]/div[1]/div[1]/nav/div/div/button[1]\r\n\r\n# Thus, we believe this is the correct element to be interacted with:\r\nsearch_button = driver.find_element(By.XPATH, \"/html/body/div[1]/div[1]/div[1]/nav/div/div/button[1]\")\r\n\r\n# Then we can click on the button\r\nsearch_button.click()\r\n```\r\n\r\nAttempt 4\r\n```python\r\n# Let's think step by step\r\n\r\n# First, we notice that the query asks us to click on the button labeled \"Search\".\r\n\r\n# In the provided HTML, we see two button elements with the text \"Search\".\r\n\r\n# We need to identify the correct button to interact with.\r\n\r\n# The first button is visible on larger screens (class: 'hidden xl:flex'), while the second button is visible on smaller screens (class: 'xl:hidden').\r\n\r\n# We will target the first button as it is more likely to be visible on a standard screen size.\r\n\r\n# The first button can be identified by its unique data-test-id attribute 'search-button-nav'.\r\n\r\n# We can use the following XPath to locate this button:\r\nsearch_button = driver.find_element(By.XPATH, \"/html/body/div[1]/div[1]/div[1]/nav/div/div/button[1]\")\r\n\r\n# Then we can click on the button\r\nsearch_button.click()\r\n```",
      "state": "closed",
      "author": "paulpalmieri",
      "author_type": "User",
      "created_at": "2024-06-14T09:24:21Z",
      "updated_at": "2024-06-28T15:45:27Z",
      "closed_at": "2024-06-28T15:45:27Z",
      "labels": [
        "bug",
        "help wanted",
        "core",
        "Driver",
        "HighPrio"
      ],
      "label_count": 5,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/353/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "paulpalmieri",
        "mbrunel",
        "HiImMadness"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/353",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/353",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:38.226314",
      "comments": [
        {
          "author": "lyie28",
          "body": "I've had this issue come up a few times in my tests too",
          "created_at": "2024-06-14T09:35:42Z"
        },
        {
          "author": "paulpalmieri",
          "body": "## Some other insights on this issue. \r\nLaVague fails 5 times in a row on generating the Selenium code to select a very simple visible search bar on `www.target.com`. The Navigation Engine generates the same code five times in a row.\r\n\r\nInstruction: Click on the search bar located at the top of the ",
          "created_at": "2024-06-17T12:56:35Z"
        },
        {
          "author": "paulpalmieri",
          "body": "LaVague fails to select the search bar on: google.com, nike.com, apple.com",
          "created_at": "2024-06-17T13:01:00Z"
        },
        {
          "author": "adeprez",
          "body": "With last changes made by @mbrunel, interaction with the searchbar on puma is now a success.\r\n\r\nOn google, the issue persists but for another reason: the XPath found doesn't matches any element. We'll track this on issue #330 related to wrong targeting.",
          "created_at": "2024-06-28T15:45:27Z"
        }
      ]
    },
    {
      "issue_number": 391,
      "title": "Add video recorder to agent.run() for easier debugging",
      "body": "I think it's useful to record a video of the agent to better understand what it did a posterior.\r\n\r\nI think something like \r\n```python\r\nagent.run(objective=..., record_output=\"recording.mp4\")\r\n```\r\ncould do the job. \r\n\r\nIt does not seem to be hard. \r\n\r\nThere are different ways to do it. Playwright seems to be more straightforward to it, while Selenium is more involved.\r\nHere are the quick [feedback from OpenAI](https://chatgpt.com/share/964987cf-5b50-46f9-81c7-55a8fa11128e) on the topic.\r\n\r\nI guess having methods `start_recording` and `stop_recording` in our `AbstractDriver` and having driver specific implem should do the trick.",
      "state": "open",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-06-27T08:04:22Z",
      "updated_at": "2024-06-27T08:04:41Z",
      "closed_at": null,
      "labels": [
        "help wanted",
        "good first issue",
        "new feature",
        "Agent"
      ],
      "label_count": 4,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/391/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/391",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/391",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:38.398005",
      "comments": []
    },
    {
      "issue_number": 379,
      "title": "Azure OpenAI",
      "body": "Based on documentation (https://docs.lavague.ai/en/latest/docs/action-engine/integrations/api/azure-openai/?h=azure) , this configuration file is required for running LaVague with the Azure OpenAI API:\r\n- https://raw.githubusercontent.com/lavague-ai/LaVague/main/examples/configurations/api/azure_openai.py\r\n\r\nThis configuration file does not exist\r\n\r\nHow to run LaVague with the Azure OpenAI API?\r\n\r\n",
      "state": "closed",
      "author": "edangx101",
      "author_type": "User",
      "created_at": "2024-06-24T13:24:56Z",
      "updated_at": "2024-06-27T02:03:04Z",
      "closed_at": "2024-06-26T13:54:55Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/379/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/379",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/379",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:38.398030",
      "comments": [
        {
          "author": "lyie28",
          "body": "Thanks @edangx101 for pointing this out. That docs link should not be online! We removed direction mentions to these integration but it seems since they weren't removed from the GH repo they are still accessible. I'll remove them fully now.\r\n\r\nTo use LaVague with Azure OpenAI, you can use use the bu",
          "created_at": "2024-06-24T18:45:25Z"
        },
        {
          "author": "edangx101",
          "body": "HI @lyie28, I attempted as suggested:\r\n```\r\nllm= \"gpt-4o\"\r\nmm_llm= \"gpt-4o\"\r\ncontext = AzureOpenaiContext(llm=llm, mm_llm=mm_llm,)\r\n```\r\nBut i ran into this error:\r\n```\r\nERROR - Error while running the agent: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}\r\nActionResult",
          "created_at": "2024-06-25T17:06:00Z"
        },
        {
          "author": "edangx101",
          "body": "Hi @lyie28, \r\n\r\nCannot use Azure OpenAI API with LaVague\r\n\r\n**To Reproduce**\r\nfor OpenAIEmbedding, i used OpenAI API\r\nfor llm and mm_llm, I used Azure OpenAI API\r\n```\r\nfrom lavague.core import WorldModel, ActionEngine\r\nfrom lavague.core.agents import WebAgent\r\nfrom lavague.contexts.openai import Azu",
          "created_at": "2024-06-25T23:12:09Z"
        },
        {
          "author": "lyie28",
          "body": "Sorry I closed the issue on you @edangx101 - I had someone ask the same question on Discord yesterday and we managed to resolve it, so I assumed it was you - but just a coincidence!\r\n\r\nSo basically, your error means there was some issue finding your deployment with the Azure details provided.\r\n\r\nI w",
          "created_at": "2024-06-26T12:48:41Z"
        },
        {
          "author": "edangx101",
          "body": "Thanks! @lyie28 \r\n\r\nI did the following, and the example runs successfully\r\n\r\nInstall:\r\n- pip install llama-index-llms-azure-openai\r\n- pip install llama-index-multi-modal-llms-azure-openai\r\n- pip install llama-index-embeddings-huggingface\r\n\r\nThen run \r\n```python\r\nfrom lavague.core import WorldModel,",
          "created_at": "2024-06-26T13:51:19Z"
        }
      ]
    },
    {
      "issue_number": 369,
      "title": "Add option to Evaluator.compare method so we can optionally select to visualize just 1 or 2 elements of recall, precision & time",
      "body": "By default, the Evaluator.compare method will provide visualization for the compared performance of recall, precision and time taken:\r\n\r\n```\r\ndf = pd.DataFrame()\r\ndf[\"precision\"] = [df[\"precision_retriever\"].mean() for df in results.values()]\r\ndf[\"recall\"] = [df[\"recall_retriever\"].mean() for df in results.values()]\r\ndf[\"time\"] = [df[\"retrieval_time\"].mean() for df in results.values()]\r\ndf[\"name\"] = list(results.keys())\r\n\r\n```\r\n\r\nI would like to add an optional list, where uses call supply any number of these measures so we are not obliged to see all three. For example:\r\n\r\n```\r\nretriever_evaluator.compare(metrics = [\"recall\", \"precision\"], results = {\"default\": default_ret, \"my_custom_retriever\": custom_ret})```\r\n\r\nThis will involve:\r\n- adding optional list argument to compare method\r\n- If this argument is set, adding only the relevant columns to the `df` variable.",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-06-20T08:56:40Z",
      "updated_at": "2024-06-25T17:24:07Z",
      "closed_at": "2024-06-25T17:24:07Z",
      "labels": [
        "help wanted",
        "good first issue"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/369/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/369",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/369",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:38.626645",
      "comments": [
        {
          "author": "jashuajoy",
          "body": "Hi @lyie28, I'm trying to implement this. Pls let me know if my understanding is correct:\r\n\r\n- Users should have the ability to pass in a list of metrics as argument and the compare function should only show those metrics in the figure.\r\n- The new argument must be an optional.\r\n- If this argument is",
          "created_at": "2024-06-20T15:59:14Z"
        },
        {
          "author": "lyie28",
          "body": "Exactly. It is just so users have the option to have a graph for say just recall or just precision. The name column must always be included though.\r\n\r\nWe can do this for the compare methods for both the RetrieverEvaluator and LLMEvaluator :)",
          "created_at": "2024-06-20T16:39:27Z"
        },
        {
          "author": "jashuajoy",
          "body": "ok, I will implement this.",
          "created_at": "2024-06-20T16:48:53Z"
        },
        {
          "author": "jashuajoy",
          "body": "Hi @lyie28, I have created a pull request.",
          "created_at": "2024-06-20T17:15:09Z"
        }
      ]
    },
    {
      "issue_number": 385,
      "title": "Clean datasets for evaluation on The Wave and WebLinx",
      "body": "@HiImMadness : The dataset that we use for eval, [The Wave 250](https://huggingface.co/datasets/BigAction/the-wave-250), is broken:\r\n\r\n![image](https://github.com/lavague-ai/LaVague/assets/36925557/da6c5f7e-3a87-44b5-8aab-735b35098127)\r\n\r\n**Please always ensure datasets are working**.\r\n\r\nAlso, it would be ideal if you upload a different dataset that contains the nodes of our best retriever, with metadata about this retriever if we want to make things more reproducible, so we can directly evaluate an LLM without having to rerun the retriever.\r\nObviously, these examples must contain the ground truth elements to make sure the LLM can find the solution.\r\n\r\nSomething like this would be ideal:\r\n\r\n```python\r\nfrom lavague.core.evaluator import LLMEvaluator\r\nfrom lavague.contexts.openai import OpenaiContext\r\nfrom lavague.core.navigation import NavigationEngine\r\nfrom lavague.drivers.selenium import SeleniumDriver\r\nimport pandas as pd\r\n\r\nllm_test_df = pd.read_parquet(\"hf://datasets/BigAction/the-wave-250-best-retrieved-nodes/data/test-00000-of-00001.parquet\")\r\nopenai_engine = NavigationEngine.from_context(OpenaiContext(), SeleniumDriver())\r\nllm_evaluator = LLMEvaluator() \r\nopenai_results = llm_evaluator.evaluate(openai_engine, retrieved_data_opsm, \"openai_results.csv\")\r\n```\r\n\r\nAlso, optionally it might be better to provide Full XPath to be more consistent as the way to select the ground truth element. I see sometimes different selectors, which can work but be ambiguous or inconsistent in some scenarios.\r\n\r\nTodo:\r\n- [ ] Fix The Wave 250\r\n- [ ] Prepare a dataset for fast LLM Evaluation with already retrieved node\r\n- [ ] Make data more consistent",
      "state": "closed",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-06-25T08:20:02Z",
      "updated_at": "2024-06-25T15:28:21Z",
      "closed_at": "2024-06-25T15:28:21Z",
      "labels": [
        "BigAction",
        "Datasets"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/385/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/385",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/385",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:38.835751",
      "comments": [
        {
          "author": "lyie28",
          "body": "Datasets now uploading in classic parquet format:\r\n\r\nRaw dataset: https://huggingface.co/datasets/BigAction/the-meta-wave-raw\r\nPre-processed dataset for Retriever evaluation: https://huggingface.co/datasets/BigAction/the-meta-wave-rewritten\r\nRetrieved dataset for LLM evaluation: https://huggingface.",
          "created_at": "2024-06-25T15:28:21Z"
        }
      ]
    },
    {
      "issue_number": 358,
      "title": "Chrome extension driver",
      "body": "We are doing an MVP of Chrome extension where end users can consume web agents defined by devs.\r\n\r\nThe interface should \r\n\r\n```python\r\nfrom lavague.core import  WorldModel, ActionEngine\r\nfrom lavague.core.agents import WebAgent\r\nfrom lavague.core.server import AgentServer\r\nfrom lavague.core.extractors import JsonFromMarkdownExtractor\r\nfrom lavague.drivers.selenium.base import SeleniumDriver\r\nfrom lavague.drivers.remote import RemoteDriver\r\n\r\ndriver = DriverServer()\r\nworld_model = WorldModel()\r\naction_engine = ActionEngine(driver, extractor=JsonFromMarkdownExtractor())\r\nagent = WebAgent(world_model, action_engine)\r\nserver = AgentServer(agent)\r\nserver.serve()\r\n```\r\n\r\nIn that scenario, the workflow is:\r\n- The dev launches a server\r\n- The client with Chrome Extension connects to it\r\n- The client provides an objective and run it\r\n- The Chrome is piloted by the `Agent Server`\r\n\r\nTo do:\r\n- [ ] Interface Chrome \r\n- [ ] Publish on Marketplace\r\n- [ ] Extensive testing on our different use cases\r\n- [ ] Integrate the server class",
      "state": "closed",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-06-17T16:57:27Z",
      "updated_at": "2024-06-25T15:18:15Z",
      "closed_at": "2024-06-20T16:47:30Z",
      "labels": [
        "core",
        "Driver",
        "HighPrio"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/358/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "adeprez",
        "JoFrost"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/358",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/358",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:39.073512",
      "comments": [
        {
          "author": "adeprez",
          "body": "The agent server uses a builder to manage multiple simultaneous connections, and thus multiple agents\n\n```python\nfrom lavague.core import WorldModel, ActionEngine\nfrom lavague.core.agents import WebAgent\nfrom lavague.drivers.driverserver import DriverServer\nfrom lavague.server import AgentServer, Ag",
          "created_at": "2024-06-25T15:18:14Z"
        }
      ]
    },
    {
      "issue_number": 360,
      "title": "Add option to Selenium Driver that accepts a `selenium.webdriver.chrome.options` options argument",
      "body": "Optionally, users should be able to provide an `options` argument that will be passed to our webdriver in the SeleniumDriver `init` method.\r\n\r\nFile to be updated: `LaVague/tree/main/lavague-integrations/drivers/lavague-drivers-selenium/lavague/drivers/selenium/base.py`\r\n\r\nMethod to be updated: `def default_init_code(self) -> Any:`\r\n \r\n Task details: If `options` provided, pass this to webdriver instead of instantiating our own Options().",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-06-18T08:47:51Z",
      "updated_at": "2024-06-25T08:41:33Z",
      "closed_at": "2024-06-25T08:41:33Z",
      "labels": [
        "good first issue",
        "community-assigned",
        "Driver"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/360/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "shawon-majid"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/360",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/360",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:39.277046",
      "comments": [
        {
          "author": "shawon-majid",
          "body": "Hi, the issue looks simple, I'm new to open source, as I've understand the issue:\r\n1. I need to import Options from selenium chrome webdriver\r\n2. need to pass an optional parameter for options in the init method for object instantiation\r\n3. also assign the options in the self (as class variable)\r\n4.",
          "created_at": "2024-06-19T16:46:54Z"
        },
        {
          "author": "lyie28",
          "body": "@shawon-majid - yes that's it. The import should already be in the code but for the other steps, yes, that should be it :)",
          "created_at": "2024-06-19T16:52:16Z"
        },
        {
          "author": "JoFrost",
          "body": "Merged",
          "created_at": "2024-06-25T08:41:33Z"
        }
      ]
    },
    {
      "issue_number": 375,
      "title": "Do not re index the whole current page if nothing much has changed in the Navigation Engine",
      "body": "Today the `Navigation Engine` re indexes the current page for each request.\r\nSome pages, for instance forms, might require to do several calls before moving to a totally new page.\r\n\r\nIt would make sense that if we don't change URL, we only look at the delta of HTML after an action (for instance clicking on a search bar) and only reindex those, and add them to the index.\r\n\r\n@HiImMadness / @adeprez what do you think?",
      "state": "open",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-06-24T07:55:06Z",
      "updated_at": "2024-06-24T09:28:51Z",
      "closed_at": null,
      "labels": [
        "help wanted",
        "good first issue",
        "ActionEngine"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/375/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/375",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/375",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:39.523022",
      "comments": [
        {
          "author": "adeprez",
          "body": "We can make use of the [MutationObserver](https://developer.mozilla.org/en-US/docs/Web/API/MutationObserver) to detect DOM changes and reindex only updated nodes",
          "created_at": "2024-06-24T09:28:50Z"
        }
      ]
    },
    {
      "issue_number": 365,
      "title": "Rewriting of Agent to have better variable and output management",
      "body": "The `Agent` class currently has two issues:\r\n- The `WorldModel` sometimes uses OCR directly and stops there. However, it might be better to not end on an OCR output but have the agent write to some memory (which we call [agent_outputs](https://github.com/lavague-ai/LaVague/blob/main/lavague-core/lavague/core/memory.py) so that this output can be consumed by another tool. For instance, we might want to send an email containing the output of a demand to fetch some information on a website.\r\n- The `WorldModel` sometimes calls the `PythonEngine` to extract information on a given page. However, because it is called after and is asked to provide an output, it sometimes does not fully output what was meant to be provided. This is mentioned in #344. To solve this, the agent should end by providing the name of the variable that contains the answer, instead of asking an LLM to read the content of the variables the agent has access to and writing down in a next token manner. This is both expensive as we consume a lot of LLM output tokens, but can also be imprecise.\r\n\r\nTo solve both issues we should:\r\n1. Create a specific instruction, like WRITE_MEMORY for the `Agent` to write in memory information from a direct OCR call\r\n2. Have the agent only end with an output by providing the name of the variable that contains the information.\r\n\r\n",
      "state": "open",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-06-19T10:33:41Z",
      "updated_at": "2024-06-24T04:50:58Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "help wanted",
        "good first issue",
        "Agent",
        "HighPrio"
      ],
      "label_count": 5,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/365/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/365",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/365",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:39.779427",
      "comments": []
    },
    {
      "issue_number": 347,
      "title": "AgentOps Integration",
      "body": null,
      "state": "open",
      "author": "AtomSilverman",
      "author_type": "User",
      "created_at": "2024-06-14T05:28:47Z",
      "updated_at": "2024-06-18T12:37:47Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "help wanted"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/347/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/347",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/347",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:41.539703",
      "comments": [
        {
          "author": "lyie28",
          "body": "Thanks for the suggestion. We'll have a look into it! @dhuynh95 : https://github.com/AgentOps-AI/agentops",
          "created_at": "2024-06-14T10:02:59Z"
        }
      ]
    },
    {
      "issue_number": 197,
      "title": "Using local configuration deepseekcoder.py return Expected all tensors to be on the same device, but found at least two devices",
      "body": "**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. lavague -i examples/instructions/huggingface.yaml -c examples/configurations/local/deepseek-coder.py launch\r\n2. Accees url or share link\r\n3. enter instructions\r\n4. See error. No code or actions performed.\r\nTraceback (most recent call last):\r\n  File \"/LaVague/venv_lv/lib/python3.11/site-packages/gradio/queueing.py\", line 501, in call_prediction\r\n    output = await route_utils.call_process_api(\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/LaVague/venv_lv/lib/python3.11/site-packages/gradio/route_utils.py\", line 253, in call_process_api\r\n    output = await app.get_blocks().process_api(\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/LaVague/venv_lv/lib/python3.11/site-packages/gradio/blocks.py\", line 1695, in process_api\r\n    result = await self.call_function(\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/gradio/blocks.py\", line 1247, in call_function\r\n    prediction = await utils.async_iteration(iterator)\r\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/gradio/utils.py\", line 516, in async_iteration\r\n    return await iterator.__anext__()\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/gradio/utils.py\", line 509, in __anext__\r\n    return await anyio.to_thread.run_sync(\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/anyio/to_thread.py\", line 56, in run_sync\r\n    return await get_async_backend().run_sync_in_worker_thread(\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 2144, in run_sync_in_worker_thread\r\n    return await future\r\n           ^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 851, in run\r\n    result = context.run(func, *args)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/gradio/utils.py\", line 492, in run_sync_iterator_async\r\n    return next(iterator)\r\n           ^^^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/gradio/utils.py\", line 675, in gen_wrapper\r\n    response = next(iterator)\r\n               ^^^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/lavague/command_center.py\", line 65, in process_instructions_impl\r\n    for text in self.actionEngine.get_action_streaming(query, state):\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/lavague/action_engine.py\", line 116, in get_action_streaming\r\n    streaming_response = query_engine.query(query)\r\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/llama_index/core/base/base_query_engine.py\", line 40, in query\r\n    return self._query(str_or_query_bundle)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/llama_index/core/query_engine/retriever_query_engine.py\", line 186, in _query\r\n    nodes = self.retrieve(query_bundle)\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/llama_index/core/query_engine/retriever_query_engine.py\", line 142, in retrieve\r\n    nodes = self._retriever.retrieve(query_bundle)\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/llama_index/core/base/base_retriever.py\", line 229, in retrieve\r\n    nodes = self._retrieve(query_bundle)\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/lavague/retrievers.py\", line 28, in _retrieve\r\n    return self.html_retriever._retrieve_html(self.html, query_bundle)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/lavague/retrievers.py\", line 309, in _retrieve_html\r\n    results = self._get_results(html, query.query_str)\r\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/lavague/retrievers.py\", line 220, in _get_results\r\n    index = VectorStoreIndex(nodes, embed_model=self.embedder)\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/llama_index/core/indices/vector_store/base.py\", line 74, in __init__\r\n    super().__init__(\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/llama_index/core/indices/base.py\", line 94, in __init__\r\n    index_struct = self.build_index_from_nodes(\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/llama_index/core/indices/vector_store/base.py\", line 307, in build_index_from_nodes\r\n    return self._build_index_from_nodes(nodes, **insert_kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/llama_index/core/indices/vector_store/base.py\", line 279, in _build_index_from_nodes\r\n    self._add_nodes_to_index(\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/llama_index/core/indices/vector_store/base.py\", line 232, in _add_nodes_to_index\r\n    nodes_batch = self._get_node_with_embedding(nodes_batch, show_progress)\r\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/llama_index/core/indices/vector_store/base.py\", line 140, in _get_node_with_embedding\r\n    id_to_embed_map = embed_nodes(\r\n                      ^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/llama_index/core/indices/utils.py\", line 138, in embed_nodes\r\n    new_embeddings = embed_model.get_text_embedding_batch(\r\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/llama_index/core/base/embeddings/base.py\", line 255, in get_text_embedding_batch\r\n    embeddings = self._get_text_embeddings(cur_batch)\r\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/llama_index/embeddings/huggingface/base.py\", line 204, in _get_text_embeddings\r\n    return self._embed(texts)\r\n           ^^^^^^^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/llama_index/embeddings/huggingface/base.py\", line 161, in _embed\r\n    model_output = self._model(**encoded_input)\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py\", line 981, in forward\r\n    embedding_output = self.embeddings(\r\n                       ^^^^^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py\", line 207, in forward\r\n    inputs_embeds = self.word_embeddings(input_ids)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/torch/nn/modules/sparse.py\", line 163, in forward\r\n    return F.embedding(\r\n           ^^^^^^^^^^^^\r\n  File \" /LaVague/venv_lv/lib/python3.11/site-packages/torch/nn/functional.py\", line 2264, in embedding\r\n    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:3 and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)\r\n\r\n\r\n**Expected behavior**\r\nNo error and actions performed for the instructions\r\n\r\n",
      "state": "closed",
      "author": "alexsiu398",
      "author_type": "User",
      "created_at": "2024-05-03T03:36:44Z",
      "updated_at": "2024-06-18T12:33:42Z",
      "closed_at": "2024-06-18T12:33:42Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/197/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "JoFrost",
        "dhuynh95",
        "HiImMadness"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/197",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/197",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:41.746120",
      "comments": [
        {
          "author": "lyie28",
          "body": "Hey @alexsiu398 - sorry we never got back to you before. We could not replicate your previous errors.\r\n\r\nHowever, have you tried deepseekcoder with the latest package. The codebase has changed a lot since your last message.\r\n\r\nI just tested with deepseekcoder and it at least seems to work with some ",
          "created_at": "2024-06-11T16:32:43Z"
        },
        {
          "author": "lyie28",
          "body": "I will close this issue for now since it is an old one now- feel free to ping us on Discord or on your more recent issue to discuss further.",
          "created_at": "2024-06-18T12:33:42Z"
        }
      ]
    },
    {
      "issue_number": 224,
      "title": "Debugging guide for users",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-05-15T12:34:32Z",
      "updated_at": "2024-06-18T11:54:50Z",
      "closed_at": "2024-06-18T11:54:49Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/224/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "paulpalmieri"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/224",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/224",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:41.961450",
      "comments": [
        {
          "author": "paulpalmieri",
          "body": "Related to https://github.com/lavague-ai/LaVague/issues/241",
          "created_at": "2024-05-21T10:13:25Z"
        },
        {
          "author": "lyie28",
          "body": "Debugging guide available here: https://docs.lavague.ai/en/latest/docs/learn/debugging/",
          "created_at": "2024-06-18T11:54:49Z"
        }
      ]
    },
    {
      "issue_number": 158,
      "title": "Add docstring to the codebase",
      "body": null,
      "state": "open",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-23T15:22:14Z",
      "updated_at": "2024-06-18T09:00:33Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "help wanted",
        "core"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/158/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/158",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/158",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:42.197327",
      "comments": [
        {
          "author": "shubhamofbce",
          "body": "This is very very important, if we are planning to bring more contributors from the community. We need proper docstrings as well as comments for any logic that is not straight forward.",
          "created_at": "2024-04-23T16:08:35Z"
        },
        {
          "author": "lyie28",
          "body": "I agree. I am off for the rest of the week so I won't be able to add any until next week now. If you want to have a go at any, feel free to create a PR - at the latest, I will review on Monday when I am back in the office.",
          "created_at": "2024-04-23T17:28:28Z"
        },
        {
          "author": "ayemrsavage",
          "body": "seems doable ",
          "created_at": "2024-05-24T21:55:20Z"
        },
        {
          "author": "tharunarasu",
          "body": "Hi @lyie28 @shubhamofbce   I would like to work on adding docstrings contribute to LaVague and loved the vision. If anyone can explain on the objective I can start actively contributing.",
          "created_at": "2024-05-27T12:26:20Z"
        },
        {
          "author": "shubhamofbce",
          "body": "@tharunarasu The objective is very simple. We just need to add docstrings to each and every class and method. You can start with a specific module and then cover the whole repo. This will help future contributors to understand classes and methods easily.",
          "created_at": "2024-05-27T12:35:52Z"
        }
      ]
    },
    {
      "issue_number": 94,
      "title": "Is it possible to generate for other languages? (Java, Javascript, Typescript...)?",
      "body": "I've tried to change code & rebuild for supporting Java, but it thrown error because Java doesn't support by Gradio component. Can you please give guideline to how to support other language (e,g: javascript) ?\r\n\r\n**gradio/components/code.py**\r\n```\r\n    languages = [\r\n        \"python\",\r\n        \"markdown\",\r\n        \"json\",\r\n        \"html\",\r\n        \"css\",\r\n        \"javascript\",\r\n        \"typescript\",\r\n        \"yaml\",\r\n        \"dockerfile\",\r\n        \"shell\",\r\n        \"r\",\r\n        \"sql\",\r\n        \"sql-msSQL\",\r\n        \"sql-mySQL\",\r\n        \"sql-mariaDB\",\r\n        \"sql-sqlite\",\r\n        \"sql-cassandra\",\r\n        \"sql-plSQL\",\r\n        \"sql-hive\",\r\n        \"sql-pgSQL\",\r\n        \"sql-gql\",\r\n        \"sql-gpSQL\",\r\n        \"sql-sparkSQL\",\r\n        \"sql-esper\",\r\n        None,\r\n    ]\r\n\r\n```",
      "state": "closed",
      "author": "trongtran",
      "author_type": "User",
      "created_at": "2024-04-04T02:29:21Z",
      "updated_at": "2024-06-18T09:00:12Z",
      "closed_at": "2024-06-18T09:00:12Z",
      "labels": [
        "enhancement",
        "question"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/94/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/94",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/94",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:42.392446",
      "comments": [
        {
          "author": "lyie28",
          "body": "Hi @trongtran, to generate the code in Java/JavaScript/Typescript leveraging Selenium, I  would recommend focusing on generating the code with the 'lavague-build' command. You can then execute the generated code directly locally. Note you should remove the 'headless' option from the generated code i",
          "created_at": "2024-04-04T09:09:30Z"
        },
        {
          "author": "trongtran",
          "body": "@lyie28 Thank you for your comment. I will review it and follow your suggestion to try it, and I'll update you with the results later.",
          "created_at": "2024-04-04T09:18:15Z"
        },
        {
          "author": "lyie28",
          "body": "Oh and you'll also need to add and use a new cleaning function as we clean the generated code to get to the first bit of python code by default\r\nYou can just define a new cleaning function in your config file, see docs on how to do this here: https://docs.lavague.ai/en/latest/docs/get-started/custom",
          "created_at": "2024-04-04T09:31:35Z"
        },
        {
          "author": "lyie28",
          "body": "Will close this one for now since there has not been any new activity for a while. Feel free to join us on Discord to discuss further!",
          "created_at": "2024-06-18T09:00:12Z"
        }
      ]
    },
    {
      "issue_number": 361,
      "title": "Dynamic prompt template builder for drivers",
      "body": "Selenium and Playwright drivers currently use a static prompt template. To increase flexibility, we propose a dynamic prompt builder.\r\n\r\n\r\nFeatures:\r\n- Add / remove examples\r\n- Add / remove instructions\r\n\r\nImplementation:\r\n- Develop a prompt template builder class\r\n- Ensure compatibility with both Selenium and Playwright drivers",
      "state": "open",
      "author": "adeprez",
      "author_type": "User",
      "created_at": "2024-06-18T08:49:03Z",
      "updated_at": "2024-06-18T08:49:30Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Driver"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/361/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/361",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/361",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:42.597424",
      "comments": []
    },
    {
      "issue_number": 287,
      "title": "Track cost & have possibilities to put a token limit/ document number of retries limits too",
      "body": "Idea: Improve features/docs around cost limitations and adding some kind of limit for token usage ",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-06-03T08:19:32Z",
      "updated_at": "2024-06-18T07:17:26Z",
      "closed_at": "2024-06-18T07:17:25Z",
      "labels": [
        "help wanted"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/287/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/287",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/287",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:42.597445",
      "comments": [
        {
          "author": "lyie28",
          "body": "Retries now documented and tracking of token usage/cost duplicated by issue #355 ",
          "created_at": "2024-06-18T07:17:25Z"
        }
      ]
    },
    {
      "issue_number": 273,
      "title": "Add in the logger token consumption ",
      "body": "We now have a logger with `df = agent.logger.return_pandas()`\r\n\r\nIt does not log yet the amount of tokens consumed by the `llm` and `mm_llm`. It could be good to record these for people to reduce their consumption on OpenAI ^^\r\n\r\nI guess we could use [observability tooling from llama_index](https://docs.llamaindex.ai/en/stable/module_guides/observability/) as we are leveraging their wrappers.",
      "state": "closed",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-05-29T11:54:31Z",
      "updated_at": "2024-06-18T07:16:31Z",
      "closed_at": "2024-06-18T07:16:17Z",
      "labels": [
        "enhancement",
        "help wanted",
        "good first issue",
        "new feature"
      ],
      "label_count": 4,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/273/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/273",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/273",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:42.795490",
      "comments": [
        {
          "author": "lyie28",
          "body": "Duplicated by issue #355 ",
          "created_at": "2024-06-18T07:16:17Z"
        }
      ]
    },
    {
      "issue_number": 7,
      "title": "Create browser extension inspired by parts of Selenium IDE",
      "body": "-> Specs: doesn't require developer mode",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-03-12T17:26:26Z",
      "updated_at": "2024-06-18T04:35:53Z",
      "closed_at": "2024-06-18T04:35:53Z",
      "labels": [
        "new feature"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/7/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "JoFrost",
        "mbrunel"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/7",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/7",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:42.987526",
      "comments": [
        {
          "author": "retsamcam",
          "body": "This would be interesting",
          "created_at": "2024-03-16T10:08:21Z"
        },
        {
          "author": "shivamsharma00",
          "body": "I would like to work on this issue.",
          "created_at": "2024-04-24T19:51:19Z"
        },
        {
          "author": "lyie28",
          "body": "@dhuynh95 @mbrunel",
          "created_at": "2024-04-24T21:54:09Z"
        },
        {
          "author": "lyie28",
          "body": "@shivamsharma00 That would be awesome! Are you on our Discord server? It would be great to schedule a quick call to discuss this with you",
          "created_at": "2024-04-29T19:02:03Z"
        },
        {
          "author": "shivamsharma00",
          "body": "> r\r\n\r\nHey @lyie28 I am on discord server, my username is \"galeetch\". Let us schedule a quick call to discuss this.",
          "created_at": "2024-04-30T18:34:28Z"
        }
      ]
    },
    {
      "issue_number": 346,
      "title": "ActionEngine.from_context() missing some options",
      "body": " The ActionEngine.from_context() method should have all the options as the default constructor. \r\n \r\n The missing options need to be added to the from_context() method.",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-06-13T19:33:57Z",
      "updated_at": "2024-06-18T04:33:55Z",
      "closed_at": "2024-06-18T04:33:55Z",
      "labels": [
        "community-assigned"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/346/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/346",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/346",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:43.230143",
      "comments": [
        {
          "author": "aaronted009",
          "body": "Hello, if I'm getting it right, you want the `ActionEngine.from_context()` to have all parameters as `ActionEngine` default constructor. Is that right?",
          "created_at": "2024-06-13T21:42:03Z"
        },
        {
          "author": "lyie28",
          "body": "@aaronted009 Yes, exactly. But, actually, it will not need the LLM or embedding, since they are defined in the context.\r\n\r\nBut it is lacking:\r\n\r\ntime_between_actions: float = 1.5,\r\nn_attempts: int = 5,\r\nlogger: AgentLogger = None,",
          "created_at": "2024-06-14T08:01:57Z"
        },
        {
          "author": "aaronted009",
          "body": "Alright, I can do the update if that's ok",
          "created_at": "2024-06-14T12:51:33Z"
        },
        {
          "author": "lyie28",
          "body": "Great! Will mark is as assigned :)",
          "created_at": "2024-06-14T16:45:10Z"
        },
        {
          "author": "aaronted009",
          "body": "Hello @lyie28, I made a PR. Do you mind taking a look?",
          "created_at": "2024-06-14T22:03:01Z"
        }
      ]
    },
    {
      "issue_number": 258,
      "title": "Add caching when using API like GPT4o or Gemini",
      "body": "We are aware (and sorry) that the default option is OpenAI for our open-source framework but it is currently the only working solution for the `WorldModel`.\r\n\r\nWe do realize it takes a toll on your credits so I think an immediate and temporary solution is to provide caching to reduce calls.\r\n\r\nI looked at [GPTCache](https://github.com/zilliztech/GPTCache) but it is outdated and does not support OpenAI 1.X.\r\nThey have an old PR from [March](https://github.com/zilliztech/GPTCache/pull/614) that could work.\r\n\r\nIs someone interested in making their PR work and integrate it in LaVague? Thanks!",
      "state": "closed",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-05-27T05:12:07Z",
      "updated_at": "2024-06-17T10:44:16Z",
      "closed_at": "2024-06-17T10:44:15Z",
      "labels": [
        "enhancement",
        "help wanted",
        "good first issue",
        "new feature",
        "community-assigned"
      ],
      "label_count": 5,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/258/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "alhridoy"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/258",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/258",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:43.451343",
      "comments": [
        {
          "author": "alhridoy",
          "body": "Hi @dhuynh95 , would love to work on the issue. You could assign me for that! ",
          "created_at": "2024-05-27T07:26:04Z"
        },
        {
          "author": "dhuynh95",
          "body": "Hi @alhridoy!\r\nThat would be great! Do you need help for this? I think it's pretty orthogonal based on how they designed but if we can help we would be happy to",
          "created_at": "2024-05-27T15:48:57Z"
        },
        {
          "author": "alhridoy",
          "body": "> Hi @alhridoy! That would be great! Do you need help for this? I think it's pretty orthogonal based on how they designed but if we can help we would be happy to\r\n\r\n I have a few technical questions to ensure a smooth integration:\r\n\r\n**Cache Initialization:**\r\n\r\nIs there a preferred location or modu",
          "created_at": "2024-05-28T05:36:52Z"
        },
        {
          "author": "dhuynh95",
          "body": "**Cache initializaiton**\r\n\r\nI guess we could do it at the agent level, where we could have an option for using caching.\r\nWe also have contexts to package some configurations. You can find the OpenAI context [here](https://github.com/lavague-ai/LaVague/blob/main/lavague-integrations/contexts/lavague-",
          "created_at": "2024-05-28T06:18:11Z"
        }
      ]
    },
    {
      "issue_number": 332,
      "title": "add easier wrapper method to get nodes (from Logger)",
      "body": "Currently in order to display the nodes retrieved for previous actions, you have to run something like:\r\n\r\n```python\r\ndf_logs = agent.logger.return_pandas()\r\n\r\n# Print the code generated for step 0 of our run\r\nstep = 0\r\n\r\nfrom IPython.display import display, HTML, Code\r\n\r\n# An instruction can be split into sub-instructions by the rephraser, but in this case there is just one instruction\r\nsub_instruction = 0\r\nx = 0\r\nfor node in df_logs.at[step, 'engine_log'][sub_instruction]['retrieved_html']:\r\n    print(f\"node {x}\")\r\n    x = x + 1\r\n    display(HTML(node)) # Display node as visual element\r\n    display(Code(node, language=\"html\")) # Display code\r\n```\r\n\r\nThis doesn't seem very user-friendly considering it could be a commonly used debugging feature.\r\n\r\nI think we could have an easier method, at either an agent, action engine or navigation engine level:\r\n\r\nSomething like: \r\n```python\r\nagent.display_last_nodes(step: x)\r\n```\r\nor `navigation_engine.display_last_nodes()` - I guess agent might be easier for accessing the log?\r\n\r\nIf there are multiple sub-instructions it should print out the nodes for all of them.",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-06-10T16:47:35Z",
      "updated_at": "2024-06-13T09:23:41Z",
      "closed_at": "2024-06-13T09:23:41Z",
      "labels": [
        "good first issue",
        "community-assigned"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/332/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/332",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/332",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:43.619156",
      "comments": [
        {
          "author": "jashuajoy",
          "body": "I'm found a way to implement this.",
          "created_at": "2024-06-12T15:04:03Z"
        }
      ]
    },
    {
      "issue_number": 335,
      "title": "Built-in export options",
      "body": "Built in export options for any of the following:\r\n- FastAPI - option to wrap all code generated by the LLM into a file to launch code in a FastAPI server\r\n- Docker - option to wrap all code generated by the LLM into files to build a Docker application to run code\r\n- Pytest file - code generated wrapped into a pytest file - we wrote some code for this here, but needs to be integrated into the code base - perhaps in an exports.py file - https://docs.lavague.ai/en/latest/docs/examples/qa-automation/",
      "state": "open",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-06-11T10:28:44Z",
      "updated_at": "2024-06-12T16:07:57Z",
      "closed_at": null,
      "labels": [
        "help wanted",
        "Integrations"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/335/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/335",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/335",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:43.795407",
      "comments": []
    },
    {
      "issue_number": 333,
      "title": "Integrate pytest file export from QA example into codebase as export option in a exports.py module",
      "body": "We recently provided an example with some code to transform code generated by LaVague into a pytest file for testing: https://docs.lavague.ai/en/latest/docs/examples/qa-automation/\r\n\r\nI think it would be nice to add this into an exports.py file as a first export option integrated within the codebase rather than having a script.",
      "state": "open",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-06-11T09:52:51Z",
      "updated_at": "2024-06-12T16:04:39Z",
      "closed_at": null,
      "labels": [
        "help wanted",
        "good first issue",
        "new feature",
        "Integrations"
      ],
      "label_count": 4,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/333/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/333",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/333",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:43.795429",
      "comments": []
    },
    {
      "issue_number": 254,
      "title": "Ensure Abstract driver is up to date to work with Selenium and Playwright",
      "body": "While we have had Playwright support initially (https://github.com/lavague-ai/LaVague/tree/main/lavague-integrations/drivers/lavague-drivers-playwright), I am not sure it's up to date.\r\n\r\nWe have been focusing on Selenium recently because it was easier to use with Gradio and in Jupyter.\r\n\r\nHowever, I think it could be good to start using [`AbstractDriver`](https://github.com/lavague-ai/LaVague/blob/main/lavague-core/lavague/core/base_driver.py#L9) more in our codebase, that would make it compatible with both Selenium and Playwright.\r\n\r\nIndeed, now that we have an agent, it could be great to bench it with environments such as [BrowserGym](https://github.com/ServiceNow/BrowserGym) which assumes the use of Playwright.\r\n\r\nI have to confess I have been a bit hacking stuff and used Selenium as a default, but I realize it would be better we abstract more our codebase for better integrations.\r\n\r\nSo, could someone help in:\r\n\r\n- [ ] Making sure the `AbstractDriver` class has the same methods as Selenium (is it actually a good idea that the abstract class has the same methods? I was thinking I like the methods of Selenium but don't know if it makes sense)\r\n- [ ] Ensure the driver we wrote with Playwright works with the current stack\r\n- [ ] Update the prompt template of Playwright\r\n- [ ] Ensure all the codebase uses proper abstract drivers\r\n\r\nCommunity help would be appreciated :)",
      "state": "closed",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-05-25T13:44:18Z",
      "updated_at": "2024-06-12T15:04:52Z",
      "closed_at": "2024-06-12T15:04:52Z",
      "labels": [
        "enhancement",
        "help wanted",
        "Driver"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/254/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/254",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/254",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:43.795437",
      "comments": [
        {
          "author": "lyie28",
          "body": "Was all this covered by your work @mbrunel ? If so, I will close this",
          "created_at": "2024-06-11T15:07:39Z"
        }
      ]
    },
    {
      "issue_number": 217,
      "title": "Agent output repetition",
      "body": "Just a small thing, but we have 2 x \"Thoughts:\" in our output here:\r\n\r\n![double-thoughts](https://github.com/lavague-ai/LaVague/assets/52970539/48965f27-5215-4a30-8c03-7e7e18468555)",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-05-13T22:24:59Z",
      "updated_at": "2024-06-11T15:09:44Z",
      "closed_at": "2024-06-11T15:09:43Z",
      "labels": [
        "bug",
        "Agent"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/217/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/217",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/217",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:43.972260",
      "comments": [
        {
          "author": "lyie28",
          "body": "Fixed in more recent versions",
          "created_at": "2024-06-11T15:09:43Z"
        }
      ]
    },
    {
      "issue_number": 116,
      "title": "Error in code execution: 'WebElement' object has no attribute 'select_by_value'",
      "body": "**Describe the bug**\r\nIt seems that the generated code is trying to call specific function from the Select class (select_by_value), but driver.find_element function returns a WebElement class. It's missing the conversion to the Select class.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to 'https://ticketsmuseums.comune.fi.it/1_museo-di-palazzo-vecchio/'\r\n2. Type in instruction: select 1 whole ticket' and run the query\r\n3. see generated code below:\r\n\r\n```\r\n# Let's proceed step by step.\r\n# First we need to identify the select element for whole tickets and choose the option with value '1'.\r\n\r\n# Based on the HTML provided, the select element for whole tickets can be identified using the name \"search_museo_int\"\r\n# Let's use this name with Selenium to identify the select element\r\nselect_whole_tickets = driver.find_element(By.XPATH, \"//select[@name='search_museo_int']\")\r\n\r\n# Then we select the option with value '1'\r\nselect_whole_tickets.select_by_value('1')\r\n```\r\nand error `Error in code execution: 'WebElement' object has no attribute 'select_by_value'`\r\n\r\n**Expected behavior**\r\nGenerate and run the following code:\r\n```\r\nfrom selenium.webdriver.support.ui import Select\r\nselect_whole_tickets = Select(driver.find_element(By.XPATH, \"//select[@name='search_museo_int']\"))\r\n\r\n# Then we select the option with value '1'\r\nselect_whole_tickets.select_by_value('1')\r\n```\r\n\r\n**Work Around**\r\nAdd Select class to the `action_engine.py` imports works, probably need other classes of the sort as well.\r\n",
      "state": "closed",
      "author": "y22ma",
      "author_type": "User",
      "created_at": "2024-04-15T19:29:54Z",
      "updated_at": "2024-06-11T13:08:29Z",
      "closed_at": "2024-06-11T13:03:31Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/116/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "dhuynh95",
        "mbrunel",
        "HiImMadness"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/116",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/116",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:44.180084",
      "comments": [
        {
          "author": "lyie28",
          "body": "Hey there @y22ma  - sorry for the delay in getting back to you.\r\n\r\nThe codebase has changed and been improved quite a bit since you opened this, and your example now works - I just added a museum name so the agent knows which museum to select a ticket for :)\r\n\r\n```python\r\nfrom lavague.drivers.seleni",
          "created_at": "2024-06-11T13:03:31Z"
        }
      ]
    },
    {
      "issue_number": 169,
      "title": "convert research dataset for LaVague",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-29T09:48:53Z",
      "updated_at": "2024-06-11T10:11:16Z",
      "closed_at": "2024-06-11T10:11:16Z",
      "labels": [
        "AI-performance",
        "BigAction"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/169/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "HiImMadness"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/169",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/169",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:44.382613",
      "comments": [
        {
          "author": "lyie28",
          "body": "This dataset: https://mcgill-nlp.github.io/weblinx/\r\nWas converted to: https://huggingface.co/datasets/BigAction/the-wave-250",
          "created_at": "2024-06-11T10:11:16Z"
        }
      ]
    },
    {
      "issue_number": 159,
      "title": "Add playwright_ground_truth row to BigAction/the-wave-clean",
      "body": "**Is your feature request related to a problem? Please describe.**\r\nWe need a playwright ground truth row in the wave clean dataset to evaluate playwright scripts. \r\n\r\n**Describe the solution you'd like**\r\nI would like a row similar like selenium_ground_truth for playwright_ground_truth\r\n\r\n**Describe alternatives you've considered**\r\nNA\r\n\r\n**Additional context**\r\nNA\r\n",
      "state": "closed",
      "author": "shubhamofbce",
      "author_type": "User",
      "created_at": "2024-04-23T16:19:40Z",
      "updated_at": "2024-06-11T10:09:24Z",
      "closed_at": "2024-06-11T10:09:23Z",
      "labels": [
        "community-assigned"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/159/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "shubhamofbce"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/159",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/159",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:44.614618",
      "comments": [
        {
          "author": "lyie28",
          "body": "@dhuynh95 @HiImMadness this one is for you guys!",
          "created_at": "2024-04-23T17:49:25Z"
        },
        {
          "author": "shubhamofbce",
          "body": "@lyie28 I discussed this with @dhuynh95 on discord, I will be taking this up. ",
          "created_at": "2024-04-23T18:28:31Z"
        },
        {
          "author": "shubhamofbce",
          "body": "Not sure, how to contribute to dataset so just created a new sheet with playwright ground truth for all queries in the dataset\r\nhttps://docs.google.com/spreadsheets/d/1xwopMgt1oE91ZdhkpiX-0gPScbOM5hyM3CvRMJr8kD0/edit?usp=sharing",
          "created_at": "2024-04-25T19:41:06Z"
        },
        {
          "author": "lyie28",
          "body": "@shubhamofbce Should I close this one now?",
          "created_at": "2024-06-10T13:29:58Z"
        },
        {
          "author": "shubhamofbce",
          "body": "This is still open, I have created a PR on huggingface dataset which Daniel needs to review and merge.\r\nhttps://huggingface.co/datasets/BigAction/the-wave-clean/discussions/4",
          "created_at": "2024-06-10T17:38:53Z"
        }
      ]
    },
    {
      "issue_number": 161,
      "title": "Avoid cleaning Input attributes from html",
      "body": "**Describe the bug**\r\nWe need to avoid cleaning input attributes like placeholder, type and all. They are important for the agent.\r\n\r\n**To Reproduce**\r\nAdd a query to search any input by placeholder, action engine fails as the input attribute was cleaned.\r\n\r\n**Expected behavior**\r\nInput attributes must not be cleaned\r\n```python\r\ninput_attributes = [\"accept\", \"alt\", \"checked\", \"disabled\", \"height\", \"max\", \"maxlength\", \"min\",\r\n                    \"multiple\", \"pattern\", \"placeholder\", \"readonly\", \"required\", \"size\", \"src\",\r\n                    \"step\", \"type\", \"value\", \"width\"]\r\n```\r\n\r\n**Screenshots**\r\nNA\r\n",
      "state": "closed",
      "author": "shubhamofbce",
      "author_type": "User",
      "created_at": "2024-04-25T18:29:29Z",
      "updated_at": "2024-06-11T07:26:04Z",
      "closed_at": "2024-06-11T07:26:04Z",
      "labels": [
        "enhancement",
        "AI-performance"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/161/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/161",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/161",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:44.891402",
      "comments": [
        {
          "author": "lyie28",
          "body": "@shubhamofbce @mbrunel - should I close this? Seems like this was solved by changes to the retriever?",
          "created_at": "2024-06-10T13:29:00Z"
        },
        {
          "author": "shubhamofbce",
          "body": "@lyie28 Yes you can.",
          "created_at": "2024-06-10T17:36:58Z"
        }
      ]
    },
    {
      "issue_number": 288,
      "title": "Save logs locally",
      "body": "Right now, you can only obtain logs at runtime with `agent.logger.return_pandas()`. For convenience we should have local copies of logs every time LaVague runs.\r\n\r\nFeature: \r\n- V1: save logs locally, only after the agent has finished running. A csv perhaps ?\r\n- V2: write logs at each step to get logs even in case of crashes. ",
      "state": "closed",
      "author": "paulpalmieri",
      "author_type": "User",
      "created_at": "2024-06-03T09:17:02Z",
      "updated_at": "2024-06-10T18:38:20Z",
      "closed_at": "2024-06-10T18:38:20Z",
      "labels": [
        "help wanted",
        "good first issue"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/288/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/288",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/288",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:45.112151",
      "comments": [
        {
          "author": "mattanapol",
          "body": "@paulpalmieri Please review PR #328 and feel free to leave any suggestion.",
          "created_at": "2024-06-10T13:59:13Z"
        }
      ]
    },
    {
      "issue_number": 320,
      "title": "Got error \"TypeError: string indices must be integers, not 'str'\" when llm response contain []",
      "body": "**Describe the bug**\r\nGot error \"TypeError: string indices must be integers, not 'str'\" when llm response contain []\r\n\r\n**Observe error**\r\nLlm response\r\n```\r\n[{'query':'img[data-testid=\"lang-switch\"]', 'action':'Click on the image with the `data-testid` attribute equal to `lang-switch`'}]\r\n```\r\nError\r\n```\r\nError: The extracted string is not a valid Python literal.\r\nTraceback (most recent call last):\r\n  File \"/Users/kaewsai/miniconda3/envs/poc-lavague/lib/python3.12/site-packages/lavague/core/agents.py\", line 248, in run\r\n    action_result = self.action_engine.dispatch_instruction(\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/kaewsai/miniconda3/envs/poc-lavague/lib/python3.12/site-packages/lavague/core/action_engine.py\", line 151, in dispatch_instruction\r\n    ret = next_engine.execute_instruction(instruction)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/kaewsai/miniconda3/envs/poc-lavague/lib/python3.12/site-packages/lavague/core/navigation.py\", line 248, in execute_instruction\r\n    logging_print.debug(\"Rephrased instruction: \" + action[\"action\"])\r\n                                                    ~~~~~~^^^^^^^^^^\r\n```\r\n**Expected behavior**\r\nLaVague should run properly\r\n",
      "state": "closed",
      "author": "mattanapol",
      "author_type": "User",
      "created_at": "2024-06-09T10:06:13Z",
      "updated_at": "2024-06-10T15:18:25Z",
      "closed_at": "2024-06-10T15:18:25Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/320/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "JoFrost"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/320",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/320",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:45.339703",
      "comments": [
        {
          "author": "JoFrost",
          "body": "PR merged",
          "created_at": "2024-06-10T15:18:25Z"
        }
      ]
    },
    {
      "issue_number": 198,
      "title": "Documentation for using Action Engine directly from Python",
      "body": "@lyie28 I think our high level interfaces are cool but we could add a third section on the qucik tour on how to directly use the Action Engine without using a higher level interface",
      "state": "closed",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-05-04T08:33:55Z",
      "updated_at": "2024-06-10T13:23:30Z",
      "closed_at": "2024-06-10T13:23:04Z",
      "labels": [
        "documentation",
        "enhancement",
        "ActionEngine"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/198/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/198",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/198",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:45.550576",
      "comments": [
        {
          "author": "lyie28",
          "body": "https://docs.lavague.ai/en/latest/docs/learn/action-engine/",
          "created_at": "2024-06-10T13:23:28Z"
        }
      ]
    },
    {
      "issue_number": 110,
      "title": "Schedule call/talk on how we do benchmarking and improve retrieval and general AI strategy",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-08T15:24:02Z",
      "updated_at": "2024-06-10T13:22:40Z",
      "closed_at": "2024-06-10T13:22:40Z",
      "labels": [
        "AI-performance"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/110/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "dhuynh95"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/110",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/110",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:45.739409",
      "comments": []
    },
    {
      "issue_number": 203,
      "title": "Cookie accepting is an issue",
      "body": "**Describe the bug**\r\nWhen I go to any website that uses cookies, the assistant cant click accept all. This makes websites such as youtube unusable.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to youtube.com and the 'accept all' button that pops up to use it is not pressable.\r\n\r\n\r\n**Expected behavior**\r\nI would like it if the demo didnt get locked out with the cookie screen in certain websites. Any sort of auto accept would be great, but at least it should be able to accept it with a prompt if not.\r\n\r\n**Screenshots**\r\n\r\n![123124](https://github.com/lavague-ai/LaVague/assets/56364750/3af028f5-3c79-4e59-a300-109c55a83fce)\r\n",
      "state": "closed",
      "author": "saffie91",
      "author_type": "User",
      "created_at": "2024-05-08T12:12:47Z",
      "updated_at": "2024-06-10T13:16:04Z",
      "closed_at": "2024-06-10T13:16:03Z",
      "labels": [
        "documentation",
        "Driver"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/203/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "dhuynh95",
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/203",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/203",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:45.739426",
      "comments": [
        {
          "author": "dhuynh95",
          "body": "Hi @saffie91!\r\nThanks for pointing that out.\r\nThis would be a bit heavy to implement.\r\nI think one solution would be to create a stateful session, for instance using developer mode with Selenium or Playwright, accept the cookies once for all, and then connect to it using LaVague.\r\n\r\nI can show you h",
          "created_at": "2024-05-09T13:38:34Z"
        },
        {
          "author": "saffie91",
          "body": "Yes I would like it if you showed how. I'm sure it would help a lot of people to update this in general. \r\n\r\n\r\nI tried running the default selenium session with my logged in Google profile but it did not work. Although I know that's the function being called in lavague launch I have no idea why, so ",
          "created_at": "2024-05-09T13:49:28Z"
        },
        {
          "author": "lyie28",
          "body": "@saffie91 I plan to add some info on this in the docs next few days. I will let you know when it's live!",
          "created_at": "2024-05-14T10:38:17Z"
        },
        {
          "author": "lyie28",
          "body": "@saffie91 - the project has changed quite a bit since we last spoke but I did finally add some docs on plugging in an existing chrome session:\r\n\r\nhttps://docs.lavague.ai/en/latest/docs/learn/browser-drivers/#plugging-in-an-existing-browser-session_1\r\n\r\nIf you do test it out, please let me know if it",
          "created_at": "2024-06-07T11:39:48Z"
        },
        {
          "author": "lyie28",
          "body": "@saffie91 in fact either strategy mentioned now in the quick tour for logins are relevant to cookie accepting too.  You could also enforce a pause in your code and manually accept the cookie at this point: See instructions here: https://docs.lavague.ai/en/latest/docs/get-started/quick-tour/#manual-l",
          "created_at": "2024-06-10T13:16:03Z"
        }
      ]
    },
    {
      "issue_number": 253,
      "title": "Export option code/actions generated by agent",
      "body": "I intend to use this tool for testing a web application. The idea is that it records actions generated for Selenium and saves them as a new code file. This allows users to run / modify the code multiple times for verification purposes without paying open ai and lot more repeatable.\r\n\r\nSo this act as first step for the QA tester to write automation script.\r\n\r\n",
      "state": "closed",
      "author": "FaizRasool",
      "author_type": "User",
      "created_at": "2024-05-24T18:28:37Z",
      "updated_at": "2024-06-10T12:57:38Z",
      "closed_at": "2024-06-10T12:57:38Z",
      "labels": [
        "help wanted",
        "Integrations"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/253/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/253",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/253",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:45.992541",
      "comments": [
        {
          "author": "dhuynh95",
          "body": "Definitely! I am working on a branch to add advanced recording metrics, which will include the generated code. \nShould be done in a few days ",
          "created_at": "2024-05-24T18:50:55Z"
        },
        {
          "author": "lyie28",
          "body": "@dhuynh95 @FaizRasool We have been talking about trying to add export options and we will probably make these `help-wanted` issues.  I think a wrapper around exporting code would be a great start. Then hopefully we can add export integrations for things for pytest, fastAPI, etc.\r\n\r\nIf you're interes",
          "created_at": "2024-05-28T09:10:55Z"
        },
        {
          "author": "lyie28",
          "body": "Hi @FaizRasool,\r\n\r\nWe have now implemented two ways to get the code.\r\n\r\nFirstly, the Agent now returns a ActionResult object containing: \r\n\r\n- instruction -> the user objective\r\n- code -> all the code of the successful actions run (for Navigation Engine only)\r\n- success -> boolean of if the objectiv",
          "created_at": "2024-06-10T12:57:38Z"
        }
      ]
    },
    {
      "issue_number": 292,
      "title": "Cannot do multiple runs with the same agent - have to create a new instance of Agent each time",
      "body": "If you do multiple agent.run() commands with the same instance of agent, you get errors relating to the screenshot folder  - seems to be related to clearing the previous screenshot folder after run 1 and then run 2 expecting it to still exist?\r\n\r\n`FileNotFoundError: [Errno 2] No such file or directory: 'screenshots/https_huggingface.co_docs'`\r\n\r\nThis doesn't happen if you have a new instance of Agent in between runs\r\n",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-06-04T12:20:11Z",
      "updated_at": "2024-06-06T15:02:58Z",
      "closed_at": "2024-06-06T15:02:58Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/292/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "JoFrost",
        "mbrunel"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/292",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/292",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:46.251348",
      "comments": []
    },
    {
      "issue_number": 293,
      "title": "user_data agent.run() argument never used",
      "body": "In `agents.py`, we accept a user_data argument for the `run()` method but we seem to have lost the line of code where we actually use it - it is not used currently on main!",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-06-04T12:21:37Z",
      "updated_at": "2024-06-05T07:45:57Z",
      "closed_at": "2024-06-05T07:45:56Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/293/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "JoFrost",
        "mbrunel"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/293",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/293",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:46.251371",
      "comments": [
        {
          "author": "lyie28",
          "body": "Fixed now ",
          "created_at": "2024-06-05T07:45:56Z"
        }
      ]
    },
    {
      "issue_number": 171,
      "title": "Do contrib page for converting dataset for LaVague",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-29T09:49:14Z",
      "updated_at": "2024-05-30T11:53:50Z",
      "closed_at": "2024-05-30T11:53:50Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/171/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "paulpalmieri"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/171",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/171",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:48.286952",
      "comments": []
    },
    {
      "issue_number": 117,
      "title": "Add error handling ability upon generated code error",
      "body": "**Is your feature request related to a problem? Please describe.**\r\nWhen code gets generated and it doesn't work, we throw an error and give up. The backtrace should provide very clear direction to fix the generated code and try to take another shot at it.\r\n\r\n**Describe the solution you'd like**\r\nAdd a error handling mechanism, where if code error is encountered, dump the error into the context and retool the code.\r\nThis is a part of langchain [out of the box](https://python.langchain.com/docs/use_cases/tool_use/tool_error_handling/#retry-with-exception), the equivalent for llamaindex would be [Retry Query Engine](https://docs.llamaindex.ai/en/stable/examples/evaluation/RetryQuery/?h=query+engine#retry-query-engine).\r\n\r\n**Describe alternatives you've considered**\r\nmaybe robustness can be increased by providing many examples in context to steer the code gen output, but backtracking is additive.\r\n\r\n",
      "state": "closed",
      "author": "y22ma",
      "author_type": "User",
      "created_at": "2024-04-15T20:44:33Z",
      "updated_at": "2024-05-30T11:53:21Z",
      "closed_at": "2024-05-30T11:53:21Z",
      "labels": [
        "enhancement",
        "help wanted",
        "AI-performance"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/117/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "dhuynh95",
        "HiImMadness"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/117",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/117",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:48.286990",
      "comments": [
        {
          "author": "lyie28",
          "body": "Thanks for the request. I will let @dhuynh95 and @HiImMadness reply to this as it is more their area of expertise :)",
          "created_at": "2024-04-16T14:40:36Z"
        },
        {
          "author": "shubhamofbce",
          "body": "@y22ma This is a great suggestion and we should do this. In our case we can just use lxml to evaluate if the xpath generated is correct or not. If not correct then we can use the retry query engine to generate a different or a better xpath that evaluates to a valid element before actually executing ",
          "created_at": "2024-04-16T17:39:19Z"
        },
        {
          "author": "y22ma",
          "body": "Well, \r\n\r\n> @y22ma This is a great suggestion and we should do this. In our case we can just use lxml to evaluate if the xpath generated is correct or not. If not correct then we can use the retry query engine to generate a different or a better xpath that evaluates to a valid element before actuall",
          "created_at": "2024-04-16T19:45:25Z"
        },
        {
          "author": "lyie28",
          "body": "This is now handled by an automatic retry mechanism for up to X tries (can be defined by user)",
          "created_at": "2024-05-30T11:53:16Z"
        }
      ]
    },
    {
      "issue_number": 93,
      "title": "Add new Re-submit button for Python code generated",
      "body": "After the Python code is generated. I want to change directly code generated and re-run it to see how it work instead of rewrite query",
      "state": "closed",
      "author": "trongtran",
      "author_type": "User",
      "created_at": "2024-04-04T02:25:34Z",
      "updated_at": "2024-05-30T11:50:51Z",
      "closed_at": "2024-05-30T11:50:51Z",
      "labels": [
        "help wanted",
        "good first issue",
        "community-assigned"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/93/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/93",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/93",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:48.574136",
      "comments": [
        {
          "author": "lyie28",
          "body": "That could be interesting. This would involve modifying the Gradio code in the `command_center.py` file. I will set it as help-wanted because we all have quite a few tasks  on our plates internally for now but maybe someone will take this from the community! Or if you want to give it a go, that woul",
          "created_at": "2024-04-04T09:13:27Z"
        },
        {
          "author": "shivamsharma00",
          "body": "I would like to work on this issue.",
          "created_at": "2024-04-24T19:52:37Z"
        },
        {
          "author": "lyie28",
          "body": "Sounds great @shivamsharma00. I'll set the issue to community assigned. Let me know if you need any more info about this one",
          "created_at": "2024-04-24T21:57:16Z"
        },
        {
          "author": "lyie28",
          "body": "This is now handled by an automatic retry mechanism if steps fail",
          "created_at": "2024-05-30T11:50:51Z"
        }
      ]
    },
    {
      "issue_number": 174,
      "title": "Do contrib page for contribution to AI pipeline",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-29T09:50:32Z",
      "updated_at": "2024-05-30T11:49:13Z",
      "closed_at": "2024-05-30T11:49:13Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/174/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/174",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/174",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:48.827828",
      "comments": []
    },
    {
      "issue_number": 172,
      "title": "Do contrib page for contributing for the_wave",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-29T09:50:23Z",
      "updated_at": "2024-05-30T11:49:03Z",
      "closed_at": "2024-05-30T11:49:03Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/172/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "paulpalmieri"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/172",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/172",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:48.827845",
      "comments": []
    },
    {
      "issue_number": 173,
      "title": "Do contrib page for evaluation",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-29T09:50:27Z",
      "updated_at": "2024-05-30T11:48:53Z",
      "closed_at": "2024-05-30T11:48:53Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/173/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/173",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/173",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:48.827851",
      "comments": []
    },
    {
      "issue_number": 223,
      "title": "Build examples section in docs",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-05-15T12:34:27Z",
      "updated_at": "2024-05-30T11:43:05Z",
      "closed_at": "2024-05-30T11:43:05Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/223/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "paulpalmieri"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/223",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/223",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:48.827857",
      "comments": []
    },
    {
      "issue_number": 225,
      "title": "Build and share place where people can suggest their use cases and results",
      "body": "Make a specific backlog people can add their ideas for uses cases and comment or share solutions - look if it's best to do this as a new backlog on GH or a feature suggestion thing @paulpalmieri ",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-05-15T12:37:05Z",
      "updated_at": "2024-05-30T11:42:49Z",
      "closed_at": "2024-05-30T11:42:49Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/225/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/225",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/225",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:48.827862",
      "comments": []
    },
    {
      "issue_number": 170,
      "title": "create contributor evaluation leaderboard",
      "body": null,
      "state": "open",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-29T09:48:59Z",
      "updated_at": "2024-05-30T11:37:07Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "AI-performance"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/170/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "JoFrost"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/170",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/170",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:48.827869",
      "comments": []
    },
    {
      "issue_number": 274,
      "title": "Benchmark various open and closed source models",
      "body": "A lot of people are interested in using different models so will be great to benchmark asap so people know what kind of performance to expected from various models",
      "state": "open",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-05-29T12:01:32Z",
      "updated_at": "2024-05-30T11:37:01Z",
      "closed_at": null,
      "labels": [
        "AI-performance",
        "HighPrio"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/274/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "dhuynh95",
        "HiImMadness"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/274",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/274",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:48.827874",
      "comments": [
        {
          "author": "dhuynh95",
          "body": "Yes @HiImMadness will provide TheWave 2.0 and we will bench those",
          "created_at": "2024-05-29T12:22:19Z"
        }
      ]
    },
    {
      "issue_number": 226,
      "title": "CI/CD for quick tour notebook and README/Index code for every push to main",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-05-15T13:10:54Z",
      "updated_at": "2024-05-15T21:09:38Z",
      "closed_at": "2024-05-15T21:09:38Z",
      "labels": [
        "documentation",
        "CI/CD"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/226/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/226",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/226",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:49.097185",
      "comments": []
    },
    {
      "issue_number": 5,
      "title": "Fine-tune a gemma-7b for better local model",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-03-12T17:24:50Z",
      "updated_at": "2024-05-14T15:09:48Z",
      "closed_at": "2024-05-14T15:09:48Z",
      "labels": [
        "help wanted",
        "new feature",
        "ActionEngine"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/5/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/5",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/5",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:49.097213",
      "comments": [
        {
          "author": "farouqaldori",
          "body": "I'm the co-founder of FinetuneDB. Happy to provide the infrastructure to build the dataset for fine-tuning. If the community collaborates on a high quality dataset, we can achieve great results.\r\n\r\nWho's in?",
          "created_at": "2024-03-14T00:27:02Z"
        }
      ]
    },
    {
      "issue_number": 20,
      "title": "Build hub for agents",
      "body": null,
      "state": "open",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-03-14T13:38:21Z",
      "updated_at": "2024-05-14T15:08:57Z",
      "closed_at": null,
      "labels": [
        "new feature"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/20/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "JoFrost"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/20",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/20",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:49.317239",
      "comments": []
    },
    {
      "issue_number": 9,
      "title": "Add export integration with hub",
      "body": "Add modular different export options that will interact with hub when built: python, pytests, FastAPI etc.",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-03-13T12:11:43Z",
      "updated_at": "2024-05-14T15:08:44Z",
      "closed_at": "2024-05-14T15:08:44Z",
      "labels": [
        "core"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/9/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "JoFrost"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/9",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/9",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:49.317258",
      "comments": []
    },
    {
      "issue_number": 89,
      "title": "Add compatibility for behave input for instructions",
      "body": "Behave:\n- https://behave.readthedocs.io/en/latest/philosophy/\n- https://behave.readthedocs.io/en/latest/tutorial/\n\nBehave is a behavior-driven development (BDD) framework which uses Gherkin language for writting automation scenarios, for example:\n\n```\nFeature: Automated web interaction\n  Scenario: Login to the website\n    Given a user navigates to the login page\n    When the user enters valid credentials\n    Then the user should be redirected to the dashboard\n```\n\nWe would like to be able to optionally handle Behave scenario files as an instruction input and output the necessary code to perform these actions.",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-03T13:47:32Z",
      "updated_at": "2024-05-14T15:08:28Z",
      "closed_at": "2024-05-14T15:08:28Z",
      "labels": [
        "help wanted",
        "good first issue"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/89/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/89",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/89",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:49.317264",
      "comments": [
        {
          "author": "slimwizard",
          "body": "Hi @lyie28, could you provide another example or two of what you have in mind for the kind of content which would be in a Behavior file that would be used with LaVague?",
          "created_at": "2024-05-13T14:21:40Z"
        }
      ]
    },
    {
      "issue_number": 85,
      "title": "Puppeteer integration",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-03T13:23:40Z",
      "updated_at": "2024-05-14T15:08:17Z",
      "closed_at": "2024-05-14T15:08:17Z",
      "labels": [
        "enhancement",
        "help wanted",
        "Driver"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/85/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/85",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/85",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:49.571744",
      "comments": []
    },
    {
      "issue_number": 86,
      "title": "Cypress integration",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-03T13:24:10Z",
      "updated_at": "2024-05-14T15:08:08Z",
      "closed_at": "2024-05-14T15:08:08Z",
      "labels": [
        "enhancement",
        "help wanted",
        "Driver"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/86/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/86",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/86",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:49.571764",
      "comments": []
    },
    {
      "issue_number": 90,
      "title": "Build option to export with pytest compatibility",
      "body": "We would like to add an option to generate an automation code which is compatible with pytest. To do this you will need to create a custom prompt in `prompts.py` that will give the LLM examples of files prepared for testing with pytest instead of just Python code examples.\n\nThen you can test it by using a custom config file for LaVague which defines the `prompt_template` as your new prompt template.",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-03T13:48:00Z",
      "updated_at": "2024-05-14T11:57:24Z",
      "closed_at": "2024-05-14T11:57:24Z",
      "labels": [
        "help wanted",
        "good first issue"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/90/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/90",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/90",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:49.571771",
      "comments": []
    },
    {
      "issue_number": 88,
      "title": "Build option to export with fastapi compatibility",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-03T13:46:39Z",
      "updated_at": "2024-05-13T21:54:15Z",
      "closed_at": "2024-05-13T21:54:15Z",
      "labels": [
        "help wanted",
        "good first issue"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/88/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/88",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/88",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:49.571779",
      "comments": []
    },
    {
      "issue_number": 17,
      "title": "Integrate vision",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-03-14T09:40:32Z",
      "updated_at": "2024-05-13T21:53:46Z",
      "closed_at": "2024-05-13T21:53:46Z",
      "labels": [
        "enhancement",
        "new feature",
        "community-assigned"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/17/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "dhuynh95",
        "mbrunel"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/17",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/17",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:49.571785",
      "comments": [
        {
          "author": "badreddineFarah",
          "body": "Hi, i want to contribute help in this task but, how do you see the integration of vision, but I don't fully understand how do you ant to do this  is it  sending snapshots of the web page ? ",
          "created_at": "2024-04-03T00:00:35Z"
        },
        {
          "author": "dhuynh95",
          "body": "Discussed with @badreddineFarah\r\n\r\nThe idea is : \r\nToday we take low level instructions like \"Select X, do Y\".For the retriever to work well, we have to be quite specific but it's annyoing to write\r\nThe goal is to use vision model to provide mid level instructions, like \"this form with name \"Daniel\"",
          "created_at": "2024-04-03T00:50:23Z"
        }
      ]
    },
    {
      "issue_number": 87,
      "title": "Add new config files + integration notebooks such as Claude 3",
      "body": "- Place your custom config file for integration with X API or model in `examples/api`\n- Add an integration notebook to `docs/docs/integrations following the other integration notebooks as an example`",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-03T13:45:32Z",
      "updated_at": "2024-05-13T21:53:25Z",
      "closed_at": "2024-05-13T21:53:25Z",
      "labels": [
        "help wanted",
        "good first issue"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/87/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/87",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/87",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:49.754294",
      "comments": []
    },
    {
      "issue_number": 157,
      "title": "Add export option to VSCode extension",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-23T15:21:33Z",
      "updated_at": "2024-05-13T21:52:46Z",
      "closed_at": "2024-05-13T21:52:46Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/157/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "JoFrost"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/157",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/157",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:49.754315",
      "comments": []
    },
    {
      "issue_number": 149,
      "title": "Add CLI option and docstring to PR for metrics",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-22T10:21:34Z",
      "updated_at": "2024-05-13T21:52:26Z",
      "closed_at": "2024-05-13T21:52:26Z",
      "labels": [
        "enhancement",
        "core",
        "AI-performance"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/149/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/149",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/149",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:49.754322",
      "comments": []
    },
    {
      "issue_number": 96,
      "title": "Installation guide for Windows",
      "body": "- Make a setup script at root of project for windows\n- Add section in the docs/docs/get-started/setting-up-la-vague.md for installation with windows",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-04T11:54:34Z",
      "updated_at": "2024-05-13T21:51:52Z",
      "closed_at": "2024-05-13T21:51:52Z",
      "labels": [
        "help wanted",
        "good first issue"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/96/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/96",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/96",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:49.754353",
      "comments": [
        {
          "author": "hack-scan",
          "body": "ä½œè€…æ‚¨å¥½ï¼ŒçŽ°åœ¨windowsçš„å®‰è£…æŒ‡å—æ˜¯å¦ç¼–å†™å¥½äº†ï¼Ÿ",
          "created_at": "2024-04-07T02:46:17Z"
        },
        {
          "author": "lyie28",
          "body": "Hello,\r\n\r\nNo, this still needs to be done. We are looking for a contributor to help us with this :)",
          "created_at": "2024-04-07T05:48:08Z"
        }
      ]
    },
    {
      "issue_number": 111,
      "title": "Add prompting guide and more instruction examples in docs",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-08T15:25:47Z",
      "updated_at": "2024-05-13T21:51:40Z",
      "closed_at": "2024-05-13T21:51:40Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/111/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/111",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/111",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:49.967980",
      "comments": []
    },
    {
      "issue_number": 130,
      "title": "CI test for docs - check all URLS are valid and check that all files referenced exist in the repo",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-17T15:49:44Z",
      "updated_at": "2024-05-13T21:51:22Z",
      "closed_at": "2024-05-13T21:51:22Z",
      "labels": [
        "documentation",
        "CI/CD"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/130/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/130",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/130",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:49.967993",
      "comments": []
    },
    {
      "issue_number": 177,
      "title": "VS Code extension, prompting a second time doesn't work or is extremely slow",
      "body": "**Describe the bug**\r\nAfter running the boilerplate cell, the first prompt cell and the first generated code cell, I create a new cell to enter another prompt. \r\nThis second prompt usually takes 30+ seconds and outputs a partially working cell\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\nI am on OSX (this is why you see me replacing the boilerplate at the start of the video)\r\n1. Create new project with extension\r\n2. Run boilerplate\r\n3. Run generated cell\r\n4. Create a new cell and input ```%lavague_exec \"myprompt\"```\r\n5. Wait for processing\r\n\r\n**Expected behavior**\r\nShould be faster and properly output code cells\r\n\r\n**Screenshots**\r\n[See video (free hosting, will expire in 48h) ](https://streamable.com/fpxvyd)\r\nOr ping me so that I send you the file! ",
      "state": "closed",
      "author": "paulpalmieri",
      "author_type": "User",
      "created_at": "2024-04-29T13:52:36Z",
      "updated_at": "2024-05-13T21:49:01Z",
      "closed_at": "2024-05-13T21:49:01Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/177/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/177",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/177",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:49.967998",
      "comments": [
        {
          "author": "lyie28",
          "body": "I cannot consistently reproduce this issue. But I think the VSCode extension was not designed to be able to have:\r\n- Instruction/ magic command\r\n- generated code\r\n- New instruction/magic command cell\r\n\r\nWhen I tested, it will replace the previous generated code rather than create a new cell. Can you",
          "created_at": "2024-04-30T09:39:37Z"
        },
        {
          "author": "JoFrost",
          "body": "Hm. It's indeed supposed to replace the old cell. If it can't, it will target a new cell.\nI'm surprised however that the code is not fully sent. My guess is that the process fail on the python side.\n\n@paulpalmieri I would like to get the file if possible.",
          "created_at": "2024-04-30T09:44:47Z"
        },
        {
          "author": "paulpalmieri",
          "body": "@JoFrost here's another link https://streamable.com/7xbgul",
          "created_at": "2024-05-02T10:38:27Z"
        }
      ]
    },
    {
      "issue_number": 192,
      "title": "Make all docs pages .md files with link to notebook as option",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-05-02T11:34:20Z",
      "updated_at": "2024-05-13T21:24:13Z",
      "closed_at": "2024-05-13T21:24:13Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/192/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/192",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/192",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:50.196613",
      "comments": []
    },
    {
      "issue_number": 193,
      "title": "Add to docs CI to run all notebooks",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-05-02T11:34:26Z",
      "updated_at": "2024-05-13T21:23:59Z",
      "closed_at": "2024-05-13T21:23:59Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/193/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/193",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/193",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:50.196636",
      "comments": []
    },
    {
      "issue_number": 175,
      "title": "Rework README.md to reflect community focus",
      "body": null,
      "state": "closed",
      "author": "paulpalmieri",
      "author_type": "User",
      "created_at": "2024-04-29T10:22:17Z",
      "updated_at": "2024-05-13T21:23:47Z",
      "closed_at": "2024-05-13T21:23:47Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/175/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "paulpalmieri"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/175",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/175",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:50.196643",
      "comments": []
    },
    {
      "issue_number": 194,
      "title": "Review all docs and improve structure and visuals",
      "body": "Perform a review and upgrade of current docs:\r\n\r\nAims are:\r\n- Make docs prettier & more visual - add GIFS, videos, schemas\r\n- Remove stupid typos/ bad links through CI\r\n- Improve structure\r\n- Add some key missing sections",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-05-02T11:34:31Z",
      "updated_at": "2024-05-13T21:23:38Z",
      "closed_at": "2024-05-13T21:23:38Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/194/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "paulpalmieri",
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/194",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/194",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:50.196650",
      "comments": []
    },
    {
      "issue_number": 200,
      "title": "New retriever appears to provide context that frequently exceeds context length",
      "body": "With OpenAI, HF llama70b & Azure GPT3 using the eval module with 25 rows of the the_wave dataset, the new retriever consistently provides a context that exceeds max context length on the 13th row of the dataset.\r\n\r\nTo reproduce, see this notebook, adding in your openai key: \r\n[notebook](https://colab.research.google.com/drive/1dSHO4yj41TlqYQkpYmUSJ5daz9pm-Tpv?usp=sharing)\r\n\r\n",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-05-06T11:13:56Z",
      "updated_at": "2024-05-13T21:22:58Z",
      "closed_at": "2024-05-13T21:22:58Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/200/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/200",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/200",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:50.196656",
      "comments": []
    },
    {
      "issue_number": 92,
      "title": "Articles sharing your usage of LaVague",
      "body": "Create an article in docs/docs/examples which introduces us to examples where you have used LaVague - your natural language instructions, what you did and any customizations you did, image of what you achieved.\r\n\r\nYou can leave your instructions in the examples folder",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-03T15:58:41Z",
      "updated_at": "2024-05-13T17:21:48Z",
      "closed_at": "2024-05-13T17:21:48Z",
      "labels": [
        "documentation",
        "help wanted",
        "good first issue"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/92/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/92",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/92",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:50.196666",
      "comments": []
    },
    {
      "issue_number": 186,
      "title": "Wrapping of Playwright into FastAPI for Gradio compatibility",
      "body": "@mbrunel / @shubhamofbce : I think Playwright might be a better default solution as it is faster / easier to install, more performant and also has built-in wait mechanisms.\r\n\r\nAs Gradio is our most popular interface today, and given Playwright's popularity, I thought it could be good to solve that issue.\r\n\r\nFrom our last discussions, I think there is some async issue when using Gradio.\r\n\r\nWould it technically work to wrap the Playwright Driver and/or the Action Engine inside a FastAPI and call it from the Gradio?",
      "state": "closed",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-05-01T13:07:44Z",
      "updated_at": "2024-05-09T20:16:17Z",
      "closed_at": "2024-05-06T12:58:09Z",
      "labels": [
        "help wanted",
        "core"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 10,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/186/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "JoFrost",
        "shubhamofbce"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/186",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/186",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:50.196674",
      "comments": [
        {
          "author": "shubhamofbce",
          "body": "@dhuynh95 I can give it a try, will let you all know my findings.",
          "created_at": "2024-05-01T13:12:03Z"
        },
        {
          "author": "shubhamofbce",
          "body": "I created a very simple gradio app, just to goto the link mentioned in the input box in the same browser.\r\nI found that the exact same code is working on gradio Interace but not on Gradio blocks.\r\nWith gradio block - which we are using at lavague, it throws error:  It looks like you are using Playwr",
          "created_at": "2024-05-04T07:08:17Z"
        },
        {
          "author": "shubhamofbce",
          "body": "The funny part is, Interface extends Blocks class.\r\n![image](https://github.com/lavague-ai/LaVague/assets/45156638/c1ab50f6-2e6d-4132-a1af-0a62a53ae673)\r\n",
          "created_at": "2024-05-04T07:25:36Z"
        },
        {
          "author": "dhuynh95",
          "body": "Interesting! \n\nI guess blocks is more useful for us. \n\nCan you explain to me what are the issues we currently face? \n\nTo my understanding there is some issue in using Gradio and Playwright due to sync/async",
          "created_at": "2024-05-04T07:32:21Z"
        },
        {
          "author": "shubhamofbce",
          "body": "@dhuynh95 \r\nThe current issue with using sync playwright api with gradio is:\r\nGradio tries to open this in a new thread and playwright sync implementation doesn't allows that:\r\n```bash\r\nWhen you run\r\n!lavague -c examples/configurations/api/openai_api_playwright.py launch\r\nError:\r\n/playwright/_impl/_",
          "created_at": "2024-05-04T08:19:35Z"
        }
      ]
    },
    {
      "issue_number": 205,
      "title": "Wrapping of Playwright into FastAPI ",
      "body": "Playwright was successfully implemented as default drivers, but the implementation on Gradio has a few caveats: \n\n- Because Gradio uses multithreading, the playwright instance might be moved between threads, breaking the whole execution flow at times. This issue was circumvented by recreating the driver before each action. It works, but it might be a performance bottleneck at times.\n\n- As the drivers needs to be recreated at each action, keeping a state is difficult.\n\nA way to improve the current implementation would be to have a FastAPI server executed locally, hosting a Playwright instance (and potentially the Action Engine).\n\nThis method would allow to use Playwright drivers with Gradio and Jupyter Notebooks without caveats.",
      "state": "closed",
      "author": "JoFrost",
      "author_type": "User",
      "created_at": "2024-05-09T14:59:50Z",
      "updated_at": "2024-05-09T20:15:59Z",
      "closed_at": "2024-05-09T20:15:58Z",
      "labels": [
        "help wanted"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/205/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/205",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/205",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:50.468047",
      "comments": [
        {
          "author": "JoFrost",
          "body": "Done and pushed to main.",
          "created_at": "2024-05-09T20:15:58Z"
        }
      ]
    },
    {
      "issue_number": 176,
      "title": "VS Code extension boilerplate code doesn't work on Mac OSX",
      "body": "**Describe the bug**\r\nThe app can't find the necessary binary and driver for OSX. It seems to be because boilerplate code is not made for Mac. \r\nWe should mutualize the boilerplate code for all apps since the ```build``` command generates boilerplate that can successfully run on Mac OSX. \r\n\r\n**To Reproduce**\r\n1. From an OSX device cmd+shift+P in vscode, new lavague project, type the URL, press Enter\r\n2. Try to run the first boilerplate code\r\n\r\n**Expected behavior**\r\nChrome opens and loads the provided URL\r\n\r\n**Current behavior**\r\n```NoSuchDriverException: Message: Unable to locate or obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location```\r\n\r\n",
      "state": "closed",
      "author": "paulpalmieri",
      "author_type": "User",
      "created_at": "2024-04-29T13:24:59Z",
      "updated_at": "2024-05-03T11:15:19Z",
      "closed_at": "2024-05-03T11:15:19Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/176/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "JoFrost"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/176",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/176",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:50.722590",
      "comments": [
        {
          "author": "lyie28",
          "body": "Indeed, we haven't added the new default macOS path, @JoFrost is going to add that :)",
          "created_at": "2024-04-29T14:04:33Z"
        }
      ]
    },
    {
      "issue_number": 165,
      "title": "Command line should have default params",
      "body": "Current `lavague` commands like `launch` and so on require instructions file and config.\r\n\r\nWe should provide by default an instruction file, like the Hugging Face one, and the OpenAI Config by default. ",
      "state": "closed",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-04-27T18:38:46Z",
      "updated_at": "2024-05-03T11:02:45Z",
      "closed_at": "2024-05-03T11:02:45Z",
      "labels": [
        "documentation",
        "enhancement"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/165/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "JoFrost"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/165",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/165",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:50.985649",
      "comments": []
    },
    {
      "issue_number": 191,
      "title": "New contribution home page & general guidelines",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-05-02T11:33:44Z",
      "updated_at": "2024-05-02T11:35:58Z",
      "closed_at": "2024-05-02T11:35:58Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/191/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/191",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/191",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:50.985668",
      "comments": []
    },
    {
      "issue_number": 180,
      "title": "When using deepseek coder, cannot import name 'GEMMA_PROMPT' from 'lavague.prompts'",
      "body": "**Describe the bug**\r\nfrom lavague.prompts import GEMMA_PROMPT\r\nImportError: cannot import name 'GEMMA_PROMPT' from 'lavague.prompts'\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. lavague -i examples/instructions/huggingface.yaml -c xamples/configurations/local/deepseek-coder.py launch\r\n2. See error ImportError: cannot import name 'GEMMA_PROMPT' from 'lavague.prompts'\r\n\r\n**Expected behavior**\r\nI found out that deepseek-coder.py does not contains GEMMA_PROMPT but it contains SELENIUM_GEMMA_PROMPT\r\n\r\n",
      "state": "closed",
      "author": "alexsiu398",
      "author_type": "User",
      "created_at": "2024-04-30T06:46:17Z",
      "updated_at": "2024-04-30T07:38:03Z",
      "closed_at": "2024-04-30T07:37:53Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/180/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/180",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/180",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:52.829224",
      "comments": [
        {
          "author": "lyie28",
          "body": "Thanks @alexsiu398 - I hadn't spotted this update in the codebase. I have updated the config file on main now to use the SELENIUM_GEMMA_PROMPT ",
          "created_at": "2024-04-30T07:37:53Z"
        }
      ]
    },
    {
      "issue_number": 143,
      "title": "Integrate AI performance into CI",
      "body": null,
      "state": "open",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-19T15:13:16Z",
      "updated_at": "2024-04-29T20:41:51Z",
      "closed_at": null,
      "labels": [
        "CI/CD",
        "AI-performance"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/143/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/143",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/143",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:53.022564",
      "comments": []
    },
    {
      "issue_number": 6,
      "title": "Improve retrieval to make sure only relevant pieces of code are used for code generation",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-03-12T17:25:33Z",
      "updated_at": "2024-04-29T18:57:16Z",
      "closed_at": "2024-04-29T18:57:16Z",
      "labels": [
        "enhancement",
        "help wanted",
        "AI-performance"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/6/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "dhuynh95",
        "mbrunel",
        "HiImMadness"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/6",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/6",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:53.022588",
      "comments": [
        {
          "author": "shyampatadia",
          "body": "https://arxiv.org/pdf/2307.12856.pdf\n\nThe above research paper might help! ",
          "created_at": "2024-03-16T21:56:46Z"
        }
      ]
    },
    {
      "issue_number": 81,
      "title": "Integrate new experiments to improve model performance",
      "body": "@HiImMadness : see with @mbrunel to integrate the work you did on improving the retriever and the new prompt template to increase performance",
      "state": "closed",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-04-02T23:59:55Z",
      "updated_at": "2024-04-29T16:48:38Z",
      "closed_at": "2024-04-29T16:48:38Z",
      "labels": [
        "core"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/81/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "mbrunel",
        "HiImMadness"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/81",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/81",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:53.275051",
      "comments": []
    },
    {
      "issue_number": 134,
      "title": "Upgrade base retriever for better performance",
      "body": "@mbrunel : @HiImMadness wrote the following code (it's a bit ugly) to improve retrieval performance : https://github.com/lavague-ai/lavague_experiments/blob/master/op_sm%2Bsplit.ipynb\r\n\r\nCan you play around with it and if it works, we could make that the base retriever",
      "state": "closed",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-04-18T22:27:26Z",
      "updated_at": "2024-04-29T16:43:07Z",
      "closed_at": "2024-04-29T16:43:07Z",
      "labels": [
        "AI-performance"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/134/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "mbrunel"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/134",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/134",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:53.275070",
      "comments": []
    },
    {
      "issue_number": 120,
      "title": "Create benchmarking metrics",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-16T14:02:37Z",
      "updated_at": "2024-04-29T16:13:40Z",
      "closed_at": "2024-04-29T16:13:40Z",
      "labels": [
        "core",
        "AI-performance",
        "BigAction"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/120/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "dhuynh95",
        "HiImMadness"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/120",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/120",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:53.275097",
      "comments": [
        {
          "author": "dhuynh95",
          "body": "I have a notebook that shows how one can test our Action Engine: https://github.com/lavague-ai/LaVague/blob/evaluation/metric.ipynb\r\n\r\nIt's not clean but it gives the gist of it.",
          "created_at": "2024-04-18T22:44:57Z"
        }
      ]
    },
    {
      "issue_number": 150,
      "title": "Create docs for how to test performance/metrics and what they are",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-22T10:22:21Z",
      "updated_at": "2024-04-29T15:03:30Z",
      "closed_at": "2024-04-29T15:03:30Z",
      "labels": [
        "duplicate"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/150/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/150",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/150",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:53.474441",
      "comments": []
    },
    {
      "issue_number": 133,
      "title": "Playwright generated code is not good enough",
      "body": "@shubhamofbce @dhuynh95 \r\n\r\nIt may come from the prompt template, it requires more investigations.",
      "state": "closed",
      "author": "mbrunel",
      "author_type": "User",
      "created_at": "2024-04-18T21:03:48Z",
      "updated_at": "2024-04-29T14:23:19Z",
      "closed_at": "2024-04-29T14:23:19Z",
      "labels": [
        "community-assigned"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/133/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "shubhamofbce"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/133",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/133",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:53.474464",
      "comments": [
        {
          "author": "shubhamofbce",
          "body": "Lets get on a call today to discuss this. @mbrunel ",
          "created_at": "2024-04-19T01:02:32Z"
        },
        {
          "author": "shubhamofbce",
          "body": "I will look into this. @lyie28 can you please assign this to me.",
          "created_at": "2024-04-19T01:26:40Z"
        },
        {
          "author": "dhuynh95",
          "body": "By the way, I have an Eval class being prepared: https://github.com/lavague-ai/LaVague/issues/120\n\nThe second metric is recall_LLM which might be useful to evaluate performance of prompts ",
          "created_at": "2024-04-19T01:33:33Z"
        },
        {
          "author": "shubhamofbce",
          "body": "Thanks @dhuynh95 I saw that, I will try using that too here.",
          "created_at": "2024-04-19T01:57:45Z"
        },
        {
          "author": "shubhamofbce",
          "body": "These are some actual issues that i found in the first look:\r\n1. If you do `find_element_by_` in selenium, it by default picks up the 1st element unless you do `find_elements_by_` but in playwright the `locator` function we are using returns all matching elements and if there are multiple matching i",
          "created_at": "2024-04-19T02:18:39Z"
        }
      ]
    },
    {
      "issue_number": 151,
      "title": "Import error when using Python3.8",
      "body": "With python3.10 I have no error, but when using LaVague 1.0.7 with python3.8 I have the following error:\r\n\r\nImportError: cannot import name 'default_get_selenium_driver' from 'lavague.defaults' ",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-22T13:16:59Z",
      "updated_at": "2024-04-23T10:04:05Z",
      "closed_at": "2024-04-23T10:04:05Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/151/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/151",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/151",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:53.708520",
      "comments": [
        {
          "author": "lyie28",
          "body": "Fix now merged ",
          "created_at": "2024-04-23T10:04:05Z"
        }
      ]
    },
    {
      "issue_number": 147,
      "title": "Broken link to customization guide in quickstart",
      "body": "In the [Colab](https://colab.research.google.com/github/lavague-ai/lavague/blob/main/docs/docs/get-started/quick-tour-notebook/quick-tour.ipynb): Go to quick start notebook, and click link to customization guide. Leads to 404.\r\n\r\n![image](https://github.com/lavague-ai/LaVague/assets/5819303/a0fc15bc-b634-44fa-b7b2-f9a7df766dd0)\r\n\r\n![image](https://github.com/lavague-ai/LaVague/assets/5819303/65eb3786-77cf-43e7-b9d5-f33adcc67e4d)\r\n",
      "state": "closed",
      "author": "vincentschen",
      "author_type": "User",
      "created_at": "2024-04-21T19:43:36Z",
      "updated_at": "2024-04-22T09:42:12Z",
      "closed_at": "2024-04-22T09:42:11Z",
      "labels": [
        "bug",
        "documentation"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/147/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/147",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/147",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:53.896486",
      "comments": [
        {
          "author": "lyie28",
          "body": "Thanks, fixed now.",
          "created_at": "2024-04-22T09:42:11Z"
        }
      ]
    },
    {
      "issue_number": 118,
      "title": "CD - continuous deployment automatic also force updates",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-16T13:29:47Z",
      "updated_at": "2024-04-22T08:59:57Z",
      "closed_at": "2024-04-22T08:59:57Z",
      "labels": [
        "CI/CD"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/118/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "JoFrost"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/118",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/118",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:54.101598",
      "comments": [
        {
          "author": "mbrunel",
          "body": "Also check formatting",
          "created_at": "2024-04-16T14:00:24Z"
        }
      ]
    },
    {
      "issue_number": 1,
      "title": "Playwright support ",
      "body": "Do you plan to support playwright?",
      "state": "closed",
      "author": "skuam",
      "author_type": "User",
      "created_at": "2024-03-03T16:40:17Z",
      "updated_at": "2024-04-19T17:06:56Z",
      "closed_at": "2024-04-19T17:06:56Z",
      "labels": [
        "new feature",
        "approved",
        "community-assigned"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/1/reactions",
        "total_count": 4,
        "+1": 3,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 1
      },
      "assignees": [
        "mbrunel"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/1",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/1",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:54.327855",
      "comments": [
        {
          "author": "dhuynh95",
          "body": "I might not have time to but it should not be complicated. If you look at the code, you just need to load the driver first, then you will have to edit the prompt template to adapt it for playwright ",
          "created_at": "2024-03-03T19:43:08Z"
        },
        {
          "author": "afsarali-pg",
          "body": "I would love to contribute for this feature . Plz let me know what would be starting point for me to see any example ",
          "created_at": "2024-03-14T12:37:40Z"
        },
        {
          "author": "lyie28",
          "body": "Hey @afsarali-pg,\r\n\r\nThat would be awesome!\r\n\r\nWe are just cleaning and re-organizing the codebase into a modular python package with a CLI to make it easier for people to build on- this should be done in the next few days.\r\n\r\nI'll let you know when that is done and give you some more info then. But",
          "created_at": "2024-03-14T14:31:12Z"
        },
        {
          "author": "lyie28",
          "body": "Hey @afsarali-pg,\n\nFor now, we have created a Python package for the Action Engine and have updated our notebook accordingly.\n\nThe Action Engine takes HTML source code, splitting it up into smaller chunks, indexing it with an embedding model and getting the most relevant HTML code:\n`action_engine.ge",
          "created_at": "2024-03-15T13:50:35Z"
        },
        {
          "author": "lyie28",
          "body": "Hey @afsarali-pg,\n\nAs you may have noticed - the code base has grown quite a lot since we last spoke!  We also have [docs now](https://docs.lavague.ai/en/latest/)\n\nAre you still wanting to work on the Playwright feature, as we are looking to assign this to someone? Are you on Discord? If so, could b",
          "created_at": "2024-03-25T15:16:48Z"
        }
      ]
    },
    {
      "issue_number": 64,
      "title": "VSCode plug-in for LaVague",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-03-25T15:24:26Z",
      "updated_at": "2024-04-19T17:06:28Z",
      "closed_at": "2024-04-19T17:06:28Z",
      "labels": [
        "core"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/64/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "JoFrost"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/64",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/64",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:54.560032",
      "comments": []
    },
    {
      "issue_number": 103,
      "title": "Cleaning of HTML to remove useless parts ",
      "body": "@shubhamofbce  mentioned the relevancy of removing stuff like SVG and all:\r\nhttps://discord.com/channels/1216089456134586388/1216359221793128589/1225301018032734248\r\n> I am playing with HTML itself, We don't need to create index with whole HTML. We can clean up styles, svg tags and script tags as it is just another text for the LLM.\r\nWith this my token count is getting reduced by 10x and I am getting better answers for my query.\r\n\r\nI think it's quite relevant and we should explore this",
      "state": "closed",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-04-05T00:42:18Z",
      "updated_at": "2024-04-18T22:30:52Z",
      "closed_at": "2024-04-18T22:30:52Z",
      "labels": [
        "enhancement",
        "core"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/103/reactions",
        "total_count": 2,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 2,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "mbrunel"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/103",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/103",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:54.560068",
      "comments": []
    },
    {
      "issue_number": 123,
      "title": "Build TheWave dataset",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-16T14:05:54Z",
      "updated_at": "2024-04-17T15:52:17Z",
      "closed_at": "2024-04-17T15:52:17Z",
      "labels": [
        "community-assigned"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/123/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "dhuynh95"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/123",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/123",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:54.560080",
      "comments": []
    },
    {
      "issue_number": 95,
      "title": "Add MacOS installation instructions",
      "body": "- Create a 'setup-macos' script at root of repo\r\n- Add a 'MacOS' sub-section to the docs/docs/get-started/setting-up-la-vague installation guide",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-04T07:12:25Z",
      "updated_at": "2024-04-17T15:51:39Z",
      "closed_at": "2024-04-17T15:51:38Z",
      "labels": [
        "help wanted",
        "community-assigned"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/95/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/95",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/95",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:54.560090",
      "comments": [
        {
          "author": "willschneider15",
          "body": "https://github.com/lavague-ai/LaVague/pull/104",
          "created_at": "2024-04-05T07:17:40Z"
        },
        {
          "author": "1of13",
          "body": "Thank you for adding a MacOS script. \r\n\r\nThe url to chromedriver and chome in the script is outdated. See the error below. Also, after manually downloading the files, my computer refuses to launch them--even after \"chmod +x\". Any suggestions of how to fix that?\r\n\r\n<img width=\"626\" alt=\"SCR-20240416-",
          "created_at": "2024-04-16T17:54:34Z"
        },
        {
          "author": "willschneider15",
          "body": "Try copying down just the bash script and running that. Since it was designed to do everything including clone down the repo.\n\nAlso take screenshots of your terminal including the commands you ran if you do have issues.",
          "created_at": "2024-04-16T19:09:21Z"
        },
        {
          "author": "1of13",
          "body": "Thanks for the reply. Here is the command I ran and the results. Like I mentioned before, there are a bunch of errors.\r\n\r\n\r\n(base) collective@collective LaVague % sudo bash setup-macos.sh              \r\nPassword:\r\nhttps://storage.googleapis.com/chrome-for-testing-public/123.0.6312.105/mac-arm64/chro",
          "created_at": "2024-04-16T19:25:39Z"
        },
        {
          "author": "willschneider15",
          "body": "https://stackoverflow.com/questions/33886917/how-to-install-wget-in-macos\n\nAlso, I am willing to bet those URLs are not your computer password.",
          "created_at": "2024-04-16T20:00:29Z"
        }
      ]
    },
    {
      "issue_number": 4,
      "title": "Setting up software CI processes & actions",
      "body": "- automated testing needed after pushes to main",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-03-12T15:34:56Z",
      "updated_at": "2024-04-17T15:51:22Z",
      "closed_at": "2024-04-17T15:51:22Z",
      "labels": [
        "CI/CD"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/4/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/4",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/4",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:54.822513",
      "comments": [
        {
          "author": "dhuynh95",
          "body": "I have created this test file to test the Gradio interface (with LaVague!).\n\nMight be some issues with timing of the sleep time to make sure we wait until LaVague finishes generating code and executing it, before moving to the next action.\n\n```python\nimport time\n\nfrom selenium import webdriver\nfrom ",
          "created_at": "2024-03-26T01:08:52Z"
        }
      ]
    },
    {
      "issue_number": 97,
      "title": "Improve CLI",
      "body": "- cleaner code\n- remove import overheads\n- change config file logic ?",
      "state": "closed",
      "author": "mbrunel",
      "author_type": "User",
      "created_at": "2024-04-04T14:08:04Z",
      "updated_at": "2024-04-17T15:51:02Z",
      "closed_at": "2024-04-17T15:51:02Z",
      "labels": [
        "enhancement",
        "core"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/97/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "mbrunel"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/97",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/97",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:55.071526",
      "comments": []
    },
    {
      "issue_number": 122,
      "title": "Launch BigAction initiative",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-16T14:05:08Z",
      "updated_at": "2024-04-17T15:50:49Z",
      "closed_at": "2024-04-17T15:50:49Z",
      "labels": [
        "BigAction"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/122/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "dhuynh95"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/122",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/122",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:55.071553",
      "comments": []
    },
    {
      "issue_number": 124,
      "title": "Release improved performance version",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-16T14:08:40Z",
      "updated_at": "2024-04-16T14:18:39Z",
      "closed_at": "2024-04-16T14:18:39Z",
      "labels": [
        "AI-performance"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/124/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "dhuynh95",
        "HiImMadness"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/124",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/124",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:55.071566",
      "comments": []
    },
    {
      "issue_number": 119,
      "title": "Docs page on prompting/instructions guidelines",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-16T13:38:05Z",
      "updated_at": "2024-04-16T14:14:57Z",
      "closed_at": "2024-04-16T14:14:57Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/119/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/119",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/119",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:55.071575",
      "comments": []
    },
    {
      "issue_number": 121,
      "title": "Create open source tool for contributing to LAM dataset(s)",
      "body": null,
      "state": "open",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-16T14:04:43Z",
      "updated_at": "2024-04-16T14:13:38Z",
      "closed_at": null,
      "labels": [
        "BigAction"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/121/reactions",
        "total_count": 2,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 1,
        "eyes": 0
      },
      "assignees": [
        "dhuynh95",
        "HiImMadness"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/121",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/121",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:55.071583",
      "comments": []
    },
    {
      "issue_number": 109,
      "title": "Create stable demo website that won't change to illustrate LaVague",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-08T15:22:58Z",
      "updated_at": "2024-04-16T13:37:00Z",
      "closed_at": "2024-04-16T13:37:00Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/109/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/109",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/109",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:55.071590",
      "comments": []
    },
    {
      "issue_number": 72,
      "title": "Make getting started experience quicker and easier",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-03-26T18:55:41Z",
      "updated_at": "2024-04-08T15:26:19Z",
      "closed_at": "2024-04-08T15:26:19Z",
      "labels": [
        "core"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/72/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/72",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/72",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:55.071600",
      "comments": [
        {
          "author": "lyie28",
          "body": "Aim to reduce steps needed to set-up and run LaVague locally and then update with new shorter steps",
          "created_at": "2024-03-26T18:56:26Z"
        }
      ]
    },
    {
      "issue_number": 108,
      "title": "Docker: permission denied on entrypoint.sh",
      "body": "Docker image permission denied issue to be fixed",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-04-08T09:11:04Z",
      "updated_at": "2024-04-08T12:51:43Z",
      "closed_at": "2024-04-08T12:51:43Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/108/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/108",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/108",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:55.318055",
      "comments": [
        {
          "author": "lyie28",
          "body": "Fixed and updated docker image and docker instructions in docs. Please re-pull the latest image version and use the latest instructions.",
          "created_at": "2024-04-08T12:51:43Z"
        }
      ]
    },
    {
      "issue_number": 59,
      "title": "Do new PyPi release",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-03-22T14:46:34Z",
      "updated_at": "2024-04-04T19:51:53Z",
      "closed_at": "2024-04-04T19:51:53Z",
      "labels": [
        "core",
        "CI/CD"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/59/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/59",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/59",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:55.593033",
      "comments": []
    },
    {
      "issue_number": 53,
      "title": "Split LaVague dependencies so the package is not so heavy",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-03-22T09:57:07Z",
      "updated_at": "2024-04-04T18:06:23Z",
      "closed_at": "2024-04-04T18:06:23Z",
      "labels": [
        "enhancement",
        "core"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/53/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "mbrunel"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/53",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/53",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:55.593052",
      "comments": []
    },
    {
      "issue_number": 19,
      "title": "Create a decentralized dataset of interactions between users and LaVague to improve model and evaluate its performance",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-03-14T09:44:34Z",
      "updated_at": "2024-04-04T17:41:34Z",
      "closed_at": "2024-04-04T17:41:34Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/19/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "JoFrost"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/19",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/19",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:55.593058",
      "comments": []
    },
    {
      "issue_number": 55,
      "title": "Documentation: Add customization/under the hood guide",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-03-22T09:58:43Z",
      "updated_at": "2024-04-04T16:54:23Z",
      "closed_at": "2024-04-04T16:54:23Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/55/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/55",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/55",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:55.593064",
      "comments": []
    },
    {
      "issue_number": 12,
      "title": "Make HF Gradio space",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-03-13T14:00:15Z",
      "updated_at": "2024-04-04T15:40:15Z",
      "closed_at": "2024-04-04T15:40:15Z",
      "labels": [
        "core"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/12/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "JoFrost"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/12",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/12",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:55.593088",
      "comments": [
        {
          "author": "shubhamofbce",
          "body": "Can i work on this, I am just confused if i can add it to my hf account ??",
          "created_at": "2024-03-15T09:39:28Z"
        },
        {
          "author": "lyie28",
          "body": "Hi @shubhamofbce,\r\n\r\nWe are working on this one internally- in fact, it should be released soon!\r\n\r\nCheck out the issues with a 'help wanted' label for issues you can work on :)",
          "created_at": "2024-03-15T09:57:31Z"
        },
        {
          "author": "shubhamofbce",
          "body": "That's great.",
          "created_at": "2024-03-15T09:59:03Z"
        }
      ]
    },
    {
      "issue_number": 62,
      "title": "Split dependencies to install",
      "body": "We have a monolithic installation process, for instance cuda is installed by default, which is too heavy for some use cases.\r\n\r\nWe will provide soon a version where the Action Engine can be provided through a SaaS to make it easier for people who don't want to do computing locally, so their package will be very lightweight.\r\n\r\n@lyie28 Could you have a look? I guess this can be done in conjunction with #59 ",
      "state": "closed",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-03-23T14:36:19Z",
      "updated_at": "2024-04-04T07:27:22Z",
      "closed_at": "2024-04-04T07:26:49Z",
      "labels": [
        "duplicate",
        "core"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/62/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/62",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/62",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:55.809990",
      "comments": [
        {
          "author": "lyie28",
          "body": "Closing as duplicate issue",
          "created_at": "2024-04-04T07:27:22Z"
        }
      ]
    },
    {
      "issue_number": 14,
      "title": "User-Level Locking for Selenium Driver Instances",
      "body": "Assigning an ID to Selenium drivers and locking them for individual users",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-03-13T14:08:17Z",
      "updated_at": "2024-04-04T07:19:57Z",
      "closed_at": "2024-04-04T07:19:57Z",
      "labels": [
        "core"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/14/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "JoFrost"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/14",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/14",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:56.036675",
      "comments": []
    },
    {
      "issue_number": 66,
      "title": "code cleaning: add typing + comments, abstract driver",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-03-25T15:58:06Z",
      "updated_at": "2024-04-03T17:46:13Z",
      "closed_at": "2024-04-03T17:46:13Z",
      "labels": [
        "enhancement",
        "core"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/66/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "mbrunel"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/66",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/66",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:56.036694",
      "comments": []
    },
    {
      "issue_number": 16,
      "title": "Add docker option to \"getting started\"",
      "body": "**Is your feature request related to a problem? Please describe.**\r\nAdd a way for people to test and run this locally - not in a codelab. Docker is an easy path for folks.\r\n\r\n**Describe the solution you'd like**\r\nI'd like clear instructions on how to run this locally.\r\n",
      "state": "closed",
      "author": "Dbz",
      "author_type": "User",
      "created_at": "2024-03-14T02:32:23Z",
      "updated_at": "2024-04-03T15:53:09Z",
      "closed_at": "2024-04-03T15:53:09Z",
      "labels": [
        "approved"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/16/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "JoFrost",
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/16",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/16",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:56.036702",
      "comments": [
        {
          "author": "lyie28",
          "body": "Hey there,\r\n\r\nOur next step is to provide the code as a Python package.\r\n\r\nA docker would be a nice addition, but we won't have time to work on it for now so I've put it into our help-wanted section.",
          "created_at": "2024-03-14T13:23:03Z"
        },
        {
          "author": "smach",
          "body": "Python package would be another excellent option to run locally, thanks! You may want to change the website docs here, though, because it says that a Docker image is \"coming soon\"? Doesn't sound like it's expected soon. [https://docs.lavague.ai/en/latest/docs/get-started/get-started-docker/](https:/",
          "created_at": "2024-03-24T21:04:41Z"
        },
        {
          "author": "lyie28",
          "body": "@smach Thanks for flagging. In the end, we have decided to go with a dev Container option - have updated the docs: https://docs.lavague.ai/en/latest/docs/get-started/setting-up-la-vague/",
          "created_at": "2024-03-25T16:42:41Z"
        },
        {
          "author": "lyie28",
          "body": "We also created a docker image in the end too: https://docs.lavague.ai/en/latest/docs/get-started/setting-up-la-vague/ ",
          "created_at": "2024-04-03T15:53:09Z"
        }
      ]
    },
    {
      "issue_number": 65,
      "title": "Docs: add sec warning + telemetry info",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-03-25T15:58:01Z",
      "updated_at": "2024-04-02T11:26:17Z",
      "closed_at": "2024-04-02T11:26:17Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/65/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/65",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/65",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:56.234359",
      "comments": []
    },
    {
      "issue_number": 63,
      "title": "Add support for LM Studio",
      "body": "Is it possible to connect LM Studio?\r\n\r\nIf not, can you add it?\r\n\r\nThanks.",
      "state": "closed",
      "author": "zinwelzl",
      "author_type": "User",
      "created_at": "2024-03-24T10:15:04Z",
      "updated_at": "2024-03-26T10:10:30Z",
      "closed_at": "2024-03-26T10:10:30Z",
      "labels": [
        "help wanted"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/63/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/63",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/63",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:57.663937",
      "comments": [
        {
          "author": "lyie28",
          "body": "Hello,\n\nThanks for the issue. I have put this into our `help wanted` section for now as all our team are assigned to key tasks at the moment. If you would be interested in trying to integrate it, let us know!",
          "created_at": "2024-03-25T16:24:03Z"
        }
      ]
    },
    {
      "issue_number": 54,
      "title": "Documentation: add local integration guide",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-03-22T09:57:44Z",
      "updated_at": "2024-03-22T12:09:02Z",
      "closed_at": "2024-03-22T12:09:02Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/54/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/54",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/54",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:57.869826",
      "comments": []
    },
    {
      "issue_number": 23,
      "title": "Make command center CLI tool",
      "body": "The command center module should:\n- Get HTML source code from URL\n- Make calls to actionEngine using config file for customizable parameters such as models to use, prompt template to use, etc.\n- Execute the generated code",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-03-15T13:54:04Z",
      "updated_at": "2024-03-22T09:58:59Z",
      "closed_at": "2024-03-21T21:44:17Z",
      "labels": [
        "core"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/23/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "dhuynh95"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/23",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/23",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:57.869847",
      "comments": [
        {
          "author": "jmanhype",
          "body": "https://github.com/lavague-ai/LaVague/pull/37",
          "created_at": "2024-03-19T12:50:43Z"
        }
      ]
    },
    {
      "issue_number": 18,
      "title": "Improving retriever for better precision/ accuracy when finding relevant HTML of current page",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-03-14T09:43:38Z",
      "updated_at": "2024-03-22T09:30:07Z",
      "closed_at": "2024-03-22T09:30:07Z",
      "labels": [
        "duplicate",
        "enhancement"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/18/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/18",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/18",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:58.065112",
      "comments": []
    },
    {
      "issue_number": 13,
      "title": "Create documentation",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-03-13T14:01:45Z",
      "updated_at": "2024-03-22T09:27:06Z",
      "closed_at": "2024-03-22T09:26:17Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/13/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/13",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/13",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:58.065130",
      "comments": [
        {
          "author": "lyie28",
          "body": "Documentation available at: docs.lavague.ai",
          "created_at": "2024-03-22T09:26:30Z"
        }
      ]
    },
    {
      "issue_number": 11,
      "title": "Make quick-tour notebook for Python CLI",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-03-13T12:14:50Z",
      "updated_at": "2024-03-21T21:43:51Z",
      "closed_at": "2024-03-21T21:43:51Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/11/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/11",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/11",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:58.357781",
      "comments": []
    },
    {
      "issue_number": 38,
      "title": "Create wrapper for OpenAI for ease-of-use",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-03-19T13:22:28Z",
      "updated_at": "2024-03-21T21:43:01Z",
      "closed_at": "2024-03-21T21:42:16Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/38/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/38",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/38",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:58.357802",
      "comments": [
        {
          "author": "lyie28",
          "body": "Covered by CLI with OpenAI default file",
          "created_at": "2024-03-21T21:43:00Z"
        }
      ]
    },
    {
      "issue_number": 30,
      "title": "Streaming broken",
      "body": "#29 highlighted some recent issue with llama-index streaming not working anymore.\r\nHave to fix it",
      "state": "closed",
      "author": "dhuynh95",
      "author_type": "User",
      "created_at": "2024-03-16T14:50:15Z",
      "updated_at": "2024-03-19T13:17:05Z",
      "closed_at": "2024-03-19T13:17:05Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/30/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "mbrunel"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/30",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/30",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:58.588023",
      "comments": [
        {
          "author": "deepbeepmeep",
          "body": "Hi,\r\nI would be grateful if you could provide a fix also for the local LLM since it is broken as well\r\n\r\n",
          "created_at": "2024-03-16T18:57:21Z"
        },
        {
          "author": "lyie28",
          "body": "@deepbeepmeep, we are releasing some updates to the local code this week and some documentation so I think this will fix any issues.\r\n\r\nI'll close this issue now because streaming is fixed but please submit a bug report if you are still having issues at the end of the week with local inference",
          "created_at": "2024-03-19T13:17:05Z"
        }
      ]
    },
    {
      "issue_number": 8,
      "title": "Make codebase modular & create pypi package",
      "body": "Take code from Google Colab example and make it into a modular Python library",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-03-12T17:29:29Z",
      "updated_at": "2024-03-18T14:15:16Z",
      "closed_at": "2024-03-18T14:15:16Z",
      "labels": [
        "core"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/8/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "mbrunel"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/8",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/8",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:58.825149",
      "comments": []
    },
    {
      "issue_number": 3,
      "title": "Create contribution guidelines",
      "body": null,
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-03-12T15:04:33Z",
      "updated_at": "2024-03-13T14:09:15Z",
      "closed_at": "2024-03-13T14:09:15Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/3/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "lyie28"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/3",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/3",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:58.825172",
      "comments": []
    },
    {
      "issue_number": 10,
      "title": "Setup data telemetry for failure of AI",
      "body": "Add telemetry to help us improve performance/reduce failures:\n\nCollect:\nURL\nDate\nHTML code\nRetrieved nodes by Llama Index\nLLM used\nError message\nCode produced\nScreenshot",
      "state": "closed",
      "author": "lyie28",
      "author_type": "User",
      "created_at": "2024-03-13T12:13:25Z",
      "updated_at": "2024-03-13T12:14:38Z",
      "closed_at": "2024-03-13T12:14:38Z",
      "labels": [
        "core"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/lavague-ai/LaVague/issues/10/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "JoFrost"
      ],
      "milestone": null,
      "html_url": "https://github.com/lavague-ai/LaVague/issues/10",
      "api_url": "https://api.github.com/repos/lavague-ai/LaVague/issues/10",
      "repository": "lavague-ai/LaVague",
      "extraction_date": "2025-06-22T00:36:58.825180",
      "comments": []
    }
  ]
}