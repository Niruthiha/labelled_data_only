{
  "repository": "coleam00/local-ai-packaged",
  "repository_info": {
    "repo": "coleam00/local-ai-packaged",
    "stars": 1998,
    "language": "Python",
    "description": "Run all your local AI together in one package - Ollama, Supabase, n8n, Open WebUI, and more!",
    "url": "https://github.com/coleam00/local-ai-packaged",
    "topics": [],
    "created_at": "2025-02-16T21:12:36Z",
    "updated_at": "2025-06-22T02:19:22Z",
    "search_query": "together.ai language:python stars:>1",
    "total_issues_estimate": 130,
    "labeled_issues_estimate": 130,
    "labeling_rate": 100.0,
    "sample_labeled": 32,
    "sample_total": 32,
    "has_issues": true,
    "repo_id": 933862859,
    "default_branch": "main",
    "size": 4056
  },
  "extraction_date": "2025-06-22T00:48:32.536367",
  "extraction_type": "LABELED_ISSUES_ONLY",
  "total_labeled_issues": 68,
  "issues": [
    {
      "issue_number": 108,
      "title": "[BUG] N8N Pipe for Open WebUI",
      "body": "No matter how simple a workflow I create with an AI Agent hooked into an Open WebUI pipe (as described by Cole in one of his latest videos) - I always get this same error:\n\n\"Error during sequence execution: list indices must be integers or slices, not str\"\n\n\n\n\n\n\n\n\n\n",
      "state": "open",
      "author": "AlexanderHanff",
      "author_type": "User",
      "created_at": "2025-06-22T02:30:35Z",
      "updated_at": "2025-06-22T02:30:35Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/108/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/108",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/108",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:18.336616",
      "comments": []
    },
    {
      "issue_number": 102,
      "title": "[BUG] /etc/vector/vector.yml is a directory",
      "body": "## Description\nWhen starting stack thru (python start_services.py --profile gpu-amd) receive this error.\n```\n2025-06-18T13:06:18.645103Z  INFO vector::app: Loading configs. paths=[\"/etc/vector/vector.yml\"]\n2025-06-18T13:06:18.645165Z ERROR vector::cli: Configuration error. error=Is a directory (os error 21)\n```\n\n## Steps to Reproduce\n1. Go to 'local-ai-packaged'\n2. run 'python start_services.py --profile gpu-amd'\n3. \"first stage\" of setup runs fine but when supabase gets cleared and everything gets rebuilt I receive the error. \n\n## Expected Behavior\nI would expect that vector would properly create the .yml file it is looking for.\n\n## Actual Behavior\nThe logs state that it is creating the .yml as a directory.\n\n## Screenshots\n![Image](https://github.com/user-attachments/assets/fa020760-d34e-4b64-9abb-86a340f28f4d)\n\n## Environment\n - OS: [linux - garuda - arch]\n - Using podman with podman-docker\n\n## Additional Context\nAdd any other context about the problem here, such as:\n- Does this happen consistently or intermittently? Consistently\n- Were there any recent changes that might be related? None that I can think of.\n- Any workarounds you've discovered? I have not discovered any solutions but I have checked for this issue. Solution https://github.com/orgs/supabase/discussions/26362#discussioncomment-9513623 did not fix this for me.\n\nI have other issues as well but I think this one might be the cause of the others so I am starting with it.\n\nThank you for your assistance and patience. I will try not to drink dumbdumb juice today. <3",
      "state": "open",
      "author": "Reaper176",
      "author_type": "User",
      "created_at": "2025-06-18T13:15:53Z",
      "updated_at": "2025-06-21T14:17:34Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/102/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/102",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/102",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:18.336639",
      "comments": [
        {
          "author": "Reaper176",
          "body": "I have since this, reinstalled my os and installed only docker-desktop\n\nlogs continue to show\n```\n2025-06-20T19:30:14.768091Z  INFO vector::app: Internal log rate limit configured. internal_log_rate_secs=10\n2025-06-20T19:30:14.768184Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec",
          "created_at": "2025-06-20T19:32:32Z"
        },
        {
          "author": "Reaper176",
          "body": "I have attempted to change the location out of /etc/vector/vector.yml to a new location \"home/john/supa-vec/vector.yml but it now throws an error that the mount path must be absolute and I have no idea what that means. Never the less. I shall continue.\n",
          "created_at": "2025-06-21T14:17:34Z"
        }
      ]
    },
    {
      "issue_number": 83,
      "title": "[FEATURE] Add capability to host on headless local server",
      "body": "## Describe the feature you'd like and why\nI work primarily from a laptop and host my AI services from another machine as a headless server. This would function similarly to cloud, but still be local.\n\n## User Impact\nProvides more flexibility for accessing AI services from remote locations on the same network. (i.e. use n8n from laptop on the couch/bed/etc.)\n\n## Implementation Details (optional)\nIt seems like the introduction of the \"profiles\" has solidified this project as something which is intended to be hosted on the same machine you plan to access the web services from. I would suggest adding an additional profile which provides more flexibility to host the services through the docker host gateway.\n\n## Additional context\nAs an alternative, you could maintain alternate branches in git to host a version of the project which is supports headless configurations.",
      "state": "open",
      "author": "psiryan",
      "author_type": "User",
      "created_at": "2025-06-05T00:46:17Z",
      "updated_at": "2025-06-21T00:19:13Z",
      "closed_at": null,
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/83/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/83",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/83",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:18.580577",
      "comments": [
        {
          "author": "skibsthebear",
          "body": "Install Tailscale and funnel port 5678 for access to n8n. If you want other things, you can also set up public facing ports with it. If you use tailscale serve, then it'll let you create a tailnet vpn of your devices and make all the services accessible with just your devices but remotely :) Until t",
          "created_at": "2025-06-12T12:24:04Z"
        }
      ]
    },
    {
      "issue_number": 106,
      "title": "[error] failed to start: container supabase-vector is unhealthy",
      "body": "```\npython start_services.py --profile none\nSupabase repository already exists, updating...\nRunning: git pull\nAlready up to date.\nCopying .env in root to .env in supabase/docker...\nChecking SearXNG settings...\nSearXNG settings.yml already exists at searxng/settings.yml\nGenerating SearXNG secret key...\nDetected Linux/Unix platform, using standard sed command...\nSearXNG secret key generated successfully.\nNo running SearXNG container found - assuming first run\nStopping and removing existing containers for the unified project 'localai'...\nRunning: docker compose -p localai -f docker-compose.yml down\nWARN[0000] The \"FLOWISE_USERNAME\" variable is not set. Defaulting to a blank string.\nWARN[0000] The \"FLOWISE_PASSWORD\" variable is not set. Defaulting to a blank string.\nStarting Supabase services...\nRunning: docker compose -p localai -f supabase/docker/docker-compose.yml up -d\n[+] Running 14/14\n‚úî Network localai_default                   Created                                  0.0s\n‚úò Container supabase-vector                 Error                                    1.8s\n‚úî Container supabase-imgproxy               Started                                  1.3s\n‚úî Container supabase-db                     Created                                  0.1s\n‚úî Container supabase-analytics              Create...                                0.1s\n‚úî Container supabase-kong                   Created                                  0.5s\n‚úî Container supabase-pooler                 Created                                  0.5s\n‚úî Container supabase-edge-functions         C...                                     0.5s\n‚úî Container realtime-dev.supabase-realtime  Created                                  0.5s\n‚úî Container supabase-rest                   Created                                  0.4s\n‚úî Container supabase-studio                 Created                                  0.5s\n‚úî Container supabase-auth                   Created                                  0.5s\n‚úî Container supabase-meta                   Created                                  0.6s\n‚úî Container supabase-storage                Created                                  0.2s\ndependency failed to start: container supabase-vector is unhealthy\nTraceback (most recent call last):\nFile \"/run/media/john/Malconthet/github/local-ai-packaged/start_services.py\", line 248, in <module>\nmain()\n~~~~^^\nFile \"/run/media/john/Malconthet/github/local-ai-packaged/start_services.py\", line 238, in main\nstart_supabase(args.environment)\n~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\nFile \"/run/media/john/Malconthet/github/local-ai-packaged/start_services.py\", line 64, instart_supabase\nrun_command(cmd)\n~~~~~~~~~~~^^^^^\nFile \"/run/media/john/Malconthet/github/local-ai-packaged/start_services.py\", line 21, inrun_command\nsubprocess.run(cmd, cwd=cwd, check=True)\n~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile \"/usr/lib/python3.13/subprocess.py\", line 577, in run\nraise CalledProcessError(retcode, process.args,\noutput=stdout, stderr=stderr)\nsubprocess.CalledProcessError: Command '['docker', 'compose', '-p', 'localai', '-f', 'supabase/docker/docker-compose.yml', 'up', '-d']' returned non-zero exit status 1.\n```",
      "state": "open",
      "author": "Reaper176",
      "author_type": "User",
      "created_at": "2025-06-19T23:06:51Z",
      "updated_at": "2025-06-20T19:31:11Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/106/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/106",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/106",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:18.738042",
      "comments": [
        {
          "author": "LostInInaka",
          "body": "You should be able to fix this by adding \n\n`LOGFLARE_PUBLIC_ACCESS_TOKEN=your-super-secret-and-long-logflare-key-your-super-secret-and-long-logflare-key`\n\nto your .env file - just replace your-super-secret-and-long-logflare-key-your-super-secret-and-long-logflare-key with your own key",
          "created_at": "2025-06-20T04:25:50Z"
        },
        {
          "author": "Reaper176",
          "body": "@LostInInaka I am already have those filled out. Issue persists. \n\nTerminal readout\n```\n‚úñ] Û∞õì  python start_services.py --profile none\nSupabase repository already exists, updating...\nRunning: git pull\nAlready up to date.\nCopying .env in root to .env in supabase/docker...\nChecking SearXNG settings...\n",
          "created_at": "2025-06-20T19:31:11Z"
        }
      ]
    },
    {
      "issue_number": 107,
      "title": "[BUG] unversioned directory \"supabase/\"",
      "body": "## Description\n\nGit tells me that I have a directory that is not under version control, should this be in the git ignore file?\n\n## Steps to Reproduce\n\n- start the system\n- `git status`\n\n## Expected Behavior\nnothing to see\n\n\n## Actual Behavior\n\nit lists `supabase/` as unversioned\n\n## Screenshots\nIf applicable, add screenshots to help explain your problem.\n\n## Environment\n\nmac\n\n## Possible Solution\n\nadd `supabase/` to git ignore file if this is the right thing to do",
      "state": "open",
      "author": "hoschi",
      "author_type": "User",
      "created_at": "2025-06-20T18:15:55Z",
      "updated_at": "2025-06-20T18:15:55Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/107/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/107",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/107",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:18.971925",
      "comments": []
    },
    {
      "issue_number": 1,
      "title": "Additions to the Local AI Package",
      "body": "hey bro im so glad you added supabase and kept qdrant. if you dont mind id like to make some suggestions\n\nTraefik for reverse proxy - manage local self signed ssl and sub domains (n8n.yourlocaldomain.you)\nAuthentik - Auth and SSO for the stack\n\nLissy Dashy - cenrtral hub UI portal for the other services\nDokploy - self hosted app launch platform (your own personal local \"github\" for all your software projects)\n\nset flowise and n8n to queue mode : \nn8n-main\nn8n-worker\nn8n-webhook-processor\n\nflowise-main\nflowise-worker\n\nRedis for process cache and process queue management \nredisinsight to visualize process queues\n\nBrowser-use webui  \nCrawl4ai\nPerplexica + SearXNG\n\nBolt.diy\nOpenhands\n\nComfyUI\n\nLastly you can set a variable in the .env file that sets compose to use ollama cpu or gpu instead of launching the stack with a -gpu tag\n\nI have so many more in my plan but I think this outlines a perfect baseline self hosted AI stack when added to your project. \n\nFYI- the only downside to Supabase is that the community edition is only capable of single tenant single thread operations. while it can qeue serial processes it can not execute parallel operations. Also you are limited to a single \"project\" per supabase stack so even though you can create new tables and schema for various services in the same supabase, you cant have multiple seperate databases isolated fom each other in the same supabase stack. the solution is to setup sub stacks on isolated docker networks bridged to the main netowork, one for each seperate database you need.\n\nlike you i also use Docker desktop in windows with WSL2 integration, for this I got my free 3 node Portainer BE license and set that up in WSL, this gives me intricate stack and docker  network controls",
      "state": "open",
      "author": "RepairYourTech",
      "author_type": "User",
      "created_at": "2025-02-17T01:46:00Z",
      "updated_at": "2025-06-20T16:51:05Z",
      "closed_at": null,
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 10,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/1/reactions",
        "total_count": 7,
        "+1": 5,
        "-1": 0,
        "laugh": 0,
        "hooray": 2,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/1",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/1",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:18.971942",
      "comments": [
        {
          "author": "coleam00",
          "body": "This are all great suggestions, thank you so much @mayphilc! Love the title for your issue too haha",
          "created_at": "2025-02-18T20:21:07Z"
        },
        {
          "author": "coleam00",
          "body": "Adding this to a new project board I'm about to create for the local AI package üëç ",
          "created_at": "2025-02-24T19:03:28Z"
        },
        {
          "author": "RepairYourTech",
          "body": "> Adding this to a new project board I'm about to create for the local AI package üëç \n\nYou can look into using Deployarr to launch the initial proxy + forward auth with traefik, saves so much headache and setup and you can add to what it sets up, it uses includes so you can just add to it",
          "created_at": "2025-02-25T13:18:17Z"
        },
        {
          "author": "RepairYourTech",
          "body": "so ive been talking to the gentleman who created Deployarr (previosuly known as auto-traefik) and hes going to add about 20 ai related apps (i gave him the list) to the next release of Deployarr v5.7 .  ",
          "created_at": "2025-02-27T11:53:14Z"
        },
        {
          "author": "RepairYourTech",
          "body": "![Image](https://github.com/user-attachments/assets/ce0edfe8-4eb2-4d3f-8057-26b5e3f44df6)\n\nim almost done lol. its getting complicated with a stack this big. I need to find a way to add bolt.diy without building from the dockerfile",
          "created_at": "2025-03-03T01:37:52Z"
        }
      ]
    },
    {
      "issue_number": 76,
      "title": "[BUG] After updating to Sequoia 15.5 and updating the package fresh install also fails",
      "body": "After updating to Macos 15.5 (from 15.4.1) i tried to update the package and by starting the service n8n container does not start and can't be manually started as there seems to be an issue with n8n-import.\n(on another machine with 15.4.4 it works fine)\n\nterminal output is (supabase starts as well):\n\n```\n[+] Running 5/5\n ‚úò Container n8n-import  service \"n8n-import\" didn't complete successfully: exit 139                           0.8s \n ‚úî Container open-webui  Started                                                                               0.3s \n ‚úî Container flowise     Started                                                                               0.2s \n ‚úî Container qdrant      Started                                                                               0.3s \n ‚úî Container n8n         Created                                                                               0.0s \nservice \"n8n-import\" didn't complete successfully: exit 139\nTraceback (most recent call last):\n  File \"/Users/uwesommer/local-ai-packaged/start_services.py\", line 95, in <module>\n    main()\n  File \"/Users/uwesommer/local-ai-packaged/start_services.py\", line 92, in main\n    start_local_ai(args.profile)\n  File \"/Users/uwesommer/local-ai-packaged/start_services.py\", line 72, in start_local_ai\n    run_command(cmd)\n  File \"/Users/uwesommer/local-ai-packaged/start_services.py\", line 19, in run_command\n    subprocess.run(cmd, cwd=cwd, check=True)\n  File \"/Users/uwesommer/anaconda3/lib/python3.11/subprocess.py\", line 571, in run\n    raise CalledProcessError(retcode, process.args,\nsubprocess.CalledProcessError: Command '['docker', 'compose', '-p', 'localai', '-f', 'docker-compose.yml', 'up', '-d']' returned non-zero exit status 1.\n```\n\n\ncan you help?",
      "state": "open",
      "author": "yvesete",
      "author_type": "User",
      "created_at": "2025-06-02T05:17:07Z",
      "updated_at": "2025-06-20T07:49:42Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/76/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/76",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/76",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:19.269402",
      "comments": [
        {
          "author": "leex279",
          "body": "Closed, as @yvesete posted this as well in the community and got it fixed:\nhttps://thinktank.ottomator.ai/t/problem-to-copy-n8n-workflows-out-of-local-ai-packaged/7422/6",
          "created_at": "2025-06-03T06:38:38Z"
        },
        {
          "author": "yvesete",
          "body": "well actualy these are 2 different topics, got the workflows out of the database but updating the local-ai-package under sequoia 15.5 doesn't work (for me)",
          "created_at": "2025-06-03T06:47:50Z"
        },
        {
          "author": "leex279",
          "body": "@yvesete ah sry, ok. I reopened it.",
          "created_at": "2025-06-03T06:50:11Z"
        },
        {
          "author": "leex279",
          "body": "Can you post the full log of the n8n-import container please?",
          "created_at": "2025-06-03T06:51:22Z"
        },
        {
          "author": "yvesete",
          "body": "The log in docker dektop for n8n import only shows:: Segmentation fault\n\n\nThe full message after starting the service is:\n\n(base) uwesommer@Mac local-ai-packaged % python3 start_services.py --profile none\nSupabase repository already exists, updating...\nRunning: git pull\nremote: Enumerating objects: ",
          "created_at": "2025-06-03T11:34:50Z"
        }
      ]
    },
    {
      "issue_number": 42,
      "title": "[BUG] Container supabase-analytics Error",
      "body": "_**Ubuntu 20.x LTS, self-hosted, dedicated server, 8 core, 32 MB ram, script start_services.py (latest)**_ \n\n## Question\nCan someone help with this? \n\nAre these **kind of health-checks** valid with a real domain name in the server?...\n\n```\ndepends_on:\n      analytics:\n        condition: service_healthy\n    environment:\n      STUDIO_PG_META_URL: http://meta:8080\n      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}\n\n      DEFAULT_ORGANIZATION_NAME: ${STUDIO_DEFAULT_ORGANIZATION}\n      DEFAULT_PROJECT_NAME: ${STUDIO_DEFAULT_PROJECT}\n      OPENAI_API_KEY: ${OPENAI_API_KEY:-}\n\n      SUPABASE_URL: http://kong:8000\n      SUPABASE_PUBLIC_URL: ${SUPABASE_PUBLIC_URL}\n      SUPABASE_ANON_KEY: ${ANON_KEY}\n      SUPABASE_SERVICE_KEY: ${SERVICE_ROLE_KEY}\n      AUTH_JWT_SECRET: ${JWT_SECRET}\n\n[...]\n\nauth:\n    container_name: supabase-auth\n    image: supabase/gotrue:v2.170.0\n    restart: unless-stopped\n    healthcheck:\n      test:\n        [\n          \"CMD\",\n          \"wget\",\n          \"--no-verbose\",\n          \"--tries=1\",\n          \"--spider\",\n          \"http://localhost:9999/health\"\n        ]\n      timeout: 5s\n      interval: 5s\n      retries: 3\n\n[...]\n\n```\n\n## Steps to Reproduce\ntrigger: python3 start_services.py --profile cpu\n\n\n## Ouput\n\n```\nStarting Supabase services...\nRunning: docker compose -p localai -f supabase/docker/docker-compose.yml up -d\n[+] Running 14/14\n ‚úî Network localai_default                   Created                                                             0.1s\n ‚úî Container supabase-imgproxy               Started                                                             0.8s\n ‚úî Container supabase-vector                 Healthy                                                             6.3s\n ‚úî Container supabase-db                     Healthy                                                            13.1s\n ‚úò Container supabase-analytics              Error                                                             125.3s\n ‚úî Container supabase-rest                   Created                                                             0.1s\n ‚úî Container supabase-meta                   Created                                                             0.1s\n ‚úî Container supabase-kong                   Created                                                             0.1s\n ‚úî Container realtime-dev.supabase-realtime  Created                                                             0.1s\n ‚úî Container supabase-edge-functions         Created                                                             0.1s\n ‚úî Container supabase-studio                 Created                                                             0.1s\n ‚úî Container supabase-auth                   Created                                                             0.1s\n ‚úî Container supabase-pooler                 Created                                                             0.1s\n ‚úî Container supabase-storage                Created                                                             0.0s\ndependency failed to start: container supabase-analytics is unhealthy\nTraceback (most recent call last):\n  File \"start_services.py\", line 242, in <module>\n    main()\n  File \"start_services.py\", line 232, in main\n    start_supabase()\n  File \"start_services.py\", line 63, in start_supabase\n    run_command([\n  File \"start_services.py\", line 21, in run_command\n    subprocess.run(cmd, cwd=cwd, check=True)\n  File \"/usr/lib/python3.8/subprocess.py\", line 516, in run\n    raise CalledProcessError(retcode, process.args,\nsubprocess.CalledProcessError: Command '['docker', 'compose', '-p', 'localai', '-f', 'supabase/docker/docker-compose.yml', 'up', '-d']' returned non-zero exit status 1.\n```\n",
      "state": "closed",
      "author": "Steviey",
      "author_type": "User",
      "created_at": "2025-04-07T11:56:13Z",
      "updated_at": "2025-06-19T20:01:46Z",
      "closed_at": "2025-04-17T17:03:54Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/42/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/42",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/42",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:19.545249",
      "comments": [
        {
          "author": "Steviey",
          "body": "wrong password settings- my fault.",
          "created_at": "2025-04-17T17:03:54Z"
        },
        {
          "author": "Reaper176",
          "body": "I am actually having the same issue. What exactly did you do to fix this? Like what setting was wrong?",
          "created_at": "2025-06-19T20:01:46Z"
        }
      ]
    },
    {
      "issue_number": 105,
      "title": "[FEATURE] Hardware requirements",
      "body": "Can we please confirm the hardware requirements perhaps with reasons?\nI am uncertain if the 8gig ram is only needed for running the recommended local models and not for the apps thus lets say if you where only running a tiny model and mostly other cloud API's for LLM I would then be fine to host this package effectively on a 2 gig (what is min when disregarding models?) or 4gig ram VPS? Thanks",
      "state": "open",
      "author": "jay377",
      "author_type": "User",
      "created_at": "2025-06-19T18:14:54Z",
      "updated_at": "2025-06-19T18:14:54Z",
      "closed_at": null,
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/105/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/105",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/105",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:19.764263",
      "comments": []
    },
    {
      "issue_number": 103,
      "title": "[BUG]",
      "body": "## Description\nSetup instructions on Hostinger deployment doesn't work. When all the setup is done when I navigate to my domain I get this error.\n\n```txt\nThis site can‚Äôt provide a secure connection\nn8n.<my_doman_name>.com sent an invalid response.\nERR_SSL_PROTOCOL_ERROR\n```\n\nBasically HTTPS is not enabled on the site and hence the error?\n\n## Steps to Reproduce\n1. Follow the readme instructions to install. Enable the `ufw and 80, 443 ports etc`\n2. Do all the configurations changes suggested in the `.env` file.\n3. Add the `A` record in the DNS\n4. Run the setup command `python3 start_services.py --profile cpu`\n5. Wait for the installations to complete. Once done navigate to the  endpoints `n8n.<domain>.com` ... etc SSL errors are observed.\n\n## Expected Behavior\nShould Caddy should be able to provide the SSL certificates from `let's encrypt`\n\n\n\n## Screenshots\nIf applicable, add screenshots to help explain your problem.\n\n## Environment\n - OS: Ubuntu 24.04\n - Using Docker \n\n\n",
      "state": "closed",
      "author": "Santhosh-KS",
      "author_type": "User",
      "created_at": "2025-06-18T18:54:56Z",
      "updated_at": "2025-06-18T19:02:07Z",
      "closed_at": "2025-06-18T19:02:07Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/103/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/103",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/103",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:19.764285",
      "comments": [
        {
          "author": "Santhosh-KS",
          "body": "Applogies. I missed to enable `LETSENCRYPT_EMAIL` variable. After enabling and providing the proper email Issue is resolved!",
          "created_at": "2025-06-18T19:02:07Z"
        }
      ]
    },
    {
      "issue_number": 96,
      "title": "[FEATURE] Instructions/Support for using with LM Studio instead of Ollama",
      "body": "## Describe the feature you'd like and why\nI am running on macOS Sequoia 15.5 and have manage most of my local models with LM Studio.  I have done a fair bit of customization to the local models in LM Studio and I generally prefer managing models with LM Studio over Ollama.  I do not want to have to manage links from Ollama to LM Studio's models and I prefer to have LM Studio managing the loading/unloading of models on the machine.\n\n## User Impact\nUsers who prefer using LM Studio to Ollama.\n\n## Implementation Details (optional)\nI was hoping it could be done with just some instructions for tweaking the current configuration, but I have not looked deeply enough into the source to see how the workflow sends requets to Ollama.\n\n## Additional context\nPlease let me know if you need further details.",
      "state": "open",
      "author": "tonygod",
      "author_type": "User",
      "created_at": "2025-06-15T21:12:13Z",
      "updated_at": "2025-06-17T01:58:42Z",
      "closed_at": null,
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/96/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/96",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/96",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:19.942581",
      "comments": [
        {
          "author": "tonygod",
          "body": "I was able to get the workflow working with LM Studio:\n1. Removed the ollama stuff out of the docker-compose.yml and docker-compose.override.privatelyml\n2. In docker-compose.yml, replaced the OLLAMA_HOST port (11434) with the LM Studio port (1234).  I probably could have changed LM Studio to use the",
          "created_at": "2025-06-17T01:58:42Z"
        }
      ]
    },
    {
      "issue_number": 98,
      "title": "[BUG] Error: \"supabase-vector\" is not a valid container, cannot be used as a dependency: no container with name or ID \"supabase-vector\" found: no such container",
      "body": "## Description\nError: \"supabase-vector\" is not a valid container, cannot be used as a dependency: no container with name or ID \"supabase-vector\" found: no such container\n\n## Steps to Reproduce\n1. run python start_services.py \n2. Get error\n\n## Expected Behavior\nNot getting this error\n\n## Actual Behavior\nreceive error\n\n## Screenshots\nIf applicable, add screenshots to help explain your problem.\n\n## Environment\n - OS: Linux-garuda-arch\n - Using Docker Desktop\n\n## Additional Context\nAdd any other context about the problem here, such as:\n- Does this happen consistently or intermittently? Consistently\n- Were there any recent changes that might be related? None this is a fresh pull\n- Any workarounds you've discovered? no\n\n## Possible Solution\nIf you have suggestions on how to fix the issue or what might be causing it.",
      "state": "closed",
      "author": "Reaper176",
      "author_type": "User",
      "created_at": "2025-06-16T14:05:58Z",
      "updated_at": "2025-06-16T15:46:28Z",
      "closed_at": "2025-06-16T15:46:27Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/98/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/98",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/98",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:20.119430",
      "comments": [
        {
          "author": "leex279",
          "body": "Hey, one more question => main or stable branch? :) ",
          "created_at": "2025-06-16T14:11:37Z"
        },
        {
          "author": "Reaper176",
          "body": "@leex279 main\n\nEdit: both actually\n\n",
          "created_at": "2025-06-16T14:16:50Z"
        },
        {
          "author": "Reaper176",
          "body": "Oh wow. I found the issue. I have been running things rootless for so long I forgot that sudo was a requirement for docker. Issue is resolved.",
          "created_at": "2025-06-16T15:46:27Z"
        }
      ]
    },
    {
      "issue_number": 99,
      "title": "[FEATURE]",
      "body": "## Describe the feature you'd like and why\nEnable all services to be listening on ALL IPS or SPECIFIC IPS as an envar or command string. My powerhouse machine that runs all of my LLM stuff is a beefy server in a server closet that I connect to over Tailscale by name or IP address. Services that *ONLY* listen on `localhost` or `127.0.0.1` are therefore not available remotely.\n\n## User Impact\nAny user who has a dev lab setup that is NOT on the single laptop or desktop they primarily use for development\n\n## Implementation Details (optional)\nI *think* this can probably be set for each service in the .env\n\n## Additional context\nAdd any other screenshots, mockups, or context about the feature request here.",
      "state": "open",
      "author": "MoJo1760",
      "author_type": "User",
      "created_at": "2025-06-16T14:09:23Z",
      "updated_at": "2025-06-16T14:22:31Z",
      "closed_at": null,
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/99/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/99",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/99",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:20.282885",
      "comments": [
        {
          "author": "MoJo1760",
          "body": "my workaround is just to `sed 's/127.0.0.1/0.0.0.0/g' -i docker-compose.override.private.yml `and set \n`N8N_SECURE_COOKIE=false` in the `environment` section like this:\n`  n8n:\n    ports:\n      - 0.0.0.0:5678:5678\n    environment:\n      - N8N_SECURE_COOKIE=false\n`",
          "created_at": "2025-06-16T14:22:31Z"
        }
      ]
    },
    {
      "issue_number": 97,
      "title": "Portainer Setup pitfalls",
      "body": "I'm currently setting up a Portainer-managed local Supabase and AI stack. I'm new to this, so if anything looks off, feel free to disregard or correct!\n\nA couple things I‚Äôve run into:\nSupabase and Portainer don't play well together when using depends_on with healthchecks.\nSome services (notably vector) may report as unhealthy and block startup if your hardware is slower or the service just takes longer to initialize. This is a Docker Compose limitation that Portainer exposes more obviously. I've just created the supabase stuff outside of portainer for now, but I think this is solvable. \n\nAs pointed out [here](https://github.com/coleam00/local-ai-packaged/issues/58) Port 8000 (used by Kong) conflicts with Portainer.\nLuckily, Supabase allows this to be customized using KONG_HTTP_PORT in your .env file. Adjusting the Kong port is safer than trying to change Portainer‚Äôs internal setup (IMHO).\n\nPostgres container conflict across Compose files.\nBoth the Supabase and Local-AI Compose files spin up a postgres service, which will conflict if you run them on the same Docker host. You‚Äôll either need to remove one of the postgres containers, or manually adjust ports and service names to avoid collisions\n\nShared network helps bridge Supabase and AI containers.\nI‚Äôm working around the isolation by assigning both Compose stacks to a custom local-ai Docker network. This makes it easier to reference containers across stacks. But it does require editing both Compose files, which isn‚Äôt ideal for widespread distribution.\n\nThat‚Äôs where I‚Äôm at! Still iterating on this and welcome any ideas or feedback.",
      "state": "open",
      "author": "Guyanthalas",
      "author_type": "User",
      "created_at": "2025-06-15T21:36:29Z",
      "updated_at": "2025-06-15T21:36:29Z",
      "closed_at": null,
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/97/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/97",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/97",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:20.490421",
      "comments": []
    },
    {
      "issue_number": 67,
      "title": "[BUG] Supabase and N8N connect Problem",
      "body": "![Image](https://github.com/user-attachments/assets/8f94f651-177e-4eb7-9790-73a2ee32d5b6)\n\n![Image](https://github.com/user-attachments/assets/7320d07c-71da-44ee-9c5b-5f8a2377d57c)\n\nI face problem connecting supabase to N8N when adding the credentials it stuck and continue testing without any response \nalso in auth theirs a massage in supabase any help please",
      "state": "open",
      "author": "mahmoudmahdy077",
      "author_type": "User",
      "created_at": "2025-05-26T21:51:58Z",
      "updated_at": "2025-06-10T21:35:36Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/67/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/67",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/67",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:20.490454",
      "comments": [
        {
          "author": "leex279",
          "body": "hey, the screenshot does not show your configuration (url). I also see in the top screenshot \"Beta\". What supabase is this?",
          "created_at": "2025-05-26T21:56:46Z"
        },
        {
          "author": "mahmoudmahdy077",
          "body": "The Configuration URL is working and accessable through browsers it's custom domain and port reversed proxy to supabase docker container, I just reinstalled the local ai package that what appears in dashboard ",
          "created_at": "2025-05-26T23:38:26Z"
        },
        {
          "author": "PrymalInstynct",
          "body": "I seem to be running into the same issue. This is a brand new \"first time\" deployment. I am setting the Service Role Secret to the same value I set for `SERVICE_ROLE_KEY` in .env.\n![Image](https://github.com/user-attachments/assets/431d30e7-da3e-4770-8048-7c927ecc8a68)",
          "created_at": "2025-05-28T16:12:19Z"
        },
        {
          "author": "mahmoudmahdy077",
          "body": "> I seem to be running into the same issue. This is a brand new \"first time\" deployment. I am setting the Service Role Secret to the same value I set for `SERVICE_ROLE_KEY` in .env. ![Image](https://github.com/user-attachments/assets/431d30e7-da3e-4770-8048-7c927ecc8a68)\n\nI think it's a problem rela",
          "created_at": "2025-05-28T16:17:55Z"
        },
        {
          "author": "leex279",
          "body": "just to make sure => you did not start the stack, then changed the .env file? cause then you need to use the old/default service_key from the repo, as it is persisted after the first start, as far as I know.",
          "created_at": "2025-06-01T11:45:26Z"
        }
      ]
    },
    {
      "issue_number": 58,
      "title": "Port 8000 conflict with Portainer",
      "body": "Hey, just to let you know, its better to set KONG http port to 8001 instead of 8000 because if using Portainer it has 8000 as a used port as well.",
      "state": "open",
      "author": "usadaddy",
      "author_type": "User",
      "created_at": "2025-05-10T15:27:27Z",
      "updated_at": "2025-06-10T21:00:33Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "question"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/58/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/58",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/58",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:20.690255",
      "comments": [
        {
          "author": "coleam00",
          "body": "This is good to know, especially because I do want to include Portainer in the stack at some point. It's too bad though because everyone currently using the stack would be confused when they have to change the port for something they've been using for a while already. Would it be possible to instead",
          "created_at": "2025-05-12T12:20:39Z"
        },
        {
          "author": "usadaddy",
          "body": "I just changed the value for KONG in the .env and didn't look at changing it for Portainer because that I installed with cli. You could probably set it to a different port in the .env also if you add it to the package as its own container. ",
          "created_at": "2025-05-12T15:27:10Z"
        },
        {
          "author": "ogoflowgo",
          "body": "Cole, have you though about using Dockge instead of Portainer? I've not used Portainer, and I'm a noob at all this docker stuff, but I found Dockge to be pretty dead simple and useful for managing this stack, and some of my own I've now created. \nDockge runs on port 5001 but you could change the ext",
          "created_at": "2025-05-15T20:44:07Z"
        },
        {
          "author": "leex279",
          "body": "@coleam00 the port we can easily change and just add this to the docker compose:\n```\n  portainer:\n    image: portainer/portainer-ce\n    restart: unless-stopped\n    ports:\n      - \"9005:9000\"\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n      - portainer_data:/data\n```\n\nThe Stack is",
          "created_at": "2025-05-15T21:40:17Z"
        },
        {
          "author": "psiryan",
          "body": "I propose to clearly define a range of ports to be used by each product in the suite which are in the private range of ports and not likely to interfere with any other software on a user's system.\n\nHere are some important points which should probably be considered:\n\n- The goal as stated in the READM",
          "created_at": "2025-06-06T01:50:14Z"
        }
      ]
    },
    {
      "issue_number": 90,
      "title": "[BUG] Qdrant is inaccessible from n8n",
      "body": "I set up a local ai package on Win10 Docker Desktop.\n\nAfter a few hiccups everything inside is running smoothly.\n\nBoth n8n and Qdrant instances are accessible, with ports 5678 and 6333, respectively. Qdrant dashboard is accessible locally, everything seems fine. \n\nThe problem arises when trying to connect Qdrant Vector Store node. When I‚Äôm trying to provide Qdrant vector store node with the credentials, I‚Äôm seeing a green light that the address and credentials are correct.\n\nI tried credentials with and without `api_key` the following addresses \n`http://localhost:6333`\n`http://qdrant:6333`\n`http://host.docker.internal:6333`,\neven `http://container_IP_address:6333`,\nbut I continue receving ‚ÄúConnection tested successfully‚Äù in Qdrant credential menu, and ‚ÄúInvalid Qdrant URL: undefined‚Äù when inserting data or retrieving collections list.\n\n![Image](https://github.com/user-attachments/assets/fe19721f-a7ab-4764-b765-68b0329c2d09)\n\n![Image](https://github.com/user-attachments/assets/580a6669-4b99-4d56-a2c3-7d32dce5c058)\n\nI also exposed 6334 port, which helped some people on the internet.\n\nNothing helped so far, unfortunately.",
      "state": "closed",
      "author": "BeeegZee",
      "author_type": "User",
      "created_at": "2025-06-07T08:09:12Z",
      "updated_at": "2025-06-08T18:44:18Z",
      "closed_at": "2025-06-07T20:36:18Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/90/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/90",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/90",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:20.888808",
      "comments": [
        {
          "author": "leex279",
          "body": "Hey,\n\nare you on the main branch or the stable branch? asking because there is big difference at the moment.",
          "created_at": "2025-06-07T20:07:05Z"
        },
        {
          "author": "BeeegZee",
          "body": "Hey, @leex279, \n\nIt seems I'm on the default one, meaning main (right?).\n\nYou've got me into thinking about performing a clean set up for whatever's sake. ",
          "created_at": "2025-06-07T20:15:13Z"
        },
        {
          "author": "leex279",
          "body": "ok, yeah we just changed this to have the main as more a development/beta status and the stable a release/more tested one. may refine this a bit, but the current readme has the \"-b stable\" already to make sure people get the tested state.\n\nWith the current main state there are a lot of improvements ",
          "created_at": "2025-06-07T20:26:44Z"
        },
        {
          "author": "BeeegZee",
          "body": "Wow that's really huge improvements pack you're cooking! \n\nThank you for your suggestion and clarification about branches.\n\nBy the way, I've done clean set up and it seems not showing the error I was encountering in this thread, so I gonna close the thread for now. Microsoft's way of troubleshooting",
          "created_at": "2025-06-07T20:35:35Z"
        },
        {
          "author": "leex279",
          "body": "Thanks, I will take a look :) ",
          "created_at": "2025-06-07T20:44:36Z"
        }
      ]
    },
    {
      "issue_number": 71,
      "title": "[BUG] Upgrading Containers errors",
      "body": "![Image](https://github.com/user-attachments/assets/82200971-4cdc-4a02-a0af-7d3fe3222fc9)\n\nwhen I try to upgrade the containers using the script it stuck and fail to check supabase analytics container even the container is running but the script stuck sometimes it works but lately I can't upgrade the containers ",
      "state": "closed",
      "author": "mahmoudmahdy077",
      "author_type": "User",
      "created_at": "2025-05-30T14:16:25Z",
      "updated_at": "2025-06-08T13:58:26Z",
      "closed_at": "2025-06-08T13:58:26Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/71/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/71",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/71",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:21.101429",
      "comments": [
        {
          "author": "mrwilch",
          "body": "I have the same problem",
          "created_at": "2025-05-31T17:44:54Z"
        },
        {
          "author": "leex279",
          "body": "Can you please take a look at the container logs and post them here as well?",
          "created_at": "2025-05-31T18:17:35Z"
        },
        {
          "author": "mrwilch",
          "body": "how could I do that?",
          "created_at": "2025-06-04T17:08:36Z"
        },
        {
          "author": "jfbethlehem",
          "body": "Your .env is not OK. To fix this, add the following lines anywhere in the .env, preferably near the rest of the LOGFLARE stuff:\n\nLOGFLARE_PUBLIC_ACCESS_TOKEN=\"not-in-use\"\nLOGFLARE_PRIVATE_ACCESS_TOKEN=\"not-in-use\"\n",
          "created_at": "2025-06-08T13:00:16Z"
        },
        {
          "author": "coleam00",
          "body": "This issue has been fixed, Supabase just updated their environment variables so I had to change that in .env.example here",
          "created_at": "2025-06-08T13:58:26Z"
        }
      ]
    },
    {
      "issue_number": 91,
      "title": "[BUG] Container supabase-vector failed to initialized.",
      "body": "1. What happended : \n```bash\n[+] Running 15/15\n ‚úî Network localai_default                   Created                                                                                                                          0.0s \n ‚úî Volume \"localai_db-config\"                Created                                                                                                                          0.0s \n ‚úî Container supabase-imgproxy               Started                                                                                                                          1.0s \n ‚úò Container supabase-vector                 Error                                                                                                                            2.0s \n ‚úî Container supabase-db                     Created                                                                                                                          0.1s \n ‚úî Container supabase-analytics              Created                                                                                                                          0.0s \n ‚úî Container supabase-edge-functions         Created                                                                                                                          0.1s \n ‚úî Container supabase-kong                   Created                                                                                                                          0.1s \n ‚úî Container supabase-studio                 Created                                                                                                                          0.1s \n ‚úî Container supabase-meta                   Created                                                                                                                          0.1s \n ‚úî Container realtime-dev.supabase-realtime  Created                                                                                                                          0.1s \n ‚úî Container supabase-auth                   Created                                                                                                                          0.1s \n ‚úî Container supabase-pooler                 Created                                                                                                                          0.1s \n ‚úî Container supabase-rest                   Created                                                                                                                          0.1s \n ‚úî Container supabase-storage                Created                                                                                                                          0.1s \ndependency failed to start: container supabase-vector is unhealthy\nTraceback (most recent call last):\n  File \"/root/local-ai-packaged/start_services.py\", line 239, in <module>\n    main()\n  File \"/root/local-ai-packaged/start_services.py\", line 229, in main\n    start_supabase()\n  File \"/root/local-ai-packaged/start_services.py\", line 60, in start_supabase\n    run_command([\n  File \"/root/local-ai-packaged/start_services.py\", line 21, in run_command\n    subprocess.run(cmd, cwd=cwd, check=True)\n  File \"/usr/lib/python3.11/subprocess.py\", line 571, in run\n    raise CalledProcessError(retcode, process.args,\nsubprocess.CalledProcessError: Command '['docker', 'compose', '-p', 'localai', '-f', 'supabase/docker/docker-compose.yml', 'up', '-d']' returned non-zero exit status 1.\nroot@Local-Ai-Stack:~/local-ai-packaged# docker logs supabase-vector\n2025-06-07T14:02:32.085741Z  INFO vector::app: Internal log rate limit configured. internal_log_rate_secs=10\n2025-06-07T14:02:32.085938Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,lapin=info,kube=info\"\n2025-06-07T14:02:32.086017Z  INFO vector::app: Loading configs. paths=[\"/etc/vector/vector.yml\"]\n2025-06-07T14:02:32.086669Z ERROR vector::cli: Configuration error. error=sinks.logflare_auth.request.headers.x-api-key: invalid type: unit value, expected any valid TOML value at line 169 column 19\n2025-06-07T14:02:32.345284Z  INFO vector::app: Internal log rate limit configured. internal_log_rate_secs=10\n2025-06-07T14:02:32.345442Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,lapin=info,kube=info\"\n2025-06-07T14:02:32.345506Z  INFO vector::app: Loading configs. paths=[\"/etc/vector/vector.yml\"]\n2025-06-07T14:02:32.346159Z ERROR vector::cli: Configuration error. error=sinks.logflare_auth.request.headers.x-api-key: invalid type: unit value, expected any valid TOML value at line 169 column 19\n2025-06-07T14:02:32.693625Z  INFO vector::app: Internal log rate limit configured. internal_log_rate_secs=10\n2025-06-07T14:02:32.693777Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,lapin=info,kube=info\"\n2025-06-07T14:02:32.693887Z  INFO vector::app: Loading configs. paths=[\"/etc/vector/vector.yml\"]\n2025-06-07T14:02:32.694532Z ERROR vector::cli: Configuration error. error=sinks.logflare_auth.request.headers.x-api-key: invalid type: unit value, expected any valid TOML value at line 169 column 19\n2025-06-07T14:02:33.237355Z  INFO vector::app: Internal log rate limit configured. internal_log_rate_secs=10\n2025-06-07T14:02:33.237503Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,lapin=info,kube=info\"\n2025-06-07T14:02:33.237562Z  INFO vector::app: Loading configs. paths=[\"/etc/vector/vector.yml\"]\n2025-06-07T14:02:33.238169Z ERROR vector::cli: Configuration error. error=sinks.logflare_auth.request.headers.x-api-key: invalid type: unit value, expected any valid TOML value at line 169 column 19\n2025-06-07T14:02:34.182687Z  INFO vector::app: Internal log rate limit configured. internal_log_rate_secs=10\n2025-06-07T14:02:34.182837Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,lapin=info,kube=info\"\n2025-06-07T14:02:34.182893Z  INFO vector::app: Loading configs. paths=[\"/etc/vector/vector.yml\"]\n2025-06-07T14:02:34.183502Z ERROR vector::cli: Configuration error. error=sinks.logflare_auth.request.headers.x-api-key: invalid type: unit value, expected any valid TOML value at line 169 column 19\n2025-06-07T14:02:35.925179Z  INFO vector::app: Internal log rate limit configured. internal_log_rate_secs=10\n2025-06-07T14:02:35.925322Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,lapin=info,kube=info\"\n2025-06-07T14:02:35.925376Z  INFO vector::app: Loading configs. paths=[\"/etc/vector/vector.yml\"]\n2025-06-07T14:02:35.925957Z ERROR vector::cli: Configuration error. error=sinks.logflare_auth.request.headers.x-api-key: invalid type: unit value, expected any valid TOML value at line 169 column 19\n2025-06-07T14:02:39.288863Z  INFO vector::app: Internal log rate limit configured. internal_log_rate_secs=10\n2025-06-07T14:02:39.289006Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,lapin=info,kube=info\"\n2025-06-07T14:02:39.289074Z  INFO vector::app: Loading configs. paths=[\"/etc/vector/vector.yml\"]\n2025-06-07T14:02:39.289661Z ERROR vector::cli: Configuration error. error=sinks.logflare_auth.request.headers.x-api-key: invalid type: unit value, expected any valid TOML value at line 169 column 19\n2025-06-07T14:02:45.833271Z  INFO vector::app: Internal log rate limit configured. internal_log_rate_secs=10\n2025-06-07T14:02:45.833418Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,lapin=info,kube=info\"\n2025-06-07T14:02:45.833472Z  INFO vector::app: Loading configs. paths=[\"/etc/vector/vector.yml\"]\n2025-06-07T14:02:45.834065Z ERROR vector::cli: Configuration error. error=sinks.logflare_auth.request.headers.x-api-key: invalid type: unit value, expected any valid TOML value at line 169 column 19\n```\n2. expected to happen : \n.env should provide sufficient key to run without issues\n\n3. workaround\nreplace values with updated logflare setting.\n\nAS-IS\n\n```bash\n############\n# Logs - Configuration for Logflare\n# Please refer to https://supabase.com/docs/reference/self-hosting-analytics/introduction\n############\n\nLOGFLARE_LOGGER_BACKEND_API_KEY=your-super-secret-and-long-logflare-key\n\n# Change vector.toml sinks to reflect this change\nLOGFLARE_API_KEY=your-super-secret-and-long-logflare-key\n\nTO-BE\n```bash\n############\n# Logs - Configuration for Logflare\n# Please refer to https://supabase.com/docs/reference/self-hosting-analytics/introduction\n############\n\nLOGFLARE_LOGGER_BACKEND_API_KEY=my-very-naughy-key\n# Change vector.toml sinks to reflect this change\nLOGFLARE_API_KEY=my-very-naughy-key\nLOGFLARE_PUBLIC_ACCESS_TOKEN=my-very-naughy-key\nLOGFLARE_PRIVATE_ACCESS_TOKEN=my-very-naughy-key\nLOGFLARE_SOURCE_ID=my-very-naughy-key\n```\n\n",
      "state": "closed",
      "author": "lonerkim",
      "author_type": "User",
      "created_at": "2025-06-07T14:17:06Z",
      "updated_at": "2025-06-08T13:57:51Z",
      "closed_at": "2025-06-08T13:57:51Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/91/reactions",
        "total_count": 4,
        "+1": 4,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/91",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/91",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:21.317309",
      "comments": [
        {
          "author": "coleam00",
          "body": "Supabase updated their environment variables and I needed to reflect that here which I've done with a push today!",
          "created_at": "2025-06-08T13:57:51Z"
        }
      ]
    },
    {
      "issue_number": 87,
      "title": "[BUG] Supabase-vector not starting properly",
      "body": "## Description\nI just installed the whole repository locally on my Ubuntu 24.04 Server and while running the start command the supabase-vector container is not starting properly.\n\n## Steps to Reproduce\n1. Installed the repo\n2. Filled out the .env required variables\n3. Typed in `python3 start_services.py --profile cpu` to start everything\n\n## Expected Behavior\nEverything up and running.\n\n## Actual Behavior\nThis is the error at the moment:\n\n```\nSupabase repository already exists, updating...\nRunning: git pull\nAlready up to date.\nCopying .env in root to .env in supabase/docker...\nChecking SearXNG settings...\nSearXNG settings.yml already exists at searxng/settings.yml\nGenerating SearXNG secret key...\nDetected Linux/Unix platform, using standard sed command...\nSearXNG secret key generated successfully.\nNo running SearXNG container found - assuming first run\nStopping and removing existing containers for the unified project 'localai'...\nRunning: docker compose -p localai --profile cpu -f docker-compose.yml down\nWARN[0000] The \"aptLjyZqenDxmrY4XT\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"vfeZv8\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"VMV\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"yr8p63\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"aptLjyZqenDxmrY4XT\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"vfeZv8\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"VMV\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"yr8p63\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"aptLjyZqenDxmrY4XT\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"vfeZv8\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"VMV\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"yr8p63\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"aptLjyZqenDxmrY4XT\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"vfeZv8\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"VMV\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"yr8p63\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"FLOWISE_USERNAME\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"FLOWISE_PASSWORD\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"aptLjyZqenDxmrY4XT\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"vfeZv8\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"VMV\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"yr8p63\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"LOGFLARE_PRIVATE_ACCESS_TOKEN\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"LOGFLARE_PUBLIC_ACCESS_TOKEN\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"LOGFLARE_PUBLIC_ACCESS_TOKEN\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"LOGFLARE_PRIVATE_ACCESS_TOKEN\" variable is not set. Defaulting to a blank string. \nStarting Supabase services...\nRunning: docker compose -p localai -f supabase/docker/docker-compose.yml up -d\nWARN[0000] The \"aptLjyZqenDxmrY4XT\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"vfeZv8\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"VMV\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"yr8p63\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"aptLjyZqenDxmrY4XT\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"vfeZv8\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"VMV\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"yr8p63\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"aptLjyZqenDxmrY4XT\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"vfeZv8\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"VMV\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"yr8p63\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"aptLjyZqenDxmrY4XT\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"vfeZv8\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"VMV\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"yr8p63\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"LOGFLARE_PRIVATE_ACCESS_TOKEN\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"LOGFLARE_PUBLIC_ACCESS_TOKEN\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"LOGFLARE_PRIVATE_ACCESS_TOKEN\" variable is not set. Defaulting to a blank string. \nWARN[0000] The \"LOGFLARE_PUBLIC_ACCESS_TOKEN\" variable is not set. Defaulting to a blank string. \n[+] Running 15/15\n ‚úî Network localai_default                   Created                                                                                                                                                                       0.0s \n ‚úî Volume \"localai_db-config\"                Created                                                                                                                                                                       0.0s \n ‚úò Container supabase-vector                 Error                                                                                                                                                                         1.2s \n ‚úî Container supabase-imgproxy               Started                                                                                                                                                                       0.7s \n ‚úî Container supabase-db                     Created                                                                                                                                                                       0.0s \n ‚úî Container supabase-analytics              Created                                                                                                                                                                       0.0s \n ‚úî Container supabase-meta                   Created                                                                                                                                                                       0.1s \n ‚úî Container supabase-rest                   Created                                                                                                                                                                       0.0s \n ‚úî Container supabase-kong                   Created                                                                                                                                                                       0.1s \n ‚úî Container supabase-auth                   Created                                                                                                                                                                       0.0s \n ‚úî Container realtime-dev.supabase-realtime  Created                                                                                                                                                                       0.0s \n ‚úî Container supabase-edge-functions         Created                                                                                                                                                                       0.1s \n ‚úî Container supabase-pooler                 Created                                                                                                                                                                       0.1s \n ‚úî Container supabase-studio                 Created                                                                                                                                                                       0.0s \n ‚úî Container supabase-storage                Created                                                                                                                                                                       0.0s \ndependency failed to start: container supabase-vector is unhealthy\nTraceback (most recent call last):\n  File \"/root/local-ai-packaged/start_services.py\", line 239, in <module>\n    main()\n  File \"/root/local-ai-packaged/start_services.py\", line 229, in main\n    start_supabase()\n  File \"/root/local-ai-packaged/start_services.py\", line 60, in start_supabase\n    run_command([\n  File \"/root/local-ai-packaged/start_services.py\", line 21, in run_command\n    subprocess.run(cmd, cwd=cwd, check=True)\n  File \"/usr/lib/python3.12/subprocess.py\", line 571, in run\n    raise CalledProcessError(retcode, process.args,\nsubprocess.CalledProcessError: Command '['docker', 'compose', '-p', 'localai', '-f', 'supabase/docker/docker-compose.yml', 'up', '-d']' returned non-zero exit status 1.\n```\n\n## Screenshots\nIf applicable, add screenshots to help explain your problem.\n\n## Environment\n - OS: Ubuntu 24.04\n\n## Additional Context\nI checked the docker logs of supabase-vector and this is what's here:\n\n```\n2025-06-06T09:52:13.924174Z  INFO vector::app: Internal log rate limit configured. internal_log_rate_secs=10\n2025-06-06T09:52:13.924635Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,lapin=info,kube=info\"\n2025-06-06T09:52:13.924813Z  INFO vector::app: Loading configs. paths=[\"/etc/vector/vector.yml\"]\n2025-06-06T09:52:13.925621Z ERROR vector::cli: Configuration error. error=sinks.logflare_auth.request.headers.x-api-key: invalid type: unit value, expected any valid TOML value at line 169 column 19\n2025-06-06T09:52:14.194197Z  INFO vector::app: Internal log rate limit configured. internal_log_rate_secs=10\n2025-06-06T09:52:14.195537Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,lapin=info,kube=info\"\n2025-06-06T09:52:14.195601Z  INFO vector::app: Loading configs. paths=[\"/etc/vector/vector.yml\"]\n2025-06-06T09:52:14.196161Z ERROR vector::cli: Configuration error. error=sinks.logflare_auth.request.headers.x-api-key: invalid type: unit value, expected any valid TOML value at line 169 column 19\n2025-06-06T09:52:14.570308Z  INFO vector::app: Internal log rate limit configured. internal_log_rate_secs=10\n2025-06-06T09:52:14.570540Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,lapin=info,kube=info\"\n2025-06-06T09:52:14.570627Z  INFO vector::app: Loading configs. paths=[\"/etc/vector/vector.yml\"]\n2025-06-06T09:52:14.571196Z ERROR vector::cli: Configuration error. error=sinks.logflare_auth.request.headers.x-api-key: invalid type: unit value, expected any valid TOML value at line 169 column 19\n2025-06-06T09:52:15.120542Z  INFO vector::app: Internal log rate limit configured. internal_log_rate_secs=10\n2025-06-06T09:52:15.120727Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,lapin=info,kube=info\"\n2025-06-06T09:52:15.120847Z  INFO vector::app: Loading configs. paths=[\"/etc/vector/vector.yml\"]\n2025-06-06T09:52:15.121427Z ERROR vector::cli: Configuration error. error=sinks.logflare_auth.request.headers.x-api-key: invalid type: unit value, expected any valid TOML value at line 169 column 19\n2025-06-06T09:52:16.063992Z  INFO vector::app: Internal log rate limit configured. internal_log_rate_secs=10\n2025-06-06T09:52:16.064338Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,lapin=info,kube=info\"\n2025-06-06T09:52:16.064492Z  INFO vector::app: Loading configs. paths=[\"/etc/vector/vector.yml\"]\n2025-06-06T09:52:16.065133Z ERROR vector::cli: Configuration error. error=sinks.logflare_auth.request.headers.x-api-key: invalid type: unit value, expected any valid TOML value at line 169 column 19\n2025-06-06T09:52:17.833693Z  INFO vector::app: Internal log rate limit configured. internal_log_rate_secs=10\n2025-06-06T09:52:17.833884Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,lapin=info,kube=info\"\n2025-06-06T09:52:17.833947Z  INFO vector::app: Loading configs. paths=[\"/etc/vector/vector.yml\"]\n2025-06-06T09:52:17.834545Z ERROR vector::cli: Configuration error. error=sinks.logflare_auth.request.headers.x-api-key: invalid type: unit value, expected any valid TOML value at line 169 column 19\n2025-06-06T09:52:21.178160Z  INFO vector::app: Internal log rate limit configured. internal_log_rate_secs=10\n2025-06-06T09:52:21.178397Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,lapin=info,kube=info\"\n2025-06-06T09:52:21.178508Z  INFO vector::app: Loading configs. paths=[\"/etc/vector/vector.yml\"]\n2025-06-06T09:52:21.179244Z ERROR vector::cli: Configuration error. error=sinks.logflare_auth.request.headers.x-api-key: invalid type: unit value, expected any valid TOML value at line 169 column 19\n2025-06-06T09:52:27.726151Z  INFO vector::app: Internal log rate limit configured. internal_log_rate_secs=10\n2025-06-06T09:52:27.726377Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,lapin=info,kube=info\"\n2025-06-06T09:52:27.726448Z  INFO vector::app: Loading configs. paths=[\"/etc/vector/vector.yml\"]\n2025-06-06T09:52:27.727030Z ERROR vector::cli: Configuration error. error=sinks.logflare_auth.request.headers.x-api-key: invalid type: unit value, expected any valid TOML value at line 169 column 19\n2025-06-06T09:52:40.675700Z  INFO vector::app: Internal log rate limit configured. internal_log_rate_secs=10\n2025-06-06T09:52:40.676006Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,lapin=info,kube=info\"\n2025-06-06T09:52:40.676189Z  INFO vector::app: Loading configs. paths=[\"/etc/vector/vector.yml\"]\n2025-06-06T09:52:40.677010Z ERROR vector::cli: Configuration error. error=sinks.logflare_auth.request.headers.x-api-key: invalid type: unit value, expected any valid TOML value at line 169 column 19\n2025-06-06T09:53:06.423682Z  INFO vector::app: Internal log rate limit configured. internal_log_rate_secs=10\n2025-06-06T09:53:06.423907Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,lapin=info,kube=info\"\n2025-06-06T09:53:06.424007Z  INFO vector::app: Loading configs. paths=[\"/etc/vector/vector.yml\"]\n2025-06-06T09:53:06.424634Z ERROR vector::cli: Configuration error. error=sinks.logflare_auth.request.headers.x-api-key: invalid type: unit value, expected any valid TOML value at line 169 column 19\n2025-06-06T09:53:57.771501Z  INFO vector::app: Internal log rate limit configured. internal_log_rate_secs=10\n2025-06-06T09:53:57.771712Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,lapin=info,kube=info\"\n2025-06-06T09:53:57.771775Z  INFO vector::app: Loading configs. paths=[\"/etc/vector/vector.yml\"]\n2025-06-06T09:53:57.772344Z ERROR vector::cli: Configuration error. error=sinks.logflare_auth.request.headers.x-api-key: invalid type: unit value, expected any valid TOML value at line 169 column 19\n2025-06-06T09:54:57.907421Z  INFO vector::app: Internal log rate limit configured. internal_log_rate_secs=10\n2025-06-06T09:54:57.907600Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,lapin=info,kube=info\"\n2025-06-06T09:54:57.907664Z  INFO vector::app: Loading configs. paths=[\"/etc/vector/vector.yml\"]\n2025-06-06T09:54:57.908290Z ERROR vector::cli: Configuration error. error=sinks.logflare_auth.request.headers.x-api-key: invalid type: unit value, expected any valid TOML value at line 169 column 19\n2025-06-06T09:55:58.046074Z  INFO vector::app: Internal log rate limit configured. internal_log_rate_secs=10\n2025-06-06T09:55:58.046542Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,lapin=info,kube=info\"\n2025-06-06T09:55:58.046644Z  INFO vector::app: Loading configs. paths=[\"/etc/vector/vector.yml\"]\n2025-06-06T09:55:58.047225Z ERROR vector::cli: Configuration error. error=sinks.logflare_auth.request.headers.x-api-key: invalid type: unit value, expected any valid TOML value at line 169 column 19\n```",
      "state": "closed",
      "author": "mikenussbaumer",
      "author_type": "User",
      "created_at": "2025-06-06T09:58:36Z",
      "updated_at": "2025-06-08T13:57:28Z",
      "closed_at": "2025-06-07T12:36:14Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/87/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/87",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/87",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:21.517637",
      "comments": [
        {
          "author": "skibsthebear",
          "body": "Add this to your .env file in your root folder where \"start_services.py\" is:\n\n```\nLOGFLARE_PUBLIC_ACCESS_TOKEN=\"not-in-use\"\nLOGFLARE_PRIVATE_ACCESS_TOKEN=\"not-in-use\" \n```\n\nYou can put it anywhere but I would suggest bundle it up with the other supabase related variables. Hope this helps :)\n@coleam0",
          "created_at": "2025-06-06T14:00:15Z"
        },
        {
          "author": "psiryan",
          "body": "Confirming @skibsthebear 's solution resolves the issue with vector db starting up.\n\n![Image](https://github.com/user-attachments/assets/a6dfb6f0-35ed-48eb-abfd-45adc5baacdf)",
          "created_at": "2025-06-06T15:36:29Z"
        },
        {
          "author": "mikenussbaumer",
          "body": "Thanks alot this worked perfectly!",
          "created_at": "2025-06-07T12:36:14Z"
        },
        {
          "author": "coleam00",
          "body": "> Add this to your .env file in your root folder where \"start_services.py\" is:\n> \n> ```\n> LOGFLARE_PUBLIC_ACCESS_TOKEN=\"not-in-use\"\n> LOGFLARE_PRIVATE_ACCESS_TOKEN=\"not-in-use\" \n> ```\n> \n> You can put it anywhere but I would suggest bundle it up with the other supabase related variables. Hope this h",
          "created_at": "2025-06-08T13:57:28Z"
        }
      ]
    },
    {
      "issue_number": 89,
      "title": "[BUG] N8N webpage does not open",
      "body": "## Description\nI just installed the whole repository locally on my Ubuntu 24.04 Server and while running the start command everything started and i was able to open Qdrant, Flowise, superbase using my local ip:port (192.168.50.28:8000). However, when i tried ip:5678 for N8N it doesn't work. \n\n![Image](https://github.com/user-attachments/assets/81edb895-a8a0-40a5-b951-7d5ad649ce92)\n\nAll the container seems to be running fine.\n\n![Image](https://github.com/user-attachments/assets/497987ec-db40-4508-891a-c504751ea77c)\n\n![Image](https://github.com/user-attachments/assets/41c602ff-9615-4c1c-9cea-c31e452e1334)\n\nAs for the errors in the red box, I can't seem to find any fix. \n\nIf you have suggestions on how to fix the issue would be great help!",
      "state": "closed",
      "author": "Kal-31",
      "author_type": "User",
      "created_at": "2025-06-07T03:32:56Z",
      "updated_at": "2025-06-08T06:39:01Z",
      "closed_at": "2025-06-08T01:03:50Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/89/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/89",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/89",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:21.760348",
      "comments": [
        {
          "author": "skibsthebear",
          "body": "Hey man, it seems like a driver issue to me. Are you sure you have the necessary graphic drivers installed? With the Ubuntu's server version, you may be missing the required drivers.\n\nBefore you go diving into finding the right drivers, are you absolutely positive that you have a Nvidia gpu? You can",
          "created_at": "2025-06-07T04:03:52Z"
        },
        {
          "author": "Kal-31",
          "body": "Thank you for the response, i tried bot solutions and i still get the same error. The N8N webpage is still not working. Any fix on that?\n\n![Image](https://github.com/user-attachments/assets/c5b26a65-1ac6-4aad-bfac-559c3b527249)\n\nalso running with CPU, i get the following.\n\n![Image](https://github.co",
          "created_at": "2025-06-07T11:01:57Z"
        },
        {
          "author": "skibsthebear",
          "body": "@Kal-31 sucks that you're still getting the issue! \n\nI am not too positive about the GPU issue, might need to wait for someone else but that 4gb of VRAM won't be able to run a decent llm unfortunately to begin with. Just something to keep it mind!\n\nFor your second issue, it's because Ollama is alrea",
          "created_at": "2025-06-07T14:47:28Z"
        },
        {
          "author": "Kal-31",
          "body": "@skibsthebear - The commands you provided did not work but they did help. I had to remove the containers and than ran \n\n`sudo python3 start_services.py --profile-cpu`\n\nand eveything started without any errors.\n\n![Image](https://github.com/user-attachments/assets/ed8deab1-b751-4239-80e2-d4df106fbd08)",
          "created_at": "2025-06-08T00:44:54Z"
        },
        {
          "author": "Kal-31",
          "body": "Found the solution. just added the following in the docker-compose.yml and it worked.\n\n`N8N_SECURE_COOKIE=false`\n\n![Image](https://github.com/user-attachments/assets/15a4454a-28e1-4376-beac-d0f652f9a032)",
          "created_at": "2025-06-08T01:03:50Z"
        }
      ]
    },
    {
      "issue_number": 88,
      "title": "[BUG] when updating this repository supabase vector fails to start",
      "body": "\n  \n<img width=\"1024\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/d1890d31-d74a-4d6c-80ac-d7ec84ab721a\" />",
      "state": "closed",
      "author": "roy2003boy",
      "author_type": "User",
      "created_at": "2025-06-06T15:57:16Z",
      "updated_at": "2025-06-06T16:04:56Z",
      "closed_at": "2025-06-06T16:04:55Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/88/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/88",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/88",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:21.993997",
      "comments": [
        {
          "author": "roy2003boy",
          "body": "Sorry The previous post fixed it please ignore this ",
          "created_at": "2025-06-06T16:04:56Z"
        }
      ]
    },
    {
      "issue_number": 10,
      "title": "Not using git to manage versioning",
      "body": "I was looking for an earlier version of the docker compose file to do a comparison for my own learning and I noticed that you are making changes, but not really versioning. If you are making changes to your configuration, can you please manage the changes so that we can tell what is being changed?",
      "state": "open",
      "author": "psiryan",
      "author_type": "User",
      "created_at": "2025-02-19T16:20:47Z",
      "updated_at": "2025-06-06T00:18:27Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "question"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/10/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/10",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/10",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:22.246801",
      "comments": [
        {
          "author": "coleam00",
          "body": "I appreciate you calling this out! I certainly want to get better at versioning things, especially so that my old videos don't reference a completely different codebase when I link to something that's been updated a lot.\n\nI'll add this issue to my project board and think about how I'd do this best! ",
          "created_at": "2025-02-24T19:13:46Z"
        },
        {
          "author": "psiryan",
          "body": "When I opened this issue, I was trying to view the history of a file, knowing that it had been changed since the first time I had cloned the repo, near the release of the original video citing this project. I can view file history now, but I can't be sure that it goes back to the original version fr",
          "created_at": "2025-06-06T00:16:59Z"
        }
      ]
    },
    {
      "issue_number": 84,
      "title": "[BUG] dependency failed to start: container supabase-vector is unhealthy",
      "body": "System setup: MacOS, Docker Desktop\n\nI did install the package few days ago and everything was working just fine. I tried to stop and start the services today using:\n```shell\ndocker compose -p localai -f docker-compose.yml --profile none down\npython3 start_services.py --profile none\n``` \n\n\nand I'm facing the following error:\n```shell\ndependency failed to start: container supabase-vector is unhealthy\nTraceback (most recent call last):\n  File \"/Users/server1/Documents/AI Server/GitHub/local-ai-packaged/start_services.py\", line 239, in <module>\n    main()\n    ~~~~^^\n  File \"/Users/server1/Documents/AI Server/GitHub/local-ai-packaged/start_services.py\", line 229, in main\n    start_supabase()\n    ~~~~~~~~~~~~~~^^\n  File \"/Users/server1/Documents/AI Server/GitHub/local-ai-packaged/start_services.py\", line 60, in start_supabase\n    run_command([\n    ~~~~~~~~~~~^^\n        \"docker\", \"compose\", \"-p\", \"localai\", \"-f\", \"supabase/docker/docker-compose.yml\", \"up\", \"-d\"\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ])\n    ^^\n  File \"/Users/server1/Documents/AI Server/GitHub/local-ai-packaged/start_services.py\", line 21, in run_command\n    subprocess.run(cmd, cwd=cwd, check=True)\n    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/subprocess.py\", line 577, in run\n    raise CalledProcessError(retcode, process.args,\n                             output=stdout, stderr=stderr)\nsubprocess.CalledProcessError: Command '['docker', 'compose', '-p', 'localai', '-f', 'supabase/docker/docker-compose.yml', 'up', '-d']' returned non-zero exit status 1.\ndependency failed to start: container supabase-vector is unhealthy\nTraceback (most recent call last):\n  File \"/Users/server1/Documents/AI Server/GitHub/local-ai-packaged/start_services.py\", line 239, in <module>\n    main()\n    ~~~~^^\n  File \"/Users/server1/Documents/AI Server/GitHub/local-ai-packaged/start_services.py\", line 229, in main\n    start_supabase()\n    ~~~~~~~~~~~~~~^^\n  File \"/Users/server1/Documents/AI Server/GitHub/local-ai-packaged/start_services.py\", line 60, in start_supabase\n    run_command([\n    ~~~~~~~~~~~^^\n        \"docker\", \"compose\", \"-p\", \"localai\", \"-f\", \"supabase/docker/docker-compose.yml\", \"up\", \"-d\"\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ])\n    ^^\n  File \"/Users/server1/Documents/AI Server/GitHub/local-ai-packaged/start_services.py\", line 21, in run_command\n    subprocess.run(cmd, cwd=cwd, check=True)\n    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/subprocess.py\", line 577, in run\n    raise CalledProcessError(retcode, process.args,\n                             output=stdout, stderr=stderr)\nsubprocess.CalledProcessError: Command '['docker', 'compose', '-p', 'localai', '-f', 'supabase/docker/docker-compose.yml', 'up', '-d']' returned non-zero exit status 1.\n``` \n\n\n\n\nWhen I check details in the Docker, I can see following (supabase-vector [timberio/vector:0.28.1-alpine]):\n```shell\n2025-06-05T09:44:13.413350Z  INFO vector::app: Loading configs. paths=[\"/etc/vector/vector.yml\"]\n2025-06-05T09:44:13.414317Z ERROR vector::cli: Configuration error. error=sinks.logflare_auth.request.headers.x-api-key: invalid type: unit value, expected any valid TOML value at line 169 column 19\n``` \n\n\n\n\nSo far, I tried:\n- restarting computer\n- updating & restarting Docker\n- deleting the folder supabase/docker/volumes/db/data\n- updating the packages using all the 3 steps as per documentation by Cole\n\n\nI searched and I can see there are few errors regarding the Supabase Vector. One caused by Docker and one by \"software\"(?!). I still have to dig deeper into the Docker issue because the explanation is not clear enough for me, but so far no luck.\nI will continue searching of course, but so far I was not able to find any issue and I'm bit confused by the fact that it was working just fine in the beginning.\n\nDo you have someone an idea, what could be the reason, please?",
      "state": "closed",
      "author": "pauln8nai",
      "author_type": "User",
      "created_at": "2025-06-05T09:57:13Z",
      "updated_at": "2025-06-05T14:48:44Z",
      "closed_at": "2025-06-05T14:48:42Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/84/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/84",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/84",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:22.479696",
      "comments": [
        {
          "author": "quangvinh2080",
          "body": "Same problem",
          "created_at": "2025-06-05T11:07:27Z"
        },
        {
          "author": "BeeegZee",
          "body": "Hey @pauln8nai \nI encountered a similar error when deploying on win10 with Docker Desktop\n\nCan you share **supabase-vector** container logs?\n\nIn my case, I've got the following error:\n\n```\nERROR vector::cli: Configuration error. error=sinks.logflare_auth.request.headers.x-api-key: invalid type: unit",
          "created_at": "2025-06-05T14:09:17Z"
        },
        {
          "author": "openelearning",
          "body": "Hi\nSame problem here with debian. \n\n\n```\ndependency failed to start: container supabase-vector is unhealthy\nTraceback (most recent call last):\n  File \"/../local-ai-packaged/start_services.py\", line 242, in <module>\n    main()\n  File \"/..//local-ai-packaged/start_services.py\", line 232, in main\n    s",
          "created_at": "2025-06-05T14:21:30Z"
        },
        {
          "author": "BeeegZee",
          "body": "Hey @openelearning \nTry adding `LOGFLARE_PUBLIC_ACCESS_TOKEN` and `LOGFLARE_PRIVATE_ACCESS_TOKEN` to .env file and do a clean setup.\n\nIt seems that something has changed in the **supabase** overall deployment variables - `supabase/docker/.env.example` contains those couple of variables, while `.env.",
          "created_at": "2025-06-05T14:30:37Z"
        },
        {
          "author": "openelearning",
          "body": "Yes thanks a lot @BeeegZee this has solved the problem :)",
          "created_at": "2025-06-05T14:35:03Z"
        }
      ]
    },
    {
      "issue_number": 30,
      "title": "[FEATURE] Add standalone docker-compose.yml and replace Ollama with LiteLLM",
      "body": "## Describe the feature you'd like and why\nCurrently, the project setup relies on an installation script, which requires manual execution and increases deployment complexity. I propose adding a standalone docker-compose.yml file that allows users to deploy the project without running additional scripts.\n\nAdditionally, this change would replace Ollama with LiteLLM as the LLM backend. LiteLLM offers broader compatibility with multiple model providers, giving users more flexibility in choosing and managing LLMs.\n\nThis improvement would streamline deployment, reduce manual setup steps, and make the system more adaptable to different user needs.\n\n## User Impact\n- Developers & Self-Hosters: Would benefit from a simplified deployment process, reducing setup time and potential errors.\n- Users with different LLM providers: LiteLLM allows integration with multiple backends, making it easier to switch between models without modifying the core setup.\n- Maintenance & Scalability: A docker-compose.yml setup makes it easier to manage updates and ensure a more portable, reproducible environment.\n\n## Implementation Details (optional)\n- Add a docker-compose.yml file that:\n  - Defines all required services.\n  - Configures LiteLLM as the default backend.\n  - Uses environment variables for model selection and API configuration.\n- Remove the dependency on the installation script for deployment.\n- Ensure that LiteLLM is correctly configured to interact with the existing application workflow.\n\n## Additional context\n- The selected LLM model and API key would be configurable through environment variables (.env file).\n- This change aligns with best practices for containerized deployments, reducing manual intervention.\n- The transition from Ollama to LiteLLM expands the range of supported models while maintaining performance and reliability.",
      "state": "open",
      "author": "AlejandroIglesiasCalvo",
      "author_type": "User",
      "created_at": "2025-03-19T09:50:16Z",
      "updated_at": "2025-06-04T23:42:53Z",
      "closed_at": null,
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/30/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/30",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/30",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:22.706102",
      "comments": [
        {
          "author": "AugustoSystems",
          "body": "I would upvote this.  Breaking out the docker-compose would allow for additional docker containers",
          "created_at": "2025-03-20T21:09:50Z"
        },
        {
          "author": "coleam00",
          "body": "Main reason I added the script is because Supabase has its own docker-compose file so it isn't as simple as defining everything in a single docker-compose.yml. The script also takes care of some config for SearXNG, so in the end the process wouldn't get simpler. I'd appreciate your thoughts if you t",
          "created_at": "2025-03-23T19:52:55Z"
        },
        {
          "author": "AugustoSystems",
          "body": "@coleam00 Here is my suggestion (not sure it will cover the need for supabase)\n\nI have followed anand https://www.simplehomelab.com/anand/ for a few years for my home docker solution.\n\nHe has a pretty good following, but my suggestion would be to include and have individual docker files\n\nExample: in",
          "created_at": "2025-03-23T21:08:19Z"
        },
        {
          "author": "AlejandroIglesiasCalvo",
          "body": "**About the single Docker Compose:** I understand the need to run the script to start Supabase. I don‚Äôt mind doing that on my main PC. But I‚Äôd like to install this on a NAS as a concept, so it‚Äôs available 24/7. I‚Äôm not sure if copying the instance from the PC to the NAS would be a viable option ü§î\n\n*",
          "created_at": "2025-03-24T08:35:07Z"
        },
        {
          "author": "bobkumar-online",
          "body": "@coleam00 , great work!  This project has saved me tons of time.  I am new to Docker so will need to play around but adding LiteLLM would be a great addition to the package as a LLM API Proxy.  I will try adding it directly on the host and direct OpenWebUI to point to the local instance but having a",
          "created_at": "2025-04-19T14:23:11Z"
        }
      ]
    },
    {
      "issue_number": 82,
      "title": "[FEATURE] Ability to delete old records for files that do not exist",
      "body": "## Describe the feature you'd like and why\nWould like the n8n workflow to delete old records for files that no longer exist in the /data/shared folder\n\n## User Impact\nBe able to use the RAG against only documents that are relevant\n\n## Implementation Details (optional)\nIt looks like when a folder trigger occurs, any files that are existing get deleted and re-imported, but any files that are now missing do not get deleted, unless I'm reading the n8n nodes wrong. Not to familiar with n8n yet, so not sure how to implement it or I would add to mine.",
      "state": "open",
      "author": "heapsoftware",
      "author_type": "User",
      "created_at": "2025-06-04T23:30:07Z",
      "updated_at": "2025-06-04T23:30:07Z",
      "closed_at": null,
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/82/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/82",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/82",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:22.922844",
      "comments": []
    },
    {
      "issue_number": 68,
      "title": "[FEATURE] Nagging N8N secure cookie alert",
      "body": "Well, if you host locally or on a local VM I usually don¬¥t setup https.\n\nUnfoprtunately N8N is nagging with that stupid page that the secure cookie is not set to false.\n\nChanging my local copy of the docker-compose script is annoying as I have to stash the change to include the following env variable:\n\nN8N_SECURE_COOKIE=false\n\nCould you please add that to docker-compose.yml or (better yet) include it in the env file and reference it from docker-compose.yml?\n\nOr do you prefer a PR for such things?",
      "state": "open",
      "author": "nofrillsdev",
      "author_type": "User",
      "created_at": "2025-05-28T14:31:35Z",
      "updated_at": "2025-06-03T18:06:40Z",
      "closed_at": null,
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/68/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/68",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/68",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:22.922866",
      "comments": [
        {
          "author": "leex279",
          "body": "I keep this in mind. We are currently doing a few bigger changes and we will take a look how we include this after it.\nThink should be no problem then, cause we also got a --environment to choose between public and private deployment. For the private we could then auto enable the secure cookie.\nWe w",
          "created_at": "2025-06-01T11:48:04Z"
        },
        {
          "author": "b-tops",
          "body": "Yep. Just add it to docker-compose.override.private.yml.\nSomething like:\n```\nn8n:\n    ports:\n      - 127.0.0.1:5678:5678\n    environment:\n      - N8N_SECURE_COOKIE=false\n```\n\nThat should fix it.",
          "created_at": "2025-06-01T17:53:26Z"
        },
        {
          "author": "nofrillsdev",
          "body": "Ok, this introduction of docker-compose.override.private.yml is now creating a whole new set of issues - probably just my way of using this repo:\n\nI have a machine that I use headless and connect to it on my local network. But now the docker containers only bind to 127.0.0.1 which prevents accessing",
          "created_at": "2025-06-03T14:44:22Z"
        },
        {
          "author": "leex279",
          "body": "I think when you remove the 127.0.0.1 in https://github.com/coleam00/local-ai-packaged/blob/main/docker-compose.override.private.yml for all services, it should work as before.\nDid you try that?\n\nI dont agree with \"in a private it should bind to all\", cause also in private networks you not automatic",
          "created_at": "2025-06-03T18:06:39Z"
        }
      ]
    },
    {
      "issue_number": 80,
      "title": "[FEATURE] External Port",
      "body": "## Describe the feature you'd like and why\nI Having issues where I cant use port 443 so need to use say 8888 but this has lots of issues with the scripts getting it working after that then in things like n8n o auth call back urls needing external.env \n\n## User Impact\nanyone who cannot use 443\n\n## Implementation Details (optional)\nadd port in the .env and the url rewrite for the n8n \n\n## Additional context\nAdd any other screenshots, mockups, or context about the feature request here.",
      "state": "open",
      "author": "Skycomm",
      "author_type": "User",
      "created_at": "2025-06-03T16:02:26Z",
      "updated_at": "2025-06-03T16:02:26Z",
      "closed_at": null,
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/80/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/80",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/80",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:23.102737",
      "comments": []
    },
    {
      "issue_number": 70,
      "title": "[FEATURE] Mention Git-Version",
      "body": "Mention Git-Version\nOlder Git version will quit quite using the start_script.py on Win 10.",
      "state": "open",
      "author": "Steviey",
      "author_type": "User",
      "created_at": "2025-05-29T04:33:37Z",
      "updated_at": "2025-06-03T06:37:48Z",
      "closed_at": null,
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/70/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/70",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/70",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:23.102762",
      "comments": [
        {
          "author": "venturero",
          "body": "@Steviey what should be the range for git version?",
          "created_at": "2025-06-01T11:39:57Z"
        },
        {
          "author": "leex279",
          "body": "I also dont understand what is ment by that. can you explain in more detail with maybe an example?",
          "created_at": "2025-06-01T11:42:59Z"
        },
        {
          "author": "Steviey",
          "body": "start_script.py broke under an older git version on win 10. I hat to update it.",
          "created_at": "2025-06-02T21:40:37Z"
        },
        {
          "author": "leex279",
          "body": "@Steviey ok, thx. I think thats ok and we dont need to support older git versions as users should stay on updated versions.\n\n@coleam00 your thoughts on this?\n",
          "created_at": "2025-06-03T06:37:47Z"
        }
      ]
    },
    {
      "issue_number": 77,
      "title": "[BUG] dependency failed to start: container supabase-vector is unhealthy",
      "body": "## Description\nThe supabase-vector container fails to start when I run the following command:\n```bash\npython3 start_services.py --profile gpu-nvidia\n```\n\nTo isolate the start-up to just supabase-vector, I trimmed down the docker-compose.yaml file to the attached docker-compose-supabase-studio.yaml file, which contains the studio, analytics, db and vector services.\n\n[docker-compose-supabase-studio.yml.txt](https://github.com/user-attachments/files/20555861/docker-compose-supabase-studio.yml.txt)\n\nI have also attached the docker compose logs output in the attached logs.txt file:\n[logs.txt](https://github.com/user-attachments/files/20555817/logs.txt)\n\nQ01: What should I do to troubleshoot and get supabase-vector container to run properly?\n\n## Environment\n - OS: Ubuntu 24.04\n\n\n",
      "state": "closed",
      "author": "edowson",
      "author_type": "User",
      "created_at": "2025-06-02T16:51:59Z",
      "updated_at": "2025-06-02T18:39:15Z",
      "closed_at": "2025-06-02T18:39:14Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/77/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/77",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/77",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:23.311807",
      "comments": [
        {
          "author": "edowson",
          "body": "If I change the docker image for vector, versions from\n`timberio/vector:0.47.0-debian` to `timberio/vector:0.33.0-debian`\n\nNote: It doesn't matter if I use the alpine image or the debian image.\n\n\nHere is the error message:\n```bash\nsupabase-vector     | 2025-06-02T17:47:23.307264Z ERROR vector::topol",
          "created_at": "2025-06-02T18:02:23Z"
        },
        {
          "author": "edowson",
          "body": "I found the reason for the docker permissions error. I have docker username-space remapping enabled.\n\nMy /etc/subgid had the wrong group-id specified for the docker group. I re-checked the current gid for the docker group and updated the /etc/subgid\n\n\nGet the docker group id:\n```bash\ngetent group do",
          "created_at": "2025-06-02T18:39:14Z"
        }
      ]
    },
    {
      "issue_number": 39,
      "title": "[BUG]",
      "body": "## Description\nHello,\n\nanyone knows why this \n\n![Image](https://github.com/user-attachments/assets/3af07140-d264-46be-ad36-1578ca6dfa3a)\n\nhappens?\n\nIt was working until ~1h ago and out of the sudden it started to fail.\nI am not sure if this is a real bug or something else and also I have no idea how to fix it.\n\nI have found something here https://community.n8n.io/t/can-t-run-the-self-hosted-ai-starter-kit/74396 but is a bit old even is the same kind of error.\n\nAny advice or ideas are welcome.\n\nThank you in advance,\nGeorge\n\n## Steps to Reproduce\n1. Go to '...'\n2. Click on '....'\n3. Scroll down to '....'\n4. See error\n\n## Expected Behavior\nA clear and concise description of what you expected to happen.\n\n## Actual Behavior\nA clear and concise description of what actually happened.\n\n## Screenshots\nIf applicable, add screenshots to help explain your problem.\n\n## Environment\n - OS: [e.g. Windows 10, macOS Monterey, Ubuntu 22.04]\n - Using Docker Desktop, WSL, etc.\n\n## Additional Context\nAdd any other context about the problem here, such as:\n- Does this happen consistently or intermittently?\n- Were there any recent changes that might be related?\n- Any workarounds you've discovered?\n\n## Possible Solution\nIf you have suggestions on how to fix the issue or what might be causing it.",
      "state": "closed",
      "author": "gxgl",
      "author_type": "User",
      "created_at": "2025-03-27T08:22:34Z",
      "updated_at": "2025-05-31T20:04:42Z",
      "closed_at": "2025-05-31T20:04:42Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/39/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/39",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/39",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:23.492173",
      "comments": [
        {
          "author": "coleam00",
          "body": "@gxgl I would look into the Docker logs for the n8n-import container and see what you find there! There should be a much more helpful error message there.",
          "created_at": "2025-05-12T12:16:28Z"
        }
      ]
    },
    {
      "issue_number": 36,
      "title": "[FEATURE] Graph RAG with Neo4J",
      "body": "## Describe the feature you'd like and why\nHave you ever looked into graph RAG with neo4j? Graph databases allow showing relationships which can make the information more accurate when an LLM is hitting the vector db. neo4j has a way to vectorize the nodes while maintaining the relationships. I wonder how possible it is to pull off in n8n, they do allow for custom code and python is one of the options, plus you could build a custom n8n image to pull in any python libraries needed. (I have an image for puppeteer for more accurate web crawling since it uses chrome to render js pages.) \n\n## User Impact\n¬Ø\\\\\\_(„ÉÑ)_/¬Ø \nim sure someone would like it\n\n## Implementation Details (optional)\nNo idea with n8n and neo4j. The tricky part is loading the data since langchain is used in python in the examples I have seen. They have an experimental branch that allows for categorizing the data as it is loaded into the graph and its not a straight forward create/update on a row like the other db tools. i have seen a community n8n-nodes-neo4j node but not sure how extensive it is, it seemed new\n\n## Additional context\nthese were some jupyter notebooks from articles i had seen. most other people dont seem to load or read the data correctly.\nhttps://github.com/tomasonjo/blogs/blob/master/llm/llm_graph_transformer_in_depth.ipynb\nhttps://github.com/tomasonjo/blogs/blob/master/llm/enhancing_rag_with_graph.ipynb\n\nhttps://medium.com/data-science/building-knowledge-graphs-with-llm-graph-transformer-a91045c49b59\n\nhttps://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/",
      "state": "closed",
      "author": "scarolac",
      "author_type": "User",
      "created_at": "2025-03-26T05:16:27Z",
      "updated_at": "2025-05-31T20:04:25Z",
      "closed_at": "2025-05-31T20:04:24Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/36/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/36",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/36",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:23.673925",
      "comments": [
        {
          "author": "thesteganos",
          "body": "Please, mark as closed/implemented.",
          "created_at": "2025-05-31T11:29:09Z"
        },
        {
          "author": "coleam00",
          "body": "Yes I will, thanks @thesteganos!",
          "created_at": "2025-05-31T20:04:24Z"
        }
      ]
    },
    {
      "issue_number": 23,
      "title": "[QUESTION]  n8n questions of V2 and V3 RAG AI Agent",
      "body": "I can run the \"local ai\" in Docker desktop in Ubuntu 24.  Everything is in the Docker. \n\nV2 first: documents table.\nIt seem the documnt table is missing. I want to create it manually in the supabase.  Can anyone share the table info? need to know the columns name and type.  thanks.\n\nV3: trigger issue\nI try the n8n with V3 Local Agentic RAG AI Agent.  All 3 items in Credentials are set as green text shown \"connection tested successfully\".  Two tables \"document_metadata\" and \"document_rows\" are created in supabase (checked in localhost:8000 -> Table Editor). \n\n And turn the workflow to \"Active\". then click the \"Local File Trigger\".  Then goto the folder \"/home/user/local-ai-packaged/shared\", add a test.txt and put some text.  but nothing in the \"Output\". it take \"forever\"! I wait 20 mins and stop it.  Nothing in the output or in supabase.  \n\nI restart the Agent (\"docker compose.... down\", and \"python3 start_services.py --profile cpu\")\n\ntry again, it take another 20 minus and I stop it, the document_metadata updated but not others.  looks better and try. let it run and go to dinner.  Come back and still running.  I check the supabase.  3 records in Document_metadata. 0 record in document_rows. And 3 records in documents_pg.\n\nmore, everytime I copy a file into the shared folder. I go to the docker -> n8n -> exec to ls the folder. I can see the files immediately.\n\nmy question is:\nhow to troubleshoot the slow issue? the V2 is first, V3 is slow. need to use GPU or and wait to see which node is slow?\nwhat is the best way to clean the supabase and the shared folder? I may did it wrong and cause the issue.\n\nThanks\nwai\n\n\n\n\n",
      "state": "closed",
      "author": "waiwaiwai27",
      "author_type": "User",
      "created_at": "2025-03-10T14:04:06Z",
      "updated_at": "2025-05-30T02:32:44Z",
      "closed_at": "2025-03-12T06:48:44Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/23/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/23",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/23",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:23.896492",
      "comments": [
        {
          "author": "waiwaiwai27",
          "body": "local file trigger: after searching the internet and test many methdos.  it only work within the container. e.g. at docker-desktop n8n container -> exec, touch test.txt under the folder /data/shared and it show on the hosts folder ~/xxx/shared.  but it fails if copy a file into hosts folder.  it see",
          "created_at": "2025-03-12T06:48:44Z"
        },
        {
          "author": "dmann000",
          "body": "waiwaiwai27 - I just wanted to thank you. You saved me hours of troubleshooting. I'm going to look for a more in-depth rag approach",
          "created_at": "2025-05-30T02:32:43Z"
        }
      ]
    },
    {
      "issue_number": 69,
      "title": "commenting N8N_HOSTNAME=n8n.yourdomain.com [BUG]",
      "body": "commenting out N8N_HOSTNAME=n8n.yourdomain.com\nwill lead to a standard error in caddy, which is missleading.",
      "state": "closed",
      "author": "Steviey",
      "author_type": "User",
      "created_at": "2025-05-29T02:30:41Z",
      "updated_at": "2025-05-29T04:56:50Z",
      "closed_at": "2025-05-29T04:56:50Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/69/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/69",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/69",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:24.105906",
      "comments": []
    },
    {
      "issue_number": 65,
      "title": "[BUG] Port 9000 conflit clickhouse/minio",
      "body": "\nWhen running the command bellow, we get error \"container localai-clickhouse-1 is unhealthy\" or the same for minio. Seems that clickhouse and minio are using the same port configuration.\n\nCommand: python start_services.py --profile cpu\n\n## Screenshots\n\n![Image](https://github.com/user-attachments/assets/a0966529-3336-4d48-954b-d547f39d1fbb)\n\n## Environment\n - Using Docker Desktop\n",
      "state": "open",
      "author": "carlosafgraca",
      "author_type": "User",
      "created_at": "2025-05-26T09:25:05Z",
      "updated_at": "2025-05-26T21:59:32Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/65/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/65",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/65",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:24.105925",
      "comments": [
        {
          "author": "leex279",
          "body": "hey, they dont use the same ports (exposed). The internal ports dont matter.\n\nCan you provide the logs from the containers please?\n\n",
          "created_at": "2025-05-26T21:59:32Z"
        }
      ]
    },
    {
      "issue_number": 66,
      "title": "[BUG] Supabase analytics conatiner fail",
      "body": "## Description\nwhen I'm trying to deploy through python script it fails \n\n![Image](https://github.com/user-attachments/assets/63c6a860-7039-47d5-86e8-e2d21e783774)",
      "state": "closed",
      "author": "mahmoudmahdy077",
      "author_type": "User",
      "created_at": "2025-05-26T20:58:57Z",
      "updated_at": "2025-05-26T21:47:30Z",
      "closed_at": "2025-05-26T21:47:30Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/66/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/66",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/66",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:24.317418",
      "comments": []
    },
    {
      "issue_number": 26,
      "title": "Self-Adding Manual Services",
      "body": "First I want to thank @coleam00 for this guide and package, it is very helpful, I've successfully installed and run the project thanks to your both video and documantation. Tool options are improving so while i used this for a while, i've seen another tool and wanted to implement it but wanted to add it without deleting/reinstalling the existing one. So here is my feature request:\n\n## Feaure Request\nIt would be so helpful for a new section to the readme file to add some instructions to add new product to existing toolset. For example, I've a few workflows which uses Supabase database, ollama etc. and I wanted to add a new product for example TestWebUI interface.\n\nI've tried to implement docker-compose.yml but there are some errors so I've decided to open this feature request. It could be very useful to add some instructions about how can we update code for adding a new container and tool inside of \"localai\" project (container group). \n\nBest regards. \n",
      "state": "open",
      "author": "azelmas",
      "author_type": "User",
      "created_at": "2025-03-14T08:29:58Z",
      "updated_at": "2025-05-15T22:00:12Z",
      "closed_at": null,
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/26/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/26",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/26",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:24.317439",
      "comments": [
        {
          "author": "coleam00",
          "body": "Do you mean instructions for adding a new service, like if we wanted to add Langfuse into the stack for example? If so then yeah I agree that would be useful to include in the docs!",
          "created_at": "2025-03-23T19:55:42Z"
        },
        {
          "author": "azelmas",
          "body": "Yes, i meant that, it would be useful.",
          "created_at": "2025-03-24T05:02:09Z"
        },
        {
          "author": "leex279",
          "body": "Suggestion @coleam00: as we got with a recent PR the \"include\" in docker-compose anyway, we could create another include custom-services.yml, where users can put in their own additonal stuff. This way the original one is still clean and no problems with updates.\n\n",
          "created_at": "2025-05-15T22:00:10Z"
        }
      ]
    },
    {
      "issue_number": 9,
      "title": "Embedding Docling in Local Docker n8n Deployment",
      "body": "I recommend using [DocLing](https://github.com/DS4SD/docling) to generate and manage our project's documentation.  \n\nDocling simplifies document processing, parsing diverse formats ‚Äî including advanced PDF understanding ‚Äî and providing seamless integrations with the gen AI ecosystem.\n\n\n\n",
      "state": "open",
      "author": "ruanjunmin",
      "author_type": "User",
      "created_at": "2025-02-19T14:15:59Z",
      "updated_at": "2025-05-15T21:56:55Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "question"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/9/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/9",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/9",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:24.536243",
      "comments": [
        {
          "author": "coleam00",
          "body": "I appreciate the suggestion @ruanjunmin! I'm hoping to keep the docs pretty simple though so I'm not sure if I'd need to parse diverse formats or handle PDFs. What are the main benefits you see for something like the local AI package docs specifically?",
          "created_at": "2025-02-24T19:12:30Z"
        },
        {
          "author": "leex279",
          "body": "I would also keep it simple, either with just the readme or maybe same we do for bolt.diy with the markdown files",
          "created_at": "2025-05-15T21:56:54Z"
        }
      ]
    },
    {
      "issue_number": 17,
      "title": "GPU count, password hints",
      "body": "Hi,\n\nAt fist thanks for your great work, it really helps me getting into this stuff!\n\nI noticed two things:\n\n* If you have more gpus it will bypass only one, i suggest to change that in docker-compose-yml, ollama-gpu -> count:all\n\n* supabase is picky about passwords starting with special chars. Also changing any other of the \"changeme\"-keys than you mentioned (like vault_enc_key or logflare keys) lead to some supabase containers not starting up. that costed me some hours to figure out...\n\ngreetings",
      "state": "closed",
      "author": "andi-at-1",
      "author_type": "User",
      "created_at": "2025-02-24T09:53:14Z",
      "updated_at": "2025-05-12T13:16:37Z",
      "closed_at": "2025-05-12T12:11:03Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/17/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/17",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/17",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:24.841126",
      "comments": [
        {
          "author": "coleam00",
          "body": "Thanks for these couple of tips!\n\n1. The n8n team in their original starter kit excluded count:all and I'm thinking it's because you might want multiple containers each running a separate Ollama instance on a GPU for parallel processing. But only some use cases would want that, others you would want",
          "created_at": "2025-02-24T19:20:00Z"
        },
        {
          "author": "andi-at-1",
          "body": "1) Yes, i mean that was pretty straight forward to overcome, just a hint where to change the config seems good enough\n\n2) `# :  \"` are also not the best, and quite sure there are more. Haven¬¥t tried more and tested that just with the postgres password. It leads to instant crash or supabases-analytic",
          "created_at": "2025-02-27T07:52:56Z"
        },
        {
          "author": "openelearning",
          "body": "Same problem for passwords with special characters in debian : \n\nin .env I think (but not 100% sure, it was impossible to use the superbase api) that it was POSTGRES_PASSWORD with one (or all) of them: √† %  ?  \"\n",
          "created_at": "2025-03-22T17:23:25Z"
        },
        {
          "author": "openelearning",
          "body": "Maybe adding this warning in.env.example could be useful ?",
          "created_at": "2025-03-22T17:27:27Z"
        },
        {
          "author": "openelearning",
          "body": "It's here : https://supabase.com/docs/guides/database/postgres/roles#special-symbols-in-passwords\n\n\"Passwords[#](https://supabase.com/docs/guides/database/postgres/roles#passwords)\n\nYour Postgres database is the core of your Supabase project, so it's important that every role has a strong, secure pa",
          "created_at": "2025-03-22T17:37:30Z"
        }
      ]
    },
    {
      "issue_number": 48,
      "title": "[FEATURE] Adding perplexica",
      "body": "hello can u add perplexica, ready to work with this working docker please\n\n",
      "state": "open",
      "author": "gamersalpha",
      "author_type": "User",
      "created_at": "2025-04-17T16:38:58Z",
      "updated_at": "2025-05-12T12:19:43Z",
      "closed_at": null,
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/48/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/48",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/48",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:25.091991",
      "comments": [
        {
          "author": "coleam00",
          "body": "I appreciate the suggestion! I'll consider it!",
          "created_at": "2025-05-12T12:19:42Z"
        }
      ]
    },
    {
      "issue_number": 45,
      "title": "[FEATURE] Add OpenManus family of projects",
      "body": "## Describe the feature you'd like and why\nThe OpenManus family of projects seem like they would be a nice addition\n\n- https://github.com/OpenManus/OpenManus-RL\n- https://github.com/mannaandpoem/OpenManus\n\n## User Impact\nAnybody who doesn't have a manus invite, or wants to share information with manus\n\n## Implementation Details (optional)\n\nhttps://github.com/iszmxw/OpenManus-Docker",
      "state": "open",
      "author": "levonk",
      "author_type": "User",
      "created_at": "2025-04-09T21:22:42Z",
      "updated_at": "2025-05-12T12:19:05Z",
      "closed_at": null,
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/45/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/45",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/45",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:25.271943",
      "comments": [
        {
          "author": "coleam00",
          "body": "I appreciate the suggestion @levonk! I'm working on gathering suggestions like this into a list and I'll see when/if it makes sense to add all of them!",
          "created_at": "2025-05-12T12:19:04Z"
        }
      ]
    },
    {
      "issue_number": 50,
      "title": "[BUG] Supabase AI assistant is not working",
      "body": "## Description\nWhen trying to use the AI assistant in Supabase, I am getting an authentication error. I have to log in to the Panel again (Kong Basic Auth)\nMy OpenAI API key is added correctly\n\n## Environment\n - OS: MacOS Sequoia \n - Using Docker Desktop\n\n## Possible Solution\nIs anyone else having a similar problem? Has anyone managed to solve it?",
      "state": "closed",
      "author": "norbertwalczak",
      "author_type": "User",
      "created_at": "2025-04-19T20:55:39Z",
      "updated_at": "2025-05-12T12:18:30Z",
      "closed_at": "2025-05-12T12:18:29Z",
      "labels": [
        "bug",
        "question"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/50/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/50",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/50",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:25.468560",
      "comments": [
        {
          "author": "coleam00",
          "body": "This seems like it would be more an issue for the Supabase repo than this one. I haven't actually tried adding my Open AI key to Supabase yet but if you did and that didn't work, I would suggest creating an issue here:\n\nhttps://github.com/supabase/supabase",
          "created_at": "2025-05-12T12:18:29Z"
        }
      ]
    },
    {
      "issue_number": 40,
      "title": "[BUG] Google OAUTH2 does not work due to http://localhost:5678 while Google requires https",
      "body": "## Description\nIt is not possible to activate google OAUTH2 because Google refuses to allow http connections for OAuth2 logins.\n\n## Steps to Reproduce\n1. Go to 'credentials'\n2. Create an API key in Google Developer, GD requires https\n3. Create a Google Drive, Docs or other OAuth2 credential\n5. When everything is filled in, click the button that appears\n6. Error message stating protocol mismatch\n\n## Possible Solution\nI have changed the local-ai-packaged/docker-compose.yml file to enable url changing and allowing first login from other places than localhost. See below:\n\n(only partial copy-paste)\n\nx-n8n: &service-n8n\n  image: n8nio/n8n:latest\n  environment:\n    - DB_TYPE=postgresdb\n    - DB_POSTGRESDB_HOST=db\n    - DB_POSTGRESDB_USER=postgres\n    - DB_POSTGRESDB_PASSWORD=${POSTGRES_PASSWORD}\n    - DB_POSTGRESDB_DATABASE=postgres\n    - N8N_DIAGNOSTICS_ENABLED=false\n    - N8N_PERSONALIZATION_ENABLED=false\n    - N8N_ENCRYPTION_KEY\n    - N8N_USER_MANAGEMENT_JWT_SECRET\n    - N8N_SECURE_COOKIE\n    - N8N_HOST=${N8N_HOSTNAME}\n    - N8N_EDITOR_BASE_URL=https://${N8N_HOSTNAME}\n    - WEBHOOK_URL=https://${N8N_HOSTNAME}\n\nThe N8N_SECURE_COOKIE is to enable/disable the secure cookie setting using the .env file, which gave issues when running N8N on a remote host over http://remotehost:5678, which gives a secure cookie error message.\nThe N8N_HOST, N8N_EDITOR_BASE and WEBHOOK_URL are to enable https and by-hostname OAuth2 authentication.",
      "state": "closed",
      "author": "jfbethlehem",
      "author_type": "User",
      "created_at": "2025-03-28T08:42:26Z",
      "updated_at": "2025-05-12T12:17:29Z",
      "closed_at": "2025-05-12T12:17:29Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/40/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/40",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/40",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:25.629312",
      "comments": [
        {
          "author": "Emanu5",
          "body": "and if we use ngrok?",
          "created_at": "2025-04-01T08:56:11Z"
        },
        {
          "author": "coleam00",
          "body": "I believe something like ngrok would be necessary for this as @Emanu5 mentioned. I am thinking of adding that into the local AI package, and then I did add WEBHOOK_URL to the n8n service too!",
          "created_at": "2025-05-12T12:17:29Z"
        }
      ]
    },
    {
      "issue_number": 38,
      "title": "Local Agentic RAG not writing to correct tables?",
      "body": "## Description\nI'm not sure that the data of an existing file are being written to the correct tables in Supabase. \nIt seems like a crossover between the SQL writing to \nthey all refer to documents_pg but the data seems to be getting written in documents_ metadata\n\n![Image](https://github.com/user-attachments/assets/2dcd88fc-6a4a-47f2-9000-c5bcf252e87a)\n\n## Steps to Reproduce\n1. Go to 'V3 Local Agentic RAG AI Agent' n8n workflow\n2. Click on 'Delete old data records' they all refer to documents_pg but the data seems to be getting written in documents_ metadata\n\n## Screenshots\n\n![Image](https://github.com/user-attachments/assets/99abc7f9-8b44-4176-bc71-b586b0c5b5d5)\n\n\n![Image](https://github.com/user-attachments/assets/0ea275ad-fdf4-47a0-a61f-fea0ddb740e4)\n\n## Environment\n - OS: Windows 11\n - Use Docker Desktop, WSL, etc.\n",
      "state": "closed",
      "author": "systemccg",
      "author_type": "User",
      "created_at": "2025-03-26T20:31:54Z",
      "updated_at": "2025-05-12T12:15:30Z",
      "closed_at": "2025-05-12T12:15:29Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/38/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/38",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/38",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:25.855599",
      "comments": [
        {
          "author": "coleam00",
          "body": "documents_pg is for storing the embeddings for RAG and document_metadata is for storing the higher level document information like title, URL, etc.!",
          "created_at": "2025-05-12T12:15:29Z"
        }
      ]
    },
    {
      "issue_number": 31,
      "title": "[FEATURE] Request for Login Setup Enhancement in Flowise",
      "body": "## Describe the feature you'd like and why\nI propose enhancing the security of Flowise by implementing a login setup that restricts unauthorized access. Below are the detailed steps for configuring this feature using environment variables and Docker Compose. This enhancement would greatly benefit Flowise users who deploy their instances online.\n\n## User Impact\nImplementing a login setup in Flowise will significantly enhance security by ensuring that only authorized users can access the application. This feature is particularly beneficial for organizations and individuals who deploy Flowise in environments where sensitive data is handled or where unauthorized access could lead to data breaches or misuse. By restricting access through authentication, users can have greater confidence in the integrity and confidentiality of their workflows and data managed within Flowise.\n\n## Implementation Details (optional)\nSuggested Implementation Steps:\n1. Enable App-Level Authentication: Flowise supports app-level authorization, which restricts access to your instance using a username and password. This ensures that only authorized users can access your applications.\n\n2. Create or Update the .env File: In the project‚Äôs root directory (or within the Docker folder), create or update the .env file with the following content:\n\n# Authentication credentials for Flowise\nFLOWISE_USERNAME=your_username\nFLOWISE_PASSWORD=your_password\n\nReplace your_username and your_password with your desired credentials.\n\n3. Modify the Docker Compose File: Update the docker-compose.yml file to reference these environment variables. Ensure the environment section of your Flowise service includes:\n\nflowise:\n    image: flowiseai/flowise\n    restart: unless-stopped\n    container_name: flowise\n    environment:\n        - PORT=3001\n        - FLOWISE_USERNAME=${FLOWISE_USERNAME}\n        - FLOWISE_PASSWORD=${FLOWISE_PASSWORD}\n    ports:\n        - 3001:3001\n    extra_hosts:\n        - \\\"host.docker.internal:host-gateway\\\"\n    volumes:\n        - ~/.flowise:/root/.flowise\n    entrypoint: /bin/sh -c \\\"sleep 3; flowise start\\\"\n\n4. Restart the Docker Services: After making these changes:\n# Stop all services\ndocker compose -p localai -f docker-compose.yml -f supabase/docker/docker-compose.yml down\n\n# Pull latest versions of all containers\ndocker compose -p localai -f docker-compose.yml -f supabase/docker/docker-compose.yml pull\n\n# Start services again with your desired profile\npython3 start_services.py --profile <your-profile>\n\n\n## Additional context\nBenefits:\nImplementing this setup will enhance the security of Flowise instances by restricting access to authorized users. It is particularly useful for deployments on public or shared servers.\n\n![Image](https://github.com/user-attachments/assets/8dac60da-82c4-4f43-8ad0-223df7d2bd5c)",
      "state": "closed",
      "author": "Zebrando",
      "author_type": "User",
      "created_at": "2025-03-20T06:01:42Z",
      "updated_at": "2025-05-12T12:14:37Z",
      "closed_at": "2025-05-12T12:14:36Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/31/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/31",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/31",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:26.033575",
      "comments": [
        {
          "author": "coleam00",
          "body": "I kept this out just to keep the .env setup as simple as possible, but I think you're right that is should be included by default or at least covered in the README! I'll think about this",
          "created_at": "2025-03-23T19:51:34Z"
        },
        {
          "author": "coleam00",
          "body": "This is included now after:\n\n#59 !",
          "created_at": "2025-05-12T12:14:36Z"
        }
      ]
    },
    {
      "issue_number": 27,
      "title": "[FEATURE]",
      "body": "How can we utilize this script for a linux homelab server?\n\nAs a homelab server user, I think many power users nowadays utilize a mini pc as a server at home. I think it would be better  if I can deploy this on a proxmox server that runs ubuntu and docker rather than a pc or mac.\n\nHow can I modify the .env file so that I can install this compose file in such a case?",
      "state": "closed",
      "author": "modidep",
      "author_type": "User",
      "created_at": "2025-03-17T14:49:02Z",
      "updated_at": "2025-05-12T12:13:38Z",
      "closed_at": "2025-05-12T12:13:37Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/27/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/27",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/27",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:26.231847",
      "comments": [
        {
          "author": "coleam00",
          "body": "You should be able to deploy this as is to a Linux homelab server! Anything specific that wasn't working for you?",
          "created_at": "2025-03-23T19:53:59Z"
        },
        {
          "author": "modidep",
          "body": "I get multiple errors during supabase install. Th I will check and comment. L",
          "created_at": "2025-03-31T08:27:28Z"
        }
      ]
    },
    {
      "issue_number": 25,
      "title": "[BUG] \t\"An invalid response was received from the upstream server\"",
      "body": "## Description\nWhen connecting to http://localhost:8000 and qdrant, i'm getting the error as per title\n\n## Screenshots\n\n![Image](https://github.com/user-attachments/assets/5e2564f2-b7a8-4d77-bf4c-1b5f4fe367cd)\n\n![Image](https://github.com/user-attachments/assets/b83078c7-2d35-418a-8be1-cdf88fd9e644)\n\n## Environment\n - Linux 24.04\n\n## Additional Context\non the PC where i'm currently trying i actualy managed to open the supabase once. After that i kept getting consistently this error.",
      "state": "closed",
      "author": "Rossobimbo",
      "author_type": "User",
      "created_at": "2025-03-12T12:27:31Z",
      "updated_at": "2025-05-12T12:13:27Z",
      "closed_at": "2025-05-12T12:13:26Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/25/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/25",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/25",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:26.486357",
      "comments": [
        {
          "author": "coleam00",
          "body": "Could you try visiting the dashboard for Qdrant instead of the base URL?\n\nhttp://localhost:6333/dashboard\n\nFor Supabase, not sure why you would be getting this. Seems like a networking issue which I haven't seen before.",
          "created_at": "2025-03-23T19:57:02Z"
        },
        {
          "author": "coleam00",
          "body": "Closing this since I haven't heard back, feel free to open another issue if you need!",
          "created_at": "2025-05-12T12:13:26Z"
        }
      ]
    },
    {
      "issue_number": 21,
      "title": "[BUG] How do you upload files through \"psql\" on the same machine?",
      "body": "## Description\nI am trying to upload data to the Supabase locally using \"psql\", this works for all PostgreSQL database, but I don't know why it can't work with this project. Even if I use the ip of the docker or container id, this won't work\n\n## Steps to Reproduce\n1. Use `psql -h localhost -p 5432 -U postgres -d postgres` in command line to connect to Supabase's PostgreSQL database.\n2. You will get 'psql: error: connection to server at \"localhost\" (::1), port 5432 failed: FATAL:  Tenant or user not found'\n3. Use `psql -h 172.19.0.4 -p 5432 -U postgres -d postgres` which 172.19.0.4 is the ip of the container, you will get psql: error: connection to server at \"172.19.0.4\", port 5432 failed: Connection timed out (0x0000274C/10060)\n\n## Expected Behavior\npsql: error: connection to server at \"172.19.0.4\", port 5432 failed: Connection timed out (0x0000274C/10060))\nor\npsql: error: connection to server at \"localhost\" (::1), port 5432 failed: FATAL:  Tenant or user not found\n\n## Actual Behavior\nConnection fail. And I have to find a way upload data from local.\n\n## Screenshots\nN/A\n\n## Environment\n - OS:  Windows\n - Using Docker Desktop\n\n## Additional Context\nN/A\n\n## Possible Solution\nI need to make the port in the docker expose to the exterior. But can't find out how.",
      "state": "open",
      "author": "OstiumAxioma",
      "author_type": "User",
      "created_at": "2025-03-06T19:45:35Z",
      "updated_at": "2025-05-12T12:12:47Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/21/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/21",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/21",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:26.690762",
      "comments": [
        {
          "author": "coleam00",
          "body": "@OstiumAxioma When it says \"Tenant or user not found\" I wonder if you changed the default Postgres user when setting up the local AI package? That is the only thing I can think of in this case.",
          "created_at": "2025-05-12T12:12:40Z"
        }
      ]
    },
    {
      "issue_number": 14,
      "title": "Issue with Local File Updates Causing Multiple Additions in Supabase DB",
      "body": "I am experiencing an issue with my n8n workflow where updating a local file results in multiple additions of the same content to the Supabase database, rather than just one update. When I update a local file, previous entries are removed as expected, but the updated content gets added more than once.\n\nHere‚Äôs what happens:\n1. Updating a local file removes existing entries.\n2. The updated file is then added to Supabase DB multiple times instead of only once.\n\nThis issue can be seen in the attached image which shows the Supabase DB documents table.\n\n**Expected Behavior:**\n- Existing records should be removed and the new content should be added once, without duplication.\n\n**Actual Behavior:**\n- Entries are correctly removed on the first run but the updated content/entries get duplicated on subsequent runs.\n\n**Steps to Reproduce:**\n1. Update a local file in n8n.\n2. Observe that previous entries are removed and new ones are added, but they appear more than once.\n\n**Attachments:**\n- ![Image](https://github.com/user-attachments/assets/1bf17840-af97-4391-b817-6619b21933de)\n- ![Image](https://github.com/user-attachments/assets/6cc3fd9e-c99b-40d5-97d4-c55acdc2ed5d)",
      "state": "closed",
      "author": "YassaaaTU",
      "author_type": "User",
      "created_at": "2025-02-21T02:02:32Z",
      "updated_at": "2025-05-12T12:08:23Z",
      "closed_at": "2025-05-12T12:08:23Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/14/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/14",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/14",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:26.883400",
      "comments": [
        {
          "author": "coleam00",
          "body": "This is a bug in the n8n workflow that I need to fix, so thanks for calling this out! The issue is the \"Delete Old Doc Rows\" node outputs an item for every record deleted, so in your case it's outputting two items so the rest of the workflow runs twice. The solution is to go into the settings for th",
          "created_at": "2025-02-24T19:16:13Z"
        }
      ]
    },
    {
      "issue_number": 5,
      "title": "How to fix this?",
      "body": "Command I ran: python start_services.py --profile cpu\n\n[+] Running 24/64                                                                                                                                            10.3s \n - supavisor [‚£ø‚£ø‚†Ä‚†Ä‚†Ä‚£ø‚£ø] Pulling                                                                                                                               10.3s \n ‚úò meta Error              failed to resolve reference \"docker.io/supabase/postgres-meta:v0.84.2\": failed to do request: Head \"https://registr...            10.3s \n ‚úò vector Error            context canceled                                                                                                                  10.3s \n - db Pulling                                                                                                                                                10.3s \n - analytics [‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä] Pulling                                                                                                                              10.3s \n - realtime [‚£ø‚†Ä‚†Ä‚£ø‚£ø‚£ø‚†Ä‚£ø] 3.146MB / 56.66MB Pulling                                                                                                             10.3s \n - studio [‚£Ä‚†Ä‚£ø‚£§‚£ø‚†Ä‚†Ä‚†Ä‚£ø‚£ø‚†Ä] Pulling                                                                                                                              10.3s \n - auth [‚†Ä‚£ø‚£ø‚£ø‚£ø‚£Ä] Pulling                                                                                                                                     10.3s \n ‚úò storage Error           context canceled                                                                                                                  10.3s \n - functions [‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£ø] Pulling                                                                                                                                10.3s \n ‚úò imgproxy Error          context canceled                                                                                                                  10.3s \n - kong [‚£ø‚†Ä‚£ø‚†Ä] Pulling                                                                                                                                       10.3s \n - rest [‚°Ä] 1.049MB / 5.311MB Pulling                                                                                                                        10.3s \nError response from daemon: failed to resolve reference \"docker.io/supabase/postgres-meta:v0.84.2\": failed to do request: Head \"https://registry-1.docker.io/v2/supabase/postgres-meta/manifests/v0.84.2\": net/http: TLS handshake timeout\nTraceback (most recent call last):\n  File \"C:\\Users\\Darshan Jain\\OneDrive\\Desktop\\local-ai-packaged\\start_services.py\", line 95, in <module>\n    main()\n    ~~~~^^\n  File \"C:\\Users\\Darshan Jain\\OneDrive\\Desktop\\local-ai-packaged\\start_services.py\", line 85, in main\n    start_supabase()\n    ~~~~~~~~~~~~~~^^\n  File \"C:\\Users\\Darshan Jain\\OneDrive\\Desktop\\local-ai-packaged\\start_services.py\", line 61, in start_supabase\n    run_command([\n    ~~~~~~~~~~~^^\n        \"docker\", \"compose\", \"-p\", \"localai\", \"-f\", \"supabase/docker/docker-compose.yml\", \"up\", \"-d\"\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ])\n    ^^\n  File \"C:\\Users\\Darshan Jain\\OneDrive\\Desktop\\local-ai-packaged\\start_services.py\", line 19, in run_command\n    subprocess.run(cmd, cwd=cwd, check=True)\n    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Darshan Jain\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 577, in run\n    raise CalledProcessError(retcode, process.args,\n                             output=stdout, stderr=stderr)\nsubprocess.CalledProcessError: Command '['docker', 'compose', '-p', 'localai', '-f', 'supabase/docker/docker-compose.yml', 'up', '-d']' returned non-zero exit status 18.\nPS C:\\Users\\Darshan Jain\\OneDrive\\Desktop\\local-ai-packaged> ",
      "state": "closed",
      "author": "DarshanJain-07",
      "author_type": "User",
      "created_at": "2025-02-17T20:53:14Z",
      "updated_at": "2025-05-12T12:07:25Z",
      "closed_at": "2025-05-12T12:07:23Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/5/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/5",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/5",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:27.044067",
      "comments": [
        {
          "author": "DarshanJain-07",
          "body": "I have been trying to self-host Supabase for quite a while now, but I encounter the exact same errors every time. While researching this issue, I found that one possible solution is to pull all the containers separately rather than using the Docker Compose file. Can anyone shed some light on this?",
          "created_at": "2025-02-17T20:59:53Z"
        },
        {
          "author": "coleam00",
          "body": "Honestly seems like something that could call for a reinstall of Docker, I haven't seen anything like this error before! Are you using Docker Desktop?",
          "created_at": "2025-02-18T20:24:17Z"
        },
        {
          "author": "berowsma",
          "body": "I am currently seeing this error as well, windows 11 with latest docker desktop V(27.5.1) and Python V(3.13), oddly this works just fine on my linux system, but due to a hatred in myself, hate attaching network shares in linux and went the windows route to handle this personal hatred. The following ",
          "created_at": "2025-02-27T14:50:45Z"
        },
        {
          "author": "JacksADirtyGit",
          "body": "@DarshanJain-07 Don't save to OneDrive\n\n@berowsma unblock port :8000  For some reason you have it blocked",
          "created_at": "2025-04-16T06:35:29Z"
        },
        {
          "author": "coleam00",
          "body": "Closing since @JacksADirtyGit had a good answer. Lmk if the error persists!",
          "created_at": "2025-05-12T12:07:23Z"
        }
      ]
    },
    {
      "issue_number": 57,
      "title": "[FEATURE]",
      "body": "## Describe the feature you'd like and why\nEasy change of model to avoid this error:\n\"model requires more system memory than is available\"\n\n## User Impact\nUsers with less than 12GB memory\n\n## Implementation Details (optional)\nTutorial how to change the model + examples of memory needed\n",
      "state": "closed",
      "author": "fabnoe",
      "author_type": "User",
      "created_at": "2025-05-10T15:22:57Z",
      "updated_at": "2025-05-10T19:52:07Z",
      "closed_at": "2025-05-10T19:52:07Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/57/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/57",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/57",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:27.256011",
      "comments": []
    },
    {
      "issue_number": 56,
      "title": "[BUG]",
      "body": "## Description\nOllama does not show llama model. n8n test workflow fails\n\n## Steps to Reproduce\nI followed the step by setp in this repo\n\n## Expected Behavior\nSelect \"llama\" in n8n node.\n\n## Actual Behavior\nA clear and concise description of what actually happened.\n\nn8n error:\n```\nProblem in node ‚ÄòAI Agent‚Äò\n\"nomic-embed-text:latest\" does not support chat\n\n```\n## Screenshots\n<img width=\"424\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/c1297ef0-3373-499f-b4d6-558b609ff441\" />\n\n## Environment\n - OS: macOS Monterey\n - Using Docker Desktop.\n\n",
      "state": "closed",
      "author": "fabnoe",
      "author_type": "User",
      "created_at": "2025-05-10T13:43:57Z",
      "updated_at": "2025-05-10T15:17:53Z",
      "closed_at": "2025-05-10T15:17:53Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/56/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/56",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/56",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:27.256030",
      "comments": []
    },
    {
      "issue_number": 43,
      "title": "[BUG] n8n-import",
      "body": "## Description\nn8n-import seems to ask for folder: 'credentials' which was never created during my install.\n\n```\n  n8n-import:\n    <<: *service-n8n\n    container_name: n8n-import\n    entrypoint: /bin/sh\n    command:\n      - \"-c\"\n      - \"n8n import:credentials --separate --input=/backup/credentials && n8n import:workflow --separate --input=/backup/workflows\"\n    volumes:\n      - ./n8n/backup:/backup\n```\n\n",
      "state": "closed",
      "author": "Steviey",
      "author_type": "User",
      "created_at": "2025-04-09T05:00:38Z",
      "updated_at": "2025-04-21T14:33:06Z",
      "closed_at": "2025-04-21T14:33:04Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/43/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/43",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/43",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:27.256037",
      "comments": [
        {
          "author": "Steviey",
          "body": "**Reinstalled docker (native instead of snap version), switched to docker compose V2.\nTweaked firewall with a little help from my friend Gemini.\nBugs are gone!**\n\nThat's magic",
          "created_at": "2025-04-21T14:33:05Z"
        }
      ]
    },
    {
      "issue_number": 47,
      "title": "[BUG] n8n-import",
      "body": "Ubuntu 20.x LTS, Dedicated Server (live), ai-local-packed latest\n\n## Description\nI got the following output from n8n-import:\n\n```\nn8n-import  | Permissions 0644 for n8n settings file /home/node/.n8n/config are too wide. This is ignored for now, but in the future n8n will attempt to change the permissions automatically. To automatically enforce correct permissions now set N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS=true (recommended), or turn this check off set N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS=false.\nn8n-import  | There was an error initializing DB\nn8n-import  | Could not establish database connection within the configured timeout of 20,000 ms. Please ensure the database is configured correctly and the server is reachable. You can increase the timeout by setting the 'DB_POSTGRESDB_CONNECTION_TIMEOUT' environment variable.\nn8n-import  | Error: Could not establish database connection within the configured timeout of 20,000 ms. Please ensure the database is configured correctly and the server is reachable. You can increase the timeout by setting the 'DB_POSTGRESDB_CONNECTION_TIMEOUT' environment variable.\nn8n-import  |     at Object.init (/usr/local/lib/node_modules/n8n/dist/db.js:57:21)\nn8n-import  |     at processTicksAndRejections (node:internal/process/task_queues:95:5)\nn8n-import  |     at ImportCredentialsCommand.init (/usr/local/lib/node_modules/n8n/dist/commands/base-command.js:98:9)\nn8n-import  |     at ImportCredentialsCommand._run (/usr/local/lib/node_modules/n8n/node_modules/@oclif/core/lib/command.js:301:13)\nn8n-import  |     at Config.runCommand (/usr/local/lib/node_modules/n8n/node_modules/@oclif/core/lib/config/config.js:424:25)\nn8n-import  |     at run (/usr/local/lib/node_modules/n8n/node_modules/@oclif/core/lib/main.js:94:16)\nn8n-import  |     at /usr/local/lib/node_modules/n8n/bin/n8n:71:2\nn8n-import  | \nn8n-import  | Connection terminated due to connection timeout\nn8n-import  | Connection terminated unexpectedly\nn8n-import  | Permissions 0644 for n8n settings file /home/node/.n8n/config are too wide. This is ignored for now, but in the future n8n will attempt to change the permissions automatically. To automatically enforce correct permissions now set N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS=true (recommended), or turn this check off set N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS=false.\nn8n-import  | User settings loaded from: /home/node/.n8n/config\nn8n-import  | There was an error initializing DB\nn8n-import  | getaddrinfo EAI_AGAIN db\nn8n-import  | Permissions 0644 for n8n settings file /home/node/.n8n/config are too wide. This is ignored for now, but in the future n8n will attempt to change the permissions automatically. To automatically enforce correct permissions now set N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS=true (recommended), or turn this check off set N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS=false.\nn8n-import  | User settings loaded from: /home/node/.n8n/config\nn8n-import  | There was an error initializing DB\nn8n-import  | getaddrinfo EAI_AGAIN db\n\n```\n\nAfter reinstall I get only the following:\n\n```\nn8n-import  | Permissions 0644 for n8n settings file /home/node/.n8n/config are too wide. This is ignored for now, but in the future n8n will attempt to change the permissions automatically. To automatically enforce correct permissions now set N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS=true (recommended), or turn this check off set N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS=false.\nn8n-import  | There was an error initializing DB\nn8n-import  | Could not establish database connection within the configured timeout of 20,000 ms. Please ensure the database is configured correctly and the server is reachable. You can increase the timeout by setting the 'DB_POSTGRESDB_CONNECTION_TIMEOUT' environment variable.\nn8n-import  | Error: Could not establish database connection within the configured timeout of 20,000 ms. Please ensure the database is configured correctly and the server is reachable. You can increase the timeout by setting the 'DB_POSTGRESDB_CONNECTION_TIMEOUT' environment variable.\nn8n-import  |     at Object.init (/usr/local/lib/node_modules/n8n/dist/db.js:57:21)\nn8n-import  |     at processTicksAndRejections (node:internal/process/task_queues:95:5)\nn8n-import  |     at ImportCredentialsCommand.init (/usr/local/lib/node_modules/n8n/dist/commands/base-command.js:98:9)\nn8n-import  |     at ImportCredentialsCommand._run (/usr/local/lib/node_modules/n8n/node_modules/@oclif/core/lib/command.js:301:13)\nn8n-import  |     at Config.runCommand (/usr/local/lib/node_modules/n8n/node_modules/@oclif/core/lib/config/config.js:424:25)\nn8n-import  |     at run (/usr/local/lib/node_modules/n8n/node_modules/@oclif/core/lib/main.js:94:16)\nn8n-import  |     at /usr/local/lib/node_modules/n8n/bin/n8n:71:2\nn8n-import  | \nn8n-import  | Connection terminated due to connection timeout\nn8n-import  | Connection terminated unexpectedly\n\n```\n## Please help...\n\ngetaddrinfo EAI_AGAIN db seems to be an DNS-Error.\nBut I have no clue in this context.\nI m using dynDNS.\n\n",
      "state": "closed",
      "author": "Steviey",
      "author_type": "User",
      "created_at": "2025-04-17T15:57:42Z",
      "updated_at": "2025-04-21T14:31:37Z",
      "closed_at": "2025-04-21T14:29:00Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/47/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/47",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/47",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:27.530709",
      "comments": [
        {
          "author": "Steviey",
          "body": "**Reinstalled docker (native instead of snap version), switched to docker compose V2.\nTweaked firewall with a little help from my friend Gemini.\nBugs are gone!**\n\nThat's magic ",
          "created_at": "2025-04-21T14:29:00Z"
        }
      ]
    },
    {
      "issue_number": 44,
      "title": "[FEATURE] Define named network to permit sharing of internal network between docker-compose projects",
      "body": "## Describe the feature you'd like and why\n\nEach running service should be on a named network, rather than relying on docker's automatic network name. Something like\n`  network: \"local-ai`\n\n## Describe why\n\nThis would permit setting up a docker network before launching this project, and then launching another project that uses the same named network. Therefore not ever service needs to be exposed to be used by external containers\n\n## User Impact Who would benefit from this feature and how?\n\nI have another feature request coming to add services and this would have made it easier to setup sharing the services like ollama without having to expose them beyond the local machine.\n\n## Implementation Details (optional)\nAny thoughts on how this might be implemented?\n\nhttps://docs.docker.com/compose/how-tos/networking/#specify-custom-networks\n",
      "state": "closed",
      "author": "levonk",
      "author_type": "User",
      "created_at": "2025-04-09T21:17:28Z",
      "updated_at": "2025-04-19T05:05:08Z",
      "closed_at": "2025-04-19T05:05:07Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/44/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/44",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/44",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:27.709955",
      "comments": [
        {
          "author": "levonk",
          "body": "I should have looked closer before submitting this bug, sorry.",
          "created_at": "2025-04-19T05:05:07Z"
        }
      ]
    },
    {
      "issue_number": 4,
      "title": "Couple things to finish connecting",
      "body": "1. Hooking up Ollama to n8n worked, but the URL in the readme `ollama:11434` doesnt work (might confuse some) and might just be better saying \"localhost\".\n2. Qdrant, the same as above, but I didnt even see where to configure this in the n8n workflow, or where to grab a key?\n3. Postgres hooked up fine, from the .env, but I don't know the Supabase URL to configure those credentials. And there is not a step in the setup talking about that\n4. openwebui has these 4 in workspace, Models, prompts, Knowledge, Tools... no \"functions\" I tried to import it as a tool, but I get an error.\n5. Google Docs, I dont even see where to configure Google Docs in the n8n workflow. Not sure how this fits in.\n\n\nAny additional guidance you can give would be great. the setup script ran pretty flawless, and it seems all the other pieces are coming together. ",
      "state": "closed",
      "author": "timothyjoh",
      "author_type": "User",
      "created_at": "2025-02-17T13:50:44Z",
      "updated_at": "2025-03-30T08:25:02Z",
      "closed_at": "2025-02-24T19:07:50Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 13,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/4/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/4",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/4",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:27.928952",
      "comments": [
        {
          "author": "timothyjoh",
          "body": "I went back to your video and saw that for Supabase we should use\n`http://host.docker.internal:8000` or `http://kong:8000` with the `SERVICE_ROLE_KEY` (I assume) but neither of these worked for some reason",
          "created_at": "2025-02-17T16:23:34Z"
        },
        {
          "author": "timothyjoh",
          "body": "Weirdly, when I go to the API settings (like the n8n docs say to) I get redirected back to the project default homepage. So if it is another key I have to generate (like here https://docs.n8n.io/integrations/builtin/credentials/supabase/#related-resources) then I cant get it... wonder why",
          "created_at": "2025-02-17T16:31:52Z"
        },
        {
          "author": "timothyjoh",
          "body": "A couple new things I can resolve myself. \n\nThe workflow here: https://github.com/coleam00/local-ai-packaged/blob/main/n8n/backup/workflows/Local_RAG_AI_Agent_n8n_Workflow.json did NOT install with the other Supabase one. That is why I was confused about Qdrant and Google Docs, which were not used i",
          "created_at": "2025-02-17T17:11:31Z"
        },
        {
          "author": "timothyjoh",
          "body": "SMH!!!\n\nI skipped the link to the Supabase selfhosted guide to generate keys based on my JWT\nhttps://supabase.com/docs/guides/self-hosting/docker#generate-api-keys\n\nWould be great to add a note in the `.env.example` between the JWT and these 2 keys. \n\nI'm getting closer, only OpenWebUI to go...",
          "created_at": "2025-02-17T17:13:40Z"
        },
        {
          "author": "timothyjoh",
          "body": "I had to go to http://localhost:3000/admin/functions to get to the functions... ugh\n\nI keep getting responses like \n```\nError during sequence execution: HTTPConnectionPool(host='localhost', port=5678): Max retries exceeded with url: /webhook....\n```\n\nbut still digging into it\n",
          "created_at": "2025-02-17T18:47:58Z"
        }
      ]
    },
    {
      "issue_number": 37,
      "title": "[FEATURE] USE mcp with UVX",
      "body": "##  Currently, the mcp server using npx can be used, but the uvx one cannot be used\n\n### Config\n\n![Image](https://github.com/user-attachments/assets/21608011-754b-4393-9b10-1561fad27a95)\n\n### RUN with ' uvx terminal_controller '\n![Image](https://github.com/user-attachments/assets/69d5d782-85d7-4411-8cd1-7b268cd53ceb)\n\n\n",
      "state": "closed",
      "author": "GongRzhe",
      "author_type": "User",
      "created_at": "2025-03-26T09:51:28Z",
      "updated_at": "2025-03-26T10:38:20Z",
      "closed_at": "2025-03-26T10:38:20Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/37/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/37",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/37",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:28.137577",
      "comments": []
    },
    {
      "issue_number": 20,
      "title": "[BUG]  you have the portainer uses in this",
      "body": "## Description\nA clear and concise description of the issue.\n\n## Steps to Reproduce\n1. Go to '...'\n2. Click on '....'\n3. Scroll down to '....'\n4. See error\n\n## Expected Behavior\nA clear and concise description of what you expected to happen.\n\n## Actual Behavior\nA clear and concise description of what actually happened.\n\n## Screenshots\nIf applicable, add screenshots to help explain your problem.\n\n## Environment\n - OS: [e.g. Windows 10, macOS Monterey, Ubuntu 22.04]\n - Using Docker Desktop, WSL, etc.\n\n## Additional Context\nAdd any other context about the problem here, such as:\n- Does this happen consistently or intermittently?\n- Were there any recent changes that might be related?\n- Any workarounds you've discovered?\n\n## Possible Solution\nIf you have suggestions on how to fix the issue or what might be causing it.",
      "state": "closed",
      "author": "pirateben820",
      "author_type": "User",
      "created_at": "2025-03-05T20:22:26Z",
      "updated_at": "2025-03-23T19:57:54Z",
      "closed_at": "2025-03-23T19:57:54Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/20/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/20",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/20",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:28.137590",
      "comments": []
    },
    {
      "issue_number": 29,
      "title": "[BUG]  you script downloads everything at once makeing it fail please make them download 2 or 3 at a time",
      "body": "my computer dosnt like everything all at once and cant manage the networking ",
      "state": "closed",
      "author": "pirateben820",
      "author_type": "User",
      "created_at": "2025-03-17T23:13:02Z",
      "updated_at": "2025-03-23T19:54:34Z",
      "closed_at": "2025-03-23T19:54:33Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/29/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/29",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/29",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:28.137594",
      "comments": [
        {
          "author": "coleam00",
          "body": "I'm going to close this issue since not a lot of info is given. Please open another if you want and describe the errors you are getting!",
          "created_at": "2025-03-23T19:54:33Z"
        }
      ]
    },
    {
      "issue_number": 28,
      "title": "[BUG] Pooler not starting correctly",
      "body": "## Description\nThe supabase-pooler was continuously restarting and never getting to a healthy state\n\n## Steps to Reproduce\nInstalled as described onto a Digital Ocean droplet\n\n## Expected Behavior\nA correctly functioning supabase-pooler\n\n## Actual Behavior\nsupabase-pooler restarting\n\n## Screenshots\nIf applicable, add screenshots to help explain your problem.\n\n## Environment\n - Docker on a Digital Ocean droplet\n\n## Additional Context\n\n\n## Possible Solution\nI managed to fix this by adding a 32 character key to VAULT_ENC_KEY for the Supervisor settings in .env",
      "state": "closed",
      "author": "Videoblam",
      "author_type": "User",
      "created_at": "2025-03-17T21:47:25Z",
      "updated_at": "2025-03-23T19:53:21Z",
      "closed_at": "2025-03-23T19:53:20Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/28/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/28",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/28",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:28.313250",
      "comments": [
        {
          "author": "Videoblam",
          "body": "Just to add,  the localhost URLs need to be replaced with 'subdomain.domain.com' to allow buckets to work correctly from the web interface",
          "created_at": "2025-03-17T22:40:25Z"
        },
        {
          "author": "coleam00",
          "body": "Check the README troubleshooting section, I cover what to do if the pooler is constantly restarting!",
          "created_at": "2025-03-23T19:53:20Z"
        }
      ]
    },
    {
      "issue_number": 32,
      "title": "[FEATURE] Update the prerequisites to indicate how much disk space is required",
      "body": "## Describe the feature you'd like and why\nHere's a suggestion that could save local-ai-package users some trouble, and which could be added to the prerequisites ( https://github.com/coleam00/local-ai-packaged/issues ):\n\n28 GB of free hard disk space\n\n## User Impact\nThose who are going to install local-ai-package\n",
      "state": "open",
      "author": "openelearning",
      "author_type": "User",
      "created_at": "2025-03-20T16:14:32Z",
      "updated_at": "2025-03-23T19:50:57Z",
      "closed_at": null,
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/32/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/32",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/32",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:29.564440",
      "comments": [
        {
          "author": "AugustoSystems",
          "body": "I ran into this on a virtual machine. I also had to comment out a few items on the docker-compose so that it only did a pull for a few of the larger images at a time. ",
          "created_at": "2025-03-20T21:08:45Z"
        },
        {
          "author": "nikhilmaddirala",
          "body": "> ## Describe the feature you'd like and why\n> Here's a suggestion that could save local-ai-package users some trouble, and which could be added to the prerequisites ( https://github.com/coleam00/local-ai-packaged/issues ):\n> \n> 28 GB of free hard disk space\n> \n> ## User Impact\n> Those who are going",
          "created_at": "2025-03-21T00:36:04Z"
        },
        {
          "author": "openelearning",
          "body": "Docker therefore uses almost the entire space. But I haven't managed to get any more precise information than the attached screenshots. And for the moment I can't use Docker Desktop, there's a rights issue.\n\n![Image](https://github.com/user-attachments/assets/f61c2b1b-b5c4-43f4-b621-70d723e2230b)\n![",
          "created_at": "2025-03-21T09:09:03Z"
        },
        {
          "author": "openelearning",
          "body": "But we can see that if we can use our local ollama and openwebui, we can save at least 6.1 GB of disk space. Maybe we can try to document how to do that.",
          "created_at": "2025-03-21T09:11:39Z"
        },
        {
          "author": "openelearning",
          "body": "@AugustoSystems \n\n> I ran into this on a virtual machine. I also had to comment out a few items on the docker-compose so that it only did a pull for a few of the larger images at a time.\n\nTo do this, did you just delete this part in docker-compose.yml before running start_services.py?\n```\nx-ollama: ",
          "created_at": "2025-03-21T09:16:22Z"
        }
      ]
    },
    {
      "issue_number": 18,
      "title": "Ollama startup failure with start_services.py",
      "body": "I am using Ubuntu 20.04 LTR.\nWhen I run the python start_services.py \n- supbase initializes successfully\n- everything else starts correctly\n- ollama seems to fail.\n\nThe problem seems rooted in network (see screen capture). In Docker Desktop, it appears that the following containers don't start:\n- ollama-pull-llama\n- ollama\n- n8n\n\n![Image](https://github.com/user-attachments/assets/92ce6eab-e532-4f80-8c77-753307480d9e)\n\n",
      "state": "closed",
      "author": "sidkdbl07",
      "author_type": "User",
      "created_at": "2025-02-24T18:56:34Z",
      "updated_at": "2025-03-07T20:46:22Z",
      "closed_at": "2025-02-24T22:34:56Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/18/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/18",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/18",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:29.793605",
      "comments": [
        {
          "author": "coleam00",
          "body": "I saw this happen to one other person and it's because they had an old Ollama container hanging around which I think is the case for you since it's referencing a network with an auto generated name instead of the \"localai\" network set with the -p flag in the Docker compose command.\n\nHave you run Oll",
          "created_at": "2025-02-24T19:21:53Z"
        },
        {
          "author": "sidkdbl07",
          "body": "Hazaa! I removed the ollama and ollama-pull-llama containers, the localai-olama-storage volume. Then I ran your script again, and it seemed to work (see below).\n\nI'm not sure why n8n-import is of 'Exited' status, but I am further than I was before. You can close this issue, and hopefully it help som",
          "created_at": "2025-02-24T22:34:56Z"
        },
        {
          "author": "xactant",
          "body": "Thanks, I have the same issue, also on Ubuntu. I have run Ollama on this machine in the past. I will give this a try.",
          "created_at": "2025-03-07T11:54:37Z"
        },
        {
          "author": "xactant",
          "body": "I was able to solve my issue but it is slightly different so I will post here in case it helps anyone else. \n1. I did have an older copy of ollama but not in a container. When I first ran the script it failed due to the other ollama instance using the ollama port.\n2. The failure caused an unnamed co",
          "created_at": "2025-03-07T20:46:22Z"
        }
      ]
    },
    {
      "issue_number": 7,
      "title": "Error response from daemon: network 9ab344ea5c1d7916a166cfbef3ffc3a74416de817aeb5b05b6dbbc970f931280 not found",
      "body": "[start_services.zip](https://github.com/user-attachments/files/18845912/start_services.zip)\n\nEvery time I execute python start_services.py --profile gpu-nvidia, I always get an error: Error response from daemon: network 9ab344ea5c1d7916a166cfbef3ffc3a74416de817aeb5b05b6dbbc970f931280 not found\n\nResoluationÔºö\nI noticed that this is a Docker network-related error. According to code analysis, this problem may be caused by incomplete Docker network cleanup. I suggest adding a more powerful network cleanup mechanism to the existing cleanup logic to ensure that all related Docker network resources are completely cleaned up before starting the service, and increase the appropriate waiting time.\n\nThe following start_services.py file modifies the clean_docker_environment function to add a more powerful network cleanup mechanism, including forcibly removing all related Docker network resources and increasing the waiting time. Please adopt it.\n\nstart_services.py\n\n+ 46 - 9\n\nReview\n\nI have completed the fix for the Docker network error problem. The main improvements include:\n\n1. Enhanced the network cleanup mechanism of the clean_docker_environment function:\n\n- Added forced removal of all localai related Docker networks\n- Increased the waiting time for network cleanup\n- Improved error handling and log output\n2. Specific improvements include:\n\n- Use the docker network ls command to list all related networks\n- Use docker network rm -f to forcefully delete each network\n- Added an error handling mechanism for network cleanup\n- Increased the waiting time after cleanup to 10 seconds\nThese improvements should be able to solve the problem of incomplete network resource cleanup and avoid the occurrence of \"network not found\" errors.\n\nRevised code content as follows:\n`#!/usr/bin/env python3\n\"\"\"\nstart_services.py\n\nThis script starts the Supabase stack first, waits for it to initialize, and then starts\nthe local AI stack. Both stacks use the same Docker Compose project name (\"localai\")\nso they appear together in Docker Desktop.\n\nEnhanced version with better error handling and network management.\n\"\"\"\n\nimport os\nimport subprocess\nimport shutil\nimport time\nimport argparse\nimport sys\nfrom typing import List, Optional\n\ndef run_command(cmd: List[str], cwd: Optional[str] = None, capture_output: bool = False) -> subprocess.CompletedProcess:\n    \"\"\"Run a shell command and print it.\"\"\"\n    print(\"Running:\", \" \".join(cmd))\n    try:\n        return subprocess.run(cmd, cwd=cwd, check=True, capture_output=capture_output, text=True)\n    except subprocess.CalledProcessError as e:\n        print(f\"Error executing command: {' '.join(cmd)}\")\n        print(f\"Error output: {e.stderr if hasattr(e, 'stderr') else 'No error output available'}\")\n        raise\n\ndef clone_supabase_repo() -> None:\n    \"\"\"Clone the Supabase repository using sparse checkout if not already present.\"\"\"\n    max_retries = 3\n    retry_delay = 5  # seconds\n\n    def git_command_with_retry(cmd: List[str], cwd: Optional[str] = None) -> None:\n        for attempt in range(max_retries):\n            try:\n                # Add git config commands to handle SSL issues\n                if cmd[0] == \"git\" and cmd[1] == \"pull\":\n                    # First try to set SSL verification to false\n                    subprocess.run([\"git\", \"config\", \"--global\", \"http.sslVerify\", \"false\"], \n                                 check=True, capture_output=True)\n                \n                result = subprocess.run(cmd, cwd=cwd, check=True, capture_output=True, text=True)\n                # Reset SSL verification to true after successful pull\n                if cmd[0] == \"git\" and cmd[1] == \"pull\":\n                    subprocess.run([\"git\", \"config\", \"--global\", \"http.sslVerify\", \"true\"],\n                                 check=True, capture_output=True)\n                return\n            except subprocess.CalledProcessError as e:\n                print(f\"Attempt {attempt + 1} failed: {e.stderr}\")\n                if attempt < max_retries - 1:\n                    print(f\"Retrying in {retry_delay} seconds...\")\n                    time.sleep(retry_delay)\n                else:\n                    # If all retries failed but supabase directory exists, continue anyway\n                    if os.path.exists(\"supabase\") and os.path.exists(os.path.join(\"supabase\", \"docker\")):\n                        print(\"Git operation failed but required files exist. Continuing...\")\n                        return\n                    print(\"All retry attempts failed.\")\n                    raise\n\n    if not os.path.exists(\"supabase\"):\n        print(\"Cloning the Supabase repository...\")\n        git_command_with_retry([\n            \"git\", \"clone\", \"--filter=blob:none\", \"--no-checkout\",\n            \"https://github.com/supabase/supabase.git\"\n        ])\n        os.chdir(\"supabase\")\n        git_command_with_retry([\"git\", \"sparse-checkout\", \"init\", \"--cone\"])\n        git_command_with_retry([\"git\", \"sparse-checkout\", \"set\", \"docker\"])\n        git_command_with_retry([\"git\", \"checkout\", \"master\"])\n        os.chdir(\"..\")\n    else:\n        print(\"Supabase repository already exists, updating...\")\n        os.chdir(\"supabase\")\n        git_command_with_retry([\"git\", \"pull\"])\n        os.chdir(\"..\")\n\ndef remove_network(network_name: str) -> None:\n    \"\"\"Remove Docker network if it exists.\"\"\"\n    try:\n        subprocess.run(\n            [\"docker\", \"network\", \"rm\", network_name],\n            check=True,\n            capture_output=True\n        )\n        print(f\"Removed network {network_name}\")\n        # Wait a bit for the network to be fully removed\n        time.sleep(2)\n    except subprocess.CalledProcessError:\n        pass  # Ignore if network doesn't exist\n\ndef clean_docker_environment() -> None:\n    \"\"\"Clean up Docker environment completely.\"\"\"\n    print(\"Cleaning up Docker environment...\")\n    \n    # Stop all running containers in the project\n    try:\n        run_command([\n            \"docker\", \"compose\",\n            \"-p\", \"localai\",\n            \"-f\", \"docker-compose.yml\",\n            \"-f\", \"supabase/docker/docker-compose.yml\",\n            \"down\", \"--remove-orphans\"\n        ])\n    except Exception as e:\n        print(f\"Warning: Error during compose down: {str(e)}\")\n    \n    # Force remove all containers with the project name\n    try:\n        containers = subprocess.run(\n            [\"docker\", \"ps\", \"-aq\", \"--filter\", \"name=localai\"],\n            capture_output=True, text=True, check=True\n        ).stdout.strip().split('\\n')\n        \n        for container in containers:\n            if container:  # Skip empty strings\n                try:\n                    subprocess.run([\"docker\", \"rm\", \"-f\", container], check=True)\n                except Exception as e:\n                    print(f\"Warning: Could not remove container {container}: {str(e)}\")\n    except Exception as e:\n        print(f\"Warning: Error listing containers: {str(e)}\")\n    \n    # Remove all networks related to the project\n    try:\n        networks = subprocess.run(\n            [\"docker\", \"network\", \"ls\", \"--filter\", \"name=localai\", \"--format\", \"{{.ID}}\"],\n            capture_output=True, text=True, check=True\n        ).stdout.strip().split('\\n')\n        \n        for network in networks:\n            if network:  # Skip empty strings\n                try:\n                    subprocess.run([\"docker\", \"network\", \"rm\", \"-f\", network], check=True)\n                except Exception as e:\n                    print(f\"Warning: Could not remove network {network}: {str(e)}\")\n    except Exception as e:\n        print(f\"Warning: Error listing networks: {str(e)}\")\n    \n    # Remove the specific network\n    remove_network(\"localai_default\")\n    \n    # Prune networks\n    run_command([\"docker\", \"network\", \"prune\", \"-f\"])\n    \n    # Wait longer for everything to clean up\n    print(\"Waiting for Docker resources to clean up...\")\n    time.sleep(10)  # Increased wait time to ensure complete cleanup\n    time.sleep(3)\n\ndef prepare_supabase_env() -> None:\n    \"\"\"Copy .env to .env in supabase/docker.\"\"\"\n    env_path = os.path.join(\"supabase\", \"docker\", \".env\")\n    env_example_path = os.path.join(\".env\")\n    \n    if not os.path.exists(env_example_path):\n        print(\"Error: .env file not found in root directory\")\n        sys.exit(1)\n        \n    print(\"Copying .env in root to .env in supabase/docker...\")\n    shutil.copyfile(env_example_path, env_path)\n\ndef start_supabase() -> None:\n    \"\"\"Start the Supabase services (using its compose file).\"\"\"\n    print(\"Starting Supabase services...\")\n    compose_file = os.path.join(\"supabase\", \"docker\", \"docker-compose.yml\")\n    if not os.path.exists(compose_file):\n        raise FileNotFoundError(f\"Docker compose file not found: {compose_file}\")\n    \n    max_retries = 3\n    for attempt in range(max_retries):\n        try:\n            run_command([\n                \"docker\", \"compose\", \"-p\", \"localai\", \"-f\", compose_file, \"up\", \"-d\"\n            ])\n            print(\"Supabase services started successfully\")\n            return\n        except subprocess.CalledProcessError as e:\n            print(f\"Attempt {attempt + 1} failed to start Supabase services\")\n            if attempt < max_retries - 1:\n                print(\"Cleaning up and retrying...\")\n                clean_docker_environment()\n                time.sleep(5)\n            else:\n                raise Exception(\"Failed to start Supabase services after multiple attempts\")\n\ndef start_local_ai(profile: Optional[str] = None) -> None:\n    \"\"\"Start the local AI services (using its compose file).\"\"\"\n    print(\"Starting local AI services...\")\n    \n    # Prepare the command\n    cmd = [\"docker\", \"compose\", \"-p\", \"localai\"]\n    if profile and profile != \"none\":\n        cmd.extend([\"--profile\", profile])\n    cmd.extend([\"-f\", \"docker-compose.yml\", \"up\", \"-d\"])\n    \n    # Add retry logic\n    max_retries = 3\n    current_retry = 0\n    \n    while current_retry < max_retries:\n        try:\n            run_command(cmd)\n            print(\"Local AI services started successfully\")\n            break\n        except subprocess.CalledProcessError as e:\n            current_retry += 1\n            print(f\"Attempt {current_retry} failed. Error: {str(e)}\")\n            if current_retry < max_retries:\n                print(f\"Waiting 10 seconds before retry {current_retry + 1}/{max_retries}...\")\n                time.sleep(10)\n            else:\n                raise Exception(\"Failed to start local AI services after multiple attempts\")\n\ndef check_prerequisites() -> None:\n    \"\"\"Check if all prerequisites are met.\"\"\"\n    try:\n        # Check Docker\n        run_command([\"docker\", \"--version\"], capture_output=True)\n        # Check Docker Compose\n        run_command([\"docker\", \"compose\", \"version\"], capture_output=True)\n        # Check Git\n        run_command([\"git\", \"--version\"], capture_output=True)\n    except subprocess.CalledProcessError as e:\n        print(\"Error: Prerequisites check failed\")\n        print(f\"Error details: {str(e)}\")\n        sys.exit(1)\n    except FileNotFoundError as e:\n        print(f\"Error: Required program not found: {str(e)}\")\n        print(\"Please ensure Docker, Docker Compose, and Git are installed and in your PATH\")\n        sys.exit(1)\n\ndef main() -> None:\n    \"\"\"Main function to run the script.\"\"\"\n    parser = argparse.ArgumentParser(description='Start the local AI and Supabase services.')\n    parser.add_argument('--profile', \n                       choices=['cpu', 'gpu-nvidia', 'gpu-amd', 'none'], \n                       default='cpu',\n                       help='Profile to use for Docker Compose (default: cpu)')\n    args = parser.parse_args()\n\n    try:\n        # Check prerequisites first\n        check_prerequisites()\n        \n        # Initialize services\n        clone_supabase_repo()\n        prepare_supabase_env()\n        \n        # Clean up Docker environment completely\n        clean_docker_environment()\n        \n        # Start Supabase first\n        start_supabase()\n        \n        # Give Supabase some time to initialize\n        print(\"Waiting for Supabase to initialize...\")\n        time.sleep(15)  # Increased wait time\n        \n        # Then start the local AI services\n        start_local_ai(args.profile)\n        \n        print(\"\\nAll services started successfully!\")\n        print(\"You can access:\")\n        print(\"- n8n at: http://localhost:5678\")\n        print(\"- Open WebUI at: http://localhost:3000\")\n        print(\"- Supabase Studio at: http://localhost:8000\")\n        print(\"- Flowise at: http://localhost:3001\")\n        print(\"- Qdrant Dashboard at: http://localhost:6333\")\n        \n    except Exception as e:\n        print(f\"\\nError: {str(e)}\")\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()`",
      "state": "closed",
      "author": "ruanjunmin",
      "author_type": "User",
      "created_at": "2025-02-18T13:24:04Z",
      "updated_at": "2025-03-03T20:00:44Z",
      "closed_at": "2025-02-24T19:11:16Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/7/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/7",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/7",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:29.988144",
      "comments": [
        {
          "author": "coleam00",
          "body": "Could you please make a pull request for this? I'd appreciate it! ",
          "created_at": "2025-02-18T20:26:29Z"
        },
        {
          "author": "ruanjunmin",
          "body": "> Could you please make a pull request for this? I'd appreciate it!\n\nNo problem, I appreciate the opportunity!  The pull request is here: https://github.com/coleam00/local-ai-packaged/pull/8/commits/feb5b063576805627d3ec551656fe04cecc2fce7",
          "created_at": "2025-02-19T02:15:45Z"
        },
        {
          "author": "coleam00",
          "body": "Thanks @ruanjunmin! I followed up with a question there.",
          "created_at": "2025-02-24T19:11:16Z"
        },
        {
          "author": "FCPotesD",
          "body": "I'm having the same issue :(",
          "created_at": "2025-03-03T20:00:43Z"
        }
      ]
    },
    {
      "issue_number": 16,
      "title": "Not a issue, adding nocodb?",
      "body": "After some research on the web about open-source  tools, Nocodb is a kind of alternative to  Airtable and a little bit of Notion. It can be usefull and added to the package for a full free working stack workflow.\n\nhttps://github.com/nocodb/nocodb\n\nI found an interesting YT video about it i how he using it. Maling sinc with Nocodb, n8n and database (probably Supabase for us)\nhttps://youtu.be/DjbAtL3eswU",
      "state": "open",
      "author": "onigetoc",
      "author_type": "User",
      "created_at": "2025-02-22T09:30:25Z",
      "updated_at": "2025-03-03T17:35:23Z",
      "closed_at": null,
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/16/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/16",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/16",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:30.171629",
      "comments": [
        {
          "author": "coleam00",
          "body": "I appreciate the suggestion! I think NocoDB is fantastic - haven't used it much myself but I've seen some great implementations with it. I'll add it to the backlog for things to add to the stack in the project board!",
          "created_at": "2025-02-24T19:17:41Z"
        },
        {
          "author": "RepairYourTech",
          "body": "i just added it to mine what a great addition \n\n![Image](https://github.com/user-attachments/assets/0ff33779-baef-40cc-bdb4-959fa5359383)",
          "created_at": "2025-03-03T17:35:21Z"
        }
      ]
    },
    {
      "issue_number": 6,
      "title": "Container supabase-vector  Error",
      "body": "Please help, I have been receiving this error for days now, regardless of what I try.\n\nPS C:\\Users\\Dell\\OneDrive\\Desktop\\Local-Ai Package\\local-ai-packaged> python start_services.py --profile cpu\nSupabase repository already exists, updating...\nRunning: git pull\nremote: Enumerating objects: 167, done.\nremote: Counting objects: 100% (118/118), done.\nremote: Compressing objects: 100% (62/62), done.\nremote: Total 167 (delta 61), reused 77 (delta 51), pack-reused 49 (from 2)\nReceiving objects: 100% (167/167), 45.16 KiB | 633.00 KiB/s, done.\nResolving deltas: 100% (77/77), completed with 34 local objects.\nTotal 0 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\nFrom https://github.com/supabase/supabase\n   b7df65f71f..e1eaa9844c  master                -> origin/master\n + 2082ae7e7b...926cc40386 avallete/pgmeta-14-migrate-tests-for-rolessql -> origin/avallete/pgmeta-14-migrate-tests-for-rolessql  (forced update)\n * [new branch]            avallete/pgmeta-31-triggerssql -> origin/avallete/pgmeta-31-triggerssql\n * [new branch]            avallete/pgmeta-34-viewssql -> origin/avallete/pgmeta-34-viewssql\n * [new branch]            chore/adding-one-more-human -> origin/chore/adding-one-more-human\n   1c6614743c..4e23985480  chore/settings-ui     -> origin/chore/settings-ui\n   6288e50d45..6959af6463  feat/inline-editor-v2 -> origin/feat/inline-editor-v2\n + bb072562dd...c342beaeed gha/auto-update-mgmt-api-docs -> origin/gha/auto-update-mgmt-api-docs  (forced update)\nUpdating b7df65f71f..e1eaa9844c\nremote: Enumerating objects: 1, done.\nremote: Counting objects: 100% (1/1), done.\nremote: Total 1 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\nReceiving objects: 100% (1/1), 1002 bytes | 83.00 KiB/s, done.\nFast-forward\nremote: Enumerating objects: 34, done.\nremote: Counting objects: 100% (28/28), done.\nremote: Compressing objects: 100% (21/21), done.\nremote: Total 34 (delta 11), reused 8 (delta 7), pack-reused 6 (from 2)\nReceiving objects: 100% (34/34), 65.07 KiB | 2.03 MiB/s, done.\nResolving deltas: 100% (11/11), done.\n .../interfaces/QueryPerformance/QueryIndexes.tsx   |   9 +\n .../QueryPerformance/QueryPerformanceGrid.tsx      |   5 +-\n .../TableGridEditor/GridHeaderActions.tsx          |  18 ++\n .../SidePanelEditor/TableEditor/TableEditor.tsx    |  20 +-\n .../ProjectLayout/LayoutHeader/LayoutHeader.tsx    |  30 ++-\n .../layouts/ProjectLayout/ProjectLayout.tsx        |   6 -\n .../components/ui/AIAssistantPanel/AIAssistant.tsx |  27 ++-\n .../ui/AIAssistantPanel/MessageMarkdown.tsx        |   4 +-\n .../database/retrieve-index-from-select-query.ts   | 152 +++++++++-----\n .../data/subscriptions/project-addons-query.ts     |   3 +-\n apps/studio/lib/api/apiHelpers.ts                  |   3 +-\n apps/studio/lib/constants/index.ts                 |  14 +-\n apps/studio/pages/api/ai/sql/generate-v3.ts        | 230 +++++++++++----------\n apps/studio/pages/api/ai/sql/tools.ts              |  27 ++-\n .../api/platform/pg-meta/[ref]/query/index.ts      |  16 +-\n packages/common/telemetry-constants.ts             |  35 +++-\n tests/local-studio-tests/scripts/generate-env.js   |   2 +-\n turbo.json                                         |   3 +-\n 18 files changed, 377 insertions(+), 227 deletions(-)\nCopying .env in root to .env in supabase/docker...\nStopping and removing existing containers for the unified project 'localai'...\nRunning: docker compose -p localai -f docker-compose.yml -f supabase/docker/docker-compose.yml down\n[+] Running 14/14\n ‚úî Container supabase-kong                   Removed                                                               0.2s\n ‚úî Container supabase-pooler                 Removed                                                               0.5s\n ‚úî Container supabase-meta                   Removed                                                               0.5s\n ‚úî Container supabase-edge-functions         Removed                                                               0.6s\n ‚úî Container realtime-dev.supabase-realtime  Removed                                                               0.6s\n ‚úî Container supabase-studio                 Removed                                                               0.5s\n ‚úî Container supabase-storage                Removed                                                               0.5s\n ‚úî Container supabase-auth                   Removed                                                               0.6s\n ‚úî Container supabase-imgproxy               Removed                                                               1.0s\n ‚úî Container supabase-rest                   Removed                                                               0.3s\n ‚úî Container supabase-analytics              Removed                                                               0.3s\n ‚úî Container supabase-db                     Removed                                                               0.2s\n ‚úî Container supabase-vector                 Removed                                                               0.4s\n ‚úî Network localai_default                   Removed                                                               0.8s\nStarting Supabase services...\nRunning: docker compose -p localai -f supabase/docker/docker-compose.yml up -d\n[+] Running 14/14\n ‚úî Network localai_default                   Created                                                               0.3s\n ‚úî Container supabase-imgproxy               Started                                                               6.0s\n ‚úò Container supabase-vector                 Error                                                                 7.3s\n ‚úî Container supabase-db                     Created                                                               0.8s\n ‚úî Container supabase-analytics              Created                                                               0.5s\n ‚úî Container supabase-auth                   Created                                                               1.8s\n ‚úî Container supabase-pooler                 Created                                                               1.8s\n ‚úî Container supabase-studio                 Created                                                               1.8s\n ‚úî Container supabase-edge-functions         Created                                                               1.3s\n ‚úî Container realtime-dev.supabase-realtime  Created                                                               1.3s\n ‚úî Container supabase-kong                   Created                                                               1.8s\n ‚úî Container supabase-meta                   Created                                                               1.8s\n ‚úî Container supabase-rest                   Created                                                               1.1s\n ‚úî Container supabase-storage                Created                                                               1.0s\ndependency failed to start: container supabase-vector is unhealthy\nTraceback (most recent call last):\n  File \"C:\\Users\\Dell\\OneDrive\\Desktop\\Local-Ai Package\\local-ai-packaged\\start_services.py\", line 95, in <module>\n    main()\n    ~~~~^^\n  File \"C:\\Users\\Dell\\OneDrive\\Desktop\\Local-Ai Package\\local-ai-packaged\\start_services.py\", line 85, in main\n    start_supabase()\n    ~~~~~~~~~~~~~~^^\n  File \"C:\\Users\\Dell\\OneDrive\\Desktop\\Local-Ai Package\\local-ai-packaged\\start_services.py\", line 61, in start_supabase\n    run_command([\n    ~~~~~~~~~~~^^\n        \"docker\", \"compose\", \"-p\", \"localai\", \"-f\", \"supabase/docker/docker-compose.yml\", \"up\", \"-d\"\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ])\n    ^^\n  File \"C:\\Users\\Dell\\OneDrive\\Desktop\\Local-Ai Package\\local-ai-packaged\\start_services.py\", line 19, in run_command\n    subprocess.run(cmd, cwd=cwd, check=True)\n    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python313\\Lib\\subprocess.py\", line 577, in run\n    raise CalledProcessError(retcode, process.args,\n                             output=stdout, stderr=stderr)\nsubprocess.CalledProcessError: Command '['docker', 'compose', '-p', 'localai', '-f', 'supabase/docker/docker-compose.yml', 'up', '-d']' returned non-zero exit status 1.\nPS C:\\Users\\Dell\\OneDrive\\Desktop\\Local-Ai Package\\local-ai-packaged>\n",
      "state": "closed",
      "author": "jonnyallum",
      "author_type": "User",
      "created_at": "2025-02-18T10:12:55Z",
      "updated_at": "2025-03-01T23:11:03Z",
      "closed_at": "2025-03-01T20:26:14Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/6/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/6",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/6",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:30.360870",
      "comments": [
        {
          "author": "coleam00",
          "body": "Could you also share the logs from the Supabase-vector container? When it fails to start there will still be logs that could shed some light on the issue.",
          "created_at": "2025-02-18T20:25:17Z"
        },
        {
          "author": "coleam00",
          "body": "Also if using Docker Desktop, go into the settings and make sure you have the \"Expose daemon\" option checked!",
          "created_at": "2025-02-18T20:25:51Z"
        },
        {
          "author": "nic0711",
          "body": "I use Docker Desktop on MAC - these settings do not exist there.\n\nHowever, I still have the problem that I cannot access my Supabase Vector Store.\nSupabase uses BasicAuth for me... Have I set it up incorrectly?\n\nI can connect to Supabase from N8N if I use the access data in the URL - but then the Ve",
          "created_at": "2025-02-25T11:54:39Z"
        },
        {
          "author": "jonnyallum",
          "body": "Thank you, it was an issue with my software. great work ",
          "created_at": "2025-03-01T20:26:13Z"
        },
        {
          "author": "coleam00",
          "body": "Sounds good. I appreciate it!",
          "created_at": "2025-03-01T23:11:02Z"
        }
      ]
    },
    {
      "issue_number": 19,
      "title": "should add ngrok to it also",
      "body": "You should add ngrok to it also so it can be truly offline and all nodes still work. I am still trying to figure out how to add ngrok to this package.",
      "state": "open",
      "author": "drgsldr691",
      "author_type": "User",
      "created_at": "2025-02-24T19:05:27Z",
      "updated_at": "2025-02-24T21:23:32Z",
      "closed_at": null,
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/19/reactions",
        "total_count": 3,
        "+1": 3,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/19",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/19",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:31.907006",
      "comments": [
        {
          "author": "coleam00",
          "body": "Yes I definitely want to add ngrok! Feel free to submit a PR once you figure out how to do it!",
          "created_at": "2025-02-24T19:22:29Z"
        },
        {
          "author": "joelhans",
          "body": "Subscribed! I'm with ngrok and would love to help out in any way I can. Our [Docker container](https://ngrok.com/docs/using-ngrok-with/docker/) should roll into your existing `docker-compose.yml` with a few extra entries in `.env` for an authtoken, but let me know if you can't find a way through and",
          "created_at": "2025-02-24T21:23:30Z"
        }
      ]
    },
    {
      "issue_number": 12,
      "title": "Hailo 8 AI processor support for EDGE devices",
      "body": "Hello,\n\nI'm interested in running this local AI package on my Raspberry Pi 5, which is equipped with a Hailo-8 AI processor via a PCIe M.2 HAT. The Hailo-8 provides significant AI acceleration capabilities, and integrating support for it could enhance the project's performance on edge devices.\n\nIf I can successfully adapt the project to utilize the Hailo-8, I would be happy to submit a pull request to share the necessary modifications. (unless someone beats me to it)\n\nThank you for considering this enhancement.\n\nBest regards,\n\nKeith (rcpilotp51)",
      "state": "open",
      "author": "rcpilotp51",
      "author_type": "User",
      "created_at": "2025-02-20T14:09:27Z",
      "updated_at": "2025-02-24T19:14:41Z",
      "closed_at": null,
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/12/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/12",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/12",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:32.161502",
      "comments": [
        {
          "author": "coleam00",
          "body": "As long as it doesn't change a whole lot and could be just another profile for the Docker compose stack, I would absolutely love to see a PR for this!",
          "created_at": "2025-02-24T19:14:39Z"
        }
      ]
    },
    {
      "issue_number": 3,
      "title": "logflare env",
      "body": "im just going through the inistal setup and was looking at subabases self host docs about logflare and it says:\nRegardless of the backend chosen, the following environment variables must be set for the supabase/logflare docker image:\n\nLOGFLARE_SINGLE_TENANT=true: The feature flag for enabling single tenant mode for Logflare. Must be set to true\nLOGFLARE_SUPABASE_MODE=true: The feature flag for seeding Supabase-related data. Must be set to true\n\nbut i dont see those it he env, are they already in the compose for supabase?",
      "state": "closed",
      "author": "RepairYourTech",
      "author_type": "User",
      "created_at": "2025-02-17T05:44:24Z",
      "updated_at": "2025-02-24T19:05:25Z",
      "closed_at": "2025-02-24T19:05:25Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/3/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/coleam00/local-ai-packaged/issues/3",
      "api_url": "https://api.github.com/repos/coleam00/local-ai-packaged/issues/3",
      "repository": "coleam00/local-ai-packaged",
      "extraction_date": "2025-06-22T00:48:32.372258",
      "comments": [
        {
          "author": "coleam00",
          "body": "You know I was confused by this myself, might be the case that the documentation is out of date for the Supabase self hosting. I copied the entire .env.example from Supabase into mine so I shouldn't be missing anything!",
          "created_at": "2025-02-18T20:22:56Z"
        }
      ]
    }
  ]
}