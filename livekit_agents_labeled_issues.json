{
  "repository": "livekit/agents",
  "repository_info": {
    "repo": "livekit/agents",
    "stars": 6378,
    "language": "Python",
    "description": "A powerful framework for building realtime voice AI agents 🤖🎙️📹 ",
    "url": "https://github.com/livekit/agents",
    "topics": [
      "agents",
      "ai",
      "openai",
      "real-time",
      "video",
      "voice"
    ],
    "created_at": "2023-10-19T23:00:55Z",
    "updated_at": "2025-06-22T01:49:37Z",
    "search_query": "ai agent language:python stars:>3 -framework",
    "total_issues_estimate": 70,
    "labeled_issues_estimate": 53,
    "labeling_rate": 76.2,
    "sample_labeled": 16,
    "sample_total": 21,
    "has_issues": true,
    "repo_id": 707441527,
    "default_branch": "main",
    "size": 13438
  },
  "extraction_date": "2025-06-22T00:36:22.320436",
  "extraction_type": "LABELED_ISSUES_ONLY",
  "total_labeled_issues": 500,
  "issues": [
    {
      "issue_number": 2305,
      "title": "Azure STT fails with error: SpeechRecognition session stopped",
      "body": "On version 1.0.21\n\nWhen I set the STT in the agent session azure STT does not work, however deepgram works\n\n```python\nsession = AgentSession[IntakeSessionState](\n            allow_interruptions=True,\n            vad=ctx.proc.userdata[\"vad\"],\n            turn_detection=EnglishModel(),\n            stt=azure.STT(),\n            #stt=deepgram.STT(),\n            llm=openai.LLM(model=\"gpt-4o\"),\n            tts=azure.TTS(voice=azure_speech_tts_voice),\n            #tts=deepgram.TTS(),\n            userdata=session_state\n        )\n```\n\nwith azure.STT configured on the session I get this error\n\n```\nsite-packages\\livekit\\plugins\\azure\\stt.py\", line 225, in _run\n    raise APIConnectionError(\"SpeechRecognition session stopped\")\nlivekit.agents._exceptions.APIConnectionError: SpeechRecognition session stopped\n```\n\nTo get the STT working I had to set in on the agent constructor\n\n```\nclass OutboundCallerAgent(Agent):\n    def __init__(\n            self,\n            job_context: JobContext,\n            instructions: str) -> None:\n        self.job_context = job_context\n        super().__init__(\n            instructions=instructions,\n            stt=azure.STT(),\n            llm=openai.LLM(model=\"gpt-4o\"),\n            tts=azure.TTS(voice=azure_speech_tts_voice),\n        )\n```",
      "state": "open",
      "author": "notauserx",
      "author_type": "User",
      "created_at": "2025-05-16T05:10:54Z",
      "updated_at": "2025-06-21T17:48:03Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2305/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2305",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2305",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:12.947962",
      "comments": [
        {
          "author": "longcw",
          "body": "Can you double check your azure STT configuration, connection and keys are correctly set? This error usually happens when the STT failed to start with configuration issue.",
          "created_at": "2025-05-16T08:29:01Z"
        },
        {
          "author": "notauserx",
          "body": "The configuration settings are correct, the same configuration works when I use it on the agent, but fails when I set it on Agent Session.\n\nUpdate: Now getting the same error when I set stt on agent as well. However, azure.TTS works, we are using the azure speech service in other services where it's",
          "created_at": "2025-05-18T04:57:10Z"
        },
        {
          "author": "sunghyunjun",
          "body": "Not sure if this helps, but just wanted to share what worked for me.\n\nI had the same error, and in my case, it was caused by manually changing stt._config. It worked with Deepgram (using stt._opt.language), but Azure needs stt._config to be a list.\n\nIf it’s not, the session may stop unexpectedly. Th",
          "created_at": "2025-06-21T17:48:03Z"
        }
      ]
    },
    {
      "issue_number": 2427,
      "title": "Beyond Presence Avatar does not speak or hear when first loaded",
      "body": "When first starting Beyond Presence load time takes a long time and avatar doesnt speak or hear. Closing and restarting the avatar load time reduces and avatar works without issue. We have contacted Beyond Presence and they have indicated no issues on their side. ",
      "state": "open",
      "author": "davidlpatten",
      "author_type": "User",
      "created_at": "2025-05-28T11:13:23Z",
      "updated_at": "2025-06-21T10:26:14Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2427/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2427",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2427",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:13.189397",
      "comments": [
        {
          "author": "ChenghaoMou",
          "body": "Maybe @niqodea can help.\n\nI have tested all avatar plugins (Tavus, bithuman, and bey), bey is the only one I did not get it to speak (I can see the avatar, but nothing else). I just thought I ran out of the 1 minute trial before realizing it. But I can't debug it without paying a subscription first ",
          "created_at": "2025-05-28T15:03:25Z"
        },
        {
          "author": "niqodea",
          "body": "Hi @davidlpatten, @ChenghaoMou! Can you share your test code here? I will look into the issue you are having. Also feel free to share any private information by sending an email to <nicola@beyondpresence.ai>.\n\nIf you encounter other issues with Beyond Presence in the future, I suggest to also post a",
          "created_at": "2025-05-29T17:28:14Z"
        },
        {
          "author": "davidzhao",
          "body": "@niqodea could this be some sort of race condition on the server integration side? maybe there are timing issues preventing the avatar server from receiving audio that the agent is trying to send?",
          "created_at": "2025-05-31T06:34:35Z"
        },
        {
          "author": "niqodea",
          "body": "@davidzhao That’s possible—having some example scripts or logs would definitely help. It sounds like there are multiple issues: from what David described on Slack, the problem seems to be slow avatar startup, while Chenghao hasn’t been able to get the avatar to speak at all.\n\n@ChenghaoMou Just to co",
          "created_at": "2025-06-03T08:20:17Z"
        },
        {
          "author": "niqodea",
          "body": "Hi @ChenghaoMou!\n\nI believe I found the issue. The [LiveKit example](https://github.com/livekit/agents/blob/234ef9031ea78ed7db7bf9fa160d0bee700977fd/examples/avatar_agents/bey/agent_worker.py#L26-L29) doesn't mute the local agent, unlike [ours](https://github.com/bey-dev/bey-examples/blob/e24bc1dffd",
          "created_at": "2025-06-21T10:26:14Z"
        }
      ]
    },
    {
      "issue_number": 2659,
      "title": "Usage metric not collected",
      "body": "When breaking in the middle of a chat, we dont collect LLM metrics\n```python\n    async def llm_node(\n        self,\n        chat_ctx: ChatContext,\n        tools: list[FunctionTool | RawFunctionTool],\n        model_settings: ModelSettings,\n    ) -> AsyncGenerator[ChatChunk | str, None]:\n        tool_choice = model_settings.tool_choice if model_settings else NOT_GIVEN\n\n        last_response = \"\"\n\n        async with self.session.llm.chat(chat_ctx=chat_ctx, tools=tools, tool_choice=tool_choice) as stream:\n            async for chunk in stream:\n                if \"hello\" in last_response:\n                    yield \"Hello! How can I assist you today?\"\n                    break\n\n                yield chunk\n                last_response += chunk.delta.content\n```\nThe usage code never runs\n``` python\n                        chunk = llm.ChatChunk(\n                            id=chunk.id,\n                            usage=llm.CompletionUsage(\n                                completion_tokens=chunk.usage.completion_tokens,\n                                prompt_tokens=chunk.usage.prompt_tokens,\n                                prompt_cached_tokens=cached_tokens or 0,\n                                total_tokens=chunk.usage.total_tokens,\n                            ),\n                        )\n                        self._event_ch.send_nowait(chunk)\n```\n\n    \"livekit>=1.0.8\",\n    \"livekit-agents==1.0.23\",\n    \"livekit-plugins-openai==1.0.23\",",
      "state": "closed",
      "author": "sarmientoF",
      "author_type": "User",
      "created_at": "2025-06-20T08:58:29Z",
      "updated_at": "2025-06-21T07:17:21Z",
      "closed_at": "2025-06-21T07:17:21Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2659/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2659",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2659",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:13.424091",
      "comments": [
        {
          "author": "davidzhao",
          "body": "this is expected.. you skipped the usage tokens downstream by breaking out of that loop. \n\nllm_node needs to yield these usage tokens in order for them to be counted.",
          "created_at": "2025-06-21T07:17:21Z"
        }
      ]
    },
    {
      "issue_number": 1953,
      "title": "Livekit multimodal agent gemini skipping function call and hallucinating",
      "body": "We are experiencing hallucinations.\nSome times it working perfectly but sometimes it's skipping function calls and hallucinating.\nIs there any way that we can make it not hallucinate.\n",
      "state": "open",
      "author": "BhavaniMallapragada",
      "author_type": "User",
      "created_at": "2025-04-10T04:27:07Z",
      "updated_at": "2025-06-21T06:15:14Z",
      "closed_at": null,
      "labels": [
        "bug",
        "model"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 23,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1953/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1953",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1953",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:13.687445",
      "comments": []
    },
    {
      "issue_number": 2666,
      "title": "After updating livekit-plugins-google to 1.1.2 there's Unclosed client session error message each time google's llm is used",
      "body": "I have updated livekit-plugins-google to 1.1.2.\nMy setup is\n```\n llm=google.LLM(\n            model=\"gemini-2.5-flash-preview-05-20\",\n            temperature=1.0,\n        ),\n```\n\nEvery time llm is called I see these errors:\n```\n2025-06-20 12:55:14,193 - ERROR asyncio - Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x11a0b5e50> {\"pid\": 90452, \"job_id\": \"AJ_h5xQ54vsHHFz\"}\n2025-06-20 12:55:14,194 - ERROR asyncio - Unclosed connector\nconnections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x11a0c2ff0>, 974158.686853523)])']\nconnector: <aiohttp.connector.TCPConnector object at 0x11a0b60d0> {\"pid\": 90452, \"job_id\": \"AJ_h5xQ54vsHHFz\"}\n```\nThe llm returns response and works fine, though.\n\nWhen I switch llm to OpenAI, the errors don't show up.\nI am using livekit-agents = \">=1.1.2\"",
      "state": "open",
      "author": "kirylkliushkin",
      "author_type": "User",
      "created_at": "2025-06-20T19:59:21Z",
      "updated_at": "2025-06-21T01:02:49Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2666/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2666",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2666",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:13.687463",
      "comments": [
        {
          "author": "longcw",
          "body": "It seems the error was introduced from `google-genai` v1.21, when using v1.20 it works fine.",
          "created_at": "2025-06-21T01:02:49Z"
        }
      ]
    },
    {
      "issue_number": 1172,
      "title": "How to await a tools feedback message?",
      "body": "In the examples for the voice-pipeline-agent, the function_calling_weather.py has an example on how to add tools to the agent. In line 43 it executes a say() function to give feedback to the user telling him that the tool is going to be used [await call_ctx.agent.say(message)] This function is not awaited and the agent returns the response before delivering the feedback message. Does anyone now how to actually make the function await this call and make it happen before the rest of the function is executed?\r\n",
      "state": "closed",
      "author": "lschnoller",
      "author_type": "User",
      "created_at": "2024-12-04T09:05:09Z",
      "updated_at": "2025-06-20T14:18:09Z",
      "closed_at": "2025-06-20T14:18:09Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1172/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1172",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1172",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:13.939301",
      "comments": [
        {
          "author": "davidzhao",
          "body": "I'm not sure what you mean.. could you give an example for`This function is not awaited and the agent returns the response before delivering the feedback message.`",
          "created_at": "2024-12-05T09:05:20Z"
        },
        {
          "author": "m-aliabbas",
          "body": "It first completes the function call and its associated sound, then play the filler sound. But instead it should play the filler sound first. \r\n\r\n`class AssistantFnc(llm.FunctionContext):\r\n    \"\"\"\r\n    The class defines a set of LLM functions that the assistant can execute.\r\n    \"\"\"\r\n\r\n    @llm.ai_c",
          "created_at": "2024-12-10T16:43:54Z"
        },
        {
          "author": "LintonAchmad",
          "body": "@m-aliabbas how to add filler messages when using the `MultimodalAgent`?",
          "created_at": "2024-12-19T17:03:11Z"
        }
      ]
    },
    {
      "issue_number": 1147,
      "title": "Please add a client notification to the agent termination event",
      "body": "Currently there is no way from the cli client code to know when the agent received SIGTERM or SIGINT and is in the graceful shutdown state. It would be useful to have a possibility for it to emit an event or provide a possibility to assign a callback, so one could execute a custom code when that happens. \r\n\r\nRelated to https://github.com/livekit/livekit-helm/issues/116",
      "state": "closed",
      "author": "mykola-mokhnach-parloa",
      "author_type": "User",
      "created_at": "2024-11-28T11:49:03Z",
      "updated_at": "2025-06-20T14:18:09Z",
      "closed_at": "2025-06-20T14:18:09Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1147/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1147",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1147",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:14.149098",
      "comments": [
        {
          "author": "peter-assort",
          "body": "+1 that would be nice! \r\n\r\nFWIW you can do \"cleanup\" on the \"job/worker\" level using :\r\n```\r\n            # https://docs.livekit.io/agents/build/session/#post-processing-and-cleanup\r\n            # Just add some logging when shutdown is initiated\r\n            async def my_shutdown_hook() -> None:\r\n   ",
          "created_at": "2024-12-19T17:39:32Z"
        }
      ]
    },
    {
      "issue_number": 1724,
      "title": "Integration with Custom TTS in LiveKit",
      "body": "I want to integrate my own TTS model with LiveKit for real-time audio streaming. Currently, LiveKit relies on external TTS services, but I need the flexibility to use my own self-hosted or custom-trained TTS model (e.g., Coqui TTS, Piper, or VITS).\n\n**Expected Behavior:**\nLiveKit should allow custom TTS integration by accepting synthesized audio from an external source.\nThe audio should be streamed in real-time to connected participants.\nLow-latency processing to ensure smooth speech delivery.\n\n**Current Behavior:**\nNo direct support for integrating custom TTS models.\nUsers must rely on third-party TTS services, which may not always meet specific requirements.\n\n**Proposed Solution:**\nProvide an API or plugin system to inject custom TTS-generated audio into LiveKit’s media pipeline.\nSupport WebRTC-compatible audio formats to ensure seamless playback.\nOption to configure and switch between different TTS sources dynamically.\n\n**Use Case:**\nI’m working on a real-time AI voice assistant and need to generate speech dynamically using my own TTS model instead of relying on cloud-based services.\n",
      "state": "open",
      "author": "narendra-bluebash",
      "author_type": "User",
      "created_at": "2025-03-25T05:13:56Z",
      "updated_at": "2025-06-20T14:11:45Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1724/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1724",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1724",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:14.408891",
      "comments": [
        {
          "author": "AkashMaher",
          "body": "Create your custom class inherited from livekit.agents.tts.TTS\n\ncreate a function in the class synthesize(self, text) and return livekit.agents.tts.ChunkedStream\n\nany ques, ask me",
          "created_at": "2025-03-25T07:03:18Z"
        },
        {
          "author": "narendra-bluebash",
          "body": "Can you provide some code to implement text-to-speech (TTS)? : https://github.com/SesameAILabs/csm",
          "created_at": "2025-03-25T08:08:17Z"
        },
        {
          "author": "ChenghaoMou",
          "body": "Similar requests/questions e.g. #962 #1687\n\nI think, the difference here is that Livekit integration is primarily with TTS services/vendors, not TTS models. One can already easily create a new TTS plugin with service endpoints, be it REST or websocket. If you are looking for solutions to turn those ",
          "created_at": "2025-03-25T16:51:09Z"
        },
        {
          "author": "savi727",
          "body": "Has anyone able to integrate custom TTS or STT with Livekit Agents?  I also have a similar requirement",
          "created_at": "2025-05-20T06:01:24Z"
        },
        {
          "author": "aspirant2018",
          "body": "Hey, has any one managed to integrate Coqui tts with livekit.\n\n",
          "created_at": "2025-06-20T14:11:45Z"
        }
      ]
    },
    {
      "issue_number": 2644,
      "title": "Worker is logging `WARNING livekit.agents - _SegmentSynchronizerImpl.playback_finished called before text/audio input is done` every turn while using Gemini Realtime model",
      "body": "<!--\nHello! Thanks for taking the time to ask a question.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already asked this question.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n\nFeel free to join us in the #agents channel on our Slack, and ask your question\nthere to get quicker help from us and the community:\n\nhttps://livekit.io/join-slack\n-->\n\nI'm seeing this Warning every turn of speech when using any of the Gemini Live models, is it safe to ignore this Warning? \n",
      "state": "closed",
      "author": "td2thinh",
      "author_type": "User",
      "created_at": "2025-06-19T08:51:36Z",
      "updated_at": "2025-06-20T13:25:06Z",
      "closed_at": "2025-06-20T13:25:06Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 11,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2644/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2644",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2644",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:14.667769",
      "comments": [
        {
          "author": "longcw",
          "body": "Could you try the latest version of agents (1.1.1), it should be fixed.",
          "created_at": "2025-06-19T08:53:47Z"
        },
        {
          "author": "td2thinh",
          "body": "Hello, `pip freeze | grep livekit` shows: \n```\nlivekit==1.0.9\nlivekit-agents==1.1.1\nlivekit-api==1.0.2\nlivekit-plugins-google==1.1.1\nlivekit-protocol==1.0.3\n```\nI'm on the latest version already I think. If it helps, the model is `gemini-2.5-flash-preview-native-audio-dialog`.",
          "created_at": "2025-06-19T09:09:20Z"
        },
        {
          "author": "longcw",
          "body": "I cannot reproduce it with the latest version and this model, can you share an example?",
          "created_at": "2025-06-19T10:51:52Z"
        },
        {
          "author": "td2thinh",
          "body": "> I cannot reproduce it with the latest version and this model, can you share an example?\n\nHmm, I started the session in the console using `python main.py console` though. As for testing with a livekit room, I used `python main.py start`, I will try `dev` command to see if it outputs this WARNING in",
          "created_at": "2025-06-19T11:58:07Z"
        },
        {
          "author": "td2thinh",
          "body": "@longcw I can confirm that this WARNING is still logged after every speech turn of the LLM when I launched the worker using `python main.py dev`.",
          "created_at": "2025-06-19T12:21:53Z"
        }
      ]
    },
    {
      "issue_number": 2642,
      "title": "User's audio/transcript overflows onto the next turn and skips that next user turn entirely",
      "body": "I'm using agent version 1.0.23 and my configurations are as follows\n```\nvad=silero.VAD.load(min_silence_duration=2.0)\nturn_detection=\"vad\"\nmin_endpointing_delay=2.0\nallow_interruptions=False\nmax_endpointing_delay=5.0\n```\nThe issue is when the user's turn starts, there's a slight delay in transcript and it soon catches up, but if the user says something then takes a pause and then says another sentence, this transcript after the pause is cut off from this turn and the turn is changed since there was a silence of 2 seconds in between. \nInstead of that extra cut off sentence being discarded or flushed, this extra sentence is overflowing in the next user turn and in this turn the user does not get a chance to speak itself. It takes the overflow audio as input and immediately fires the on_user_turn_completed and generates the next ai transcript. \n\nCan you please help.\n ",
      "state": "open",
      "author": "devb-enp",
      "author_type": "User",
      "created_at": "2025-06-19T07:59:55Z",
      "updated_at": "2025-06-20T09:22:23Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2642/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2642",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2642",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:14.921090",
      "comments": [
        {
          "author": "longcw",
          "body": "Maybe you can try the turn detector model https://docs.livekit.io/agents/build/turns/turn-detector/",
          "created_at": "2025-06-19T08:44:18Z"
        },
        {
          "author": "devb-enp",
          "body": "@longcw I've just tried it using the turn detector model too but i'm still able to replicate this issue. \nIt'll make it a bit better by working along with max_endpointing_delay if the sentence before the silence is not a complete one. But this would just be masking the problem making it less rare in",
          "created_at": "2025-06-19T09:29:36Z"
        },
        {
          "author": "devb-enp",
          "body": "@longcw This issue got fixed when i added `self.session.clear_user_turn()` inside `on_user_turn_completed` function. But ideally in case when `allow_interruptions` is False, this should be called internally when the turn is changed from user to AI",
          "created_at": "2025-06-20T09:06:56Z"
        },
        {
          "author": "longcw",
          "body": "oh I see your original issue now, it's because the `allow_interruption=False` so the user transcripts came later cannot interrupt the agent and will be take as input of the next turn. `clear_user_turn` could fix the issue, I'll think about if we should do that internally.",
          "created_at": "2025-06-20T09:13:41Z"
        },
        {
          "author": "devb-enp",
          "body": "Yes and the next turn is skipped entirely without user ever getting a chance to speak itself. \nThe overflow content itself is taken as an input for that turn and the agent generates a reply based on just that. That behaviour itself was very unexpected.",
          "created_at": "2025-06-20T09:22:23Z"
        }
      ]
    },
    {
      "issue_number": 1897,
      "title": "SendText on JS SDK with Python Agent does not work as expected",
      "body": "The documentation suggests send a Text Stream message using sendText() allows to input message to Agent via text. However, this does not work in VoicePipeline or Realtime Model.\n\nStep to reproduce:\nFrontend:\n`await room.localParticipant.sendText(\"hello\", {topic: 'lk.chat'});\n`\nResult:\n`2025-04-05 21:43:56 2025-04-05 16:13:56,343 - INFO root - ignoring text stream with topic 'lk.chat', no callback attached {\"pid\": 174, \"job_id\": \"AJ_6W8evqDQD6pi\"}`\n\nThis confirms the message is send and received but the expected behaviour of inputing to the model does not happen.\n\nThere is a way around in realtime model by sending a message on another topic and then explicitly calling\n\n```\n  await session.conversation.item.create(\n            llm.ChatMessage(\n                role=\"user\",\n                content=text,\n            )\n        )\n```\n\nBut the VoicePipeline doesn't seem to have a workaround and the expected behaviour also does not work.",
      "state": "closed",
      "author": "vnandan",
      "author_type": "User",
      "created_at": "2025-04-05T16:23:27Z",
      "updated_at": "2025-06-20T09:05:10Z",
      "closed_at": "2025-06-20T09:03:27Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1897/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1897",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1897",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:15.140830",
      "comments": [
        {
          "author": "davidzhao",
          "body": "this is now handled automatically in v1, example: https://github.com/livekit/agents/blob/main/examples/other/text_only.py#L41\n\npreviously, you would have to [register for a text listener](https://docs.livekit.io/home/client/data/text-streams/#handling-incoming-streams) yourself, and append it to the",
          "created_at": "2025-04-05T17:45:18Z"
        }
      ]
    },
    {
      "issue_number": 2656,
      "title": "ModuleNotFoundError: No module named 'livekit.agents.voice_assistant'",
      "body": "Hi,\nI am trying to use the VoiceAssistant class as shown in some examples, but I get the following error when running my code:\nModuleNotFoundError: No module named 'livekit.agents.voice_assistant'\n\nI have installed the livekit package using pip, and my import statement is:\n\n\nfrom livekit.agents.voice_assistant import VoiceAssistant\n\n\nfrom livekit.agents.voice_assistant import VoiceAssistant\n\nCould you please clarify:\nIs voice_assistant part of the current public release of the livekit Python SDK?\nIf not, is there an alternative or a recommended way to implement a voice assistant with the current SDK?\nIf it is available, which version should I install, or is there an extra step required?\nThank you!",
      "state": "closed",
      "author": "Aadi-stack",
      "author_type": "User",
      "created_at": "2025-06-20T05:58:48Z",
      "updated_at": "2025-06-20T07:26:03Z",
      "closed_at": "2025-06-20T06:01:13Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2656/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2656",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2656",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:15.387176",
      "comments": [
        {
          "author": "davidzhao",
          "body": "could you share where you are finding these examples? they are for an older version of livekit agents. \n\nthe current version changed a [few things](https://docs.livekit.io/agents/start/v0-migration/). you can find the updated examples [here](https://github.com/livekit/agents/tree/main/examples/voice",
          "created_at": "2025-06-20T06:01:13Z"
        },
        {
          "author": "Aadi-stack",
          "body": "Thank you for pointing that out! The examples I referenced earlier were based on older documentation and community code, but LiveKit Agents has recently changed quite a bit.\nFor the most up-to-date examples and best practices:\nThe official, current Python agent examples are now maintained at the liv",
          "created_at": "2025-06-20T07:26:02Z"
        }
      ]
    },
    {
      "issue_number": 2554,
      "title": "Blank \"participantInfo.identity\" in text streams \"lk.transcription\" if Agent is hidden",
      "body": "This is an issue reproducible with the very simple example [transcriber.py](https://github.com/livekit-examples/python-agents-examples/blob/main/pipeline-stt/transcriber.py), using the latest version of livekit agents ([1.1.0](https://github.com/livekit/agents/releases/tag/livekit-agents%401.1.0)).\n\nIf you modify the `WorkerOptions` to include the `hidden` property in the `WorkerPermissions` object like this:\n\n```python\nif __name__ == \"__main__\":\n    cli.run_app(WorkerOptions(\n            entrypoint_fnc=entrypoint,\n            permissions=WorkerPermissions(hidden=True)\n     ))\n```\n\nThen any frontend trying to receive the transcription text stream exactly as documented [here](https://docs.livekit.io/agents/build/text/#frontend-integration) will receive the `participantInfo.identity` as an empty string. In other words: this...\n\n```javascript\nroom.registerTextStreamHandler('lk.transcription', async (reader, participantInfo) => {\n  const message = await reader.readAll();\n  if (reader.info.attributes['lk.transcribed_track_id']) {\n    console.log(`New transcription from ${participantInfo.identity}: ${message}`);\n  } else {\n    console.log(`New message from ${participantInfo.identity}: ${message}`);\n  }\n});\n```\n\n...will print...\n\n```console\nNew transcription from : Good morning.\n```\n\nI think this is a bug, because why should the `hidden` property of the `WorkerPermissions` affect whether the transcription events arrive with a valid participant identity value or not? This `participantInfo.identity` belongs to the participant owning the track that generated the transcription event. Nothing related to the Agent participant itself, whether it is hidden or not.",
      "state": "closed",
      "author": "pabloFuente",
      "author_type": "User",
      "created_at": "2025-06-10T15:03:09Z",
      "updated_at": "2025-06-20T05:58:32Z",
      "closed_at": "2025-06-20T05:58:32Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 15,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2554/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2554",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2554",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:15.639169",
      "comments": [
        {
          "author": "longcw",
          "body": "I can reproduce it, and confirmed that the identity was set when sending the text stream. It seems a bug in the server or rust sdk? cc @theomonnom @lukasIO ",
          "created_at": "2025-06-11T02:24:20Z"
        },
        {
          "author": "davidzhao",
          "body": "this is the expected behavior.. if the agent is hidden.. no other participant could know who they are.. so from their perspective, they won't know who sent the message",
          "created_at": "2025-06-11T06:10:50Z"
        },
        {
          "author": "longcw",
          "body": "I think the question was the agent is hidden but the identity of user transcription is blank, because the user transcription was also sent by the agent, with a `sender_identity=user_identity`.\n\nBut I see the issue, the `sender_identity` is hidden even it's for the user transcription in this case.",
          "created_at": "2025-06-11T06:14:27Z"
        },
        {
          "author": "davidzhao",
          "body": "I think I understand now.. so it seems that this is an issue on the server side?",
          "created_at": "2025-06-11T06:21:23Z"
        },
        {
          "author": "pabloFuente",
          "body": "Yes, definitely a problem in livekit-server. I have been debugging the issue and the problem is quite simple. In [**participant.go**](https://github.com/livekit/livekit/blob/e98fb94fd2563c0740d0bca957aca217ffaaddf3/pkg/rtc/participant.go):\n\n[Here](https://github.com/livekit/livekit/blob/e98fb94fd256",
          "created_at": "2025-06-11T09:43:23Z"
        }
      ]
    },
    {
      "issue_number": 2605,
      "title": "How to properly update chat context for realtime models",
      "body": "Hi,\nWe are building a voice based agent using the Gemini Flash 2.5 native audio dialog (realtime) model on livekit. Based on user’s query we fetch products from the database. We want to pass the product details to the agent so that they don't hallucinate on the product details and can work on providing responses based on product features, such as the price or brand.\nWe tried appending these details in the chat context (using update_chat_ctx method with the system and also with the assistant roles) and have handled this in the prompt as well. But this does not seem to be working - the agent still hallucinates. What am I missing here? It works only when we pass the product details through the tool output. Does update_chat_ctx not work for real time models and what would be the right way to do this for real time models?\n\nPackage Versions:\nlivekit==1.0.8\nlivekit-agents==1.0.23\nlivekit-api==1.0.2\nlivekit-plugins-deepgram==1.0.23\nlivekit-plugins-google==1.0.23\nlivekit-plugins-noise-cancellation==0.2.4\nlivekit-plugins-openai==1.0.23\nlivekit-plugins-silero==1.0.23\nlivekit-plugins-turn-detector==1.0.23\nlivekit-protocol==1.0.3\n",
      "state": "open",
      "author": "tusheet-geoiq",
      "author_type": "User",
      "created_at": "2025-06-15T16:32:41Z",
      "updated_at": "2025-06-20T02:26:57Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2605/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2605",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2605",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:15.933539",
      "comments": [
        {
          "author": "longcw",
          "body": "`update_chat_ctx` should work for the realtime model, but gemini doesn't support adding system messages to the chat context. You can try `update_instructions` to update the instructions as well.",
          "created_at": "2025-06-18T02:19:46Z"
        },
        {
          "author": "td2thinh",
          "body": "@tusheet-geoiq  I hope you don't mind me asking but how is function calling working out for you? We've been having trouble getting it to work, the model executes declared tools like 5% of the time only, sometimes it even output the audio of the tool's description instead of execute it.",
          "created_at": "2025-06-19T08:46:54Z"
        },
        {
          "author": "davidzhao",
          "body": "Gemini 2.5 is still beta, function calling is not supported yet in full duplex mode (audio in -> audio out)\n\nYou can stick with gemini flash 2.0 for now. function calling is more reliable there",
          "created_at": "2025-06-20T02:26:57Z"
        }
      ]
    },
    {
      "issue_number": 2645,
      "title": "STT Fallback on Gladia does not work",
      "body": "Hello,\n\nThe STT Fallback does not work as expected.\nSetting `attempt_timeout=0.01` to make Gladia timeout does not trigger the fallbacks, the other providers are never tried.\n\n```python\nstt = STTFallbackAdapter(\n    stt=[gladia_stt, stt_deepgram, whisper_stt],\n    attempt_timeout=0.01,\n    max_retry_per_stt=0,\n    retry_interval=0\n)\n```\n\nErrors:\n```\n2025-06-19 11:02:25,134 - ERROR livekit.plugins.gladia - Error in speech stream: Connection timeout to host https://api.gladia.io/v2/live\nTraceback (most recent call last):\n  File \"/Users/cyprien/miniconda3/envs/lk-dev/lib/python3.12/site-packages/aiohttp/connector.py\", line 1248, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/cyprien/miniconda3/envs/lk-dev/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/cyprien/miniconda3/envs/lk-dev/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File \"/Users/cyprien/miniconda3/envs/lk-dev/lib/python3.12/asyncio/selector_events.py\", line 651, in sock_connect\n    return await fut\n           ^^^^^^^^^\nasyncio.exceptions.CancelledError\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/cyprien/miniconda3/envs/lk-dev/lib/python3.12/site-packages/aiohttp/client.py\", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/cyprien/miniconda3/envs/lk-dev/lib/python3.12/site-packages/aiohttp/connector.py\", line 622, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/cyprien/miniconda3/envs/lk-dev/lib/python3.12/site-packages/aiohttp/connector.py\", line 1189, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/cyprien/miniconda3/envs/lk-dev/lib/python3.12/site-packages/aiohttp/connector.py\", line 1561, in _create_direct_connection\n    raise last_exc\n  File \"/Users/cyprien/miniconda3/envs/lk-dev/lib/python3.12/site-packages/aiohttp/connector.py\", line 1530, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/cyprien/miniconda3/envs/lk-dev/lib/python3.12/site-packages/aiohttp/connector.py\", line 1245, in _wrap_create_connection\n    async with ceil_timeout(\n               ^^^^^^^^^^^^^\n  File \"/Users/cyprien/miniconda3/envs/lk-dev/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n    raise TimeoutError from exc_val\nTimeoutError\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/cyprien/Documents/bee2link/agents/livekit-plugins/livekit-plugins-gladia/livekit/plugins/gladia/stt.py\", line 640, in _run\n    session_info = await self._init_live_session()\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/cyprien/Documents/bee2link/agents/livekit-plugins/livekit-plugins-gladia/livekit/plugins/gladia/stt.py\", line 730, in _init_live_session\n    raise e\n  File \"/Users/cyprien/Documents/bee2link/agents/livekit-plugins/livekit-plugins-gladia/livekit/plugins/gladia/stt.py\", line 716, in _init_live_session\n    async with self._session.post(\n               ^^^^^^^^^^^^^^^^^^^\n  File \"/Users/cyprien/miniconda3/envs/lk-dev/lib/python3.12/site-packages/aiohttp/client.py\", line 1482, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File \"/Users/cyprien/miniconda3/envs/lk-dev/lib/python3.12/site-packages/aiohttp/client.py\", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/Users/cyprien/miniconda3/envs/lk-dev/lib/python3.12/site-packages/aiohttp/client.py\", line 729, in _connect_and_send_request\n    raise ConnectionTimeoutError(\naiohttp.client_exceptions.ConnectionTimeoutError: Connection timeout to host https://api.gladia.io/v2/live {\"pid\": 62068, \"job_id\": \"AJ_rFSB7f53K5aK\"}\n```",
      "state": "closed",
      "author": "CyprienRicqueB2L",
      "author_type": "User",
      "created_at": "2025-06-19T09:13:20Z",
      "updated_at": "2025-06-20T02:12:21Z",
      "closed_at": "2025-06-20T02:12:21Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2645/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2645",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2645",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:16.176842",
      "comments": [
        {
          "author": "longcw",
          "body": "Does this only happen to Gladia STT or for all others? It seems that it's the issue in gladia stt plugin, id doesn't raise the error but just sleep and retry https://github.com/livekit/agents/blob/livekit-agents@1.1.0/livekit-plugins/livekit-plugins-gladia/livekit/plugins/gladia/stt.py#L675-L688.\n\n`",
          "created_at": "2025-06-19T11:08:46Z"
        }
      ]
    },
    {
      "issue_number": 2650,
      "title": "v1.1.0 breaks the openai.realtime.RealtimeModel.with_azure",
      "body": "openai.realtime.RealtimeModel.with_azure returns Unknown parameter: 'session.tracing' error on connection, probably as a consequence of https://github.com/livekit/agents/pull/2546\nIn addition, \"conversation_item_added\" event is not fired any more for the user messages with openai.realtime.RealtimeModel.with_azure.\nReverting to v1.0.23 resolves both issues.\n",
      "state": "closed",
      "author": "NikolaMorena",
      "author_type": "User",
      "created_at": "2025-06-19T14:56:50Z",
      "updated_at": "2025-06-20T01:59:46Z",
      "closed_at": "2025-06-20T01:59:46Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2650/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2650",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2650",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:16.446714",
      "comments": [
        {
          "author": "DeninSiby",
          "body": "I am not able to get any User transcripts while using the openai realtime model with Azure, @NikolaMorena. Can you confirm even if you are facing the same issue?",
          "created_at": "2025-06-19T19:39:27Z"
        }
      ]
    },
    {
      "issue_number": 2619,
      "title": "Incomplete implementation of hume plugin in version ~1.1.0",
      "body": "I wanted to upgrade my livekit agent to 1.1.0 because in version 1.0.23 we faced a problem with AssemblyAI format_turns which got fixed in 1.1.0 but in this version we're facing issues with hume plugin as well as it's custom voice implementation.\n\nThe only way to pass the voice is to pass utterance_options and the text is a mandatory field. Even when passing the text as an empty string, it throws some error regarding the stream.\n\nI think the hume tts is still incomplete for version ~1.1.0",
      "state": "closed",
      "author": "devb-enp",
      "author_type": "User",
      "created_at": "2025-06-17T07:11:25Z",
      "updated_at": "2025-06-19T21:10:03Z",
      "closed_at": "2025-06-19T21:10:03Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2619/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "bcherry"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2619",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2619",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:16.668355",
      "comments": [
        {
          "author": "devb-enp",
          "body": "@zgreathouse can you look at the custom voice implementation in hume plugin?",
          "created_at": "2025-06-18T02:20:11Z"
        }
      ]
    },
    {
      "issue_number": 1259,
      "title": "Incorrect transcription on failing audio capture",
      "body": "Hi,\r\nI want to report that when this error occurs: https://github.com/livekit/agents/issues/863 , the WHOLE audio transcription is committed as agent speech, but NONE of that speech has been said:\r\n\r\n```\r\n2024-12-18 21:52:43,520 DEBUG livekit.agents.pipeline: speech playout started\r\n2024-12-18 21:52:43,523 ERROR livekit.agents.pipeline: Error in _capture_task\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.12/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\r\n    return await fn(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/usr/local/lib/python3.12/site-packages/livekit/agents/pipeline/agent_playout.py\", line 148, in _capture_task\r\n    await self._audio_source.capture_frame(frame)\r\n  File \"/usr/local/lib/python3.12/site-packages/livekit/rtc/audio_source.py\", line 152, in capture_frame\r\n    raise Exception(cb.capture_audio_frame.error)\r\nException: an RtcError occured: InvalidState - failed to capture frame\r\n2024-12-18 21:52:43,543 DEBUG livekit.agents.pipeline: speech playout finished\r\n2024-12-18 21:52:43,543 INFO voicebot.db.conversations: User speech committed: Pronto?\r\n2024-12-18 21:52:43,543 INFO voicebot.db.conversations: Agent speech committed:  [THE WHOLE AGENT TRANSCRIPTION - but not even a single word was heard]\r\n2024-12-18 21:52:43,543 DEBUG livekit.agents.pipeline: committed agent speech\r\n```\r\n\r\nI can live with that issue occurring sometimes, but the agent should be aware that no speech has been produced. This is causing huge problems in user interaction.\r\n\r\nAny help?",
      "state": "closed",
      "author": "IngLP",
      "author_type": "User",
      "created_at": "2024-12-19T12:14:43Z",
      "updated_at": "2025-06-19T14:05:20Z",
      "closed_at": "2025-06-19T14:05:20Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1259/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1259",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1259",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:16.893100",
      "comments": []
    },
    {
      "issue_number": 1247,
      "title": "Missing cached_tokens_details from MultimodalLLMMetrics and UsageCollector",
      "body": "`MultimodalLLMMetrics` is missing `cached_tokens_details` from the original OpenAI realtime usage metrics response. Here is the full response example (spec here: https://platform.openai.com/docs/api-reference/realtime-server-events/response/done):\r\n```\r\n{\r\n      \"total_tokens\":275,\r\n      \"input_tokens\":127,\r\n      \"output_tokens\":148,\r\n      \"input_token_details\": {\r\n          \"cached_tokens\":384,\r\n          \"text_tokens\":119, \r\n          \"audio_tokens\":8,\r\n\r\n          # this block is required to compute the pricing for the request since some cached tokens are text whereas some are audio\r\n          \"cached_tokens_details\": { \r\n              \"text_tokens\": 128,\r\n              \"audio_tokens\": 256\r\n          }\r\n      },\r\n      \"output_token_details\": {\r\n         \"text_tokens\":36,\r\n         \"audio_tokens\":112\r\n      }\r\n}\r\n```\r\n\r\nIt would also be nice if UsageCollector supports the full MultimodalLLMMetrics, but I can pretty easily roll my own there since its just an aggregator.",
      "state": "closed",
      "author": "willsmanley",
      "author_type": "User",
      "created_at": "2024-12-17T17:35:18Z",
      "updated_at": "2025-06-19T14:05:20Z",
      "closed_at": "2025-06-19T14:05:20Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1247/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1247",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1247",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:16.893128",
      "comments": [
        {
          "author": "willsmanley",
          "body": "Just created a PR that provides `cached_tokens_details` to the client. However does not include any UsageCollector changes.",
          "created_at": "2024-12-17T18:34:15Z"
        },
        {
          "author": "davidzhao",
          "body": "thanks! any interest in creating a PR to improve UsageCollector?",
          "created_at": "2024-12-18T07:36:01Z"
        },
        {
          "author": "willsmanley",
          "body": "i'd love to! https://github.com/livekit/agents/pull/1255\r\n\r\nHappy to make changes but this is what makes the most sense to me (and the way i am storing them locally in my `model_usage_events` table).\r\n\r\nI will explain because I feel like the way openai sends back the cached tokens is a bit odd. for ",
          "created_at": "2024-12-18T14:36:21Z"
        }
      ]
    },
    {
      "issue_number": 1938,
      "title": "text modality not working for gemini multimodal",
      "body": "when i add text modality in addition to audio, and trying to generate a reply there is error  \nCLOSE 1007 (invalid frame payload data) Request contains an invalid argument. [39 bytes]\nworks fine with just audio. the google-genai version seems to be old is that the cause of the problem?",
      "state": "open",
      "author": "kailashprem",
      "author_type": "User",
      "created_at": "2025-04-09T06:43:43Z",
      "updated_at": "2025-06-19T03:05:07Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1938/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1938",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1938",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:17.097336",
      "comments": [
        {
          "author": "ChenghaoMou",
          "body": "I don't think it supports both audio and text at the same time right now. \n\nSee: https://github.com/google-gemini/cookbook/issues/386 and https://github.com/google-gemini/cookbook/issues/379",
          "created_at": "2025-04-29T15:33:09Z"
        },
        {
          "author": "MatheusRDG",
          "body": "Is this working? I'm getting struggled to get both and save transcription when the interview finish.\nI got the text on playground but the user input keep overwritting the first message.",
          "created_at": "2025-06-09T18:43:30Z"
        },
        {
          "author": "longcw",
          "body": "Text modality is supported in https://github.com/livekit/agents/pull/2628",
          "created_at": "2025-06-19T03:05:07Z"
        }
      ]
    },
    {
      "issue_number": 2417,
      "title": "How to force speech synthesis for partial `llm_node` result?",
      "body": "Hi there!\n\nI am working on a custom `llm_node` method on one of my agents that performs a sequence of LLM calls for various purposes and stitches them together to create a final output to send to the TTS service. Before I send the final outputs, I want to be able to send some speech to be played while the rest of the LLM calls occur. However, I've found that the speech will not begin; it seems it's waiting for a threshold of available text to be generated.\n\nAs an example, this demonstrates largely what I'm aiming for...\n\n```python\nclass MyAgent(Agent):\n    def llm_node(...):\n        # Perform an initial LLM call and get some text.\n        response = await self.call_some_fast_llm()\n        # Send this to the TTS service.\n        yield response\n        # TODO: How to force the TTS service to say the text that's been sent?\n        remaining = await self.call_some_slow_llm()\n        # Send the remaining text to the TTS service.\n        yield remaining\n        # Normally it's only now the speech begins.\n```\n\nIs there a way to force the TTS to begin playing the provided text while waiting for the rest to generate, all from within the `llm_node` method? Or perhaps there's a better way to accomplish this?",
      "state": "open",
      "author": "furious-luke",
      "author_type": "User",
      "created_at": "2025-05-28T03:19:55Z",
      "updated_at": "2025-06-19T01:52:56Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2417/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 1
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2417",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2417",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:17.459630",
      "comments": [
        {
          "author": "theomonnom",
          "body": "For now, this isn’t supported — the llm_node does not have a “Flush” capability. Attempt #2023 was an effort to implement this. We do, however, have a related example that uses [on_user_turn_completed](https://github.com/livekit/agents/blob/main/examples/voice_agents/fast-preresponse.py) to inject “",
          "created_at": "2025-05-28T08:26:01Z"
        },
        {
          "author": "furious-luke",
          "body": "Understood, thanks for the reply!",
          "created_at": "2025-05-28T20:48:53Z"
        },
        {
          "author": "iandoesallthethings",
          "body": "> For now, this isn’t supported — the llm_node does not have a “Flush” capability. Attempt [#2023](https://github.com/livekit/agents/pull/2023) was an effort to implement this. We do, however, have a related example that uses [on_user_turn_completed](https://github.com/livekit/agents/blob/main/examp",
          "created_at": "2025-06-16T19:43:58Z"
        },
        {
          "author": "longcw",
          "body": "@iandoesallthethings you can customize the text input callback from `RoomInputOptions.text_input_cb` https://github.com/livekit/agents/blob/livekit-agents%401.1.0/livekit-agents/livekit/agents/voice/room_io/room_io.py#L76",
          "created_at": "2025-06-17T01:59:53Z"
        },
        {
          "author": "iandoesallthethings",
          "body": "> [@iandoesallthethings](https://github.com/iandoesallthethings) you can customize the text input callback from `RoomInputOptions.text_input_cb` https://github.com/livekit/agents/blob/livekit-agents%401.1.0/livekit-agents/livekit/agents/voice/room_io/room_io.py#L76\n\nAh, I see. So if I want text and ",
          "created_at": "2025-06-18T15:41:31Z"
        }
      ]
    },
    {
      "issue_number": 2601,
      "title": "`generate_reply` doesn't work in `on_enter` when using tavus avatar",
      "body": "Currently, `on_enter` is called after the avatar participant joins the room. \n\nHowever, it appears that is too early and `generate_reply` doesn't work:\n```python\nasync def on_enter(self):\n    # doesn't work\n    await self.session.generate_reply(\n        instructions=\"Greet the user with a warm welcome\",\n    )\n```\n\nThe workaround is to wait for the avatar participant to publish its video track first, and by that time `generate_reply` starts to work.",
      "state": "closed",
      "author": "koakuma-chan",
      "author_type": "User",
      "created_at": "2025-06-13T13:17:50Z",
      "updated_at": "2025-06-19T01:50:37Z",
      "closed_at": "2025-06-19T01:50:37Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2601/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2601",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2601",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:17.780854",
      "comments": []
    },
    {
      "issue_number": 2637,
      "title": "livekit.agents.multimodal error",
      "body": "    from livekit.agents.multimodal import MultimodalAgent\nModuleNotFoundError: No module named 'livekit.agents.multimodal'\n\nI am getting this error while  trying to run an agent. Wondering what could be the problem. ",
      "state": "closed",
      "author": "IndraniB2020",
      "author_type": "User",
      "created_at": "2025-06-18T22:41:12Z",
      "updated_at": "2025-06-19T00:11:26Z",
      "closed_at": "2025-06-19T00:11:26Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2637/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2637",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2637",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:17.780875",
      "comments": [
        {
          "author": "davidzhao",
          "body": "this is because you are running an older example (for 0.x) against 1.x of agents.<br><br>please try a more recent example or see [here](https://docs.livekit.io/agents/start/v0-migration/) for how to migrate",
          "created_at": "2025-06-19T00:11:15Z"
        }
      ]
    },
    {
      "issue_number": 2356,
      "title": "function calling is not working for gemini-2.5-flash-preview-native-audio-dialog",
      "body": "function calling is not working for gemini-2.5-flash-preview-native-audio-dialog model selection. Please fix it. Because this model can support many languages.",
      "state": "open",
      "author": "shirosh",
      "author_type": "User",
      "created_at": "2025-05-22T06:43:31Z",
      "updated_at": "2025-06-18T22:48:20Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 30,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2356/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2356",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2356",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:17.999868",
      "comments": []
    },
    {
      "issue_number": 2633,
      "title": "How to deal with punctuation while using Turn Detector plugin?",
      "body": "I believe Deepgram sets `.` quite randomly based on pauses and it overwhelms the turn detector model\nCould you advise if turn detector  supposed to work _better_ if I delete all the punctuation from messages?\n\nSame question if I add double space `\"  \"` if I got `is_final` flag for interim transcript. Does it confuse the model? \n\nI hope for some hints if text without punctuation were used for training ",
      "state": "open",
      "author": "SedoshkinIlia",
      "author_type": "User",
      "created_at": "2025-06-18T18:58:41Z",
      "updated_at": "2025-06-18T18:58:41Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2633/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2633",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2633",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:17.999889",
      "comments": []
    },
    {
      "issue_number": 2604,
      "title": "TTS on a multimodal voice agent having massive delay after the llm has given it an answer [Error in Decode Loop]",
      "body": "<!--\nHello! Thanks for taking the time to file a bug report.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already reported this issue.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n-->\nHello everyone,\n\nI am currently building a voice agent (STT, LLM, TTS all openai) and i keep having trouble on 30% of my responses the tts part of the agents seems to delay up to 30seconds in order to speak out loud the response from the llm. The error i am getting is attached below. Does somebody understand why this inconsistency keeps happening? Below lies the error that i am getting:\n\nERROR livekit.plugins.openai: Error in _decode_loop\nTraceback (most recent call last):\n  File \"...\\\\httpx\\\\_transports\\\\default.py\", line 394, in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n  ...\nhttpcore.ReadTimeout\n\nThe above exception was the direct cause of the following exception:\nhttpx.ReadTimeout\n\nThe above exception was the direct cause of the following exception:\nopenai.APITimeoutError: Request timed out\n////////////////////////////////////////////////////////////////////\nWARNING livekit.agents: failed to synthesize speech, retrying in 0.1s\nTraceback (most recent call last):\n  File \"...\\\\livekit\\\\plugins\\\\openai\\\\tts.py\", line 254, in _run\n    async with oai_stream as stream:\nopenai.APITimeoutError: Request timed out\n\nDuring handling of the above exception, another exception occurred:\nlivekit.agents._exceptions.APITimeoutError: Request timed out\n ",
      "state": "open",
      "author": "langverseadmin",
      "author_type": "User",
      "created_at": "2025-06-14T21:44:06Z",
      "updated_at": "2025-06-18T07:39:24Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2604/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2604",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2604",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:17.999897",
      "comments": [
        {
          "author": "langverseadmin",
          "body": "I have tried changing the time out options and tried many other chunking mechanisms  and it still won't work, not really sure why since the input from the llm is max 2 sentences long. Adding my agents logic below for reference.\n\n\n```\nimport json\nimport asyncio\nimport os\nimport re\nimport time\nfrom li",
          "created_at": "2025-06-16T16:37:25Z"
        },
        {
          "author": "longcw",
          "body": "can you try a different TTS provider to see if it's the issue of the openai TTS?",
          "created_at": "2025-06-17T02:21:50Z"
        },
        {
          "author": "langverseadmin",
          "body": "Hello, thank you for your reply! So since changing the provider was my last resort i managed to find a way to temporarily bypass the issue by decreasing the httpx timeout inside the run method of the tts.py file in openai-plugins from 30 to 5 sec. Now if there is an issue it will quickly throw the e",
          "created_at": "2025-06-18T07:39:24Z"
        }
      ]
    },
    {
      "issue_number": 2501,
      "title": "TTS Voice Issue (Hindi/Arabic) in LiveKit Agents 1.0.22 — Works Fine in 0.x",
      "body": "## Summary\nWe’re experiencing a bug with the ElevenLabs TTS voice integration when using LiveKit Agents version `1.0.22`. The issue affects Hindi and Arabic voices — the output is broken, with characters pronounced one by one instead of fluid speech. \n\nThis problem does **not occur in LiveKit Agent version 0.x**, where the same code and voice configuration works perfectly.\n\n## Reproduction Steps\n1. Use ElevenLabs with Hindi or Arabic voice (`language=\"hi\"` or similar)\n2. Use `livekit-agents==1.0.22`\n3. Compare the TTS output with the same configuration on `livekit-agents==0.x`\n\n",
      "state": "open",
      "author": "premkumar-zudu",
      "author_type": "User",
      "created_at": "2025-06-03T22:49:07Z",
      "updated_at": "2025-06-18T03:29:13Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2501/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2501",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2501",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:18.229676",
      "comments": [
        {
          "author": "longcw",
          "body": "It should be fixed in 1.0.23, could you test with the latest version?",
          "created_at": "2025-06-04T01:36:06Z"
        },
        {
          "author": "civilcoder55",
          "body": "> It should be fixed in 1.0.23, could you test with the latest version?\n\nThanks, @longcw. This problem happened to me, and it was solved when I updated to the latest agent version.",
          "created_at": "2025-06-18T03:29:13Z"
        }
      ]
    },
    {
      "issue_number": 2488,
      "title": "Fallback Adapter not catching Gemini parsing failures",
      "body": "I had a user today report a crashed room - when I looked into it there was an error from Gemini:\n```\nraise APIConnectionError(\\nlivekit.agents._exceptions.APIConnectionError: gemini llm: error generating content Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\",\n```\nI traced this down and it doesn't seem to be a LiveKit issue - Gemini is returning bad JSON and Google's Python SDK isn't catching it properly. I found more information about this bug in [this issue on another repo](https://github.com/BerriAI/litellm/issues/5650).\n\nObviously this isn't LiveKit's fault, but it does end up crashing the worker,  even with a FallbackAdapter. Is it possible to include an error like this within the scope of the FallbackAdapter?",
      "state": "open",
      "author": "bryanhoulton",
      "author_type": "User",
      "created_at": "2025-06-03T00:26:31Z",
      "updated_at": "2025-06-18T01:23:55Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2488/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2488",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2488",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:18.548021",
      "comments": [
        {
          "author": "longcw",
          "body": "could you share an example or more logs that can reproduce this issue with the `FallbackAdapter`, it works when I test with the following when I raise an error from the gemini LLM.\n```python\n        llm=FallbackAdapter(\n            llm=[\n                google.LLM(model=\"gemini-2.0-flash-001\"),\n    ",
          "created_at": "2025-06-11T07:26:05Z"
        },
        {
          "author": "bryanhoulton",
          "body": "```\n{\"message\": \"livekit.plugins.google.llm.LLM failed, switching to next LLM\\nTraceback (most recent call last):\\n  File \\\"/opt/render/project/src/.venv/lib/python3.12/site-packages/livekit/plugins/google/llm.py\\\", line 294, in _run\\n    async for response in stream:\\n  File \\\"/opt/render/project/s",
          "created_at": "2025-06-13T16:17:08Z"
        },
        {
          "author": "amfleming",
          "body": "Seems like there may be a need to accumulate json chunks across calls\n\nhttps://github.com/BerriAI/litellm/pull/5488/files#diff-c382622fab77f2fb02bde841f903a5a463797c87c5416ea69aa2295110c7efe9R1580-R1641\n",
          "created_at": "2025-06-17T23:23:59Z"
        },
        {
          "author": "longcw",
          "body": "@bryanhoulton from your logs the fallbackadapter caught the error and was trying to switch to next LLM. but probably the LLM already sent some chunks before fail so it [skipped the retry for this turn](https://github.com/livekit/agents/blob/livekit-agents%401.1.0/livekit-agents/livekit/agents/llm/fa",
          "created_at": "2025-06-18T01:23:55Z"
        }
      ]
    },
    {
      "issue_number": 2406,
      "title": "Unhandled Google TTS Abort Exception",
      "body": "I am seeing the below exception thrown from Google TTS - observed this when the user goes silent -\n\n```\nraise _create_rpc_error(\ngrpc.aio._call.AioRpcError: <AioRpcError of RPC that terminated with:\n        status = StatusCode.ABORTED\n        details = \"Stream aborted due to long duration elapsed without input sent. Input must be sent continuously, at least every 5s seconds.\"\n        debug_error_string = \"UNKNOWN:Error received from peer ipv4:142.251.222.170:443 {grpc_message:\"Stream aborted due to long duration elapsed without input sent. Input must be sent continuously, at least every 5s seconds.\", grpc_status:10, created_time:\"2025-05-27T11:02:56.881525+05:30\"}\"\n>\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/app/lib/python3.11/site-packages/livekit/plugins/google/tts.py\", line 352, in _run_stream\n    async for resp in stream:\n  File \"/app/lib/python3.11/site-packages/google/api_core/grpc_helpers_async.py\", line 109, in _wrapped_aiter\n    raise exceptions.from_grpc_error(rpc_error) from rpc_error\ngoogle.api_core.exceptions.Aborted: 409 Stream aborted due to long duration elapsed without input sent. Input must be sent continuously, at least every 5s seconds.\n```\n\nEnvironment and Library version:\n1. Python - 3.11.11\n2. LiveKit Plugin version - livekit-plugins-google==1.0.22\n3. Google libs -\n    google-api-core==2.24.2\n    google-auth==2.40.2\n    google-cloud-speech==2.32.0\n    google-cloud-texttospeech==2.27.0\n    google-genai==1.16.1\n    googleapis-common-protos==1.70.0\n    grpcio==1.71.0\n    grpcio-status==1.71.0\n",
      "state": "open",
      "author": "zaheerabbas-prodigal",
      "author_type": "User",
      "created_at": "2025-05-27T05:53:04Z",
      "updated_at": "2025-06-17T20:21:34Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2406/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2406",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2406",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:18.812109",
      "comments": [
        {
          "author": "zaheerabbas-prodigal",
          "body": "@jayeshp19 @theomonnom - would appreciate your help here. Have you guys seen this error. Still facing this issue in prod where the google-plugin throws the above error.",
          "created_at": "2025-06-07T13:53:01Z"
        },
        {
          "author": "zaheerabbas-prodigal",
          "body": "Ping on this @theomonnom @jayeshp19 - if you guys can help. Would appreciate it",
          "created_at": "2025-06-17T20:21:34Z"
        }
      ]
    },
    {
      "issue_number": 2586,
      "title": "25% Audio Failure Rate When Using Gemini via LiveKit",
      "body": "We are experiencing a ~25% failure rate when using Gemini with audio routed through LiveKit. When we run the exact same voice pipeline using the recorded Twilio audio output, the failures persist. However, when we test with Gemini’s own SDK or Google Studio, the pipeline works reliably. This strongly suggests the issue may be related to LiveKit's handling of the audio stream.\n\n\nTo reproduce, we can pass the audio file that isn't recognised by the pipeline \n\nEnvironment:\n- Audio source: Twilio\n- Agent: Gemini Realtime API (2.5)\n- LiveKit WebRTC Gateway\n- Confirmed behavior in testing and in production",
      "state": "open",
      "author": "anantk-147",
      "author_type": "User",
      "created_at": "2025-06-12T18:04:45Z",
      "updated_at": "2025-06-17T16:02:53Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2586/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2586",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2586",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:19.101214",
      "comments": [
        {
          "author": "longcw",
          "body": "Yes can you share the audio file please, did you enabled the noise cancelling in livekit agents?",
          "created_at": "2025-06-13T00:51:04Z"
        },
        {
          "author": "MatheusRDG",
          "body": "That occurs to me as well. Some times the model only stucks. I'm using the frontend from livekit and screen sharing.",
          "created_at": "2025-06-13T17:58:00Z"
        },
        {
          "author": "td2thinh",
          "body": "Are you guys using Gemini Flash 2.5 audio native? I have seen a lot of problems reported with this model, I heavily suspect this is a model related issue, as it's in preview.",
          "created_at": "2025-06-17T11:35:55Z"
        },
        {
          "author": "anantk-147",
          "body": "using gemini-2.5-flash-preview-native-audio-dialog but we tested the same audio file in google studio + with the SDK and it performed correctly, which is why we don't believe it's a model problem (at least not in isolation)",
          "created_at": "2025-06-17T11:40:59Z"
        },
        {
          "author": "MatheusRDG",
          "body": "@anantk-147 Same here, only in livekit side I got problems. The model stop to answer after some iterations, we have bugs on transcriptions as well. Using gemini-2.5-flash-preview-native-audio-dialog. works with the old model (gemini flash 2.0)",
          "created_at": "2025-06-17T15:06:56Z"
        }
      ]
    },
    {
      "issue_number": 2280,
      "title": "Allow configuration of `ensure_ascii` in JSON logging for non-English characters",
      "body": "<!--\nHello! Thanks for taking the time to ask a question.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already asked this question.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n\nFeel free to join us in the #agents channel on our Slack, and ask your question\nthere to get quicker help from us and the community:\n\nhttps://livekit.io/join-slack\n-->\n\n**Title:**  \nAllow configuration of `ensure_ascii` in JSON logging for non-English characters\n\n**Description:**\n\nCurrently, the JSON logging formatter in our codebase uses `ensure_ascii=True` by default. This causes non-English characters (such as Korean, Japanese, Chinese, etc.) to be escaped as Unicode sequences, which makes logs less readable and harder to debug for users working with these languages.\n\nFor example, a log message containing Korean text like \"안녕하세요\" is output as `\\uc548\\ub155\\ud558\\uc138\\uc694` instead of the actual characters.\n\n**Proposal:**\n\nWe propose to modify the logging setup to make the `ensure_ascii` option configurable. Here are a few suggested approaches:\n\n1. **Configuration Parameter in WorkerOptions**\n   - Add `log_ensure_ascii: bool` to the `WorkerOptions` class\n   - This would allow users to configure the behavior when initializing the worker\n   ```python\n   opts = WorkerOptions(\n       ws_url=\"ws://localhost:7880\",\n       log_ensure_ascii=False  # New parameter\n   )\n   ```\n\n2. **CLI Option**\n   - Add a command-line flag to control this behavior\n   ```bash\n   livekit-agent start --log-ensure-ascii=false\n   ```\n\n3. **Plugin Configuration**\n   - Allow plugins to specify their preferred logging format\n   - This would be particularly useful for plugins that need to handle non-English content\n\n**Questions:**\n\n1. Is there a specific reason why `ensure_ascii` is currently hardcoded to `True`?  \n   - If it's for compatibility or legacy reasons, could we consider making it configurable while keeping `True` as the default?\n\n2. Would it be possible to update the logging formatter to support these configuration options?\n\n**Impact:**\n\nMaking this change would significantly improve the usability of our logging system for international users and developers working with non-English languages. It would make debugging and log analysis much more straightforward for users working with non-English content.\n\n**Additional Context:**\n- This is particularly important for applications that need to handle user input or generate content in non-English languages\n- Many logging tools and systems (like ELK Stack) can handle UTF-8 encoded JSON logs without issues\n- The change would be backward compatible if we keep `True` as the default value",
      "state": "closed",
      "author": "sunghyunjun",
      "author_type": "User",
      "created_at": "2025-05-13T15:03:59Z",
      "updated_at": "2025-06-17T12:56:24Z",
      "closed_at": "2025-06-17T12:56:24Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2280/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2280",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2280",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:20.356705",
      "comments": [
        {
          "author": "longcw",
          "body": "@theomonnom should we just remove the `ensure_ascii=True` in logs?",
          "created_at": "2025-05-13T15:17:27Z"
        },
        {
          "author": "zuber-ctrlagent",
          "body": "Hi, any update on this?",
          "created_at": "2025-05-24T03:34:24Z"
        },
        {
          "author": "theomonnom",
          "body": "https://github.com/livekit/agents/pull/2622",
          "created_at": "2025-06-17T12:56:24Z"
        }
      ]
    },
    {
      "issue_number": 1999,
      "title": "speech_id in metrics changes when tool calls are involved",
      "body": "Using v1, I'm interested in measuring the conversation latency as defined in the [v0 docs](https://docs.livekit.io/agents/v0/build/metrics/#measuring-conversation-latency)\n\nWhile the various ttfts and durations are exposed in the v1 metrics models, I'm unsure how to identify each \"turn\" of a conversation to correlate latencies of the same.  Is there an example that demonstrates how this might be implemented?\n\nTo add onto this, and assuming there is a way to identify a specific conversation turn, a cascading pipeline approach may involve the use of tool calls in which case the conversation latency needs to include the full duration of the tool calling LLM inference step.  Is there a way to easily identify the type of LLM call made through the metrics framework or would we have to rely heuristics (i.e. only count `ttft` of the last llm call and any prior llm calls count its full `duration`)?",
      "state": "open",
      "author": "yuyuma",
      "author_type": "User",
      "created_at": "2025-04-14T21:46:05Z",
      "updated_at": "2025-06-17T12:21:21Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 11,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1999/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "theomonnom"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1999",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1999",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:20.627171",
      "comments": [
        {
          "author": "LilaRest",
          "body": "Same question here!",
          "created_at": "2025-04-15T18:21:46Z"
        },
        {
          "author": "LilaRest",
          "body": "Hey @yuyuma\nI just found some examples about that here:\nhttps://github.com/livekit-examples/python-agents-examples/tree/main/metrics\n\nIt's working great on my side.",
          "created_at": "2025-04-16T13:50:30Z"
        },
        {
          "author": "ChenghaoMou",
          "body": "From what I can see, it's bit tricky with STT. In some plugins, audio chunks are sent every x seconds nonstop, and responses from those services aren't linked back to any chunk timestamps. So it is not that straightforward to calculate the latency in STT. see #1135 \n\nHowever, you can try to measure ",
          "created_at": "2025-04-16T17:31:55Z"
        },
        {
          "author": "LilaRest",
          "body": "@ChenghaoMou Yes, same experience here. I’ll try your alternative solution, thanks for sharing!\n\nAnyway LiveKit team, I’d love to see metrics a bit more polished and showcased in the docs, that could be helpful to a lot of devs after us! If I can help, ping me.",
          "created_at": "2025-04-17T06:35:42Z"
        },
        {
          "author": "yuyuma",
          "body": "@ChenghaoMou Thanks for your explanation and alternate suggestion. I saw that the [metrics documentation page for v1](https://docs.livekit.io/agents/build/metrics/) has just been published yesterday and I'm inclined to continue pursuing the doc suggested way of measuring conversation latency a littl",
          "created_at": "2025-04-17T19:18:04Z"
        }
      ]
    },
    {
      "issue_number": 2361,
      "title": "Bug Report: Incorrect transcription_delay calculation results in extremely large values",
      "body": "## Summary\nThe `transcription_delay` parameter occasionally receives extremely large values (e.g., `1747888559.8039`) that appear to be timestamps instead of proper delay calculations.\n\n## Environment\n- **STT**: Streaming STT\n- **Livekit Agent Version**: 1.0.22\n\n## Expected Behavior\n`transcription_delay` should be a small positive value representing the delay in seconds.\n\n## Actual Behavior\nSometimes `transcription_delay` gets values like `1747888559.8039` which look like Unix timestamps.\n\n## Code Context\nThe issue occurs in this code:\n\n```python\ncommitted = await self._hooks.on_end_of_turn(\n    _EndOfTurnInfo(\n        new_transcript=self._audio_transcript,\n        transcription_delay=max(\n            self._last_final_transcript_time - last_speaking_time, 0\n        ),\n        end_of_utterance_delay=time.time() - last_speaking_time,\n    )\n)\n```\n\n## Suspected Cause\n`last_speaking_time` appears to be `0` sometimes, causing `transcription_delay` to equal `self._last_final_transcript_time` (which is a timestamp).\n\n## Reproduction\nCannot reproduce intentionally, but happens quite often during normal usage with Streaming STT.",
      "state": "closed",
      "author": "hsjun99",
      "author_type": "User",
      "created_at": "2025-05-22T09:23:45Z",
      "updated_at": "2025-06-17T08:20:55Z",
      "closed_at": "2025-06-17T08:20:55Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2361/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 1
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2361",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2361",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:20.868295",
      "comments": [
        {
          "author": "longcw",
          "body": "This may happen when VAD enabled but VAD didn't detect the speech started (like a false negative of vad) before STT returns the final transcription. Will fix it soon.",
          "created_at": "2025-05-22T09:27:42Z"
        },
        {
          "author": "hsjun99",
          "body": "@longcw Thanks for the reply !",
          "created_at": "2025-05-22T09:29:08Z"
        },
        {
          "author": "zaheerabbas-prodigal",
          "body": "I have notice these large values occur in the TTS Metrics too. Has anyone else seen that. I am using Cartesia TTS.\n\nPls lmk if I should open a new issue for that.",
          "created_at": "2025-06-14T17:04:45Z"
        },
        {
          "author": "hsjun99",
          "body": "@zaheerabbas-prodigal Haven't seen any when using Elevenlabs.",
          "created_at": "2025-06-16T01:41:59Z"
        }
      ]
    },
    {
      "issue_number": 2616,
      "title": "Adding optional arguments to a function tool doesn't pass strict schema validation if using OpenAI LLM",
      "body": "Hi, I searched for the similar issue and could not find it.\n\nTool example:\n```\n@function_tool()\nasync def update_user_settings(\n    ctx: RunContext, \n    setting1: Union[str, None], \n    setting2: Optional[str], \n) -> str:\n```\n\nSession is created with llm=openai.LLM(model=\"gpt-4.1-mini\").\n\nError:\n```\nTraceback (most recent call last):\n  File \"/Users/kk/projects/esnc/agents/emilio_agent/.venv/lib/python3.13/site-packages/livekit/plugins/openai/llm.py\", line 646, in _run\n    fnc_ctx = to_fnc_ctx(self._tools) if self._tools else openai.NOT_GIVEN\n              ~~~~~~~~~~^^^^^^^^^^^^^\n  File \"/Users/kk/projects/esnc/agents/emilio_agent/.venv/lib/python3.13/site-packages/livekit/plugins/openai/utils.py\", line 38, in to_fnc_ctx\n    tools.append(llm.utils.build_strict_openai_schema(fnc))  # type: ignore\n                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^\n  File \"/Users/kk/projects/esnc/agents/emilio_agent/.venv/lib/python3.13/site-packages/livekit/agents/llm/utils.py\", line 213, in build_strict_openai_schema\n    schema = _strict.to_strict_json_schema(model)\n  File \"/Users/kk/projects/esnc/agents/emilio_agent/.venv/lib/python3.13/site-packages/livekit/agents/llm/_strict.py\", line 17, in to_strict_json_schema\n    return _ensure_strict_json_schema(schema, path=(), root=schema)\n  File \"/Users/kk/projects/esnc/agents/emilio_agent/.venv/lib/python3.13/site-packages/livekit/agents/llm/_strict.py\", line 69, in _ensure_strict_json_schema\n    key: _ensure_strict_json_schema(prop_schema, path=(*path, \"properties\", key), root=root)\n         ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/kk/projects/esnc/agents/emilio_agent/.venv/lib/python3.13/site-packages/livekit/agents/llm/_strict.py\", line 163, in _ensure_strict_json_schema\n    t = non_null[\"type\"]\n        ~~~~~~~~^^^^^^^^\nKeyError: 'type'\n```\n\nChanging the arg type to \"str\" resolves the error. What's the right way to make the args to be optional?",
      "state": "open",
      "author": "kirylkliushkin",
      "author_type": "User",
      "created_at": "2025-06-16T17:57:47Z",
      "updated_at": "2025-06-17T06:10:28Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2616/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2616",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2616",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:21.076132",
      "comments": [
        {
          "author": "longcw",
          "body": "I cannot reproduce it with the agents 1.1.1, which version are you using and can you try with the latest version?\n\nThis is the function I tested\n```python\n\n    @function_tool\n    async def update_user_settings(\n        ctx: RunContext,\n        setting1: Union[str, None],\n        setting2: Optional[s",
          "created_at": "2025-06-17T06:10:28Z"
        }
      ]
    },
    {
      "issue_number": 2326,
      "title": "Feature Request: Utterance timestamps in the ChatContext or Transcript",
      "body": "I want to capture the word level or atleast utterance level timestamps for both the `user` and `agent` transcripts and store the timestamp details in the `ChatContext`. The usecase is to use the `ChatContext` as the transcript to run some post-processing. Example use cases- displaying the calls in UI, redaction, summarization etc.\n\nCurrently the transcription data the SDK exposes for the user transcript is just the `text` part of the transcript and the utterance or word level timestamps are NOT exposed at all from the SDK.\n\nThe agent's transcript however does not even have the timestamps even though [elevenlabs](https://elevenlabs.io/docs/api-reference/text-to-speech/v-1-text-to-speech-voice-id-stream-input#receive.Audio-Output.alignment) and [cartesia](https://docs.cartesia.ai/2025-04-16/api-reference/tts/tts#receive.Receive.timestamps) TTS support timestamps in their API.\n\nHas anyone tried a way to get these timestamp data from the livekit-agents SDK?\n\nI am happy to submit a PR to add this feature. Would the PR be merged if I added this feature?",
      "state": "open",
      "author": "zaheerabbas-prodigal",
      "author_type": "User",
      "created_at": "2025-05-19T08:41:02Z",
      "updated_at": "2025-06-17T03:42:12Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2326/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2326",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2326",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:21.345543",
      "comments": [
        {
          "author": "hsjun99",
          "body": "@zaheerabbas-prodigal How have you ended up regarding this issue?",
          "created_at": "2025-06-16T06:58:23Z"
        },
        {
          "author": "longcw",
          "body": "It's added in https://github.com/livekit/agents/pull/2580, it supports the word level timestamp for cartesia TTS or sentence level timestamp for non-streaming TTS using StreamAdapter.\n\nWe are not adding the timed transcripts to the chat context, but you can access the it from the `transcription_node",
          "created_at": "2025-06-16T07:24:56Z"
        },
        {
          "author": "hsjun99",
          "body": "@longcw Great news thanks. Would it also work for elevenlabs?\nAlso, what is the best strategy to create a word-level timestamp(relative X, absolute O) for the user transcript?",
          "created_at": "2025-06-16T07:36:30Z"
        },
        {
          "author": "longcw",
          "body": "elevenlabs is not supported right now as we are using the websocket api and they only support timestamps in post api https://elevenlabs.io/docs/api-reference/text-to-speech/stream-with-timestamps",
          "created_at": "2025-06-16T07:41:45Z"
        },
        {
          "author": "hsjun99",
          "body": "@longcw Isn't the normalizedAlignment/Alignment field that provides the timestamps?\n![Image](https://github.com/user-attachments/assets/409ef766-dc07-444a-9dd9-e540db732e07)",
          "created_at": "2025-06-16T07:45:08Z"
        }
      ]
    },
    {
      "issue_number": 2606,
      "title": "Bug: Incorrectly large transcription_delay when VAD is missed but STT provides a transcript (v1.1.1)",
      "body": "**Describe the bug**\nThere are circumstances where the `transcription_delay` metric, calculated in `_EndOfTurnInfo`, is reported as an unexpectedly large value, sometimes in the range of 10-15 seconds.\n\nThis issue occurs when the Voice Activity Detector (VAD) fails to trigger for a user's utterance, but the Speech-to-Text (STT) engine successfully transcribes the audio and produces a final transcript.\n\n**Root Cause Analysis**\nThe `transcription_delay` is calculated as `self._last_final_transcript_time - last_speaking_time`.\n\n1.  `_last_speaking_time` is primarily updated by the VAD system upon detecting the end of speech (in `_on_vad_event` via `VADEventType.END_OF_SPEECH`).\n2.  `_last_final_transcript_time` is updated when the STT engine emits a `FINAL_TRANSCRIPT` event (in `_on_stt_event`).\n3.  If a user speaks, but the VAD does not fire, `_last_speaking_time` is not updated and retains its value from the previous utterance.\n4.  However, the STT can still process the audio and produce a transcript. When this `FINAL_TRANSCRIPT` is received, `_on_stt_event` is called.\n5.  Inside `_on_stt_event`, the code checks `if not self._speaking:`. Because VAD never triggered, `self._speaking` is `False`, and this block is entered.\n6.  The `_run_eou_detection` function is then called, which uses the current (and now stale) `self._last_speaking_time` to schedule the `_bounce_eou_task`.\n7.  The final calculation becomes `time.time()` (from the final transcript) minus `_last_speaking_time` (from the *previous* turn), resulting in a very large and incorrect delay value.\n\nThe problematic code section is in `AudioRecognition._on_stt_event`:\n\n```python\n# file: livekit-agents/livekit/agents/ipc/audio_recognition.py\n\n# ... inside AudioRecognition class\n    async def _on_stt_event(self, ev: stt.SpeechEvent) -> None:\n        # ...\n        if ev.type == stt.SpeechEventType.FINAL_TRANSCRIPT:\n            # ...\n            self._last_final_transcript_time = time.time()\n            # ...\n\n            if not self._speaking: # This is True if VAD didn't detect speech\n                if not self._vad:\n                    # This block only runs if VAD is completely disabled.\n                    # The issue arises when VAD is enabled but misses an utterance.\n                    self._last_speaking_time = time.time()\n\n                if self._vad_base_turn_detection or self._user_turn_committed:\n                    # This calls _run_eou_detection with the stale _last_speaking_time\n                    chat_ctx = self._hooks.retrieve_chat_ctx().copy()\n                    self._run_eou_detection(chat_ctx)\n```\n\nThe value is then used in the `_bounce_eou_task`:\n```python\n# ... inside AudioRecognition class\n        async def _bounce_eou_task(last_speaking_time: float) -> None:\n            # ...\n            committed = self._hooks.on_end_of_turn(\n                _EndOfTurnInfo(\n                    new_transcript=self._audio_transcript,\n                    transcription_delay=max(\n                        self._last_final_transcript_time - last_speaking_time, 0 # This calculation is incorrect due to stale last_speaking_time\n                    ),\n                    end_of_utterance_delay=time.time() - last_speaking_time,\n                )\n            )\n```\n\n**Expected behavior**\nThe calculated `transcription_delay` should accurately reflect the time difference between the end of a user's speech and the generation of the final transcript for that *same* utterance. It should not be skewed by timestamps from previous turns.",
      "state": "closed",
      "author": "hsjun99",
      "author_type": "User",
      "created_at": "2025-06-16T01:40:05Z",
      "updated_at": "2025-06-17T03:39:33Z",
      "closed_at": "2025-06-17T03:39:33Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2606/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2606",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2606",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:21.588151",
      "comments": [
        {
          "author": "longcw",
          "body": "duplicates https://github.com/livekit/agents/issues/2361",
          "created_at": "2025-06-17T03:39:33Z"
        }
      ]
    },
    {
      "issue_number": 2165,
      "title": "await self.session.generate_reply is not working at all in gemmini realtime",
      "body": "so basically while calling any function tool in gemini realtime voice  and i want to use  generate_reply to reply before return of the tool but if i use without await than this generate_reply work after the return of the tool reply  but if i use the await then it give the error \n\n\n```\n\n(env) recro@Manishs-MacBook-Pro voice_agent_livekit_server % python Chef_voice_agent/main.py console\nDEBUG:asyncio:Using selector: KqueueSelector\n2025-04-27 12:09:01,436 - DEBUG asyncio - Using selector: KqueueSelector \n==================================================\n     Livekit Agents - Console\n==================================================\nPress [Ctrl+B] to toggle between Text/Audio mode, [Q] to quit.\n\nINFO:livekit.agents:starting worker\n2025-04-27 12:09:01,437 - INFO livekit.agents - starting worker {\"version\": \"1.0.17\", \"rtc-version\": \"1.0.6\"}\nINFO:livekit.agents:see tracing information at http://localhost:52105/debug\n2025-04-27 12:09:01,439 - INFO livekit.agents - see tracing information at http://localhost:52105/debug \nINFO:livekit.agents:initializing job runner\n2025-04-27 12:09:01,440 - INFO livekit.agents - initializing job runner {\"tid\": 17135917}\nINFO:livekit.agents:job runner initialized\n2025-04-27 12:09:01,440 - INFO livekit.agents - job runner initialized {\"tid\": 17135917}\nDEBUG:asyncio:Using selector: KqueueSelector\n2025-04-27 12:09:01,440 - DEBUG asyncio - Using selector: KqueueSelector \n[Debug] GreetingAgent.__init__ called\n[Debug] Prompt instructions loaded\nDEBUG:livekit.plugins.google:connecting to Gemini Realtime API...\n2025-04-27 12:09:01,640 - DEBUG livekit.plugins.google - connecting to Gemini Realtime API... \n[Debug] on_enter start\n[Debug] current_stage set to greeting\n[Debug] Found recipe: Paneer Butter Masala\n[Audio] cBook Pro Microphone [-56.11 dBFS] [######------------------------]INFO:google_genai.live:b'{\\n  \"setupComplete\": {}\\n}\\n'\n2025-04-27 12:09:03,841 - INFO google_genai.live - b'{\\n  \"setupComplete\": {}\\n}\\n' \n[Audio] cBook Pro Microphone [-66.53 dBFS] [#-----------------------------]DEBUG:livekit.plugins.google:usage metadata\n2025-04-27 12:09:10,737 - DEBUG livekit.plugins.google - usage metadata {\"usage_metadata\": \"prompt_token_count=861 cached_content_token_count=None response_token_count=157 tool_use_prompt_token_count=None thoughts_token_count=None total_token_count=1018 prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=861)] cache_tokens_details=None response_tokens_details=[ModalityTokenCount(modality=<MediaModality.AUDIO: 'AUDIO'>, token_count=157)] tool_use_prompt_tokens_details=None traffic_type=None\"}\n[Audio] cBook Pro Microphone [-61.21 dBFS] [####--------------------------][Debug] generate_reply for recipe greeting executed\n[Audio] cBook Pro Microphone [-61.99 dBFS] [###---------------------------]DEBUG:livekit.agents:executing tool\n2025-04-27 12:09:25,378 - DEBUG livekit.agents - executing tool {\"function\": \"set_servings_and_list_ingredients\", \"arguments\": \"{\\\"servings\\\": 4}\", \"speech_id\": \"speech_8dd1356c2a6a\"}\n[Debug] set_servings_and_list_ingredients start with servings=4\n[Debug] Valid servings received: 4\n[Debug] userdata.servings set to 4\n[Debug] calculate_ingredients start for 4 servings of Paneer Butter Masala\n[Debug] scaling_factor calculated: 1.0\n[Debug] Ingredient line added: - 250 g of Paneer (Indian Cottage Cheese)\n[Debug] Ingredient line added: - 2 units of Onions (medium sized, finely chopped)\n[Debug] Ingredient line added: - 3 units of Tomatoes (large, pureed)\n[Debug] ingredient_text built: Okay, for 4 servings of Paneer Butter Masala, you will need:\n- 250 g of Paneer (Indian Cottage Cheese)\n- 2 units of Onions (medium sized, finely chopped)\n- 3 units of Tomatoes (large, pureed)\n/Users/recro/Documents/voice_agent_livekit_server/env/lib/python3.11/site-packages/livekit/agents/voice/agent_activity.py:1310: RuntimeWarning: coroutine 'RealtimeSession.update_options' was never awaited\n  self._rt_session.update_options(tool_choice=model_settings.tool_choice)\nRuntimeWarning: Enable tracemalloc to get the object allocation traceback\n[Audio] cBook Pro Microphone [-62.20 dBFS] [###---------------------------]/Users/recro/Documents/voice_agent_livekit_server/env/lib/python3.11/site-packages/livekit/agents/voice/agent_activity.py:1328: RuntimeWarning: coroutine 'RealtimeSession.update_options' was never awaited\n  self._rt_session.update_options(tool_choice=ori_tool_choice)\nRuntimeWarning: Enable tracemalloc to get the object allocation traceback\nERROR:livekit.agents:Error in _realtime_reply_task\nTraceback (most recent call last):\n  File \"/Users/recro/Documents/voice_agent_livekit_server/env/lib/python3.11/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/recro/Documents/voice_agent_livekit_server/env/lib/python3.11/site-packages/livekit/agents/voice/agent_activity.py\", line 1313, in _realtime_reply_task\n    generation_ev = await self._rt_session.generate_reply(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nlivekit.agents.llm.realtime.RealtimeError: generate_reply timed out waiting for generation_created event.\n2025-04-27 12:09:30,382 - ERROR livekit.agents - Error in _realtime_reply_task \nTraceback (most recent call last):\n  File \"/Users/recro/Documents/voice_agent_livekit_server/env/lib/python3.11/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/recro/Documents/voice_agent_livekit_server/env/lib/python3.11/site-packages/livekit/agents/voice/agent_activity.py\", line 1313, in _realtime_reply_task\n    generation_ev = await self._rt_session.generate_reply(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nlivekit.agents.llm.realtime.RealtimeError: generate_reply timed out waiting for generation_created event.\nERROR:asyncio:Task exception was never retrieved\nfuture: <Task finished name='AgentActivity.realtime_reply' coro=<AgentActivity._realtime_reply_task() done, defined at /Users/recro/Documents/voice_agent_livekit_server/env/lib/python3.11/site-packages/livekit/agents/utils/log.py:13> exception=RealtimeError('generate_reply timed out waiting for generation_created event.')>\nTraceback (most recent call last):\n  File \"/Users/recro/Documents/voice_agent_livekit_server/env/lib/python3.11/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/recro/Documents/voice_agent_livekit_server/env/lib/python3.11/site-packages/livekit/agents/voice/agent_activity.py\", line 1313, in _realtime_reply_task\n    generation_ev = await self._rt_session.generate_reply(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nlivekit.agents.llm.realtime.RealtimeError: generate_reply timed out waiting for generation_created event.\n2025-04-27 12:09:30,383 - ERROR asyncio - Task exception was never retrieved\nfuture: <Task finished name='AgentActivity.realtime_reply' coro=<AgentActivity._realtime_reply_task() done, defined at /Users/recro/Documents/voice_agent_livekit_server/env/lib/python3.11/site-packages/livekit/agents/utils/log.py:13> exception=RealtimeError('generate_reply timed out waiting for generation_created event.')> \nTraceback (most recent call last):\n  File \"/Users/recro/Documents/voice_agent_livekit_server/env/lib/python3.11/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/recro/Documents/voice_agent_livekit_server/env/lib/python3.11/site-packages/livekit/agents/voice/agent_activity.py\", line 1313, in _realtime_reply_task\n    generation_ev = await self._rt_session.generate_reply(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nlivekit.agents.llm.realtime.RealtimeError: generate_reply timed out waiting for generation_created event.\n[Debug] generate_reply for ingredients executed\n[Debug] current_stage updated to handoff_to_prep\nDEBUG:livekit.agents:tools execution completed\n2025-04-27 12:09:30,383 - DEBUG livekit.agents - tools execution completed {\"speech_id\": \"speech_8dd1356c2a6a\"}\n[Audio] cBook Pro Microphone [-53.34 dBFS] [#######-----------------------]DEBUG:livekit.plugins.google:usage metadata\n2025-04-27 12:09:30,991 - DEBUG livekit.plugins.google - usage metadata {\"usage_metadata\": \"prompt_token_count=1913 cached_content_token_count=None response_token_count=30 tool_use_prompt_token_count=None thoughts_token_count=None total_token_count=1943 prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.AUDIO: 'AUDIO'>, token_count=28), ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=1885)] cache_tokens_details=None response_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=30)] tool_use_prompt_tokens_details=None traffic_type=None\"}\n[Audio] cBook Pro Microphone [-62.88 dBFS] [###---------------------------]DEBUG:livekit.plugins.google:usage metadata\n2025-04-27 12:09:47,822 - DEBUG livekit.plugins.google - usage metadata {\"usage_metadata\": \"prompt_token_count=1058 cached_content_token_count=None response_token_count=400 tool_use_prompt_token_count=None thoughts_token_count=None total_token_count=1458 prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.AUDIO: 'AUDIO'>, token_count=14), ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=1044)] cache_tokens_details=None response_tokens_details=[ModalityTokenCount(modality=<MediaModality.AUDIO: 'AUDIO'>, token_count=400)] tool_use_prompt_tokens_details=None traffic_type=None\"}\n[Audio] cBook Pro Microphone [-58.30 dBFS] [#####------\n```\n\n```\n\nfrom function import load_prompt\nimport asyncio\nimport time\nfrom livekit.agents import (\n    JobContext,\n    WorkerOptions,\n    cli,\n    Agent,\n    AgentSession,\n    RunContext,\n    function_tool,\n    RoomInputOptions\n)\nimport math\n\n\nclass GreetingAgent(Agent):\n    def __init__(self):\n        print(\"[Debug] GreetingAgent.__init__ called\")\n        super().__init__(instructions=load_prompt('greeting_agent_prompt.yaml'))\n        print(\"[Debug] Prompt instructions loaded\")\n\n    async def on_enter(self):\n        print(\"[Debug] on_enter start\")\n        userdata = self.session.userdata\n        userdata.current_stage = \"greeting\"\n        print(f\"[Debug] current_stage set to {userdata.current_stage}\")\n\n        if not userdata.recipe:\n            print(\"[Debug] No recipe found in userdata\")\n            await self.session.generate_reply(instructions=\"Say this to user : Hello! I'm your Recipe Chef, but I seem to be missing the recipe details right now.\")\n            print(\"[Debug] generate_reply for missing recipe executed\")\n            return None\n\n        print(f\"[Debug] Found recipe: {userdata.recipe.name}\")\n        await self.session.generate_reply(instructions=f\"Say exact line to the user :-  Hello! I'm your Recipe Chef. I'll help you make {userdata.recipe.name}. First, how many servings would you like to prepare?\")\n        print(\"[Debug] generate_reply for recipe greeting executed\")\n        return None\n\n    async def calculate_ingredients(self, recipe, servings: int, session) -> None:\n        print(f\"[Debug] calculate_ingredients start for {servings} servings of {recipe.name}\")\n        scaling_factor = servings / recipe.base_servings\n        print(f\"[Debug] scaling_factor calculated: {scaling_factor}\")\n\n        ingredients_list = [f\"Okay, for {servings} servings of {recipe.name}, you will need:\"]\n        for ing in recipe.ingredients:\n            scaled_quantity = ing.quantity * scaling_factor\n            display_quantity = (\n                int(scaled_quantity)\n                if scaled_quantity == int(scaled_quantity)\n                else round(scaled_quantity, 1)\n                if scaled_quantity > 0.1\n                else scaled_quantity\n            )\n            if ing.unit == \"units\" and display_quantity != int(display_quantity):\n                display_quantity = math.ceil(scaled_quantity)\n\n            line = f\"- {display_quantity} {ing.unit} of {ing.name}\"\n            ingredients_list.append(line)\n            print(f\"[Debug] Ingredient line added: {line}\")\n\n        ingredient_text = \"\\n\".join(ingredients_list)\n        print(f\"[Debug] ingredient_text built: {ingredient_text}\")\n\n        await self.session.generate_reply(instructions=f\"Say this exact line to user : {ingredient_text}\")\n        print(\"[Debug] generate_reply for ingredients executed\")\n        return None\n\n    @function_tool()\n    async def set_servings_and_list_ingredients(self, servings: int, context: RunContext) -> None:\n        print(f\"[Debug] set_servings_and_list_ingredients start with servings={servings}\")\n        userdata = self.session.userdata\n        session = self.session\n\n        if not userdata.recipe:\n            print(\"[Debug] No recipe data; sending error reply\")\n            await session.generate_reply(instructions=\"Say this to user : I seem to have misplaced the recipe details.\")\n            return \"Error: Recipe data missing.\"\n\n        if servings <= 0:\n            print(\"[Debug] Invalid servings number; sending error reply\")\n            await self.session.generate_reply(instructions=\"Say this to user : Please provide a positive number for servings.\")\n            return \"Error: Invalid servings number.\"\n\n        print(f\"[Debug] Valid servings received: {servings}\")\n        userdata.servings = servings\n        print(f\"[Debug] userdata.servings set to {userdata.servings}\")\n\n        # Calculate and reply with ingredients\n        await self.calculate_ingredients(userdata.recipe, servings, session)\n\n        userdata.current_stage = \"handoff_to_prep\"\n        print(f\"[Debug] current_stage updated to {userdata.current_stage}\")\n        return None\n```",
      "state": "open",
      "author": "Manish06097",
      "author_type": "User",
      "created_at": "2025-04-30T07:04:38Z",
      "updated_at": "2025-06-17T03:18:10Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2165/reactions",
        "total_count": 3,
        "+1": 3,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2165",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2165",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:23.508234",
      "comments": [
        {
          "author": "ramon-prieto",
          "body": "This isn't working for me either on any gemini model",
          "created_at": "2025-05-02T17:35:44Z"
        },
        {
          "author": "dan-impaq",
          "body": "Having troubles with it too. Couldn't point out any pattern",
          "created_at": "2025-05-22T10:20:26Z"
        },
        {
          "author": "tusheet-geoiq",
          "body": "Not able to use generate_reply inside tool calls with the Gemini Realtime model. It works in the on_enter functions but inside the tool calls I always get this error - future: <Task finished name='AgentActivity.realtime_reply' coro=<AgentActivity._realtime_reply_task() done, defined at /home/ubuntu/",
          "created_at": "2025-05-30T03:24:38Z"
        },
        {
          "author": "samaksh-khatri-simform",
          "body": "I am getting the exact same error for realtime Azure OpenAI. Maybe it is an issue when using realtime models",
          "created_at": "2025-06-13T11:45:40Z"
        },
        {
          "author": "td2thinh",
          "body": "I'm pretty sure this is mentioned somewhere in the docs or in one of the examples but you need to call `session.interrupt()` to stop any current generation.",
          "created_at": "2025-06-16T13:53:34Z"
        }
      ]
    },
    {
      "issue_number": 1673,
      "title": "Guidance on Hybrid Integration of Gemini Realtime API with VoicePipelineAgent",
      "body": "Hi LiveKit team,\n\nI’m building an AI phone calling system for small and medium businesses (SMBs) using LiveKit Agents, with a focus on supporting a language with gender-specific grammar and requiring robust speech handling in noisy environments. I’m integrating Google’s Gemini Realtime Multimodal API (gemini-2.0-flash) for its combined STT and LLM capabilities, paired with Google TTS for voice output. My attempts to fit this into VoicePipelineAgent have hit significant hurdles, and I’d appreciate your advice on the best approach to achieve low latency, persistent session management, and interruption handling.\n\n\nI’ve chosen Gemini’s Realtime API over separate STT/LLM solutions for these reasons:\n\n1. Robust Speech Understanding: It excels in harsh environments (e.g., background noise), outperforming other STT options I’ve tested, which is critical for business calls.\n2. Emotional Tone Detection: It can interpret the user’s emotional state, vital for tailoring responses in a business context.\n3. Gender Recognition: In my language, many words are written identically but pronounced differently based on gender. Gemini detects male/female speakers, enabling my system instructions to address users correctly (e.g., adjusting grammar).\n4. Cost-Effectiveness: Combining STT and LLM in one model is the most economical solution I’ve found, reducing API costs significantly.\n\n\n\nFrom what I understand, LiveKit Agents supports two main integration paths:\n\n1. Realtime API (e.g., livekit.plugins.google.beta.realtime_api):\nDirect use of RealtimeModel and GeminiRealtimeSession for audio input and text output.\nGreat for low-latency, unified STT/LLM processing, but lacks built-in TTS or interruption handling.\n\n2. VoicePipelineAgent:\nStructured STT → LLM → TTS pipeline with VAD-based interruptions (e.g., using Silero VAD).\nIdeal for TTS integration and conversation flow, but assumes separate STT and LLM components.\n\nI’m trying to create a hybrid:\n\n- Use Gemini’s Realtime API for audio input, generating both transcription (for logging) and response (for TTS) in one stream.\n- Leverage VoicePipelineAgent’s TTS and VAD-based interruption handling (e.g., user says “wait” to stop TTS).\n\n\nMy attempts to combine these approaches have been problematic:\n\n1. Dummy STT + LLM-Driven:\nSTT emits placeholders, LLM feeds audio to Gemini and streams responses.\n\n2. Combined Output Parsing:\nPrompt Gemini to output (transcription) Response: response, parsed by adapters.\n\n3. Separate STT/LLM Adapters:\nSTT uses input_speech_transcription_completed, LLM uses response_content_added.\n\n\nThe core problem is losing VoicePipelineAgent’s interruption handling when leaning on Realtime’s unified output, but attempts to marry them raise more issues than they solve.\n\n\nOptions I’m Considering\n\n1. Custom Agent:\n\n- Build a new agent directly using RealtimeModel, handling audio, Gemini events, TTS, and VAD interruptions.\n- Pros: Low latency, full control over Gemini’s stream.\n- Cons: High effort, loses pipeline features (e.g., function calls).\n- Question: Is this a practical solution, or overkill for my use case?\n\n2. Separate STT/LLM Plugins:\n\n- Modify livekit/plugins/google/ to add GoogleRealtimeSTT and GoogleRealtimeLLM, sharing one GeminiRealtimeSession tied to room lifecycle.\n- Pros: Fits pipeline, cleaner session management.\n- Cons: Potential session conflicts or event timing issues.\n- Question: Is sharing a session across plugins viable? Any known risks with GeminiRealtimeSession?\n\n3. Refined Hybrid Parsing:\n\n- Stick with adapters, improving buffering/parsing of Gemini’s combined output.\n- Pros: Simple, uses pipeline.\n- Cons: Fragile parsing, slight latency hit.\n- Question: Can VoicePipelineAgent be adapted to handle unified STT/LLM output better?\n\n\nI’d love your perspective on:\n\n1. Best Approach: Which option aligns best with LiveKit Agents for my hybrid needs? Any you’d recommend?\n2. Session Persistence: How should I keep a GeminiRealtimeSession open across a room’s lifecycle? Is a manager class (e.g., tied to JobContext) the right approach?\n3. Event Sync: Gemini lacks a “response complete” event—any tips for aligning its streaming output with VoicePipelineAgent’s flow?\n4. Pipeline Flexibility: Are there ways to tweak VoicePipelineAgent to support a combined STT/LLM model without breaking interruption handling?\n5. Alternatives: If VoicePipelineAgent isn’t ideal, what’s a lighter LiveKit abstraction for custom realtime AI flows with WebRTC?",
      "state": "open",
      "author": "JosephDahan",
      "author_type": "User",
      "created_at": "2025-03-18T16:14:37Z",
      "updated_at": "2025-06-17T01:41:45Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1673/reactions",
        "total_count": 5,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 3
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1673",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1673",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:23.728254",
      "comments": [
        {
          "author": "thsunkid",
          "body": "Bump. I think this is an important question to address. \n\nThe realtime API solution captures other speech dimensions that STT can’t yet, but it’s not capable enough right now to operate alone unless we chain it with TTS or an LLM. This especially is true if the task instruction is 'heavy'.",
          "created_at": "2025-04-20T16:51:35Z"
        },
        {
          "author": "amfleming",
          "body": "Hey this is super important, and it's **not** a question; this a feature, and the feature is \n### Support the Gemini Realtime models, in Half Duplex, with Tool Calling\n\n @longcw @JosephDahan @theomonnom \n\nGemini refers to this as \"Half Cascade\" but we might also call is \"Half Duplex\", and it is **th",
          "created_at": "2025-06-17T01:07:23Z"
        },
        {
          "author": "amfleming",
          "body": "I would definitely not consider this work complete until and unless there is a clean example in `livekit/examples/agents`\n",
          "created_at": "2025-06-17T01:09:08Z"
        },
        {
          "author": "longcw",
          "body": "@amfleming realtime model (audio in, text out) with a separate TTS model is on our roadmap.",
          "created_at": "2025-06-17T01:41:45Z"
        }
      ]
    },
    {
      "issue_number": 2522,
      "title": "Metrics Latency Calculation",
      "body": "In previous versions of Livekit, there were Pipeline{STT, TTS, LLM, VAD}Metrics types that allowed me to compute latency, since each metric could be traced to a specific sequence_id kicked off by a user's utterance. However, recent versions of Livekit no longer have these types implemented. How do I trace a specific STTMetric, TTSMetric and LLMMetric to the same sequence kicked off by an STT event so I can compute latency among other things? Thank you!",
      "state": "open",
      "author": "chow-vincent",
      "author_type": "User",
      "created_at": "2025-06-05T23:32:11Z",
      "updated_at": "2025-06-16T21:19:09Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2522/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2522",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2522",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:23.943185",
      "comments": [
        {
          "author": "ChenghaoMou",
          "body": "You probably can use the EOU metric instead: https://docs.livekit.io/agents/build/metrics/#end-of-utterance-eou- with `@session.on(\"metrics_collected\")`.\n\nEven though it says \"This event is only available in Realtime APIs when turn_detection is set to either VAD or LiveKit's turn detector plugin.\" i",
          "created_at": "2025-06-06T13:43:27Z"
        },
        {
          "author": "yuyuma",
          "body": "Related: #1999 ",
          "created_at": "2025-06-16T21:19:09Z"
        }
      ]
    },
    {
      "issue_number": 2384,
      "title": "BackgroundAudioPlayer example errors out on latest livekit dependencies",
      "body": "[Background audio player example](https://github.com/livekit/agents/blob/main/examples/voice_agents/background_audio.py) is failing with the following error.\n\n```\n2025-05-22 16:15:35,623 - INFO livekit.agents - received job request {\"job_id\": \"AJ_dCmbTthnkoHK\", \"dispatch_id\": \"\", \"room_name\": \"livekit-web-20250522T2315-5biVPw-DEVTEST\", \"agent_name\": \"\", \"resuming\": false}\n2025-05-22 16:15:37,054 - INFO livekit.agents - initializing process {\"pid\": 1892205}\n2025-05-22 16:15:37,070 - INFO livekit.agents - process initialized {\"pid\": 1892205, \"elapsed_time\": 0.02}\n2025-05-22 16:15:37,070 - DEBUG asyncio - Using selector: EpollSelector {\"pid\": 1892205, \"job_id\": \"AJ_dCmbTthnkoHK\"}\n2025-05-22 16:15:38,695 - DEBUG livekit.agents - http_session(): creating a new httpclient ctx {\"pid\": 1892205, \"job_id\": \"AJ_dCmbTthnkoHK\"}\n2025-05-22 16:15:38,699 - DEBUG livekit.agents - start reading stream {\"participant\": \"guest_-1bTlh2g\", \"source\": \"SOURCE_MICROPHONE\", \"pid\": 1892205, \"job_id\": \"AJ_dCmbTthnkoHK\"}\n2025-05-22 16:15:49,206 - ERROR livekit - livekit::rtc_engine::rtc_session:507:livekit::rtc_engine::rtc_session - signal_event taking too much time: Answer(SessionDescription { r#type: \"answer\", sdp: \"v=0\\r\\no=- 6898906946367908073 1747955739 IN IP4 0.0.0.0\\r\\ns=-\\r\\nt=0 0\\r\\na=msid-semantic:WMS*\\r\\na=fingerprint:sha-256 84:85:49:92:B4:1D:C1:B4:4E:13:42:83:D0:49:74:F2:A0:43:5C:37:60:20:B8:73:D1:47:D4:CB:E9:F6:3D:CB\\r\\na=ice-lite\\r\\na=extmap-allow-mixed\\r\\na=group:BUNDLE 0 1\\r\\nm=audio 9 UDP/TLS/RTP/SAVPF 63 111\\r\\nc=IN IP4 0.0.0.0\\r\\na=setup:active\\r\\na=mid:0\\r\\na=ice-ufrag:LXBNCayiRAzAZXXW\\r\\na=ice-pwd:knSVnnajnxZXNjZuBGlBsNChryBtPKEQ\\r\\na=rtcp-mux\\r\\na=rtcp-rsize\\r\\na=rtpmap:63 red/48000/2\\r\\na=fmtp:63 111/111\\r\\na=rtpmap:111 opus/48000/2\\r\\na=fmtp:111 minptime=10;useinbandfec=1;usedtx=1\\r\\na=rtcp-fb:111 nack \\r\\na=extmap:1 urn:ietf:params:rtp-hdrext:ssrc-audio-level\\r\\na=extmap:4 urn:ietf:params:rtp-hdrext:sdes:mid\\r\\na=recvonly\\r\\nm=application 9 UDP/DTLS/SCTP webrtc-datachannel\\r\\nc=IN IP4 0.0.0.0\\r\\na=setup:active\\r\\na=mid:1\\r\\na=sendrecv\\r\\na=sctp-port:5000\\r\\na=max-message-size:65535\\r\\na=ice-ufrag:LXBNCayiRAzAZXXW\\r\\na=ice-pwd:knSVnnajnxZXNjZuBGlBsNChryBtPKEQ\\r\\n\" }) {\"pid\": 1892205, \"job_id\": \"AJ_dCmbTthnkoHK\"}\n```\n\nUsing the latest livekit dependencies:\n\n```\nlivekit==1.0.8\nlivekit-agents==1.0.22\nlivekit-api==1.0.2\nlivekit-plugins-google==1.0.22\nlivekit-plugins-noise-cancellation==0.2.4\nlivekit-plugins-openai==1.0.22\nlivekit-plugins-silero==1.0.22\nlivekit-plugins-turn-detector==1.0.22\nlivekit-protocol==1.0.3\n```",
      "state": "closed",
      "author": "yuyuma",
      "author_type": "User",
      "created_at": "2025-05-23T15:48:14Z",
      "updated_at": "2025-06-16T21:16:21Z",
      "closed_at": "2025-06-16T21:16:21Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2384/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2384",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2384",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:24.201477",
      "comments": [
        {
          "author": "longcw",
          "body": "Does other examples work for you? It seems to be a connection issue instead of the background audio player issue.",
          "created_at": "2025-05-24T02:34:39Z"
        },
        {
          "author": "yuyuma",
          "body": "Yes other examples work for me, and I don't have any issues either with a complex multi-agent project I'm working on.\n\nThis same background_audio.py example works as well if I simply comment out `await background_audio.start(room=ctx.room, agent_session=session)`\n\nIf you can clarify what connection ",
          "created_at": "2025-05-24T02:54:17Z"
        },
        {
          "author": "yuyuma",
          "body": "@longcw I remember this same example worked for me when 1.0 first came out. I just tested further and the last version where I was able to run this successfully was `livekit-agents==1.0.18`.  All releases since fails. Hope this helps.",
          "created_at": "2025-05-27T00:40:15Z"
        },
        {
          "author": "yuyuma",
          "body": "Not seeing this issue anymore on the latest version 1.1.1.  Closing.",
          "created_at": "2025-06-16T21:16:21Z"
        }
      ]
    },
    {
      "issue_number": 2478,
      "title": "AWS STT ( Transcribe ) Timeout",
      "body": "I had previously opened a ticket regarding this. That was marked closed but the issue still persists. \nHere is the comparison of the behaviour of the previous and the new version\n\n**Context**\nWe are building a voice AI assistant for German healthcare centers, and we need to give a long message before we proceed to the AI assisted workflow.\n\n**Previous**\nIn the previous behave the AWS transcribe was throwing errors. Post a message reached 15 seconds of length and the flow stop responding.\n\n**Curent**\nHowever, in the newer implementations, the transcribe is not throwing any errors and the system simply hangs so our issue to say long consent messages during the start of the call still persists.\n\n",
      "state": "open",
      "author": "NIGAMAR",
      "author_type": "User",
      "created_at": "2025-06-02T02:24:21Z",
      "updated_at": "2025-06-16T16:13:13Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2478/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2478",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2478",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:24.476823",
      "comments": [
        {
          "author": "j-beniwal",
          "body": "Hi facing the same issue, need help. ",
          "created_at": "2025-06-16T16:13:12Z"
        }
      ]
    },
    {
      "issue_number": 2607,
      "title": "Bug: TTS interruption causes discrepancy between spoken audio and displayed chat text",
      "body": "**Describe the bug**\nWhen a user interrupts the agent's Text-to-Speech (TTS) stream, a discrepancy occurs between the final text that is displayed and added to the chat context, and the audio that was actually spoken. The displayed text consistently includes 1-2 more words than what the user heard before the interruption was triggered.\n\nThis pollutes the chat context with text that the user never received audibly, which can confuse the LLM in subsequent turns.\n\n**Steps to Reproduce**\n1.  Initiate a conversation with an agent using a streaming TTS provider.\n2.  Receive a response from the agent that is long enough to be interruptible.\n3.  While the agent's TTS is playing, interrupt it by starting to speak.\n4.  Observe the final text message from the agent as it is reflected in the chat history.\n5.  Compare the displayed text to the actual words spoken by the TTS audio before it was cut off.\n\n**Expected Behavior**\nThe text added to the chat context should precisely match the words that were audibly synthesized and played by the TTS engine before the interruption occurred.\n\n**Actual Behavior**\nThe final text in the chat context is consistently longer than the spoken audio. For example, if the agent intended to say \"The weather today is sunny with a high of 25 degrees\" and was interrupted after speaking the word \"sunny\", the chat context might incorrectly save the text as \"The weather today is sunny with a...\".\n\n**Environment**\n* **Library Version:** `livekit-agents` v1.1.1\n* **TTS Providers:** This issue has been confirmed to happen with both **ElevenLabs** and **Cartesia**, indicating the problem is likely in the core TTS interruption handling logic and not specific to one provider.",
      "state": "open",
      "author": "hsjun99",
      "author_type": "User",
      "created_at": "2025-06-16T03:40:51Z",
      "updated_at": "2025-06-16T07:37:17Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2607/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2607",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2607",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:24.718110",
      "comments": [
        {
          "author": "longcw",
          "body": "It's the error from agent transcription/audio sync. The sync is not perfect so the transcript may slightly faster or slower than the audio playout. This pr https://github.com/livekit/agents/pull/2580 will improve the sync quality for supported TTS (cartesia and non-streaming tts using StreamAdatper)",
          "created_at": "2025-06-16T07:29:23Z"
        },
        {
          "author": "hsjun99",
          "body": "@longcw Thanks for the reply. Looking forward to it being deployed.",
          "created_at": "2025-06-16T07:37:17Z"
        }
      ]
    },
    {
      "issue_number": 1692,
      "title": "Deploy livekit agent to Google cloud run problems",
      "body": "I deployed my voice agent in google cloud run. Sometimes, after a few minutes' conversation, the agent stops responding, moments later it starts a new conversation.\nI see error message \"Default STARTUP TCP probe failed 1 time consecutively for container \"agent-1\" on port 8080. The instance was not started. Timed out after 4m.\" when this happens.  \nThis doesn't happen on my local sand-box. Has anyone deployed your livekit agent in Google cloud run? how to set grace period in Google cloud run?  I didn't see Google cloud in agent deployment examples. Is Google cloud run a good platform for this task?\n",
      "state": "closed",
      "author": "LaVivien",
      "author_type": "User",
      "created_at": "2025-03-20T23:15:26Z",
      "updated_at": "2025-06-16T04:10:53Z",
      "closed_at": "2025-03-30T06:51:04Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 13,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1692/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1692",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1692",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:24.997074",
      "comments": [
        {
          "author": "LaVivien",
          "body": "Can I ask your advice whether render.com's background workers is a good platform to host livekit agents? It is urgent. Thanks in advance!",
          "created_at": "2025-03-25T12:00:04Z"
        },
        {
          "author": "ChenghaoMou",
          "body": "Never used Google Run before, but it looks like it is expecting a status endpoint exposed at 8080. I don't think you can disable it, so you can start a dummy web server at that port to skip the health probe.",
          "created_at": "2025-03-25T16:40:07Z"
        },
        {
          "author": "LaVivien",
          "body": "I do expose 8080. The agent can run a few minutes with normal conversations. But after that,  the conversation stops. Then after a few seconds, it restarts with the greeting I set. To me it looks like the old session stops for some reason, then start a new session with the same user.",
          "created_at": "2025-03-25T16:57:26Z"
        },
        {
          "author": "ChenghaoMou",
          "body": "But are you running anything at 8080 at all? Based on the error message, the port isn't responding to the health probe queries.",
          "created_at": "2025-03-25T22:21:48Z"
        },
        {
          "author": "longcw",
          "body": "Yes, it seems it's the Google cloud run failed to check the health of the container so it was closed by google cloud run. Did you set the 8080 as the entrypoint in somewhere of google cloud run?",
          "created_at": "2025-03-26T02:21:42Z"
        }
      ]
    },
    {
      "issue_number": 2581,
      "title": "PTT: Groq STT returning empty transcripts if end_turn called before STT completes",
      "body": "When using the LiveKit push-to-talk example with Groq STT, if end_turn is triggered before the user's audio has been transcribed, the transcript is lost — `on_user_turn_completed` is called with an empty transcript.\n\nRepro Steps:\n\n1. Call start_turn → audio is enabled\n2. User speaks\n3. Call end_turn before STT finishes\n4. commit_user_turn is called, but transcript is empty",
      "state": "closed",
      "author": "s-hamdananwar",
      "author_type": "User",
      "created_at": "2025-06-12T08:05:10Z",
      "updated_at": "2025-06-16T01:27:05Z",
      "closed_at": "2025-06-16T01:27:05Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2581/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "longcw"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2581",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2581",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:25.265564",
      "comments": []
    },
    {
      "issue_number": 2585,
      "title": "Event Loop availability in initialize/prewarm",
      "body": "I would like to pre-compute & set up various asyncio constructs in prewarm. However, that doesn't work due to the event loop being created in _ProcClient.run...which runs after _ProcClient.initialize.\n\nWould you consider starting the event loop in _ProcClient.initialize before initialize_fnc is called? It would help with avoiding workarounds. Or is there a reason to not make the asyncio event loop available?",
      "state": "open",
      "author": "btakita",
      "author_type": "User",
      "created_at": "2025-06-12T17:22:50Z",
      "updated_at": "2025-06-14T07:11:32Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2585/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 1
      },
      "assignees": [
        "theomonnom"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2585",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2585",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:25.265587",
      "comments": []
    },
    {
      "issue_number": 2561,
      "title": "Selecting a model while using Assembly AI",
      "body": "Hello everyone, currently we can use different models in [AssemblyAI's API](https://www.assemblyai.com/docs/speech-to-text/pre-recorded-audio/select-the-speech-model) although it is not supported in the livekit plugin yet ([source](https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-assemblyai/livekit/plugins/assemblyai/stt.py)).\n\nIs there a way to specify the model and language? or would one have to modify the plugin like this:\n\n```diff\n@dataclass\nclass STTOptions:\n    sample_rate: int\n    buffer_size_seconds: float\n    word_boost: NotGivenOr[list[str]] = NOT_GIVEN\n    word_finalization_max_wait_time: NotGivenOr[int] = NOT_GIVEN\n    end_of_turn_confidence_threshold: NotGivenOr[float] = NOT_GIVEN\n    min_end_of_turn_silence_when_confident: NotGivenOr[int] = NOT_GIVEN\n    max_turn_silence: NotGivenOr[int] = NOT_GIVEN\n+    speech_model: str = NOT_GIVEN\n+    language: str = NOT_GIVEN\n...\n\nclass STT(stt.STT):\n    def __init__(\n        self,\n        *,\n        api_key: NotGivenOr[str] = NOT_GIVEN,\n+       speech_model: str = \"slam-1\",\n+       language: str = \"en\",\n        sample_rate: int = 16000,\n        word_boost: NotGivenOr[list[str]] = NOT_GIVEN,\n        word_finalization_max_wait_time: NotGivenOr[int] = NOT_GIVEN,\n        end_of_turn_confidence_threshold: NotGivenOr[float] = NOT_GIVEN,\n        min_end_of_turn_silence_when_confident: NotGivenOr[int] = NOT_GIVEN,\n        max_turn_silence: NotGivenOr[int] = NOT_GIVEN,\n        formatted_finals: NotGivenOr[bool] = NOT_GIVEN,\n        http_session: aiohttp.ClientSession | None = None,\n        buffer_size_seconds: float = 0.05,\n    ):\n       ...\n        self._opts = STTOptions(\n+            speech_model=speech_model,\n+            language=language,\n        ...\n        )\n        ...\n\n```\n\nif that's the case, I can just open up a PR.",
      "state": "closed",
      "author": "alperiox",
      "author_type": "User",
      "created_at": "2025-06-11T09:07:18Z",
      "updated_at": "2025-06-14T06:34:22Z",
      "closed_at": "2025-06-14T06:34:22Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2561/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2561",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2561",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:25.265594",
      "comments": [
        {
          "author": "ChenghaoMou",
          "body": "I don't think the Slam model supports streaming audio yet.",
          "created_at": "2025-06-11T10:31:16Z"
        },
        {
          "author": "alperiox",
          "body": "yeah I think so too, actually I had just randomly written one. was actually asking about using the api parameters like that. ",
          "created_at": "2025-06-11T11:49:06Z"
        },
        {
          "author": "ChenghaoMou",
          "body": "> yeah I think so too, actually I had just randomly written one. was actually asking about using the api parameters like that. \n\nI see. I couldn't find any model related parameters in their docs for streaming: https://www.assemblyai.com/docs/api-reference/streaming-api/streaming-api. Not sure it is ",
          "created_at": "2025-06-13T04:41:39Z"
        }
      ]
    },
    {
      "issue_number": 2602,
      "title": "Task exception was never retrieved from FallbackAdapter on OpenAI STT timeout",
      "body": "LiveKit Version: **1.1.1**\nEnvironment: **Python, livekit-agents**\nSTT Config: **Using FallbackAdapter with multiple openai.STT models (gpt-4o-transcribe, gpt-4o-mini-transcribe, whisper-1)**\n\nObserved Behavior: **When the OpenAI STT stream fails or times out (e.g., due to network issue or client disconnect), an unhandled RuntimeError is raised inside a background task in fallback_adapter.py, and no error handler or session recovery logic gets triggered.**\n\nError Output\n`Task exception was never retrieved\nfuture: <Task finished name='Task-37' coro=<FallbackRecognizeStream._run.<locals>._forward_input_task() ...> exception=RuntimeError('livekit.plugins.openai.stt.SpeechStream input ended')>\nTraceback (most recent call last):\n  File \".../fallback_adapter.py\", line 282, in _forward_input_task\n    main_stream.end_input()\n  File \".../stt.py\", line 354, in end_input\n    self.flush()\n  File \".../stt.py\", line 343, in flush\n    self._check_input_not_ended()\n  File \".../stt.py\", line 387, in _check_input_not_ended\n    raise RuntimeError(f\"{cls.__module__}.{cls.__name__} input ended\")\nRuntimeError: livekit.plugins.openai.stt.SpeechStream input ended`\n\n\n**Agent Setup (simplified)**\n\n```\nsession = AgentSession(\n    vad=silero.VAD.load(min_silence_duration=0.7, activation_threshold=0.6, min_speech_duration=0.3),\n    stt=stt.FallbackAdapter([\n        openai.STT(model=\"gpt-4o-transcribe\", detect_language=detect, use_realtime=True),\n        openai.STT(model=\"gpt-4o-mini-transcribe\", detect_language=detect, use_realtime=True),\n        openai.STT(model=\"whisper-1\", detect_language=detect, use_realtime=True),\n    ])\n)\n\nsession.on(\"error\", session_error_handler)\n```\n\n**session_error_handler**\n\n```\ndef session_error_handler(ev: ErrorEvent):\n    if ev.error.recoverable:\n        return\n\n    print(f\"Session closing due to unrecoverable error: {ev.error}\")\n    \n    if isinstance(ev.source, stt.STT):\n        session.update_agent(session.current_agent)\n        ev.error.recoverable = True\n        return\n```\n\n\n**Problem Summary**\n\n- The exception is raised inside _forward_input_task in FallbackAdapter when main_stream.end_input() is called after the stream has already ended.\n- The exception is not caught or propagated to the error event handler registered with the session.\n- This causes asyncio: Task exception was never retrieved warnings and missed recovery opportunities.\n\n\n**Expected Behavior**\n\nEither:\n1. The FallbackAdapter should catch main_stream.end_input() exceptions gracefully and raise them via the session’s error event.\n2. Or, the application should be able to override or hook into _forward_input_task to restart sessions manually when this occurs.\n\n\n**Questions**\n\n- Is this behavior expected and should it be manually caught outside the session lifecycle?\n- Is there a recommended way to handle STT session recovery when using FallbackAdapter, especially when the primary STT fails?\n- Should the FallbackAdapter propagate the failure upstream instead of leaking it silently via asyncio?\n\n\n",
      "state": "open",
      "author": "dragos-emotii",
      "author_type": "User",
      "created_at": "2025-06-13T13:39:31Z",
      "updated_at": "2025-06-13T13:53:25Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2602/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2602",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2602",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:25.497008",
      "comments": [
        {
          "author": "longcw",
          "body": "It should be fixed in https://github.com/livekit/agents/pull/2597 by close the vad stream in stt StreamAdapter https://github.com/livekit/agents/pull/2597/files#diff-ab5f1de6fc57afe6e42f4687e5220a68e6cb52bfee902050068afd2035ddf4f4",
          "created_at": "2025-06-13T13:51:50Z"
        }
      ]
    },
    {
      "issue_number": 2600,
      "title": "Using Mistral with LiveKit Agent Framework",
      "body": "Hi LiveKit team!\n\nI’m interested in using the agent framework with my Mistral account: https://docs.mistral.ai/getting-started/quickstart\n\nMistral doesn’t appear to be supported as a plugin. Is there a straightforward way to use it for the LLM component, or would it make sense to integrate it as a plugin?\n\nAppreciate your time, thanks!",
      "state": "open",
      "author": "niqodea",
      "author_type": "User",
      "created_at": "2025-06-13T12:34:13Z",
      "updated_at": "2025-06-13T12:34:13Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2600/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2600",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2600",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:25.728901",
      "comments": []
    },
    {
      "issue_number": 1223,
      "title": "Expose instructions getter in realtime session?",
      "body": "I have a pattern where I update system prompt / instructions dynamically during the course of a conversation with realtime agent.\r\n\r\nI'd like to do a simple check to compare updated instructions with existing instructions, however its private behind `_opts`.\r\n\r\nSince instructions is initially a consumer-facing property during initialization, maybe it should be accessible afterwards with a public getter?\r\n\r\nThis is a pretty minor thing, I can always have a duplicate copy on my application side, but it adds some duplicative memory footprint when the prompt is particularly long.\r\n\r\nHowever could be a simple change in `realtime.py` like this:\r\n```\r\nclass RealtimeSession(utils.EventEmitter[EventTypes]):\r\n    @property\r\n    def instructions(self) -> str:\r\n        return self._opts.instructions\r\n```\r\n\r\nSorry for bug label, it won't let me create an issue any other way.",
      "state": "closed",
      "author": "willsmanley",
      "author_type": "User",
      "created_at": "2024-12-13T00:49:09Z",
      "updated_at": "2025-06-13T10:42:43Z",
      "closed_at": "2025-06-13T10:42:43Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1223/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 1,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1223",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1223",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:25.728922",
      "comments": []
    },
    {
      "issue_number": 1215,
      "title": "How to make agents stop speaking when sending a new message",
      "body": "Hi livekit team,\r\nI tried to use the event from voice_pipeline_agent\r\n` @chat.on(\"message_received\")\r\n    def on_chat_received(msg: rtc.ChatMessage):`\r\n    \r\nI want to interrupt agent speaking when the new message sent to agent. How to achieve this ?\r\nUsing following code is not working, It will wait the agent to complete its speech\r\n`    async def answer_from_text(txt: str):\r\n        # chat_ctx = agent.chat_ctx.copy()\r\n        agent.chat_ctx.append(role=\"user\", text=txt)\r\n        stream = agent.llm.chat(chat_ctx=agent.chat_ctx, fnc_ctx=fnc_ctx)\r\n        logger.info(f\"Chat Context Log: ${agent.chat_ctx}\")\r\n        await agent.say(stream, allow_interruptions=True)`\r\n\r\nBest regards",
      "state": "closed",
      "author": "AkiThuong",
      "author_type": "User",
      "created_at": "2024-12-12T10:42:47Z",
      "updated_at": "2025-06-13T10:42:43Z",
      "closed_at": "2025-06-13T10:42:43Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1215/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1215",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1215",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:25.728929",
      "comments": []
    },
    {
      "issue_number": 2598,
      "title": "Azure OpenAI Realtime VAD appears to be broken",
      "body": "Hey there,\n\nit seems like the VAD when using the Azure OpenAI Realtime API using `with_azure()` does not work as intended.\nIt doesn't seem to respect the `silence_duration_ms` properly as changing this value does not seem to have any impact. It starts to interrupt the user at any minor silence no matter what the `silence_duration_ms` is set to. It already acted weird in `1.0.x` but its really extreme on `1.1.0`",
      "state": "open",
      "author": "GigaDroid",
      "author_type": "User",
      "created_at": "2025-06-13T09:47:24Z",
      "updated_at": "2025-06-13T09:47:24Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2598/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2598",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2598",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:25.728934",
      "comments": []
    },
    {
      "issue_number": 2537,
      "title": "“Task was destroyed but it is pending” asyncio Errors on Windows Azure VM",
      "body": "When running a LiveKit Agent on a Windows Azure VM, we encountered persistent asyncio-related errors during shutdown, such as:\n\n```\nTask was destroyed but it is pending!\nRuntimeError: no running event loop\n```\nSwitching to a Linux VM (Ubuntu) immediately resolved all issues, using the exact same codebase.\n\n**Environment**\n\n- OS (failing): Windows Server 2022, hosted on Azure VM\n- OS (working): Ubuntu 22.04, hosted on Azure VM\n- Python: 3.11\n- Async backend: asyncio (native)\n- Custom codebase: https://github.com/nakshat-ra/Project_Code\n- Log file: [Asyncio Error Log on Windows](https://docs.google.com/document/d/1rQ1sYBf7QV_BKw7Du3M-V41_uWBbKwokJI9HgbRFhjA/edit?usp=sharing)\n\n**Steps to Reproduce**\n\n1. Deploy an agent using the LiveKit Agents SDK on a Windows VM\n2. Integrate custom STT, TTS, and LLM providers via backend (STT/LLM created globally or reused across agents)\n3. Join a room, then disconnect with a deleteRoom backend call\n4. Observe errors when all agents disconnect\n\n**Error Logs (Excerpt)**\n```\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-421' coro=<VoicePipelineAgent._main_task()...>>\n\nRuntimeError: no running event loop\n\nException ignored in: <coroutine object HumanInput._recognize_task ...>\n...\nFile \".../aio/__init__.py\", line 12, in gracefully_cancel\nloop = asyncio.get_running_loop()\nRuntimeError: no running event loop\n```\n\nFull logs here: [Google Doc with logs](https://docs.google.com/document/d/1rQ1sYBf7QV_BKw7Du3M-V41_uWBbKwokJI9HgbRFhjA/edit?usp=sharing)\n\n**Mitigations Attempted**\n\n- Increased VM spec to 4 vCores → no change\n- Moved STT/TTS/LLM object instantiation into entrypoint() → reduced conflicts\n- Removed deleteRoom call and instead allowed passive disconnection → same errors\n- Switched to Linux VM → all issues disappeared\n\n**Request**\nThis seems like a platform-specific bug in how asyncio is handled in the shutdown phase on Windows. If reproducible in a smaller agent, I'm happy to help file a minimal repro.\n\nWould be great if this could be looked into or documented as a platform caveat.\n\nThanks!\n",
      "state": "open",
      "author": "naksh-atra",
      "author_type": "User",
      "created_at": "2025-06-09T09:39:36Z",
      "updated_at": "2025-06-13T07:06:55Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2537/reactions",
        "total_count": 3,
        "+1": 3,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2537",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2537",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:25.728941",
      "comments": [
        {
          "author": "theomonnom",
          "body": "It looks like those tasks are only on our 0.x versions (`VoicePipelineAgent`). I strongly recommend upgrading your app to 1.0.",
          "created_at": "2025-06-13T07:06:55Z"
        }
      ]
    },
    {
      "issue_number": 2517,
      "title": "server panic if calling non-exists rpc in tool",
      "body": "```bash\n/lib/python3.12/site-packages/livekit/agents/llm/utils.py:389: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n  for name, field in model.model_fields.items():\n\nthread 'tokio-runtime-worker' panicked at /rustc/17067e9ac6d7ecb70e50f92c1944e545188d2359/library/core/src/time.rs:1126:31:\noverflow when subtracting durations\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\nFFI Panic:  task 335 panicked\n\nthread 'tokio-runtime-worker' panicked at livekit-ffi/src/server/mod.rs:269:21:\nwatch_panic: task panicked\n2025-06-05 18:55:31,572 - DEBUG livekit.agents - executing tool {\"room\": \"xxxx\", \"function\": \"web_search\", \"arguments\": \"{\\\"queries\\\":[\\\"xxxx\"]}\", \"speech_id\": \"speech_f786d6089f69\", \"pid\": 76169, \"job_id\": \"AJ_vMHqxrUgiwgm\"}\n\n2025-06-05 18:55:31,574 - ERROR livekit - livekit_ffi::server:267:livekit_ffi::server - task panicked: JoinError::Panic(Id(335), ...)\n```\n```python\n@function_tool\nasync def web_search(\n  ctx: RunContext[AppData],\n  queries: Annotated[list[str], Field(description='web search queries')],\n) -> str:\n  room = get_job_context().room\n  participant_identity = next(iter(room.remote_participants))\n  start = time.time()\n  try:\n    response = await room.local_participant.perform_rpc(\n      destination_identity=participant_identity,\n     # frontend newly deploy this (so some old app may not have it)\n      method='chat_notification',\n      payload=orjson.dumps(\n        {'text': '正在检索信息...', 'progressing': True, 'cleanup': True}\n      ),\n      response_timeout=0.5,\n    )\n  except:\n    main_logger.exception(\n      'web search notification failed, participant %s',\n      participant_identity,\n    )\n  else:\n    main_logger.info(\n      'web search notification response: %s',\n      response,\n    )\n  finally:\n    main_logger.info(\n      'web search notification took %.2f seconds',\n      time.time() - start,\n    )\n```",
      "state": "closed",
      "author": "DeoLeung",
      "author_type": "User",
      "created_at": "2025-06-05T11:14:08Z",
      "updated_at": "2025-06-13T07:02:18Z",
      "closed_at": "2025-06-13T07:02:18Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2517/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2517",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2517",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:25.919937",
      "comments": [
        {
          "author": "theomonnom",
          "body": "Hey, this should be fixed when using livekit>=1.0.9 (our rtc package)",
          "created_at": "2025-06-13T07:02:18Z"
        }
      ]
    },
    {
      "issue_number": 2560,
      "title": "Agent unable to play audio when BackgroundAudioPlayer is playing, and vice versa",
      "body": "This can be replicated by running `examples/voice_agents/background_audio.py`, depending on a race condition either the Agent will be able to play audio or the BackgroundAudioPlayer will be able to play audio.\n\nI've tried manually adding an AudioSource and publishing a track, which also seems to mute the Agent, so I suspect there's some conflict with additional tracks alongside the Agent.",
      "state": "closed",
      "author": "jamessha",
      "author_type": "User",
      "created_at": "2025-06-11T04:42:48Z",
      "updated_at": "2025-06-12T23:46:18Z",
      "closed_at": "2025-06-12T23:46:17Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2560/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2560",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2560",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:26.131327",
      "comments": [
        {
          "author": "theomonnom",
          "body": "Hey, this may be a client-side issue, which frontend/client sdk are you using? ",
          "created_at": "2025-06-11T21:11:27Z"
        },
        {
          "author": "jamessha",
          "body": "Good call, seems like this is occurring in the javascript sdk, and doesn't happen when I dial in with SIP. I'll move the issue there.",
          "created_at": "2025-06-12T23:46:17Z"
        }
      ]
    },
    {
      "issue_number": 2333,
      "title": "BackgroundAudioPlayer sometimes raises aclose(): asynchronous generator is already running",
      "body": "```\nfuture: <Task finished name='Task-17257' coro=<BackgroundAudioPlayer._play_task() done, defined at /opt/anaconda3/lib/python3.12/site-packages/livekit/agents/utils/log.py:13> exception=RuntimeError('aclose(): asynchronous generator is already running')>\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.12/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/lib/python3.12/site-packages/livekit/agents/voice/background_audio.py\", line 355, in _play_task\n    await gen.aclose()\nRuntimeError: aclose(): asynchronous generator is already running {\"pid\": 5\n```\nIt seems to be an issue when closing the async generator",
      "state": "open",
      "author": "longcw",
      "author_type": "User",
      "created_at": "2025-05-20T02:14:36Z",
      "updated_at": "2025-06-12T15:07:17Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2333/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2333",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2333",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:26.381097",
      "comments": [
        {
          "author": "xtreme-sameer-vohra",
          "body": "Also ran into this error",
          "created_at": "2025-06-12T15:07:17Z"
        }
      ]
    },
    {
      "issue_number": 2584,
      "title": "[Cartesia] Deprecating experimental controls",
      "body": "Speed and emotion controls are deprecated in the new models: https://docs.cartesia.ai/developer-tools/changelog\n\nBut there is a way to use them with a specific version and model. I am thinking about a PR for this. But which option should I choose:\n\n- Drop them completely\n- Warn users without adding the workaround (new version parameter)\n- Warn user and add the workaround\n",
      "state": "open",
      "author": "ChenghaoMou",
      "author_type": "User",
      "created_at": "2025-06-12T11:00:36Z",
      "updated_at": "2025-06-12T11:00:36Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2584/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2584",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2584",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:26.622092",
      "comments": []
    },
    {
      "issue_number": 2583,
      "title": "Livekit Agents Google plugin function calling 400 error not recoverable",
      "body": "<!--\nHello! Thanks for taking the time to file a bug report.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already reported this issue.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n-->\n# Error logs\n\n```\n2025-06-12 11:57:36,764 - INFO google_genai.models - AFC remote call 1 is done. \n2025-06-12 11:57:36,826 - INFO livekit.agents - LLM metrics: ttft=0.36, input_tokens=2989,  cached_input_tokens=0, output_tokens=5, tokens_per_second=11.78 \n2025-06-12 11:57:36,871 - DEBUG livekit.agents - ------------------- Agent is listening for user input \n[Audio] xterno (Realtek(R) A [-37.09 dBFS] [##############----------------]Took 391.0 ms to get audio chunks for text: ¿Perdona?\n2025-06-12 11:57:37,223 - INFO livekit.agents - TTS metrics: ttfb=0.39, audio_duration=0.77\n2025-06-12 11:57:37,223 - INFO livekit.agents - Total Agent Latency: 1.66s (EOU: 54.46%, LLM TTFT: 21.90%, TTS TTFB: 23.64%)\n2025-06-12 11:57:37,472 - DEBUG livekit.agents - +++++++++++++++++++ User stopped speaking \n2025-06-12 11:57:37,714 - INFO livekit.agents - USER: ' 3 horas.' --------]\n2025-06-12 11:57:37,716 - INFO livekit.agents - STT metrics: audio_duration=1.62\n2025-06-12 11:57:37,716 - DEBUG livekit.agents - received user transcript {\"user_transcript\": \" 3 horas.\", \"language\": \"es\"}\n2025-06-12 11:57:37,756 - DEBUG livekit.plugins.turn_detector - eou prediction {\"eou_probability\": 0.9843538999557495, \"input\": \"<|im_start|>assistant\\nDe acuerdo. Entonces en una hora te llamar\\u00e1 un asesor especializado para resolver todas tus dudas.<|im_end|>\\n<|im_start|>user\\nPerfecto, gracias<|im_end|>\\n<|im_start|>assistant\\nGracias a ti, que tengas un buen d\\u00eda.<|im_end|>\\n<|im_start|>user\\nBueno, llame mejor dentro de...<|im_end|>\\n<|im_start|>user\\n3 horas.\", \"duration\": 0.036}\n2025-06-12 11:57:37,756 - INFO livekit.agents - EOU metrics: end_of_utterance_delay=0.86, transcription_delay=0.82 \n2025-06-12 11:57:37,756 - DEBUG livekit.agents - ------------------- Agent is processing user input and generating a response\n2025-06-12 11:57:37,759 - INFO google_genai.models - AFC is enabled with max remote calls: 10.\n2025-06-12 11:57:38,498 - INFO google_genai.models - AFC remote call 1 is done. \n2025-06-12 11:57:38,501 - DEBUG livekit.agents - executing tool {\"function\": \"save_user_contact_info\", \"arguments\": \"{\\\"contact_date\\\": \\\"datetime.now() + timedelta(hours=3)\\\", \\\"contact_details\\\": \\\"Llamar dentro de tres horas\\\"}\", \"speech_id\": \"speech_73af01afa8dd\"}\n2025-06-12 11:57:38,505 - INFO google_genai.models - AFC is enabled with max remote calls: 10.\n2025-06-12 11:57:38,506 - INFO livekit.agents - LLM metrics: ttft=0.74, input_tokens=2993,  cached_input_tokens=0, output_tokens=43, tokens_per_second=57.39\n2025-06-12 11:57:38,507 - DEBUG livekit.agents - tools execution completed {\"speech_id\": \"speech_73af01afa8dd\"}\n2025-06-12 11:57:38,507 - DEBUG livekit.agents - ------------------- Agent is listening for user input\n2025-06-12 11:57:38,508 - DEBUG livekit.agents - ------------------- Agent is processing user input and generating a response\n2025-06-12 11:57:39,028 - ERROR livekit.agents - AgentSession is closing due to unrecoverable error \nTraceback (most recent call last):\n  File \"C:\\Desarrollo\\projects\\055_voice_agents\\.venv\\Lib\\site-packages\\livekit\\plugins\\google\\llm.py\", line 294, in _run\n    async for response in stream:\n  File \"C:\\Desarrollo\\projects\\055_voice_agents\\.venv\\Lib\\site-packages\\google\\genai\\models.py\", line 7266, in async_generator\n    response = await self._generate_content_stream(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Desarrollo\\projects\\055_voice_agents\\.venv\\Lib\\site-packages\\google\\genai\\models.py\", line 6191, in _generate_content_stream\n    response_stream = await self._api_client.async_request_streamed(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Desarrollo\\projects\\055_voice_agents\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py\", line 806, in async_request_streamed\n    response = await self._async_request(http_request=http_request, stream=True)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Desarrollo\\projects\\055_voice_agents\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py\", line 721, in _async_request\n    await errors.APIError.raise_for_async_response(response)\n  File \"C:\\Desarrollo\\projects\\055_voice_agents\\.venv\\Lib\\site-packages\\google\\genai\\errors.py\", line 129, in raise_for_async_response\n    raise ClientError(status_code, response_json, response)\ngoogle.genai.errors.ClientError: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting', 'status': 'INVALID_ARGUMENT'}}\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Desarrollo\\projects\\055_voice_agents\\.venv\\Lib\\site-packages\\livekit\\agents\\llm\\llm.py\", line 138, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Desarrollo\\projects\\055_voice_agents\\.venv\\Lib\\site-packages\\livekit\\plugins\\google\\llm.py\", line 336, in _run\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: gemini llm: client error (status_code=400, request_id=8137d8ca205e, body=An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting INVALID_ARGUMENT)\n2025-06-12 11:57:39,034 - ERROR livekit.agents - Error in _inference_task\nTraceback (most recent call last):\n  File \"C:\\Desarrollo\\projects\\055_voice_agents\\.venv\\Lib\\site-packages\\livekit\\plugins\\google\\llm.py\", line 294, in _run\n    async for response in stream:\n  File \"C:\\Desarrollo\\projects\\055_voice_agents\\.venv\\Lib\\site-packages\\google\\genai\\models.py\", line 7266, in async_generator\n    response = await self._generate_content_stream(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Desarrollo\\projects\\055_voice_agents\\.venv\\Lib\\site-packages\\google\\genai\\models.py\", line 6191, in _generate_content_stream\n    response_stream = await self._api_client.async_request_streamed(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Desarrollo\\projects\\055_voice_agents\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py\", line 806, in async_request_streamed\n    response = await self._async_request(http_request=http_request, stream=True)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Desarrollo\\projects\\055_voice_agents\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py\", line 721, in _async_request\n    await errors.APIError.raise_for_async_response(response)\n  File \"C:\\Desarrollo\\projects\\055_voice_agents\\.venv\\Lib\\site-packages\\google\\genai\\errors.py\", line 129, in raise_for_async_response\n    raise ClientError(status_code, response_json, response)\ngoogle.genai.errors.ClientError: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting', 'status': 'INVALID_ARGUMENT'}}\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Desarrollo\\projects\\055_voice_agents\\.venv\\Lib\\site-packages\\livekit\\agents\\utils\\log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Desarrollo\\projects\\055_voice_agents\\.venv\\Lib\\site-packages\\livekit\\agents\\voice\\generation.py\", line 85, in _inference_task\n    async for chunk in llm_node:\n  File \"C:\\Desarrollo\\projects\\055_voice_agents\\agent.py\", line 169, in llm_node\n    async for chunk in Agent.default.llm_node(\n  File \"C:\\Desarrollo\\projects\\055_voice_agents\\.venv\\Lib\\site-packages\\livekit\\agents\\voice\\agent.py\", line 352, in llm_node\n    async for chunk in stream:\n  File \"C:\\Desarrollo\\projects\\055_voice_agents\\.venv\\Lib\\site-packages\\livekit\\agents\\llm\\llm.py\", line 232, in __anext__\n    raise exc  # noqa: B904\n    ^^^^^^^^^\n  File \"C:\\Desarrollo\\projects\\055_voice_agents\\.venv\\Lib\\site-packages\\livekit\\agents\\llm\\llm.py\", line 138, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Desarrollo\\projects\\055_voice_agents\\.venv\\Lib\\site-packages\\livekit\\plugins\\google\\llm.py\", line 336, in _run\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: gemini llm: client error (status_code=400, request_id=8137d8ca205e, body=An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting INVALID_ARGUMENT)\n```\n\nThis is the error **gemini llm: client error (status_code=400** \n\nIt sometimes occurs, which makes me think that the problem lies in the way the function calling is implemented. Nevertheless, I don't believe it should break the agent; it should simply `logger.error`.\n\nI am using:\n\n```\n    \"livekit>=1.0.8\",\n    \"livekit-agents[google,silero,turn-detector,openai,cartesia,deepgram,groq,assemblyai,speechmatics]>=1.0.23\",\n    \"livekit-plugins-noise-cancellation>=0.2.4\",\n```\n\n```\nllm=google.LLM(\n            model=\"gemini-2.5-flash-preview-05-20\",\n            thinking_config=types.ThinkingConfig(thinking_budget=0),\n        )\n```",
      "state": "open",
      "author": "anlagbr",
      "author_type": "User",
      "created_at": "2025-06-12T10:10:44Z",
      "updated_at": "2025-06-12T10:34:37Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2583/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2583",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2583",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:26.622115",
      "comments": [
        {
          "author": "anlagbr",
          "body": "From the Google docs: https://ai.google.dev/gemini-api/docs/troubleshooting?authuser=2\n\n![Image](https://github.com/user-attachments/assets/65b00594-7955-4a70-b841-60e5542d8294)\n\n\nHTTP Code | Status | Description | Example | Solution\n-- | -- | -- | -- | --\n400 | INVALID_ARGUMENT | The request body i",
          "created_at": "2025-06-12T10:12:12Z"
        },
        {
          "author": "anlagbr",
          "body": "@davidzhao ",
          "created_at": "2025-06-12T10:34:37Z"
        }
      ]
    },
    {
      "issue_number": 2577,
      "title": "OpenAI Realtime breaks when speed parameter isn't set in 1.1.0",
      "body": "I've upgraded to 1.1.0 and openai 1.86.0. My realtime agent got the following error:\n\n```\nlivekit.plugins.openai - ERROR - OpenAI Realtime API returned an error {\"message\": \"OpenAI Realtime API returned an error\", \"level\": \"ERROR\", \"name\": \"livekit.plugins.openai\", \"error\": \"Error(message=\\\"Invalid type for 'session.speed': expected a decimal, but got null instead.\\\", type='invalid_request_error', code='invalid_type', event_id='session_update_ea477b3e6ce9', param='session.speed')\", \"pid\": 103, \"job_id\": \"AJ_XcJwSvUc8hPB\", \"timestamp\": \"2025-06-11T21:41:51.959800+00:00\"}\n\nlivekit.plugins.openai - WARNING - OpenAI Realtime API connection failed, retrying in 0.1s Traceback (most recent call last): File \"/usr/local/lib/python3.11/site-packages/livekit/plugins/openai/realtime/realtime_model.py\", line 618, in _main_task await self._run_ws(ws_conn) File \"/usr/local/lib/python3.11/site-packages/livekit/plugins/openai/realtime/realtime_model.py\", line 820, in _run_ws task.result() File \"/usr/local/lib/python3.11/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs return await fn(*args, **kwargs) ^^^^^^^^^^^^^^^^^^^^^^^^^ File \"/usr/local/lib/python3.11/site-packages/livekit/plugins/openai/realtime/realtime_model.py\", line 721, in _recv_task raise APIConnectionError(message=\"OpenAI S2S connection closed unexpectedly\") livekit.agents._exceptions.APIConnectionError: OpenAI S2S connection closed unexpectedly (body=None, retryable=True) {\"message\": \"OpenAI Realtime API connection failed, retrying in 0.1s\\nTraceback (most recent call last):\\n File \\\"/usr/local/lib/python3.11/site-packages/livekit/plugins/openai/realtime/realtime_model.py\\\", line 618, in _main_task\\n await self._run_ws(ws_conn)\\n File \\\"/usr/local/lib/python3.11/site-packages/livekit/plugins/openai/realtime/realtime_model.py\\\", line 820, in _run_ws\\n task.result()\\n File \\\"/usr/local/lib/python3.11/site-packages/livekit/agents/utils/log.py\\\", line 16, in async_fn_logs\\n return await fn(*args, **kwargs)\\n ^^^^^^^^^^^^^^^^^^^^^^^^^\\n File \\\"/usr/local/lib/python3.11/site-packages/livekit/plugins/openai/realtime/realtime_model.py\\\", line 721, in _recv_task\\n raise APIConnectionError(message=\\\"OpenAI S2S connection closed unexpectedly\\\")\\nlivekit.agents._exceptions.APIConnectionError: OpenAI S2S connection closed unexpectedly (body=None, retryable=True)\", \"level\": \"WARNING\", \"name\": \"livekit.plugins.openai\", \"attempt\": 0, \"max_retries\": 3, \"pid\": 103, \"job_id\": \"AJ_XcJwSvUc8hPB\", \"timestamp\": \"2025-06-11T21:41:51.963388+00:00\"}\n```\n\nI set my realtime agent speed to 1.0 as a default, now it works again\n```python\nreturn openai.realtime.RealtimeModel(\n    temperature=config.temperature,\n    voice=config.voice,\n    model=config.model,\n    speed=config.speed if config.speed else 1.0,\n)\n```\n\nThis should probably be handled more gracefully I guess? ",
      "state": "closed",
      "author": "schedawg74",
      "author_type": "User",
      "created_at": "2025-06-11T21:53:15Z",
      "updated_at": "2025-06-11T22:10:49Z",
      "closed_at": "2025-06-11T22:10:49Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2577/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2577",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2577",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:26.905487",
      "comments": [
        {
          "author": "davidzhao",
          "body": "yup this was an issue, that's fixed in `1.1.1`",
          "created_at": "2025-06-11T22:10:48Z"
        }
      ]
    },
    {
      "issue_number": 2553,
      "title": "Correct graceful handling of KeyboardInterrupt with Openai Realtime API",
      "body": "When a KeyboardInterrupt is provided (e.g. tearing down a development environment) whilst the OpenAI Realtime model is currently generating responses we get\n\n```\n^C2025-06-10 14:59:54,463 - INFO livekit.agents - shutting down worker {\"id\": \"AW_ZZQxwy5Ry5Qi\"}\n2025-06-10 14:59:54,464 - INFO livekit.agents - process exiting {\"reason\": \"\", \"pid\": 734965, \"job_id\": \"AJ_i8FhcBwNehQn\"}\n2025-06-10 14:59:54,484 - ERROR livekit.agents - 2025-06-10 14:59:54,484 - ERROR livekit.agents - AgentSession is closing due to unrecoverable error \nlivekit.agents._exceptions.APIConnectionError: OpenAI S2S connection closed unexpectedly {\"pid\": 734965, \"job_id\": \"AJ_i8FhcBwNehQn\"}\n2025-06-10 14:59:54,484 - ERROR livekit.plugins.openai - 2025-06-10 14:59:54,484 - ERROR livekit.plugins.openai - Error in _recv_task \nTraceback (most recent call last):\n  File \"/home/ben/repos/voc-voice-agent-livekit-latest/.venv/lib/python3.13/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/repos/voc-voice-agent-livekit-latest/.venv/lib/python3.13/site-packages/livekit/plugins/openai/realtime/realtime_model.py\", line 581, in _recv_task\n    raise error\nException: OpenAI S2S connection closed unexpectedly {\"pid\": 734965, \"job_id\": \"AJ_i8FhcBwNehQn\"}\n2025-06-10 14:59:54,485 - ERROR livekit.plugins.openai - 2025-06-10 14:59:54,485 - ERROR livekit.plugins.openai - Error in _main_task \nTraceback (most recent call last):\n  File \"/home/ben/repos/voc-voice-agent-livekit-latest/.venv/lib/python3.13/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/repos/voc-voice-agent-livekit-latest/.venv/lib/python3.13/site-packages/livekit/plugins/openai/realtime/realtime_model.py\", line 669, in _main_task\n    await asyncio.gather(*tasks)\n  File \"/home/ben/repos/voc-voice-agent-livekit-latest/.venv/lib/python3.13/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/repos/voc-voice-agent-livekit-latest/.venv/lib/python3.13/site-packages/livekit/plugins/openai/realtime/realtime_model.py\", line 581, in _recv_task\n    raise error\nException: OpenAI S2S connection closed unexpectedly {\"pid\": 734965, \"job_id\": \"AJ_i8FhcBwNehQn\"}\n```\n\nThe error itself is no issue, as we are shutting down the software. But what is the recommended way to graceful handle this shutdown - either by waiting for OpenAI to gracefully shutdown or by instead silencing these exceptions from livekit in the specific case where they occur soon after KeyboardInterrupt?\n\nIf we do not find a solution for this, it means error telemetry tools will give false positives error reports on intentional shutdowns \n\n**What I have Tried**\n\n- I have read https://docs.livekit.io/agents/build/events/#error-event and am aware we can get a handle on errors via the error event, however it seems that this error is error logged regardless of how it is handled here - so this is not a viable solution to silence the error logging in this situation",
      "state": "closed",
      "author": "bml1g12",
      "author_type": "User",
      "created_at": "2025-06-10T14:15:25Z",
      "updated_at": "2025-06-11T20:27:15Z",
      "closed_at": "2025-06-11T20:27:15Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2553/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2553",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2553",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:27.091759",
      "comments": [
        {
          "author": "longcw",
          "body": "Which version of livekit-agents are you using? In agents 1.1.1 we added a clean up before shutting down the worker https://github.com/livekit/agents/pull/2398/files#diff-ae28db7b71d42ec453a1b46d74382b9c06c4678645e46f08a26a4452a83ad1ccR380-R384, this may fix the issue.",
          "created_at": "2025-06-11T02:33:15Z"
        },
        {
          "author": "bml1g12",
          "body": "@longcw  it does seem like this particular error has been removed on keyboard interrupt with 1.1.1 - nice! \n\nI will close this for now and reopen if we encounter a similar issue in future",
          "created_at": "2025-06-11T20:27:15Z"
        }
      ]
    },
    {
      "issue_number": 2569,
      "title": "Issue with added tracing options to OpenAI RealtimeModel and RealtimeSession",
      "body": "Using with Azure gpt-4o-mini-realtime-preview model (api_version=\"2024-10-01-preview\") leads to an error:\n\n`ERROR livekit.plugins.openai - OpenAI Realtime API returned an error {\"error\": \"Error(message=\\\"Unknown parameter: 'session.tracing'.\\\", type='invalid_request_error', code='unknown_parameter', event_id='session_update_5bfd853a8dfe', param='session.tracing')\"}`\n\n@mikevin920 \n\n\n",
      "state": "open",
      "author": "MLFDE",
      "author_type": "User",
      "created_at": "2025-06-11T18:20:32Z",
      "updated_at": "2025-06-11T18:20:32Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2569/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2569",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2569",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:27.291661",
      "comments": []
    },
    {
      "issue_number": 2567,
      "title": "Agent enters \"listening\" state before \"speaking\" when using on_enter for conversation initiation",
      "body": "According to the agent_state_changed callback, the agent enters the \"listening\" state before switching to \"speaking\" when I use the on_enter callback to initiate a conversation.\n\nHow can I skip this intermediate \"listening\" state if the agent is supposed to start the conversation?\n\nI’m using the following method:\n\n```\nasync def on_enter(self):\n    # When the agent is added to the session, it will generate a reply\n    # according to its instructions\n    self.session.generate_reply()\n```\n\nExpected behavior:\nThe agent should avoid listening to the user if it will start the conversation.\n\nEnvironment:\nlivekit-agents==1.1.1\n\n",
      "state": "closed",
      "author": "RBT22",
      "author_type": "User",
      "created_at": "2025-06-11T13:57:00Z",
      "updated_at": "2025-06-11T17:11:50Z",
      "closed_at": "2025-06-11T17:11:50Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2567/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2567",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2567",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:27.291682",
      "comments": [
        {
          "author": "longcw",
          "body": "The agent will always enter the `listening` state after `session.start`, there is no way to skip that for now.",
          "created_at": "2025-06-11T14:39:56Z"
        }
      ]
    },
    {
      "issue_number": 2564,
      "title": "Missing Metrics from Cartesia STT",
      "body": "The Cartesia STT does not send any RECOGNITION_USAGE event and therefore no metrics would be reported.",
      "state": "closed",
      "author": "ChenghaoMou",
      "author_type": "User",
      "created_at": "2025-06-11T10:10:58Z",
      "updated_at": "2025-06-11T10:53:57Z",
      "closed_at": "2025-06-11T10:53:57Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2564/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2564",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2564",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:27.479772",
      "comments": []
    },
    {
      "issue_number": 2563,
      "title": "azure personal voice cloning tts integration",
      "body": "Is there some guide on integrating azure tts https://learn.microsoft.com/en-us/azure/ai-services/speech-service/personal-voice-how-to-use \"personal voice api with voice cloning\" with livekit agents? \nFrom the docs azure personal voice clone supports ssml and streaming and it takes voice id as parameter I don't find any documentation or guide on using azure personal voice in streaming.",
      "state": "open",
      "author": "thunder-007",
      "author_type": "User",
      "created_at": "2025-06-11T10:06:22Z",
      "updated_at": "2025-06-11T10:06:22Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2563/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2563",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2563",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:27.479791",
      "comments": []
    },
    {
      "issue_number": 2528,
      "title": "How to select a different agent based on a condition in entrypoint function",
      "body": "Hello Community,\nI am trying to build an AI agent which is able to take AI Interviews as well as transcribe manual interview. The logic is that first I will fetch the information from the database of the interview mode selected & then based on a condition on interview mode, I want to call either multi-user-transcribe agent or AI interview agent. \n\nWhen I try to use a basic branching on this condition the agent first shows connected but later gets disconnected with 2 different errors, one of them:\n `2025-06-06 18:52:19,380 - WARNING livekit - livekit::rtc_engine:446:livekit::rtc_engine - received session close: \"signal client closed: \\\"stream closed\\\"\" UnknownReason Resume {\"pid\": 8706, \"job_id\": \"AJ_7gg3DgArdGYc\"}`\n\nIs there any other way this should be handled? Because I didn't find any multi-agent reference based on condition & I don't want to add a redundant Agent to just orchestrate calling either agents.\n\nAny help would be appreciated!",
      "state": "open",
      "author": "pavan-aubergine",
      "author_type": "User",
      "created_at": "2025-06-06T13:32:46Z",
      "updated_at": "2025-06-11T02:37:29Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2528/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2528",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2528",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:27.479798",
      "comments": [
        {
          "author": "longcw",
          "body": "Can you show an example how you select or switch the agents?",
          "created_at": "2025-06-11T02:37:29Z"
        }
      ]
    },
    {
      "issue_number": 2552,
      "title": "RealtimeError: generate_reply timed out should be recoverable",
      "body": "We often get:\n`livekit.agents.llm.realtime.RealtimeError: generate_reply timed out.`\nwhen the OpenAI servers burp.\n\nWhen this happens, the conversation with the agents dies. There is no recovery other than disconnecting and trying again.\nThis is very annoying to the end users who keep trying to talk to the agent.\n\nThere should be some sort of retry mechanism to make the conversation more robust.",
      "state": "closed",
      "author": "MajorTal",
      "author_type": "User",
      "created_at": "2025-06-10T13:27:55Z",
      "updated_at": "2025-06-11T02:26:05Z",
      "closed_at": "2025-06-11T02:26:05Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2552/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2552",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2552",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:27.701766",
      "comments": [
        {
          "author": "longcw",
          "body": "just added the retry for the realtime model https://github.com/livekit/agents/pull/2544, will make this error recoverable",
          "created_at": "2025-06-10T13:36:38Z"
        },
        {
          "author": "MatheusRDG",
          "body": "I'm getting a lot of problem with this today, is really only retry or any problem with the service?",
          "created_at": "2025-06-10T15:19:16Z"
        },
        {
          "author": "longcw",
          "body": "@MatheusRDG I got some errors too, probably there was an issue with openai's service. The user input transcription was down when I testing.",
          "created_at": "2025-06-10T15:28:24Z"
        },
        {
          "author": "koakuma-chan",
          "body": "> I'm getting a lot of problem with this today, is really only retry or any problem with the service?\n\nhttps://status.openai.com/incidents/01JXCAW3K3JAE0EP56AEZ7CBG3",
          "created_at": "2025-06-10T17:52:57Z"
        },
        {
          "author": "koakuma-chan",
          "body": "> just added the retry for the realtime model [#2544](https://github.com/livekit/agents/pull/2544), will make this error recoverable\n\nThe latest release is broken though due to the speed parameter.",
          "created_at": "2025-06-10T17:53:53Z"
        }
      ]
    },
    {
      "issue_number": 2558,
      "title": "Unable to use  model=\"eleven_v3\", I get this error  Invalid response status status_code=500,",
      "body": "Hello, you've all been scratching my head at this for a bit.\n\nI am not sure what I am missing I attempted to ensure that everything was up to date and I get this error\n\nI will leave some logs below please let me know if there anything else you need this is what my config looks like \n\n```python\n    session = AgentSession(\n        vad=ctx.proc.userdata[\"vad\"],\n        llm=openai.LLM(store=\"True\", model=\"gpt-4.1-mini\"),\n        stt=deepgram.STT(model=\"nova-3\"),\n        tts=elevenlabs.TTS(\n      voice_id=\"Hjzqw9NR0xFMYU9Us0DL\",\n      model=\"eleven_v3\",\n   ),\n        turn_detection=MultilingualModel(),\n    )\n```\n```bash\n2025-06-10 17:11:33,992 - DEBUG livekit.agents - start reading stream {\"room\": \"voice_assistant_room_9335\", \"user_id\": \"420\", \"participant\": \"voice_assistant_user_7125\", \"source\": \"SOURCE_MICROPHONE\"}\n2025-06-10 17:11:34,918 - INFO livekit.agents - LLM metrics: ttft=1.14, input_tokens=111,  cached_input_tokens=0, output_tokens=28, tokens_per_second=18.73 {\"room\": \"voice_assistant_room_9335\", \"user_id\": \"420\"}\n2025-06-10 17:11:36,647 - WARNING livekit.agents - failed to synthesize speech, retrying in 0.1s {\"room\": \"voice_assistant_room_9335\", \"user_id\": \"420\", \"tts\": \"livekit.plugins.elevenlabs.tts.TTS\", \"attempt\": 1, \"streamed\": true}\nTraceback (most recent call last):\n  File \"C:\\Users\\MindExpander\\AppData\\Roaming\\Python\\Python311\\site-packages\\livekit\\agents\\tts\\tts.py\", line 311, in _main_task\n    await self._run(output_emitter)\n  File \"C:\\Users\\MindExpander\\AppData\\Roaming\\Python\\Python311\\site-packages\\livekit\\plugins\\elevenlabs\\tts.py\", line 337, in _run\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: Invalid response status (status_code=500, request_id=0e24d57b0627, body=None, retryable=True)   \n2025-06-10 17:11:36,735 - WARNING livekit.agents - failed to synthesize speech, retrying in 2.0s {\"room\": \"voice_assistant_room_9335\", \"user_id\": \"420\", \"tts\": \"livekit.plugins.elevenlabs.tts.TTS\", \"attempt\": 2, \"streamed\": true}\nTraceback (most recent call last):\n  File \"C:\\Users\\MindExpander\\AppData\\Roaming\\Python\\Python311\\site-packages\\livekit\\agents\\tts\\tts.py\", line 319, in _main_task\n    raise APIError(f\"no audio frames were pushed for text: {self._pushed_text}\")\nlivekit.agents._exceptions.APIError: no audio frames were pushed for text: Hey, stranger! Ready to wander through the cosmos of curiosity or dive into some quantum quirks? What’s on your mind today? (body=None, retryable=True)\n2025-06-10 17:11:38,365 - INFO livekit.agents - STT metrics: audio_duration=4.35 {\"room\": \"voice_assistant_room_9335\", \"user_id\": \"420\"}\n2025-06-10 17:11:38,725 - WARNING livekit.agents - failed to synthesize speech, retrying in 2.0s {\"room\": \"voice_assistant_room_9335\", \"user_id\": \"420\", \"tts\": \"livekit.plugins.elevenlabs.tts.TTS\", \"attempt\": 3, \"streamed\": true}\nTraceback (most recent call last):\n  File \"C:\\Users\\MindExpander\\AppData\\Roaming\\Python\\Python311\\site-packages\\livekit\\agents\\tts\\tts.py\", line 319, in _main_task\n    raise APIError(f\"no audio frames were pushed for text: {self._pushed_text}\")\nlivekit.agents._exceptions.APIError: no audio frames were pushed for text: Hey, stranger! Ready to wander through the cosmos of curiosity or dive into some quantum quirks? What’s on your mind today? (body=None, retryable=True)\n```\n\nThank you all in advanced sorry it is a bit messy",
      "state": "closed",
      "author": "TheMindExpansionNetwork",
      "author_type": "User",
      "created_at": "2025-06-11T00:15:12Z",
      "updated_at": "2025-06-11T02:00:07Z",
      "closed_at": "2025-06-11T02:00:07Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2558/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2558",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2558",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:27.946888",
      "comments": [
        {
          "author": "longcw",
          "body": "This error raises because the TTS didn't response any audio, seems because the eleven v3 is not publicly avaibale.\n\nhttps://elevenlabs.io/docs/models#eleven-v3-alpha\n> Eleven v3 API access is currently not publicly available, but will be soon. To request access, please [contact our sales team](https",
          "created_at": "2025-06-11T01:04:18Z"
        },
        {
          "author": "TheMindExpansionNetwork",
          "body": "\n\n\n> This error raises because the TTS didn't response any audio, seems because the eleven v3 is not publicly avaibale.\n> \n> https://elevenlabs.io/docs/models#eleven-v3-alpha\n> \n> > Eleven v3 API access is currently not publicly available, but will be soon. To request access, please [contact our sal",
          "created_at": "2025-06-11T01:23:28Z"
        }
      ]
    },
    {
      "issue_number": 2304,
      "title": "Tool Schema Specified with `@function_tool(raw_schema={<SCHEMA>})` Broken",
      "body": "When using the `raw_schema` parameter of the `function_tool` decorator,  the `prepare_function_arguments` method fails.\n\nThis is because it is unable to map the `raw_fields` dict to the signature of the method since the fields are erroneously written to a separate dictionary.\n\nI was able to fix this locally by updating the `agents/llm/utils.py` file at line 375 to reference the `args_dict` instead of the `raw_fields` dictionary like so:\n```\nbound = signature.bind(**{**args_dict, **context_dict})\n```",
      "state": "closed",
      "author": "blakemjones",
      "author_type": "User",
      "created_at": "2025-05-16T03:59:57Z",
      "updated_at": "2025-06-11T01:33:07Z",
      "closed_at": "2025-06-11T01:05:47Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2304/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2304",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2304",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:28.176625",
      "comments": [
        {
          "author": "longcw",
          "body": "Can you share your function example? To use raw schema it expects the function to have only one argument `raw_arguments` as in [this example](https://github.com/livekit/agents/blob/main/examples/voice_agents/raw_function_description.py#L60).",
          "created_at": "2025-05-16T04:27:04Z"
        },
        {
          "author": "blakemjones",
          "body": "Hi longcw, sorry for the late response.\n\nI didn't realize that when using a raw schema that you then had to update the method signature to use a raw_arguments dictionary.\n\nI don't totally understand the benefit of that as opposed to parsing the arguments into the method signature similarly to the de",
          "created_at": "2025-06-11T01:05:47Z"
        },
        {
          "author": "longcw",
          "body": "I think one reason is to have a single source of the params definition (in `raw_schema` in this case), otherwise your have to maintain two places and they may have conflicts.",
          "created_at": "2025-06-11T01:09:52Z"
        },
        {
          "author": "blakemjones",
          "body": "I see, and the reason why that's less of an issue with the doc string parsing is that the entire point is that the doc string is doubling as the tool description for the LLM _and_  as the documentation, so you would want to maintain it in both places anyways, is that right?",
          "created_at": "2025-06-11T01:33:07Z"
        }
      ]
    },
    {
      "issue_number": 2220,
      "title": "Running Multiple Agent Workers for Different Use Cases (Voice Assistant vs Virtual Avatar)",
      "body": "I’m working on a system that uses LiveKit Agents for two distinct purposes:\n\n- A voice assistant \n- A virtual avatar (e.g., animated character responding with custom behavior)\n\nFrom the [Agent Dispatch documentation](https://docs.livekit.io/agents/worker/agent-dispatch/), I understand that I can use a dispatch function to route requests to different worker instances. I want to confirm my understanding of the correct approach for running multiple agents for different purposes.\n\n```\n@router.get(\"/getToken\")\nasync def getToken(user_id: str, user_name: str, agent_name: str = \"voice-agent\"):\n    token = (\n        AccessToken(os.getenv(\"LIVEKIT_API_KEY\"), os.getenv(\"LIVEKIT_API_SECRET\"))\n        .with_grants(\n            VideoGrants(\n                room_join=True,\n                room=f\"room_{shortuuid()}\",\n            )\n        )\n        .with_room_config(\n            RoomConfiguration(\n                agents=[\n                    RoomAgentDispatch(\n                        agent_name=agent_name\n                    ),\n                ],\n            ),\n        )\n    )\n    return token.to_jwt()\n```\n\n```\n    cli.run_app(\n        WorkerOptions(\n            entrypoint_fnc=entrypoint,\n            worker_type=WorkerType.ROOM,\n            agent_name=\"avatar-agent\",\n        ),\n    )\n```\n\nIs this the recommended way to run multiple workers with distinct behaviors?",
      "state": "open",
      "author": "ahenawy",
      "author_type": "User",
      "created_at": "2025-05-07T07:22:44Z",
      "updated_at": "2025-06-10T10:29:28Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2220/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2220",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2220",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:28.421896",
      "comments": [
        {
          "author": "theomonnom",
          "body": "Yes, exactly — using agent_name is the right approach!\n\ncc @bcherry, we might want to consider improving the documentation to make this clearer.",
          "created_at": "2025-05-07T09:40:04Z"
        },
        {
          "author": "ahenawy",
          "body": "I have two LiveKit workers configured as follows:\n\n```\ncli.run_app(\n    WorkerOptions(\n        entrypoint_fnc=entrypoint,\n        agent_name=\"virtual-avatar\",  # Unique name for explicit dispatch\n    )\n)\n\ncli.run_app(\n    WorkerOptions(\n        entrypoint_fnc=entrypoint,\n        agent_name=\"voice-as",
          "created_at": "2025-05-07T09:46:09Z"
        },
        {
          "author": "bcherry",
          "body": "@ahenawy yes you've set it up correctly. the current result you describe does sound like a bug.  are you starting your workers with `python <worker-file>.py dev`?",
          "created_at": "2025-05-07T17:25:53Z"
        },
        {
          "author": "ahenawy",
          "body": "@bcherry Yes, I do for both workers. One of them always accepted the job, ignoring the agent's name. Can you please mark it as a bug?",
          "created_at": "2025-05-08T03:20:24Z"
        },
        {
          "author": "pavan-aubergine",
          "body": "> [@bcherry](https://github.com/bcherry) Yes, I do for both workers. One of them always accepted the job, ignoring the agent's name. Can you please mark it as a bug?\n\nHey there @ahenawy , I am facing a similar issue for setting up different agents based on different scenario. \nDid you find the solut",
          "created_at": "2025-06-07T17:11:13Z"
        }
      ]
    },
    {
      "issue_number": 2358,
      "title": "Add a auto reconnect/reset for the OpenAI Realtime model",
      "body": "After 30mins of session. When using OpenAI Realtime 4o mini model with MultimodalAgent, we are facing this error: \n\n`[2025-05-20 07:49:03,436] 1313 livekit.plugins.openai.realtime - ERROR - OpenAI S2S error {'type': 'error', 'event_id': 'event_BZC0diqUciYtBOplwd5i9', 'error': {'type': 'invalid_request_error', 'code': 'session_expired', 'message': 'Your session hit the maximum duration of 30 minutes.', 'param': None, 'event_id': None}} [2025-05-20 07:49:03,437] 21 livekit.plugins.openai.realtime - ERROR - Error in _recv_task`\n\nAlso currently are there any workarounds for this error? We have already tried using the FallbackAdapter  method as suggested by @yepher but couldn't make it work.",
      "state": "closed",
      "author": "Parva101",
      "author_type": "User",
      "created_at": "2025-05-22T07:07:03Z",
      "updated_at": "2025-06-10T09:52:12Z",
      "closed_at": "2025-06-10T09:52:12Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2358/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2358",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2358",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:28.680819",
      "comments": [
        {
          "author": "longcw",
          "body": "fixed in https://github.com/livekit/agents/pull/2360",
          "created_at": "2025-06-10T09:52:12Z"
        }
      ]
    },
    {
      "issue_number": 1194,
      "title": "Expand Supported Top-Level Domains (TLDs) in `split_sentences` Function",
      "body": "## **Description**\r\n\r\nThe `split_sentences` function in the `livekit.agents.tokenize.basic` module inadequately handles domain names and email addresses with Top-Level Domains (TLDs) not included in its predefined list. This limitation results in the insertion of a space before the TLD, causing websites, emails, and other domain-related strings to be split incorrectly. Consequently, Text-to-Speech (TTS) systems mispronounce these entities, making them unrecognizable and disrupting the user experience.\r\n\r\nI have successfully resolved it using a monkey-patch in my case, but I believe this should be generally addressed to cater to the global audience of LiveKit.\r\n\r\n## **Proposed Solution**\r\n\r\n1. **Expand the TLD List:**\r\n   - Update the `websites` regex pattern to include a comprehensive list of both generic and country-code TLDs.\r\n\r\n2. **Make TLDs Configurable:**\r\n   - Allow users to provide a custom list of TLDs or fetch the latest TLDs from a reliable source to ensure up-to-date and extensive coverage.\r\n\r\n3. **Modify the `split_sentences` Function:**\r\n   - Integrate the expanded TLD list directly into the existing sentence-splitting logic to prevent improper splits.\r\n\r\n-----------\r\n\r\n\r\n### More Comprehensive list of TLDs from IANA registry\r\ntlds = (\r\n    \"com|net|org|edu|gov|mil|int|info|biz|name|pro|museum|coop|aero|\"\r\n    \"dev|app|io|ai|co|me|tv|xyz|cloud|tech|design|studio|online|store|\"\r\n    \"ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|\"\r\n    \"ba|bb|bd|be|bf|bg|bh|bi|bj|bl|bm|bn|bo|bq|br|bs|bt|bv|bw|by|bz|\"\r\n    \"ca|cat|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cu|cv|cw|cx|cy|cz|\"\r\n    \"de|dj|dk|dm|do|dz|\"\r\n    \"ec|ee|eg|eh|er|es|et|eu|eus|\"\r\n    \"fi|fj|fk|fm|fo|fr|\"\r\n    \"ga|gal|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|\"\r\n    \"hk|hm|hn|hr|ht|hu|\"\r\n    \"id|ie|il|im|in|io|iq|ir|is|it|\"\r\n    \"je|jm|jo|jp|\"\r\n    \"ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|\"\r\n    \"la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|\"\r\n    \"ma|mc|md|me|mf|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|\"\r\n    \"na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|\"\r\n    \"om|\"\r\n    \"pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|\"\r\n    \"qa|\"\r\n    \"re|ro|rs|ru|rw|\"\r\n    \"sa|sb|sc|sd|se|sg|sh|si|sj|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|\"\r\n    \"tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|\"\r\n    \"ua|ug|uk|us|uy|uz|\"\r\n    \"va|vc|ve|vg|vi|vn|vu|\"\r\n    \"wf|ws|\"\r\n    \"ye|yt|\"\r\n    \"za|zm|zw\"\r\n)\r\n",
      "state": "closed",
      "author": "robertvy",
      "author_type": "User",
      "created_at": "2024-12-09T01:27:02Z",
      "updated_at": "2025-06-09T13:33:21Z",
      "closed_at": "2025-06-09T13:33:21Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1194/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1194",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1194",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:28.930397",
      "comments": []
    },
    {
      "issue_number": 2083,
      "title": "Integration of Nova sonic(AWS multimodal)",
      "body": "Is there anything planned for release of the AWS Nova sonic multimodal? \n\nhttps://docs.aws.amazon.com/nova/latest/userguide/speech.html",
      "state": "open",
      "author": "kailashsp",
      "author_type": "User",
      "created_at": "2025-04-22T20:49:26Z",
      "updated_at": "2025-06-09T08:38:30Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2083/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2083",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2083",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:30.803907",
      "comments": [
        {
          "author": "timopetric",
          "body": "Yes please! It would be awesome to be able to switch between Openai realtime API, Gemini live api and Amazon Nova Sonic realtime models.\nMore context: https://aws.amazon.com/ai/generative-ai/nova/speech/",
          "created_at": "2025-04-29T13:51:47Z"
        },
        {
          "author": "davidzhao",
          "body": "we are planning to add Nova as a s2s model that we'll support. the team has done some early work in the integration. It's very do-able",
          "created_at": "2025-05-28T00:12:23Z"
        },
        {
          "author": "dariusteep",
          "body": "> we are planning to add Nova as a s2s model that we'll support. the team has done some early work in the integration. It's very do-able\n\nthat would be great ",
          "created_at": "2025-05-28T09:11:25Z"
        },
        {
          "author": "BumaldaOverTheWater94",
          "body": "@davidzhao Hi David,\nIt looks like we are working on the same thing. I also have some working code that I can share.\nI would like to collaborate with you on this workstream. What would be the best way to contact you?\n\nCan we get on a zoom call tormorrow?\nAny time between 11AM to 1PM PST works for me",
          "created_at": "2025-05-28T19:07:21Z"
        },
        {
          "author": "davidzhao",
          "body": "@BumaldaOverTheWater94 yes! let's chat. My email is ___. I can chat on Friday, but let's coordinate over email :) ",
          "created_at": "2025-05-29T07:24:54Z"
        }
      ]
    },
    {
      "issue_number": 2512,
      "title": "voice agent produce \"[]\" assistant message when using tools",
      "body": "using livekit `1.0.23` and voice pipeline agent with openai llm\n\n```bash\nChatMessage(id='item_877843ee7622', type='message', role='assistant', content=['[]'], interrupted=False, hash=None, created_at=1749088896.0788195), \nFunctionCall(id='item_877843ee7622/fnc_0', type='function_call', call_id='call_662zcd3nnzthwmp5rk1itbb1', arguments='{\"queries\":[\"abcde\"]}', name='web_search', created_at=1749088900.4875188), FunctionCallOutput(id='item_3e6eb6438cc5', name='web_search', type='function_call_output', call_id='call_662zcd3nnzthwmp5rk1itbb1', output=\"参考信息... ...\", is_error=False, created_at=1749088900.4875188),\n```\n\nit seems somewhere insert an empty `['[]']` message",
      "state": "closed",
      "author": "DeoLeung",
      "author_type": "User",
      "created_at": "2025-06-05T02:30:55Z",
      "updated_at": "2025-06-09T07:30:25Z",
      "closed_at": "2025-06-09T07:30:24Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2512/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2512",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2512",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:31.035069",
      "comments": [
        {
          "author": "longcw",
          "body": "Which LLM are you using? I suspect it's LLM responded with a `[]` alongside the tool call..",
          "created_at": "2025-06-07T02:32:03Z"
        },
        {
          "author": "DeoLeung",
          "body": "using openai llm but pass through our own proxy server, i will double check it if it's our implementation error :(",
          "created_at": "2025-06-07T03:38:09Z"
        },
        {
          "author": "DeoLeung",
          "body": "confirm it should be our proxy model's fault :) the mcp return result with json format, and our model not handling it well, however switching back to real openai 4.1 model it works without problem :)",
          "created_at": "2025-06-09T07:30:24Z"
        }
      ]
    },
    {
      "issue_number": 2484,
      "title": "Avatar (bey or tavus) will automatically leave the room",
      "body": "hi team, after about 5 minutes of room startup, the digital person will automatically leave the room. from the event log. **it can be seen that when avatar leave the room , user still in the room .**   please help take a look ,thanks very much\n\n### environment\nprod\n\n### package versions\nlivekit-agents==1.0.22\nlivekit-api==1.0.2\nlivekit-plugins-openai==1.0.22\nlivekit-plugins-deepgram==1.0.22\nlivekit-plugins-silero==1.0.22\nlivekit-plugins-turn-detector==1.0.22\nlivekit-plugins-google==1.0.18\nlivekit-plugins-bey==1.0.22\nlivekit-plugins-tavus==1.0.22\nlivekit-plugins-noise-cancellation==0.2.4\npython-dotenv~=1.0\naiofile~=3.8.8\nlivekit~=1.0.5\naiohttp~=3.11.2\n\n### minimal examples:\n\n![Image](https://github.com/user-attachments/assets/a9a53beb-b993-42f1-9256-ddbd0781f8e6)\n\n### error logs\n\ntavus avatar event log (room session id: RM_6AKAKqSrRtNN)\n![Image](https://github.com/user-attachments/assets/1b596090-3cfe-4349-8cac-0c40ba171065)\n\nbey event log (room session id: RM_UnCaQDyB3by3) , **it return connection timeout**\n![Image](https://github.com/user-attachments/assets/8aad3056-dc42-43c4-9507-3cb959c4f9f1)\n\n![Image](https://github.com/user-attachments/assets/a0227a64-cb86-4c50-818f-c95597ea205a)",
      "state": "open",
      "author": "meiyanxi",
      "author_type": "User",
      "created_at": "2025-06-02T11:07:37Z",
      "updated_at": "2025-06-09T07:12:19Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2484/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2484",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2484",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:31.319241",
      "comments": [
        {
          "author": "longcw",
          "body": "from the tavus log the disconnection reason is `CLIENT_INITIATED`, and the bey one is `CONNECTION_TIMEOUT`, does this always happen when you are using the avatar?",
          "created_at": "2025-06-09T07:12:18Z"
        }
      ]
    },
    {
      "issue_number": 2454,
      "title": "Chat context update overwritten",
      "body": "Hello,\n\nWithin `llm_node` I have a function re-ordering the chat items to fix the error from openai.\nAlso in `on_enter` I add a message to the chat.\nThe 2 follow the same flow of \n1. Copy chat\n2. Fix / Add message\n3. Update with `update_chat_ctx`\n\nSo if they occur at the same time, the last to update overwrites the previous one.\nTo prevent this I included a lock with\n```python\nself.chat_ctx_lock: asyncio.Lock = asyncio.Lock()\n```\nand use only `self.chat_ctx`\n\nBut now I realize that `self.chat_ctx` is not always up to date.\nFor instance after a call to a tool, the `chat_ctx` sent as param to llm_node contains the tool calling items, while `self.chat_ctx` does not.\n\nTo simplify all this, I am thinking about buffering items I have to add to the chat and add them all at once when `llm_node` is called, so that I can remove that lock and always use the `chat_ctx` passed as param of llm_node.\nOr maybe just not update the chat in `llm_node` given that I re-order each item anyway.\n\nTo make it clear I was doing\n\n```python\n    async def llm_node(\n        self,\n        chat_ctx: ChatContext,\n        tools: list[FunctionTool],\n        model_settings: ModelSettings,\n    ):\n        logger.info(f\"[llm_node] Acquiring chat context lock for llm_node\")\n        await self.chat_ctx_lock.acquire()\n```\n\nGiven that you know the behavior of livekit agents, what do you think is the best approach?\n\n\n",
      "state": "closed",
      "author": "CyprienRicqueB2L",
      "author_type": "User",
      "created_at": "2025-05-30T12:06:11Z",
      "updated_at": "2025-06-09T07:05:20Z",
      "closed_at": "2025-06-09T07:05:19Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2454/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2454",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2454",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:31.575964",
      "comments": [
        {
          "author": "davidzhao",
          "body": "could you share a minimal example with code to demonstrate what the use case is? I think that'll make it easier for folks to understand",
          "created_at": "2025-05-31T06:37:59Z"
        },
        {
          "author": "longcw",
          "body": "> For instance after a call to a tool, the chat_ctx sent as param to llm_node contains the tool calling items, while self.chat_ctx does not.\n\n`chat_ctx` passed to the `llm_node` is a copy of `agent.chat_ctx` in addition with the items needed for this turn, the new tool calling items will be added to",
          "created_at": "2025-06-01T08:17:21Z"
        },
        {
          "author": "CyprienRicqueB2L",
          "body": "Thank you ! I lacked that information about the behavior of `llm_node`\n\nAn example goes like this:\n```python\n\nclass APVAgent(Agent):\n    def __init__(self, job_context: JobContext) -> None:\n        self.chat_ctx_lock: asyncio.Lock = asyncio.Lock()\n        super().__init__( instructions=get_instructi",
          "created_at": "2025-06-03T15:14:46Z"
        },
        {
          "author": "longcw",
          "body": "> While I did setup a lock for the 2 not to occur at the same time, I am still unsure if the internals of livekit chat updates could overwrite one of my chat messages. Also is this lock the right thing to do?\n\nIf you `raise StopResponse()` in `on_user_turn_completed` we won't update the `agent.chat_",
          "created_at": "2025-06-09T07:05:19Z"
        }
      ]
    },
    {
      "issue_number": 2221,
      "title": "Failed to generate LLM completion",
      "body": "We have create an agent with some callable tools, which was working fine for like a month or so and 2 days ago we started getting weird errors which were happening only on tool calls. \n\nWe could go through the conversation flow and talk to the agent normaly but tool calls are not working.\n\nerror:\n```\nTraceback (most recent call last):\n  File \".../livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n    \n  File \".../livekit/agents/pipeline/agent_output.py\", line 244, in _stream_synthesis_task\n    async for seg in tts_source:\n    \n  File \".../livekit/agents/utils/aio/itertools.py\", line 47, in tee_peer\n    item = await iterator.__anext__()\n    \n  File \".../livekit/agents/pipeline/pipeline_agent.py\", line 1109, in _llm_stream_to_str_generator\n    async for chunk in stream:\n    \n  File \".../livekit/agents/llm/llm.py\", line 246, in __anext__\n    raise exc from None\n    \n  File \".../livekit/agents/llm/llm.py\", line 162, in _main_task\n    raise APIConnectionError(\n    \nlivekit.agents._exceptions.APIConnectionError: failed to generate LLM completion after 4 attempts\n```\n\nWe've tried to change STT from assembly to speechmatics, that did not help. Then we changed to gpt-4o-transcribe, that also did not help. We tried with changing the versions of livekit and other s but did not help.\n\nrequirements.txt\n```\nlivekit==0.20.0\nlivekit-agents==0.12.17\nlivekit-plugins-openai==0.12.3\nlivekit-plugins-cartesia==0.4.7\nlivekit-plugins-deepgram==0.6.18\nlivekit-plugins-silero==0.7.4\nlivekit-plugins-elevenlabs==0.8.0\nlivekit-plugins-turn-detector==0.4.1\nlivekit-plugins-assemblyai==0.2.3\nlivekit-plugins-speechmatics==0.0.2\n```",
      "state": "open",
      "author": "moreno1123",
      "author_type": "User",
      "created_at": "2025-05-07T08:18:53Z",
      "updated_at": "2025-06-09T00:55:28Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2221/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2221",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2221",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:31.860056",
      "comments": [
        {
          "author": "longcw",
          "body": "can you share more logs from the llm?",
          "created_at": "2025-05-07T08:28:00Z"
        },
        {
          "author": "moreno1123",
          "body": "```\nPipeline STT metrics: duration=189.15, audio_duration=1.80\n\nPipeline STT metrics: duration=190.94, audio_duration=1.80\n\nNew messages: [{'role': 'assistant', 'content': 'Could you please tell me the city where you want to rent the storage unit?'}]\n\nPipeline STT metrics: duration=192.75, audio_dur",
          "created_at": "2025-05-07T09:10:19Z"
        },
        {
          "author": "longcw",
          "body": "I actually cannot find a version that match this trackback, line 796 of this file is different to the trackback\n```\n  File \"/usr/local/lib/python3.12/site-packages/livekit/plugins/openai/llm.py\", line 796, in _run\n    raise APIConnectionError(retryable=retryable) from e\n```\n\nCan you list your packag",
          "created_at": "2025-05-07T09:23:54Z"
        },
        {
          "author": "sachanayush47",
          "body": "Im also getting same error when using nextjs as a client.\n```\n(venv) apple@apples-MacBook-Pro vagents % pip list | grep livekit\nlivekit                            1.0.8\nlivekit-agents                     1.0.22\nlivekit-api                        1.0.2\nlivekit-plugins-cartesia           1.0.22\nliveki",
          "created_at": "2025-05-24T08:45:49Z"
        },
        {
          "author": "sriram488",
          "body": "Got the same error what is the fix for this?",
          "created_at": "2025-06-08T22:17:36Z"
        }
      ]
    },
    {
      "issue_number": 1170,
      "title": "Hanging up as a SIP participant message doesn't get committed to the chat_ctx",
      "body": "We're using the on_agent_message_committed to log the transcript to our backend.\r\n\r\nThe behavior we've noticed is that when the user hangs up, while the agent stops speaking, we don't get a final on_agent_message_committed - so that final cut off message doesn't appear in our own transcript.\r\n\r\nTo reproduce:\r\n\r\n1. Add callback handlers for on_agent_message_committed and on_agent_message_interrupted that log.\r\n2. Call the agent.\r\n3. Hang up the phone half way through.\r\n\r\nThe audio (at least on egress) will stop, but no callbacks will happen.",
      "state": "closed",
      "author": "martin-purplefish",
      "author_type": "User",
      "created_at": "2024-12-04T02:48:03Z",
      "updated_at": "2025-06-08T16:49:36Z",
      "closed_at": "2025-06-08T13:44:21Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1170/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1170",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1170",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:32.128119",
      "comments": [
        {
          "author": "martin-purplefish",
          "body": "https://github.com/livekit/agents/issues/1179 would be a fix.",
          "created_at": "2024-12-05T20:21:24Z"
        },
        {
          "author": "martin-purplefish",
          "body": "Also happens for if the candidate is speaking when they hang up (rare in practice) - their last message isn't committed.",
          "created_at": "2024-12-07T19:51:53Z"
        },
        {
          "author": "davidzhao",
          "body": "this has been fixed in #2398",
          "created_at": "2025-06-08T16:49:35Z"
        }
      ]
    },
    {
      "issue_number": 2487,
      "title": "text_only example not working",
      "body": "It seems that the [text_only example](https://github.com/livekit/agents/blob/main/examples/other/text_only.py) does not work correctly. To reproduce, run an agent, connect to it via the sandbox, and attempt to chat with the agent over text. The user's messages are registered but the assistant messages do not show up.",
      "state": "closed",
      "author": "wackenvoss",
      "author_type": "User",
      "created_at": "2025-06-02T17:21:56Z",
      "updated_at": "2025-06-07T05:56:41Z",
      "closed_at": "2025-06-04T07:19:39Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2487/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2487",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2487",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:32.393441",
      "comments": [
        {
          "author": "longcw",
          "body": "which frontend are you using?\nmost likely it's because the agent transcription is not shown up in the playground when there is no audio track published, we will fix that in the frontend soon. But for now you should be able to see the agent output from `lk.transcription` text stream topic (https://do",
          "created_at": "2025-06-03T01:59:56Z"
        },
        {
          "author": "davidzhao",
          "body": "fixed in #2490",
          "created_at": "2025-06-04T07:19:39Z"
        },
        {
          "author": "wackenvoss",
          "body": "Hey @davidzhao and @longcw thank you for taking a look at this! The fix made in #2490 was indeed a problem, but it seems that Playground requires some changes as well to support this usecase. Specifically, in text-only mode, I needed to merge in the lk.chat and lk.transcriptions topic into one messa",
          "created_at": "2025-06-04T14:38:08Z"
        },
        {
          "author": "sid-js",
          "body": "I have a similar setup where I'm trying to implement text-only functionality using `audio_enabled=False` as specified on the docs [https://docs.livekit.io/agents/build/text/](https://docs.livekit.io/agents/build/text/).\n\nI'm expecting the agent to publish text responses to the `lk.transcription` tex",
          "created_at": "2025-06-06T17:46:47Z"
        },
        {
          "author": "longcw",
          "body": "@sid-js which livekit-agents version are you using, can you share the result of `pip list | grep livekit`? Only in a few old preview version it was sent to `lk.chat` topic, but after that it should always use the `lk.transcription` topic. And you can also test it with the [this example](https://gith",
          "created_at": "2025-06-07T02:42:07Z"
        }
      ]
    },
    {
      "issue_number": 2515,
      "title": "session.say(..., add_to_chat_ctx=False) save it in session.history",
      "body": "During the Agent switching process, I use `session.say` to speak some static prompts and set `add_to_chat_ctx=False` to avoid interfering with the LLM's generation. However, during testing and debugging, I hope to record all the words spoken by the agents.\n\nI'm wondering if it's possible to record all the content of session.say into chat_ctx, but ignore the add_to_chat_ctx=False information when calling the LLM?\n\nOr is there any other way to help me achieve this?",
      "state": "closed",
      "author": "badbye",
      "author_type": "User",
      "created_at": "2025-06-05T09:54:24Z",
      "updated_at": "2025-06-07T01:33:45Z",
      "closed_at": "2025-06-07T01:33:45Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2515/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2515",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2515",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:32.649327",
      "comments": [
        {
          "author": "davidzhao",
          "body": "that isn't possible today. there might be an event that we can emit for this. though chat_ctx needs to be kept in-tact.",
          "created_at": "2025-06-06T06:28:01Z"
        }
      ]
    },
    {
      "issue_number": 2504,
      "title": "Gemini Realtime Proactivity not working, missing http_options",
      "body": "Hello,\n\nI'm using the `gemini-2.5-flash-preview-native-audio-dialog` model like this:\n```\ngoogle.beta.realtime.RealtimeModel(\n                        model=\"models/gemini-2.5-flash-preview-native-audio-dialog\",\n                        proactivity=True,\n)\n```\n\nI get the following error:\n```\nwebsockets.exceptions.ConnectionClosedError: received 1007 (invalid frame payload data) Invalid JSON payload received. Unknown name \"proactivity\" at 'setup': Cannot find field.; then sent 1007 (invalid frame payload data) Invalid JSON payload received. Unknown name \"proactivity\" at 'setup': Cannot find field.\n```\n\nIf I remove `proactivity=True`, it works well.\n\nLooking at the Live API docs [here](https://ai.google.dev/gemini-api/docs/live#proactive-audio), it seems that the genai client should have the `http_options` option set up like this:\n```\nclient = genai.Client(api_key=\"GOOGLE_API_KEY\", http_options={\"api_version\": \"v1alpha\"})\n```\n\nThere is currently no way (that I know of) to add this http_options with the current plugin.\n\nI made a test and edited the `plugins/google/beta/realtime/realtime_api.py` like this and it worked:\n```\n        self._client = genai.Client(\n            api_key=self._opts.api_key,\n            vertexai=self._opts.vertexai,\n            project=self._opts.project,\n            location=self._opts.location,\n            http_options={\"api_version\": \"v1alpha\"},\n        )\n```\n\nLet me know if I can be of any help",
      "state": "closed",
      "author": "florent-martineau",
      "author_type": "User",
      "created_at": "2025-06-04T09:09:24Z",
      "updated_at": "2025-06-06T07:42:55Z",
      "closed_at": "2025-06-06T07:42:55Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2504/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2504",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2504",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:32.858041",
      "comments": [
        {
          "author": "ChenghaoMou",
          "body": "Chiming in on this. Looking at the client creation code, wouldn’t it be better for the model to accept a client object during initialization, much like how session objects are passed to other models?",
          "created_at": "2025-06-05T08:05:17Z"
        },
        {
          "author": "davidzhao",
          "body": "@ChenghaoMou we definitely can.. for now I've fixed the root cause of having to set api_version, this is simpler for users in any case.\n",
          "created_at": "2025-06-06T05:11:10Z"
        }
      ]
    },
    {
      "issue_number": 2476,
      "title": "Affective Dialog argument for Gemini Live",
      "body": "<!--\nHello! Thanks for taking the time to file a bug report.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already reported this issue.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n-->\nHi, I am trying to enable affective Dialog by passing the argument for Gemini Live, but it keeps throwing error that the argument is not allowed. However I have seen in your plugins that the argument is present. Can you help with this please ",
      "state": "closed",
      "author": "Akshaychdr09",
      "author_type": "User",
      "created_at": "2025-06-01T16:35:39Z",
      "updated_at": "2025-06-06T07:42:55Z",
      "closed_at": "2025-06-06T07:42:55Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2476/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2476",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2476",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:33.064129",
      "comments": [
        {
          "author": "davidzhao",
          "body": "this was added in 1.0.23. what version are you running?",
          "created_at": "2025-06-01T16:38:59Z"
        },
        {
          "author": "Akshaychdr09",
          "body": "I was using an older one. Will update to 1.0.23 and check. Thanks",
          "created_at": "2025-06-01T16:42:58Z"
        },
        {
          "author": "Akshaychdr09",
          "body": "Tried with 1.0.23 for model gemini-2.5-flash-exp-native-audio-thinking-dialog, it still doesn't accept the affective dialog argument",
          "created_at": "2025-06-01T17:19:17Z"
        },
        {
          "author": "Akshaychdr09",
          "body": "Hi Contributors, anyone else facing this issue. I have updated the live kit, but still the affective Dialog option throws error",
          "created_at": "2025-06-04T13:39:17Z"
        }
      ]
    },
    {
      "issue_number": 2509,
      "title": "How to run async function in `prewarm_fnc`?",
      "body": "<!--\nHello! Thanks for taking the time to ask a question.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already asked this question.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n\nFeel free to join us in the #agents channel on our Slack, and ask your question\nthere to get quicker help from us and the community:\n\nhttps://livekit.io/join-slack\n-->\n\n\nI would like to warm my TTS HTTP async client before user interaction so latency is lower but I am unable to do it.\n\nI tried `asyncio.create_task` but I get `RuntimeError: no running event loop`\n",
      "state": "closed",
      "author": "anlagbr",
      "author_type": "User",
      "created_at": "2025-06-04T16:29:39Z",
      "updated_at": "2025-06-06T07:27:56Z",
      "closed_at": "2025-06-06T06:43:26Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2509/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2509",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2509",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:33.292773",
      "comments": [
        {
          "author": "anlagbr",
          "body": "Made a workaround by creating a local API and using it as a proxy of a warm `aiohttp.ClientSession` that calls final TTS API",
          "created_at": "2025-06-05T12:19:10Z"
        },
        {
          "author": "theomonnom",
          "body": "Hey, I think you should do your connection warming inside the entrypoint. There is no point in doing it inside the prewarm_fnc.\n\nThe prewarm_fnc is actually about initializing heavy resources before marking a \"process\" ready for receiving a job.",
          "created_at": "2025-06-05T12:38:33Z"
        },
        {
          "author": "anlagbr",
          "body": "@theomonnom \n\nIf it is executed within the entrypoint, latency may increase right?\n\nIf I warm the `aiohttp.ClientSession` in the entrypoint, it takes an extra second to warm that is noticeable by the user (when doing an outbound call)\n\nBy doing it in the prewarm_fnc I am making that second not notic",
          "created_at": "2025-06-05T12:53:23Z"
        },
        {
          "author": "theomonnom",
          "body": "You can ensure the request runs in the background. (before doing `ctx.connect()`)\nThe issue with prewarm_fnc is that it might execute on a process that won't necessarily receive a job in the next few minutes.",
          "created_at": "2025-06-05T16:09:12Z"
        },
        {
          "author": "anlagbr",
          "body": "@theomonnom Thank you, it works as expected. I execute the warm-up function before `ctx.connect()`, and now the user does not notice any latency because `aiohttp.ClientSession` is already warm with the API provider session.",
          "created_at": "2025-06-06T07:27:56Z"
        }
      ]
    },
    {
      "issue_number": 2472,
      "title": "Option to Disable LLM-to-TTS Streaming for Long Responses?",
      "body": "\nHi LiveKit team,\n\nI’m working with a language that has a very slow TTS engine. Right now, we’re streaming the response from the LLM directly to TTS, but this actually makes the experience worse. It often starts speaking and then cuts off mid-sentence because of how the tokenizer works or due to chunking issues.\n\nIn my case, it’s actually better UX to say something like “Please wait…” and wait for the full LLM response before passing it to TTS all at once.\n\n**Is there a way to disable streaming between LLM and TTS? Or at least buffer the entire message before playback?**\n\nAny help would be appreciated. Thanks!",
      "state": "closed",
      "author": "dvirginz",
      "author_type": "User",
      "created_at": "2025-06-01T14:47:23Z",
      "updated_at": "2025-06-06T06:49:13Z",
      "closed_at": "2025-06-06T06:49:13Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2472/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2472",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2472",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:33.487374",
      "comments": [
        {
          "author": "longcw",
          "body": "Could you provide an example of the text you send to the TTS, is that English or another language?",
          "created_at": "2025-06-01T15:08:40Z"
        },
        {
          "author": "dvirginz",
          "body": "Thank you for the prompt response! No, it's not English, but that's a conceptual thing, if it's custom tts models that we evaluate, they are slower, and we need to disable the tokenizer - no way of doing that?",
          "created_at": "2025-06-01T15:12:05Z"
        },
        {
          "author": "davidzhao",
          "body": "You can get this done with a combination of:\n1. using a pre-response during generation ([example](https://github.com/livekit/agents/blob/main/examples/voice_agents/fast-preresponse.py#L39))\n2. wrapping the TTS with a `tts.StreamAdapter` and your own tokenizer that keeps buffering until flush.\n\nnorma",
          "created_at": "2025-06-01T16:26:40Z"
        },
        {
          "author": "dvirginz",
          "body": "\nThanks David, really appreciate the help - and honestly, the platform is amazing and super easy to work with.\n\nFor future reference, what worked for us was just:\n\n```\ncustom_tokenizer = tokenize.basic.SentenceTokenizer(min_sentence_len=100)\n\ntts = agents.tts.StreamAdapter(\n    tts=GoogleTTSWrapper(",
          "created_at": "2025-06-02T04:19:05Z"
        }
      ]
    },
    {
      "issue_number": 2519,
      "title": "MCP function tool crashes using LLM",
      "body": "Hi,\nWhen I use the llm (anthropic), stt, tts with a MCP server, it cannot create function_tool and crashes with following error. (entrypoint code is below)\n\nPS: When using realtime LLM (Google) it didn't crash.\n\n**Error Log:**\n\n```\n(mcp-server) ➜  poc-mcp-server git:(main) ✗ python agentMcp.py console\n2025-06-05 22:49:08,194 - DEBUG asyncio - Using selector: KqueueSelector \n==================================================\n     Livekit Agents - Console\n==================================================\nPress [Ctrl+B] to toggle between Text/Audio mode, [Q] to quit.\n\n2025-06-05 22:49:08,194 - INFO livekit.agents - starting worker {\"version\": \"1.0.23\", \"rtc-version\": \"1.0.8\"}\n2025-06-05 22:49:08,209 - INFO livekit.agents - see tracing information at http://localhost:57587/debug \n2025-06-05 22:49:08,210 - INFO livekit.agents - initializing job runner {\"tid\": 70854385}\n2025-06-05 22:49:08,210 - DEBUG asyncio - Using selector: KqueueSelector \n2025-06-05 22:49:08,211 - INFO livekit.agents - job runner initialized {\"tid\": 70854385, \"elapsed_time\": 0.0}\n2025-06-05 22:49:08,272 - WARNING livekit.agents - VAD is not set. Enabling VAD is recommended when using LLM and STT for more responsive interruption handling. \n2025-06-05 22:49:08,630 - DEBUG livekit.agents - http_session(): creating a new httpclient ctx \n2025-06-05 22:49:08,647 - ERROR livekit.agents - Error in _inference_task \nTraceback (most recent call last):\n  File \"/Users/xxxx/Projects/poc-mcp-server/.venv/lib/python3.13/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xxxx/Projects/poc-mcp-server/.venv/lib/python3.13/site-packages/livekit/agents/voice/generation.py\", line 85, in _inference_task\n    async for chunk in llm_node:\n    ...<29 lines>...\n            )\n  File \"/Users/xxxx/Projects/poc-mcp-server/.venv/lib/python3.13/site-packages/livekit/agents/voice/agent.py\", line 349, in llm_node\n    async with activity_llm.chat(\n               ~~~~~~~~~~~~~~~~~^\n        chat_ctx=chat_ctx, tools=tools, tool_choice=tool_choice\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ) as stream:\n    ^\n  File \"/Users/xxxx/Projects/poc-mcp-server/.venv/lib/python3.13/site-packages/livekit/plugins/anthropic/llm.py\", line 144, in chat\n    extra[\"tools\"] = to_fnc_ctx(tools, self._opts.caching)\n                     ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xxxx/Projects/poc-mcp-server/.venv/lib/python3.13/site-packages/livekit/plugins/anthropic/utils.py\", line 22, in to_fnc_ctx\n    tools.append(_build_anthropic_schema(fnc, cache_ctrl=cache_ctrl))\n                 ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xxxx/Projects/poc-mcp-server/.venv/lib/python3.13/site-packages/livekit/plugins/anthropic/utils.py\", line 141, in _build_anthropic_schema\n    fnc = llm.utils.build_legacy_openai_schema(function_tool, internally_tagged=True)\n  File \"/Users/xxxx/Projects/poc-mcp-server/.venv/lib/python3.13/site-packages/livekit/agents/llm/utils.py\", line 180, in build_legacy_openai_schema\n    info = get_function_info(function_tool)\n  File \"/Users/xxxx/Projects/poc-mcp-server/.venv/lib/python3.13/site-packages/livekit/agents/llm/tool_context.py\", line 196, in get_function_info\n    return cast(_FunctionToolInfo, getattr(f, \"__livekit_tool_info\"))\n                                   ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n```\n\n**Worked Changes:**\n\nand I changed the function **build_legacy_openai_schema** under the **llm.utils**  as follows, and it is working now. I believe this is not the correct solution. It is expected only **FunctionTool** is passed here, but it was raw_function_tool.\n\nsee current here:\nhttps://github.com/livekit/agents/blob/e7a240477ce6dfded8f6de80550ea80cdf640db2/livekit-agents/livekit/agents/llm/utils.py#L182\n\n```\ndef build_legacy_openai_schema(\n    function_tool: FunctionTool, *, internally_tagged: bool = False\n) -> dict[str, Any]:\n    \"\"\"non-strict mode tool description\n    see https://serde.rs/enum-representations.html for the internally tagged representation\"\"\"\n    model = function_arguments_to_pydantic_model(function_tool)\n    \n    name = None\n    description = None\n    \n    if  is_raw_function_tool(function_tool):\n        info = get_raw_function_info(function_tool)\n        name = info.name\n        description = info.raw_schema[\"description\"]\n    else:\n        info = get_function_info(function_tool)\n        name = info.name\n        description = info.description\n        \n    schema = model.model_json_schema()\n\n    if internally_tagged:\n        return {\n            \"name\": name,\n            \"description\": description or \"\",\n            \"parameters\": schema,\n            \"type\": \"function\",\n        }\n    else:\n        return {\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": name,\n                \"description\": description or \"\",\n                \"parameters\": schema,\n            },\n        }\n\n```\n\nSecondly somehow **raw_arguments** mislead the LLM about function arguments, as you can see below log, It calls the function tool with wrong arguments schema and gets an error. and re-tries with the correct argument schema.\n\n<img width=\"1639\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/2e3d5c6b-c4e5-45ba-8fa6-06174fe8fb53\" />\n\n\n**entrypoint code :**\n\n```\nasync def entrypoint(ctx: agents.JobContext):\n    session = AgentSession(\n        stt=deepgram.STT(model=\"nova-3\"),\n        llm=anthropic.LLM(\n            model=\"claude-3-5-sonnet-20241022\",\n            temperature=0.8,\n        ),\n        tts=elevenlabs.TTS(),\n        mcp_servers=[\n            mcp.MCPServerHTTP(\n                \"http://127.0.0.1:8000/mcp\"\n            )\n        ]\n    )\n\n    await session.start(\n        # room=ctx.room,\n        agent=MCPAssistant(),\n        room_input_options=RoomInputOptions(\n            noise_cancellation=noise_cancellation.BVC(),\n        ),\n        room_output_options=RoomOutputOptions()\n    )\n    # await ctx.connect()\n    await session.generate_reply(\n        instructions=\"say hi.\"\n    )\n```",
      "state": "closed",
      "author": "gsahancsc",
      "author_type": "User",
      "created_at": "2025-06-05T21:06:20Z",
      "updated_at": "2025-06-06T06:08:04Z",
      "closed_at": "2025-06-06T06:08:04Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2519/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2519",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2519",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:33.721758",
      "comments": [
        {
          "author": "gsahancsc",
          "body": "this is what MCP server returns\n\n```\nchunk: b'event: message\\r\\ndata: {\"jsonrpc\":\"2.0\",\"id\":1,\"result\":{\"tools\":[{\"name\":\"get_alerts\",\"description\":\"Get weather alerts for a US state.\\\\n\\\\nArgs:\\\\n\n                             state: Two-letter US state code (e.g. CA,                                ",
          "created_at": "2025-06-05T21:09:49Z"
        },
        {
          "author": "longcw",
          "body": "This should be fixed in https://github.com/livekit/agents/pull/2423, and will be included in next release. You can try it by installing from the main branch with `GIT_LFS_SKIP_SMUDGE=1 uv pip install git+https://github.com/livekit/agents@main#subdirectory=livekit-plugins/livekit-plugins-anthropic`, ",
          "created_at": "2025-06-06T01:40:58Z"
        }
      ]
    },
    {
      "issue_number": 2403,
      "title": "Tool calling seemingly broken on Cerebras",
      "body": "Using livekit agents **1.0.22**, cerebras and model `llama-4-scout-17b-16e-instruct`\nI'm getting the following error when making any tool call\n\n```python\n2025-05-26 21:31:18,919 - WARNING livekit.agents - failed to generate LLM completion, retrying in 2.0s\nTraceback (most recent call last):\n  File \"/Users/thavidur/dev/livekit/.venv/lib/python3.12/site-packages/livekit/agents/llm/llm.py\", line 138, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/thavidur/dev/livekit/.venv/lib/python3.12/site-packages/livekit/plugins/openai/llm.py\", line 623, in _run\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: Error code: 400 - {'message': \"'NoneType' object is not iterable\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'wrong_api_format'} (status_code=400, request_id=None, body={'message': \"'NoneType' object is not iterable\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'wrong_api_format'}) \n```\n\nthe tool itself actually does successfully get called but afterwards the agent breaks and no longer produces responses. In that same turn, no response is passed to the TTS part of the pipeline. The agent does continue to listen for one more turn since I see the transcription of my next turn arriving on screen, but then the LLM part errors out with the above ^ (it tries 4 times before exiting the worker).\n\nNote: I've noticed it sometimes calls the tool immediately at the start of the session too, other times only when I instruct it to, but either way the agent ends up in a messed up state after the tool call is done. The issue doesn't occur on the regular (non-cerebras) version of the openai plugin. The cerebras plugin also works great if no tools are provided to it.\n\n**Minimal example:**\n```python\nfrom dotenv import load_dotenv\n\nfrom livekit import agents\nfrom livekit.agents import AgentSession, Agent, RoomInputOptions\nfrom livekit.plugins import openai, cartesia, deepgram, noise_cancellation, silero\nfrom livekit.plugins.turn_detector.multilingual import MultilingualModel\nfrom livekit.agents.llm import function_tool\nfrom livekit.agents import RunContext\n\nload_dotenv()\n\n\nclass Assistant(Agent):\n    def __init__(self) -> None:\n        super().__init__(instructions=\"You are a helpful voice AI assistant.\")\n\n    @function_tool\n    async def magic_tool(self, ctx: RunContext):\n        print(\"magic tool called!\")\n\n\nasync def entrypoint(ctx: agents.JobContext):\n    session = AgentSession(\n        stt=deepgram.STT(model=\"nova-3\", language=\"multi\"),\n        # llm=openai.LLM(model=\"gpt-4o-mini\"),\n        llm=openai.LLM.with_cerebras(model=\"llama-4-scout-17b-16e-instruct\"),\n        tts=cartesia.TTS(),\n        vad=silero.VAD.load(),\n        turn_detection=MultilingualModel(),\n    )\n\n    await session.start(\n        room=ctx.room,\n        agent=Assistant(),\n        room_input_options=RoomInputOptions(\n            noise_cancellation=noise_cancellation.BVC(), \n        ),\n    )\n\n    await ctx.connect()\n\n    await session.generate_reply(\n        instructions=\"Greet the user and offer your assistance.\"\n    )\n\n\nif __name__ == \"__main__\":\n    agents.cli.run_app(agents.WorkerOptions(entrypoint_fnc=entrypoint))\n```",
      "state": "closed",
      "author": "thavidu",
      "author_type": "User",
      "created_at": "2025-05-27T04:49:26Z",
      "updated_at": "2025-06-06T06:04:55Z",
      "closed_at": "2025-06-06T06:04:54Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2403/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2403",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2403",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:33.986584",
      "comments": [
        {
          "author": "nikitavasilev",
          "body": "I also have the same issue with Cerebras.",
          "created_at": "2025-05-27T09:13:29Z"
        },
        {
          "author": "hsjun99",
          "body": "I'm on the subscription plan for cerebras, and this is what I've got a week ago from the team. (Might be related)\n\n> **Note**\n> This change will go into effect in **3 weeks**.\n\nWe're updating the **Cerebras Inference API** to better align with OpenAI’s schema expectations for tool calling.  \nThis wi",
          "created_at": "2025-05-28T00:26:17Z"
        },
        {
          "author": "davidzhao",
          "body": "We are in touch with the Cerebras team and they are working on fixing this on their end. Here's a script that reproduces the issue: https://gist.github.com/davidzhao/86d1f0777c8f9115c9c5b7af152db8b0",
          "created_at": "2025-05-29T07:28:37Z"
        },
        {
          "author": "davidzhao",
          "body": "Cerebras has fixed this issue with `llama-4-scout-17b-16e-instruct`",
          "created_at": "2025-06-06T06:03:49Z"
        },
        {
          "author": "davidzhao",
          "body": "closing this, and keeping #1154 for other models",
          "created_at": "2025-06-06T06:04:54Z"
        }
      ]
    },
    {
      "issue_number": 2493,
      "title": "LiveKit Voice Pipeline Agent: 3-4s first response delay - how to optimize?",
      "body": "\nVoice agent taking 3-4s for first response (local setup). Using STT+TTS+LLM+VAD+Multilingual Turn Detector. Anyone faced similar latency issues? Tips for optimization?\n\nI measured my voice agent pipeline latency: LLM TTFT (~2s) + TTS TTFB (~1.2s) + VAD (~0.4s) = 3.6s total. Expected <2s response time like production voice assistants. Looking for optimization strategies for each component and overall pipeline architecture improvements.\n\n",
      "state": "closed",
      "author": "Eemmreee",
      "author_type": "User",
      "created_at": "2025-06-03T08:10:06Z",
      "updated_at": "2025-06-05T06:42:34Z",
      "closed_at": "2025-06-05T06:42:33Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2493/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2493",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2493",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:34.212579",
      "comments": [
        {
          "author": "longcw",
          "body": "It depends on which model and where the model is deployed. You can try some fast LLM and TTS providers. For example, here is a benchmark for LLMs https://artificialanalysis.ai/leaderboards/providers",
          "created_at": "2025-06-03T13:43:13Z"
        },
        {
          "author": "davidzhao",
          "body": "the LLM TTFT is really slow. same as TTS.. you should try running the agent closer to the inference servers.\n\nin any case, this is not a livekit issue, but a model/runtime one. closing it here.",
          "created_at": "2025-06-05T06:42:33Z"
        }
      ]
    },
    {
      "issue_number": 2496,
      "title": "cannot load both english & multilingual EOU",
      "body": "If the code import both EOU, it will fail to start because the code has a hardcoded timeout of 30s\n\nHere is the code in question in worker.py\n\n```\n        self._inference_executor: ipc.inference_proc_executor.InferenceProcExecutor | None = None\n        if len(_InferenceRunner.registered_runners) > 0:\n            self._inference_executor = ipc.inference_proc_executor.InferenceProcExecutor(\n                runners=_InferenceRunner.registered_runners,\n                initialize_timeout=30,\n                close_timeout=5,\n                memory_warn_mb=2000,\n```\n\nNot sure why it ignores the initialize_process_timeout in WorkerOptions",
      "state": "open",
      "author": "trungduyvu",
      "author_type": "User",
      "created_at": "2025-06-03T09:38:41Z",
      "updated_at": "2025-06-05T06:41:08Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2496/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2496",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2496",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:34.458759",
      "comments": [
        {
          "author": "davidzhao",
          "body": "any reason why you'd want to load both?",
          "created_at": "2025-06-05T06:41:07Z"
        }
      ]
    },
    {
      "issue_number": 1324,
      "title": "Agent not getting track when another participant joins the room.",
      "body": "I'm using the livekit meet example where the agent auto joins the call. I want it to be able to communicate with all partiicipants that join the call but it isnt. Could you please check what could be wrong.\r\n\r\n`import asyncio\r\nimport logging\r\nfrom typing import Dict, Set\r\nfrom dataclasses import dataclass\r\n\r\nfrom dotenv import load_dotenv\r\nfrom livekit import rtc\r\nfrom livekit.agents import JobContext, WorkerOptions, cli, tokenize, tts\r\nfrom livekit.agents.llm import ChatContext, ChatMessage\r\nfrom livekit.agents.voice_assistant import VoiceAssistant\r\nfrom livekit.plugins import deepgram, openai, silero\r\n\r\n# Load environment variables\r\nload_dotenv(dotenv_path=\".env.local\")\r\n\r\n# Configure logging\r\nlogging.basicConfig(level=logging.INFO)\r\nlogger = logging.getLogger(__name__)\r\n\r\n@dataclass\r\nclass ParticipantState:\r\n    \"\"\"Track the state of each participant in the room.\"\"\"\r\n    identity: str\r\n    audio_track: rtc.AudioTrack = None\r\n    is_speaking: bool = False\r\n\r\nclass MultiParticipantVoiceAssistant(VoiceAssistant):\r\n    \"\"\"Enhanced voice assistant that handles multiple participants simultaneously.\"\"\"\r\n\r\n    def __init__(self, *args, **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n        self.participants: Dict[str, ParticipantState] = {}\r\n        self.conversation_history: list = []\r\n        self.processing_lock = asyncio.Lock()\r\n\r\n    async def process_audio_input(self, audio_data: bytes, participant_id: str):\r\n        \"\"\"Process audio input from a specific participant.\"\"\"\r\n        async with self.processing_lock:\r\n            try:\r\n                participant = self.participants.get(participant_id)\r\n                if not participant:\r\n                    logger.warning(f\"No participant state found for {participant_id}\")\r\n                    return\r\n\r\n                # Process the audio using STT\r\n                transcript = await self.stt.transcribe(audio_data)\r\n                if not transcript:\r\n                    return\r\n\r\n                # Update conversation history\r\n                self.conversation_history.append({\r\n                    \"speaker\": participant_id,\r\n                    \"message\": transcript,\r\n                })\r\n\r\n                # Generate response\r\n                response = await self.generate_contextual_response(participant_id, transcript)\r\n\r\n                # Broadcast response\r\n                await self.broadcast_response(response)\r\n\r\n                logger.info(f\"Processed audio from {participant_id}: {transcript}\")\r\n\r\n            except Exception as e:\r\n                logger.error(f\"Error processing audio from {participant_id}: {e}\")\r\n\r\n    async def generate_contextual_response(self, speaker_id: str, message: str) -> str:\r\n        \"\"\"Generate a response considering the conversation context.\"\"\"\r\n        context = \"\\n\".join([\r\n            f\"{entry['speaker']}: {entry['message']}\"\r\n            for entry in self.conversation_history[-5:]\r\n        ])\r\n\r\n        prompt = f\"\"\"\r\n        Recent conversation:\r\n        {context}\r\n\r\n        Current speaker ({speaker_id}): {message}\r\n\r\n        Please respond to the current speaker while maintaining context of the conversation.\r\n        \"\"\"\r\n        response = await self.llm.complete(prompt)\r\n        return response\r\n\r\n    async def broadcast_response(self, response: str):\r\n        \"\"\"Broadcast the assistant's response to all participants.\"\"\"\r\n        try:\r\n            audio_data = await self.tts.synthesize(response)\r\n\r\n            # Publish the audio track to all participants\r\n            if self.room:\r\n                for participant_id in self.participants:\r\n                    participant = self.room.get_participant(participant_id)\r\n                    if participant:\r\n                        await participant.publish_audio(audio_data)\r\n\r\n            logger.info(f\"Broadcasted response: {response}\")\r\n        except Exception as e:\r\n            logger.error(f\"Error broadcasting response: {e}\")\r\n\r\n    def add_participant(self, participant_id: str, audio_track: rtc.AudioTrack = None):\r\n        \"\"\"Add or update a participant in the assistant.\"\"\"\r\n        self.participants[participant_id] = ParticipantState(\r\n            identity=participant_id,\r\n            audio_track=audio_track\r\n        )\r\n        logger.info(f\"Added participant: {participant_id}\")\r\n\r\n    def remove_participant(self, participant_id: str):\r\n        \"\"\"Remove a participant from the assistant.\"\"\"\r\n        if participant_id in self.participants:\r\n            del self.participants[participant_id]\r\n            logger.info(f\"Removed participant: {participant_id}\")\r\n\r\nasync def handle_participant_audio(track: rtc.AudioTrack, participant: rtc.RemoteParticipant, assistant: MultiParticipantVoiceAssistant):\r\n    \"\"\"Handle audio from a specific participant.\"\"\"\r\n    CHUNK_SIZE = 1024 * 16\r\n\r\n    while True:\r\n        try:\r\n            audio_data = await track.read(CHUNK_SIZE)\r\n            if not audio_data:\r\n                continue\r\n\r\n            await assistant.process_audio_input(audio_data, participant.identity)\r\n        except Exception as e:\r\n            logger.error(f\"Error handling audio from {participant.identity}: {e}\")\r\n            break\r\n\r\nasync def setup_participant(participant: rtc.RemoteParticipant, assistant: MultiParticipantVoiceAssistant):\r\n    \"\"\"Set up a new participant with the assistant.\"\"\"\r\n    for publication in participant.track_publications.values():\r\n        if publication.kind == rtc.TrackKind.KIND_AUDIO:\r\n            try:\r\n                if not publication.subscribed:\r\n                    await publication.subscribe()\r\n\r\n                if publication.track:\r\n                    assistant.add_participant(participant.identity, publication.track)\r\n\r\n                    asyncio.create_task(\r\n                        handle_participant_audio(\r\n                            publication.track,\r\n                            participant,\r\n                            assistant\r\n                        )\r\n                    )\r\n            except Exception as e:\r\n                logger.error(f\"Error setting up participant {participant.identity}: {e}\")\r\n\r\nasync def entrypoint(ctx: JobContext):\r\n    \"\"\"Main entry point for the LiveKit agent.\"\"\"\r\n    await ctx.connect(auto_subscribe=True)\r\n    logger.info(f\"Connected to room: {ctx.room.name}\")\r\n\r\n    chat_context = ChatContext(\r\n        messages=[\r\n            ChatMessage(\r\n                role=\"system\",\r\n                content=(\r\n                    \"You are a helpful assistant in a multi-participant voice call. \"\r\n                    \"Pay attention to who is speaking and maintain conversation context. \"\r\n                    \"Address participants by their identifiers and ensure your responses \"\r\n                    \"are relevant to the ongoing conversation.\"\r\n                ),\r\n            )\r\n        ]\r\n    )\r\n\r\n    assistant = MultiParticipantVoiceAssistant(\r\n        vad=silero.VAD.load(),\r\n        stt=deepgram.STT(),\r\n        llm=openai.LLM(model=\"gpt-4\"),\r\n        tts=tts.StreamAdapter(\r\n            tts=openai.TTS(voice=\"alloy\"),\r\n            sentence_tokenizer=tokenize.basic.SentenceTokenizer(),\r\n        ),\r\n        chat_ctx=chat_context,\r\n    )\r\n\r\n    @ctx.room.on(\"participant_connected\")\r\n    def handle_participant_connected(participant: rtc.RemoteParticipant):\r\n        logger.info(f\"New participant connected: {participant.identity}\")\r\n        asyncio.create_task(setup_participant(participant, assistant))\r\n\r\n    @ctx.room.on(\"participant_disconnected\")\r\n    def handle_participant_disconnected(participant: rtc.RemoteParticipant):\r\n        logger.info(f\"Participant disconnected: {participant.identity}\")\r\n        assistant.remove_participant(participant.identity)\r\n\r\n    assistant.start(ctx.room)\r\n\r\n    for participant in ctx.room.remote_participants.values():\r\n        await setup_participant(participant, assistant)\r\n\r\n    await assistant.say(\r\n        \"Hello everyone! I'm ready to chat with all of you.\", allow_interruptions=True\r\n    )\r\n\r\n    while True:\r\n        await asyncio.sleep(1)\r\n\r\nif __name__ == \"__main__\":\r\n    cli.run_app(WorkerOptions(entrypoint_fnc=entrypoint))\r\n```",
      "state": "closed",
      "author": "Hemanth-TS",
      "author_type": "User",
      "created_at": "2025-01-02T02:53:22Z",
      "updated_at": "2025-06-04T14:28:15Z",
      "closed_at": "2025-01-02T18:19:47Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1324/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1324",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1324",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:34.684524",
      "comments": [
        {
          "author": "davidzhao",
          "body": "the VoicePipelineAgent is currently designed to work for one on one conversations. It does not support multi-user at the moment.",
          "created_at": "2025-01-02T18:19:47Z"
        },
        {
          "author": "IqbalLx",
          "body": "any references to custom built our voice agent that able to interact for all participants? @davidzhao ",
          "created_at": "2025-01-18T10:46:11Z"
        },
        {
          "author": "nitishymtpl",
          "body": "Hey everyone, any progress with respect to this thread.",
          "created_at": "2025-02-14T14:53:24Z"
        },
        {
          "author": "ILG2021",
          "body": "Also need this, any progress?",
          "created_at": "2025-04-22T21:18:53Z"
        },
        {
          "author": "longcw",
          "body": "In agents 1.0, you are now able to switch the linked participant in the room, see example https://github.com/livekit/agents/blob/main/examples/voice_agents/toggle_io.py#L43\n\nThe agent can hear one participant at a time and all participant can hear the agent.",
          "created_at": "2025-04-23T01:19:27Z"
        }
      ]
    },
    {
      "issue_number": 1171,
      "title": "Tools voice feedback isn't awaited.",
      "body": "In the examples for the voice-pipeline-agent, the function_calling_weather.py has an example on how to add tools to the agent. In line 43 it executes a say() function to give feedback to the user telling him that the tool is going to be used [await call_ctx.agent.say(message)] This function is not awaited and the agent returns the response before delivering the feedback message. ",
      "state": "closed",
      "author": "lschnoller",
      "author_type": "User",
      "created_at": "2024-12-04T09:03:10Z",
      "updated_at": "2025-06-04T10:59:21Z",
      "closed_at": "2025-06-04T10:59:21Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1171/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1171",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1171",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:34.915356",
      "comments": []
    },
    {
      "issue_number": 2382,
      "title": "Google STT streaming response missing \"is_final\" for \"FR-fr\"",
      "body": "Hello,\n\nI have an issue where the streaming never ends when talking.\n\n```\n            stt=google.STT(\n                model=\"chirp_2\",\n                languages=\"fr-FR\",\n                location=\"europe-west4\",\n                use_streaming=True,\n            )\n```\n\nI logged the response from the API and it transcribes correctly but it misses `is_final` in every responses from the stream.\nIt's like every utterance is added to the same stream that never ends.\n\nIt works when I disable the stream.\n\nIssue might come from the API I guess. It works well in \"en-US\".\n\n```\nPython: 3.10\nPackage                        Version\n------------------------------ ---------------\naiofiles                       24.1.0\naiohappyeyeballs               2.6.1\naiohttp                        3.11.18\naiosignal                      1.3.2\nannotated-types                0.7.0\nanyio                          4.9.0\nasync-timeout                  5.0.1\nattrs                          25.3.0\nav                             14.4.0\nazure-cognitiveservices-speech 1.44.0\nazure-core                     1.34.0\ncachecontrol                   0.14.3\ncachetools                     5.5.2\ncertifi                        2025.4.26\ncffi                           1.17.1\ncharset-normalizer             3.4.2\nclick                          8.2.1\ncolorama                       0.4.6\ncoloredlogs                    15.0.1\ncryptography                   45.0.2\ndistro                         1.9.0\ndocstring-parser               0.16\neval-type-backport             0.2.2\nexceptiongroup                 1.3.0\nfirebase-admin                 6.8.0\nflatbuffers                    25.2.10\nfrozenlist                     1.6.0\ngoogle-api-core                2.24.2\ngoogle-api-python-client       2.170.0\ngoogle-auth                    2.40.2\ngoogle-auth-httplib2           0.2.0\ngoogle-cloud-core              2.4.3\ngoogle-cloud-firestore         2.20.2\ngoogle-cloud-speech            2.32.0\ngoogle-cloud-storage           3.1.0\ngoogle-cloud-texttospeech      2.27.0\ngoogle-crc32c                  1.7.1\ngoogle-genai                   1.16.1\ngoogle-resumable-media         2.7.2\ngoogleapis-common-protos       1.70.0\ngrpcio                         1.71.0\ngrpcio-status                  1.71.0\nh11                            0.16.0\nhttpcore                       1.0.9\nhttplib2                       0.22.0\nhttpx                          0.28.1\nhumanfriendly                  10.0\nidna                           3.10\njiter                          0.10.0\nlivekit                        1.0.8\nlivekit-agents                 1.0.22\nlivekit-api                    1.0.2\nlivekit-plugins-azure          1.0.22\nlivekit-plugins-cartesia       1.0.22\nlivekit-plugins-deepgram       1.0.22\nlivekit-plugins-google         1.0.22\nlivekit-plugins-openai         1.0.22\nlivekit-plugins-silero         1.0.22\nlivekit-protocol               1.0.3\nloguru                         0.7.3\nmpmath                         1.3.0\nmsgpack                        1.1.0\nmultidict                      6.4.4\nnest-asyncio                   1.6.0\nnumpy                          2.2.6\nonnxruntime                    1.22.0\nopenai                         1.82.0\npackaging                      25.0\npillow                         11.2.1\npropcache                      0.3.1\nproto-plus                     1.26.1\nprotobuf                       5.29.4\npsutil                         7.0.0\npyasn1                         0.6.1\npyasn1-modules                 0.4.2\npycparser                      2.22\npydantic                       2.11.5\npydantic-core                  2.33.2\npyjwt                          2.10.1\npyparsing                      3.2.3\npython-dotenv                  1.0.1\npython-json-logger             3.3.0\npytz                           2025.2\nrequests                       2.32.3\nrsa                            4.9.1\nsix                            1.17.0\nsniffio                        1.3.1\nsounddevice                    0.5.2\nsympy                          1.14.0\ntqdm                           4.67.1\ntypes-protobuf                 4.25.0.20240417\ntyping-extensions              4.13.2\ntyping-inspection              0.4.1\nuritemplate                    4.1.1\nurllib3                        2.4.0\nwatchfiles                     1.0.5\nwebsockets                     15.0.1\nyarl                           1.20.0\n```",
      "state": "open",
      "author": "aurelien-ldp",
      "author_type": "User",
      "created_at": "2025-05-23T13:09:45Z",
      "updated_at": "2025-06-04T05:35:24Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2382/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2382",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2382",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:34.915379",
      "comments": [
        {
          "author": "Terisback",
          "body": "It doesn't work for either, minimal setup - only credentials file.",
          "created_at": "2025-05-23T15:42:29Z"
        },
        {
          "author": "Terisback",
          "body": "nvm, google fixed it",
          "created_at": "2025-06-04T05:35:23Z"
        }
      ]
    },
    {
      "issue_number": 2431,
      "title": "[NEW] Gemini Native [TTS] Support [AMAZING]",
      "body": "Hey Team, have you guys seen the new - https://ai.google.dev/gemini-api/docs/speech-generation\n\nYou can test it on AI studio - https://aistudio.google.com/generate-speech\n\nPlans on supporting the Native TTS for Gemini as an addon to the google plugin? \n\nThe quality of this module is better then 11 Labs and PlayHT by 2 Levels up. \nMulti Language support is amazing, and price is much cheaper then 11 Labs and others\n\nNo Steaming support yet only from the live API\n\nbut this is something to look at for the future ",
      "state": "open",
      "author": "mercuryyy",
      "author_type": "User",
      "created_at": "2025-05-28T21:37:38Z",
      "updated_at": "2025-06-03T23:08:16Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2431/reactions",
        "total_count": 9,
        "+1": 8,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 1
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2431",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2431",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:35.252267",
      "comments": [
        {
          "author": "Goktug",
          "body": "Actually, it seems like there is streaming support as well.\n\nhttps://ai.google.dev/gemini-api/docs/speech-generation#stream",
          "created_at": "2025-05-29T05:53:47Z"
        },
        {
          "author": "mercuryyy",
          "body": "I saw that, tried few variations its not actual streaming from the API endpoint, please share snippet if you can get it working! ",
          "created_at": "2025-05-30T00:05:50Z"
        },
        {
          "author": "PROTAG0N1ST",
          "body": "@mercuryyy\n> I saw that, tried few variations its not actual streaming from the API endpoint, please share snippet if you can get it working!\n\n```Python\n# pip install google-genai\n\nimport base64\nimport mimetypes\nimport os\nimport re\nimport struct\nfrom google import genai\nfrom google.genai import type",
          "created_at": "2025-06-03T21:35:31Z"
        },
        {
          "author": "PROTAG0N1ST",
          "body": "@theomonnom Gemini should have a separate plugin, rather than combining everything into a single Google plugin.\nPlease add the new TTS models ``gemini-2.5-flash-preview-tts`` and ``gemini-2.5-pro-preview-tts`` to the plugin.\n",
          "created_at": "2025-06-03T22:02:20Z"
        },
        {
          "author": "mercuryyy",
          "body": "I think it should be inside the google TTS plugin as its own settings",
          "created_at": "2025-06-03T23:08:15Z"
        }
      ]
    },
    {
      "issue_number": 2497,
      "title": "Call SIP Participant using phone number of another SIP Participant",
      "body": "Hello,\n\nI would like to replace an SIP transfert with adding the user in the room.\nLike SIP user A wants to talk to SIP user B, instead of doing an SIP transfert, which would make the user leave the room:\nI would like to add the other user in the room and let them talk together inside the room.\n\nHowever doing to means we ring the user B with our phone number and not user A's phone number.\n\nIs there a way of rigging the SIP user B from the phone number of SIP user A instead of the one of the outbound trunk?\n\nIf not possible, is there a workaround?\n",
      "state": "open",
      "author": "CyprienRicqueB2L",
      "author_type": "User",
      "created_at": "2025-06-03T16:13:38Z",
      "updated_at": "2025-06-03T16:13:38Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2497/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2497",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2497",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:35.471098",
      "comments": []
    },
    {
      "issue_number": 2467,
      "title": "Tavus avatar could not start/follow with the given system instruction",
      "body": "Hi Team,\n\nTavus avatar could not start/follow with the given system instruction, it's just starts like general assistance. refer below code, I tried creating new conversation in Tavus portal by setting conversational context and it it works fine.\n\nawait session.start(\n        agent=Agent(instructions=os.getenv(\"MedicalAssistanceInstruction\")),\n        room=ctx.room,\n        # audio is forwarded to the avatar, so we disable room audio output\n        room_output_options=RoomOutputOptions(audio_enabled=False),\n    )\n\nHope this will be resolved ASAP.\n\nThanks,\nSaravanan",
      "state": "closed",
      "author": "saravatpt",
      "author_type": "User",
      "created_at": "2025-06-01T03:34:27Z",
      "updated_at": "2025-06-03T10:32:25Z",
      "closed_at": "2025-06-03T10:32:24Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2467/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2467",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2467",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:35.471119",
      "comments": [
        {
          "author": "longcw",
          "body": "Dose that work when not using the tavus avatar plugin? The agent should be the same no matter the avatar plugin used or not, so I don't think it's related to avatar but the agent configuration.",
          "created_at": "2025-06-01T03:40:38Z"
        },
        {
          "author": "saravatpt",
          "body": "I was using persona from tavus stock (which has prebuilt system instruction from tavus), when I create new one and use it with Agent it worked fine.\n\nThanks,\nSravanan",
          "created_at": "2025-06-03T10:32:24Z"
        }
      ]
    },
    {
      "issue_number": 1144,
      "title": "Can not hang up the phone call when use sip with twilio",
      "body": "I have test this method in issue 1033, but the call can not hangup. \r\n\r\n[https://github.com/livekit/agents/issues/1033](url)\r\n\r\n    async def _cleanup_room(self, room_name: str):\r\n        \"\"\"Clean up the room after the conversation\"\"\"\r\n        try:\r\n            bot_logger.info(f\"Attempting to delete room: {room_name}\")\r\n            await self.api.room.delete_room(api.DeleteRoomRequest(room=room_name))\r\n            bot_logger.info(f\"Successfully deleted room: {room_name}\")\r\n        except Exception as e:\r\n            bot_logger.error(f\"Error deleting room: {e}\")\r\n\r\nWhy the room is deleted but the phone call is still exists? \r\nhow to do a hangup by agent side?",
      "state": "closed",
      "author": "ericyue",
      "author_type": "User",
      "created_at": "2024-11-27T16:36:35Z",
      "updated_at": "2025-06-03T10:28:03Z",
      "closed_at": "2024-11-28T18:09:28Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1144/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1144",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1144",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:35.678949",
      "comments": [
        {
          "author": "ericyue",
          "body": "got it ",
          "created_at": "2024-11-28T18:09:29Z"
        },
        {
          "author": "duan-nguyen",
          "body": "how? i have the same issue..",
          "created_at": "2025-02-10T13:30:26Z"
        },
        {
          "author": "Aillian",
          "body": "How to hangup the call? ",
          "created_at": "2025-06-03T10:28:02Z"
        }
      ]
    },
    {
      "issue_number": 2378,
      "title": "Using `Annotated[T | None, Field(...)]` as tool arg raises error on None",
      "body": "When I use annotated parameters for my function tools that are also allowed to be nullable, it throws an error:\n\n```txt\nTraceback (most recent call last):\n  File \"/Users/[...]/.venv/lib/python3.13/site-packages/livekit/agents/voice/generation.py\", line 336, in _execute_tools_task\n    fnc_args, fnc_kwargs = llm_utils.prepare_function_arguments(\n                           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        fnc=function_tool,\n        ^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        ),\n        ^^\n    )\n    ^\n  File \"/Users/[...]/.venv/lib/python3.13/site-packages/livekit/agents/llm/utils.py\", line 352, in prepare_function_arguments\n    raise ValueError(\n    ...<2 lines>...\n    )\nValueError: Received None for required parameter 'my_param ;this argument cannot be None and no default is available.\n```\n\n### Example code:\n\n```python\nclass MyAgent(Agent):\n    @function_tool()\n    async def my_tool(self, my_param: Annotated[int | None, Field(description=...)]):\n        ...\n```",
      "state": "closed",
      "author": "dvschuyl",
      "author_type": "User",
      "created_at": "2025-05-23T08:33:38Z",
      "updated_at": "2025-06-03T09:23:00Z",
      "closed_at": "2025-06-03T09:23:00Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2378/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2378",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2378",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:35.885819",
      "comments": [
        {
          "author": "namdoel1412",
          "body": "I caught that error too. When I use annotation @function_tool it was fine. But when I use function function_tool(f=..., raw_schema=) and I caught this error when trigger any function on inprogress call",
          "created_at": "2025-05-31T17:31:02Z"
        },
        {
          "author": "longcw",
          "body": "created a fix in https://github.com/livekit/agents/pull/2491, before that you can use docstring to describe the args, for example\n```python\n    @function_tool\n    async def get_number(self, value: int | None) -> str:\n        \"\"\"\n        Called when the user wants to get a number value, None if user ",
          "created_at": "2025-06-03T03:39:33Z"
        }
      ]
    },
    {
      "issue_number": 2448,
      "title": "Upgrading to 1.0.23 throws an exception when deleting room",
      "body": "When testing an upgrade to 1.0.23, our Livekit server API code to delete a room started throwing an exception:\n\nCode:\n`await job_ctx.api.room.delete_room(api.DeleteRoomRequest(room=room_name))`\n\nException:\n```\n2025-05-29 16:27:04,297 - ERROR voice - [livekit-web-20250529T2325-z_FyAT] Error deleting room: [Errno 1] [SSL: APPLICATION_DATA_AFTER_CLOSE_NOTIFY] application data after close notify (_ssl.c:2685) {\"room\": \"livekit-web-20250529T2325-z_FyAT\", \"pid\": 223095, \"job_id\": \"AJ_XoPGoArcSwhQ\"}\n2025-05-29 16:27:04,298 - ERROR root - Error while closing connector: ClientConnectionError('Connection lost: [SSL: APPLICATION_DATA_AFTER_CLOSE_NOTIFY] application data after close notify (_ssl.c:2685)') {\"room\": \"livekit-web-20250529T2325-z_FyAT\", \"pid\": 223095, \"job_id\": \"AJ_XoPGoArcSwhQ\"}\n```\n\nVersions\n```\nlivekit==1.0.8\nlivekit-agents==1.0.23\nlivekit-api==1.0.2\nlivekit-plugins-noise-cancellation==0.2.4\nlivekit-plugins-openai==1.0.23\nlivekit-plugins-turn-detector==1.0.23\nlivekit-protocol==1.0.3\n```\n\nPotentially related issue: https://livekit-users.slack.com/archives/C07FY8WHGPM/p1748505436178129",
      "state": "open",
      "author": "yuyuma",
      "author_type": "User",
      "created_at": "2025-05-30T00:18:48Z",
      "updated_at": "2025-06-03T09:02:26Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2448/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2448",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2448",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:36.103452",
      "comments": [
        {
          "author": "davidzhao",
          "body": "this looks to be an SSL issue, do you have the right certs installed?",
          "created_at": "2025-05-31T06:23:04Z"
        },
        {
          "author": "yuyuma",
          "body": "Hi @davidzhao can you please clarify what certs you're referring to?  We have a standard setup using Livekit Cloud with automatic agent dispatch. There are no cert considerations in this setup to my knowledge.\n\nI should have also mentioned in the original post, but we are on 1.0.22 currently and thi",
          "created_at": "2025-05-31T17:01:01Z"
        },
        {
          "author": "davidzhao",
          "body": "in your docker image, you'd need to install `ca-certs` or similar packages. the function you are calling is not part of livekit agents.. it's from `livekit-api` package.. I'm confused as to how updating agents to 1.0.23 would affect it",
          "created_at": "2025-06-01T07:19:53Z"
        },
        {
          "author": "yuyuma",
          "body": "@davidzhao I did a little more triaging. The issue can be replicated in the minimal worker example here.\n\nLooks like there is a connection to the agents package via `get_job_context` which might be what's causing the issue here, though I don't know enough about the internals to understand root cause",
          "created_at": "2025-06-02T17:16:56Z"
        },
        {
          "author": "longcw",
          "body": "@yuyuma I cannot reproduce it with 1.0.23 with your example, this is the log I got\n```bash\n2025-06-03 09:43:54,456 - INFO livekit.agents - received job request {\"job_id\": \"AJ_grtBZcQHdYHJ\", \"dispatch_id\": \"\", \"room_name\": \"playground-oi0N-N4YN\", \"agent_name\": \"\", \"resuming\": false}\n2025-06-03 09:43:",
          "created_at": "2025-06-03T01:46:22Z"
        }
      ]
    },
    {
      "issue_number": 1164,
      "title": "Questions About Audio Frame Processing",
      "body": "We have implemented Voice Activity Detection (VAD) on the client side using client-sdk-android for the client and LiveKit Agent for the server. We are currently unable to synchronize the frontend VAD events since we cannot add timestamps and metadata to audio frames.\r\n1. Is there a way to utilize the client-side VAD events?\r\n2. Can we add extra information to the audio frame?\r\n3. Is it possible to push variable-length audio streams to the audio track?\r\nThank you for any response.\r\n",
      "state": "closed",
      "author": "xiaoxiper",
      "author_type": "User",
      "created_at": "2024-12-03T01:43:09Z",
      "updated_at": "2025-06-03T07:35:11Z",
      "closed_at": "2025-06-03T07:35:11Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1164/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1164",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1164",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:36.340962",
      "comments": []
    },
    {
      "issue_number": 2229,
      "title": "ImportError: cannot import name 'VoiceAssistant' from 'livekit.agents.voice' (C:\\Users\\Desktop\\voice assistant\\venv\\Lib\\site-packages\\livekit\\agents\\voice\\__init__.py)",
      "body": "Your OS.: windows\nPython version. : Python 3.11.2\nPip version. : pip 25.1.1\nThe exact livekit-agents versions i have tried. : 1.0.17, 1.0.18, 1.0.19\nThe fact that voice_assistant.py is missing from the installed package and VoiceAssistant cannot be imported from livekit.agents.voice.\n",
      "state": "closed",
      "author": "anshulpwappgo",
      "author_type": "User",
      "created_at": "2025-05-08T09:44:08Z",
      "updated_at": "2025-06-03T04:33:30Z",
      "closed_at": "2025-05-08T09:47:13Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2229/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2229",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2229",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:36.340982",
      "comments": [
        {
          "author": "longcw",
          "body": "There is no `VoiceAssistant` class, please check the [examples](https://github.com/livekit/agents?tab=readme-ov-file#simple-voice-agent) or [docs](https://docs.livekit.io/agents/build/).",
          "created_at": "2025-05-08T09:47:13Z"
        },
        {
          "author": "krizz711",
          "body": "You can find the LiveKit Agents voice assistant in older versions, such as 0.9.0",
          "created_at": "2025-06-03T04:33:29Z"
        }
      ]
    },
    {
      "issue_number": 1372,
      "title": "Gemini Multimodal Agent Error 1",
      "body": "Hello! I am trying to run [gemini_agent.py](https://github.com/livekit/agents/blob/main/examples/multimodal-agent/gemini_agent.py) and I encountered the following error\r\n\r\n`2025-01-13 20:35:26,630 - ERROR livekit.agents - Error in _capture_task\r\nTraceback (most recent call last):\r\nFile \"/usr/local/lib/python3.12/dist-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\r\nreturn await fn(*args, **kwargs)\r\n       ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n      File \"/usr/local/lib/python3.12/dist-packages/livekit/agents/multimodal/agent_playout.py\", line 138, in _capture_task\r\n   await self._source.capture_frame(f)\r\n  File \"/usr/local/lib/python3.12/dist-packages/livekit/rtc/audio_source.py\", line 152, in capture_frame\r\n   raise Exception(cb.capture_audio_frame.error)\r\n Exception: an RtcError occured: InvalidState - failed to capture frame`\r\n \r\n \r\n Can I get some help please? ",
      "state": "closed",
      "author": "shaunakjoshi12",
      "author_type": "User",
      "created_at": "2025-01-14T19:14:18Z",
      "updated_at": "2025-06-02T20:33:50Z",
      "closed_at": "2025-05-27T06:31:03Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1372/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1372",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1372",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:36.559477",
      "comments": [
        {
          "author": "davidzhao",
          "body": "please upgrade to v1.x, we've rewritten Gemini Live support there.",
          "created_at": "2025-05-27T06:31:03Z"
        },
        {
          "author": "shaunakjoshi12",
          "body": "Thank you!",
          "created_at": "2025-06-02T20:33:49Z"
        }
      ]
    },
    {
      "issue_number": 1373,
      "title": "Gemini Multimodal Agent Error 2",
      "body": "Hello! I am trying to run [gemini_agent.py](https://github.com/livekit/agents/blob/main/examples/multimodal-agent/gemini_agent.py) and I encountered the following error\r\n\r\n` Exception ignored in: <coroutine object TTSSegmentsForwarder._main_task at 0x7ffff218d940>\r\nTraceback (most recent call last):\r\nFile \"/usr/local/lib/python3.12/dist-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\r\n2025-01-13 20:35:43,459 - ERROR livekit.agents - Error in _main_task\r\nTraceback (most recent call last):\r\nFile \"/usr/local/lib/python3.12/dist-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\r\n   return await fn(*args, **kwargs)\r\n       ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n RuntimeError: coroutine ignored GeneratorExit {\"pid\": 75, \"job_id\": \"AJ_vKkaFxQ5K487\"}\r\n   return await fn(*args, **kwargs)\r\n      ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n RuntimeError: coroutine ignored GeneratorExit`\r\n \r\n Need some help please!",
      "state": "closed",
      "author": "shaunakjoshi12",
      "author_type": "User",
      "created_at": "2025-01-14T19:16:58Z",
      "updated_at": "2025-06-02T20:33:11Z",
      "closed_at": "2025-05-27T06:31:35Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1373/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1373",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1373",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:36.775410",
      "comments": [
        {
          "author": "jayeshp19",
          "body": "Hi @shaunakjoshi12, Thank you for reporting this issue with Gemini. Could you confirm if these errors are reproducible? It would help if you could share the steps to replicate the issue, so we can investigate and work on a fix.",
          "created_at": "2025-01-15T16:13:30Z"
        },
        {
          "author": "shaunakjoshi12",
          "body": "Hi @jayeshp19 thank you very much for responding! All you need to do is \r\n1. host a server on a port (eg. 8000) by executing `python3 /app/src/gemini_agent.py dev`\r\n2. Run a frontend application to connect to that server.\r\n\r\nI have observed after numerous tests that there is no fixed pattern where i",
          "created_at": "2025-01-15T19:44:18Z"
        },
        {
          "author": "shaunakjoshi12",
          "body": "Hey @jayeshp19 did anything come out of it? Thanks",
          "created_at": "2025-03-08T00:32:26Z"
        },
        {
          "author": "davidzhao",
          "body": "please upgrade to v1.x, we've rewritten Gemini Live support there.",
          "created_at": "2025-05-27T06:31:35Z"
        },
        {
          "author": "shaunakjoshi12",
          "body": "Thank you!",
          "created_at": "2025-06-02T20:33:09Z"
        }
      ]
    },
    {
      "issue_number": 2470,
      "title": "named agents does not register worker",
      "body": "I have created sip inbound and dispatch rule: \n[https://docs.livekit.io/sip/dispatch-rule/#caller-dispatch-rule-individual-](url), It seems room_config is not set although I used the same code from doc.\n\nAnyhow, it works for unnamed agent, agent receives sip calls. logs from server are:\n\n`2025-06-01T09:00:13.382Z        INFO    livekit service/roomallocator.go:164    selected node for room  {\"room\": \"call-_0568566878_ktsUGApy3SsP\", \"selectedNodeID\": \"ND_KNZ7B7M85jg7\"}\n..\n2025-06-01T09:00:13.823Z        INFO    livekit.agents  service/agentservice.go:384     assigned job to worker  {\"jobID\": \"AJ_gEHUkVzpfvU3\", \"namespace\": \"\", **\"agentName\": \"\"**, \"room\": \"call-_0568566878_ktsUGApy3SsP\", \"roomID\": \"RM_Nmt8T8MYS2Jc\", \"workerID\": \"AW_hn3nLZPb6xb2\"}`\n\n\nThe setup works for unnamed default agent, but for named agent 'agent-1' worker fails to dispatch agent for sip call:\n`\n2025-06-01T09:17:43.482Z        INFO    livekit.agents  service/agentservice.go:275     worker registered       {\"namespace\": \"\", \"jobType\": \"JT_ROOM\", **\"agentName\": \"agent-1\"**, \"workerID\": \"AW_zXe3KJBvcifa\"}\n2025-06-01T09:18:09.324Z        INFO    livekit service/roomallocator.go:164    selected node for room  {\"room\": \"call-_0568566878_GWWSgnsDmUCs\", \"selectedNodeID\": \"ND_KNZ7B7M85jg7\"}\n...\n2025-06-01T09:18:10.341Z        INFO    livekit agent/client.go:161     failed to send job request      {\"error\": \"no response from servers\", \"namespace\": \"\", \"jobType\": \"JT_ROOM\", **\"agentName\": \"\"**}`",
      "state": "closed",
      "author": "rashad-leapai",
      "author_type": "User",
      "created_at": "2025-06-01T09:19:58Z",
      "updated_at": "2025-06-02T16:22:17Z",
      "closed_at": "2025-06-01T16:18:25Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2470/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2470",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2470",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:36.983864",
      "comments": [
        {
          "author": "davidzhao",
          "body": "make sure you are running the latest version of services. this is not an issue with agents as it's registering itself correctly.",
          "created_at": "2025-06-01T16:18:25Z"
        },
        {
          "author": "rashad-leapai",
          "body": "@davidzhao I am using the latest versions. the issue with dispatch rule I used the example [https://docs.livekit.io/sip/dispatch-rule/#caller-dispatch-rule-individual-](url) but room config is not picked correctly so agent name is not attached with dispatch rule.\n\nThis is the output for dispatch rul",
          "created_at": "2025-06-02T09:33:39Z"
        },
        {
          "author": "rashad-leapai",
          "body": "server version is v1.8.3",
          "created_at": "2025-06-02T09:45:04Z"
        },
        {
          "author": "rashad-leapai",
          "body": "For anyone comes across, the issue is 'pass RoomConfig along when creating a new dispatch rule' [https://github.com/livekit/livekit/releases/tag/v1.8.4](url) which resolved on server v1.8.4 , where latest helm chart version is v1.8.3 [https://github.com/livekit/livekit-helm](url)",
          "created_at": "2025-06-02T10:54:36Z"
        },
        {
          "author": "davidzhao",
          "body": "thanks for the heads up. I didn't realize helm has been behind for this long.. we'll update it shortly",
          "created_at": "2025-06-02T16:22:16Z"
        }
      ]
    },
    {
      "issue_number": 2486,
      "title": "Error trying to run agent",
      "body": "Hi, I'm trying to run my agent and I'm getting constantly this error:\n\nFile \"/Users/neymartes/Projects/Web/livekit-examples/basic-agent/.venv/lib/python3.11/site-packages/aiohttp/connector.py\", line 1143, in _wrap_create_connection\n    raise ClientConnectorCertificateError(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorCertificateError: Cannot connect to host \"my-url\".livekit.cloud:443 ssl:True [SSLCertVerificationError: (1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')]\n\nI followed the steps of the Voice AI Quickstart docs, installed the dependencies and added all my keys in the .env file. I tried several times but I'm always getting this error.\n\nI'm using the latest agents version. \n",
      "state": "closed",
      "author": "neymartes",
      "author_type": "User",
      "created_at": "2025-06-02T13:39:57Z",
      "updated_at": "2025-06-02T14:32:11Z",
      "closed_at": "2025-06-02T14:32:11Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2486/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2486",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2486",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:37.211928",
      "comments": [
        {
          "author": "neymartes",
          "body": "I just updated my python version to 3.13.3 and worked well.",
          "created_at": "2025-06-02T14:32:08Z"
        }
      ]
    },
    {
      "issue_number": 1157,
      "title": "Pass metadata param to OpenAI client",
      "body": "Hi team,\r\n\r\nAs I am looking to set up a proxy between agent server and openai server, I am going to need to pass in some metadata. So I can do some pre-checks before the request hits openai server. As of now, the current LLM interface doesn't support that. I think it'd be small changes that are useful for anyone looking to make use of metadata param from openai client.",
      "state": "closed",
      "author": "hoangtran98",
      "author_type": "User",
      "created_at": "2024-12-01T20:38:08Z",
      "updated_at": "2025-06-02T07:35:24Z",
      "closed_at": "2025-06-02T07:35:24Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1157/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1157",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1157",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:37.396921",
      "comments": []
    },
    {
      "issue_number": 2473,
      "title": "How to prevent avatar from leaving the call?",
      "body": "The current behaviour is that the tavus avatar agent leaves the room when the user leaves.\n\nI would like the avatar to stay in the room even if the user leaves OR reconnect if the user reconnects.\n\nI would like to avoid a situation when the user leaves and then reconnects, but the tavus avatar is gone.\n\nThanks!",
      "state": "closed",
      "author": "koakuma-chan",
      "author_type": "User",
      "created_at": "2025-06-01T15:21:02Z",
      "updated_at": "2025-06-02T07:13:03Z",
      "closed_at": "2025-06-02T07:13:02Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2473/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2473",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2473",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:37.396947",
      "comments": [
        {
          "author": "longcw",
          "body": "duplicated by https://github.com/livekit/agents/issues/2480",
          "created_at": "2025-06-02T07:13:02Z"
        }
      ]
    },
    {
      "issue_number": 2461,
      "title": "Rime TTS Plugin Generates Clicking Noises on Linux",
      "body": "On MacOS, there are no clicking sounds. Core Audio smooths out the playback. When I deploy to a Linux environment the discontinuity creates a click.\n\nI have found that this has to do with discontinuities as a result of audio encodings and sampling rates.\n\nRime supports pcm, wav, and mp3. The plugin enforces wav for the arcana model and mp3 otherwise.\n\nDocumentation says there is an audio_format parameter in the Rime TTS object but there is not. https://docs.livekit.io/agents/integrations/tts/rime/\nhttps://docs.livekit.io/reference/python/v1/livekit/plugins/rime/index.html#livekit.plugins.rime.TTS\n\n",
      "state": "closed",
      "author": "chrismarciniak",
      "author_type": "User",
      "created_at": "2025-05-31T00:05:07Z",
      "updated_at": "2025-06-02T05:41:01Z",
      "closed_at": "2025-06-01T18:46:17Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2461/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2461",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2461",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:37.595938",
      "comments": [
        {
          "author": "davidzhao",
          "body": "Agents do not use core audio on the Mac either. Do you have audio recordings that could demonstrate what you are seeing?",
          "created_at": "2025-06-01T16:47:55Z"
        },
        {
          "author": "chrismarciniak",
          "body": "I am mistaken. I have audio of the clicks but it turns out they were from the Deepgram tts that I had as a fallback adapter. \n\nThank you for your attention to this. I will close this one. The only thing that stands is the discrepancy in the docs around the audio_format parameter",
          "created_at": "2025-06-01T18:46:17Z"
        },
        {
          "author": "davidzhao",
          "body": "thanks for confirming! deepgram TTS did have an issue with clicking noises. this has already been fixed and will be released soon.",
          "created_at": "2025-06-02T05:40:59Z"
        }
      ]
    },
    {
      "issue_number": 2477,
      "title": "stt multimodels",
      "body": "why i can t use \"gemini-2.0-flash\" as sst or directly used to get audio input in the llm",
      "state": "open",
      "author": "yahyasamet",
      "author_type": "User",
      "created_at": "2025-06-02T01:54:04Z",
      "updated_at": "2025-06-02T01:54:04Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2477/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2477",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2477",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:37.839026",
      "comments": []
    },
    {
      "issue_number": 2465,
      "title": "AssertionError in turn_detector: “end_of_utterance prediction should always return a result”",
      "body": "# AssertionError in turn_detector: “end_of_utterance prediction should always return a result”\n\n## Description\nWhen running the LiveKit Agents voice bot inside Docker (GCP VM), the turn detector fails as soon as the user speaks after the bot’s first speech. The `MultilingualModel().predict_end_of_turn` method returns `None`, triggering an assertion error.\n\n## Steps to Reproduce\n1. Clone the repository and place the provided `Dockerfile`, `docker-compose.yml`, `requirements.txt`, and code snippet (below) into the project root.\n2. Build and start the container:\n   ```bash\n   docker-compose up --build\n3. Wait for the bot to initialize and deliver its first speech.\n4. Speak to the bot (first or subsequent utterances).\n5. Observe the following error in logs: AssertionError: end_of_utterance prediction should always return a result\n\n\n# Code Snippet (AgentSession Configuration)\n```python\nfrom livekit.agents import AgentSession\nfrom livekit.plugins.turn_detector.multilingual import MultilingualModel\n# ...\nsession = AgentSession(\n    stt=stt,\n    llm=llm,\n    tts=tts,\n    vad=silero.VAD.load(),\n    turn_detection=MultilingualModel(),\n    allow_interruptions=True,\n    min_interruption_duration=1,\n    min_interruption_words=3\n)\n```\n\n\n# Relevant Log Excerpt\n```\n{\"message\": \"Error in _bounce_eou_task\", \"level\": \"ERROR\", \"name\": \"livekit.agents\", \"pid\": 25, \"job_id\": \"AJ_mKhPTx564xvC\", \"timestamp\": \"2025-05-31T20:24:58.014345+00:00\"}\nTraceback (most recent call last):\n  File \".../livekit/agents/voice/audio_recognition.py\", line 321, in _bounce_eou_task\n    end_of_turn_probability = await turn_detector.predict_end_of_turn(chat_ctx)\n  File \".../livekit/plugins/turn_detector/base.py\", line 205, in predict_end_of_turn\n    assert result is not None, \"end_of_utterance prediction should always returns a result\"\nAssertionError: end_of_utterance prediction should always returns a result\n```\n\n\n# Environment\n- GCP VM: e2-small (2 vCPUs, 2 GB RAM) on Intel Broadwell (x86_64)\n- Dockerfile (Python 3.11.6-slim):\n```dockerfile\nARG PYTHON_VERSION=3.11.6\nFROM python:${PYTHON_VERSION}-slim\nENV PYTHONUNBUFFERED=1\nARG UID=10001\nRUN adduser --disabled-password --gecos \"\" --home \"/home/appuser\" --shell \"/sbin/nologin\" --uid \"${UID}\" appuser\nRUN apt-get update && apt-get install -y gcc python3-dev && rm -rf /var/lib/apt/lists/*\nUSER appuser\nRUN mkdir -p /home/appuser/.cache && chown -R appuser /home/appuser/.cache\nWORKDIR /home/appuser\nCOPY requirements.txt .\nRUN python -m pip install --user --no-cache-dir -r requirements.txt\nCOPY . .\nRUN python main.py download-files\nEXPOSE 8081\nCMD [\"python\", \"main.py\", \"start\"]\n```\n\n\n# docker-compose.yml\n```\nservices:\n  lk-agent:\n    build: .\n    ports:\n      - \"8081:8081\"\n    env_file:\n      - .env\n    command: [\"python\", \"main.py\", \"start\"]\n```\n\n\n# requirements.txt\n```\nlivekit==1.0.8\nlivekit-agents==1.0.23\nlivekit-plugins-turn-detector==1.0.23\nsilero==1.0.23\n# …other dependencies as listed\n```\n\n\n# Expected Behavior\nThe turn detector should always return a valid probability/result when the user speaks, allowing uninterrupted conversation flow\n\n\n# Actual Behavior\nMultilingualModel().predict_end_of_turn returns None, causing an AssertionError and halting the voice bot’s processing\n\n\n# Additional Context\n- The error does not occur before the bot’s first speech.\n- It happens immediately when the user attempts to speak (“end_of_turn” logic never yields a non-None result).\n- Disabling turn detection allows the session to continue without crashing.\n",
      "state": "open",
      "author": "AlejoPrietoDavalos",
      "author_type": "User",
      "created_at": "2025-05-31T20:44:59Z",
      "updated_at": "2025-06-01T19:35:55Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2465/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2465",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2465",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:37.839048",
      "comments": [
        {
          "author": "davidzhao",
          "body": "can you try giving the instance more resources? does it go away with 3 cores & 4GB?\n\nI'm not able to reproduce this, but would like to figure out the root cause",
          "created_at": "2025-06-01T16:49:45Z"
        },
        {
          "author": "davidzhao",
          "body": "can you also share the full logs from the agent run? ",
          "created_at": "2025-06-01T16:50:01Z"
        },
        {
          "author": "AlejoPrietoDavalos",
          "body": "> can you try giving the instance more resources? does it go away with 3 cores & 4GB?\n> \n> I'm not able to reproduce this, but would like to figure out the root cause\n\nOkay, I think that's it!\nWhere do I see the computational costs for the package?\nAnd how do I close the issue? How do I complete it?",
          "created_at": "2025-06-01T19:34:46Z"
        }
      ]
    },
    {
      "issue_number": 2475,
      "title": "Is livekit.agents.ipc.proc_client._ProcClient expected to have breaking changes in the future?",
      "body": "Hi, I'm making a custom FrameExecutor(SupervisedProcess) / _FrameProc using _ProcClient process pair. One critique I received was livekit.agents.ipc.proc_client._ProcClient is part of the private api. The api seems stable & hasn't really changed over the past year. I know SupervisedProcess was introduced late last year.\n\nI'm wondering if I can rely on this api being stable going forward. Are there plans on breaking changes to the process pair api? There are some ultra-low latency things that can be done with this level of access.\n\nThank you!",
      "state": "closed",
      "author": "btakita",
      "author_type": "User",
      "created_at": "2025-06-01T16:18:11Z",
      "updated_at": "2025-06-01T17:18:40Z",
      "closed_at": "2025-06-01T17:18:38Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 12,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2475/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2475",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2475",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:38.134706",
      "comments": [
        {
          "author": "davidzhao",
          "body": "since they are private, we do not recommend building on them. they are subject to change at any time.\n\nwhat are you trying to do?",
          "created_at": "2025-06-01T16:20:40Z"
        },
        {
          "author": "btakita",
          "body": "I want to use eventfd & shm.",
          "created_at": "2025-06-01T16:22:23Z"
        },
        {
          "author": "btakita",
          "body": "Also, I have a cross-process events that I would like to use this for...similar to rtc.EventEmitter. The SupervisedProcess is nice, so I'd like to use that as well...instead of rolling my own.",
          "created_at": "2025-06-01T16:23:00Z"
        },
        {
          "author": "btakita",
          "body": "I do have a zmq based many-many BrokerNode which has heartbeats. I'm working on a 1-1 ChannelNode. I could start the process myself...but I figure why not leverage what is already in Livekit? If it's a bad idea, I'll just roll my own.",
          "created_at": "2025-06-01T16:27:38Z"
        },
        {
          "author": "davidzhao",
          "body": "why are you looking to use those things? is the end goal some sort of inference?",
          "created_at": "2025-06-01T16:28:03Z"
        }
      ]
    },
    {
      "issue_number": 2157,
      "title": "Issue: track_subscribed Event Not Triggering for Outbound SIP Calls",
      "body": "### Problem\nThe track_subscribed event handler is not being triggered when making outbound calls with the LiveKit agent. This prevents audio from the remote participant (the call recipient) from being captured and processed correctly.\n\n**Context**\nI'm using a LiveKit agent for outbound calling with the following setup:\n\nLiveKit Agents Python SDK with SIP integration\n\n- Creating outbound calls using [CreateSIPParticipantRequest]\n- Collecting audio from both agent and remote participant for processing and storage\n\nExpected Behavior\nWhen a remote participant joins the call (the person answering the phone), the [on_track_subscribed] event should fire, allowing us to collect their audio into our buffers via:\n\n```\n   @ctx.room.on(\"track_subscribed\")\n   def on_track_subscribed(track: rtc.Track, publication: rtc.RemoteTrackPublication, participant: \n   rtc.RemoteParticipant):\n    logger.info(f\"Track subscribed: {track.sid} from {participant.identity}\")\n    async def handle_track_async(track: rtc.Track):\n        stream = rtc.AudioStream(track)\n        async for evt in stream:\n            # Store the frame with timestamp\n            audio_buffers['user'].append({\n                'frame': evt.frame,\n                'timestamp': time.time() - start_time\n            })\n    \n    asyncio.create_task(handle_track_async(track))\n```\n\n**Actual Behavior**\nThe event never triggers for outbound calls. The log message \"Track subscribed: {track.sid} from {participant.identity}\" never appears, and no audio frames are collected from the remote participant (the [audio_buffers['user']] (array remains empty).\n\n_Impact_\nWithout this event triggering:\n\n- The agent can't hear the person on the other end of the call\n- No audio is recorded from the remote participant\nWe can't process the complete conversation for transcription or analysis\n\n**Questions**\n\n- Is there something different about track subscription for outbound SIP calls?\n- Are there any specific configurations needed for outbound calls to receive tracks?\n- Could there be an issue with the SIP trunk configuration affecting track subscription?\n- Is there a different event I should be listening for with outbound calls?\n- Environment\n\nPython LiveKit Agents version: 1.0\n\n- OS: macOS\n- Outbound calling via SIP trunk\n- Any help or insights would be greatly appreciated!\n",
      "state": "open",
      "author": "Ravipandey24",
      "author_type": "User",
      "created_at": "2025-04-29T15:07:42Z",
      "updated_at": "2025-06-01T16:53:47Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2157/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2157",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2157",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:38.377354",
      "comments": [
        {
          "author": "ngoanpv",
          "body": "Hi @Ravipandey24 , I'm having the same problem. Do you have any solution for that?",
          "created_at": "2025-05-27T10:09:23Z"
        },
        {
          "author": "davidzhao",
          "body": "where is this event handler defined? you would need to add this *before* actually connecting to the room. otherwise it could be missed (if subscriptions happen really quickly as you are connecting, it could fire *before* your event handler is in place)",
          "created_at": "2025-06-01T16:53:46Z"
        }
      ]
    },
    {
      "issue_number": 2471,
      "title": "OpenAI realtime responding with text-only when transferring to different agents.",
      "body": "I'm following the restaurant agent example in Livekit's examples, but I'm using the OpenAI realtime `gpt-4-o-mini` model.  Whenever the model runs a tool to transfer to another agent, I get this error\n\n```shell\n2025-06-01 08:27:07,172 - WARNING livekit.plugins.openai - received text-only response from realtime API \n2025-06-01 08:27:07,257 - WARNING livekit.plugins.openai - trying to recover from text-only response {\"retries\": 1}\n2025-06-01 08:27:08,012 - WARNING livekit.plugins.openai - trying to recover from text-only response {\"retries\": 2}\n2025-06-01 08:27:08,892 - WARNING livekit.plugins.openai - trying to recover from text-only response {\"retries\": 3}\n2025-06-01 08:27:09,649 - WARNING livekit.plugins.openai - trying to recover from text-only response {\"retries\": 4}\n2025-06-01 08:27:10,398 - WARNING livekit.plugins.openai - trying to recover from text-only response {\"retries\": 5}\n2025-06-01 08:27:11,242 - ERROR livekit.plugins.openai - failed to recover from text-only response {\"retried_times\": 5}\n2025-06-01 08:27:11,892 - ERROR livekit.agents - Error in _realtime_reply_task \nTraceback (most recent call last):\n  File \"/Users/amirranjbar/Documents/coding/learning/livekit-gemini-realtime/.venv/lib/python3.11/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/amirranjbar/Documents/coding/learning/livekit-gemini-realtime/.venv/lib/python3.11/site-packages/livekit/agents/voice/agent_activity.py\", line 1394, in _realtime_reply_task\n    generation_ev = await self._rt_session.generate_reply(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nlivekit.agents.llm.realtime.RealtimeError: generate_reply timed out.\n2025-06-01 08:27:11,899 - ERROR asyncio - Task exception was never retrieved\nfuture: <Task finished name='AgentActivity.realtime_reply' coro=<AgentActivity._realtime_reply_task() done, defined at /Users/amirranjbar/Documents/coding/learning/livekit-gemini-realtime/.venv/lib/python3.11/site-packages/livekit/agents/utils/log.py:13> exception=RealtimeError('generate_reply timed out.')> \nTraceback (most recent call last):\n  File \"/Users/amirranjbar/Documents/coding/learning/livekit-gemini-realtime/.venv/lib/python3.11/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n```\n\n### Configuration\n- Python version: 3.11.2\n- requirements:\n  - livekit: 1.0.8\n  - livekit-agents: 1.0.23\n  - livekit-plugins-openai: 1.0.23\n\n### Code\n```python\nfrom dotenv import load_dotenv\nfrom typing import Annotated, cast, Optional\nfrom dataclasses import dataclass, field\nimport yaml\nfrom pydantic import Field\nfrom livekit import agents\nimport logging\nfrom livekit.agents import (\n    AgentSession,\n    Agent,\n    RoomInputOptions,\n    function_tool,\n    RunContext,\n)\nfrom livekit.plugins import noise_cancellation, openai\n\nlogger = logging.getLogger(\"driving-school-example\")\nlogger.setLevel(logging.INFO)\n\nload_dotenv()\n\n\n@dataclass\nclass UserData:\n    customer_name: Optional[str] = None\n    customer_phone: Optional[str] = None\n\n    agents: dict[str, Agent] = field(default_factory=dict)\n    prev_agent: Optional[Agent] = None\n\n    def summarize(self) -> str:\n        data = {\n            \"customer_name\": self.customer_name or \"unknown\",\n            \"customer_phone\": self.customer_phone or \"unknown\",\n        }\n        return yaml.dump(data)\n\n\nRunContext_T = RunContext[UserData]\n\n\n@function_tool()\nasync def update_name(\n    name: Annotated[str, Field(description=\"The customer's name\")],\n    context: RunContext_T,\n) -> str:\n    \"\"\"Called when the user provides their name.\n    Confirm the spelling with the user before calling the function.\"\"\"\n    userdata = context.userdata\n    userdata.customer_name = name\n    return f\"The name is updated to {name}\"\n\n\n@function_tool()\nasync def update_phone(\n    phone: Annotated[str, Field(description=\"The customer's phone number\")],\n    context: RunContext_T,\n) -> str:\n    \"\"\"Called when the user provides their phone number.\n    Confirm the spelling with the user before calling the function.\"\"\"\n    userdata = context.userdata\n    userdata.customer_phone = phone\n    return f\"The phone number is updated to {phone}\"\n\n\n@function_tool()\nasync def to_receptionist(context: RunContext_T):\n    \"\"\"Called when user asks any unrelated questions or requests\n    any other services not in your job description.\"\"\"\n    curr_agent = cast(BaseAgent, context.session.current_agent)\n    return await curr_agent._transfer_to_agent(\"receptionist\", context)\n\n\nclass BaseAgent(Agent):\n    async def on_enter(self) -> None:\n        agent_name = self.__class__.__name__\n        logger.info(f\"entering task {agent_name}\")\n\n        userdata: UserData = self.session.userdata\n        chat_ctx = self.chat_ctx.copy()\n\n        # add the previous agent's chat history to the current agent\n        if isinstance(userdata.prev_agent, Agent):\n            truncated_chat_ctx = userdata.prev_agent.chat_ctx.copy(\n                exclude_instructions=True, exclude_function_call=False\n            ).truncate(max_items=6)\n            existing_ids = {item.id for item in chat_ctx.items}\n            items_copy = [\n                item for item in truncated_chat_ctx.items if item.id not in existing_ids\n            ]\n            chat_ctx.items.extend(items_copy)\n\n        # add an instructions including the user data as assistant message\n        chat_ctx.add_message(\n            role=\"system\",  # role=system works for OpenAI's LLM and Realtime API\n            content=f\"You are {agent_name} agent. Current user data is {userdata.summarize()}\",\n        )\n        await self.update_chat_ctx(chat_ctx)\n        self.session.generate_reply(tool_choice=\"none\")\n\n    async def _transfer_to_agent(\n        self, name: str, context: RunContext_T\n    ) -> tuple[Agent, str]:\n        userdata = context.userdata\n        current_agent = context.session.current_agent\n        next_agent = userdata.agents[name]\n        userdata.prev_agent = current_agent\n\n        return next_agent, f\"Transferring to {name}.\"\n\n\nclass Receptionist(BaseAgent):\n    def __init__(self) -> None:\n        super().__init__(\n            instructions=(\n                \"You are the receptionist of a driving school.\"\n                \"Your job is to greet the caller and direct them to the rsep agent using tools if they want to register for it.\"\n            ),\n        )\n\n    @function_tool()\n    async def to_rsep(self, context: RunContext_T) -> tuple[Agent, str]:\n        \"\"\"Called when user wants to register for the RSEP course. This function will transfer the user to the rsep agent.\"\"\"\n        return await self._transfer_to_agent(\"rsep\", context)\n\n\nclass RSEP(BaseAgent):\n    def __init__(self) -> None:\n        super().__init__(\n            instructions=\"You are a school representative of a driving school. Your job is to ask for the user's name and phone number and finalize the registration using tools.\",\n            tools=[update_name, update_phone, to_receptionist],\n        )\n\n    @function_tool()\n    async def finalize_registration(\n        self, context: RunContext_T\n    ) -> str | tuple[Agent, str]:\n        \"\"\"Called when the user confirms the registration.\"\"\"\n        userdata = context.userdata\n        if not userdata.customer_name or not userdata.customer_phone:\n            return \"Please provide your name and phone number first.\"\n\n        logger.info(\n            f\"RSEP registration finalized for {userdata.customer_name} with phone {userdata.customer_phone}\"\n        )\n\n        chat_ctx = self.chat_ctx.copy()\n        chat_ctx.add_message(\n            role=\"system\",\n            content=f\"RSEP registration finalized. Please inform the user that a school representative will contact them shortly.\",\n        )\n        await self.update_chat_ctx(chat_ctx)\n\n        return await self._transfer_to_agent(\"receptionist\", context)\n\n\nasync def entrypoint(ctx: agents.JobContext):\n    userdata = UserData()\n    userdata.agents = {\n        \"receptionist\": Receptionist(),\n        \"rsep\": RSEP(),\n    }\n\n    session = AgentSession(\n        llm=openai.realtime.RealtimeModel(\n            model=\"gpt-4o-mini-realtime-preview-2024-12-17\",\n            temperature=0.6,\n        ),\n        userdata=userdata,\n    )\n\n    await session.start(\n        room=ctx.room,\n        agent=userdata.agents[\"receptionist\"],\n        room_input_options=RoomInputOptions(\n            noise_cancellation=noise_cancellation.BVCTelephony(),\n        ),\n    )\n\n    await ctx.connect()\n\n\nif __name__ == \"__main__\":\n    agents.cli.run_app(agents.WorkerOptions(entrypoint_fnc=entrypoint))\n\n```\n\n",
      "state": "closed",
      "author": "Amir-R1384",
      "author_type": "User",
      "created_at": "2025-06-01T14:43:14Z",
      "updated_at": "2025-06-01T16:52:28Z",
      "closed_at": "2025-06-01T16:52:27Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2471/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2471",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2471",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:38.629076",
      "comments": [
        {
          "author": "longcw",
          "body": "This is an issue on the OAI realtime api side https://community.openai.com/t/trouble-loading-previous-messages-with-realtime-api/1050576\n\nWhen you load the text chat context to the API, it may response with only text. We tried to remove the text response, add an empty dummy user audio, then require ",
          "created_at": "2025-06-01T15:06:47Z"
        },
        {
          "author": "Amir-R1384",
          "body": "Thanks a lot! I had seen some commits in the restaurant example that had seemed to fix it, so I thought maybe I was doing it wrong, but I guess not.",
          "created_at": "2025-06-01T16:52:27Z"
        }
      ]
    },
    {
      "issue_number": 1697,
      "title": "How is streaming between LLM to TTS working",
      "body": "I mostly being using the AWS bedrock LLM, TTS and STT. I have noticed  in the terminal that only after you get all the chunks from LLM, TTS starts to work. When the answer are long the latency tend to be really high.  Is this the intended way?  Or are there any ways to optimise for latency. ",
      "state": "closed",
      "author": "kailashsp",
      "author_type": "User",
      "created_at": "2025-03-21T12:52:22Z",
      "updated_at": "2025-06-01T16:50:45Z",
      "closed_at": "2025-06-01T16:50:45Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1697/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1697",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1697",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:38.860503",
      "comments": [
        {
          "author": "ChenghaoMou",
          "body": "Are you using AWS Polly TTS (aws.TTS)? I don't think it supports streaming TTS, and the README file might need some update.",
          "created_at": "2025-03-24T16:56:40Z"
        },
        {
          "author": "kailashprem",
          "body": "yes im using AWS polly. Can you guide me to how implement streaming? or any other plugin that implements streaming",
          "created_at": "2025-03-24T17:00:22Z"
        },
        {
          "author": "ChenghaoMou",
          "body": "> yes im using AWS polly. Can you guide me to how implement streaming? or any other plugin that implements streaming\n\nYou can try other plugins mentioned in [readme](https://github.com/livekit/agents?tab=readme-ov-file#tts) with Streaming checked. Vendors like Cartesia, Deepgram do offer free credit",
          "created_at": "2025-03-24T17:59:01Z"
        },
        {
          "author": "davidzhao",
          "body": "as long as the LLM is generating in a streaming fashion, we would chunk the generation by sentences. Currently our sentence tokenizer might not be very accurate for certain languages. which language are you testing with?",
          "created_at": "2025-03-29T07:22:04Z"
        },
        {
          "author": "dvirginz",
          "body": "Any way of disabling streaming? wouldn't like to stream the responses to the tts at all @davidzhao ",
          "created_at": "2025-06-01T14:24:39Z"
        }
      ]
    },
    {
      "issue_number": 2209,
      "title": "Failed to make an inbound call",
      "body": "I have followed the configure trunk [guide](https://docs.livekit.io/sip/quickstarts/configuring-plivo-trunk/). I'm following the accepting calls [guide](https://docs.livekit.io/sip/accepting-calls/) too but haven't found a clue as to how to accept a call yet.\n\nWhen I make a call to the configured number, the call just rings and nothing happens.\n\nHere's my `dispatch-inbound.py` file:\n\n```\nasync def main():\n    lkapi = api.LiveKitAPI()\n    request = api.CreateSIPDispatchRuleRequest(\n        rule=api.SIPDispatchRule(\n            dispatch_rule_individual=api.SIPDispatchRuleIndividual(\n                room_prefix=\"call-\",\n            )\n        ),\n        room_config=api.RoomConfiguration(\n            agents=[\n                api.RoomAgentDispatch(\n                    agent_name=\"outbound-caller\",\n                    metadata=\"job dispatch metadata\",\n                )\n            ]\n        ),\n    )\n    dispatch = await lkapi.sip.create_sip_dispatch_rule(request)\n    print(\"created dispatch\", dispatch)\n    await lkapi.aclose()\n```\n\nAnd this is how I run my agent:\n\n```\n    cli.run_app(\n        WorkerOptions(\n            entrypoint_fnc=entrypoint,\n            # giving this agent a name will allow us to dispatch it via API\n            # automatic dispatch is disabled when `agent_name` is set\n            agent_name=\"outbound-caller\",\n            # prewarm by loading the VAD model, needed only for VoicePipelineAgent\n            prewarm_fnc=prewarm,\n        )\n    )\n```\n\nAs you can see there is only the `sip` participant present, not the `agent` or `egress`.\n\n<img width=\"1179\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/6971c188-09fd-42bb-aefa-7e1280d3ae9d\" />",
      "state": "closed",
      "author": "joshiayush",
      "author_type": "User",
      "created_at": "2025-05-06T06:20:35Z",
      "updated_at": "2025-06-01T07:26:25Z",
      "closed_at": "2025-05-09T06:02:10Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2209/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2209",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2209",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:39.100534",
      "comments": [
        {
          "author": "yepher",
          "body": "Verify you followed this step:\nhttps://docs.livekit.io/agents/start/telephony/#dispatch-rules\n\nMake sure it matches your agent name.",
          "created_at": "2025-05-07T14:08:37Z"
        },
        {
          "author": "davidzhao",
          "body": "I can confirm this isn't a bug with the framework. closing the issue.\n\nyou are welcome to join our community slack to ask for help with your specific configuration",
          "created_at": "2025-05-09T06:02:10Z"
        },
        {
          "author": "rashad-leapai",
          "body": "This is still an error I just face right now, followed the same configuration for dispatch rule and agent name.\n\nThe error on the server is:\n`2025-05-29T14:31:36.638Z        INFO    livekit agent/client.go:161     failed to send job request      {\"error\": \"no response from servers\", \"namespace\": \"\",",
          "created_at": "2025-05-29T14:48:03Z"
        },
        {
          "author": "rashad-leapai",
          "body": "@joshiayush please share if you resolved the issue.",
          "created_at": "2025-05-29T14:51:11Z"
        },
        {
          "author": "davidzhao",
          "body": "I see.. it's not a good idea to mix unnamed agents vs named agents. otherwise new rooms may end up with an unnamed default agent even if you are trying to dispatch a specific agent to it",
          "created_at": "2025-05-30T08:14:22Z"
        }
      ]
    },
    {
      "issue_number": 2463,
      "title": "Deepgram TTS Plugin Generates Clicking Noise",
      "body": "\nDeepgram has guidance on the clicking noise to set container=none in the url parameters.\nhttps://developers.deepgram.com/docs/handling-audio-issues-in-text-to-speech\n\nI tried setting the base_url parameter to \"https://api.deepgram.com/v1/speak?container=none&\" and got the following error\n   raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: Bad Request (status_code=400, request_id=69170df74eb9, body={'err_code': 'UNSUPPORTED_AUDIO_FORMAT', 'err_msg': 'Unsupported audio format: `container` is not applicable when `encoding=mp3`.', 'request_id': '2f4b7f81-f5bc-4b42-9e8f-11dabd803458'})\n\nWhen I set the base_url to \"https://api.deepgram.com/v1/speak?container=none&encoding=linear16&\" everything works as expected with no clicks.\n\nThis means that even though the default encoding for the plugin is 'linear16', something is going wrong in the url creation to where the request is actually returning mp3 encoded audio.",
      "state": "closed",
      "author": "chrismarciniak",
      "author_type": "User",
      "created_at": "2025-05-31T05:04:15Z",
      "updated_at": "2025-06-01T07:18:22Z",
      "closed_at": "2025-06-01T07:18:21Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2463/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2463",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2463",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:39.357224",
      "comments": [
        {
          "author": "davidzhao",
          "body": "this has been fixed in main. will be released shortly.",
          "created_at": "2025-06-01T07:18:21Z"
        }
      ]
    },
    {
      "issue_number": 2426,
      "title": "Incorrect Audio Token Count - Gemini Live API RealtimeModel",
      "body": "Hi, Im using the Gemini Live API as a RealtimeModel with LiveKit, and noticed the audio token count is not populated correctly when using the Audio modality.\n\nI used the following code to track the metric that contains the audio and text token counts:\n```\n@session.on(\"metrics_collected\")\n    def _on_metrics_collected(ev: MetricsCollectedEvent):\n        print(\"ev metrics:\", ev.metrics)\n        metrics.log_metrics(ev.metrics)\n```\nI notice that the input audio tokens count increases by 1 each time, starting at 0 which is clearly incorrect since the input is of me speaking for multiple seconds, and the output audio tokens is always 0.\n\nSince the audio tokens are incorrect in the `ev.metrics` object, its subsequently incorrect in the `metrics.log()` function call and the `usage_collector` object.\n\nSome ev.metrics values from a short conversation with the voice agent:\n```\ntype='realtime_model_metrics' label='livekit.plugins.google.beta.realtime.realtime_api.RealtimeModel' request_id='gemini-turn-58971acd2589' timestamp=1748428916.454256 duration=13.88671088218689 ttft=9.393692016601562e-05 cancelled=False input_tokens=3047 output_tokens=49 total_tokens=3096 tokens_per_second=3.528553335322514 input_token_details=InputTokenDetails(audio_tokens=0, text_tokens=3047, image_tokens=0, cached_tokens=0, cached_tokens_details=CachedTokenDetails(audio_tokens=0, text_tokens=0, image_tokens=0)) output_token_details=OutputTokenDetails(text_tokens=49, audio_tokens=0, image_tokens=0)\n```\nSummarizing just input and output audio tokens from the next few outputs in the same conversation:\n```\nrequest_id='gemini-turn-6b1d8f8e9b73' input_token_details=InputTokenDetails(audio_tokens=1, text_tokens=3182, image_tokens=0, cached_tokens=0, cached_tokens_details=CachedTokenDetails(audio_tokens=0, text_tokens=0, image_tokens=0)) output_token_details=OutputTokenDetails(text_tokens=33, audio_tokens=0, image_tokens=0)\n```\n```\nrequest_id='gemini-turn-86abeed1fd71' input_token_details=InputTokenDetails(audio_tokens=2, text_tokens=3302, image_tokens=0, cached_tokens=0, cached_tokens_details=CachedTokenDetails(audio_tokens=0, text_tokens=0, image_tokens=0)) output_token_details=OutputTokenDetails(text_tokens=36, audio_tokens=0, image_tokens=0)\n```\n```\nrequest_id='gemini-turn-38693a0f458c' input_token_details=InputTokenDetails(audio_tokens=3, text_tokens=3440, image_tokens=0, cached_tokens=0, cached_tokens_details=CachedTokenDetails(audio_tokens=0, text_tokens=0, image_tokens=0)) output_token_details=OutputTokenDetails(text_tokens=33, audio_tokens=0, image_tokens=0)\n```\n\nI tried the same thing using Gemini Live API directly and printed the token counts for each modality and audio and text tokens there are more reasonable numbers (audio tokens are around 100+ tokens per interaction which makes sense since each interaction is a few seconds long). \n**Note**: audio tokens are 32 tokens per second as per the [gemini docs](https://ai.google.dev/gemini-api/docs/tokens?lang=python#multimodal-tokens).\n\nI tried exploring the `_token_details_map` function inside `_handle_usage_metadata` function in the `RealtimeSession` class, and printing the token counts there, and I think the issue runs deeper than that since they're incorrect at that stage too.\n\nAny advice on this would be highly appreciated since I want to log the token counts accurately and want to calculate the cost of each conversation accordingly.\n\n---------------------\n**Additional info:**\nI run the code using `python app.py console` although the same issue occurs when i run it using `python app.py dev`\nHere is my session object creation:\n```\nsession = AgentSession(\n        llm=google.beta.realtime.RealtimeModel(\n            model=\"gemini-2.0-flash-exp\",\n            voice=\"Zephyr\",\n            temperature=0.8,\n            instructions=SYSTEM_INSTRUCTIONS,\n            modalities=[\"AUDIO\"],\n        ),\n    )\n```\n\n\n",
      "state": "closed",
      "author": "rohanmitra14",
      "author_type": "User",
      "created_at": "2025-05-28T11:01:34Z",
      "updated_at": "2025-06-01T06:58:40Z",
      "closed_at": "2025-06-01T06:58:39Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2426/reactions",
        "total_count": 3,
        "+1": 3,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2426",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2426",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:39.546890",
      "comments": [
        {
          "author": "benjaminreji",
          "body": "+1",
          "created_at": "2025-05-28T11:02:28Z"
        },
        {
          "author": "nidalaraf",
          "body": "+1",
          "created_at": "2025-05-28T11:07:02Z"
        },
        {
          "author": "davidzhao",
          "body": "confirmed this is actually the expected value. while the audio token from each interaction is low, `prompt_token_count` continues to increase.. for example, printing out the raw stats from a short conversation turn:\n\n```\n2025-05-31 23:55:54,369 - INFO livekit.plugins.google - usage_metadata: prompt_",
          "created_at": "2025-06-01T06:58:39Z"
        }
      ]
    },
    {
      "issue_number": 1594,
      "title": "Gemini Live API tools support",
      "body": "I noticed that the package only supports function declarations for using tools with the Gemini Live APi, is there a planned support for the other tools types described in gemini's API, such as code execution and google search?",
      "state": "closed",
      "author": "genrry",
      "author_type": "User",
      "created_at": "2025-03-04T08:51:13Z",
      "updated_at": "2025-06-01T06:47:10Z",
      "closed_at": "2025-06-01T06:47:10Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1594/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "jayeshp19"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1594",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1594",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:39.784945",
      "comments": [
        {
          "author": "davidzhao",
          "body": "yeah we do plan to improve this to open it up to other tools across LLM providers",
          "created_at": "2025-03-16T19:53:12Z"
        },
        {
          "author": "jayeshp19",
          "body": "Hey @genrry I'm curious what's your use case for code execution with voice agent. Thanks",
          "created_at": "2025-03-17T14:25:23Z"
        },
        {
          "author": "genrry",
          "body": "Still just playing around with the API, but these multimodal, real-time conversation workflows could allow you to iterate on an idea very quickly, suggesting changes and spotting bugs as they are generated, which could increase productivity. @jayeshp19 If you are looking for a hand in adding support",
          "created_at": "2025-03-18T19:13:26Z"
        },
        {
          "author": "jayeshp19",
          "body": "That makes sense. We're definitely open to contributions. If you're interested, feel free to start a draft PR and we can coordinate. Thanks!",
          "created_at": "2025-03-19T04:00:14Z"
        }
      ]
    },
    {
      "issue_number": 2300,
      "title": "Ground and elastic search for Gemini LLM and Gemini live",
      "body": "So i looked into googles Groundings: https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/overview\n[-> Grounding with Google Search](https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/grounding-with-google-search)\n[-> Grounding with Elasticsearch](https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/grounding-with-elasticsearch)\n[and even Grounding with Google Maps](https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/grounding-with-google-maps)\n\n\nAre any of the features above are support in gemini LLM  or gemini live?\nThis is a wanted feature ,\nPlease implement this and inform us about this or tell us how we should do it.\n\nThank you",
      "state": "closed",
      "author": "ElyasMoshirpanahi",
      "author_type": "User",
      "created_at": "2025-05-15T12:16:53Z",
      "updated_at": "2025-06-01T06:47:09Z",
      "closed_at": "2025-06-01T06:47:09Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2300/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2300",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2300",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:39.999619",
      "comments": [
        {
          "author": "shirosh",
          "body": "I'm also facing this issue. Please enable this feature, since GenAI SDK already supporting this. And Gemini Live API is now in Preview mode.",
          "created_at": "2025-05-20T10:09:55Z"
        },
        {
          "author": "smxthereisonlyone",
          "body": "Any update here by the LiveKit team?",
          "created_at": "2025-05-23T16:05:47Z"
        },
        {
          "author": "smxthereisonlyone",
          "body": "@davidzhao \n\nYou added Google Search and Maps support right? Are you also able to add https://cloud.google.com/python/docs/reference/vertexai/latest/vertexai.generative_models.grounding.VertexAISearch  and Dynamic Retrieval?",
          "created_at": "2025-05-27T08:03:31Z"
        }
      ]
    },
    {
      "issue_number": 2464,
      "title": "MCP transport detection fails for URLs with query parameters",
      "body": "## Bug Description\nThe `_should_use_streamable_http()` method in `MCPServerHTTP` incorrectly detects transport type when URLs contain query parameters, causing servers to fallback to deprecated SSE transport instead of streamable HTTP.\n\n## Steps to Reproduce\n1. Create MCP server with URL: `https://server.smithery.ai/@upstash/context7-mcp/mcp?api_key=xxx`\n2. Transport detection returns `sse` instead of `streamable_http`\n\n## Expected Behavior\nURLs ending with `/mcp` path should use `streamable_http` transport regardless of query parameters.\n\n## Current vs Expected\n- **Current:** `transport=sse` ❌\n- **Expected:** `transport=streamable_http` ✅\n\n## Fix\nReplace line in `_should_use_streamable_http()`:\n```python\n# Current (broken)\nurl_lower = url.lower().rstrip(\"/\")\n\n# Fixed\nfrom urllib.parse import urlparse\nparsed_url = urlparse(url)\npath_lower = parsed_url.path.lower().rstrip(\"/\")\n```\n\n## Impact\nAffects any MCP server using query parameters for authentication (Smithery, potentially others).\n\n## Related\nComment in merged PR #2394",
      "state": "closed",
      "author": "robertvy",
      "author_type": "User",
      "created_at": "2025-05-31T19:55:10Z",
      "updated_at": "2025-06-01T06:31:16Z",
      "closed_at": "2025-06-01T06:30:46Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2464/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2464",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2464",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:40.228346",
      "comments": [
        {
          "author": "Akshay-a",
          "body": "Thanks for pointing this out!! I made the changes earlier with goal of integrating it to Zapier MCP server and it did the job. \nMade the advised code changes to fix this bug.\nhttps://github.com/livekit/agents/pull/2468",
          "created_at": "2025-06-01T06:03:40Z"
        },
        {
          "author": "davidzhao",
          "body": "we'll get this released next week. thanks for the report and PR both of you!",
          "created_at": "2025-06-01T06:31:14Z"
        }
      ]
    },
    {
      "issue_number": 2250,
      "title": "How do you integrate with baseten models",
      "body": "I want to integrate models from https://www.baseten.co/library/ into livekit does it support for external API for TTS and STT models how do you customize the endpoints for baseten plugin as they are not openai compatible.\n",
      "state": "open",
      "author": "zohar-cozmox",
      "author_type": "User",
      "created_at": "2025-05-09T09:41:02Z",
      "updated_at": "2025-05-31T07:28:38Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2250/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2250",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2250",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:40.471306",
      "comments": [
        {
          "author": "davidzhao",
          "body": "we don't support baseten TTS and STT yet, but would love to integrate with them",
          "created_at": "2025-05-31T07:28:37Z"
        }
      ]
    },
    {
      "issue_number": 2391,
      "title": "Replace Gemini Realtime Model’s Built-in STT Node with External STT Provider",
      "body": "## Title\n\nReplace Gemini Realtime Model’s Built-in STT Node with External STT Provider\n\n## Description\n\nI would like to replace the default speech-to-text (STT) node in the Gemini Realtime model pipeline with an external STT provider (e.g., Deepgram). My goal is to always send the transcribed text (not raw audio) to the Gemini Realtime LLM for processing, while still receiving audio responses from the LLM as usual.\n\n---\n\n**Problem:**  \nCurrently, the Gemini Realtime model uses its built-in STT for audio input. I want to bypass this step and use my own STT solution, sending only text to the LLM node.\n\n**Question:**  \nIs there a supported way to swap out the built-in STT node for an external provider, so that only the transcribed text is sent to the LLM? If so, are there example configurations or best practices for achieving this?\n\n**Additional Context:**  \n- The rest of the pipeline should remain unchanged; only the STT part should be replaced.\n- The output should still be audio, as generated by the LLM.\n\nAny guidance or documentation on how to achieve this would be appreciated!",
      "state": "closed",
      "author": "Goktug",
      "author_type": "User",
      "created_at": "2025-05-25T06:23:54Z",
      "updated_at": "2025-05-31T07:11:07Z",
      "closed_at": "2025-05-31T07:07:28Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2391/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2391",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2391",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:40.725445",
      "comments": [
        {
          "author": "davidzhao",
          "body": "Hi @Goktug, we do support using external STT providers for the transcript, but currently we would still feed audio in directly to the realtime model, as opposed to the transcribed text by the STT.\n\nDo you mind sharing a bit about why you'd like to pursue that path?",
          "created_at": "2025-05-26T21:34:09Z"
        },
        {
          "author": "Goktug",
          "body": "> Hi @Goktug, we do support using external STT providers for the transcript, but currently we would still feed audio in directly to the realtime model, as opposed to the transcribed text by the STT.\n> \n> Do you mind sharing a bit about why you'd like to pursue that path?\n\nHi @davidzhao \n\nThanks for ",
          "created_at": "2025-05-27T05:02:14Z"
        },
        {
          "author": "davidzhao",
          "body": "yes, you can send text to the framework at anytime.\n\n- directly from clients: https://docs.livekit.io/agents/build/text/#text-input\n- programmatically from agent: https://docs.livekit.io/agents/build/audio/#generate_reply",
          "created_at": "2025-05-31T07:07:28Z"
        },
        {
          "author": "davidzhao",
          "body": "in terms of managing existing context, this is a bit of a longer discussion. folks have different strategies on managing chat context.. with livekit you could use `session.update_agent` to essentially reset the context. you can then leverage techniques to reduce/summarize previous context.",
          "created_at": "2025-05-31T07:11:05Z"
        }
      ]
    },
    {
      "issue_number": 2407,
      "title": "Make auto_tool_reply_generation configurable in Gemini Realtime Model",
      "body": "Currently, the Gemini Realtime Model automatically generates responses for tool calls with `auto_tool_reply_generation` hardcoded to `True`. This feature request proposes making this behavior configurable to provide more flexibility in handling tool responses.\n\n> **Note**: This feature is being implemented in PR [#2405](https://github.com/livekit/agents/pull/2405)\n\n## Problem\nThe current implementation doesn't allow developers to:\n- Implement custom logic for tool response handling\n- Add additional validation or processing of tool results\n- Implement custom error handling for tool calls\n- Aggregate results from multiple tool calls before generating a response\n\n## Proposed Solution\nAdd a configuration option to the `RealtimeModel` class that allows developers to control the automatic tool response generation behavior:\n\n```python\nmodel = RealtimeModel(\n    auto_tool_reply_generation=False,  # Disable automatic tool response generation\n    # ... other configuration options ...\n)\n```\n\n## Use Cases\n1. **Custom Tool Response Handling**\n   - When additional validation is needed before generating responses\n   - When tool results need to be processed or transformed\n   - When implementing custom error handling logic\n\n2. **Advanced Integration Scenarios**\n   - Integrating with systems that have their own tool response handling\n   - Implementing custom retry logic for failed tool calls\n   - Adding additional context or processing before generating responses\n",
      "state": "open",
      "author": "DeninSiby",
      "author_type": "User",
      "created_at": "2025-05-27T05:53:21Z",
      "updated_at": "2025-05-31T06:56:52Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2407/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2407",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2407",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:40.973904",
      "comments": [
        {
          "author": "davidzhao",
          "body": "that parameter is simply reflecting Gemini Live's benavior.. which is when you respond to function calls, it'll automatically generate a response.\n\nwe cannot turn that behavior off",
          "created_at": "2025-05-27T06:35:12Z"
        },
        {
          "author": "Denin-Siby",
          "body": "This helps as a workaround for this issue to: https://github.com/livekit/agents/issues/2174 @davidzhao\n\nI also did try returning None and generating a reply instead but the model behaviour is very random in that case. That is sometimes it generates a reply sometimes it hallucinates to make up an ans",
          "created_at": "2025-05-27T16:40:06Z"
        },
        {
          "author": "Denin-Siby",
          "body": "Here is an example of when I return the answer, but it is not recognized and when the model generates the tool response it hallucinates to give such random answers.\n\nThe second response is the model reply with the explicit generate reply function which works in almost all cases.\n\nThis may not be the",
          "created_at": "2025-05-27T16:40:23Z"
        },
        {
          "author": "Denin-Siby",
          "body": "Any thoughts on this @davidzhao ?",
          "created_at": "2025-05-29T03:30:45Z"
        },
        {
          "author": "tusheet-geoiq",
          "body": "Is there any fix to the tool_outputs problem? @davidzhao ",
          "created_at": "2025-05-30T14:10:54Z"
        }
      ]
    },
    {
      "issue_number": 2455,
      "title": "Troubleshooting Missing LiveKit Configuration Error in Worker Entrypoint",
      "body": "When starting the agent, I encounter the following error:\n\nERROR - [worker entrypoint] -> livekit_url, livekit_api_key, and livekit_api_secret must be set by arguments or environment variables\n\nHere’s the relevant code:\n\n```\nif __name__ == \"__main__\":\n    cli.run_app(\n        WorkerOptions(\n            entrypoint_fnc=entrypoint,\n            api_key=os.environ[\"LIVEKIT_API_KEY\"],\n            api_secret=os.environ[\"LIVEKIT_API_SECRET\"],\n            ws_url=os.environ[\"LIVEKIT_WS_URL\"],\n            worker_type=WorkerType.ROOM,\n        ),\n    )\n```",
      "state": "closed",
      "author": "ahenawy",
      "author_type": "User",
      "created_at": "2025-05-30T13:31:26Z",
      "updated_at": "2025-05-31T06:53:26Z",
      "closed_at": "2025-05-31T06:53:25Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2455/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2455",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2455",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:42.874236",
      "comments": [
        {
          "author": "davidzhao",
          "body": "this is coming from one of the avatar plugins, not the worker init code.\n\nyou should set these as env vars, see [README](https://github.com/livekit/agents?tab=readme-ov-file#developing-with-livekit-clients)",
          "created_at": "2025-05-31T06:53:25Z"
        }
      ]
    },
    {
      "issue_number": 2435,
      "title": "Feasibility of Integrating Google ADK Agents with LiveKit for Complex Multi-Agent Systems",
      "body": "Hi team,\n\nWe’ve built a multi-modal multi-agent system using Google’s Realtime Model (Gemini 2.0 Flash API) on LiveKit. Currently, we have 3 multimodal agents (handling text, vision, and audio), and as the system complexity grows, we’re exploring architectural changes to keep things scalable and maintainable.\n\n**Our current challenges:**\n\nWe are already optimizing tool-calling prompts as much as possible within Gemini, but the tool-calling performance still feels inconsistent.\n\nWe’re unsure if LiveKit’s current agent model is the best fit as we scale toward more complex real-time agents.\n\nWe’re considering if Google ADK agents might better support the type of complex real-time video, audio, and text-based agents we want to build.\n\n**Our key questions:**\n\nCan ADK agents be integrated into a LiveKit-powered system for handling audio/video streams and room events, or are they fundamentally separate architectures?\n\nWould switching to ADK improve Gemini’s tool-calling performance, given our already optimized prompts?\n\nAre there best-practice architectures or design patterns for combining LiveKit (for media streams) and ADK (for agent logic) in a robust, low-latency system?\n\n**We’re not locked into ADK—we’re open to other approaches. Our core goal is to build a scalable, reliable, and complex multi-agent system that can handle real-time audio, video, and text inputs.**\n\nLooking for guidance, insights, or references.\n",
      "state": "closed",
      "author": "tusheet-geoiq",
      "author_type": "User",
      "created_at": "2025-05-29T05:51:58Z",
      "updated_at": "2025-05-31T06:22:09Z",
      "closed_at": "2025-05-31T06:22:07Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2435/reactions",
        "total_count": 3,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 1,
        "rocket": 2,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2435",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2435",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:43.071678",
      "comments": [
        {
          "author": "Denin-Siby",
          "body": "@tusheet-geoiq Questions for you:\n- Do you use the models through Vertex AI? if yes how reliable did you find the tool calling capability?\n- Which live models do you use?",
          "created_at": "2025-05-29T09:49:18Z"
        },
        {
          "author": "tusheet-geoiq",
          "body": "We are currently using the Google AI studio. The tool calling is erratic. Also the model speaks out \"tools_output\" a lot!\nWe are currently using the gemini 2.0 flash live model",
          "created_at": "2025-05-30T03:27:45Z"
        },
        {
          "author": "davidzhao",
          "body": "It's definitely to integrate Google ADK as a single LLM, but you'll be missing a lot of features from our native multi-agent support.\n\nIt's ultimately your call, but I would say it's feasible, but likely would not perform as well as the native capabilities. take a look at some of the [more extensive",
          "created_at": "2025-05-31T06:22:08Z"
        }
      ]
    },
    {
      "issue_number": 2451,
      "title": "Wrong agent state when interrupting due to new lk.chat sendText",
      "body": "We realized if the agent in the STT-LLM-TTS pipeline is being interrupted the agent switches from `speaking` to `thinking` and then directly (automatically) from `thinking` to `listening` instead of switching directly from `speaking` to `thinking`. \nAnd then he switches directly from `listening` to `speaking`, which does not make any sense, since the agent would always **think** before he **speaks**, wouldn't he? \nThis is very confusing, especially since he is in a `listening` state even though he is currently `thinking`.\n\nWe are using the latest livekit-agents 1.0 package and livekit-client@2.11.4.",
      "state": "closed",
      "author": "brianzaubar",
      "author_type": "User",
      "created_at": "2025-05-30T07:20:16Z",
      "updated_at": "2025-05-31T06:18:24Z",
      "closed_at": "2025-05-30T12:03:59Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2451/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2451",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2451",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:43.281890",
      "comments": [
        {
          "author": "longcw",
          "body": "I see the problem, basically when LLM is called the state switches to `thinking`, when the speech done (or interrupted), the state switches to `listening`.\n\nWhen agent is interrupted by text, it will call the LLM and interrupt the current speech in parallel, so you see it switches to `thinking` then",
          "created_at": "2025-05-30T07:28:40Z"
        },
        {
          "author": "brianzaubar",
          "body": "@longcw Yes exactly. Appreciate it. Can you give me an estimation on when this will be published with the next version? We have an upcoming release of a product that needs this fix next week, so I need an estimation. ",
          "created_at": "2025-05-30T10:29:19Z"
        },
        {
          "author": "davidzhao",
          "body": "@brianzaubar feel free to use the main branch if this is blocking. we'll be making a release sometimes next week",
          "created_at": "2025-05-31T06:18:23Z"
        }
      ]
    },
    {
      "issue_number": 1252,
      "title": "Reset the realtime model connection",
      "body": "The realtime API session may expired in 15mins, we can add a method in `RealtimeSession` to reset the connection and sync the user/agent transcripts to the new connection.\r\n\r\nRelated discussion: https://community.openai.com/t/realtime-api-session-expired/975036/9\r\n",
      "state": "closed",
      "author": "longcw",
      "author_type": "User",
      "created_at": "2024-12-18T02:48:07Z",
      "updated_at": "2025-05-31T06:14:08Z",
      "closed_at": "2025-05-31T06:14:07Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1252/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1252",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1252",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:43.583370",
      "comments": [
        {
          "author": "robin-intbot",
          "body": "Is there any plan to add the issue/feature to roadmap?",
          "created_at": "2025-05-21T03:39:36Z"
        },
        {
          "author": "davidzhao",
          "body": "implemented in #2360",
          "created_at": "2025-05-31T06:14:07Z"
        }
      ]
    },
    {
      "issue_number": 2462,
      "title": "MCP error on Gemini multimodal",
      "body": "When  initiating a multimodal agent with a stadard MCP setup using Gemini on any of the gemini models \n\ngemini-2.0-flash-live-001\ngemini-2.5-flash-preview-native-audio-dialog\ngemini-2.5-flash-exp-native-audio-thinking-dialog\n\nwe get this error:\n\n```\nparameters.$schema\n  Extra inputs are not permitted\n\nlivekit/plugins/google/utils.py:31 in to_fnc_ctx\n    tools.append(FunctionDeclaration(**info.raw_schema))\n                      ↑–––––––––––––––––––––––––––\npydantic/main.py:253 in __init__\n    validated_self = self.__pydantic_validator__.validate_python(data, …)\npydantic_core._pydantic_core.ValidationError: 1 validation error for FunctionDeclaration\nparameters.$schema\n  Extra inputs are not permitted [type=extra_forbidden, input_value='http://json-schema.org/draft-07/schema#', input_type=str]\n\n```\n\n\nWhen LiveKit’s Google‐Realtime code calls to_fnc_ctx(tools), it loops over each tool’s raw_schema (which came from your local definitions).\n\nIt then tries to build a Pydantic FunctionDeclaration using exactly that raw schema.\n\nBecause your tool JSON schema includes a top‐level \"parameters\": { … \"$schema\": \"http://json-schema.org/draft-07/schema#\", … }, Pydantic sees \"$schema\" as an unexpected key. By default, Pydantic’s model fields are strict—extra keys are not allowed—so it fails with extra_forbidden.",
      "state": "open",
      "author": "mercuryyy",
      "author_type": "User",
      "created_at": "2025-05-31T01:21:20Z",
      "updated_at": "2025-05-31T01:37:08Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2462/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2462",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2462",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:43.854921",
      "comments": [
        {
          "author": "longcw",
          "body": "Could you share the `info.raw_schema` you have? We may need to convert the raw_schema to `FunctionDeclaration` in a more specific way.",
          "created_at": "2025-05-31T01:37:07Z"
        }
      ]
    },
    {
      "issue_number": 2429,
      "title": "mcp gracefully shut down",
      "body": "just plugin in an mcp service\n\nwhen user left, it shuts down with error (which is annoying in my sentry :) , is there guildlines to shut it down properly without error?\n```bash\n2025-05-28 21:56:09,340 - ERROR mcp.client.sse - Error in sse_reader: peer closed connection without sending complete message body (incomplete chunked read)\n2025-05-28 21:56:13,913 - INFO livekit.agents - STT metrics: audio_duration=0.00 \n2025-05-28 21:56:21,923 - INFO livekit.agents - STT metrics: audio_duration=0.00 \n2025-05-28 21:56:29,921 - INFO livekit.agents - STT metrics: audio_duration=0.00\n2025-05-28 21:56:32,240 - DEBUG livekit.agents - stream closed\n2025-05-28 21:56:52,764 - DEBUG livekit.agents - shutting down job task\n2025-05-28 21:56:52,767 - INFO livekit.agents - process exiting\n```",
      "state": "open",
      "author": "DeoLeung",
      "author_type": "User",
      "created_at": "2025-05-28T14:21:14Z",
      "updated_at": "2025-05-31T00:14:44Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2429/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2429",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2429",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:44.097013",
      "comments": [
        {
          "author": "DeoLeung",
          "body": "this error happens not only in shutdown, sometimes it happens during session(i think may be of network issue) , then the mcp won't be usable afterward\n```python\ndispatcher-agent-1  | 2025-05-31 00:11:34,699 - ERROR livekit.agents - exception occurred while executing tool                             ",
          "created_at": "2025-05-31T00:14:44Z"
        }
      ]
    },
    {
      "issue_number": 2457,
      "title": "LLM Call Not Triggering When Using Google STT with ElevenLabs TTS in STT-LLM-TTS Pipeline",
      "body": "I'm encountering an issue in the STT-LLM-TTS pipeline. When I select Google STT along with ElevenLabs TTS, the LLM call does not happen. This is strange because the issue seems to originate from the TTS side—as soon as I speak, the transcription doesn't appear if ElevenLabs TTS is selected.\n\nCould this be due to parameters being shared or conflicting between TTS and STT, causing a failure in the transcription or blocking the LLM invocation?\n\nPlease investigate and check if:\n\nThere's any shared state or configuration between the TTS and STT modules.\n\nThe ElevenLabs TTS integration might be blocking or altering the STT event flow.\n\nLogs can confirm whether the STT transcription is even being triggered or sent to the LLM.\n\nLet me know if you need additional logs or configuration details.",
      "state": "closed",
      "author": "pashanitw",
      "author_type": "User",
      "created_at": "2025-05-30T18:35:26Z",
      "updated_at": "2025-05-30T20:22:41Z",
      "closed_at": "2025-05-30T20:22:40Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2457/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2457",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2457",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:44.305207",
      "comments": [
        {
          "author": "pashanitw",
          "body": " I suspect the issue is on the Google STT side — it’s either not sending the audio stream or there's a significant delay before the stream starts coming through.\n",
          "created_at": "2025-05-30T20:22:40Z"
        }
      ]
    },
    {
      "issue_number": 2428,
      "title": "assistant message sometimes not added to context",
      "body": "using `livekit-agents==1.0.22`\n\nhave a voice pipeline agent, occationally the assistant message is not added to the context, any idea where to debug it?\n\nthe problem results in consecutive user messages and the agent repeats the 1st question again :(\n```bash\nagent - on_user_turn_completed [\nChatMessage(id='lk.agent_task.instructions', type='message', role='system', content=[' '], interrupted=False, hash=None, created_at=1748434313.054042), \nChatMessage(id='item_8b02bdb45ffe', type='message', role='user', content=['茶叶有什么种类呀？'], interrupted=False, hash=None, created_at=1748434321.0851252), \n-- expect assistant message here, the llm response did suceed and the tts was generated as well\nChatMessage(id='item_4f1b3ff2f040', type='message', role='user', content=['好，我想看看明天这里附近有什么活动。'], interrupted=False, hash=None, created_at=1748434342.928268),\n...\n```\n",
      "state": "open",
      "author": "DeoLeung",
      "author_type": "User",
      "created_at": "2025-05-28T12:58:44Z",
      "updated_at": "2025-05-30T11:06:13Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2428/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2428",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2428",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:44.538435",
      "comments": [
        {
          "author": "longcw",
          "body": "hey could you share the steps or an example to reproduce this issue?",
          "created_at": "2025-05-28T13:22:55Z"
        },
        {
          "author": "DeoLeung",
          "body": "my full agent code is too big, and it happens occationally, maybe u could point me to where the assistant message is added, so i could narrow it down and make a minimum reproducable snippet.\n\nmy agent is something like this. things i could think of is maybe i disabled the sync transcription\n```pytho",
          "created_at": "2025-05-28T13:38:01Z"
        },
        {
          "author": "davidzhao",
          "body": "what model is this using?",
          "created_at": "2025-05-30T08:23:11Z"
        },
        {
          "author": "DeoLeung",
          "body": "> what model is this using?\n\nopenai llm, gpt-4.1",
          "created_at": "2025-05-30T10:34:35Z"
        },
        {
          "author": "longcw",
          "body": "We fixed a bug about chat context insertion in 1.0.23 (maybe related to https://github.com/livekit/agents/pull/2321), could you try the latest version and see if that fixed?",
          "created_at": "2025-05-30T11:06:12Z"
        }
      ]
    },
    {
      "issue_number": 2449,
      "title": "Livekit Google Plugin Does Not Support Gemini TTS Models",
      "body": "The LiveKit Google plugin currently does not support the newly released Gemini TTS models from Google. Attempting to use Gemini models (e.g., gemini-2.5-flash-preview-tts, or gemini-2.5-pro-preview-tts) results in errors or fallback to unsupported behavior.\n\nhttps://ai.google.dev/gemini-api/docs/speech-generation",
      "state": "closed",
      "author": "PROTAG0N1ST",
      "author_type": "User",
      "created_at": "2025-05-30T03:34:28Z",
      "updated_at": "2025-05-30T08:20:24Z",
      "closed_at": "2025-05-30T08:20:24Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2449/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2449",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2449",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:44.892839",
      "comments": [
        {
          "author": "mercuryyy",
          "body": "I made a post about this here - https://github.com/livekit/agents/issues/2431",
          "created_at": "2025-05-30T03:52:45Z"
        }
      ]
    },
    {
      "issue_number": 1152,
      "title": "roomevent and audio lost in android",
      "body": "I create a android app which has similar function like speech-to-speech playgroud\r\nBut I find that there's some roomevent and audio lost when the client first connect to the room\r\nthe log I print at the server as below:\r\n2024-11-29 07:54:10,312 - INFO my-worker - agent_started_speaking msg:human {\"pid\": 175734, \"job_id\": \"AJ_y9mKaizNVJSz\"}\r\n2024-11-29 07:54:14,863 - INFO my-worker - agent_stopped_speaking msg:human {\"pid\": 175734, \"job_id\": \"AJ_y9mKaizNVJSz\"}\r\n2024-11-29 07:54:14,863 - INFO my-worker - agent_speech_committed {\"pid\": 175734, \"job_id\": \"AJ_y9mKaizNVJSz\"}\r\n\r\nBut the first event i receive is agent_stopped_speaking, the event agent_started_speaking lost\r\n\r\nI send the event as below:\r\n\r\n @assistant.on(\"agent_started_speaking\")\r\n    def agent_started_speaking():\r\n        # convert string lists to strings, drop images\r\n        remote_participant = next(iter(ctx.room.remote_participants.values()), None)\r\n        if not remote_participant:\r\n            return\r\n        logger.info(f\"agent_started_speaking msg:{remote_participant.identity}\")\r\n        asyncio.create_task(\r\n            send_event(payload=\"\",reliable=True,destination_identities=[remote_participant.identity],topic=\"agent_started_speaking\")\r\n        )\r\n           async def send_event(\r\n        payload: Union[bytes, str],\r\n        *,\r\n        reliable: bool = True,\r\n        destination_identities: List[str] = [],\r\n        topic: str = \"\",\r\n    ):\r\n        await ctx.room.local_participant.publish_data(payload=payload,reliable=reliable,destination_identities=destination_identities,topic=topic)\r\n\r\nand the audio at the head alse lost",
      "state": "closed",
      "author": "sexiong306",
      "author_type": "User",
      "created_at": "2024-11-29T08:11:54Z",
      "updated_at": "2025-05-30T07:35:12Z",
      "closed_at": "2025-05-30T07:35:12Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1152/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1152",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1152",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:45.124708",
      "comments": []
    },
    {
      "issue_number": 1151,
      "title": "AttributeError: 'RealtimeSession' object has no attribute '_init_sync_task'",
      "body": "This is the error I'm getting when user connects to Realtime agent.\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/alankashkash/PycharmProjects/AIRecruit/realtime_agent/.venv/lib/python3.12/site-packages/livekit/agents/multimodal/multimodal_agent.py\", line 149, in _init_and_start\r\n    await self._session._init_sync_task\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nAttributeError: 'RealtimeSession' object has no attribute '_init_sync_task' {\"pid\": 11867, \"job_id\": \"AJ_nnwfvKhtFUFa\"}\r\n2024-11-29 10:42:07,347 - ERROR livekit - failed to emit event response_content_added\r\nTraceback (most recent call last):\r\n  File \"/Users/alankashkash/PycharmProjects/AIRecruit/realtime_agent/.venv/lib/python3.12/site-packages/livekit/rtc/event_emitter.py\", line 57, in emit\r\n    callback(*callback_args)\r\n  File \"/Users/alankashkash/PycharmProjects/AIRecruit/realtime_agent/.venv/lib/python3.12/site-packages/livekit/agents/multimodal/multimodal_agent.py\", line 163, in _on_content_added\r\n    if message.content_type == \"text\":\r\n       ^^^^^^^^^^^^^^^^^^^^\r\nAttributeError: 'RealtimeContent' object has no attribute 'content_type'. Did you mean: 'content_index'?\r\n\r\nAdditional info:\r\nName: livekit-agents\r\nVersion: 0.11.3\r\nLocation: /Users/alankashkash/PycharmProjects/AIRecruit/realtime_agent/.venv/lib/python3.12/site-packages\r\nRequires: aiodns, aiohttp, click, livekit, livekit-api, livekit-protocol, protobuf, psutil, pyjwt, types-protobuf, typing-extensions, watchfiles\r\nRequired-by: livekit-plugins-openai\r\n\r\nName: livekit\r\nVersion: 0.18.1\r\nLocation: /Users/alankashkash/PycharmProjects/AIRecruit/realtime_agent/.venv/lib/python3.12/site-packages\r\nRequires: protobuf, types-protobuf\r\nRequired-by: livekit-agents\r\n\r\n\r\nPackage                Version\r\n---------------------- ---------------\r\naiodns                 3.2.0\r\naiohappyeyeballs       2.4.3\r\naiohttp                3.11.7\r\naiosignal              1.3.1\r\nannotated-types        0.7.0\r\nanyio                  4.6.2.post1\r\nattrs                  24.2.0\r\nav                     13.1.0\r\ncertifi                2024.8.30\r\ncffi                   1.17.1\r\nclick                  8.1.7\r\ndistro                 1.9.0\r\nfrozenlist             1.5.0\r\nh11                    0.14.0\r\nhttpcore               1.0.6\r\nhttpx                  0.27.2\r\nidna                   3.10\r\njiter                  0.7.0\r\nlivekit                0.18.1\r\nlivekit-agents         0.11.3\r\nlivekit-api            0.8.0\r\nlivekit-plugins-openai 0.10.4\r\nlivekit-protocol       0.7.0\r\nmultidict              6.1.0\r\nopenai                 1.54.3\r\npillow                 10.3.0\r\npropcache              0.2.0\r\nprotobuf               5.28.3\r\npsutil                 5.9.8\r\npycares                4.5.0\r\npycparser              2.22\r\npydantic               2.9.2\r\npydantic-core          2.23.4\r\npyjwt                  2.10.0\r\npython-dotenv          1.0.1\r\nsniffio                1.3.1\r\ntqdm                   4.67.0\r\ntypes-protobuf         5.28.3.20241030\r\ntyping-extensions      4.12.2\r\nwatchfiles             0.24.0\r\nyarl                   1.18.0\r\n",
      "state": "closed",
      "author": "alankashkash",
      "author_type": "User",
      "created_at": "2024-11-29T07:49:13Z",
      "updated_at": "2025-05-30T07:35:12Z",
      "closed_at": "2025-05-30T07:35:12Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1151/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1151",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1151",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:45.124844",
      "comments": [
        {
          "author": "alankashkash",
          "body": "Finally fixed by removing venv and making a new one. Leaving open for you guys to decide if you want to investigate it",
          "created_at": "2024-11-29T08:03:52Z"
        }
      ]
    },
    {
      "issue_number": 1146,
      "title": "The watchfiles SDK unexpectedly replaces the SIGTERM handler",
      "body": "While killing the process started by cli.run_app method using SIGTERM I can observe the following log line:\r\n\r\n```\r\n2024-11-28 11:09:30,796 - \u001b[33mWARNING\u001b[0m watchfiles.main - received signal 15, raising KeyboardInterrupt \r\n```\r\n\r\nI assume this is not expected as the invocation of https://github.com/samuelcolvin/watchfiles/blob/cb0bcd84ae4ebea084c1db1adcf7a778952b3842/watchfiles/run.py#L438C19-L438C33 overrides the signal handler set in https://github.com/livekit/agents/blob/57834ec97db4a23452e52f98b2b48fac37eed0aa/livekit-agents/livekit/agents/cli/cli.py#L258",
      "state": "closed",
      "author": "mykola-mokhnach-parloa",
      "author_type": "User",
      "created_at": "2024-11-28T11:46:00Z",
      "updated_at": "2025-05-30T07:35:12Z",
      "closed_at": "2025-05-30T07:35:12Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1146/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1146",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1146",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:45.355359",
      "comments": [
        {
          "author": "theomonnom",
          "body": "TIL that watchfiles replaces this handler, but in a production environment, the `dev` subcommand isn't recommended. The `start` command, on the other hand, doesn’t rely on watchfiles at all.",
          "created_at": "2024-11-29T11:41:41Z"
        }
      ]
    },
    {
      "issue_number": 2442,
      "title": "AgentSession does not call custom _get_response_from_chatbot; always uses LLM plugin for responses",
      "body": "The agent’s custom _get_response_from_chatbot method is never called, regardless of whether an llm plugin is provided to AgentSession; all responses are handled by the llm plugin instead of my custom backend logic.\n\n_get_response_from_chatbot: _get_response_from_chatbot is a method I defined in my custom LiveKit Agent class.\nIts purpose is to handle user queries by sending them to my own backend chatbot API (instead of using a built-in or third-party LLM).\nWhen a user speaks, I want the agent to call this method, which then makes an HTTP request to my backend and returns the response to the user.\n\n",
      "state": "closed",
      "author": "anshulpwappgo",
      "author_type": "User",
      "created_at": "2025-05-29T10:34:48Z",
      "updated_at": "2025-05-30T07:08:14Z",
      "closed_at": "2025-05-30T07:08:14Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2442/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2442",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2442",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:45.554787",
      "comments": [
        {
          "author": "longcw",
          "body": "You have to call the `_get_response_from_chatbot` by yourself in the `on_user_turn_completed` as mentioned in https://github.com/livekit/agents/issues/2436",
          "created_at": "2025-05-29T11:58:50Z"
        }
      ]
    },
    {
      "issue_number": 2432,
      "title": "Gemini Realtime: transcribed user message not added to transcript after tool call",
      "body": "When using the Gemini Realtime model with `input_audio_transcription` enabled, the user input immediately preceding a tool call is not being added to the transcript.\n\n### Cause\nThe `RealtimeSession._handle_tool_calls` method always marks the current generation as done, effectively erasing the current (non-final) user input transcription. Since this handler runs  _before_ the  Gemini model sends the `generation_complete` message, the transcribed `input_audio_transcription_completed` event is never emitted with `is_final` set to `True`, and the message is never added to the transcript. \n\n### Thoughts\nI tested removing the `_mark_current_generation_done()` call at the end of the `RealtimeSession._handle_tool_calls()` method, and this did fix the issue, without raising any other problems that I could see. Since Gemini sends the `generation_complete` message after the tool call is complete, isn't it redundant to mark the generation done in the tool call handler anyways?\n\nThanks for your time, and please let me know if there's an opportunity for a PR.\n",
      "state": "closed",
      "author": "fredvollmer",
      "author_type": "User",
      "created_at": "2025-05-28T23:22:01Z",
      "updated_at": "2025-05-29T12:05:52Z",
      "closed_at": "2025-05-29T12:05:52Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2432/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 1
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2432",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2432",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:45.797510",
      "comments": []
    },
    {
      "issue_number": 2436,
      "title": "LiveKit Agent: STT/TTS and on_transcript not triggered unless LLM plugin is provided to AgentSession",
      "body": "## Description\n\n**Summary:**  \nWhen using LiveKit's Python Agent SDK, if I do NOT provide an `llm` plugin to `AgentSession`, the agent does not process audio input. The `on_transcript` method is never called, and STT/TTS do not work.  \nIf I add any LLM plugin (even a dummy), everything works as expected. I want to fully control response logic (e.g., call my own backend), but without a dummy LLM plugin, the agent's basic pipeline does not function.\n\n---\n\n### Steps to Reproduce\n\n1. Create an Agent class with a custom `on_transcript` and (optionally) `_get_response_from_chatbot`.\n2. Initialize `AgentSession` with only STT, TTS, and VAD (do NOT include `llm=...`).\n   ```python\n   session = AgentSession(stt=stt_plugin, tts=tts_plugin, vad=vad_plugin)",
      "state": "closed",
      "author": "anshulpwappgo",
      "author_type": "User",
      "created_at": "2025-05-29T09:14:13Z",
      "updated_at": "2025-05-29T10:33:21Z",
      "closed_at": "2025-05-29T10:33:21Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2436/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2436",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2436",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:45.797533",
      "comments": [
        {
          "author": "anshulpwappgo",
          "body": "give me a answer ",
          "created_at": "2025-05-29T09:42:01Z"
        },
        {
          "author": "anshulpwappgo",
          "body": "ok , then give me the answer\nyou closed my issue and didnt give the solution",
          "created_at": "2025-05-29T09:51:33Z"
        },
        {
          "author": "longcw",
          "body": "When llm ist not set, you can still use `session.say` and `Agent.on_user_turn_completed` callback. Raise a `StopResponse` to skip the agent reply that relies on llm. Any calls `session.generate_reply` will hang the agent since you don't have the llm.\n\n```python\nfrom livekit.agents.llm import StopRes",
          "created_at": "2025-05-29T10:10:35Z"
        }
      ]
    },
    {
      "issue_number": 2440,
      "title": "AgentSession does not call custom _get_response_from_chatbot; always uses LLM plugin for responses",
      "body": "The agent’s custom _get_response_from_chatbot method is never called, regardless of whether an llm plugin is provided to AgentSession; all responses are handled by the llm plugin instead of my custom backend logic.\n\n_get_response_from_chatbot: _get_response_from_chatbot is a method I defined in my custom LiveKit Agent class.\nIts purpose is to handle user queries by sending them to my own backend chatbot API (instead of using a built-in or third-party LLM).\nWhen a user speaks, I want the agent to call this method, which then makes an HTTP request to my backend and returns the response to the user.",
      "state": "closed",
      "author": "anshulpwappgo",
      "author_type": "User",
      "created_at": "2025-05-29T09:45:24Z",
      "updated_at": "2025-05-29T09:50:39Z",
      "closed_at": "2025-05-29T09:47:08Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2440/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2440",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2440",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:46.059375",
      "comments": [
        {
          "author": "longcw",
          "body": "pls stop creating duplicated issues https://github.com/livekit/agents/issues/2436",
          "created_at": "2025-05-29T09:47:08Z"
        },
        {
          "author": "anshulpwappgo",
          "body": "ok , then give me the answer \nyou closed my issue and didnt give the solution",
          "created_at": "2025-05-29T09:50:38Z"
        }
      ]
    },
    {
      "issue_number": 2437,
      "title": "Custom Agent Method `_get_response_from_chatbot` Not Called When `llm` Plugin Is Omitted in AgentSession",
      "body": "## Description\n\n**Summary:**  \nWhen building a custom agent with the LiveKit Python Agent SDK, my class overrides the `_get_response_from_chatbot` method (and/or the `on_transcript` method).  \nIf I provide an `llm` plugin (e.g., Groq, custom, or even a dummy), everything works: STT/TTS are active, user queries are processed, and my agent responds (either via the LLM or my override).\n\nHowever, if I **omit the `llm` plugin** (i.e., create `AgentSession` with only `stt`, `tts`, and `vad`), the agent does not process audio, does not call my `_get_response_from_chatbot`, and does not call `on_transcript` at all. No errors are reported, but the agent is unresponsive to user input.\n\n---\n\n## Steps to Reproduce\n\n1. Define a custom `Agent` subclass with an overridden `_get_response_from_chatbot` method.\n2. Initialize `AgentSession` **without** the `llm` argument:\n   ```python\n   session = AgentSession(stt=stt_plugin, tts=tts_plugin, vad=vad_plugin)\n   ```\n3. Start the agent and join a room.\n4. Speak or send a text query to the agent.\n\n**Observed Behavior:**  \n- The agent does not respond to input.\n- The overridden `_get_response_from_chatbot` is never called.\n- `on_transcript` is also not called (no logs, no TTS, nothing).\n- No backend API is called and no exceptions are raised.\n\n**If I add any `llm` plugin:**  \n- The agent works as expected (even if the LLM always returns a static response).\n- STT and TTS work, and queries are processed.\n\n---\n\n## Expected Behavior\n\n- When `AgentSession` is initialized **without** an `llm` plugin, the agent should still process transcripts and pass them to the custom logic (e.g., `_get_response_from_chatbot`).\n- It should be possible to fully control agent responses using only custom backend calls, without having to provide a \"dummy\" LLM plugin.\n\n---\n\n## Additional Notes\n\n- All plugin API keys are valid (Deepgram, ElevenLabs, etc.).\n- This issue occurs regardless of the STT/TTS/VAD plugin used.\n- There are no errors in the logs; the agent simply does nothing in response to input.\n- The current workaround is to provide a dummy LLM that calls out to the backend, but this is awkward and undocumented.\n\n---\n\n## Environment\n\n- LiveKit Python Agent SDK Version: (e.g., 1.0.22)\n- Python Version: (e.g., 3.10)\n- OS: (e.g., Windows 11, Ubuntu 22.04)\n\n---\n\n## Request\n\n- Is this behavior intended?\n- Can the agent framework be improved so that custom agent logic (e.g., `_get_response_from_chatbot`) is called even if no LLM plugin is provided?\n- Is there a recommended pattern for using only custom backend logic for agent responses, without a dummy LLM plugin?\n\n---\n\nThank you!",
      "state": "closed",
      "author": "anshulpwappgo",
      "author_type": "User",
      "created_at": "2025-05-29T09:15:51Z",
      "updated_at": "2025-05-29T09:43:33Z",
      "closed_at": "2025-05-29T09:37:07Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2437/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2437",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2437",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:46.307594",
      "comments": [
        {
          "author": "longcw",
          "body": "duplicates https://github.com/livekit/agents/issues/2436",
          "created_at": "2025-05-29T09:37:07Z"
        },
        {
          "author": "anshulpwappgo",
          "body": "but i didnt get my answer \nhow do i do this",
          "created_at": "2025-05-29T09:43:33Z"
        }
      ]
    },
    {
      "issue_number": 2438,
      "title": "AgentSession does not call custom `_get_response_from_chatbot`; always uses LLM plugin for responses",
      "body": "The agent’s custom _get_response_from_chatbot method is never called, regardless of whether an llm plugin is provided to AgentSession; all responses are handled by the llm plugin instead of my custom backend logic.\n\n_get_response_from_chatbot: _get_response_from_chatbot is a method I defined in my custom LiveKit Agent class.\nIts purpose is to handle user queries by sending them to my own backend chatbot API (instead of using a built-in or third-party LLM).\nWhen a user speaks, I want the agent to call this method, which then makes an HTTP request to my backend and returns the response to the user.\n\n",
      "state": "closed",
      "author": "anshulpwappgo",
      "author_type": "User",
      "created_at": "2025-05-29T09:29:12Z",
      "updated_at": "2025-05-29T09:38:04Z",
      "closed_at": "2025-05-29T09:38:03Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2438/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2438",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2438",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:46.523391",
      "comments": [
        {
          "author": "longcw",
          "body": "duplicates https://github.com/livekit/agents/issues/2436",
          "created_at": "2025-05-29T09:38:03Z"
        }
      ]
    },
    {
      "issue_number": 1648,
      "title": "Word level TTS timing data for lip sync?",
      "body": "The title pretty much sums it up.  😆\n\nI'm looking to capture word-level timing information so that I may properly sync a 3D model's lips to the words as they're being spoken.  \n\nIs there a way to do this?  Perhaps over a webrtc data channel?  I know the info is available from ElevenLabs at least, but based on the code, it didn't look like it was exposed at all.\n\nThanks!\n\n ",
      "state": "open",
      "author": "tjf",
      "author_type": "User",
      "created_at": "2025-03-13T20:03:44Z",
      "updated_at": "2025-05-29T05:06:13Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1648/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1648",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1648",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:46.739439",
      "comments": [
        {
          "author": "cp-radhika-s",
          "body": "@tjf Just wondering if you ever found a solution for this? I'm also trying to sync lips with the words being spoken, and need word-level timing. Let me know if you figured something out!",
          "created_at": "2025-05-29T05:06:12Z"
        }
      ]
    },
    {
      "issue_number": 2434,
      "title": "how to force use of tts stream or non-stream",
      "body": "hi,\n\nI implemented a tts module with both stream and non-stream ability.\n\nin voice agent pipeline, it generally uses the streaming part, which is fine. but sometime's i use the `self.session.say` to generate some fixed voice. how can i force `say` to use the non-streaming part?\n\nmy purpose is that non-streaming will be more easy for us to implement a cache on it :)",
      "state": "closed",
      "author": "DeoLeung",
      "author_type": "User",
      "created_at": "2025-05-29T01:59:02Z",
      "updated_at": "2025-05-29T02:15:25Z",
      "closed_at": "2025-05-29T02:15:24Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2434/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2434",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2434",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:47.032744",
      "comments": [
        {
          "author": "DeoLeung",
          "body": "or maybe how to tell my tts module's stream that the incoming text is from `say`, so we know that the text is complete and we could dynamic route it to caching module",
          "created_at": "2025-05-29T02:01:47Z"
        },
        {
          "author": "longcw",
          "body": "it cannot switch stream/non-stream on the fly, but you can send the audios to `say` with `session.say(\"...\", audio=[AudioFrame, ...])`.",
          "created_at": "2025-05-29T02:08:32Z"
        },
        {
          "author": "DeoLeung",
          "body": "> it cannot switch stream/non-stream on the fly, but you can send the audios to `say` with `session.say(\"...\", audio=[AudioFrame, ...])`.\n\nyep i saw the doc, in that case, i could wrap a audio generation before say and check the cache outside of it :) only downside is i need to structure out the non",
          "created_at": "2025-05-29T02:15:24Z"
        }
      ]
    },
    {
      "issue_number": 646,
      "title": "The testing on agents-playground.livekit.io is not functioning properly",
      "body": "When using LiveKit Cloud on agents-playground.livekit.io, it keeps loading indefinitely, making it unusable and impossible to test.\r\n\r\n![20240813162552](https://github.com/user-attachments/assets/5b56ca5f-8c0e-4909-b6cf-0cde2bb1e669)\r\n",
      "state": "closed",
      "author": "makeryangcom",
      "author_type": "User",
      "created_at": "2024-08-13T08:27:24Z",
      "updated_at": "2025-05-28T19:08:49Z",
      "closed_at": "2025-02-19T05:40:03Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/646/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/646",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/646",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:47.257512",
      "comments": [
        {
          "author": "davidzhao",
          "body": "did you connect an agent?",
          "created_at": "2024-08-19T05:24:36Z"
        },
        {
          "author": "robert-sarosi",
          "body": "same here for the agent. having the actual livekit cloud url, key and secret, but is still unable to connect.\r\n\r\n<img width=\"1207\" alt=\"Screenshot 2024-08-23 at 00 07 13\" src=\"https://github.com/user-attachments/assets/a70a3f99-25c4-4e9a-b261-866a582677dd\">\r\n",
          "created_at": "2024-08-22T17:07:54Z"
        },
        {
          "author": "keepingitneil",
          "body": "This looks like an issue on your agent. It's likely that it doesn't have the `LIVKIT_URL` `LIVEKIT_API_KEY` and `LIVEKIT_API_SECRET` environment variables set properly",
          "created_at": "2024-08-23T16:45:09Z"
        },
        {
          "author": "makeryangcom",
          "body": "Do you also need to set up your own agent when using cloud services? If so, where do I need to configure it?\r\n\r\nThe agent is continuously loading, and both the microphone and camera permissions have been granted.\r\n\r\n![image](https://github.com/user-attachments/assets/eec04e62-8388-4d57-9623-476c260b",
          "created_at": "2024-08-25T15:35:31Z"
        },
        {
          "author": "ryanleecode",
          "body": "it works like 1/100 of the time. super frustrating",
          "created_at": "2024-09-06T23:59:22Z"
        }
      ]
    },
    {
      "issue_number": 1163,
      "title": "Expose worker information via Prometheus",
      "body": "Currently, there is no way to monitor spawned workers or jobs dispatched by a worker. These metrics should be exported to Prometheus via the metrics interface",
      "state": "open",
      "author": "s-hamdananwar",
      "author_type": "User",
      "created_at": "2024-12-02T22:32:59Z",
      "updated_at": "2025-05-28T12:08:18Z",
      "closed_at": null,
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1163/reactions",
        "total_count": 2,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 2,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1163",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1163",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:47.521826",
      "comments": [
        {
          "author": "g4ze",
          "body": "hey! this something that I would also like to have in my projects... is this in your pipeline for implementation  or is it an open issue for someone like me to raise for?",
          "created_at": "2025-05-28T12:08:17Z"
        }
      ]
    },
    {
      "issue_number": 2425,
      "title": "How to debug autoegress?",
      "body": "I create rooms as follows:\n\n```json\n{\n  \"name\": \"01971662-ee54-7000-9a58-47dc174d66c0\",\n  \"emptyTimeout\": 600,\n  \"maxParticipants\": 2,\n  \"egress\": {\n    \"room\": {\n      \"roomName\": \"01971662-ee54-7000-9a58-47dc174d66c0\",\n      \"layout\": \"grid\",\n      \"audioOnly\": false,\n      \"videoOnly\": false,\n      \"customBaseUrl\": \"\",\n      \"fileOutputs\": [\n        {\n          \"fileType\": \"MP4\",\n          \"filepath\": \"livekit-recordings/01971662-ee54-7000-9a58-47dc174d66c0/01971662-ee54-7000-9a58-47dc174d66c0.mp4\",\n          \"s3\": {\n            \"accessKey\": \"cucumber\",\n            \"secret\": \"cucumber\",\n            \"region\": \"\",\n            \"endpoint\": \"redacted\",\n            \"bucket\": \"cucumber\",\n            \"forcePathStyle\": false,\n            \"metadata\": {},\n            \"tagging\": \"\",\n            \"contentDisposition\": \"\",\n            \"sessionToken\": \"\"\n          },\n          \"disableManifest\": false\n        }\n      ],\n      \"streamOutputs\": [],\n      \"segmentOutputs\": [],\n      \"imageOutputs\": [],\n      \"audioMixing\": \"DEFAULT_MIXING\",\n      \"webhooks\": []\n    }\n  }\n}\n```\n\nAnd the API returns:\n\n```json\n{\n  \"sid\": \"RM_DRNjRFfYsQaq\",\n  \"name\": \"01971662-ee54-7000-9a58-47dc174d66c0\",\n  \"emptyTimeout\": 600,\n  \"maxParticipants\": 2,\n  \"creationTime\": \"1748428161\",\n  \"turnPassword\": \"\",\n  \"enabledCodecs\": [\n    {\n      \"mime\": \"video/H264\",\n      \"fmtpLine\": \"\"\n    },\n    {\n      \"mime\": \"video/VP8\",\n      \"fmtpLine\": \"\"\n    },\n    {\n      \"mime\": \"video/VP9\",\n      \"fmtpLine\": \"\"\n    },\n    {\n      \"mime\": \"video/AV1\",\n      \"fmtpLine\": \"\"\n    },\n    {\n      \"mime\": \"audio/red\",\n      \"fmtpLine\": \"\"\n    },\n    {\n      \"mime\": \"audio/opus\",\n      \"fmtpLine\": \"\"\n    }\n  ],\n  \"metadata\": \"\",\n  \"numParticipants\": 0,\n  \"activeRecording\": false,\n  \"numPublishers\": 0,\n  \"version\": {\n    \"unixMicro\": \"1748428161035002\",\n    \"ticks\": 0\n  },\n  \"departureTimeout\": 20,\n  \"creationTimeMs\": \"1748428161030\"\n}\n```\n\nThe fact I enabled autoegress doesn't seem to do anything, and `activeRecording` in the response is set to `false`.\n\nWhat could be my next steps to figure out why it is not working? I use the node server SDK.",
      "state": "closed",
      "author": "koakuma-chan",
      "author_type": "User",
      "created_at": "2025-05-28T10:40:37Z",
      "updated_at": "2025-05-28T11:18:06Z",
      "closed_at": "2025-05-28T11:18:05Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2425/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2425",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2425",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:47.756171",
      "comments": [
        {
          "author": "koakuma-chan",
          "body": "Error messages can be found in the cloud console under `Egresses`, although there seems to be a significant delay before they appear. In my particular case I had to set `force_path_style` to `true`.",
          "created_at": "2025-05-28T11:18:05Z"
        }
      ]
    },
    {
      "issue_number": 1143,
      "title": "Getting a \"WARNING livekit.agents - The realtime API returned a text content part, which is not supported\" warning during conversations",
      "body": "Hello - I'm not sure if this is a bug or something I'm doing wrong.\r\n\r\nUsing `RealtimeModel`\\`MultimodalAgent` I am attempting to start a conversation and seed it with some conversation history so the user can pick up where they left off when the conversation.\r\n\r\nI am setting the modality to \"audio\" to try and ensure text responses aren't being used, but I sometimes get this warning/error, and no audio output is produced. It seems to happen somewhat randomly: the more convo history there is, the more likely it seems to happen.\r\n\r\nSome code for how I've set things up:\r\n```\r\nmodel = openai.realtime.RealtimeModel(\r\n            instructions=data['globalPrompt'],\r\n            voice='shimmer',\r\n            temperature=0.8,\r\n            # max_response_output_tokens=float('inf'),\r\n            modalities=['audio'],\r\n            turn_detection=openai.realtime.ServerVadOptions(\r\n                threshold=0.9, prefix_padding_ms=200, silence_duration_ms=500\r\n            ),\r\n        )\r\n\r\nagent = MultimodalAgent(model=model)\r\n\r\nagent.start(ctx.room)\r\n\r\nlogger.info(\"starting agent\")\r\n        \r\nsession = model.sessions[0]\r\n# Add messages to conversation history if needed\r\nfor message in data.get('messages', []):\r\n    logger.info(f\"role: {message['role']}, content: {message['content']}\")\r\n    session.conversation.item.create(\r\n        llm.ChatMessage(role='assistant' if message['role'] == 'system' else 'user', content=message['content'])\r\n    )\r\n        \r\nsession.response.create()\r\n```\r\n\r\n`messages` is an array of messages returned from my API that just contains `content` (a string) and `role` (a string). It seems that setting role to \"assistant\" instead of \"system\" seems to reduce the frequency of this issue, but it could be a placebo effect.\r\n\r\nThis code is based on the example code from the integration guide: https://docs.livekit.io/agents/openai/multimodalagent/\r\n\r\nWhich is interesting that this example code sets audio *and* text modalities, when text doesn't really seem to work at all.",
      "state": "closed",
      "author": "zacharyw",
      "author_type": "User",
      "created_at": "2024-11-27T14:27:27Z",
      "updated_at": "2025-05-28T07:35:13Z",
      "closed_at": "2025-05-28T07:35:13Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1143/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1143",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1143",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:48.031602",
      "comments": [
        {
          "author": "longcw",
          "body": "First most likely the Realtime model doesn't support `system` role. And this is more like a bug in the model side that there is a chance to response in text mode if there are some text chat ctx initialized (even `assistant` role has a higher chance to trigger the text mode than `user`).\r\n\r\nHere is a",
          "created_at": "2024-11-27T14:39:50Z"
        },
        {
          "author": "zacharyw",
          "body": "Oh thank you - looks like I need to get onto the cutting edge of changes then. Out of curiosity could you explain why setting the modalities to `audio` and `text` is required despite `text` being an undesirable state to get into?",
          "created_at": "2024-11-27T15:03:21Z"
        },
        {
          "author": "longcw",
          "body": "There is no way to set the API audio-only, from the document https://platform.openai.com/docs/api-reference/realtime-client-events/session/update, we can only set the mode to [\"text\"] to disable audio, but not the other way around.",
          "created_at": "2024-11-27T15:07:57Z"
        }
      ]
    },
    {
      "issue_number": 1142,
      "title": "user_speech_committed event is never fired using RealtimeModel/MultimodalAgent",
      "body": "Hello - I'm not sure if this is a bug, or just something I'm doing wrong.\r\n\r\nI am creating a model:\r\n\r\n```\r\nmodel = openai.realtime.RealtimeModel(\r\n            instructions=data['globalPrompt'],\r\n            voice='shimmer',\r\n            temperature=0.8,\r\n            # max_response_output_tokens=float('inf'),\r\n            modalities=['audio'],\r\n            turn_detection=openai.realtime.ServerVadOptions(\r\n                threshold=0.9, prefix_padding_ms=200, silence_duration_ms=500\r\n            ),\r\n        )\r\n\r\nagent = MultimodalAgent(model=model)\r\n```\r\n\r\nI have event handlers defined for when speech is committed:\r\n\r\n```\r\n@agent.on(\"user_speech_committed\")\r\ndef on_user_speech_committed(msg: llm.ChatMessage):\r\n    logger.info(f\"User speech committed: {msg}\")\r\n        \r\n@agent.on(\"agent_speech_committed\")\r\ndef on_agent_speech_committed(msg: llm.ChatMessage):\r\n    logger.info(f\"Agent speech committed: {msg}\")\r\n```\r\n\r\nDuring a conversation, the `agent_speech_committed` event is fired normally and the `msg` param contains the AI's response.\r\n\r\nHowever, the `user_speech_committed` event is never picked up.\r\n\r\nIn addition, in the debug logs, I can see a user conversation item being created with audio, but the transcription is blank:\r\n\r\n```\r\nDEBUG livekit.plugins.openai.realtime - conversation item created {\"type\": \"conversation.item.created\", \"event_id\": \"event_AYCyhuvHvIlGLSpkTu6MH\", \"previous_item_id\": \"item_AYCyaCV55zc87azG5Z4cz\", \"item\": {\"id\": \"item_AYCyhNzFR1Nobo2kKvcCW\", \"object\": \"realtime.item\", \"type\": \"message\", \"status\": \"completed\", \"role\": \"user\", \"content\": [{\"type\": \"input_audio\", \"transcript\": null}]}, \"pid\": 1181, \"job_id\": \"AJ_XvWaLLkWk3Hv\"}\r\n```\r\n\r\nI'm not sure if that could be related to the event not firing or not.\r\n\r\n",
      "state": "closed",
      "author": "zacharyw",
      "author_type": "User",
      "created_at": "2024-11-27T14:19:41Z",
      "updated_at": "2025-05-28T07:35:13Z",
      "closed_at": "2025-05-28T07:35:13Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1142/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1142",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1142",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:48.275027",
      "comments": [
        {
          "author": "longcw",
          "body": "The transcription is expected to be empty when the conversation item is created. The transcription should be included in a message sent later by the realtime API, and the `user_speech_committed` event will be emitted when the agent receives the transcription.\r\n\r\nThere should be a debug log for `comm",
          "created_at": "2024-11-27T14:32:41Z"
        },
        {
          "author": "zacharyw",
          "body": "Hmm, I restarted my docker container, without having changed anything, and now the event is being picked up it looks like, and I'm seeing events trigger on both sides now, sorry for the errant issue.\r\n\r\nI will say though that the transcription is radically different from actual audio that the AI pic",
          "created_at": "2024-11-27T15:08:44Z"
        }
      ]
    },
    {
      "issue_number": 2418,
      "title": "background player somethings crash when interrupted",
      "body": "using `livekit-agent==1.0.22`, it runs into error and then everything hangs, any idea how to make it more crash safe?\n```bash\n2025-05-28 12:37:07,793 - ERROR asyncio - Task exception was never retrieved\nfuture: <Task finished name='Task-531' coro=<BackgroundAudioPlayer._play_task() done, defined at /lib/python3.12/site-packages/livekit/agents/utils/log.py:13> exception=RuntimeError('aclose(): asynchronous generator is already running')>\nTraceback (most recent call last):\n  File \"/lib/python3.12/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/lib/python3.12/site-packages/livekit/agents/voice/background_audio.py\", line 355, in _play_task\n    await gen.aclose()\nRuntimeError: aclose(): asynchronous generator is already running\n```",
      "state": "closed",
      "author": "DeoLeung",
      "author_type": "User",
      "created_at": "2025-05-28T04:43:00Z",
      "updated_at": "2025-05-28T04:44:21Z",
      "closed_at": "2025-05-28T04:44:20Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2418/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2418",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2418",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:48.480281",
      "comments": [
        {
          "author": "DeoLeung",
          "body": "dup #2333 ",
          "created_at": "2025-05-28T04:44:20Z"
        }
      ]
    },
    {
      "issue_number": 2065,
      "title": "use vad stream in stt stream sometimes got exception not set at the beginning",
      "body": "https://github.com/livekit/agents/blob/main/livekit-agents/livekit/agents/vad.py#L164\n\n```bash\nError in send_task\nTraceback (most recent call last):\n  File \"ib/python3.12/site-packages/livekit/agents/vad.py\", line 162, in __anext__\n    val = await self._event_aiter.__anext__()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nStopAsyncIteration\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"lib/python3.12/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/sttv3.py\", line 289, in send_task\n    async for event in self._vad_stream:\n  File \"ib/python3.12/site-packages/livekit/agents/vad.py\", line 164, in __anext__\n    if not self._task.cancelled() and (exc := self._task.exception()):\n                                              ^^^^^^^^^^^^^^^^^^^^^^\nasyncio.exceptions.InvalidStateError: Exception is not set.\n```\n\ni'm manually iterating the vad stream in my stt module, but occationally at the start will get this error, any idea of how to avoid this?",
      "state": "closed",
      "author": "DeoLeung",
      "author_type": "User",
      "created_at": "2025-04-22T03:53:10Z",
      "updated_at": "2025-05-28T04:40:11Z",
      "closed_at": "2025-05-28T04:40:10Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2065/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2065",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2065",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:48.687487",
      "comments": [
        {
          "author": "longcw",
          "body": "What stt are you using, and can you share a code snippet to reproduce the issue?",
          "created_at": "2025-04-22T03:55:19Z"
        },
        {
          "author": "DeoLeung",
          "body": "is my implementation of volcengine, it's a bit messy\n```python\nimport asyncio\nimport dataclasses\nimport functools\nimport io\nimport wave\nimport weakref\nfrom dataclasses import dataclass\nfrom typing import List\nfrom uuid import uuid4\n\nimport aiohttp\nfrom livekit.agents import (\n  DEFAULT_API_CONNECT_O",
          "created_at": "2025-04-22T06:01:40Z"
        },
        {
          "author": "longcw",
          "body": "It seems like that the `_event_ch` of VAD stream was closed somewhere while the VAD stream main task didn't done. This shouldn't happen from the VAD design. The `_event_ch.close` should be only called when the task is done or the stream closed (also after the task done).\n",
          "created_at": "2025-04-22T07:46:25Z"
        },
        {
          "author": "DeoLeung",
          "body": "i c, i'm cleaning it up and preparing a pr for the volcengine stt/tts, let me c if this happened again\n\nalso if the agent itself provide vad over stt stream will be great, so we don't need to implement it gain(i just copy it from the non streaming adaptor and modify a bit)",
          "created_at": "2025-04-22T08:10:50Z"
        },
        {
          "author": "DeoLeung",
          "body": "> It seems like that the `_event_ch` of VAD stream was closed somewhere while the VAD stream main task didn't done. This shouldn't happen from the VAD design. The `_event_ch.close` should be only called when the task is done or the stream closed (also after the task done).\n\ni found a better way to r",
          "created_at": "2025-05-21T03:05:41Z"
        }
      ]
    },
    {
      "issue_number": 2404,
      "title": "Manual Turn: Transcript appears but no audio playback when rapidly toggling Start/Cancel Turn",
      "body": "Hello there!\n\nFirst off, thanks so much for the Manual Turn feature—it’s been working great for us in production! We’ve run into an intermittent bug where **the transcript always comes back correctly, but no audio plays** (it seems to happen somewhere in the STT process). It usually reproduces if we **rapidly toggle Start Turn and Cancel Turn.**\n\nBecause our business logic is pretty heavy, we wanted to reproduce it in a “pure” environment before filing an issue. So we checked out your voice-assistant-frontend repo’s push-to-talk branch and set everything up. While the audio level graph animates as expected, clicking the `Press to Talk` button does absolutely nothing—no audio is captured or played back.\n\t1.\tHow would you recommend testing this in isolation?\n\t2.\tHave you ever seen a case where the transcript appears but no audio is recorded or played back?\n\nFor reference:\n\t•\t[Agent: using examples/push_to_talk.py](https://github.com/livekit/agents/blob/main/examples/voice_agents/push_to_talk.py)\n\t•\t[Frontend: this repo’s push-to-talk branch](https://github.com/longcw/voice-assistant-frontend/tree/longc/push-to-talk-example)\n\nThanks in advance for any guidance!",
      "state": "closed",
      "author": "well-balanced",
      "author_type": "User",
      "created_at": "2025-05-27T05:00:24Z",
      "updated_at": "2025-05-28T02:37:20Z",
      "closed_at": "2025-05-28T02:37:20Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2404/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2404",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2404",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:48.942860",
      "comments": [
        {
          "author": "well-balanced",
          "body": "cc. @longcw ",
          "created_at": "2025-05-27T05:03:53Z"
        },
        {
          "author": "longcw",
          "body": "did you tried to hold the push until you finished the speech?",
          "created_at": "2025-05-27T05:04:02Z"
        },
        {
          "author": "well-balanced",
          "body": "https://github.com/user-attachments/assets/3da94d81-38e0-41cf-a39d-dacbe0946e46\n\nI hold down the button, it still doesn’t work.",
          "created_at": "2025-05-27T05:08:15Z"
        },
        {
          "author": "longcw",
          "body": "https://github.com/user-attachments/assets/328149bf-806c-44d7-a5e9-75fa8c2cddb1\n\nIt seems that the button doesn't work in your browser? This is what expected, when press and hold the button, it shows \"Speaking\" and will automatically unmute the microphone, it mutes the mic when release.\n",
          "created_at": "2025-05-27T05:14:13Z"
        },
        {
          "author": "well-balanced",
          "body": "I should’ve checked the browser logs first. I think I installed the packages based on the main branch by mistake. It’s working fine now. Thanks!\n\nBy the way, have you ever seen an issue where the transcript shows up on the client side, but there’s no voice/audio output?",
          "created_at": "2025-05-27T05:20:31Z"
        }
      ]
    },
    {
      "issue_number": 2132,
      "title": "AgentSession's error handling should not be fatal",
      "body": "Currently, `AgentSession` calls `_aclose_impl` when facing any `llm.LLMError | stt.STTError | tts.TTSError` type of error. These errors are relatively common, so they should not shut down the worker. For example, Gemini occasionally rejects or provides no answer in their responses, triggering these errors: `livekit.agents._exceptions.APIConnectionError: gemini llm: error generating content No candidates in the response (status_code=-1, request_id=bd1f1400344a, body=None)`\n\nThese currently shut down the worker, preventing further conversation. ",
      "state": "closed",
      "author": "DavidHuie",
      "author_type": "User",
      "created_at": "2025-04-25T16:17:29Z",
      "updated_at": "2025-05-27T16:44:48Z",
      "closed_at": "2025-05-27T00:28:20Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2132/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2132",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2132",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:49.150476",
      "comments": [
        {
          "author": "davidzhao",
          "body": "Gemini plugin no longer throws during empty response. see [Error handling docs](https://docs.livekit.io/agents/build/events/#error-event) for our approach on exposing these errors to you",
          "created_at": "2025-05-27T00:28:18Z"
        },
        {
          "author": "jmcclanahan13",
          "body": "@davidzhao - I assume this is not in the latest release? Not finding a related bug fix ticket. I'm still seeing these errors in 1.0.22. Seems we get errors in FallbackAdapter as well if this happens, even if we try to catch and retry in @session.on(\"error\") event handler.\n\nExample error:\n```\nTraceba",
          "created_at": "2025-05-27T14:50:12Z"
        },
        {
          "author": "davidzhao",
          "body": "@jmcclanahan13 it was fixed in #2345, we'll get a release out in the next day or so!",
          "created_at": "2025-05-27T16:44:47Z"
        }
      ]
    },
    {
      "issue_number": 1378,
      "title": "Feature Request: Ultravox example",
      "body": "Hi,\r\n\r\n[Ultravox](https://github.com/fixie-ai/ultravox) is a suite of open weight models that are designed for getting the time to first token as low as possible with audio input. Basically they trained a good and fast projector to project the whisper large v3 encoder into llama 4.1 LLMs, both in 8B and 70B size.\r\n\r\nI think it would be a great fit for livekit's agents so it would be nice to add an example and demo for it!",
      "state": "open",
      "author": "thiswillbeyourgithub",
      "author_type": "User",
      "created_at": "2025-01-15T22:26:57Z",
      "updated_at": "2025-05-27T15:49:26Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 11,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1378/reactions",
        "total_count": 7,
        "+1": 7,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1378",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1378",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:49.378837",
      "comments": [
        {
          "author": "zkoch",
          "body": "Thanks -- happy to work with folks at Livekit to make this happen!",
          "created_at": "2025-01-25T21:09:02Z"
        },
        {
          "author": "therealron",
          "body": "Any update on this?",
          "created_at": "2025-03-02T17:09:01Z"
        },
        {
          "author": "psinojiya",
          "body": "Hello Everyone, any update on this?",
          "created_at": "2025-03-19T12:14:04Z"
        },
        {
          "author": "thiswillbeyourgithub",
          "body": "I'm very interested still, especially as nothing as simple as ollama exists for chat (audio+text) but I lack the skills to implement it. I'm still surprised no one has created it since it seems to be in the best interest of all parties involved: livekit, ultravox, kyutai (they made moshi), etc. And ",
          "created_at": "2025-03-19T12:47:21Z"
        },
        {
          "author": "jayeshp19",
          "body": "Hi It will be very easy to implement with our next big release.",
          "created_at": "2025-03-19T14:01:46Z"
        }
      ]
    },
    {
      "issue_number": 2411,
      "title": "BackgroundAudioPlayer don't support on cloudrun container?",
      "body": "Hey while running the agent locally the BackgroundAudioPlayer works fine, but when we run it on cloud run container it show this warning and don't play anything:\n\nlivekit - AudioMixer: stream <async_generator object BackgroundAudioPlayer._play_task.<locals>._gen_wrapper at 0x3e6591d9e440> timeout, ignoring \u001b[90m{\"pid\": 21, \"job_id\": \"AJ_9GmKq236TS3P\"}\u001b\n\ntried on both local file and BuiltinAudioClip.OFFICE_AMBIENCE both failing\n\nany thing which can help solve this?",
      "state": "open",
      "author": "prashant9912",
      "author_type": "User",
      "created_at": "2025-05-27T12:03:11Z",
      "updated_at": "2025-05-27T12:21:57Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2411/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2411",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2411",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:50.603625",
      "comments": []
    },
    {
      "issue_number": 713,
      "title": "JobRequest- req.room.metadata is null in  livekit-agents==0.8.9 and 0.8.10 on self hosted cluster.",
      "body": "For LiveKit agent plugin versions livekit-agents==0.8.8, we get room metadata in \r\n\r\nasync def request_fnc(req: JobRequest) -> None:\r\n\r\nin req.room.metadata as value what we set while creating room, but in version 0.8.9 and 0.8.10 room metadata is empty.This is creating issue as we decide whether to accept or reject job by an worker based on metadata.\r\n\r\nFor debugging this further we setup another Kubernetes cluster with latest version of LiveKit server(1.7.2) and on that we faced same issue, but when we try same agent with a cloud url we are getting data for req.room.metadata in that case in request_fnc function.All this works fine upto version 0.8.8, and after that it works fine only against cloud deployments.\r\n\r\nWhile debugging further we noticed that when worker registers against self hosted LiveKit server we get—\r\n\r\n{\"message\": \"registered worker\", \"level\": \"INFO\", \"id\": \"AW_RUiaBy8tZiJG\", \"server_info\": \"version: \\\"1.7.2\\\"\\nprotocol: 14\\nnode_id: \\\"ND_YoMMvbptFrzu\\\"\\nagent_protocol: 1\\n\", \"timestamp\": \"2024-09-06T13:38:17.174800+00:00\"}\r\n\r\nAnd on cloud we get-\r\n{\"message\": \"registered worker\", \"level\": \"INFO\", \"id\": \"AW_9WpsyqqF9Zjp\", \"server_info\": \"edition: Cloud\\nversion: \\\"1.7.2\\\"\\nprotocol: 15\\nregion: \\\"India\\\"\\nnode_id: \\\"NC_DBLR1A_auoA9TfuCnyV\\\"\\n\", \"timestamp\": \"2024-09-06T09:19:44.927947+00:00”}\r\n\r\nIs it due to protocol difference 14 and 15?",
      "state": "open",
      "author": "Test-isom",
      "author_type": "User",
      "created_at": "2024-09-06T13:47:52Z",
      "updated_at": "2025-05-27T07:01:11Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/713/reactions",
        "total_count": 2,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 1
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/713",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/713",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:50.603645",
      "comments": [
        {
          "author": "umarniz",
          "body": "I am facing the same issue. Did you find a solution to this?",
          "created_at": "2024-10-18T17:57:16Z"
        },
        {
          "author": "umarniz",
          "body": "Actually it was an issue on my end.\r\n\r\nMy approach where metadata is correctly passed to the agent request_func:\r\n\r\n- NextJS App (UI + Server)\r\n- LiveKit Agent (Python) -> this is where request_func is called\r\n\r\nIn the NextJS App I create an API to 'createRoom'. This API. creates a room, sets the me",
          "created_at": "2024-10-18T18:54:36Z"
        },
        {
          "author": "firattamurlc",
          "body": "I have same issues is there any update on this ? ",
          "created_at": "2024-10-27T22:47:35Z"
        },
        {
          "author": "chunyeah",
          "body": "same issue. meta data always nil.\r\nlivekit-agents==0.10.2\r\n\r\n2024-10-28 17:43:35,485 - INFO voice-agent - connecting to room test-room22222, rtc.Room(sid=unknown, name=test-room22222, metadata=, connection_state=1) {\"pid\": 87126, \"job_id\": \"AJ_DNYdmSAqkeU8\"}",
          "created_at": "2024-10-28T09:47:20Z"
        },
        {
          "author": "firattamurlc",
          "body": "As a workaround I tried to set metadata to participant and it works:\r\n\r\n```python\r\ntoken = (\r\n    api.AccessToken(self.livekit_api_key, self.livekit_api_secret)\r\n    .with_identity(identity)\r\n    .with_name(room_name)\r\n    .with_grants(\r\n        api.VideoGrants(\r\n            room_join=True,\r\n       ",
          "created_at": "2024-10-28T12:52:23Z"
        }
      ]
    },
    {
      "issue_number": 1338,
      "title": "Support for Streaming Video Input to Gemini 2.0 in Voice Pipeline Agent Example",
      "body": "I was exploring the example of Gemini 2.0 provided in the repository, specifically the [voice-pipeline-agent example](https://github.com/livekit/agents/blob/main/examples/voice-pipeline-agent/gemini_voice_agent.py).\r\n\r\nI noticed that the model supports inputs such as video or images. Is there a way to stream a video feed (e.g., a screenshare) directly to the model.",
      "state": "closed",
      "author": "shreyaspapi",
      "author_type": "User",
      "created_at": "2025-01-06T10:47:38Z",
      "updated_at": "2025-05-27T06:32:21Z",
      "closed_at": "2025-05-27T06:32:19Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1338/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1338",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1338",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:50.815362",
      "comments": [
        {
          "author": "johnson7788",
          "body": "I implemented it  simple example, \r\nhttps://github.com/johnson7788/livekitrealtime/tree/main/gemini-playground",
          "created_at": "2025-01-09T08:06:42Z"
        },
        {
          "author": "davidzhao",
          "body": "supported in 1.x: https://github.com/livekit-examples/vision-demo",
          "created_at": "2025-05-27T06:32:19Z"
        }
      ]
    },
    {
      "issue_number": 1390,
      "title": "vision with multimodal gemini v2 flash",
      "body": "Hi, is anyone working on the vision implementation of the gemini-2.0-flash-exp model?\n",
      "state": "closed",
      "author": "carpathiansalt",
      "author_type": "User",
      "created_at": "2025-01-18T20:42:19Z",
      "updated_at": "2025-05-27T06:31:58Z",
      "closed_at": "2025-05-27T06:31:57Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1390/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1390",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1390",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:51.056156",
      "comments": [
        {
          "author": "johnson7788",
          "body": "I'm also very interested in this.",
          "created_at": "2025-01-20T02:01:59Z"
        },
        {
          "author": "cuongpham-1001",
          "body": "Here is my code to handle screen sharing using gemini-2.0-flash-exp. for frontend code you can refer from https://github.com/livekit-examples/meet\n\n```python3\nfrom __future__ import annotations\n\nimport logging\nimport os\nfrom typing import Annotated\n\nfrom livekit.agents import (\n    AutoSubscribe,\n  ",
          "created_at": "2025-02-05T03:00:40Z"
        },
        {
          "author": "johnson7788",
          "body": "@cuongpham-1001 Yes, it works, Greet Job!\n\n# cat .env\n```\nLIVEKIT_API_KEY=devkey\nLIVEKIT_API_SECRET=secret\nLIVEKIT_URL=\"ws://127.0.0.1:7880\"\nGOOGLE_API_KEY=\"xxxxxx\"\n```\n\n\n#cat main.py\n```\nfrom __future__ import annotations\n\nimport logging\nimport os\nfrom typing import Annotated\n\nfrom livekit.agents i",
          "created_at": "2025-02-11T01:34:15Z"
        },
        {
          "author": "cuongpham-1001",
          "body": "Hi @jayeshp19 :\nAlthough my code example is working. it's not a built-in support from livekit plugins. _queue_msg is a internal method which not suppose to be called outside. \ndo you have plan to support video streaming for genimi?",
          "created_at": "2025-02-20T07:18:54Z"
        },
        {
          "author": "davidzhao",
          "body": "vision is fully supported now in v1.x, please reference example: https://github.com/livekit-examples/vision-demo",
          "created_at": "2025-05-27T06:31:57Z"
        }
      ]
    },
    {
      "issue_number": 1575,
      "title": "Google plugin for RealtimeModel throws an error with VertexAI connection",
      "body": "Google RealtimeModel throws error with VertexAI connection ( flag set to True ). Setup works fine if Gemini API key.\n\n\nVersions\n\n```\nlivekit-agents = \"0.12.16\"\nlivekit-plugins-google = \"0.10.6\"\n```\n\nError logs\n```\n2025-02-28 19:37:51,839 - ERROR livekit.plugins.google - Error in _main_task\nTraceback (most recent call last):\n  File \"Path\\Lib\\site-packages\\livekit\\agents\\utils\\log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"Path\\agents\\livekit\\google_multimodal_real_time_model.py\", line 492, in _main_task\n    async with self._client.aio.live.connect(\n  File \"C:\\Users\\91760\\.pyenv\\pyenv-win\\versions\\3.11.0\\Lib\\contextlib.py\", line 204, in __aenter__\n    return await anext(self.gen)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"Path\\Lib\\site-packages\\google\\genai\\live.py\", line 726, in connect\n    async with connect(uri, additional_headers=headers) as ws:\n  File \"Path\\Lib\\site-packages\\websockets\\asyncio\\client.py\", line 487, in __aenter__\n    return await self\n           ^^^^^^^^^^\n  File \"Path\\Lib\\site-packages\\websockets\\asyncio\\client.py\", line 446, in __await_impl__\n    await self.connection.handshake(*self.handshake_args)\n  File \"Path\\Lib\\site-packages\\websockets\\asyncio\\client.py\", line 104, in handshake\n    raise self.protocol.handshake_exc\n  File \"Path\\Lib\\site-packages\\websockets\\client.py\", line 340, in parse\n    self.process_response(response)\n  File \"Path\\Lib\\site-packages\\websockets\\client.py\", line 151, in process_response\n    raise InvalidStatus(response)\nwebsockets.exceptions.InvalidStatus: server rejected WebSocket connection: HTTP 400\n\n```\n\nSlack thread - https://livekit-users.slack.com/archives/C07FY8WHGPM/p1740067026287069?thread_ts=1739388050.295379&cid=C07FY8WHGPM",
      "state": "closed",
      "author": "psinojiya",
      "author_type": "User",
      "created_at": "2025-02-28T14:14:51Z",
      "updated_at": "2025-05-27T06:29:27Z",
      "closed_at": "2025-05-27T06:29:26Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1575/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "jayeshp19"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1575",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1575",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:51.353555",
      "comments": [
        {
          "author": "psinojiya",
          "body": "Hello @jayeshp19 , seems like there is a bug with Realtime Model with VertexAI (Using latest google-plugin pypi release). Pls let me know if you need any more information that might be helpful.",
          "created_at": "2025-02-28T14:16:38Z"
        },
        {
          "author": "psinojiya",
          "body": "Hi @jayeshp19. Do we have any luck on this one?",
          "created_at": "2025-03-06T14:44:10Z"
        },
        {
          "author": "jayeshp19",
          "body": "It's broken in their api, will investigate, thanks for reporting :)",
          "created_at": "2025-03-06T15:17:18Z"
        },
        {
          "author": "Denin-Siby",
          "body": "Hi @jayeshp19 any luck on this?",
          "created_at": "2025-03-26T11:51:24Z"
        },
        {
          "author": "davidzhao",
          "body": "this had been resolved. the latest version works with vertexai",
          "created_at": "2025-05-27T06:29:26Z"
        }
      ]
    },
    {
      "issue_number": 1443,
      "title": "Gemini 2.0 Flash Realtime Agent return inaccuracy transcriptions",
      "body": "I'm trying to test the gemini realtime agent base on this example: https://github.com/livekit/agents/blob/main/examples/multimodal-agent/gemini_agent.py. when I enable log, I saw the agent_transcript output didn't match the voice response. \nit worked perfectly when I use openai realtime model \n",
      "state": "closed",
      "author": "cuongpham-1001",
      "author_type": "User",
      "created_at": "2025-02-04T05:45:01Z",
      "updated_at": "2025-05-27T06:27:47Z",
      "closed_at": "2025-05-27T06:27:47Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1443/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "jayeshp19"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1443",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1443",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:51.657317",
      "comments": [
        {
          "author": "cuongpham-1001",
          "body": "I just checked the code and saw live google plugin is using the same model 'gemini-2.0-flash-exp' in https://github.com/livekit/agents/blob/ab37531589eaed6c645f719988cf7c871056dc6c/livekit-plugins/livekit-plugins-google/livekit/plugins/google/beta/realtime/transcriber.py. Look like the recommended m",
          "created_at": "2025-02-04T06:20:34Z"
        },
        {
          "author": "cuongpham-1001",
          "body": "It's great if we allow config TranscriptionModel when init RealtimeModel",
          "created_at": "2025-02-06T02:57:20Z"
        },
        {
          "author": "davidzhao",
          "body": "we've isolated the issue to the realtime model producing inaccuracies. it's fixed in this PR: https://github.com/livekit/agents/pull/1446",
          "created_at": "2025-02-06T05:50:27Z"
        }
      ]
    },
    {
      "issue_number": 1636,
      "title": "Text messages and Spoken messages to Gemini out of sync.",
      "body": "I updated gemini realtime api (https://github.com/livekit/agents/commit/0a1070611b68554878f98f7f1f33e3c73bf16e51) to accept text messages and process them using following code:\n\n```\nasync def send_text(self, text: str) -> None:\n        self._chat_ctx.append(text=text, role=\"user\")\n        self.create_response(on_duplicate=\"keep_both\")\n```\nHowever, they do not seem to be in sync. Messages sent via chat seems to be in different context than the messages spoken verbally.\n\nSo if I call ```send_text(\"Say specific words - Hi there. This is a text message.\")``` Gemini will respond with that message for all the messages sent via send_text but not for the spoken messages.\n\nThis is probably because spoken messages to not seem to be sharing the same chat_ctx (https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-google/livekit/plugins/google/beta/realtime/realtime_api.py#L431)\n\nHow can it be fixed to make it work seamlessly irrespective of text or spoken message using the same context.\n\nRegards,\nAkshay Shah.",
      "state": "closed",
      "author": "meetakshay99",
      "author_type": "User",
      "created_at": "2025-03-12T11:10:42Z",
      "updated_at": "2025-05-27T05:03:14Z",
      "closed_at": "2025-05-27T05:03:13Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1636/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1636",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1636",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:51.929953",
      "comments": [
        {
          "author": "davidzhao",
          "body": "the correct API to use for this is `session.generate_reply(user_input=\"...\")`\n\nthis will now correctly use the existing chat context.",
          "created_at": "2025-05-27T05:03:13Z"
        }
      ]
    },
    {
      "issue_number": 1154,
      "title": "Cerebras messes with tools",
      "body": "<!--\r\nHello! Thanks for taking the time to file a bug report.\r\n\r\nBefore creating this issue, we kindly ask that you use the search functionality\r\nto see if anyone else has already reported this issue.\r\nPlease include details such as environment, package versions, minimal examples,\r\nand error logs, if applicable.\r\n-->\r\n\r\nUsing this configuration works\r\n```\r\n\r\n    assistant = VoiceAssistant(\r\n        vad=ctx.proc.userdata[\"vad\"],\r\n        stt=deepgram.STT(),\r\n        llm=openai.LLM(),\r\n        tts=cartesia.TTS(voice=\"41f3c367-e0a8-4a85-89e0-c27bae9c9b6d\"),\r\n        chat_ctx=initial_ctx,\r\n        fnc_ctx=func_ctx,\r\n    )\r\n```\r\n\r\nBut if we replace openai.LLM with \r\n```\r\nllm=openai.LLM(\r\n        base_url=\"https://api.cerebras.ai/v1\",\r\n        api_key=os.environ.get(\"CEREBRAS_API_KEY\"),\r\n        model=\"llama3.1-8b\",\r\n)\r\n```\r\n\r\nthen the agent is no longer able to see the results of tool calls\r\n\r\n<img width=\"1099\" alt=\"image\" src=\"https://github.com/user-attachments/assets/75f8fd54-020c-42ad-8441-3cb10fb58106\">\r\n\r\n",
      "state": "open",
      "author": "mwufi",
      "author_type": "User",
      "created_at": "2024-12-01T02:26:21Z",
      "updated_at": "2025-05-27T04:06:16Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1154/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1154",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1154",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:52.170771",
      "comments": [
        {
          "author": "billyg88",
          "body": "Shouldn't you be using ```with_cerebras``` on your LLM declaration?",
          "created_at": "2024-12-02T14:13:12Z"
        },
        {
          "author": "imohitmayank",
          "body": "Facing similar issue, even with officia Cerebras example and using both 8b and 70b model, function call is never happening. Is this bcoz of model or the some code issue?",
          "created_at": "2024-12-05T12:47:33Z"
        },
        {
          "author": "jayeshp19",
          "body": "Hi @mwufi  @imohitmayank,  \r\n\r\nI've tried reproducing these issues, and it seems Cerebras models aren't optimal for tool use. Here are my observations:  \r\n\r\n- llama3.1-8b: Doesn't handle tool calls properly.  \r\n- llama3.1-70b:  Generates same tool call even after receiving a tool response.  \r\n\r\nHope",
          "created_at": "2024-12-06T11:28:24Z"
        },
        {
          "author": "davidzhao",
          "body": "I've talked to the Cerebras team and they've confirmed these will be improved very soon, currently planned in the next few weeks! Stay tuned and we'll update here when it's resolved.",
          "created_at": "2024-12-11T01:30:39Z"
        },
        {
          "author": "imohitmayank",
          "body": "Btw function call is much better for `llama-3.3-70b`. ",
          "created_at": "2024-12-11T05:33:08Z"
        }
      ]
    },
    {
      "issue_number": 2400,
      "title": "Unable to pass Screenshare audio to agent STT node",
      "body": "Hi,\n\nCan someone please help me, I am trying to pass screenshare audio to livekit agent, but for some reason STT node is not kicking in when Screen share audio is being passed from my flutter client. But I am unable to achieve it. Can some help me with this.\n\nHere is my agent \n\n```\nclass Assistant(Agent):\n    def __init__(self) -> None:\n        self._latest_frame = None\n        self._video_stream = None\n        self._tasks = []\n        # This project is configured to use Deepgram STT, OpenAI LLM and Cartesia TTS plugins\n        # Other great providers exist like Cerebras, ElevenLabs, Groq, Play.ht, Rime, and more\n        # Learn more and pick the best one for your app:\n        # https://docs.livekit.io/agents/plugins\n        super().__init__(\n            instructions=\"You are a voice assistant created by LiveKit. Your interface with users will be voice. \"\n            \"You should use short and concise responses, and avoiding usage of unpronouncable punctuation. \",\n            stt=azure.STT(\n                ********\n        ),\n            llm=openai.LLM.with_azure(\n               ********\n            ),\n            allow_interruptions=True,\n        )\n\n    async def on_enter(self):\n        room = get_job_context().room\n\n        # The agent should be polite and greet the user when it joins :)\n        self.session.generate_reply(\n            instructions=\"Hey, how can I help you today?\", allow_interruptions=True\n        )\n        \ndef prewarm(proc: JobProcess):\n    proc.userdata[\"vad\"] = silero.VAD.load()\n\n\nasync def entrypoint(ctx: JobContext):\n    logger.info(f\"connecting to room {ctx.room.name}\")\n    await ctx.connect(auto_subscribe=AutoSubscribe.SUBSCRIBE_ALL)\n\n    # Wait for the first participant to connect\n    participant = await ctx.wait_for_participant()\n    logger.info(f\"starting voice assistant for participant {participant.identity}\")\n\n    usage_collector = metrics.UsageCollector()\n\n    # Log metrics and collect usage data\n    def on_metrics_collected(agent_metrics: metrics.AgentMetrics):\n        metrics.log_metrics(agent_metrics)\n        usage_collector.collect(agent_metrics)\n\n    session = AgentSession(\n        min_endpointing_delay=0.5,\n        max_endpointing_delay=5.0,\n         stt=azure.STT(\n         *********\n        ),\n            llm=openai.LLM.with_azure(\n              *********\n            ),\n    )\n\n    # Trigger the on_metrics_collected function when metrics are collected\n    session.on(\"metrics_collected\", on_metrics_collected)\n   \n    await session.start(\n        room=ctx.room,\n        agent=Assistant(),\n        room_input_options=RoomInputOptions(\n            # enable background voice & noise cancellation, powered by Krisp\n            # included at no additional cost with LiveKit Cloud\n            audio_enabled=True,\n            text_enabled=True,\n            video_enabled=True,\n            noise_cancellation=noise_cancellation.BVC(),\n        ),\n        room_output_options=RoomOutputOptions(transcription_enabled=True, audio_enabled=True,\n```\n            sync_transcription=False,),\n    )\n\nif __name__ == \"__main__\":\n    cli.run_app(\n        WorkerOptions(\n            entrypoint_fnc=entrypoint,\n            prewarm_fnc=prewarm,\n        ),\n    )\n",
      "state": "open",
      "author": "llamando",
      "author_type": "User",
      "created_at": "2025-05-26T17:41:59Z",
      "updated_at": "2025-05-26T22:48:58Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2400/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2400",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2400",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:52.428280",
      "comments": [
        {
          "author": "davidzhao",
          "body": "currently this is keyed to listen to microphone input. what is your use case here? is the audio expected to come from screen share and not microphone?",
          "created_at": "2025-05-26T21:18:50Z"
        },
        {
          "author": "llamando",
          "body": "yes that's right, system audio from shared screen should be passed into STT and downstream to the agent pipeline, instead of microphone\n\n![Image](https://github.com/user-attachments/assets/d0850ad2-2927-422e-b2a0-16784e142a1d)",
          "created_at": "2025-05-26T22:37:45Z"
        }
      ]
    },
    {
      "issue_number": 2092,
      "title": "Gemini Realtime problems with other languages (e.g. German) on agents v1 and 0.x",
      "body": "Hey, I'm trying to replace my openai realtime agent with the google gemini one. For this I've set up the agent via the v1 AgentSession with the model:\n\n```\nmodel = google.beta.realtime.RealtimeModel(\n            model=\"gemini-2.0-flash-live-001\",\n            location=\"europe-west3\",\n            instructions=instructions,\n            voice=\"Puck\",\n            modalities=[Modality.AUDIO],\n        )\n```\n\nHowever I can't set the language for the realtime agent. I want it to speak common languages like German, Spanish, English and French. It speaks German but it doesn't work with Umlauts (ö, ü, ..) and it also starts dictating single characters in the middle of the sentence.\nThis happens both on agents v1 and 0.x.\n\nOn googles aistudio playground ([https://aistudio.google.com/live](https://aistudio.google.com/live)) this works really well. I also can specifically set the language to German.\nIs this what's missing here? Or is there an option to set the language for realtime agents?\nWhat if the user wants to switch languages during the conversation? In openai realtime this works seamlessly.\n\nWould love to add gemini realtime to my service so any help / fixes would be much appreciated. Thanks! <3\n",
      "state": "closed",
      "author": "schedawg74",
      "author_type": "User",
      "created_at": "2025-04-23T11:51:54Z",
      "updated_at": "2025-05-26T21:35:24Z",
      "closed_at": "2025-05-26T21:35:24Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2092/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "jayeshp19"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2092",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2092",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:52.688584",
      "comments": [
        {
          "author": "jayeshp19",
          "body": "hmm there's no config for specifying language with live api in gemini. I will create an issue on their sdk",
          "created_at": "2025-04-23T14:56:52Z"
        },
        {
          "author": "jayeshp19",
          "body": "https://github.com/googleapis/python-genai/issues/719",
          "created_at": "2025-04-23T15:01:08Z"
        },
        {
          "author": "ChenghaoMou",
          "body": "Not tested, but I think they just [added](https://github.com/googleapis/python-genai/commit/807f098dedd0f885147fb10db7f79af9230999e0#diff-4579dd94816924284e59f28c7f6f42cab6c1389680a48da9b7f037a501890ce7) language code in speech config:\n\n<img width=\"602\" alt=\"Image\" src=\"https://github.com/user-attac",
          "created_at": "2025-04-23T15:14:22Z"
        },
        {
          "author": "jayeshp19",
          "body": "Oh nice, looks like they added in recent version. will add it on LK sdk",
          "created_at": "2025-04-23T15:32:27Z"
        },
        {
          "author": "schedawg74",
          "body": "> Oh nice, looks like they added in recent version. will add it on LK sdk\n\nAny updates on this? :) Thanks for your help by the way!",
          "created_at": "2025-04-25T06:51:29Z"
        }
      ]
    },
    {
      "issue_number": 2393,
      "title": "The `track_published` event is NOT triggered intermittently.",
      "body": "Hello, I am using the `track_published` event to start a egress to capture the user audio track and `local_track_published` event to start a egress to capture the agent audio track separately.\n\nI am observing a weird behavior where `track_published` event is NOT triggered at all and this issue is intermittent and is NOT replicable at all times. But the `local_track_published` is published all the time.\n\nI was using 1.0.11 version of the `agents` SDK and upgraded it to the latest `1.0.22` but still facing the same issue where I see that the `track_published` event is NOT triggered for some calls.\n\nBelow is my code and the version of the livekit-sdk and other libs I am using from livekit\n```python\n\n  @self.job_ctx.room.on(\"track_published\")\n  def on_track_published(e: RemoteTrackPublication):\n      async def _audio_track_egress(e: RemoteTrackPublication):\n          user_audio_track_file_path = (\n              Config.USER_TRACK_AUDIO_FILE_PATH_TEMPLATE.format(\n                  S3_PATH=self.audio_s3_prefix,\n                  ROOM_NAME=self.livekit_room_name,\n                  CALL_ID=self.call_id,\n              )\n          )\n          self.user_audio_track_file_path = await audio_track_egress(\n              ctx=self.job_ctx,\n              track_id=e.sid,\n              s3_bucket=self.audio_s3_bucket,\n              s3_region=self.audio_s3_region,\n              file_path=user_audio_track_file_path,\n              boto_session=boto_session,\n          )\n\n      task = asyncio.create_task(_audio_track_egress(e))\n      asyncio.gather(task)\n\n  @self.job_ctx.room.on(\"local_track_published\")\n  def on_local_track_published(e: LocalTrackPublication):\n\n      async def _audio_track_egress(e: LocalTrackPublication):\n          agent_audio_track_file_path = (\n              Config.AGENT_TRACK_AUDIO_FILE_PATH_TEMPLATE.format(\n                  S3_PATH=self.audio_s3_prefix,\n                  ROOM_NAME=self.livekit_room_name,\n                  CALL_ID=self.call_id,\n              )\n          )\n          self.agent_audio_track_file_path = await audio_track_egress(\n              ctx=self.job_ctx,\n              track_id=e.track.sid,\n              s3_bucket=self.audio_s3_bucket,\n              s3_region=self.audio_s3_region,\n              file_path=agent_audio_track_file_path,\n              boto_session=boto_session,\n          )\n\n      task = asyncio.create_task(_audio_track_egress(e))\n      asyncio.gather(task)\n```\n\nEnvironment:\n1. Python - 3.11.11\n2. LiveKit libs - \n        livekit==1.0.8\n        livekit-agents==1.0.22\n        livekit-api==1.0.2\n        livekit-plugins-anthropic==1.0.22\n        livekit-plugins-cartesia==1.0.22\n        livekit-plugins-deepgram==1.0.22\n        livekit-plugins-elevenlabs==1.0.22\n        livekit-plugins-noise-cancellation==0.2.4\n        livekit-plugins-openai==1.0.22\n        livekit-plugins-silero==1.0.22\n        livekit-plugins-turn-detector==1.0.22\n        livekit-protocol==1.0.3\n       \n\nThis is causing issues on our Production system. So would really appreciate if anyone can help me here. Please let me know if there are any questions around this.",
      "state": "closed",
      "author": "zaheerabbas-prodigal",
      "author_type": "User",
      "created_at": "2025-05-25T18:44:58Z",
      "updated_at": "2025-05-26T16:45:48Z",
      "closed_at": "2025-05-26T16:45:48Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2393/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2393",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2393",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:52.982790",
      "comments": [
        {
          "author": "theomonnom",
          "body": "Hey, make sure to register all your event listeners before calling `ctx.connect()`, let me know if it helps/already the case ",
          "created_at": "2025-05-25T18:50:12Z"
        },
        {
          "author": "zaheerabbas-prodigal",
          "body": "@theomonnom - thank you for the quick response. Yes the above events are registered before the `await ctx.connect()` is called.\n",
          "created_at": "2025-05-25T18:59:36Z"
        },
        {
          "author": "zaheerabbas-prodigal",
          "body": "@theomonnom - I also noticed that I am able to reproduce this locally 100% of the times. But when I deploy this to production, the issue is intermittent. What logs / details can I share here to help further?",
          "created_at": "2025-05-25T20:07:01Z"
        },
        {
          "author": "longcw",
          "body": "I think the track published before you join the room won't trigger the `track_published` event. You can iterate over the existing tracks right after you add the event handler\n```python\n    @ctx.room.on(\"track_published\")\n    def on_track_published(e: RemoteTrackPublication):\n        ...\n\n    for par",
          "created_at": "2025-05-26T01:12:58Z"
        },
        {
          "author": "zaheerabbas-prodigal",
          "body": "@longcw - Will check if the above resolves the issue and update here. Thank you for the response",
          "created_at": "2025-05-26T03:57:40Z"
        }
      ]
    },
    {
      "issue_number": 2377,
      "title": "Last Agent Message is not Logged During TTS Phase When User Leaves Room in LiveKit Session",
      "body": "In our LiveKit-based application, we've observed that when an agent sends a message during the Text-to-Speech (TTS) phase and the user leaves the room—resulting in the room closing—the agent's last message isn't saved in the logs. This behavior leads to incomplete audit trails and potential gaps in conversation history.\n\n\nExpected Behavior:\nEven if the user exits the room and it subsequently closes, the agent's final message during the TTS phase should be captured and saved in the logs to maintain a complete conversation history.",
      "state": "closed",
      "author": "gulamsarvar-bluebash",
      "author_type": "User",
      "created_at": "2025-05-23T08:03:22Z",
      "updated_at": "2025-05-26T13:18:25Z",
      "closed_at": "2025-05-24T10:02:59Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2377/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2377",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2377",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:53.220433",
      "comments": [
        {
          "author": "longcw",
          "body": "This should be fixed in https://github.com/livekit/agents/pull/2309, can you try the latest version 1.0.22\n\nwith that you may still need to keep the room open for a few seconds for the agent to get the final user transcript and log it.",
          "created_at": "2025-05-23T08:15:44Z"
        },
        {
          "author": "longcw",
          "body": "Which version of agents are you using?\n\nCan you listen to these two events and see if you got the last user transcript\n```python\n    @session.on(\"conversation_item_added\")\n    def _on_conversation_item_added(ev: ConversationItemAddedEvent):\n        print(f\"Conversation item added: {ev.item}\")\n\n    @",
          "created_at": "2025-05-23T09:58:20Z"
        },
        {
          "author": "gulamsarvar-bluebash",
          "body": "I'm using the latest version, but I'm not receiving the most recent agent transcript. Specifically, I need the transcript that captures the agent's speech right at the moment the room is closed, when the agent is interrupted by the shutdown. That portion of the transcription seems to be missing, and",
          "created_at": "2025-05-23T10:20:52Z"
        },
        {
          "author": "longcw",
          "body": "for agent transcription, you can just interrupt the agent using `session.interrupt` when participant disconnected? and what did you got from the `conversation_item_added` event?\n```python\n    @session.on(\"conversation_item_added\")\n    def _on_conversation_item_added(ev: ConversationItemAddedEvent):\n",
          "created_at": "2025-05-23T10:23:33Z"
        },
        {
          "author": "gulamsarvar-bluebash",
          "body": "From the `conversation_item_added` event, I only receive the transcript after the agent's playout is completed. However, I need the transcript while the agent is still speaking, specifically when playout is False and the room closes. I'm trying to capture the agent's in-progress speech transcript be",
          "created_at": "2025-05-23T10:31:58Z"
        }
      ]
    },
    {
      "issue_number": 1453,
      "title": "initialization timed out, killing process. this heppens very often and sometimes I can start the agent without any issue.",
      "body": "\nSometimes it runs successfully, but most of the time I get this error. \n```\n.venv/bin/python3.10 agent.py dev\n2025-02-06 05:02:51,425 - DEBUG asyncio - Using selector: EpollSelector \n2025-02-06 05:02:51,429 - DEV  livekit.agents - Watching /home/ai-agent/agent \n2025-02-06 05:03:02,101 - DEBUG asyncio - Using selector: EpollSelector \n2025-02-06 05:03:02,298 - INFO livekit.agents - starting worker {\"version\": \"0.12.10\", \"rtc-version\": \"0.19.1\"}\n2025-02-06 05:03:02,298 - INFO livekit.agents - starting inference executor \n2025-02-06 05:03:12,065 - INFO livekit.agents - initializing inference process {\"pid\": 13864, \"inference\": true}\n2025-02-06 05:03:12,065 - DEBUG livekit.agents - initializing inference runner {\"runner\": \"lk_end_of_utterance\", \"pid\": 13864, \"inference\": true}\n2025-02-06 05:03:32,340 - ERROR livekit.agents - initialization timed out, killing process {\"pid\": 13864, \"inference\": true}\n2025-02-06 05:03:32,340 - INFO livekit.agents - killing process {\"pid\": 13864, \"inference\": true}\n2025-02-06 05:03:32,340 - ERROR livekit.agents - worker failed \nTraceback (most recent call last):\n  File \"/home/ai-agent/agent/.venv/lib/python3.10/site-packages/livekit/agents/ipc/channel.py\", line 47, in arecv_message\n    return _read_message(await dplx.recv_bytes(), messages)\n  File \"/home/ai-agent/agent/.venv/lib/python3.10/site-packages/livekit/agents/utils/aio/duplex_unix.py\", line 35, in recv_bytes\n    len_bytes = await self._reader.readexactly(4)\n  File \"/usr/lib/python3.10/asyncio/streams.py\", line 708, in readexactly\n    await self._wait_for_data('readexactly')\n  File \"/usr/lib/python3.10/asyncio/streams.py\", line 501, in _wait_for_data\n    await self._waiter\nasyncio.exceptions.CancelledError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 456, in wait_for\n    return fut.result()\nasyncio.exceptions.CancelledError\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/ai-agent/agent/.venv/lib/python3.10/site-packages/livekit/agents/cli/cli.py\", line 266, in _worker_run\n    await worker.run()\n  File \"/home/ai-agent/agent/.venv/lib/python3.10/site-packages/livekit/agents/worker.py\", line 330, in run\n    await self._inference_executor.initialize()\n  File \"/home/ai-agent/agent/.venv/lib/python3.10/site-packages/livekit/agents/ipc/supervised_proc.py\", line 164, in initialize\n    init_res = await asyncio.wait_for(\n  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 458, in wait_for\n    raise exceptions.TimeoutError() from exc\nasyncio.exceptions.TimeoutError\n\n```\n\nagent.py\n\n```\nimport logging\n\nfrom dotenv import load_dotenv\nfrom livekit.agents import (\n    AutoSubscribe,\n    JobContext,\n    JobProcess,\n    WorkerOptions,\n    cli,\n)\nfrom livekit.plugins import turn_detector, silero\nfrom livekit.agents.pipeline import VoicePipelineAgent\nfrom whisperSTT import WhisperSTT\nfrom miraLLM import MiraLLM\nfrom xTTS import XTTS\n\nload_dotenv(dotenv_path=\".env\")\n\n\nlogger = logging.getLogger(\"voice-agent\")\n\n\ndef prewarm(proc: JobProcess):\n    proc.userdata[\"vad\"] = silero.VAD.load()\n\n\nasync def entrypoint(ctx: JobContext):\n    stt = WhisperSTT()\n    tts = XTTS()\n    mira_llm = MiraLLM()\n\n    logger.info(f\"connecting to room {ctx.room.name}\")\n    await ctx.connect(auto_subscribe=AutoSubscribe.AUDIO_ONLY)\n\n    # Wait for the first participant to connect\n    participant = await ctx.wait_for_participant(identity='agent-connector')\n    logger.info(f\"starting voice assistant for participant {participant.identity}\")\n\n    agent = VoicePipelineAgent(\n        turn_detector=turn_detector.EOUModel(),\n        vad=ctx.proc.userdata[\"vad\"],\n        stt=stt,\n        tts=tts,\n        llm=mira_llm,\n    )\n\n    logger.info('agent started')\n    agent.start(ctx.room, participant)\n    \n    def on_participant_disconnected(participant):\n        logger.info(participant)\n        if participant.identity == \"agent-connector\":\n            ctx.shutdown(reason=\"Conversation concluded\")\n\n    ctx.room.on('participant_disconnected', on_participant_disconnected)\n\n    # The agent should be polite and greet the user when it joins :)\n    await agent.say(\"Hey, how can I help you today?\", allow_interruptions=True)\n    \n\nif __name__ == \"__main__\":\n    cli.run_app(\n        WorkerOptions(\n            entrypoint_fnc=entrypoint,\n            prewarm_fnc=prewarm,\n            job_memory_warn_mb=15000,\n            initialize_process_timeout=2000,\n            agent_name=\"taiga-ai-voice-agent\",\n        ),\n    )\n\n```",
      "state": "closed",
      "author": "dipumiah018",
      "author_type": "User",
      "created_at": "2025-02-06T07:45:23Z",
      "updated_at": "2025-05-26T01:16:36Z",
      "closed_at": "2025-02-12T12:34:32Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 10,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1453/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1453",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1453",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:53.451724",
      "comments": [
        {
          "author": "davidzhao",
          "body": "what are these libraries?\n```\nfrom whisperSTT import WhisperSTT\nfrom miraLLM import MiraLLM\nfrom xTTS import XTTS\n```\n\nif they are performing heavy operations when modules are getting loaded.. this is expected to timeout",
          "created_at": "2025-02-06T08:55:46Z"
        },
        {
          "author": "dipumiah018",
          "body": "@davidzhao Ahh, do I have any option to increase the timeout limit? cause when it succeed in running it takes around a minute to start.  And, those libraries are my custom implantation for Whisper STT, XTTs, and LLM. I can provide you the files if needed. \nhere is a log for successful run. ran the c",
          "created_at": "2025-02-06T09:46:21Z"
        },
        {
          "author": "johnson7788",
          "body": "Not initial in here. Slowly.\n\n    stt = WhisperSTT()\n    tts = XTTS()\n    mira_llm = MiraLLM()",
          "created_at": "2025-02-07T02:47:26Z"
        },
        {
          "author": "Harras3",
          "body": "did you find any solution? because I am also stuck in this problem",
          "created_at": "2025-02-09T13:55:45Z"
        },
        {
          "author": "Harras3",
          "body": "try to load your llm, stt, tts in prewarm function then use them in entrypoint, maybe your issue get resolved after this. Can you provide your implementation of opensource stt, tts, llm please.",
          "created_at": "2025-02-09T17:39:33Z"
        }
      ]
    },
    {
      "issue_number": 2386,
      "title": "agent entrypoint context connect took too long",
      "body": "hi\n\nI'm using latest livekit agent and livekit==1.8.4\n\n```python\nasync def entrypoint(ctx: JobContext):\n  ctx.log_context_fields = {\n    'room': ctx.room.name,\n  }\n  main_logger.info('connecting to room %s', ctx.room.name)\n\n  # this took 4 to 5 seconds\n  await ctx.connect()\n\n  ...\n```\n\nthe `connect` method took 4+ seconds to connect to livekit server on the same machine\n\nis it normal or i need to config something to fix it?",
      "state": "closed",
      "author": "DeoLeung",
      "author_type": "User",
      "created_at": "2025-05-23T15:58:50Z",
      "updated_at": "2025-05-25T18:10:09Z",
      "closed_at": "2025-05-25T18:10:09Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2386/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2386",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2386",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:53.716146",
      "comments": [
        {
          "author": "DeoLeung",
          "body": "I think i fix it by following production deployment to config the livekit server, it's now blazing fast :)",
          "created_at": "2025-05-25T18:10:09Z"
        }
      ]
    },
    {
      "issue_number": 2389,
      "title": "[1.0 regression] EOUModel fails on FunctionCall objects: AttributeError 'FunctionCall' object has no attribute 'role'",
      "body": "**Summary**: EOUModel's `predict_end_of_turn()` method crashes when FunctionCall objects are present in chat context\n\nThe EOUModel.predict_end_of_turn() method assumes every item in chat_ctx.items has a role attribute, but function calls don't have this attribute.\n\n**Steps to Reproduce**:\n1. Use AgentSession with turn_detection=turn_detector.EOUModel()\n2. Have function tools that get called by the LLM  \n3. Function calls get added to chat context as FunctionCall objects\n4. EOUModel tries to access `.role` attribute on FunctionCall objects\n\n**Expected**: EOUModel should handle or skip FunctionCall objects\n**Actual**: AttributeError: 'FunctionCall' object has no attribute 'role'\n\n**Fix**: Add hasattr() check in eou.py line 160:\n```python\nif not hasattr(msg, \"role\") or msg.role not in (\"user\", \"assistant\"):\n```\n\n**Version**: livekit-agents==1.0.22, livekit-plugins-turn-detector==0.3.4",
      "state": "closed",
      "author": "eddiemonroe",
      "author_type": "User",
      "created_at": "2025-05-24T14:17:38Z",
      "updated_at": "2025-05-24T14:24:54Z",
      "closed_at": "2025-05-24T14:24:53Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2389/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2389",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2389",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:53.931684",
      "comments": [
        {
          "author": "eddiemonroe",
          "body": "Realize the problem was due to using an outdated version of livekit-plugins-turn-detector (0.3.4). Upgrading fixed the problem. Closing.",
          "created_at": "2025-05-24T14:24:53Z"
        }
      ]
    },
    {
      "issue_number": 2381,
      "title": "model response is not logged in text in backend console",
      "body": "is there any other way to log the model response in console in livekit\nalthough model is response properly the query of user in speech \ni tried everything \n",
      "state": "closed",
      "author": "anshulpwappgo",
      "author_type": "User",
      "created_at": "2025-05-23T11:25:00Z",
      "updated_at": "2025-05-24T07:45:30Z",
      "closed_at": "2025-05-24T07:45:30Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2381/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2381",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2381",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:54.287413",
      "comments": [
        {
          "author": "longcw",
          "body": "you can log it by yourself listening to the conversation_item_added event\n```python\n    @session.on(\"conversation_item_added\")\n    def _on_conversation_item_added(ev: ConversationItemAddedEvent):\n        print(f\"Conversation item added: {ev.item}\")\n```",
          "created_at": "2025-05-23T11:47:37Z"
        },
        {
          "author": "anshulpwappgo",
          "body": "but do you know the reason why it is not happening\n\n> you can log it by yourself listening to the conversation_item_added event\n> \n>     @session.on(\"conversation_item_added\")\n>     def _on_conversation_item_added(ev: ConversationItemAddedEvent):\n>         print(f\"Conversation item added: {ev.item}\"",
          "created_at": "2025-05-23T11:53:43Z"
        },
        {
          "author": "longcw",
          "body": "wdym \"it is not happening\"? the agent message was not printed with this event?",
          "created_at": "2025-05-23T11:56:09Z"
        },
        {
          "author": "anshulpwappgo",
          "body": "> wdym \"it is not happening\"? the agent message was not printed with this event?\ni am not able to find this in agent \nfrom livekit.agents.session import ConversationItemAddedEvent, ConversationItemKind\nModuleNotFoundError: No module named 'livekit.agents.session'\n",
          "created_at": "2025-05-23T13:21:46Z"
        },
        {
          "author": "longcw",
          "body": "import it from livekit.agents https://docs.livekit.io/agents/build/events/#events",
          "created_at": "2025-05-23T13:23:44Z"
        }
      ]
    },
    {
      "issue_number": 1128,
      "title": "Websocket between LLM and livekit disconnect due to long STT message",
      "body": "Hi Everyone,\r\nI am facing an issue with websocket disconnect when the STT message is too long or there so many STT message due to noise or outside words.\r\nIssue raises when assistant got interrupt and there a queue of STT text sending to the LLM. The connection between livekit with LLM got disconnected due to liveness and timeout.\r\nDoes anyone have any suggestions or face similar issues? please let me know.\r\nI am using latest livekit version with other latest dependencies.\r\n```bash\r\nDEBUG:    ! timed out waiting for keepalive pong\r\nDEBUG:    ! failing connection with code 1011\r\nDEBUG:    = connection is CLOSING\r\nDEBUG:    > CLOSE 1011 (unexpected error) keepalive ping timeout [24 bytes]\r\nDEBUG:    x half-closing TCP connection\r\nDEBUG:    ! timed out waiting for TCP close\r\nDEBUG:    x closing TCP connection\r\nDEBUG:    = connection is CLOSED\r\n2024-11-22 11:21:44.867 | INFO     | api_server.app_ws:websocket_endpoint:168 - Client disconnected\r\n2024-11-22 11:21:44.868 | ERROR    | api_server.app_ws:websocket_endpoint:169 - Exception occurred: \r\n```",
      "state": "closed",
      "author": "sagorbrur",
      "author_type": "User",
      "created_at": "2024-11-23T04:56:04Z",
      "updated_at": "2025-05-24T07:35:20Z",
      "closed_at": "2025-05-24T07:35:20Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1128/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1128",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1128",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:54.539325",
      "comments": []
    },
    {
      "issue_number": 1123,
      "title": "Intermittent Error When Interrupting Assistant in LiveKit with OpenAI Assistant",
      "body": "Hello,\r\n\r\nI have been working with the LiveKit project, using the integrated OpenAI Assistant, and I have encountered an intermittent problem that occurs when interrupting the assistant while it is responding. Despite having implemented several suggested solutions to properly handle task cancellation and avoid concurrent executions, the error still persists occasionally.\r\n\r\nProblem:\r\n\r\nWhen I interrupt the assistant by speaking while it is generating a response, sometimes an error occurs that prevents the assistant from responding to new inputs until I repeat my message. The error that appears in the logs is as follows:\r\n\r\n`openai.BadRequestError: Error code: 400 - {'error': {'message': 'Thread thread_xxx already has an active run run_xxx.', 'type': 'invalid_request_error', 'param': None, 'code': None}}`\r\n\r\nThis indicates that an attempt is being made to start a new run on a thread that already has an active run, which is not allowed by the OpenAI API.\r\n\r\nWhat I Have Tried to Solve the Problem:\r\n\r\n- Handling Task Cancellation: I implemented the aclose method in the AssistantLLMStream class to properly cancel the _create_stream_task when the assistant is interrupted.\r\n\r\n`async def aclose(self):`\r\n`    if not self._create_stream_task.done():`\r\n`        self._create_stream_task.cancel()`\r\n`        try:`\r\n`            await self._create_stream_task`\r\n`        except asyncio.CancelledError:`\r\n`            pass`\r\n\r\n- Exception Handling in _main_task: I modified the _main_task method to handle asyncio.CancelledError and properly close the OpenAI stream.\r\n\r\n`async def _main_task(self) -> None:`\r\n`    try:`\r\n`        # Existing code...`\r\n`        async with self._client.beta.threads.runs.stream(**kwargs) as stream:`\r\n`            try:`\r\n`                await stream.until_done()`\r\n`            except asyncio.CancelledError:`\r\n`                await stream.aclose()`\r\n`                raise`\r\n`        # Existing code...`\r\n`    except asyncio.CancelledError:`\r\n`        logger.debug(\"AssistantLLMStream _main_task was cancelled\")`\r\n`        pass`\r\n`    finally:`\r\n`        if not self._done_future.done():`\r\n`            self._done_future.set_result(None)`\r\n\r\n- Avoiding Concurrent Executions: I used an asyncio.Lock to ensure that new executions are not started while one is already active.\r\n\r\n`# In AssistantLLM.__init__()`\r\n`self._lock = asyncio.Lock()`\r\n\r\n`# When creating an instance of AssistantLLMStream`\r\n`return AssistantLLMStream(`\r\n`    # ...`\r\n`    lock=self._lock,`\r\n`)`\r\n\r\n`# In AssistantLLMStream._main_task()`\r\n`async with self._lock:`\r\n`    # Existing code...`\r\n\r\nDespite these modifications, the error still occurs intermittently. The assistant sometimes correctly handles the interruption and responds to the new input, but other times it does not, and the error appears in the logs.\r\n\r\nRelevant Logs:\r\n\r\nHere are excerpts from the logs showing the error:\r\n\r\n`2024-11-21 12:06:03,705 - DEBUG livekit.plugins.openai - AssistantLLMStream _main_task was cancelled`\r\n\r\n`openai.BadRequestError: Error code: 400 - {'error': {'message': 'Thread thread_xxx already has an active run run_xxx.', 'type': 'invalid_request_error', 'param': None, 'code': None}}`\r\n\r\nAdditional Information:\r\n\r\n- The error does not occur every time, suggesting that there may be a race condition or a case where the previous execution is not completely cancelled before starting a new one.\r\n\r\n- I have noticed that the problem occurs more frequently when the interruptions are very quick or consecutive.\r\n\r\n- The \"channel closed\" messages are now logged as DEBUG and do not seem to be directly related to this issue.\r\n\r\nI Request Help To:\r\n\r\n- Identify the root cause of this intermittent error.\r\n\r\n- Get suggestions on how to ensure that previous executions are completely cancelled before starting new ones.\r\n\r\n- Understand if there is any additional configuration or state management that should be implemented to avoid this conflict with the OpenAI API.\r\n\r\nAny guidance or code examples that you can provide would be greatly appreciated. Thank you in advance for your time and assistance!\r\n\r\nI appreciate any help you can provide to resolve this issue.",
      "state": "closed",
      "author": "JeisonNovoa",
      "author_type": "User",
      "created_at": "2024-11-21T18:33:16Z",
      "updated_at": "2025-05-24T07:35:20Z",
      "closed_at": "2025-05-24T07:35:20Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1123/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1123",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1123",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:54.539350",
      "comments": [
        {
          "author": "RenegadeMaster",
          "body": "I often receive this error as well",
          "created_at": "2024-11-23T20:05:31Z"
        }
      ]
    },
    {
      "issue_number": 2365,
      "title": "DUAL_CHANNEL_AGENT in RoomCompositeEgressRequest not work",
      "body": "I hope to store the voices of users and agents in different channels. Here is an example of my request:\n\n```python\nreq = api.RoomCompositeEgressRequest(\n        room_name=ctx.room.name,\n        audio_only=True,\n        audio_mixing=api.AudioMixing.DUAL_CHANNEL_AGENT,\n        file_outputs=[\n            api.EncodedFileOutput(\n                file_type=api.EncodedFileType.OGG,\n                filepath=audio_path,\n                s3=api.S3Upload(\n                    bucket=os.getenv(\"S3_BUCKET\"),\n                    region=os.getenv(\"S3_REGION\"),\n                    access_key=os.getenv(\"S3_ACCESS_KEY\"),\n                    secret=os.getenv(\"S3_SECRET_KEY\"),\n                ),\n            )\n        ],\n    )\n```\nThe final audio file was recorded, but the left and right channels were not distinguished. The voices of the user and the agent were still mixed together and could be heard in both channels. Is there something wrong with my usage method? How should I modify it?",
      "state": "closed",
      "author": "badbye",
      "author_type": "User",
      "created_at": "2025-05-22T11:41:34Z",
      "updated_at": "2025-05-24T04:55:52Z",
      "closed_at": "2025-05-24T04:55:51Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2365/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2365",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2365",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:54.809668",
      "comments": [
        {
          "author": "davidzhao",
          "body": "this feature has not been released yet.. it'll be available soon",
          "created_at": "2025-05-24T04:55:51Z"
        }
      ]
    },
    {
      "issue_number": 2370,
      "title": "Agents do not talk to each other in docker",
      "body": "Hello !\nI set up 2 agents which should talk to each other.\nWhile it works on my machine (macOS apple silicon)\nI can't make it work in Docker. They seem to properly join the room, but do not start the conversation.\n\n[Reproduction repo](https://github.com/CyprienRicqueB2L/lk-agents-repro)\n\n## Machine setup ✅ \n\n```bash\n./run.sh\n```\nIt creates the 2 agents and dispatch them to a room. They then start talking as expected.\n\n## Docker setup ❌ \n\n### In a single container \n```bash\ndocker compose up aio\n```\n\nIt runs the same `run.sh`. But the agents do not start the conversation\n\n### In different containers\n\n```bash\ndocker compose up a1 a2 dispatch\n```\nIt starts each in a different container, but again, they do not talk to each other.\n",
      "state": "closed",
      "author": "CyprienRicqueB2L",
      "author_type": "User",
      "created_at": "2025-05-22T16:58:47Z",
      "updated_at": "2025-05-24T04:55:32Z",
      "closed_at": "2025-05-24T04:55:31Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2370/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2370",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2370",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:55.107052",
      "comments": [
        {
          "author": "davidzhao",
          "body": "you'd have to set [this option](https://github.com/livekit-examples/python-agents-examples/blob/main/evaluating-agents/agent_evals.py#L64) to allow the agents to connect to another agent. by default they are waiting for human users",
          "created_at": "2025-05-24T04:55:31Z"
        }
      ]
    },
    {
      "issue_number": 2383,
      "title": "OpenAI Realtime Model Function Tools Compatibility Issue",
      "body": "# Bug Report: OpenAI Realtime Model Function Tools Compatibility Issue\n\n## Description\n\nWhen using `openai.realtime.RealtimeModel()` with function tools in LiveKit Agents, function tools execute successfully but cause a runtime error that prevents the agent from continuing the conversation after tool execution.\n\n## Error Details\n\nThe error occurs in `agent_activity.py` at line 1421:\n\n```python\nTraceback (most recent call last):\n  File \"/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n  File \"/livekit/agents/voice/agent_activity.py\", line 1421, in *realtime*generation_task\n    if generate_tool_reply and not isinstance(self.llm, GoogleRealtimeModel):\n```\n\nThe issue appears to be that the code only checks for `GoogleRealtimeModel` but doesn't account for `openai.realtime.RealtimeModel`, suggesting incomplete compatibility implementation.\n\n## Expected Behavior\n\n- Function tool executes successfully (✅ works)\n- Agent continues conversation after tool execution (❌ fails)\n- No runtime errors should occur\n\n## Actual Behavior\n\n- Function tool executes successfully ✅ (confirmed: API endpoint gets called)\n- Agent stops responding after tool execution ❌ \n- Runtime error occurs in agent_activity.py line 1421\n\n## Environment\n\n- **LiveKit Agents version:** 1.0.11\n- **LiveKit OpenAI Plugin version:** 1.0.11\n- **Python version:** 3.13.3\n- **Operating System:** macOS Sequoia 15.5\n\n## Minimal Reproduction Example\n\n```python\nfrom dotenv import load_dotenv\nimport aiohttp\nimport logging\nfrom typing import Any\n\nfrom livekit import agents\nfrom livekit.agents import AgentSession, Agent, RoomInputOptions, function_tool, RunContext\nfrom livekit.plugins import (\n    openai,\n    noise_cancellation,\n)\n\nload_dotenv()\n\nlogger = logging.getLogger(\"booking-agent\")\n\n\nclass Assistant(Agent):\n    def __init__(self) -> None:\n        super().__init__(instructions=\"You are a helpful voice AI assistant. After booking a slot, be sure to confirm the booking details to the user.\")\n        \n    @function_tool()\n    async def book_slot(\n        self,\n        context: RunContext,\n        name: str,\n        date: str,\n    ) -> dict[str, Any]:\n        \"\"\"Book a slot for the user.\n        \n        Args:\n            name: The name of the user booking the slot.\n            date: The date for the booking in format YYYY-MM-DD.\n        \n        \"\"\"\n        \n        async with aiohttp.ClientSession() as session:\n            async with session.post(\n                \"http://127.0.0.1:3000/api/book-slot\",\n                json={\"name\": name, \"date\": date}\n            ) as response:\n                if response.status == 200:\n                    data = await response.json()\n                    logger.info(f\"{data}\")\n                    return f\"Great! I've booked an appointment for {name} on {date}. Your booking has been confirmed.\"\n                else:\n                    return f\"I'm sorry, there was an error booking your appointment. Please try again later.\"\n\n\nasync def entrypoint(ctx: agents.JobContext):\n    await ctx.connect()\n\n    session = AgentSession(\n       llm=openai.realtime.RealtimeModel(),\n    )\n\n    await session.start(\n        room=ctx.room,\n        agent=Assistant(),\n        room_input_options=RoomInputOptions(\n            noise_cancellation=noise_cancellation.BVC(),\n        ),\n    )\n\n    await session.generate_reply(instructions=\"Greet the user and tell you are here to offer your assistance. Let them know you can help book appointment slots.\")\n\n\nif __name__ == \"__main__\":\n    agents.cli.run_app(agents.WorkerOptions(entrypoint_fnc=entrypoint))\n```\n\n## Steps to Reproduce\n\n1. Set up the minimal example above\n2. Run the agent\n3. Connect to the room and ask the agent to book a slot (e.g., \"Book a slot for Jane Doe on 2025-05-21\")\n4. Observe that:\n   - The API endpoint `http://127.0.0.1:3000/api/book-slot` gets called successfully\n   - The agent stops responding afterward and doesn't continue the conversation\n5. Check logs for the error in agent_activity.py line 1421\n\n## Root Cause Analysis\n\nThe error suggests that the code in `agent_activity.py` line 1421 only handles `GoogleRealtimeModel` for the `generate_tool_reply` condition, but doesn't include `openai.realtime.RealtimeModel` in the compatibility check:\n\n```python\nif generate_tool_reply and not isinstance(self.llm, GoogleRealtimeModel):\n```\n\nThis condition should likely be updated to handle both Google and OpenAI realtime models, or use a more generic interface check.\n\n## Related Issues\n\n- This appears to be related to incomplete realtime model function tool support\n- The LiveKit documentation shows examples of function tools working with realtime models, suggesting this should be supported\n\n---\n\n**API Endpoint Used for Testing:**\n```bash\ncurl --request POST \\\n  --url http://127.0.0.1:3000/api/book-slot \\\n  --header 'content-type: application/json' \\\n  --data '{\n  \"name\":\"Jane Doe\",\n  \"date\":\"2025-05-21\"\n}'\n```\n\n**Confirmed Behavior:**\n- ✅ The function tool executes and calls the API endpoint successfully\n- ❌ Agent becomes unresponsive after tool execution and doesn't continue conversation\n- ❌ Error occurs in agent_activity.py at the specific line checking for GoogleRealtimeModel",
      "state": "open",
      "author": "Anishpras",
      "author_type": "User",
      "created_at": "2025-05-23T14:21:39Z",
      "updated_at": "2025-05-24T02:37:37Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2383/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2383",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2383",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:55.358053",
      "comments": [
        {
          "author": "schedawg74",
          "body": "Same here. Has this ever worked on agents v1? I thought so but might need to up my testing.",
          "created_at": "2025-05-23T14:50:23Z"
        },
        {
          "author": "longcw",
          "body": "Which version of agent are you using, can you try it with the latest version? This line ` if generate_tool_reply and not isinstance(self.llm, GoogleRealtimeModel):`  was from an old version and should be fixed now.",
          "created_at": "2025-05-24T02:37:36Z"
        }
      ]
    },
    {
      "issue_number": 2166,
      "title": "Memory leak within docker container and local machines",
      "body": "[issue](https://github.com/livekit/livekit/issues/3614)\nI'm not sure if this is a bug, but it seems there is not only one person encountering memory leak issue.\nThe link above is the related post containing the problem description and lib version.\n\nHere is what i found while debugging:\nI have been debugging this for several days, and i found this issue seems to be related to livekit ffi lib. I see when a user try connecting to a livekit room, the requests below will be sent to ffi lib sequentially:\n\nconnect -> create_audio_track -> publish_track -> set_subscribed -> new_audio_stream -> ...\n\nand i found the memory leak **seems**(i'm not sure) to happen after **set_subscribed**.\n\nI hope the information above can help locate and resolving this problem, or i have to restart my agent server every several hours  😭\n\n**Updated**: the memory leak also happens on my local machine (M1 MacOS 15.3.2) on different python versions(3.11.7 / 3.12.6 / 3.13.2), and this [repo](https://github.com/theo1893/livekit-memory-leak-demo) contains the dependencies and reproducing steps in details",
      "state": "open",
      "author": "theo1893",
      "author_type": "User",
      "created_at": "2025-04-30T12:38:38Z",
      "updated_at": "2025-05-23T22:21:40Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 23,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2166/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2166",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2166",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:55.557747",
      "comments": []
    },
    {
      "issue_number": 2385,
      "title": "manual toggle synchronized transcription forwarding",
      "body": "hi\n\nit is great to have the \"synchronized transcription forwarding\", but sometimes super intelligent user just want to see the transcription asap while still listening generated voice.\n\ncould there be a toggle that i can switch it on and off by hand?",
      "state": "closed",
      "author": "DeoLeung",
      "author_type": "User",
      "created_at": "2025-05-23T15:54:50Z",
      "updated_at": "2025-05-23T17:00:47Z",
      "closed_at": "2025-05-23T16:04:11Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2385/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2385",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2385",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:55.557790",
      "comments": [
        {
          "author": "longcw",
          "body": "you can disable it with `sync_transcription=False` in room input option https://github.com/livekit/agents/blob/main/livekit-agents/livekit/agents/voice/room_io/room_io.py#L89",
          "created_at": "2025-05-23T16:04:11Z"
        },
        {
          "author": "DeoLeung",
          "body": "got it, chasing the code I think i could toggle it using rpc to set it, will see if it works :)\n\n```python\n@ctx.room.local_participant.register_rpc_method('enable_sync_transcription')\nasync def enable_sync_transcription(data: RpcInvocationData):\n  session._room_io._output_options.sync_transcription ",
          "created_at": "2025-05-23T16:19:08Z"
        },
        {
          "author": "longcw",
          "body": "emm you cannot toggle this option on the fly. If you really want to, use the `set_enabled` method of transcription synchronizer https://github.com/livekit/agents/blob/main/livekit-agents/livekit/agents/voice/transcription/synchronizer.py#L419C9-L419C20, like `room_io._tr_synchronizer.set_enabled(Fal",
          "created_at": "2025-05-23T17:00:45Z"
        }
      ]
    },
    {
      "issue_number": 2387,
      "title": "Minor issue with GOOGLE_APPLICATION_CREDENTIALS and project_id",
      "body": "The comment in the code [mentions](https://github.com/livekit/agents/blob/9d8e9a3e2de777b73a2ca190f07abf17cce295d5/livekit-plugins/livekit-plugins-google/livekit/plugins/google/beta/realtime/realtime_api.py#L145) project is inferred from key file, but it still [checks](https://github.com/livekit/agents/blob/9d8e9a3e2de777b73a2ca190f07abf17cce295d5/livekit-plugins/livekit-plugins-google/livekit/plugins/google/beta/realtime/realtime_api.py#L211) for the project regardless of the GOOGLE_APPLICATION_CREDENTIALS status. There are many ways to deal with this:\n\n1. change the comment;\n2. check for GOOGLE_APPLICATION_CREDENTIALS and project_id first;\n3. skip checking project_id if GOOGLE_APPLICATION_CREDENTIALS is present;\n\nWhat do you think?",
      "state": "open",
      "author": "ChenghaoMou",
      "author_type": "User",
      "created_at": "2025-05-23T16:01:50Z",
      "updated_at": "2025-05-23T16:01:50Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2387/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2387",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2387",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:55.764161",
      "comments": []
    },
    {
      "issue_number": 1979,
      "title": "LLM/TTS transcription",
      "body": "In v1, the examples show how to get the user transcription from the session using ```@session.on(\"user_input_transcribed\")```. How can I get the agent transcription from LLM or TTS?",
      "state": "closed",
      "author": "christiancuri",
      "author_type": "User",
      "created_at": "2025-04-12T06:47:18Z",
      "updated_at": "2025-05-23T14:19:21Z",
      "closed_at": "2025-05-11T06:11:33Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 11,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1979/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1979",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1979",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:55.764246",
      "comments": [
        {
          "author": "yuyuma",
          "body": "If I may add to this question, is there any way to obtain the agent transcription server-side that takes into account of any potential interruptions?",
          "created_at": "2025-04-12T16:14:15Z"
        },
        {
          "author": "christiancuri",
          "body": "As workaround I implemented using ```@session.on(\"conversation_item_added\")```  to get agent transcription",
          "created_at": "2025-04-12T21:31:37Z"
        },
        {
          "author": "longcw",
          "body": "Yes, you can listen to `conversation_item_added` to obtain both user and agent transcriptions, this event is emitted when the conversation item added to the chat ctx.\n\n",
          "created_at": "2025-04-13T02:19:46Z"
        },
        {
          "author": "crfgxr",
          "body": "Is there any example how to get user and agent transcriptions with realtime api? I could not find.",
          "created_at": "2025-04-13T18:43:39Z"
        },
        {
          "author": "longcw",
          "body": "@crfgxr It's the same for realtime api, you can listen to the `user_input_transcribed` for user transcription and `conversation_item_added` for agent transcription. You can find all the events from the agent session and their types in https://github.com/livekit/agents/blob/main/livekit-agents/liveki",
          "created_at": "2025-04-14T01:27:06Z"
        }
      ]
    },
    {
      "issue_number": 2346,
      "title": "Elevenlabs issue livekit v1",
      "body": "<!--\nHello! Thanks for taking the time to file a bug report.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already reported this issue.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n-->\n\nBug description: run the agent in a dockerized environment when the TTS service starts speaking it pronounces the words letter by letter especially in any language other than English. \n\nDocker version:  28.0.4\nPython version: python:3.12-slim\nLivekit version: latest\n\nElevenlabs configuration:  \n             model=\"eleven_multilingual_v2\",\n             voice_id=\"nPczCjzI2devNBz1zQrb\",\n             voice_settings=elevenlabs.VoiceSettings(\n             stability=0.5,\n             similarity_boost=0.64,\n             style=0.0,\n              speed=1.0,\n              use_speaker_boost=False,\n             ),",
      "state": "closed",
      "author": "youssefwalid7",
      "author_type": "User",
      "created_at": "2025-05-21T08:27:21Z",
      "updated_at": "2025-05-23T10:57:20Z",
      "closed_at": "2025-05-23T10:57:20Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 10,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2346/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2346",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2346",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:57.770434",
      "comments": [
        {
          "author": "longcw",
          "body": "can you share a audio recording with the issue? I cannot reproduce the issue with your settings using the [basic agent example](https://github.com/livekit/agents/blob/main/examples/voice_agents/basic_agent.py)\n```\n        tts=elevenlabs.TTS(\n            model=\"eleven_multilingual_v2\",\n            vo",
          "created_at": "2025-05-21T12:41:37Z"
        },
        {
          "author": "yepher",
          "body": "These are the sample audio files from OP\n\n[sample_audio.zip](https://github.com/user-attachments/files/20369190/sample_audio.zip)",
          "created_at": "2025-05-21T13:43:22Z"
        },
        {
          "author": "longcw",
          "body": "do you have the transcription of those audios?",
          "created_at": "2025-05-21T14:07:03Z"
        },
        {
          "author": "rashad-leapai",
          "body": "I am facing the same issue for Arabic language.\n\n`tts=elevenlabs.TTS(\n            model=\"eleven_multilingual_v2\",\n            voice_id=\"nPczCjzI2devNBz1zQrb\",\n            voice_settings=elevenlabs.VoiceSettings(\n                stability=0.5, similarity_boost=0.64, style=0.0, speed=1.0, use_speaker_",
          "created_at": "2025-05-22T11:02:11Z"
        },
        {
          "author": "rashad-leapai",
          "body": "I had an agent that use elevenlabs TTS, streaming was working for non-English. but since last update of livekit.plugins.elevenlabs the streaming broken, it only work for English now.\n\nCan someone confirm whether updates raised this issue, whether its from livekit or elevenlabs side?",
          "created_at": "2025-05-22T11:28:16Z"
        }
      ]
    },
    {
      "issue_number": 2364,
      "title": "user_state_changed event not triggered, only agent_state_changed works",
      "body": "I'm trying to handle state change events for both the agent and the user. While **agent_state_changed** is triggered as expected, the **user_state_changed** event is never fired.\n\nHere’s the code I'm using:\n\n```\nasync def entrypoint(ctx: JobContext):\n    try:\n        await ctx.connect()\n        # other code here \n        @session.on(\"agent_state_changed\")\n        def on_agent_state_changed(event):\n            print(f\"Agent state changed from {event.old_state} to {event.new_state}\")\n\n        @session.on(\"user_state_changed\")\n        def on_user_state_changed(event):\n            print(f\"User state changed from {event.old_state} to {event.new_state}\")\n```\nIn testing, only **agent_state_changed** gets triggered. The **user_state_changed** handler doesn't run at all, even though I'm expecting the user state to change.\n\n**Questions**:\n\n1/ Is this a bug?\n2/ Are there specific conditions for user_state_changed to be emitted?\n3/ Do I need to trigger the user_state_changed event manually from the client side?\n4/ If yes, what is the proper way to emit it?\n\nThanks in advance for your help!",
      "state": "closed",
      "author": "quanhavn",
      "author_type": "User",
      "created_at": "2025-05-22T10:36:27Z",
      "updated_at": "2025-05-23T01:59:50Z",
      "closed_at": "2025-05-23T01:59:48Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2364/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2364",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2364",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:58.022951",
      "comments": [
        {
          "author": "longcw",
          "body": "are you using the pipeline model or realtime model? This event is not emitted when using gemini or the pipeline model without VAD enabled.\n\nIf it's gemini, you can still enable the VAD in agent session to emit the `user_state_changed` event.",
          "created_at": "2025-05-22T15:15:50Z"
        },
        {
          "author": "quanhavn",
          "body": "@longcw  Thanks! It was due to using the pipeline model without VAD enabled — all good now.",
          "created_at": "2025-05-23T01:59:48Z"
        }
      ]
    },
    {
      "issue_number": 2216,
      "title": "Agent transcription missing in conversation_item_added",
      "body": "Hello livekit community,\n\nI'm trying to capture transcriptions of a user outbound/inbound call through telephony integration. When I hook on to the `conversation_item_added` event, I seem to only get the user content transcribed. When the assistant event is emitted, the content is empty. Right now I have a workaround intercepting the agent text in the `transcription_node` and then parsing these two streams back together but that is clunky and produces not so ideal transcripts, as sometimes the agent doesn't say what goes in the transcription_node pipeline as per my observation.\n\nexample:\nuser conversation item:\n`type='conversation_item_added' item=ChatMessage(id='item_aa077ed2b7bf', type='message', role='user', content=['Third prompt, please.'], interrupted=False, hash=None)`\nagent conversation item:\n`type='conversation_item_added' item=ChatMessage(id='item_291b8e0c549f', type='message', role='assistant', content=[''], interrupted=False, hash=None) `\n\nI am on a call with the agent as this is happening and they speak properly, so there's no issue there. There are no interruptions neither as a bug reported 2 weeks ago by one of your devs, where if interrupted sometime the content would not be registered. Also, in the transcripts I make using the transcription node, agent speech gets captured. Am I doing something wrong? I'm running 1.0.19 version of plugins and 1.0.6 of livekit.\n\nAny help would be appreciated.",
      "state": "open",
      "author": "4b1dden",
      "author_type": "User",
      "created_at": "2025-05-06T10:56:26Z",
      "updated_at": "2025-05-23T00:25:01Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 11,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2216/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2216",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2216",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:58.263643",
      "comments": [
        {
          "author": "4b1dden",
          "body": "I also get this warning beforehand, not sure if that's any relevant. \n\n```\n2025-05-06 12:53:16,320 - WARNING livekit.agents - _SegmentSynchronizerImpl.playback_finished called before text/audio input is done {\"pid\": 34776, \"job_id\": \"AJ_pG2PwtAGWnqE\"}\nconversation item added\ntype='conversation_item_",
          "created_at": "2025-05-06T10:57:30Z"
        },
        {
          "author": "davidzhao",
          "body": "what models are you using? can you share your agent init code?",
          "created_at": "2025-05-06T17:06:19Z"
        },
        {
          "author": "4b1dden",
          "body": "Sure, here are session & agent init snippets inside entrypoint\n```\n# getting user cell number, lookup client info in db\n# preparing userdata object\n...\nsession = AgentSession[UserData](\n        userdata=userdata,\n        turn_detection=\"vad\",\n        vad=silero.VAD.load(),\n        stt=deepgram.STT()",
          "created_at": "2025-05-07T09:53:42Z"
        },
        {
          "author": "longcw",
          "body": "`conversation_added_event` works on my end with this example https://github.com/livekit/agents/blob/main/examples/voice_agents/basic_agent.py, can you try that one or share a min example that can reproduce this issue?",
          "created_at": "2025-05-07T14:27:44Z"
        },
        {
          "author": "ChenghaoMou",
          "body": "I remember a PR not long ago, the content would be empty if the audio is not played. And the warning \"_SegmentSynchronizerImpl.playback_finished called before text/audio input is done\" seems to indicate 1) the played time might be zero and 2) thus empty text as one possible explanation.",
          "created_at": "2025-05-07T16:04:32Z"
        }
      ]
    },
    {
      "issue_number": 2371,
      "title": "No function call for gemini realtime model \"gemini-2.5-flash-preview-native-audio-dialog\"",
      "body": "Hey, with the new gemini \"gemini-2.5-flash-preview-native-audio-dialog\" my agent doesn't call function tools anymore. With openai realtime and pipeline agents this works just fine. \n\nSo e.g. \n```\n    @function_tool\n    async def end_call(self, context: RunContext[CallRuntime]) -> str:\n```\n\nI'm using the latest versions:\n```\nlivekit-agents==1.0.22\nlivekit-plugins-google==1.0.22\n```\n\nThere are no warning or error logs, so not sure why this isn't working. ",
      "state": "closed",
      "author": "schedawg74",
      "author_type": "User",
      "created_at": "2025-05-22T18:41:11Z",
      "updated_at": "2025-05-22T18:48:41Z",
      "closed_at": "2025-05-22T18:48:41Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2371/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2371",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2371",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:58.502946",
      "comments": []
    },
    {
      "issue_number": 2224,
      "title": "Invalid Response Status from Deepgram TTS API",
      "body": "```\nPython 3.12\nlivekit-agents==1.0.19\nlivekit-plugins-deepgram==1.0.19\nlivekit-plugins-openai==1.0.19\nlivekit-plugins-silero==1.0.19\n```\n\nIf I run [basic_agent.py in the examples](https://github.com/livekit/agents/blob/main/examples/voice_agents/basic_agent.py), but use deepgram TTS as follows:\n\n```\n    session = AgentSession(\n        vad=ctx.proc.userdata[\"vad\"],\n        # any combination of STT, LLM, TTS, or realtime API can be used\n        llm=openai.LLM(model=\"gpt-4o-mini\"),\n        stt=deepgram.STT(model=\"nova-3\", language=\"multi\"),\n        tts=deepgram.tts.TTS(\n            model=\"aura-austeria-en\",\n        ),\n        # use LiveKit's turn detection model\n        # turn_detection=MultilingualModel(),\n    )\n```\n\nI get the following error. I am using a Deepgram API key that worked prior (and also tried a new one for good measure) with no success:\n\n```\nFile \"/demo-app/backend/voice_agent/src/.venv-va/lib/python3.12/site-packages/livekit/plugins/deepgram/tts.py\", line 391, in _run\nws = await asyncio.wait_for(\n^^^^^^^^^^^^^^^^^^^^^^^\nFile \"/Users/blah/.pyenv/versions/3.12.8/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\nreturn await fut\n^^^^^^^^^\nFile \"/demo-app/backend/voice_agent/src/.venv-va/lib/python3.12/site-packages/aiohttp/client.py\", line 1021, in _ws_connect\nraise WSServerHandshakeError(\naiohttp.client_exceptions.WSServerHandshakeError: 400, message='Invalid response status', url='wss://api.deepgram.com/v1/speak?encoding=linear16&model=aura-austeria-en&sample_rate=24000&mip_opt_out=False'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\nFile \"/demo-app/backend/voice_agent/src/.venv-va/lib/python3.12/site-packages/livekit/agents/tts/tts.py\", line 301, in _main_task\nreturn await self._run()\n^^^^^^^^^^^^^^^^^\nFile \"/demo-app/backend/voice_agent/src/.venv-va/lib/python3.12/site-packages/livekit/plugins/deepgram/tts.py\", line 428, in _run\nraise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: Invalid response status (status_code=400, request_id=4781a97370a6, body=None)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\nFile \"/demo-app/backend/voice_agent/src/.venv-va/lib/python3.12/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\nreturn await fn(*args, **kwargs)\n^^^^^^^^^^^^^^^^^^^^^^^^^\nFile \"/demo-app/backend/voice_agent/src/.venv-va/lib/python3.12/site-packages/livekit/agents/voice/generation.py\", line 146, in _inference_task\nasync for audio_frame in tts_node:\nFile \"/demo-app/backend/voice_agent/src/.venv-va/lib/python3.12/site-packages/livekit/agents/voice/agent.py\", line 473, in tts_node\nasync for ev in stream:\nFile \"/demo-app/backend/voice_agent/src/.venv-va/lib/python3.12/site-packages/livekit/agents/tts/tts.py\", line 448, in anext\nraise exc # noqa: B904\n^^^^^^^^^\nFile \"/demo-app/backend/voice_agent/src/.venv-va/lib/python3.12/site-packages/livekit/agents/tts/tts.py\", line 309, in _main_task\nraise APIConnectionError(\nlivekit.agents._exceptions.APIConnectionError: failed to synthesize speech after 4 attempts\n```",
      "state": "closed",
      "author": "chow-vincent",
      "author_type": "User",
      "created_at": "2025-05-07T21:47:15Z",
      "updated_at": "2025-05-22T15:51:43Z",
      "closed_at": "2025-05-13T00:42:49Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2224/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2224",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2224",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:58.502987",
      "comments": [
        {
          "author": "giuliog97",
          "body": "Did you try with the following?\n\n```\nsession = AgentSession(\n\tvad=ctx.proc.userdata[\"vad\"],\n\t# any combination of STT, LLM, TTS, or realtime API can be used\n\tllm=openai.LLM(model=\"gpt-4o-mini\"),\n\tstt=deepgram.STT(model=\"nova-3\", language=\"multi\"),\n\ttts=deepgram.TTS(\n\t\tmodel=\"aura-asteria-en\",\n\t),\n\t#",
          "created_at": "2025-05-08T13:02:13Z"
        },
        {
          "author": "chow-vincent",
          "body": "Just tried with `deepgram.TTS(` instead of `deepgram.tts.TTS(` but experienced the same issue.",
          "created_at": "2025-05-09T18:26:14Z"
        },
        {
          "author": "jmcclanahan13",
          "body": "Upgrade to 1.0.20 this was fixed I believe",
          "created_at": "2025-05-09T21:59:44Z"
        },
        {
          "author": "davidzhao",
          "body": "I'm unable to reproduce this in the latest release either. please let us know if you are still experiencing it (and let us know your repro steps)",
          "created_at": "2025-05-13T00:42:50Z"
        },
        {
          "author": "chow-vincent",
          "body": "@davidzhao @jmcclanahan13 \nI just reproduced the error with the following requirements.txt, running Python 3.12:\n\n```\n# Core dependencies\nboto3==1.38.18\nlivekit==1.0.8\nlivekit-agents==1.0.22\nlivekit-plugins-cartesia==1.0.22\nlivekit-plugins-deepgram==1.0.22\nlivekit-plugins-openai==1.0.22\nlivekit-plug",
          "created_at": "2025-05-19T23:29:25Z"
        }
      ]
    },
    {
      "issue_number": 2368,
      "title": "Agent not able to hear after first answer when turning allow_interruptions to False",
      "body": "<!--\nHello! Thanks for taking the time to file a bug report.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already reported this issue.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n-->\n\nHi, I just tried to disable interruptions for my agent, here's the config : \n\n\n`agent_session = AgentSession[UserData](\n        allow_interruptions=False,\n        userdata=UserData(),\n        vad=silero.VAD.load(),\n        # stt=deepgram.STT(model=\"nova-2\", language=\"fr-FR\"),\n        stt=stt,\n        llm=openai.LLM(model=\"gpt-4o\"),\n        # tts=cartesia.TTS(language='fr', voice=CARTESIA_MALE),\n        tts=elevenlabs.TTS(\n            voice_id=voice_id,\n            model=\"eleven_multilingual_v2\",\n            voice_settings=elevenlabs.VoiceSettings(stability=1, speed=1.11, similarity_boost=1)\n        ),\n        min_endpointing_delay=1,\n        turn_detection=MultilingualModel(),\n    )`\n\n- The agent start the conversation as expected, ask me a question, I answer, he keeps the conversation with another question and then : he's unable to hear anything\n- It works perfectly when turning it back to True",
      "state": "open",
      "author": "HugoPOIDVIN",
      "author_type": "User",
      "created_at": "2025-05-22T14:58:35Z",
      "updated_at": "2025-05-22T15:38:26Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2368/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2368",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2368",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:58.776012",
      "comments": [
        {
          "author": "HugoPOIDVIN",
          "body": "## LiveKit Package Versions\n\nUsing the following versions of LiveKit:\n\n| Package Name                          | Version |\n|---------------------------------------|---------|\n| `livekit`                             | 1.0.7   |\n| `livekit-agents`                      | 1.0.21  |\n| `livekit-api`      ",
          "created_at": "2025-05-22T15:02:37Z"
        },
        {
          "author": "longcw",
          "body": "I cannot reproduce it with the [basic agent example](https://github.com/livekit/agents/blob/main/examples/voice_agents/basic_agent.py) by setting the `allow_interruptions=False` in AgentSession. Can you share an example that can reproduce the issue?",
          "created_at": "2025-05-22T15:10:50Z"
        },
        {
          "author": "HugoPOIDVIN",
          "body": "yes, by example do you mean our agent code or an audio file when it happens ?",
          "created_at": "2025-05-22T15:17:15Z"
        },
        {
          "author": "longcw",
          "body": "> yes, by example do you mean our agent code or an audio file when it happens ?\n\nThe agent code.",
          "created_at": "2025-05-22T15:18:16Z"
        },
        {
          "author": "HugoPOIDVIN",
          "body": "Here is the agent initialization : \n\n```\nclass APVAgent(Agent):\n    def __init__(\n        self,\n        job_context: JobContext,\n        source: Literal[\"demo\", \"phone_call\"],\n        user_phone_number: str | None,\n        agent: AgentConf,\n    ) -> None:\n        self.job_context = job_context\n     ",
          "created_at": "2025-05-22T15:34:35Z"
        }
      ]
    },
    {
      "issue_number": 1118,
      "title": "Ability to pause/resume agent interaction in channel for multimodal_agent",
      "body": "See PR: #1119 - https://github.com/livekit/agents/pull/1119\r\n\r\nIn my application case, I need to have the ability to \"pause\" the Multimodal agent so I can speak to participants in the channel without the LLM interrupting me. I also need to be able to resume the LLM interaction.\r\n\r\nIn addition to pausing the resume, I also need to be able to set the source participant the agent should be actively listening to. In my app there are multiple participants in the room.\r\n\r\nLocally I am doing this and it seems to work:\r\nupdate [multimodal_agent.py](https://github.com/livekit/agents/blob/main/livekit-agents/livekit/agents/multimodal/multimodal_agent.py#L328)\r\n\r\n```\r\n    def set_source_participant(self, participant_identity: str) -> None:\r\n        \"\"\"Set the source participant for the agent.\"\"\"\r\n        self._link_participant(participant_identity)\r\n\r\n    def pause_listening(self) -> None:\r\n        \"\"\"Pause listening to the audio stream.\"\"\"\r\n        if self._read_micro_atask is not None:\r\n            self._read_micro_atask.cancel()  # Stop the current task\r\n            self._read_micro_atask = None\r\n            logger.info(\"Paused listening to the audio stream.\")\r\n\r\n    def resume_listening(self) -> None:\r\n        \"\"\"Resume listening to the audio stream.\"\"\"\r\n        if self._subscribed_track is not None and self._read_micro_atask is None:\r\n            self._read_micro_atask = asyncio.create_task(\r\n                self._micro_task(self._subscribed_track)  # Restart the task\r\n            )\r\n            logger.info(\"Resumed listening to the audio stream.\")\r\n\r\n```",
      "state": "closed",
      "author": "yepher",
      "author_type": "User",
      "created_at": "2024-11-21T02:22:40Z",
      "updated_at": "2025-05-22T07:35:14Z",
      "closed_at": "2025-05-22T07:35:14Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1118/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1118",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1118",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:59.038448",
      "comments": []
    },
    {
      "issue_number": 1124,
      "title": "Participant is not unlinked during disconnection, so human input is out of sync",
      "body": "When a participant disconnects from an active agent the human input stays connected with the old participant, and so when a participant reconnects, the transcription and sst, vad and transcript forwarder are not connected.\r\n\r\nThe fix is to add a method to unlink_participant which requires moving a number of nested methods to class level for unlink:\r\n\r\n```\r\n    def _unlink_participant(self) -> None:\r\n        \"\"\"Clean up participant-related resources\"\"\"\r\n        if self._human_input is None:\r\n            return\r\n\r\n        # Remove all event listeners using class methods\r\n        self._human_input.off(\"start_of_speech\", self._on_start_of_speech)\r\n        self._human_input.off(\"vad_inference_done\", self._on_vad_inference_done)\r\n        self._human_input.off(\"end_of_speech\", self._on_end_of_speech)\r\n        self._human_input.off(\"interim_transcript\", self._on_interim_transcript)\r\n        self._human_input.off(\"final_transcript\", self._on_final_transcript)\r\n        self._human_input = None\r\n```\r\n\r\nSteps to reproduce\r\n\r\n1. Start room with participant\r\n2. Have agent join\r\n3. Leave room but have agent stay connected\r\n4. Rejoin room\r\n5. Have candidate speak and notice that transcription is not being forwarded.",
      "state": "closed",
      "author": "brightsparc",
      "author_type": "User",
      "created_at": "2024-11-22T02:25:06Z",
      "updated_at": "2025-05-22T07:35:13Z",
      "closed_at": "2025-05-22T07:35:13Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1124/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1124",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1124",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:59.038473",
      "comments": []
    },
    {
      "issue_number": 1217,
      "title": "Gemini real-time",
      "body": "Any plans for implementing Gemini real-time API to Agents? ",
      "state": "closed",
      "author": "Shandelier",
      "author_type": "User",
      "created_at": "2024-12-12T11:59:41Z",
      "updated_at": "2025-05-22T07:10:17Z",
      "closed_at": "2025-05-22T07:10:17Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 21,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1217/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1217",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1217",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:59.038482",
      "comments": []
    },
    {
      "issue_number": 1145,
      "title": "[MultimodalAgent] tool_choice=required results in endless loop when using openai.realtime.RealtimeModel",
      "body": "# Reproduction steps\r\nTo reproduce this behaviour, use the [multimodal_agent example ](https://github.com/livekit/agents/blob/main/examples/multimodal_agent.py#L86) and add the parameter `tool_choice=\"required\"`\r\n\r\n```python\r\n#... omitted for brevity\r\n    agent = multimodal.MultimodalAgent(\r\n        model=openai.realtime.RealtimeModel(\r\n            voice=\"alloy\",\r\n            tool_choice=\"required\", # This is the only changed line from the example multimodel agent.\r\n            temperature=0.8,\r\n            instructions=\"You are a helpful assistant\",\r\n            turn_detection=openai.realtime.ServerVadOptions(\r\n                threshold=0.6, prefix_padding_ms=200, silence_duration_ms=500\r\n            ),\r\n        ),\r\n        fnc_ctx=fnc_ctx,\r\n        chat_ctx=chat_ctx,\r\n    )\r\n#... omitted for brevity\r\n```\r\n\r\n# Expected behaviour:\r\n- Would restrict the chat to only the tools, and respond accordingly. (In the demo scenario I would expect it only to allow asking about the weather)\r\n\r\n\r\n# Actual behaviour:\r\n- Endless loop, even if a tool is matched for the chat message, with no reply to the user.\r\n\r\nLogs:\r\n```bash\r\n2024-11-28 15:24:45,939 - DEBUG asyncio - Using selector: KqueueSelector \r\n2024-11-28 15:24:46,265 - DEBUG asyncio - Using selector: KqueueSelector \r\n2024-11-28 15:24:46,267 - INFO livekit.agents - starting worker {\"version\": \"0.11.3\", \"rtc-version\": \"0.17.6\"}\r\n2024-11-28 15:24:46,381 - INFO livekit.agents - registered worker {\"id\": \"AW_kLEywugKmEG5\", \"region\": \"Australia\", \"protocol\": 15, \"node_id\": \"NC_DSYD1A_TBTtRTfcdqWM\"}\r\n2024-11-28 15:25:01,079 - INFO livekit.agents - received job request {\"job_id\": \"AJ_G9uLNncY5cYh\", \"dispatch_id\": \"\", \"room_name\": \"ta-englishhotelbooking-user-12b65030-6a8f-4487-979b-c8e869b8bae3\", \"agent_name\": \"\", \"resuming\": false}\r\n2024-11-28 15:25:01,569 - DEBUG asyncio - Using selector: KqueueSelector {\"pid\": 12183}\r\n2024-11-28 15:25:01,569 - INFO livekit.agents - initializing process {\"pid\": 12183}\r\n2024-11-28 15:25:01,569 - INFO livekit.agents - process initialized {\"pid\": 12183}\r\n2024-11-28 15:25:01,570 - INFO my-worker - starting entrypoint {\"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:01,976 - DEBUG livekit.agents - http_session(): creating a new httpclient ctx {\"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:01,980 - DEBUG livekit.plugins.openai.realtime - sync chat context {\"to_delete\": [], \"to_add\": [[null, \"item_1d0b4513cae5\"], [\"item_1d0b4513cae5\", \"item_33b6b9e44e17\"], [\"item_33b6b9e44e17\", \"item_43b704505e13\"], [\"item_43b704505e13\", \"item_9234a3ed5a53\"]], \"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:01,980 - DEBUG livekit.plugins.openai.realtime - added empty audio message to the chat context {\"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:03,127 - DEBUG livekit.plugins.openai.realtime - conversation item created {\"type\": \"conversation.item.created\", \"event_id\": \"event_AYQNLcaxuuxnAL92NSHP8\", \"previous_item_id\": null, \"item\": {\"id\": \"item_1d0b4513cae5\", \"object\": \"realtime.item\", \"type\": \"message\", \"status\": \"completed\", \"role\": \"user\", \"content\": [{\"type\": \"input_text\", \"text\": \"I'm planning a trip to Paris next month.\"}]}, \"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:03,128 - DEBUG livekit.plugins.openai.realtime - conversation item created {\"type\": \"conversation.item.created\", \"event_id\": \"event_AYQNLTomhvME8J2Dw54hU\", \"previous_item_id\": \"item_1d0b4513cae5\", \"item\": {\"id\": \"item_33b6b9e44e17\", \"object\": \"realtime.item\", \"type\": \"message\", \"status\": \"completed\", \"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": \"How exciting! Paris is a beautiful city. I'd be happy to suggest some must-visit places and help you plan your trip.\"}]}, \"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:03,128 - DEBUG livekit.plugins.openai.realtime - conversation item created {\"type\": \"conversation.item.created\", \"event_id\": \"event_AYQNL0VNWDe7Kcg31cINK\", \"previous_item_id\": \"item_33b6b9e44e17\", \"item\": {\"id\": \"item_43b704505e13\", \"object\": \"realtime.item\", \"type\": \"message\", \"status\": \"completed\", \"role\": \"user\", \"content\": [{\"type\": \"input_text\", \"text\": \"What are the must-visit places in Paris?\"}]}, \"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:03,128 - DEBUG livekit.plugins.openai.realtime - conversation item created {\"type\": \"conversation.item.created\", \"event_id\": \"event_AYQNLOlSqkobnDhhChiHv\", \"previous_item_id\": \"item_43b704505e13\", \"item\": {\"id\": \"item_9234a3ed5a53\", \"object\": \"realtime.item\", \"type\": \"message\", \"status\": \"completed\", \"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": \"The must-visit places in Paris are the Eiffel Tower, Louvre Museum, Notre-Dame Cathedral, and Montmartre.\"}]}, \"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:03,317 - DEBUG livekit.plugins.openai.realtime - conversation item created {\"type\": \"conversation.item.created\", \"event_id\": \"event_AYQNLnAEcbU7ffwyRK8xi\", \"previous_item_id\": \"item_9234a3ed5a53\", \"item\": {\"id\": \"item_c89d92a04668\", \"object\": \"realtime.item\", \"type\": \"message\", \"status\": \"completed\", \"role\": \"user\", \"content\": [{\"type\": \"input_audio\", \"transcript\": null}]}, \"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:03,317 - INFO livekit.agents - Session initialized with chat context {\"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:05,199 - DEBUG livekit.plugins.openai.realtime - conversation item created {\"type\": \"conversation.item.created\", \"event_id\": \"event_AYQNNBoVBZ6laHSZcqGGn\", \"previous_item_id\": \"item_c89d92a04668\", \"item\": {\"id\": \"item_AYQNLJLnZAZH9qMII4hIy\", \"object\": \"realtime.item\", \"type\": \"message\", \"status\": \"completed\", \"role\": \"user\", \"content\": [{\"type\": \"input_audio\", \"transcript\": null}]}, \"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:05,589 - DEBUG livekit.plugins.openai.realtime - conversation item created {\"type\": \"conversation.item.created\", \"event_id\": \"event_AYQNN4JaLD4ok3Rlt94Wc\", \"previous_item_id\": \"item_AYQNLJLnZAZH9qMII4hIy\", \"item\": {\"id\": \"item_AYQNNdjHaz3Q9DAPdVtmz\", \"object\": \"realtime.item\", \"type\": \"function_call\", \"status\": \"in_progress\", \"name\": \"get_weather\", \"call_id\": \"call_dxowrRkne43Ei0gY\", \"arguments\": \"\"}, \"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:05,641 - DEBUG livekit.plugins.openai.realtime - executing ai function {\"function\": \"get_weather\", \"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:05,641 - INFO my-worker - getting weather for Paris {\"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:06,241 - DEBUG livekit.agents - committed user speech {\"user_transcript\": \"Hi, what is the weather for Paris?\\n\", \"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:07,150 - DEBUG livekit.plugins.openai.realtime - conversation item created {\"type\": \"conversation.item.created\", \"event_id\": \"event_AYQNPGU1K178psC2DUZNK\", \"previous_item_id\": \"item_AYQNNdjHaz3Q9DAPdVtmz\", \"item\": {\"id\": \"item_58aa7cddae88\", \"object\": \"realtime.item\", \"type\": \"function_call_output\", \"call_id\": \"call_dxowrRkne43Ei0gY\", \"output\": \"The weather in Paris is Clear +7\\u00b0C.\"}, \"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:07,503 - DEBUG livekit.plugins.openai.realtime - conversation item created {\"type\": \"conversation.item.created\", \"event_id\": \"event_AYQNPWOFmT5BuhaRowv7a\", \"previous_item_id\": \"item_58aa7cddae88\", \"item\": {\"id\": \"item_AYQNPnijsovV9Ta84FN13\", \"object\": \"realtime.item\", \"type\": \"function_call\", \"status\": \"in_progress\", \"name\": \"get_weather\", \"call_id\": \"call_UYSASc0n3OemDe8r\", \"arguments\": \"\"}, \"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:07,544 - DEBUG livekit.plugins.openai.realtime - executing ai function {\"function\": \"get_weather\", \"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:07,545 - INFO my-worker - getting weather for Paris {\"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:09,060 - DEBUG livekit.plugins.openai.realtime - conversation item created {\"type\": \"conversation.item.created\", \"event_id\": \"event_AYQNQWbnq5sPJfnE33cMi\", \"previous_item_id\": \"item_AYQNPnijsovV9Ta84FN13\", \"item\": {\"id\": \"item_f3ac70c877b9\", \"object\": \"realtime.item\", \"type\": \"function_call_output\", \"call_id\": \"call_UYSASc0n3OemDe8r\", \"output\": \"The weather in Paris is Clear +7\\u00b0C.\"}, \"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:09,460 - DEBUG livekit.plugins.openai.realtime - conversation item created {\"type\": \"conversation.item.created\", \"event_id\": \"event_AYQNRPZQEFnm3zMw8NH2P\", \"previous_item_id\": \"item_f3ac70c877b9\", \"item\": {\"id\": \"item_AYQNQpMQYGBYogQVjqd3y\", \"object\": \"realtime.item\", \"type\": \"function_call\", \"status\": \"in_progress\", \"name\": \"get_weather\", \"call_id\": \"call_4l8HPyaCjJoL8u3j\", \"arguments\": \"\"}, \"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:09,495 - DEBUG livekit.plugins.openai.realtime - executing ai function {\"function\": \"get_weather\", \"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:09,495 - INFO my-worker - getting weather for Paris {\"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:11,013 - DEBUG livekit.plugins.openai.realtime - conversation item created {\"type\": \"conversation.item.created\", \"event_id\": \"event_AYQNSZlamhKQoWZRe9lWl\", \"previous_item_id\": \"item_AYQNQpMQYGBYogQVjqd3y\", \"item\": {\"id\": \"item_2437db96606b\", \"object\": \"realtime.item\", \"type\": \"function_call_output\", \"call_id\": \"call_4l8HPyaCjJoL8u3j\", \"output\": \"The weather in Paris is Clear +7\\u00b0C.\"}, \"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:11,423 - DEBUG livekit.plugins.openai.realtime - conversation item created {\"type\": \"conversation.item.created\", \"event_id\": \"event_AYQNTop8CoYVWiwbkJkpJ\", \"previous_item_id\": \"item_2437db96606b\", \"item\": {\"id\": \"item_AYQNS5niG8GDwRqLNxTHP\", \"object\": \"realtime.item\", \"type\": \"function_call\", \"status\": \"in_progress\", \"name\": \"get_weather\", \"call_id\": \"call_aIX3pCxhhQ2ol3L5\", \"arguments\": \"\"}, \"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:11,461 - DEBUG livekit.plugins.openai.realtime - executing ai function {\"function\": \"get_weather\", \"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:11,461 - INFO my-worker - getting weather for Paris {\"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:13,001 - DEBUG livekit.plugins.openai.realtime - conversation item created {\"type\": \"conversation.item.created\", \"event_id\": \"event_AYQNUvMh9M1YegzfgBrYg\", \"previous_item_id\": \"item_AYQNS5niG8GDwRqLNxTHP\", \"item\": {\"id\": \"item_6bbd6c6121c7\", \"object\": \"realtime.item\", \"type\": \"function_call_output\", \"call_id\": \"call_aIX3pCxhhQ2ol3L5\", \"output\": \"The weather in Paris is Clear +7\\u00b0C.\"}, \"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:13,375 - DEBUG livekit.plugins.openai.realtime - conversation item created {\"type\": \"conversation.item.created\", \"event_id\": \"event_AYQNVT0Vy06yWYkF481wb\", \"previous_item_id\": \"item_6bbd6c6121c7\", \"item\": {\"id\": \"item_AYQNUa3oPGZCkTAT7lOYw\", \"object\": \"realtime.item\", \"type\": \"function_call\", \"status\": \"in_progress\", \"name\": \"get_weather\", \"call_id\": \"call_sPaa7W3OMOrNVz4E\", \"arguments\": \"\"}, \"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:13,408 - DEBUG livekit.plugins.openai.realtime - executing ai function {\"function\": \"get_weather\", \"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:13,409 - INFO my-worker - getting weather for Paris {\"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n^C2024-11-28 15:25:14,299 - INFO livekit.agents - shutting down worker {\"id\": \"AW_kLEywugKmEG5\"} # Note this is where I cancelled the python app\r\n2024-11-28 15:25:14,300 - INFO livekit.agents - job exiting {\"reason\": \"\", \"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:14,300 - DEBUG livekit.agents - shutting down job task {\"reason\": \"\", \"user_initiated\": false, \"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n2024-11-28 15:25:14,324 - DEBUG livekit.agents - http_session(): closing the httpclient ctx {\"pid\": 12183, \"job_id\": \"AJ_G9uLNncY5cYh\"}\r\n```\r\n\r\nFYI @jayeshp19 ",
      "state": "closed",
      "author": "danmastrowtrusstai",
      "author_type": "User",
      "created_at": "2024-11-28T04:32:27Z",
      "updated_at": "2025-05-22T07:09:44Z",
      "closed_at": "2025-05-22T07:09:44Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1145/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1145",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1145",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:59.038489",
      "comments": [
        {
          "author": "longcw",
          "body": "The behavior is expected when `tool_choice=\"required\"` as it will force the LLM to response a function call instead of generating the answer. The process of the functioning call is: 1) LLM outputs one or multiple function call requests, 2) agent executes the functions; 3) agent append the function o",
          "created_at": "2024-11-28T07:51:00Z"
        }
      ]
    },
    {
      "issue_number": 1242,
      "title": "Gemini agent is not working",
      "body": "I was testing the voice pipeline agent that uses gemini as LLM through the openai API and google services for the other components in the pipeline (Not the gemini realtime agent which is being worked on)\r\nhttps://github.com/livekit/agents/blob/main/examples/voice-pipeline-agent/gemini_voice_agent.py\r\n\r\nI downloaded it, installed all dependencies, created a set of credentials with the correct permissions and while the welcome message is being streamed I get this error\r\n\r\n```\r\n2024-12-16 19:12:11,961 - ERROR livekit.agents.pipeline - Error in _recognize_task\r\nTraceback (most recent call last):\r\n  File \"/home/enrique/Enrique/Omniloy/test/googleVoiceTests/realtime-playground/.venv/lib/python3.12/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\r\n    return await fn(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/enrique/Enrique/Omniloy/test/googleVoiceTests/realtime-playground/.venv/lib/python3.12/site-packages/livekit/agents/pipeline/human_input.py\", line 150, in _recognize_task\r\n    await asyncio.gather(*tasks)\r\n  File \"/home/enrique/Enrique/Omniloy/test/googleVoiceTests/realtime-playground/.venv/lib/python3.12/site-packages/livekit/agents/pipeline/human_input.py\", line 120, in _audio_stream_co\r\n    stt_stream.push_frame(ev.frame)\r\n  File \"/home/enrique/Enrique/Omniloy/test/googleVoiceTests/realtime-playground/.venv/lib/python3.12/site-packages/livekit/agents/stt/stt.py\", line 265, in push_frame\r\n    self._check_not_closed()\r\n  File \"/home/enrique/Enrique/Omniloy/test/googleVoiceTests/realtime-playground/.venv/lib/python3.12/site-packages/livekit/agents/stt/stt.py\", line 327, in _check_not_closed\r\n    raise RuntimeError(f\"{cls.__module__}.{cls.__name__} is closed\")\r\nRuntimeError: livekit.plugins.google.stt.SpeechStream is closed {\"pid\": 91447, \"job_id\": \"AJ_dtKi2nzgZvqh\"}\r\n```\r\nThis is the only error or warning I see on the logs\r\n\r\nHere is the log trace in case it helps\r\n\r\n```\r\npython main.py dev\r\n2024-12-16 19:11:52,728 - DEBUG asyncio - Using selector: EpollSelector\r\n2024-12-16 19:11:52,729 - DEV  livekit.agents - Watching /home/enrique/Enrique/Omniloy/test/googleVoiceTests/realtime-playground/agent\r\n2024-12-16 19:11:53,459 - DEBUG asyncio - Using selector: EpollSelector\r\n2024-12-16 19:11:53,465 - INFO livekit.agents - starting worker {\"version\": \"0.12.2\", \"rtc-version\": \"0.18.2\"}\r\n2024-12-16 19:11:53,649 - INFO livekit.agents - registered worker {\"id\": \"AW_TnnRsKzECFut\", \"region\": \"France\", \"protocol\": 15, \"node_id\": \"NC_OMARSEILLE1A_LzQTokkbYhhv\"}\r\n2024-12-16 19:12:08,152 - INFO livekit.agents - received job request {\"job_id\": \"AJ_dtKi2nzgZvqh\", \"dispatch_id\": \"\", \"room_name\": \"playground-n1ow-rvVz\", \"agent_name\": \"\", \"resuming\": false}\r\n2024-12-16 19:12:08,995 - INFO livekit.agents - initializing job process {\"pid\": 91447}\r\n2024-12-16 19:12:09,044 - INFO livekit.agents - job process initialized {\"pid\": 91447, \"job_id\": \"AJ_dtKi2nzgZvqh\"}\r\n2024-12-16 19:12:09,044 - DEBUG asyncio - Using selector: EpollSelector {\"pid\": 91447, \"job_id\": \"AJ_dtKi2nzgZvqh\"}\r\n2024-12-16 19:12:09,046 - INFO voice-assistant - connecting to room playground-n1ow-rvVz {\"pid\": 91447, \"job_id\": \"AJ_dtKi2nzgZvqh\"}\r\n2024-12-16 19:12:09,048 - INFO livekit - livekit_ffi::server:133:livekit_ffi::server - initializing ffi server v0.12.3 {\"pid\": 91447, \"job_id\": \"AJ_dtKi2nzgZvqh\"}\r\n2024-12-16 19:12:09,048 - INFO livekit - livekit_ffi::cabi:36:livekit_ffi::cabi - initializing ffi server v0.12.3 {\"pid\": 91447, \"job_id\": \"AJ_dtKi2nzgZvqh\"}\r\n2024-12-16 19:12:09,050 - INFO livekit - livekit_api::signal_client::signal_stream:96:livekit_api::signal_client::signal_stream - connecting to wss://testomni-b7j6hodm.livekit.cloud/rtc?sdk=python&protocol=15&auto_subscribe=0&adaptive_stream=0&version=0.18.2&access_token=... {\"pid\": 91447, \"job_id\": \"AJ_dtKi2nzgZvqh\"}\r\n2024-12-16 19:12:09,156 - DEBUG livekit - rustls::anchors:150:rustls::anchors - add_parsable_certificates processed 146 valid and 0 invalid certs {\"pid\": 91447, \"job_id\": \"AJ_dtKi2nzgZvqh\"}\r\n2024-12-16 19:12:09,156 - DEBUG livekit - tokio_tungstenite::tls::encryption::rustls:103:tokio_tungstenite::tls::encryption::rustls - Added 146/146 native root certificates (ignored 0) {\"pid\": 91447, \"job_id\": \"AJ_dtKi2nzgZvqh\"}\r\n2024-12-16 19:12:09,156 - DEBUG livekit - rustls::client::hs:73:rustls::client::hs - No cached session for DnsName(\"testomni-b7j6hodm.livekit.cloud\") {\"pid\": 91447, \"job_id\": \"AJ_dtKi2nzgZvqh\"}\r\n2024-12-16 19:12:09,156 - DEBUG livekit - rustls::client::hs:132:rustls::client::hs - Not resuming any session {\"pid\": 91447, \"job_id\": \"AJ_dtKi2nzgZvqh\"}\r\n2024-12-16 19:12:09,182 - DEBUG livekit - rustls::client::hs:615:rustls::client::hs - Using ciphersuite TLS13_AES_128_GCM_SHA256 {\"pid\": 91447, \"job_id\": \"AJ_dtKi2nzgZvqh\"}\r\n2024-12-16 19:12:09,182 - DEBUG livekit - rustls::client::tls13:142:rustls::client::tls13 - Not resuming {\"pid\": 91447, \"job_id\": \"AJ_dtKi2nzgZvqh\"}\r\n2024-12-16 19:12:09,183 - DEBUG livekit - rustls::client::tls13:381:rustls::client::tls13 - TLS1.3 encrypted extensions: [] {\"pid\": 91447, \"job_id\": \"AJ_dtKi2nzgZvqh\"}\r\n2024-12-16 19:12:09,183 - DEBUG livekit - rustls::client::hs:472:rustls::client::hs - ALPN protocol is None {\"pid\": 91447, \"job_id\": \"AJ_dtKi2nzgZvqh\"}\r\n2024-12-16 19:12:09,283 - DEBUG livekit - tungstenite::handshake::client:95:tungstenite::handshake::client - Client handshake done. {\"pid\": 91447, \"job_id\": \"AJ_dtKi2nzgZvqh\"}\r\n2024-12-16 19:12:09,492 - INFO voice-assistant - starting voice assistant for participant identity-RxbH {\"pid\": 91447, \"job_id\": \"AJ_dtKi2nzgZvqh\"}\r\n2024-12-16 19:12:09,492 - DEBUG google.auth._default - Checking /home/enrique/.config/gcloud/application_default_credentials.json for explicit credentials as part of auth process... {\"pid\": 91447, \"job_id\": \"AJ_dtKi2nzgZvqh\"}\r\n2024-12-16 19:12:09,492 - DEBUG google.auth._default - Explicit credentials path /home/enrique/.config/gcloud/application_default_credentials.json is the same as Cloud SDK credentials path, fall back to Cloud SDK credentials flow... {\"pid\": 91447, \"job_id\": \"AJ_dtKi2nzgZvqh\"}\r\n2024-12-16 19:12:09,492 - DEBUG google.auth._default - Checking Cloud SDK credentials as part of auth process... {\"pid\": 91447, \"job_id\": \"AJ_dtKi2nzgZvqh\"}\r\n2024-12-16 19:12:10,561 - DEBUG grpc._cython.cygrpc - Using AsyncIOEngine.POLLER as I/O engine {\"pid\": 91447, \"job_id\": \"AJ_dtKi2nzgZvqh\"}\r\n2024-12-16 19:12:11,651 - DEBUG urllib3.connectionpool - Starting new HTTPS connection (1): oauth2.googleapis.com:443 {\"pid\": 91447, \"job_id\": \"AJ_dtKi2nzgZvqh\"}\r\n2024-12-16 19:12:11,652 - DEBUG urllib3.connectionpool - Starting new HTTPS connection (1): oauth2.googleapis.com:443 {\"pid\": 91447, \"job_id\": \"AJ_dtKi2nzgZvqh\"}\r\n2024-12-16 19:12:11,848 - DEBUG urllib3.connectionpool - https://oauth2.googleapis.com:443 \"POST /token HTTP/11\" 200 None {\"pid\": 91447, \"job_id\": \"AJ_dtKi2nzgZvqh\"}\r\n2024-12-16 19:12:11,849 - DEBUG urllib3.connectionpool - https://oauth2.googleapis.com:443 \"POST /token HTTP/11\" 200 None {\"pid\": 91447, \"job_id\": \"AJ_dtKi2nzgZvqh\"}\r\n2024-12-16 19:12:11,961 - ERROR livekit.agents.pipeline - Error in _recognize_task\r\nTraceback (most recent call last):\r\n  File \"/home/enrique/Enrique/Omniloy/test/googleVoiceTests/realtime-playground/.venv/lib/python3.12/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\r\n    return await fn(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/enrique/Enrique/Omniloy/test/googleVoiceTests/realtime-playground/.venv/lib/python3.12/site-packages/livekit/agents/pipeline/human_input.py\", line 150, in _recognize_task\r\n    await asyncio.gather(*tasks)\r\n  File \"/home/enrique/Enrique/Omniloy/test/googleVoiceTests/realtime-playground/.venv/lib/python3.12/site-packages/livekit/agents/pipeline/human_input.py\", line 120, in _audio_stream_co\r\n    stt_stream.push_frame(ev.frame)\r\n  File \"/home/enrique/Enrique/Omniloy/test/googleVoiceTests/realtime-playground/.venv/lib/python3.12/site-packages/livekit/agents/stt/stt.py\", line 265, in push_frame\r\n    self._check_not_closed()\r\n  File \"/home/enrique/Enrique/Omniloy/test/googleVoiceTests/realtime-playground/.venv/lib/python3.12/site-packages/livekit/agents/stt/stt.py\", line 327, in _check_not_closed\r\n    raise RuntimeError(f\"{cls.__module__}.{cls.__name__} is closed\")\r\nRuntimeError: livekit.plugins.google.stt.SpeechStream is closed {\"pid\": 91447, \"job_id\": \"AJ_dtKi2nzgZvqh\"}\r\n2024-12-16 19:12:12,490 - DEBUG livekit.agents.pipeline - speech playout started {\"speech_id\": \"0426d2c5853d\", \"pid\": 91447, \"job_id\": \"AJ_dtKi2nzgZvqh\"}\r\n2024-12-16 19:12:12,491 - INFO livekit.agents - Pipeline TTS metrics: sequence_id=0426d2c5853d, ttfb=1.922347173000162, audio_duration=2.20 {\"pid\": 91447, \"job_id\": \"AJ_dtKi2nzgZvqh\"}\r\n2024-12-16 19:12:14,692 - DEBUG livekit.agents.pipeline - speech playout finished {\"speech_id\": \"0426d2c5853d\", \"interrupted\": false, \"pid\": 91447, \"job_id\": \"AJ_dtKi2nzgZvqh\"}\r\n2024-12-16 19:12:14,692 - DEBUG livekit.agents.pipeline - committed agent speech {\"agent_transcript\": \" Hi there, this is Gemini, how can I help you today?\", \"interrupted\": false, \"speech_id\": \"0426d2c5853d\", \"pid\": 91447, \"job_id\": \"AJ_dtKi2nzgZvqh\"}\r\n```\r\n\r\nI'm going to test with a different stt",
      "state": "closed",
      "author": "kikoncuo",
      "author_type": "User",
      "created_at": "2024-12-16T18:17:47Z",
      "updated_at": "2025-05-22T07:09:26Z",
      "closed_at": "2025-05-22T07:09:24Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1242/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1242",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1242",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:59.303712",
      "comments": [
        {
          "author": "davidzhao",
          "body": "looks like TTS worked based on your logs?\r\n\r\nthe error had come from the STT side, are the right services enabled on your Google account? I'm unable to reproduce this on our side. ",
          "created_at": "2024-12-17T01:24:43Z"
        },
        {
          "author": "kikoncuo",
          "body": "Sorry STT, I changed to a different STT and it worked.\r\n\r\nThe API is enabled, I was getting a different error when they weren't enabled.\r\n\r\nThe logs before were really descriptive with the problem this one is a bit harder to debug.\r\n\r\nI'm not using google's STT, just wanted to report the issue with ",
          "created_at": "2024-12-17T11:35:52Z"
        },
        {
          "author": "davidzhao",
          "body": "got it, my mistake. was the service activated on Google's side? the demo is working for us here when the STT service is enabled",
          "created_at": "2024-12-25T01:13:48Z"
        },
        {
          "author": "rupakgoyal",
          "body": "It is not working on my end can you check \r\n\r\n\r\n\r\n2025-01-05 21:19:55,822 - DEBUG urllib3.connectionpool - Starting new HTTPS connection (1): oauth2.googleapis.com:443 {\"pid\": 29913, \"job_id\": \"AJ_bM2KAVUyyZJe\"}\r\n2025-01-05 21:19:55,881 - DEBUG urllib3.connectionpool - Starting new HTTPS connection ",
          "created_at": "2025-01-05T15:54:52Z"
        },
        {
          "author": "davidzhao",
          "body": "unable to reproduce",
          "created_at": "2025-05-22T07:09:24Z"
        }
      ]
    },
    {
      "issue_number": 2355,
      "title": "Google TTS not taking pauses ",
      "body": "<!--\nHello! Thanks for taking the time to file a bug report.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already reported this issue.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n-->\nIn the latest version of Google TTS. I am using chrip3 hd model for TTS. But it doesn't seems to correctly pause on punctuations.\n\nAlso its not able to take tags like [pause long] as mentioned in Google documentation.\n\nhttps://cloud.google.com/text-to-speech/docs/chirp3-hd\n\n",
      "state": "open",
      "author": "ansh-tan",
      "author_type": "User",
      "created_at": "2025-05-22T05:14:21Z",
      "updated_at": "2025-05-22T05:14:21Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2355/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2355",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2355",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:59.557936",
      "comments": []
    },
    {
      "issue_number": 2133,
      "title": "Google gemini-2.5-flash responses can throw several errors that are fatal to the worker",
      "body": "I've experienced both of these errors in the middle of a conversation. Both shut down the conversation and prevent further progress.\n\n`livekit.agents._exceptions.APIStatusError: gemini llm: client error (status_code=400, request_id=d18a6998476a, body=Please ensure that single turn requests end with a user role or the role field is empty.INVALID_ARGUMENT)`\n\n`livekit.agents._exceptions.APIConnectionError: gemini llm: error generating content No candidates in the response (status_code=-1, request_id=bd1f1400344a, body=None)`",
      "state": "closed",
      "author": "DavidHuie",
      "author_type": "User",
      "created_at": "2025-04-25T16:19:27Z",
      "updated_at": "2025-05-21T23:23:53Z",
      "closed_at": "2025-05-21T23:23:53Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2133/reactions",
        "total_count": 4,
        "+1": 4,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "davidzhao"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2133",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2133",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:59.557966",
      "comments": [
        {
          "author": "NikoLandgraf",
          "body": "I have seen the same",
          "created_at": "2025-04-30T16:50:36Z"
        },
        {
          "author": "ramon-prieto",
          "body": "Same here even with flash-2.0. I cannot use `session.generate_reply` with any of the google models",
          "created_at": "2025-05-01T00:18:23Z"
        },
        {
          "author": "anlagbr",
          "body": "This bug needs to be fixed as it causes applications to stop working completely and cannot be recovered. Sometimes, Google returns a None value in response.parts. According to some forums, this is due to content moderation, although subsequent requests work correctly.",
          "created_at": "2025-05-15T08:41:12Z"
        },
        {
          "author": "davidzhao",
          "body": "could anyone share a repro? what sequence of actions would cause this to occur?",
          "created_at": "2025-05-18T19:22:43Z"
        },
        {
          "author": "anlagbr",
          "body": "@davidzhao \n\nYou can try with a simple setup — GEMINI API keys have a free tier. You can also use Groq Whisper free tier and any TTS model.\n\nIt's difficult to reproduce the issue because Google sometimes returns None, but after that, the conversation seems to work fine. Trying with sensitive prompts",
          "created_at": "2025-05-19T06:59:01Z"
        }
      ]
    },
    {
      "issue_number": 2352,
      "title": "STT sometime in the middle of the call, WARNING failed to recognize speech like it didn't recognize the speech.",
      "body": "Hello,\n(Its a high priority to keep using livkit) !!!!!!!!!!!\n\nWe are using google stt and google tts.\nLike its been a week we have applied alot of configs tuning but still it sometime didn't detect if the user is talking.\nand in the logs it says:\nWARNING failed to recognize speech like it didn't recognize the speech.\n\nAlso has to speak loudly at sometime.\n\nMaybe we need to tune the VAD, Current VAD config is something like that.\n\nvad=silero.VAD.load(\n            min_speech_duration=0.07,\n            min_silence_duration=0.7,\n            activation_threshold=0.02,\n            prefix_padding_duration=0.3,\n        )\nturn_detection=\"vad\"\n\n\"stt_settings\": {\n    \"model\": \"latest_long\",\n    \"spoken_punctuation\": true,\n    \"sample_rate\": 16000,\n    \"punctuate\": true,\n    \"languages\": [\"en-US\"],\n    \"interim_results\": true\n  },\n  \"tts_settings\": {\n    \"language\": \"en-US\",\n    \"gender\": \"female\",\n    \"voice_name\": \"en-US-Chirp3-HD-Leda\",\n    \"audio_encoding\": \"linear16\",\n    \"sample_rate\": 23150\n  }\n\nCan anyone in the internal team help.\nThat would be great.\nThankyou.",
      "state": "open",
      "author": "fahadanwaar",
      "author_type": "User",
      "created_at": "2025-05-21T19:47:21Z",
      "updated_at": "2025-05-21T20:26:44Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2352/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2352",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2352",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:59.800462",
      "comments": []
    },
    {
      "issue_number": 2349,
      "title": "Realtime metrics collection throws error when token_count is None",
      "body": "We are using the Gemini Realtime model. After upgrading to 1.0.21, we started seeing the following error immediately proceeding any function_tool invocation:\n\n```\n2025-05-21 13:40:42,333 - ERROR livekit.plugins.google - error in receive task: unsupported operand type(s) for +=: 'int' and 'NoneType' \nTraceback (most recent call last):\n  .\\livekit\\plugins\\google\\beta\\realtime\\realtime_api.py\", line 571, in _recv_task\n    self._handle_usage_metadata(response.usage_metadata)\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^\n  .\\livekit\\plugins\\google\\beta\\realtime\\realtime_api.py\", line 822, in _handle_usage_metadata\n    **_token_details_map(usage_metadata.response_tokens_details),\n      ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n .\\livekit\\plugins\\google\\beta\\realtime\\realtime_api.py\", line 793, in _token_details_map\n    token_details_map[\"audio_tokens\"] += token_detail.token_count\nTypeError: unsupported operand type(s) for +=: 'int' and 'NoneType'\n```\n\nThis error is caused by `token_detail.token_count` being `None` in the usage metadata returned by the model.\n\nI believe this was introduced in #2275.\n\nA simple fix is ensure `token_count` is defined before attempting to update the token_details_map. I'll open a PR to this effect, but if there's a deeper cause/better fix please let me know.",
      "state": "closed",
      "author": "fredvollmer",
      "author_type": "User",
      "created_at": "2025-05-21T17:51:52Z",
      "updated_at": "2025-05-21T19:04:15Z",
      "closed_at": "2025-05-21T19:04:15Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2349/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2349",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2349",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:34:59.800484",
      "comments": [
        {
          "author": "davidzhao",
          "body": "@fredvollmer a PR here would be awesome.. you are absolutely right this should be more robust in checking for None-ness",
          "created_at": "2025-05-21T17:56:31Z"
        },
        {
          "author": "fredvollmer",
          "body": "@davidzhao Great! PR opened.",
          "created_at": "2025-05-21T18:00:07Z"
        }
      ]
    },
    {
      "issue_number": 2336,
      "title": "InvalidStateError in _init_task when calling self._audio_output.start() in room_io",
      "body": "We're encountering an InvalidStateError in the _init_task method of room_io.py when attempting to start audio output. This occurs during the call to self._audio_output.start(), which attempts to set the result of a future (self._started_fut) that is already completed or in an invalid state.\n```\nError in _init_task\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/site-packages/livekit/agents/voice/room_io/room_io.py\", line 338, in _init_task\n    await self._audio_output.start()\n  File \"/usr/local/lib/python3.12/site-packages/livekit/agents/voice/room_io/_output.py\", line 55, in start\n    self._started_fut.set_result(None)\nasyncio.exceptions.InvalidStateError: invalid state\n```\n",
      "state": "open",
      "author": "narendra-bluebash",
      "author_type": "User",
      "created_at": "2025-05-20T12:22:30Z",
      "updated_at": "2025-05-21T12:36:08Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2336/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2336",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2336",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:00.064798",
      "comments": [
        {
          "author": "narendra-bluebash",
          "body": "sometime i am gettting\n`{\"message\": \"Language pa-IN not supported by EOU model\", \"level\": \"WARNING\", \"name\": \"livekit.plugins.turn_detector\", \"pid\": 1414, \"job_id\": \"AJ_4DcNpSEaosYL\", \"timestamp\": \"2025-05-20T12:15:40.052394+00:00\"}\n`",
          "created_at": "2025-05-20T12:25:27Z"
        },
        {
          "author": "longcw",
          "body": "can you share your agent config, seems like you started the room io twice.",
          "created_at": "2025-05-20T12:53:36Z"
        },
        {
          "author": "narendra-bluebash",
          "body": "@longcw Why would it run twice?\n```\nif source==3:\n    room_io= RoomIO(agent_session=session, room=ctx.room, participant=outbound_participant)\nelse:\n    room_io = RoomIO(agent_session=session, room=ctx.room)\nawait room_io.start()\nawait session.start(\n    agent=agent,\n    room_input_options=RoomInputO",
          "created_at": "2025-05-21T10:53:56Z"
        },
        {
          "author": "longcw",
          "body": "from your code snippet the `room_io.start` is not called twice and I cannot reproduce the issue from it. could you share a minimal example that has this error?\n\nalso, maybe not related,  `RoomInputOptions` needs to be passed to `RoomIO` directly if you created it explicitly.",
          "created_at": "2025-05-21T12:36:06Z"
        }
      ]
    },
    {
      "issue_number": 2330,
      "title": "How to attach additional information in Agent Reponse Chunk?",
      "body": "Is it possible to add additional information when sending text back to client, like an additional metadata field for each text chunk/segment? Thanks.",
      "state": "open",
      "author": "Darejkal",
      "author_type": "User",
      "created_at": "2025-05-19T20:41:06Z",
      "updated_at": "2025-05-21T10:10:53Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2330/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2330",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2330",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:00.313241",
      "comments": [
        {
          "author": "davidzhao",
          "body": "what type of metadata are you trying to send back? can you give any examples of the use case?",
          "created_at": "2025-05-20T00:48:25Z"
        },
        {
          "author": "Darejkal",
          "body": "I'm trying to send back viseme for lip syncing at client. I understand that there is another option to extend avataragentsession, but what about cases when the avatar is rendered at client?\n\nThe metadata would also be helpful to implement functionality on top of the existing livekit agent framework.",
          "created_at": "2025-05-20T02:02:50Z"
        },
        {
          "author": "davidzhao",
          "body": "got it.. that's helpful to know. how are you thinking about synchronizing the clock between the agent (that produces the timing data) and the client? I think that's a tricky issue that we'd have to resolve as well.",
          "created_at": "2025-05-21T06:46:03Z"
        },
        {
          "author": "Darejkal",
          "body": "Sorry, I'm currently best efforting this. It's tolerable,... at least for our usecase.",
          "created_at": "2025-05-21T09:52:36Z"
        }
      ]
    },
    {
      "issue_number": 1305,
      "title": "Call Transfer Not Working as Expected",
      "body": "Hello, \r\n\r\nI am attempting to handle call transfers using LiveKit in a voice assistant. The assistant listens for user responses (`yes` or `no`) and initiates a transfer to the billing department when the response is affirmative. Despite following the documentation and implementing the SIP transfer process, the call transfer does not happen.  \r\n\r\nPreviously, I was able to handle call transfers successfully using DTMF handling, where the assistant listens for keypad inputs (e.g., pressing a specific number) and responds accordingly. However, the same process does not seem to work with voice-triggered responses.  \r\n\r\n\r\n#### Expected Behavior  \r\nThe call should be transferred to the billing department's phone number provided in the `.env.local` file as `BILLING_PHONE_NUMBER`.  \r\n\r\n#### Observed Behavior  \r\nThe assistant verbally confirms the transfer, but the actual SIP transfer does not take place. The call remains in the current room, and no error logs indicate why the transfer failed.\r\n\r\n---\r\n\r\n### Code Snippets  \r\n\r\n**1. Handling Call Transfer**  \r\nBelow is the code snippet for initiating the SIP call transfer:  \r\n\r\n```python\r\nasync def handle_transfer(room_name: str, participant_identity: str, assistant: VoiceAssistant) -> None:\r\n    try:\r\n        transfer_number = os.getenv('BILLING_PHONE_NUMBER')\r\n        if not transfer_number:\r\n            raise ValueError(\"Billing phone number not configured\")\r\n\r\n        if not transfer_number.startswith('+'):\r\n            transfer_number = f\"+{transfer_number}\"\r\n\r\n        await assistant.say(\"Transferring you to our billing department. Please hold.\", allow_interruptions=False)\r\n\r\n        livekit_api = api.LiveKitAPI(\r\n            url=os.getenv('LIVEKIT_URL'),\r\n            api_key=os.getenv('LIVEKIT_API_KEY'),\r\n            api_secret=os.getenv('LIVEKIT_API_SECRET')\r\n        )\r\n\r\n        transfer_uri = f\"tel:{transfer_number}\"\r\n        transfer_request = proto_sip.TransferSIPParticipantRequest(\r\n            room_name=room_name,\r\n            participant_identity=participant_identity,\r\n            transfer_to=transfer_uri,\r\n            play_dialtone=False\r\n        )\r\n\r\n        logger.info(f\"Initiating transfer for participant {participant_identity} to {transfer_uri}\")\r\n        await livekit_api.sip.transfer_sip_participant(transfer_request)\r\n        await asyncio.sleep(2)\r\n        await assistant.cleanup()\r\n        logger.info(\"Transfer completed, exiting process\")\r\n        os._exit(0)\r\n    except Exception as e:\r\n        logger.error(f\"Transfer failed: {e}\", exc_info=True)\r\n        await assistant.say(\"I apologize, but I couldn't transfer your call. Please try again later.\", allow_interruptions=True)\r\n```\r\n\r\n---\r\n\r\n**2. Handling `yes/no` Responses**  \r\nBelow is the implementation for handling user responses and deciding whether to transfer the call:  \r\n\r\n```python\r\n@assistant.on_message\r\nasync def handle_message(message: str):\r\n    message = message.lower().strip()\r\n    \r\n    if message in [\"yes\", \"yeah\", \"sure\", \"okay\", \"correct\", \"yep\"]:\r\n        participants = list(ctx.room.participants.values())\r\n        if not participants:\r\n            logger.error(\"No participants found in room\")\r\n            await assistant.say(\"I'm sorry, but I cannot process the transfer at this moment.\", allow_interruptions=True)\r\n            return\r\n\r\n        participant = participants[0]\r\n        logger.info(f\"Attempting transfer for participant: {participant.identity}\")\r\n        await handle_transfer(ctx.room.name, participant.identity, assistant)\r\n        \r\n    elif message in [\"no\", \"nope\", \"not now\", \"nah\"]:\r\n        await assistant.say(\"Alright, is there something else I can help you with?\", allow_interruptions=True)\r\n    else:\r\n        await assistant.say(\"Would you like me to transfer you to our billing department? Please say 'yes' or 'no'.\", allow_interruptions=True)\r\n```\r\n\r\n---\r\n\r\n### What I Tried  \r\n- Attempted debugging the `transfer_sip_participant` call, but found no relevant error logs.  \r\n\r\n---\r\n\r\n### Questions  \r\n1. Is the SIP transfer feature supported for this use case in LiveKit?  \r\n2. Are there additional configurations or permissions required for SIP transfers to work?  \r\n3. Could there be a potential issue with the LiveKit SDK or API?  \r\n4. Why does the transfer work as expected when using DTMF handling (listening for keypad inputs) but fails when using `yes/no` voice responses? Are there additional steps or considerations required for voice-based triggers?  \r\n\r\n---\r\n\r\n### Environment  \r\n- **LiveKit SDK Version:** (Please specify)  \r\n- **Python Version:** (e.g., 3.10)  \r\n- **OS:** (e.g., Ubuntu 22.04)  \r\n\r\nAny insights or guidance would be greatly appreciated! Let me know if you need additional logs or context.  \r\n",
      "state": "open",
      "author": "shwetd19",
      "author_type": "User",
      "created_at": "2024-12-27T04:58:44Z",
      "updated_at": "2025-05-21T09:39:57Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1305/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1305",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1305",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:00.559557",
      "comments": [
        {
          "author": "andrewcbuensalida",
          "body": "I get an deadline_exceeded error",
          "created_at": "2025-03-04T19:36:53Z"
        },
        {
          "author": "andrewcbuensalida",
          "body": "> > I get an deadline_exceeded error\n> \n> Same here.\n> \n> Have you managed to fix this issue?\n\nNo",
          "created_at": "2025-03-11T19:56:22Z"
        },
        {
          "author": "pcriadoperez",
          "body": "Hi, I'm getting the same error trying to use transfer_sip_participant with a caller calling over a number from `telnyx`.\nNo error is thrown and I don't see any logs on the telnyx side of the transfer",
          "created_at": "2025-03-16T18:54:09Z"
        },
        {
          "author": "mukunth-anyreach",
          "body": "Is this resolved?\nI'm getting `error transferring call: TwirpError(code=not_found, message=twirp error unknown: participant does not exist, status=404)`",
          "created_at": "2025-05-21T09:39:55Z"
        }
      ]
    },
    {
      "issue_number": 2348,
      "title": "JobRequest ParticipantInfo Empty",
      "body": "Hi Everyone \n\nWe are using Livekit Agent Python SDK: \n\nlivekit==1.0.7\nlivekit-agents==1.0.21\n\nWe are trying to take control of the job acceptance process. But we can't get the participant information. We are using the `request_fnc` like this:\n\n\n```python\nfrom livekit.agents import WorkerOptions, cli, JobRequest\nfrom app.utils.prewarm import prewarm\nfrom app.agent import entrypoint\nfrom ecs_load import custom_load_fnc\n\nasync def request_fnc(req: JobRequest):\n    \n    print(req.room)\n\n    print(req.publisher.__dict__)\n\n    # Some logic to accept or reject the job depending on the publisher(participant)....\n    \ndef main():\n    cli.run_app(\n        WorkerOptions(\n            request_fnc=request_fnc,\n            entrypoint_fnc=entrypoint,\n            prewarm_fnc=prewarm,\n            load_fnc=custom_load_fnc\n        ),\n    )\n\nif __name__ == \"__main__\":\n    main()\n```\n\nWe got for `req.room` the following output:\n\n```python\nsid: \"RM_a2bVcbdkD42M\"\nname: \"b8be9052-50a3-428a-9dcb-21ede409bb81\"\nempty_timeout: 300\ncreation_time: 1747814567\nenabled_codecs {\n  mime: \"video/H264\"\n}\nenabled_codecs {\n  mime: \"video/VP8\"\n}\nenabled_codecs {\n  mime: \"video/VP9\"\n}\nenabled_codecs {\n  mime: \"video/AV1\"\n}\nenabled_codecs {\n  mime: \"audio/red\"\n}\nenabled_codecs {\n  mime: \"audio/opus\"\n}\nversion {\n  unix_micro: 1747814567811533\n}\ndeparture_timeout: 20\ncreation_time_ms: 1747814567766\n```\n\nBut we are not able to get the participant information from `req.publisher` the information is not available:\n\n```python\n{'AttributesEntry': <class 'models.AttributesEntry'>, 'DESCRIPTOR': <google._upb._message.Descriptor object at 0x7f71b1b0ae30>, '__module__': 'models', '__slots__': (), '__doc__': None}\n```\n\nThank you for your help, and let me know if need more information.\n",
      "state": "open",
      "author": "Leandroglez39",
      "author_type": "User",
      "created_at": "2025-05-21T09:33:30Z",
      "updated_at": "2025-05-21T09:33:30Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2348/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2348",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2348",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:00.770625",
      "comments": []
    },
    {
      "issue_number": 2329,
      "title": "How to use a Realtime model with STT input",
      "body": "<!--\nHello! Thanks for taking the time to ask a question.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already asked this question.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n\nFeel free to join us in the #agents channel on our Slack, and ask your question\nthere to get quicker help from us and the community:\n\nhttps://livekit.io/join-slack\n-->\nHello!\n\nIs it possible to use a Realtime model with an STT as input somehow? I’d like to take advantage of the speed improvements, but also use an STT that’s more suitable for my use case.\n\nThanks in advance!",
      "state": "closed",
      "author": "RBT22",
      "author_type": "User",
      "created_at": "2025-05-19T14:17:01Z",
      "updated_at": "2025-05-21T08:16:05Z",
      "closed_at": "2025-05-21T08:16:04Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2329/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2329",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2329",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:00.770649",
      "comments": [
        {
          "author": "longcw",
          "body": "right now it's not supported. The most close example is [this one](https://github.com/livekit/agents/blob/main/examples/voice_agents/realtime_turn_detector.py), which runs STT along with the realtime model and uses STT results for local turn detection.\n\n",
          "created_at": "2025-05-20T08:23:22Z"
        },
        {
          "author": "RBT22",
          "body": "Thanks for the quick answer!",
          "created_at": "2025-05-21T08:16:04Z"
        }
      ]
    },
    {
      "issue_number": 1117,
      "title": "`interrupt_min_words` should only apply to `self._transcribed_text`",
      "body": "Despite the fix to flush Deepgram transcripts, we are still (though rarely) seeing DG send only `INTERIM` transcripts without a `FINAL`.\r\n\r\nIf this is the case, then `interrupt_min_words` should be compared to `self._transcribed_text`, not `self._transcribed_interim_text`. Otherwise, we may interrupt the agents response without it ever being prompted to respond to what it was interrupted by. This results in the agent appearing to freeze \r\n\r\n### Proposed Solution 1\r\nThis line in `VoicePipelineAgent`:\r\n```\r\ntext = self._transcribed_interim_text or self._transcribed_text\r\n```\r\n\r\nShould instead be:\r\n```\r\ntext = self._transcribed_text\r\n```\r\nI would be happy to implement this if Livekit agrees\r\nThe issue with this solution is that interruptions will appear to lag a bit from what the user actually says, so not sure if this is worth the tradeoff\r\n\r\n### Proposed Solution 2\r\nAnother solution could be having an internal timer of some sort that will use the `_transcribed_interim_text` if we never get back a `FINAL` event after a certain amount of time. I would not be as comfortable implementing this but can give it a try. I don't see a downside to this approach in terms of user experience",
      "state": "closed",
      "author": "seanmuirhead",
      "author_type": "User",
      "created_at": "2024-11-20T18:21:23Z",
      "updated_at": "2025-05-21T07:35:13Z",
      "closed_at": "2025-05-21T07:35:13Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1117/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1117",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1117",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:01.006114",
      "comments": []
    },
    {
      "issue_number": 2322,
      "title": "Google TTS always fails for first call",
      "body": "<!--\nHello! Thanks for taking the time to file a bug report.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already reported this issue.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n-->\n\nI'm trying to use Google Chirp voices for TTS, this is my agent configuration - \n\n```\nclass SimpleAgent(Agent):\n    def __init__(self) -> None:\n        super().__init__(\n            instructions=\"\"\"\n                You are a translator. You translate the user's speech from English to Hindi.\n                Every message you receive, translate it directly into Hindi.\n                Do not respond with anything else but the translation.\n            \"\"\",\n            stt=gladia.STT(\n                languages=[\"en\"],\n            ),\n            llm=openai.LLM(model=\"gpt-4.1-mini\"),\n            tts=google.TTS(\n                language=\"hi-IN\",\n                voice_name=\"hi-IN-Chirp3-HD-Zephyr\"\n                \n            ),\n            # turn_detection=\"stt\",\n            vad=silero.VAD.load(),\n            turn_detection=MultilingualModel()\n        )\n```\n\nI'm on version `1.0.22` of the SDK. I keep seeing the `google tts deadline exceeded` error -\n\n```\n2025-05-18 18:13:57,079 - DEBUG grpc._cython.cygrpc - Using AsyncIOEngine.POLLER as I/O engine \nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1747572237.191074 28880226 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n[Audio] cBook Air Microphone [-68.79 dBFS] [#-----------------------------]I0000 00:00:1747572237.223370 28880226 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n2025-05-18 18:14:04,169 - DEBUG urllib3.connectionpool - Starting new HTTPS connection (1): oauth2.googleapis.com:443 \n2025-05-18 18:14:07,808 - DEBUG livekit.plugins.google - google tts deadline exceeded: 504 Deadline Exceeded \n2025-05-18 18:14:07,808 - DEBUG grpc.aio._call - Exception while consuming the request_iterator: <AioRpcError of RPC that terminated with:\n        status = StatusCode.DEADLINE_EXCEEDED\n        details = \"Deadline Exceeded\"\n        debug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2025-05-18T18:14:07.804626+05:30\", grpc_status:4, grpc_message:\"Deadline Exceeded\"}\"\n> \n```\nThis has been happening since https://github.com/livekit/agents/pull/2143 was merged. This error usually occurs for the first call resulting in increased first response time. \n",
      "state": "closed",
      "author": "abdullah1308",
      "author_type": "User",
      "created_at": "2025-05-18T12:52:29Z",
      "updated_at": "2025-05-20T17:23:28Z",
      "closed_at": "2025-05-20T17:23:27Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2322/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2322",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2322",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:01.006135",
      "comments": [
        {
          "author": "davidzhao",
          "body": "Hi @abdullah1308, I'm unable to reproduce this. using the above configuration is working fine for me.\n\nmaybe the regional Google deployment doesn't support streaming? that was the main change in the PR that you referenced.. can you try passing in `use_streaming=False` in `google.TTS` constructor?",
          "created_at": "2025-05-18T19:14:14Z"
        },
        {
          "author": "davidzhao",
          "body": "this is also working for me:\n\n```python\nfrom google.cloud import texttospeech\n\ntts=google.TTS(\n            language=\"hi-IN\",\n            voice_name=\"hi-IN-Chirp3-HD-Zephyr\",\n            use_streaming=False,\n            audio_encoding=texttospeech.AudioEncoding.MP3,\n        ),\n```",
          "created_at": "2025-05-18T19:17:12Z"
        },
        {
          "author": "abdullah1308",
          "body": "Strange, I'd faced this issue for an entire day. Closing as it is working as expected now.",
          "created_at": "2025-05-20T17:23:27Z"
        }
      ]
    },
    {
      "issue_number": 2248,
      "title": "Gemini Realtime - Function calls aren't going through while using Vertex AI",
      "body": "When I'm using gemini with Vertex AI the function calls aren't going through. That is the model claims that it's going to call the function but then I don't see any logs of it happening. \n\nFor example I have a tool which checks the knowledge base for relevant results and this is the Bot's transcription:\n\n\"Thanks for the details. Let me check the knowledge base again for those specific specs\". \n\nBut then the backend I see no function calls being made. But I don't see this problem happening while using it without Vertex AI though.\n",
      "state": "closed",
      "author": "Denin-Siby",
      "author_type": "User",
      "created_at": "2025-05-09T08:09:02Z",
      "updated_at": "2025-05-20T15:15:08Z",
      "closed_at": "2025-05-09T18:44:38Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2248/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2248",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2248",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:01.239632",
      "comments": [
        {
          "author": "davidzhao",
          "body": "this has been fixed in #2247",
          "created_at": "2025-05-09T18:44:38Z"
        },
        {
          "author": "Denin-Siby",
          "body": "This is still reproducable @davidzhao , I tried a couple of times using a direct script connecting to gemini without livekit, It looks like the function calls come through as expected there. I use the gemini model: \"gemini-2.0-flash-live-preview-04-09\" with Vertex AI enabled.\n\nThese are the library ",
          "created_at": "2025-05-17T21:04:55Z"
        },
        {
          "author": "davidzhao",
          "body": "I'm unable to reproduce it. function calls are working fine for me using `basic_agent.py` and `gemini-2.0-flash-live-preview-04-09` on VertexAI",
          "created_at": "2025-05-19T05:30:12Z"
        },
        {
          "author": "Denin-Siby",
          "body": "the calls come through @davidzhao , but it's very random how in some sessions it doesn't work but in some it does.\n\nI tried connecting to gemini directly using a script and the function calls while using with Vertex are coming through as expected there. I evaluated it over multiple sessions and was ",
          "created_at": "2025-05-20T11:29:33Z"
        },
        {
          "author": "davidzhao",
          "body": "inconsistent behavior would be an issue with the model itself. we are unable to address that from our side. the logic to vertex vs gemini are exactly the same from the integration side",
          "created_at": "2025-05-20T15:15:03Z"
        }
      ]
    },
    {
      "issue_number": 2325,
      "title": "got errors while building up avatar with bithuman like \"process memory usage is high\" and \"worker is at full capacity",
      "body": "I want to use avatar with bithuman, but got \"process memory usage is high\" and \"worker is at full capacity, marking as unavailable\".\nDo you have any advice?\n\n2025-05-19 14:18:27.262 | INFO     | bithuman.video_graph.navigator:from_workspace:132 - Loading model from /home/ubuntu/albert_einstein.imx\n2025-05-19 14:18:27.791 | INFO     | bithuman.video_graph.video_script:update_runtime_configs:334 - Updated runtime configs from model: {}\n2025-05-19 14:18:27.794 | INFO     | bithuman.runtime:load_data:408 - Loading model data: 1 models and 0 fillers\n2025-05-19 14:18:29,878 - livekit.agents - WARNING - process memory usage is high\n{\"message\": \"process memory usage is high\", \"level\": \"WARNING\", \"name\": \"livekit.agents\", \"memory_usage_mb\": 582.828125, \"memory_warn_mb\": 500, \"memory_limit_mb\": 0, \"pid\": 3526106, \"job_id\": \"XXX\", \"timestamp\": \"2025-05-19T06:18:29.878112+00:00\"}\n2025-05-19 14:18:32.269 | INFO     | bithuman.runtime:load_data:443 - Model data loaded successfully\n2025-05-19 14:18:32,669 - livekit.agents - INFO - worker is at full capacity, marking as unavailable\n{\"message\": \"worker is at full capacity, marking as unavailable\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"load\": 0.8388, \"threshold\": \"_WorkerEnvOption(dev_default=inf, prod_default=0.75)\", \"timestamp\": \"2025-05-19T06:18:32.669676+00:00\"} \n",
      "state": "open",
      "author": "peng2219",
      "author_type": "User",
      "created_at": "2025-05-19T06:51:24Z",
      "updated_at": "2025-05-20T09:19:11Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2325/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2325",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2325",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:01.491974",
      "comments": [
        {
          "author": "ahenawy",
          "body": "Are you running in Docker? What is the system information and avatar worker setup?",
          "created_at": "2025-05-19T07:31:21Z"
        },
        {
          "author": "longcw",
          "body": "The `process memory usage is high` is a warning to indicate the agent is using more RAM than usual, but given you are using an avatar model it's expected, you can increase the warning threshold as in [this example](https://github.com/livekit/agents/blob/livekit-agents%401.0.22/examples/avatar_agents",
          "created_at": "2025-05-19T07:51:32Z"
        },
        {
          "author": "peng2219",
          "body": "> The `process memory usage is high` is a warning to indicate the agent is using more RAM than usual, but given you are using an avatar model it's expected, you can increase the warning threshold as in [this example](https://github.com/livekit/agents/blob/livekit-agents%401.0.22/examples/avatar_agen",
          "created_at": "2025-05-20T09:19:10Z"
        }
      ]
    },
    {
      "issue_number": 2252,
      "title": "How to set outbound proxy in livekit",
      "body": "\nHello ,\nI am using astrarisk so can you tell me how to config my creds in livekit for outbound\n```\nDomain/Proxy: XXXXX.23443.service\nOutbound Proxy: XXXX.hpbx.XXX.com:5060\nUsername: XXX\nPassword: XXXXXXX\n```\nHow to set the outbound proxy in livekit\n",
      "state": "closed",
      "author": "narendra-bluebash",
      "author_type": "User",
      "created_at": "2025-05-09T11:44:56Z",
      "updated_at": "2025-05-20T07:47:24Z",
      "closed_at": "2025-05-20T07:47:24Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2252/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2252",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2252",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:01.700431",
      "comments": [
        {
          "author": "davidzhao",
          "body": "livekit does not require any outbound proxies",
          "created_at": "2025-05-09T20:15:47Z"
        },
        {
          "author": "narendra-bluebash",
          "body": "Hello @davidzhao \nthis creds are working in zoiper fine but am not sure why its not working wiht livekit.\ncan someone have any idea how to set this.",
          "created_at": "2025-05-10T04:28:07Z"
        },
        {
          "author": "davidzhao",
          "body": "our SIP server does not use any outbound proxies.. why is that necessary?",
          "created_at": "2025-05-11T06:08:57Z"
        },
        {
          "author": "narendra-bluebash",
          "body": "I am using SkySwitch and it will not work without outbound proxy.",
          "created_at": "2025-05-12T05:38:35Z"
        }
      ]
    },
    {
      "issue_number": 1041,
      "title": "azue stt cannot work with livekit agent 0.11.1",
      "body": "azue stt cannot work with livekit agent 0.11.1,  but openai stt can with livekit agent 0.11.1\r\n\r\n\r\n",
      "state": "closed",
      "author": "heyanyanchina123",
      "author_type": "User",
      "created_at": "2024-11-05T07:26:23Z",
      "updated_at": "2025-05-20T07:35:21Z",
      "closed_at": "2025-05-20T07:35:21Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1041/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1041",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1041",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:01.925826",
      "comments": [
        {
          "author": "davidzhao",
          "body": "@heyanyanchina123 what issues do you see with Azure STT? Please share logs and/or repro steps",
          "created_at": "2024-11-15T06:21:05Z"
        },
        {
          "author": "theomonnom",
          "body": "Hey we fixed an issue related to Azure STT on v0.11.2\n\nCan you give it a try ",
          "created_at": "2024-11-15T10:02:40Z"
        },
        {
          "author": "adrianyip-1222",
          "body": "I have this issue as well, using `livekit-agents>=0.11.2`\r\n\r\nI've only modified the code from the voice pipeline example. \r\n```\r\n    agent = VoicePipelineAgent(\r\n        vad=ctx.proc.userdata[\"vad\"],\r\n        stt=azure.STT(),\r\n        llm=openai.LLM.with_azure(model=\"gpt-4o-mini\"),\r\n        tts=azur",
          "created_at": "2024-11-19T10:26:42Z"
        }
      ]
    },
    {
      "issue_number": 2301,
      "title": "Deepgram STT latency measurement",
      "body": "I found a recommended latency calculation script from [Deepgram](https://developers.deepgram.com/docs/measuring-streaming-latency)/[script](https://res.cloudinary.com/deepgram/raw/upload/v1681940340/devex/latency_zetbdo.py) that measures the time difference between audio and transcription time cursors. Is this something you'd be open to a PR?\n\nIt reports at the end of the session for max/min/avg latency numbers. But of course, it can be changed to report them periodically and/or with moving weights.\n\n\n",
      "state": "closed",
      "author": "ChenghaoMou",
      "author_type": "User",
      "created_at": "2025-05-15T14:38:36Z",
      "updated_at": "2025-05-19T08:43:15Z",
      "closed_at": "2025-05-19T08:41:18Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2301/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2301",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2301",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:02.186835",
      "comments": [
        {
          "author": "davidzhao",
          "body": "we are currently reporting transcription latency metrics from the [EOUMetrics event](https://docs.livekit.io/agents/build/metrics/#end-of-utterance-eou-). would this be insufficient for you?\n\nI think you can add a callback to compute min/max/avg fairly easily",
          "created_at": "2025-05-18T01:23:03Z"
        },
        {
          "author": "ChenghaoMou",
          "body": "> This event is only available in Realtime APIs when turn_detection is set to either VAD or LiveKit's turn detector plugin.\n\nI thought it's not available when using a standalone STT.",
          "created_at": "2025-05-18T06:57:58Z"
        },
        {
          "author": "ChenghaoMou",
          "body": "Just tested with @session.on(\"metrics_collected\"), it seems that it is emitting that event despite not using a Realtime model. Will close this issue for now. The docs might need some update.\n\nMaybe this would be a good idea for avatar stuff.",
          "created_at": "2025-05-19T08:41:18Z"
        }
      ]
    },
    {
      "issue_number": 2314,
      "title": "Agent 1.0 voice agent does not work properly with some of ARM64 CPUs",
      "body": "I'm running voice agent in EKS with node as - c8g.large, ARM64 based AWS's graviton instance.\nWhen the agent starts, it never receives human speech and it emits below warnings:\n\n`\n2025-05-16 08:20:57 - livekit.agents - WARNING - [RM_po4rSeXLQdTy] Running <Task pending name='job_shutdown_callback' coro=<JobContext.add_shutdown_callback.<locals>.wrapper() running at /usr/local/lib/python3.12/site-packages/livekit/agents/job.py:226> wait_for=<Task pending name='Task-311' coro=<RunnableBindingBase.ainvoke() running at /usr/local/lib/python3.12/site-packages/langchain_core/runnables/base.py:5364> cb=[Task.task_wakeup()]> cb=[gather.<locals>._done_callback() at /usr/local/lib/python3.12/asyncio/tasks.py:767]> took too long: 19.66 seconds\n2025-05-16 08:20:57 - livekit.plugins.silero - WARNING - [RM_po4rSeXLQdTy] inference is slower than realtime\n2025-05-16 08:20:57 - livekit.plugins.silero - WARNING - [RM_po4rSeXLQdTy] inference is slower than realtime\n2025-05-16 08:20:58 - livekit.plugins.silero - WARNING - [RM_po4rSeXLQdTy] inference is slower than realtime\n2025-05-16 08:20:58 - livekit.plugins.silero - WARNING - [RM_po4rSeXLQdTy] inference is slower than realtime\n2025-05-16 08:20:58 - livekit.plugins.silero - WARNING - [RM_po4rSeXLQdTy] inference is slower than realtime\n\n`\nExact same code works fine when the node is AMD64 based node like a C5A machine.\n\nThis suggests that either VAD or agent code does not work properly on ARM64 based processors. But strange part is same code works fine on my local Mac M3 Pro which is ARM64 based.\n\nSo probably some issue related to AWS graviton instances?",
      "state": "open",
      "author": "prasanna4742",
      "author_type": "User",
      "created_at": "2025-05-16T15:21:37Z",
      "updated_at": "2025-05-19T05:03:54Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2314/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2314",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2314",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:02.401300",
      "comments": [
        {
          "author": "davidzhao",
          "body": "the error log is showing that your job shutdown hook is taking too long to complete. And that resource contention is causing silero to fall behind. what are you running in the shutdown hook?",
          "created_at": "2025-05-19T05:03:53Z"
        }
      ]
    },
    {
      "issue_number": 2298,
      "title": "RoomComposite Egress only records the first room, subsequent rooms are not recorded",
      "body": "I'm using RoomComposite Egress from LiveKit to record room sessions. However, only the first room gets recorded successfully. All subsequent rooms do not trigger any recording, even though egress requests are made.\n\n### Details:\n\n- Running in production mode using the start command\n- I've tried launching multiple workers to handle concurrent recordings, but it doesn't help\n- There are no clear errors in the logs — it simply seems like new egress sessions are ignored after the first one\n\n### Expected behavior:\nAll egress requests should be processed, allowing multiple rooms to be recorded either sequentially or concurrently (depending on worker availability).\n\n### Questions:\n\n- Is there a known limitation with handling multiple RoomComposite egress sessions?\n- Is there any additional configuration needed to support multiple room recordings?\n- How can I debug or verify why only the first egress runs?\n\n### Possible bug:\nThis might be a bug related to how RoomComposite egress sessions are managed when multiple requests are made. Any insights or workarounds would be appreciated.\n\n### Source code \n\n```\nasync def entrypoint(ctx: JobContext):\n    logger.info(f\"connecting to room {ctx.room.name}\")\n    \n    prompt_service = PromptService(ctx.room.name)\n    system_prompt = prompt_service.get_system_prompt(ctx.room.name)\n    initial_ctx = llm.ChatContext().append(\n        role=\"system\",\n        text=system_prompt,\n    )\n    await ctx.connect()\n\n    participant = await ctx.wait_for_participant()\n    logger.info(f\"starting voice assistant for participant {participant.identity}\")\n\n    fnc_ctx = AssistantFnc(ctx)\n\n    agent = VoicePipelineAgent(\n        vad=ctx.proc.userdata[\"vad\"],\n        stt=stt_config,\n        llm=llm_config,\n        tts=tts_config,\n        chat_ctx=initial_ctx,\n        allow_interruptions=True, \n        interrupt_speech_duration=0.2,\n        interrupt_min_words=0,\n        min_endpointing_delay=0.2,\n        fnc_ctx=fnc_ctx,\n    )\n    \n    fnc_ctx.set_agent(agent)\n    agent.start(ctx.room, participant)\n\n    await agent.say(hello_message)\n\n    req = api.RoomCompositeEgressRequest(\n        room_name=ctx.room.name,\n        layout=\"grid\",\n        preset=api.EncodingOptionsPreset.H264_720P_30,\n        audio_only=False,\n        segment_outputs=[\n            api.SegmentedFileOutput(\n                filename_prefix=path_filename_prefix,\n                playlist_name=playlist_name,\n                live_playlist_name=live_playlist_name,\n                segment_duration=10,\n                s3=api.S3Upload(\n                    access_key=os.getenv(\"S3_ACCESS_KEY\"),\n                    secret=os.getenv(\"S3_SECRET\"),\n                    region=os.getenv(\"S3_REGION\"),\n                    bucket=os.getenv(\"S3_BUCKET\"),\n                    endpoint=os.getenv(\"S3_ENDPOINT\"),\n                    force_path_style=True,\n                )\n            )\n        ]\n    )\n    res = await lkapi.egress.start_room_composite_egress(req)\n```\n\n## Logs from agent.py \n#### Don't have any logs on livekit server and livekit egress \n```\n2025-05-15 16:08:58,275 - ERROR - root - [PID:77194] [Worker:8252717760] - ('unavailable', 'twirp error unknown: no response from servers')\nTraceback (most recent call last):\n  File \"/Users/back-end/agent.py\", line 402, in entrypoint\n    res = await lkapi.egress.start_room_composite_egress(req)\n  File \"/Users/back-end/venv310/lib/python3.10/site-packages/livekit/api/egress_service.py\", line 44, in start_room_composite_egress\n    return await self._client.request(\n  File \"/Users/back-end/venv310/lib/python3.10/site-packages/livekit/api/twirp_client.py\", line 101, in request\n    raise TwirpError(error_data[\"code\"], error_data[\"msg\"])\nlivekit.api.twirp_client.TwirpError: ('unavailable', 'twirp error unknown: no response from servers')\n('unavailable', 'twirp error unknown: no response from servers')\n2025-05-15 16:08:58,280 - ERROR - asyncio - [PID:77194] [Worker:8252717760] - Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x11e8b9d20>\n2025-05-15 16:08:58,281 - ERROR - asyncio - [PID:77194] [Worker:8252717760] - Unclosed connector\nconnections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x11e8037c0>, 28718.487585125)])']\nconnector: <aiohttp.connector.TCPConnector object at 0x11e8b9d80>\n2025-05-15 16:08:58,275 - ERROR - root - [PID:77194] [Worker:8252717760] - ('unavailable', 'twirp error unknown: no response from servers')\nTraceback (most recent call last):\n  File \"/Users/back-end/agent.py\", line 402, in entrypoint\n    res = await lkapi.egress.start_room_composite_egress(req)\n  File \"/Users/back-end/venv310/lib/python3.10/site-packages/livekit/api/egress_service.py\", line 44, in start_room_composite_egress\n    return await self._client.request(\n  File \"/Users/back-end/venv310/lib/python3.10/site-packages/livekit/api/twirp_client.py\", line 101, in request\n    raise TwirpError(error_data[\"code\"], error_data[\"msg\"])\nlivekit.api.twirp_client.TwirpError: ('unavailable', 'twirp error unknown: no response from servers')\n2025-05-15 16:08:58,281 - DEBUG - livekit.agents - [PID:77194] [Worker:8252717760] - shutting down job task\n```\n",
      "state": "closed",
      "author": "quanhavn",
      "author_type": "User",
      "created_at": "2025-05-15T09:12:52Z",
      "updated_at": "2025-05-18T04:05:24Z",
      "closed_at": "2025-05-18T04:05:23Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2298/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2298",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2298",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:02.661387",
      "comments": [
        {
          "author": "quanhavn",
          "body": "Livekit Server resource \n\n![Image](https://github.com/user-attachments/assets/38fdf768-7cf1-48ca-9b85-d3aae3599bdf)\n\nRedis data: \n\n![Image](https://github.com/user-attachments/assets/2c109a24-5721-4f5e-9065-c19d18e48186)",
          "created_at": "2025-05-15T09:18:37Z"
        },
        {
          "author": "superRookie007",
          "body": "Having similar issue here",
          "created_at": "2025-05-15T23:53:52Z"
        },
        {
          "author": "davidzhao",
          "body": "for self-hosted setup, please refer to Egress & livekit-server logs. this isn't an issue with agents.",
          "created_at": "2025-05-18T04:05:23Z"
        }
      ]
    },
    {
      "issue_number": 1865,
      "title": "MCP Support",
      "body": "Hello Livekit team!\n\nI was wondering if you guys are planning to support the [Model Context Protocol](https://www.anthropic.com/news/model-context-protocol) for LLM tool usage and many more applications. It would be nice to have an MCP client attached to the agent.",
      "state": "closed",
      "author": "ArmanJR",
      "author_type": "User",
      "created_at": "2025-04-02T22:33:44Z",
      "updated_at": "2025-05-17T00:15:42Z",
      "closed_at": "2025-05-07T12:58:03Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1865/reactions",
        "total_count": 9,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 8,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1865",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1865",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:02.893406",
      "comments": [
        {
          "author": "IngLP",
          "body": "+1!",
          "created_at": "2025-04-03T06:51:19Z"
        },
        {
          "author": "theomonnom",
          "body": "Hey,\n\nThis is on our roadmap. While I can't provide a precise ETA, I’d estimate it will happen within the next two months.",
          "created_at": "2025-04-03T09:45:11Z"
        },
        {
          "author": "quancore",
          "body": "+1",
          "created_at": "2025-04-03T14:35:20Z"
        },
        {
          "author": "narendra-bluebash",
          "body": "+1",
          "created_at": "2025-04-18T18:07:36Z"
        },
        {
          "author": "longcw",
          "body": "for anyone interested in using MCP in agents, I created a helper function here to convert a MCPTool to the agent FunctionTool dynamically https://github.com/longcw/home-assistant-mcp-agent/blob/main/mcp_client/mcp_utils.py#L15\n\nI think the agents will support loading function tools from MCP, pydanti",
          "created_at": "2025-04-21T03:45:15Z"
        }
      ]
    },
    {
      "issue_number": 1308,
      "title": "[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1002)",
      "body": "I [could not get the node agent sample working](https://github.com/livekit/agents-js/issues/231), so decided to try the Python version.\r\n\r\nCan't get this working either.\r\n\r\n`.env.local` seems ok, but when running `python3 agent.py dev`, I get the following error again and again:\r\n> 2024-12-28 14:29:00,324 - WARNING livekit.agents - failed to connect to livekit, retrying in 0s: Cannot connect to host <my-app>.livekit.cloud:443 ssl:True [SSLCertVerificationError: (1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1002)')] \r\n\r\nNo information in the docs about this.",
      "state": "closed",
      "author": "jambudipa",
      "author_type": "User",
      "created_at": "2024-12-28T14:33:37Z",
      "updated_at": "2025-05-16T21:27:56Z",
      "closed_at": "2025-01-02T17:36:21Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1308/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1308",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1308",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:03.151503",
      "comments": [
        {
          "author": "jambudipa",
          "body": "I created a minimal Python script to test this conneciton:\r\n```\r\nimport requests\r\nimport sys\r\n\r\nURL = \"https://<my-app>.livekit.cloud\"\r\n\r\ndef main():\r\n    try:\r\n        print(f\"Attempting to connect to {URL} ...\")\r\n        response = requests.get(URL, timeout=10)\r\n        response.raise_for_status()",
          "created_at": "2024-12-28T15:01:21Z"
        },
        {
          "author": "davidzhao",
          "body": "your hostname appear to be dropped in the logs, was that redacted intentionally?\r\n\r\n`Cannot connect to host .livekit.cloud:443`\r\n",
          "created_at": "2024-12-29T02:21:19Z"
        },
        {
          "author": "jambudipa",
          "body": "Yes, intentionally.",
          "created_at": "2024-12-29T03:40:04Z"
        },
        {
          "author": "davidzhao",
          "body": "how are you running this? this error typically shows up when you don't have CA certs installed on the machine. are you on windows?\r\n\r\nperhaps this thread would help: https://stackoverflow.com/questions/51925384/unable-to-get-local-issuer-certificate-when-using-requests",
          "created_at": "2024-12-30T03:39:58Z"
        },
        {
          "author": "jambudipa",
          "body": "I'm sure you're right, but I am not going to investigate. I only looked at Python because I could not get the node working...",
          "created_at": "2024-12-30T05:00:18Z"
        }
      ]
    },
    {
      "issue_number": 2232,
      "title": "Does LiveKit Support OpenTelemetry or Do I Need to Implement My Own Tracing?",
      "body": "**Objective**\nI’m planning to implement end-to-end distributed tracing across the voice pipeline (STT → LLM → TTS → LiveKit) using OpenTelemetry and Jaeger.\n\nQuestion\nIs there any built-in support or library in LiveKit for OpenTelemetry or distributed tracing? Or do I need to manually instrument LiveKit interactions and propagate trace context myself?\n\nWhat I'm Trying to Do\nTrack each user request across services:\n`LiveKit → STT → LLM → TTS`\n\nUse OpenTelemetry for tracing.\n\nExport traces to Jaeger for visualization.\n\nExample use case: Identify which component adds the most latency or fails during a call.\n\n**Bonus**\nIf there’s any example, documentation, or community reference around this — would appreciate a pointer",
      "state": "open",
      "author": "narendra-bluebash",
      "author_type": "User",
      "created_at": "2025-05-08T14:32:25Z",
      "updated_at": "2025-05-16T16:02:16Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2232/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2232",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2232",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:03.373833",
      "comments": [
        {
          "author": "ChenghaoMou",
          "body": "Maybe a duplicate of #2260 ",
          "created_at": "2025-05-16T16:02:15Z"
        }
      ]
    },
    {
      "issue_number": 2302,
      "title": "Tool failed to initialise with complex nullable params",
      "body": "<!--\nHello! Thanks for taking the time to file a bug report.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already reported this issue.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n-->\n\nWhen decorating a Agent method with a complex parameter my program crashes at the [line 162 in `livekit/agents/llm/_strict.py`](https://github.com/livekit/agents/blob/e57f6a0a4cf07190ca4b60aff6acdadc2cebce90/livekit-agents/livekit/agents/llm/_strict.py#L162):\n\n```log\n    t = non_null[\"type\"]\n        ~~~~~~~~^^^^^^^^\nKeyError: 'type'\n```\n\nA toy example:\n```py\n@dataclass\nclass MyParam:\n    x: int\n    y: int | None = None\n    z: list[int] = field(default_factory=list)\n\nclass MyAgent(BaseAgent):\n    ...\n\n    @function_tool\n    async def my_tool(self, my_param: MyParam | None):\n        ...\n\ndef entrypoint():\n    ...\n    session = AgentSession(\n        llm=openai.LLM(model=\"gpt-4o-mini\"),\n        ...,\n    )\n```\n\nThe issue does not occur when using a realtime model.\n```py\ndef entrypoint():\n    ...\n    session = AgentSession(\n        # No problem\n        llm=openai.realtime.RealtimeModel(),\n    )\n```\n\nI tried using regular Python classes, Pydantic models, TypedDicts, and dataclasses but nothing worked.\n\nI found out the line where the crash happened relate to an optimisation. Removing these lines seem to have fixed the issue: https://github.com/livekit/agents/blob/e57f6a0a4cf07190ca4b60aff6acdadc2cebce90/livekit-agents/livekit/agents/llm/_strict.py#L152-L169",
      "state": "open",
      "author": "dvschuyl",
      "author_type": "User",
      "created_at": "2025-05-15T16:00:52Z",
      "updated_at": "2025-05-16T09:08:25Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2302/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2302",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2302",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:03.589786",
      "comments": [
        {
          "author": "longcw",
          "body": "It seems that in that case the `variants` is `[{'$ref': '#/$defs/MyParam'}, {'type': 'null'}]` cc @theomonnom ",
          "created_at": "2025-05-16T09:08:23Z"
        }
      ]
    },
    {
      "issue_number": 2168,
      "title": "Feature Request: Add Dynamic Control for Chat Input and Interruption Settings During Session",
      "body": "\nCurrently, during a session, it's possible to dynamically disable audio input using:\n\n```python\nself.session.input.set_audio_enabled(False)\n```\n\nHowever, I couldn’t find a similar method to dynamically disable **chat input** during a session.\n\nAdditionally, while it's possible to control interruptions using the `allow_interruptions` parameter in `agent.say()` or `agent.generate_reply()`, there doesn’t appear to be a global or session-wide method to update this dynamically. I would expect `update_options()` to handle such settings, but currently, it seems unimplemented.\n\n**Feature Requests**:\n1. **Chat Input Toggle**: Introduce a method like `self.session.input.set_chat_enabled(False)` to dynamically disable chat input.\n2. **Global Interruption Control**: Provide a way to update the interruption behavior dynamically—possibly via `self.session.update_options()` or a similar method.\n\n**Use Case**:\nThese capabilities would be useful in controlling user interaction dynamically based on the flow or logic of the conversation.\n\n**Current Workarounds**:\n- Audio input can be disabled.\n- Interruption control is only available on a per-message basis.",
      "state": "closed",
      "author": "hsjun99",
      "author_type": "User",
      "created_at": "2025-04-30T14:06:05Z",
      "updated_at": "2025-05-16T08:39:33Z",
      "closed_at": "2025-05-16T08:39:33Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2168/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2168",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2168",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:03.816453",
      "comments": [
        {
          "author": "longcw",
          "body": "You can set the `allow_interruptions` through `session.options.allow_interruptions`.\n\nFor chat input, I assume you mean the text input, one solution is you create a custom `text_input_cb` for the room_output_options following https://github.com/livekit/agents/blob/livekit-agent%401.0.20/livekit-agen",
          "created_at": "2025-05-13T12:52:08Z"
        },
        {
          "author": "hsjun99",
          "body": "Thank you for the reply.\nThis makes sense. I will go and try with this method.",
          "created_at": "2025-05-13T13:03:39Z"
        },
        {
          "author": "hsjun99",
          "body": "Is there a plan to update the `update_options()` function?\nCurrently it is empty.",
          "created_at": "2025-05-13T13:04:47Z"
        }
      ]
    },
    {
      "issue_number": 2284,
      "title": "Google TTS has streaming disabled",
      "body": "Google Chirp 3 HD voices, natively support streaming but the google plugin is limited to calling it in batch mode with streaming=False in the constructor.\n\nhttps://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-google/livekit/plugins/google/tts.py",
      "state": "closed",
      "author": "galigutta",
      "author_type": "User",
      "created_at": "2025-05-13T17:57:28Z",
      "updated_at": "2025-05-16T06:03:54Z",
      "closed_at": "2025-05-16T06:03:54Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2284/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2284",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2284",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:04.062080",
      "comments": [
        {
          "author": "longcw",
          "body": "Seems related to this one https://github.com/livekit/agents/pull/2143?",
          "created_at": "2025-05-14T08:41:34Z"
        },
        {
          "author": "galigutta",
          "body": "Sounds like it. What would be the ETA on this.",
          "created_at": "2025-05-14T12:30:43Z"
        }
      ]
    },
    {
      "issue_number": 2099,
      "title": "AWS STT (Transcribe) Timeout",
      "body": "## Description\nWhen using AWS Transcribe with LiveKit Agents, the STT service times out after 15 seconds and stops transcribing. This creates an issue for my use case where I need to play a required legal consent message (~20 seconds long) before user interaction begins. Users cannot interrupt this message, but the transcription service stops and further interactions are hampered.\n\n## Environment\n\nLiveKit Agent Version: 1.0.11\nAWS STT Version: 1.0.11\n\n## Steps to Reproduce\n\n1. Initialize a LiveKit Agent with AWS Transcribe as the STT provider\n2. Begin a session that starts with a mandatory legal consent message (approximately 20 seconds in duration)\n3. Observe that AWS Transcribe stops transcribing after approximately 15 seconds\n\n## Expected Behavior\n\n[error_log.txt](https://github.com/user-attachments/files/19881789/error_log.txt)\n\nAWS Transcribe should continue transcribing post the duration of the consent message (full 20+ seconds) without timing out.\n\n## Actual Behavior\n\nAWS Transcribe times out after 15 seconds and stops transcribing.\n\n## Additional Context\n\nThis is particularly problematic for my application which must deliver complete legal consent messages without interruption for compliance reasons. The consent message cannot be shortened due to legal requirements.",
      "state": "closed",
      "author": "NIGAMAR",
      "author_type": "User",
      "created_at": "2025-04-24T03:23:36Z",
      "updated_at": "2025-05-16T05:40:27Z",
      "closed_at": "2025-05-16T05:40:27Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2099/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2099",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2099",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:04.326618",
      "comments": [
        {
          "author": "davidzhao",
          "body": "thanks for bringing this to our attention.. I think we need to keep the connection alive somehow. will take a look",
          "created_at": "2025-04-24T19:48:16Z"
        },
        {
          "author": "yepher",
          "body": "User is using:\n\n```\nlivekit==1.0.6\nlivekit-agents==1.0.17\nlivekit-api==1.0.2\nlivekit-plugins-aws==1.0.17\nlivekit-plugins-cartesia==1.0.17\nlivekit-plugins-deepgram==1.0.17\nlivekit-plugins-openai==1.0.17\nlivekit-plugins-silero==1.0.17\nlivekit-plugins-speechmatics==1.0.17\nlivekit-plugins-turn-detector=",
          "created_at": "2025-04-28T13:23:29Z"
        },
        {
          "author": "NikoLandgraf",
          "body": "I have the same issue! Thanks for checking.",
          "created_at": "2025-04-28T17:34:17Z"
        },
        {
          "author": "bhalothia",
          "body": "Yes, we are facing the same.",
          "created_at": "2025-04-28T21:24:48Z"
        },
        {
          "author": "NIGAMAR",
          "body": "@davidzhao any updates on this ?",
          "created_at": "2025-05-02T16:47:17Z"
        }
      ]
    },
    {
      "issue_number": 2303,
      "title": "text chat input is not working",
      "body": "I'm trying to make a text chat input work with the new releases, nothing works so far. What I tried:\n1. examples/other/text_only.py + agents-playground\n2. examples/other/text_only.py + custom frontend sending both stream and single messages according to https://docs.livekit.io/home/client/data/text-streams/\n3. custom agent registering text topic 'chat' + custom frontend sending text messages/streams there\n\nI think option 1 is a solid start for debugging, this is just a standard example that should \"just work\"\n\nmy env:\n```\nlivekit==1.0.7\nlivekit-agents==1.0.21\nlivekit-api==1.0.2\nlivekit-plugins-openai==1.0.21\nlivekit-plugins-silero==1.0.21\nlivekit-protocol==1.0.2\n```\n\nagents-playground from main branch (575da78)",
      "state": "closed",
      "author": "mrdrprofuroboros",
      "author_type": "User",
      "created_at": "2025-05-15T18:29:43Z",
      "updated_at": "2025-05-15T22:52:50Z",
      "closed_at": "2025-05-15T22:52:49Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2303/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2303",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2303",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:04.547585",
      "comments": [
        {
          "author": "mrdrprofuroboros",
          "body": "OK, this was a very weird implication of mac firewall: it blocked incoming text topics while passing both outgoing text topics and bidirectional audio O_o\n\ndebug checklist:\n- brew upgrade livekit\n- use this to debug https://livekit.io/connection-test\n- use vanilla chrome with all extensions turned o",
          "created_at": "2025-05-15T22:52:49Z"
        }
      ]
    },
    {
      "issue_number": 2203,
      "title": "weather_agent.py sample fails with aws plugins",
      "body": "The weather_agent.py sample fails with aws plugins (llm, stt, and tts). Below is the error log:\n\nERROR livekit.agents - tried to call AI function `get_weather` with invalid arguments\nTraceback (most recent call last):\n  File \"...//myvenv/lib/python3.13/site-packages/livekit/agents/voice/generation.py\", line 336, in _execute_tools_task\n    fnc_args, fnc_kwargs = llm_utils.prepare_function_arguments(\n                           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        fnc=function_tool,\n        ^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        ),\n        ^^\n    )\n    ^\n  File \"...//myvenv/lib/python3.13/site-packages/livekit/agents/llm/utils.py\", line 357, in prepare_function_arguments\n    model = model_type.model_validate(args_dict)  # can raise ValidationError\n  File \"...//myvenv/lib/python3.13/site-packages/pydantic/main.py\", line 703, in model_validate\n    return cls.__pydantic_validator__.validate_python(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        obj, strict=strict, from_attributes=from_attributes, context=context, by_alias=by_alias, by_name=by_name\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\npydantic_core._pydantic_core.ValidationError: 2 validation errors for GetWeatherArgs\nlatitude\n  Input should be a valid string [type=string_type, input_value=34.25, input_type=float]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\nlongitude\n  Input should be a valid string [type=string_type, input_value=-85.28, input_type=float]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type {\"room_name\": \"voice_assistant_room_5256\", \"user_id\": \"your user_id\", \"function\": \"get_weather\", \"arguments\": \"{\\\"latitude\\\":34.25,\\\"longitude\\\":-85.28}\", \"speech_id\": \"speech_af7fefdc3409\", \"pid\": 83802, \"job_id\": \"AJ_iFAfuvpSZyz2\"}\n2025-05-05 11:56:24,907 - ERROR livekit.plugins.aws - Error in handle_transcript_events\nTraceback (most recent call last):\n  File \"...//myvenv/lib/python3.13/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"...//myvenv/lib/python3.13/site-packages/livekit/plugins/aws/stt.py\", line 184, in handle_transcript_events\n    async for event in stream.output_stream:\n        if isinstance(event, TranscriptEvent):\n            self._process_transcript_event(event)\n  File \"...//myvenv/lib/python3.13/site-packages/amazon_transcribe/eventstream.py\", line 666, in __aiter__\n    parsed_event = self._parser.parse(event)\n  File \"...//myvenv/lib/python3.13/site-packages/amazon_transcribe/deserialize.py\", line 161, in parse\n    raise self._parse_event_exception(raw_event)\namazon_transcribe.exceptions.BadRequestException: Your request timed out because no new audio was received for 15 seconds. {\"room_name\": \"voice_assistant_room_5256\", \"user_id\": \"your user_id\", \"pid\": 83802, \"job_id\": \"AJ_iFAfuvpSZyz2\"}\n2025-05-05 11:56:24,911 - ERROR livekit.agents - Error in _stt_task\nTraceback (most recent call last):\n  File \"...//myvenv/lib/python3.13/site-packages/livekit/agents/stt/stt.py\", line 337, in __anext__\n    val = await self._event_aiter.__anext__()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nStopAsyncIteration\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"...//myvenv/lib/python3.13/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"...//myvenv/lib/python3.13/site-packages/livekit/agents/voice/audio_recognition.py\", line 299, in _stt_task\n    async for ev in node:\n        assert isinstance(ev, stt.SpeechEvent), \"STT node must yield SpeechEvent\"\n        await self._on_stt_event(ev)\n  File \"...//myvenv/lib/python3.13/site-packages/livekit/agents/voice/agent.py\", line 420, in stt_node\n    async for event in stream:\n        yield event\n  File \"...//myvenv/lib/python3.13/site-packages/livekit/agents/stt/stt.py\", line 340, in __anext__\n    raise exc  # noqa: B904\n    ^^^^^^^^^\n  File \"...//myvenv/lib/python3.13/site-packages/livekit/agents/stt/stt.py\", line 228, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"...//myvenv/lib/python3.13/site-packages/livekit/plugins/aws/stt.py\", line 193, in _run\n    await asyncio.gather(*tasks)\n  File \"...//myvenv/lib/python3.13/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"...//myvenv/lib/python3.13/site-packages/livekit/plugins/aws/stt.py\", line 184, in handle_transcript_events\n    async for event in stream.output_stream:\n        if isinstance(event, TranscriptEvent):\n            self._process_transcript_event(event)\n  File \"...//myvenv/lib/python3.13/site-packages/amazon_transcribe/eventstream.py\", line 666, in __aiter__\n    parsed_event = self._parser.parse(event)\n  File \"...//myvenv/lib/python3.13/site-packages/amazon_transcribe/deserialize.py\", line 161, in parse\n    raise self._parse_event_exception(raw_event)\namazon_transcribe.exceptions.BadRequestException: Your request timed out because no new audio was received for 15 seconds. {\"room_name\": \"voice_assistant_room_5256\", \"user_id\": \"your user_id\", \"pid\": 83802, \"job_id\": \"AJ_iFAfuvpSZyz2\"}",
      "state": "closed",
      "author": "sunilvb",
      "author_type": "User",
      "created_at": "2025-05-05T16:06:19Z",
      "updated_at": "2025-05-15T18:27:01Z",
      "closed_at": "2025-05-15T18:27:00Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2203/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2203",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2203",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:04.774444",
      "comments": [
        {
          "author": "sunilvb",
          "body": "The quick start sample works fine with aws plugins (llm, tts, and stt). I think there is an issue with function_tool implementation when using the aws plugins. below is my changed code in weather_agent.py\n\n```\nclass WeatherAgent(Agent):\n    def __init__(self) -> None:\n        super().__init__(\n     ",
          "created_at": "2025-05-05T16:16:02Z"
        },
        {
          "author": "jayeshp19",
          "body": "> Input should be a valid string [type=string_type, input_value=34.25, input_type=float]\n\nIt looks like Aws llm model is sending arguments as float instead of string\n",
          "created_at": "2025-05-06T07:18:36Z"
        },
        {
          "author": "sunilvb",
          "body": "Yes, but should this not be validate in the plugin code? or are you suggestion this should be done in the agent code? if yes, how?",
          "created_at": "2025-05-06T17:23:52Z"
        },
        {
          "author": "jayeshp19",
          "body": "it's more of model hallucination problem, you're getting an error because this is getting validated. can you try switching to `float` instead of `str` in arguments?",
          "created_at": "2025-05-07T10:09:05Z"
        },
        {
          "author": "sunilvb",
          "body": "done.",
          "created_at": "2025-05-15T18:27:00Z"
        }
      ]
    },
    {
      "issue_number": 2277,
      "title": "TTS voice cracking with background music after v1.0.18 update",
      "body": "### **Describe the bug**\nSince updating the livekit-agent to version 1.0.18, the Text-to-Speech (TTS) voice produces a cracking or distorted sound when background music is active. This issue was not present in version 1.0.17 and below.\nIt is most easily reproducible with Elevenlabs TTS.\n[Recorded Audio File](https://drive.google.com/file/d/1k0-FVaXnZ9jYBDwqBdrrveOgIdwVxX-_/view?usp=sharing)\n\n### **Suspected Commit**\nI highly suspect this commit might be related to the bug: 4ec66be66a5bd3e552c7b0a4a69a8ddc1cc2028f\n\n### **To Reproduce**\nSteps to reproduce the behavior:\n\n1. Initialize and start background music using code similar to the snippet below.\n2. Have the agent speak using TTS. (elevenlabs)\n3. Observe the cracking sound in the TTS audio output.\n\n### **Code Snippet**\n```\naudio_iterator = await bgm_service.get_audio(\n    self.agent_config.data.call_settings.background_music\n)\n\nbackground_audio = BackgroundAudioPlayer(\n    ambient_sound=AudioConfig(\n        audio_iterator,\n        volume=self.agent_config.data.call_settings.background_music_volume,\n    ),\n)\n\nawait background_audio.start(\n    room=self.livekit_sdk_service.room,\n    agent_session=session,\n)\n```\n\n### **Expected behavior**\nThe TTS voice should be clear and without any cracking or distortion, even when background music is playing, as it was in version 1.0.17.\n\n### **Environment:**\n\nLiveKit Agent Version: 1.0.18\nInfrastructure: Google Kubernetes Engine (GKE)\nResource Allocation:\nRequests:\nCPU: \"3\"\nMemory: \"10Gi\"\nLimits:\nCPU: \"3.5\"\nMemory: \"13Gi\"\n\n### **Additional context**\nIt has been observed that the lower the allocated resources, the more pronounced the cracking noise becomes. This might suggest a performance regression or a resource contention issue introduced in the recent update.",
      "state": "closed",
      "author": "hsjun99",
      "author_type": "User",
      "created_at": "2025-05-13T12:55:39Z",
      "updated_at": "2025-05-15T12:50:54Z",
      "closed_at": "2025-05-14T06:26:10Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2277/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2277",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2277",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:05.017817",
      "comments": [
        {
          "author": "yepher",
          "body": "Please retest with with >= 1.0.19. There were a few issues in 1.0.18 that got fixed in 1.0.19.",
          "created_at": "2025-05-13T13:26:36Z"
        },
        {
          "author": "hsjun99",
          "body": "Actually the issue persists even after the latest 1.0.20 update.\nSo I manually tracked down and found that 1.0.17 is the only one with no bug regarding this issue.",
          "created_at": "2025-05-13T13:30:56Z"
        },
        {
          "author": "longcw",
          "body": "What if you switch to other TTS like the cartesia, or openai with different `response_format` like `mp3`, `opus`, or `wav`. We had some change in audio decoding in 1.0.18, would like to understand if your issue is related to the different audio encoding formats.",
          "created_at": "2025-05-13T14:31:10Z"
        },
        {
          "author": "hsjun99",
          "body": "I haven't yet tested all possible variations or other response_format options for each provider.\n\nHere's a summary of TTS provider tests with their default encodings:\n\nElevenLabs: mp3_22050_32 - Not working (Bug)\nCartesia: pcm_s16le - Works fine\nOpenAI: opus - Not working (Bug)\nGoogle: LINEAR_16 - W",
          "created_at": "2025-05-13T14:59:54Z"
        },
        {
          "author": "longcw",
          "body": "@hsjun99 we reverted the changes in decoder https://github.com/livekit/agents/pull/2286, feel free to reopen if the issue is still there.",
          "created_at": "2025-05-14T07:50:27Z"
        }
      ]
    },
    {
      "issue_number": 1312,
      "title": "Support strict openai function calls",
      "body": "Recent OpenAI models have a feature called [strict function calls](https://platform.openai.com/docs/guides/function-calling#structured-outputs), which improves the way LLM invokes tools.\r\nIt would be nice to support this feature in the corresponding LK agent.",
      "state": "closed",
      "author": "mykola-mokhnach-parloa",
      "author_type": "User",
      "created_at": "2024-12-30T08:37:41Z",
      "updated_at": "2025-05-15T09:09:10Z",
      "closed_at": "2025-05-15T09:09:10Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1312/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1312",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1312",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:05.277169",
      "comments": [
        {
          "author": "themusicman",
          "body": "Looks like it already does. Which is causing an issue with xAI since they don't support it.",
          "created_at": "2025-05-09T12:09:01Z"
        }
      ]
    },
    {
      "issue_number": 2281,
      "title": "Neuphonic and Cartesia websockets raise an error after long periods of silence",
      "body": "To recreate\n1. Follow the [Voice AI Quickstart](https://docs.livekit.io/agents/start/voice-ai/) guide on the docs to create a simple chat room.\n2. Use either Neuphonic or Cartesia as the TTS.\n3. Start the room with `python main.py dev` and connect to the room using the LiveKit agents playground in the browser.\n4. Let the Agent greet you. Give it a response. Let the agent speak its response. Then go silent for about a minute.\n5. Speak to the Agent.\n6. You will see the attached errors in your console (see below). See attachments `neuphonic_error.log` and `cartesia_error.log`. In the Cartesia case, the chatbot does not break, the warning is raised in the console but the chatbot continues to speak. In the Neuphonic case, this error breaks the chatbot. The user needs to wait a few seconds and speak again before the chatbot actually responds.\n\n**neuphonic_error.log**\n```\n2025-05-13 15:04:51,577 - ERROR livekit.agents - Error in _inference_task\nTraceback (most recent call last):\n  File \"/Users/adnansiddiquei/Desktop/Neuphonic/tmp/test/Mar25/my-app/.venv/lib/python3.12/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/adnansiddiquei/Desktop/Neuphonic/tmp/test/Mar25/my-app/.venv/lib/python3.12/site-packages/livekit/agents/voice/generation.py\", line 142, in _inference_task\n    async for audio_frame in tts_node:\n  File \"/Users/adnansiddiquei/Desktop/Neuphonic/tmp/test/Mar25/my-app/.venv/lib/python3.12/site-packages/livekit/agents/voice/agent.py\", line 473, in tts_node\n    async for ev in stream:\n  File \"/Users/adnansiddiquei/Desktop/Neuphonic/tmp/test/Mar25/my-app/.venv/lib/python3.12/site-packages/livekit/agents/tts/tts.py\", line 449, in __anext__\n    raise exc from None\n  File \"/Users/adnansiddiquei/Desktop/Neuphonic/tmp/test/Mar25/my-app/.venv/lib/python3.12/site-packages/livekit/agents/tts/tts.py\", line 301, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/adnansiddiquei/Desktop/Neuphonic/tmp/test/Mar25/my-app/.venv/lib/python3.12/site-packages/livekit/plugins/neuphonic/tts.py\", line 406, in _run\n    await asyncio.gather(*tasks)\n  File \"/Users/adnansiddiquei/Desktop/Neuphonic/tmp/test/Mar25/my-app/.venv/lib/python3.12/site-packages/livekit/plugins/neuphonic/tts.py\", line 369, in _recv_task\n    msg = await ws.receive()\n          ^^^^^^^^^^^^^^^^^^\n  File \"/Users/adnansiddiquei/Desktop/Neuphonic/tmp/test/Mar25/my-app/.venv/lib/python3.12/site-packages/aiohttp/client_ws.py\", line 378, in receive\n    await self.pong(msg.data)\n  File \"/Users/adnansiddiquei/Desktop/Neuphonic/tmp/test/Mar25/my-app/.venv/lib/python3.12/site-packages/aiohttp/client_ws.py\", line 234, in pong\n    await self._writer.send_frame(message, WSMsgType.PONG)\n  File \"/Users/adnansiddiquei/Desktop/Neuphonic/tmp/test/Mar25/my-app/.venv/lib/python3.12/site-packages/aiohttp/_websocket/writer.py\", line 125, in send_frame\n    raise ClientConnectionResetError(\"Cannot write to closing transport\")\naiohttp.client_exceptions.ClientConnectionResetError: Cannot write to closing transport {\"pid\": 37493, \"job_id\": \"AJ_5CNjE4PiUSTQ\"}\n```\n\n**cartesia_error.log**\n```\n2025-05-13 15:11:57,596 - WARNING livekit.agents - failed to synthesize speech, retrying in 0.1s\nTraceback (most recent call last):\n  File \"/Users/adnansiddiquei/Desktop/Neuphonic/tmp/test/Mar25/my-app/.venv/lib/python3.12/site-packages/livekit/agents/tts/tts.py\", line 301, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/adnansiddiquei/Desktop/Neuphonic/tmp/test/Mar25/my-app/.venv/lib/python3.12/site-packages/livekit/plugins/cartesia/tts.py\", line 381, in _run\n    await asyncio.gather(*tasks)\n  File \"/Users/adnansiddiquei/Desktop/Neuphonic/tmp/test/Mar25/my-app/.venv/lib/python3.12/site-packages/livekit/plugins/cartesia/tts.py\", line 346, in _recv_task\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: Cartesia connection closed unexpectedly (status_code=-1, request_id=ee83f4cc6433, body=None) {\"tts\": \"livekit.plugins.cartesia.tts.TTS\", \"attempt\": 1, \"streamed\": true, \"pid\": 41926, \"job_id\": \"AJ_UQWK5WHYVMJS\"}\n```",
      "state": "closed",
      "author": "adnansiddiquei",
      "author_type": "User",
      "created_at": "2025-05-13T15:42:21Z",
      "updated_at": "2025-05-15T02:28:55Z",
      "closed_at": "2025-05-15T02:28:55Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2281/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2281",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2281",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:05.512581",
      "comments": []
    },
    {
      "issue_number": 2278,
      "title": "False Interim Transcriptions Segments Bug Causing Broken Chat Items",
      "body": "Hi everyone,\nSince I moved to v1.0, something weird started happening with transcriptions\n\nThis issue is reproducible on 1.0.20 and probably lower (livekit agents and deepgram plugin)\n\nI'm using Deepgram STT with interim transcriptions\nThe issue was not reproducing on other providers that I've tried\n\nHere is my frontend code that captures 'lk.transcription':\n```\nthis.room?.registerTextStreamHandler('lk.transcription', async (reader, participantInfo) => {\n        const { data } = useAuth();\n        const userEmail = data?.value?.user?.email;\n\n        console.log('segmentId', segmentId, reader.info.attributes[\"lk.transcription_final\"]);\n        for await (const chunk of reader) {\n          console.log('chunk', chunk);\n          if (userEmail && participantInfo.identity === userEmail) {\n            processMessageV2(segmentId, chunk, 'human');\n          } else {\n            processMessageV2(segmentId, chunk, 'bot');\n          }\n        }\n      });\n```\n\nBasically, captures user transcriptions and adds them to the chat on the frontend. \n`processMessageV2` function decides how to add the newly incoming chunk: \n1. If the segment ID of a new chunk was already in the chat, it replaces it with a new chunk text, since it is supposed to be updated interim result (e.g., `{\"segment_id\": \"SG_123\", \"text\": \"Hello\"}, {\"segment_id\": \"SG_123\", \"text\": \"Hello, how\"}, {\"segment_id\": \"SG_123\", \"text\": \"Hello, how are you?\"}`)\n2. If the segment ID of a new chunk was never in the chat before, it adds a new chat item, since it doesn't contain parts of previous chunks.\n\nIn most cases, it works well. However, consider the following case:\n\nI tried to say something like this to an Agent: \"That sounds incredibly frustrating! Dealing with intermittent bugs can be really draining...\"\n\nThe console logs are:\n\n<img width=\"465\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/57462e05-2d68-40aa-a42d-b0473c476d83\" />\n\nAnd the chat on the frontend looks like this:\n\n<img width=\"425\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/0ecb45fb-e957-48e8-9efd-4090b6dc4b70\" />\n\nAs you can see in the logs, \"That sounds incredibly frustrating! Dealing with\" was actually transcribed by the STT (and even appeared in the chat for a couple of seconds). However, it was violently replaced by the \"internal bugs\".\n\nThis happened because the \"internal bugs\" chunk had the same segment ID in the reader info as all the previous interim transcriptions, without including the previous chunks' text. And then normal transcription was continued.\n\nSo I'm generally confused about what identifier to use now to understand when to ADD a new chat item and when to REPLACE previous ones on interim results. \n\nPreviously, on v0.x, transcriptions had the ID, which worked perfectly in this scenario. \n\nI double-checked both Deepgram plugin's SpeechStream and stt_node and found that the `reader.info.attributes[\"lk.transcription_final\"]` seems to be misleading. The chunks classified as \"final\" are often returned on the frontend as non-final.\n\nSo, for me, it seems to be an issue with the layer above the stt_node, which is packing the STT Events in segments for the frontend.\n\nReproducibility of this issue is ~10%, increasing with long inputs (3-5 sentences). However, in real conversations I found this quite often, which really breaks the experience. \n\nI also found kinda similar issue with long audio inputs on [Retell.AI](https://www.retellai.com/) interface. I'm not sure if these issues are directly related, but their transcriptions often disappear on long inputs. \n\nLooking forward to your thoughts on this\nLet me know if you need any more info!",
      "state": "closed",
      "author": "dimasimonowich",
      "author_type": "User",
      "created_at": "2025-05-13T13:51:05Z",
      "updated_at": "2025-05-15T02:28:30Z",
      "closed_at": "2025-05-15T02:28:30Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2278/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2278",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2278",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:05.512602",
      "comments": [
        {
          "author": "longcw",
          "body": "Thanks for reporting this! It should be fixed in https://github.com/livekit/agents/pull/2279",
          "created_at": "2025-05-13T15:03:03Z"
        }
      ]
    },
    {
      "issue_number": 2290,
      "title": "Using livekit.agents.voice_assistant and it shows up as modulenotfound",
      "body": "\nI'm making a voice AI assistant, I'm using livekit ofc but I'm facing  issues with the module\n\n![Image](https://github.com/user-attachments/assets/35a2c65c-7b1c-405b-af02-c132359d575b)\n\nI'm looking for an alternative unless there's a way to get this issue fixed ",
      "state": "closed",
      "author": "joshkinght",
      "author_type": "User",
      "created_at": "2025-05-14T15:18:26Z",
      "updated_at": "2025-05-14T15:48:28Z",
      "closed_at": "2025-05-14T15:48:27Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2290/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2290",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2290",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:07.672265",
      "comments": [
        {
          "author": "longcw",
          "body": "There is no VoiceAssistant class, please check the [examples](https://github.com/livekit/agents?tab=readme-ov-file#simple-voice-agent) or [docs](https://docs.livekit.io/agents/build/).\n\nI'd like to know where you get this? there are some duplicated issues https://github.com/livekit/agents/issues/222",
          "created_at": "2025-05-14T15:48:27Z"
        }
      ]
    },
    {
      "issue_number": 2288,
      "title": "lk.transcription_final attribute is never \"true\" in the TTS transcription",
      "body": "The TTS \"lk.transcription\" stream never returns `true` in the `lk.transcription_final` attribute.\n\nWe are using these packages:\n\n- livekit-client@2.11.4\n- livekit-agent@1.0.20\n\n<img width=\"1118\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e7f3603a-6a15-4a70-8c75-3aee3d942e2e\" />",
      "state": "closed",
      "author": "brianzaubar",
      "author_type": "User",
      "created_at": "2025-05-14T13:25:45Z",
      "updated_at": "2025-05-14T14:13:54Z",
      "closed_at": "2025-05-14T14:13:54Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2288/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2288",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2288",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:07.886471",
      "comments": [
        {
          "author": "longcw",
          "body": "For agent transcription, `lk.transcription_final` attribute is set to true when the stream closed. You can read it after text stream closed.\n\nBasically for agent transcription, it's streamed as delta so every text stream is final. The final flag is mainly for the user transcription which may be inte",
          "created_at": "2025-05-14T13:37:56Z"
        }
      ]
    },
    {
      "issue_number": 2271,
      "title": "GatheringFuture CancelledError in Deepgram STT when using Push-to-Talk",
      "body": "After enabling Push-to-Talk (PTT) in our LiveKit Agents setup, we started seeing unhandled asyncio.CancelledError exceptions in the Deepgram STT plugin. This error did not occur when running without PTT.\n\nSteps to reproduce\n\nInstall and run a LiveKit Agents voice bot with Deepgram STT and PTT enabled.\n\nConnect a participant and use the “start_turn” and “end_turn” RPCs to push and release talk.\n\nWatch the server logs for repeated entries like:\n\nvbnet\nCopiar código\nERROR:asyncio:_GatheringFuture exception was never retrieved\nfuture: <_GatheringFuture finished exception=CancelledError()>\nTraceback (most recent call last):\n  File \".../livekit/plugins/deepgram/stt.py\", line 536, in recv_task\n    msg = await ws.receive()\n  ...\nasyncio.exceptions.CancelledError\nExpected behavior\nWhen PTT ends the speech turn, the Deepgram websocket should close cleanly without logging unhandled CancelledError exceptions.\n\nActual behavior\nThe STT recv_task coroutine is cancelled when the websocket closes, but the CancelledError bubbles up and is logged as an unhandled exception.\n\nEnvironment\nWe are running on Python 3.11 with these key package versions (full requirements.txt attached):\n\nlivekit==1.0.6\n\nlivekit-agents==1.0.20\n\nlivekit-plugins-deepgram==1.0.19\n\naiohttp==3.10.11\n\nhttpx==0.28.1\n\ndeepgram-sdk==3.7.7\n\nAdditional context\n\nPTT audio start/stop behavior is working correctly.\n\nThe same Deepgram STT configuration in continuous-listen mode (no PTT) does not produce any errors.\n\nWe have a small monkey-patch on aiohttp.ClientSession.__init__ only to drop an unsupported proxy kwarg; it does not affect websocket behavior.\n\nPlease let me know if you need any more information or a minimal repro repository.",
      "state": "closed",
      "author": "JeisonNovoa",
      "author_type": "User",
      "created_at": "2025-05-12T19:08:19Z",
      "updated_at": "2025-05-14T07:41:43Z",
      "closed_at": "2025-05-14T07:41:43Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2271/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2271",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2271",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:08.121346",
      "comments": [
        {
          "author": "longcw",
          "body": "The error is raised when we reset the stt in `clear_user_turn`. We reset it by closing the old one then creating a new one.\n\nThe stt may raise this error since it was not closed gracefully. So it shouldn't affect anything but I'll try to make the reset more graceful.\n",
          "created_at": "2025-05-13T01:21:43Z"
        }
      ]
    },
    {
      "issue_number": 2274,
      "title": "WebSocket closes with code 1011 when using google.beta.realtime.RealtimeModel",
      "body": "When the agent tries to hold a Gemini-Live streaming session, the socket is closed by the server with code 1011 (Internal error).\nAccording to RFC 6455 this code means “server encountered an unexpected condition” \n[Kapeli](https://kapeli.com/cheat_sheets/WebSocket_Status_Codes.docset/Contents/Resources/Documents/index?utm_source=chatgpt.com)\nIn practice it often appears when Gemini Live hits an internal fault or enforces quota limits\n\n```\nerror in receive task: received 1011 (internal error) Internal error occurred.; then sent 1011 (internal error) Internal error occurred.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/site-packages/livekit/plugins/google/beta/realtime/realtime_api.py\", line 526, in _recv_task\n    async for response in session.receive():\n  File \"/usr/local/lib/python3.11/site-packages/google/genai/live.py\", line 416, in receive\n    while result := await self._receive():\n  File \"/usr/local/lib/python3.11/site-packages/google/genai/live.py\", line 497, in _receive\n    raw_response = await self._ws.recv(decode=False)\n  File \"/usr/local/lib/python3.11/site-packages/websockets/asyncio/connection.py\", line 313, in recv\n    raise self.protocol.close_exc from self.recv_exc\nwebsockets.exceptions.ConnectionClosedError: received 1011 (internal error) Internal error occurred.; then sent 1011 (internal error) Internal error occurred.\n```\n\nAgent defintion:\n```\n    session = AgentSession(\n        llm=google.beta.realtime.RealtimeModel(\n            model=\"gemini-2.0-flash-exp\",     # <= triggers 1011\n            voice=\"Charon\",                  # valid voice\n            temperature=0.0, top_k=1\n        ),\n        vad=silero.VAD.load(activation_threshold=0.7),\n        turn_detection=EnglishModel(),\n        min_endpointing_delay=0.7,\n        max_endpointing_delay=2.0,\n    )\n```\n\nversions:\n```\nlivekit==1.0.6\nlivekit-agents==1.0.20\nlivekit-api==1.0.2\nlivekit-plugins-cartesia==1.0.20\nlivekit-plugins-noise-cancellation==0.2.1\nlivekit-plugins-deepgram==1.0.20\nlivekit-plugins-google==1.0.20\nlivekit-plugins-openai==1.0.20\nlivekit-plugins-silero==1.0.20\nlivekit-plugins-turn-detector==1.0.20\nlivekit-protocol==1.0.2\n```",
      "state": "closed",
      "author": "edengby",
      "author_type": "User",
      "created_at": "2025-05-13T06:28:08Z",
      "updated_at": "2025-05-14T06:34:26Z",
      "closed_at": "2025-05-14T06:34:25Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2274/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2274",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2274",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:08.344064",
      "comments": [
        {
          "author": "davidzhao",
          "body": "`gemini-2.0-flash-exp` is only supported on vertexai. when using standard model host, you should use `gemini-2.0-flash-live-001`.\n\nclosing as this isn't a livekit issue",
          "created_at": "2025-05-14T06:34:25Z"
        }
      ]
    },
    {
      "issue_number": 2174,
      "title": "The agent saying words like: \"tools_output\" during function-call - gemini real time API",
      "body": "Hi Team, Good Day!\n\nWe are facing issues with function calling while using the gemini-live api. The agent sometimes says words like: \"tools_output\" etc.\n\nI also see an improvement PR: https://github.com/livekit/agents/pull/2089  \nBut the issue is still reproducible with this fix. \n\n\nOne possible reason found was that we are using a deprecated API from google genai library to send message to model. Updating the latest one fixes the problem. \n\nCurrent:\n```python\nif isinstance(msg, LiveClientContent):\n      await session.send(input=msg)\n```\n\nPossible Fix: \n```python \nif isinstance(msg, LiveClientContent):\n      await session.send(input=msg)\nelif isinstance(msg, LiveClientToolResponse):\n      await session.send_tool_response(function_responses=msg.function_responses)\n````\n\n**Better Approach:**\nGoogle document suggest to use ***more specific methods***: `send_client_content`, `send_realtime_input`, or `send_tool_response` instead.\n\nDocument link: https://googleapis.github.io/python-genai/genai.html#module-genai.types\n\nUsing the latest apis - seems to be fixing this issue.\n\ncc: @davidzhao ",
      "state": "closed",
      "author": "shashwatsanket997",
      "author_type": "User",
      "created_at": "2025-05-01T19:34:22Z",
      "updated_at": "2025-05-14T06:08:58Z",
      "closed_at": "2025-05-14T06:08:57Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 19,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2174/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2174",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2174",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:08.535286",
      "comments": [
        {
          "author": "Denin-Siby",
          "body": "yes, even I see so many warnings about not using the latest versions. Some of them are:\n\n```\n -> nv/lib/python3.10/site-packages/livekit/plugins/google/beta/realtime/realtime_api.py:425: DeprecationWarning: Setting \"LiveConnectConfig.generation_config\" is deprecated, please set the fields on \"LiveCo",
          "created_at": "2025-05-02T07:39:50Z"
        },
        {
          "author": "Denin-Siby",
          "body": "I get this error now while I try to use it with Vertex-AI:\n\n`ERROR:livekit.plugins.google:error in send task: id parameter is not supported in Vertex AI.\nTraceback (most recent call last):\n  File \"/Users/deninsiby/Documents/GitHub/atomic-aiagent-service/venv/lib/python3.10/site-packages/livekit/plug",
          "created_at": "2025-05-04T16:39:22Z"
        },
        {
          "author": "davidzhao",
          "body": "@Denin-Siby thanks for the report. this is now fixed in #2194",
          "created_at": "2025-05-05T05:42:03Z"
        },
        {
          "author": "Denin-Siby",
          "body": "Doesn't look like that fixed it @shashwatsanket997 . There are no warnings anymore because we've updated the send functions. But I still hear the bot occasionally say tool_output",
          "created_at": "2025-05-06T03:34:21Z"
        },
        {
          "author": "shashwatsanket997",
          "body": "Hi @Denin-Siby, Thanks for the calling out - Even i am also able reproduce this issue again.  \n\n*Looks like there is some issue on the async task dispatch - looks like some other generation get's triggered.**   (@davidzhao, @theomonnom  can you also have a glance on this - A little priority for us a",
          "created_at": "2025-05-06T05:50:46Z"
        }
      ]
    },
    {
      "issue_number": 2188,
      "title": "'error': 401 - Access denied",
      "body": null,
      "state": "closed",
      "author": "zokkomon",
      "author_type": "User",
      "created_at": "2025-05-04T08:53:57Z",
      "updated_at": "2025-05-14T05:55:50Z",
      "closed_at": "2025-05-14T05:55:50Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2188/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2188",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2188",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:08.790330",
      "comments": [
        {
          "author": "theomonnom",
          "body": "Hey, it's hard to know what's happening here, can you provide more details?\n\nLike the complete stacktrace?",
          "created_at": "2025-05-04T10:08:24Z"
        }
      ]
    },
    {
      "issue_number": 1126,
      "title": "Help with Integration Heygen to Agents",
      "body": "Hello, I'm implementing Heygen with agents and facing issues with streaming video and transcripts. While video streams to the room, agent output and transcripts aren't appearing in chat. Here's my code. We have a tight DEADline - any help would be appreciated.\r\n\r\n```\r\nfrom __future__ import annotations\r\n\r\nfrom dataclasses import dataclass\r\nfrom typing import Optional\r\n\r\nfrom livekit import rtc\r\nfrom livekit.agents import tts, utils\r\nfrom livekit.agents.utils import shortuuid\r\n\r\nfrom app.clients.heygen import HeygenAPIClient\r\nfrom app.services.heygen import HeygenMetadata, HeygenStreamClient\r\nfrom app.utils.logger import logger\r\n\r\n\r\n@dataclass\r\nclass HeygenTTSOptions:\r\n    heygen_session: HeygenMetadata\r\n    sample_rate: int = 48000\r\n    num_channels: int = 1\r\n\r\n\r\nclass TTS(tts.TTS):\r\n    def __init__(\r\n        self,\r\n        *,\r\n        heygen_session: HeygenMetadata,\r\n        video_source: rtc.VideoSource,\r\n        audio_source: rtc.AudioSource,\r\n        api_client: Optional[HeygenAPIClient] = None,\r\n    ) -> None:\r\n        super().__init__(\r\n            capabilities=tts.TTSCapabilities(\r\n                streaming=False,\r\n            ),\r\n            sample_rate=48000,\r\n            num_channels=1,\r\n        )\r\n\r\n        self._opts = HeygenTTSOptions(\r\n            heygen_session=heygen_session,\r\n            sample_rate=48000,\r\n            num_channels=1,\r\n        )\r\n\r\n        self._video_source = video_source\r\n        self._audio_source = audio_source\r\n\r\n        self._heygen_client = HeygenStreamClient(heygen_session, api_client)\r\n        self._initialized = False\r\n\r\n    async def initialize(self) -> bool:\r\n        if self._initialized:\r\n            return True\r\n\r\n        try:\r\n            success = await self._heygen_client.initialize(\r\n                self._video_source, self._audio_source\r\n            )\r\n            if success:\r\n                self._initialized = True\r\n\r\n            return success\r\n\r\n        except Exception as e:\r\n            logger.error(f\"Failed to initialize Heygen TTS: {e}\")\r\n            return False\r\n\r\n    def synthesize(self, text: str) -> \"ChunkedStream\":\r\n        return ChunkedStream(text, self._heygen_client, self._opts)\r\n\r\n    async def aclose(self) -> None:\r\n        if self._heygen_client:\r\n            await self._heygen_client.close()\r\n\r\n\r\nclass ChunkedStream(tts.ChunkedStream):\r\n    def __init__(\r\n        self,\r\n        text: str,\r\n        heygen_client: HeygenStreamClient,\r\n        opts: HeygenTTSOptions,\r\n    ) -> None:\r\n        super().__init__()\r\n        self._text = text\r\n        self._heygen_client: HeygenStreamClient = heygen_client\r\n        self._opts = opts\r\n\r\n    async def _main_task(self) -> None:\r\n        audio_bstream = utils.audio.AudioByteStream(\r\n            sample_rate=self._opts.sample_rate, num_channels=1\r\n        )\r\n        request_id = shortuuid()\r\n        segment_id = shortuuid()\r\n\r\n        try:\r\n            success = await self._heygen_client.speak(self._text)\r\n            if not success:\r\n                logger.error(\"Failed to synthesize speech with Heygen\")\r\n                return\r\n\r\n            async for frame_event in self._heygen_client.audio_stream:\r\n                for processed_frame in audio_bstream.write(frame_event.frame.data):\r\n                    self._event_ch.send_nowait(\r\n                        tts.SynthesizedAudio(\r\n                            request_id=request_id,\r\n                            segment_id=segment_id,\r\n                            frame=processed_frame,\r\n                        )\r\n                    )\r\n\r\n            for frame in audio_bstream.flush():\r\n                self._event_ch.send_nowait(\r\n                    tts.SynthesizedAudio(\r\n                        request_id=request_id, segment_id=segment_id, frame=frame\r\n                    )\r\n                )\r\n\r\n        except Exception as e:\r\n            logger.error(f\"Error in Heygen speech synthesis: {e}\")\r\n            raise\r\n```\r\n\r\n```\r\nimport json\r\nfrom typing import Any, Dict, Optional\r\n\r\nimport aiohttp\r\n\r\nfrom app.config import settings\r\nfrom app.utils.logger import logger\r\n\r\nHEYGEN_API_ENDPOINTS = {\r\n    \"start_session\": \"/v1/streaming.start\",\r\n    \"stop_session\": \"/v1/streaming.stop\",\r\n    \"interrupt_speech\": \"/v1/streaming.interrupt\",\r\n    \"speak\": \"/v1/streaming.task\",\r\n}\r\n\r\n\r\nclass HeygenAPIClient:\r\n    def __init__(self, api_key: Optional[str] = None, base_url: Optional[str] = None):\r\n        self.api_key = api_key or settings.HEYGEN_API_KEY\r\n        self.base_url = base_url or settings.HEYGEN_BASE_URL\r\n        self.headers = {\r\n            \"Content-Type\": \"application/json\",\r\n            \"X-Api-Key\": self.api_key,\r\n        }\r\n\r\n    async def _make_request(\r\n        self, endpoint: str, payload: Dict[str, Any], method: str = \"POST\"\r\n    ) -> Optional[Dict[str, Any]]:\r\n        url = f\"{self.base_url}{endpoint}\"\r\n\r\n        async with aiohttp.ClientSession() as session:\r\n            try:\r\n                async with session.request(\r\n                    method=method, url=url, headers=self.headers, json=payload\r\n                ) as response:\r\n                    if response.status == 200:\r\n                        try:\r\n                            response_text = await response.text()\r\n                            return json.loads(response_text)\r\n\r\n                        except json.JSONDecodeError:\r\n                            logger.error(\r\n                                f\"Heygen API request failed: {endpoint} - \"\r\n                                f\"Status: {response.status} - \"\r\n                                f\"Response: {response_text}\"\r\n                            )\r\n                            return None\r\n\r\n                        except Exception as e:\r\n                            logger.error(\r\n                                f\"Error parsing Heygen API response: {e} - \"\r\n                                f\"Response: {response_text}\"\r\n                            )\r\n                            return None\r\n\r\n                    else:\r\n                        logger.error(\r\n                            f\"Heygen API request failed: {endpoint} - \"\r\n                            f\"Status: {response.status}\"\r\n                        )\r\n                        return None\r\n\r\n            except Exception as e:\r\n                logger.error(f\"Error making request to {endpoint}: {str(e)}\")\r\n                return None\r\n\r\n    async def start_session(self, session_id: str, version: str = \"v2\") -> bool:\r\n        payload = {\r\n            \"session_id\": session_id,\r\n            \"version\": version,\r\n        }\r\n\r\n        result = await self._make_request(\r\n            HEYGEN_API_ENDPOINTS[\"start_session\"], payload\r\n        )\r\n\r\n        return result is not None\r\n\r\n    async def speak(\r\n        self, session_id: str, text: str, task_type: str = \"repeat\"\r\n    ) -> bool:\r\n        payload = {\r\n            \"session_id\": session_id,\r\n            \"text\": text,\r\n            \"task_type\": task_type,\r\n        }\r\n\r\n        result = await self._make_request(HEYGEN_API_ENDPOINTS[\"speak\"], payload)\r\n        return result is not None\r\n\r\n    async def interrupt_speech(self, session_id: str) -> bool:\r\n        payload = {\"session_id\": session_id}\r\n        result = await self._make_request(\r\n            HEYGEN_API_ENDPOINTS[\"interrupt_speech\"], payload\r\n        )\r\n\r\n        return result is not None\r\n\r\n    async def stop_session(self, session_id: str) -> bool:\r\n        payload = {\"session_id\": session_id}\r\n        result = await self._make_request(HEYGEN_API_ENDPOINTS[\"stop_session\"], payload)\r\n\r\n        return result is not None\r\n```\r\n\r\n```\r\nimport asyncio\r\nfrom typing import AsyncIterable, Optional\r\n\r\nfrom livekit import rtc\r\nfrom pydantic import BaseModel\r\n\r\nfrom app.clients.heygen import HeygenAPIClient\r\nfrom app.utils.logger import logger\r\n\r\n\r\nclass HeygenMetadata(BaseModel):\r\n    session_id: str\r\n    access_token: str\r\n    livekit_url: str\r\n\r\n\r\nclass HeygenStreamClient:\r\n    def __init__(\r\n        self,\r\n        heygen_session: HeygenMetadata,\r\n        api_client: Optional[HeygenAPIClient] = None,\r\n    ):\r\n        self.heygen_session = heygen_session\r\n        self.api_client = api_client or HeygenAPIClient()\r\n        self.room: Optional[rtc.Room] = None\r\n        self.audio_stream: Optional[rtc.AudioStream] = None\r\n\r\n    async def initialize(\r\n        self, video_source: rtc.VideoSource, audio_source: rtc.AudioSource\r\n    ) -> bool:\r\n        try:\r\n            session_started = await self.api_client.start_session(\r\n                self.heygen_session.session_id\r\n            )\r\n            if not session_started:\r\n                return False\r\n\r\n            await self._setup_stream_handlers(video_source, audio_source)\r\n\r\n            return True\r\n\r\n        except Exception as e:\r\n            logger.error(f\"Failed to initialize Heygen stream: {e}\")\r\n            return False\r\n\r\n    async def _setup_stream_handlers(\r\n        self, video_source: rtc.VideoSource, audio_source: rtc.AudioSource\r\n    ):\r\n        if not self.heygen_session:\r\n            raise RuntimeError(\"Session not initialized\")\r\n\r\n        self.room = rtc.Room()\r\n\r\n        async def receive_video(video_stream: rtc.VideoStream):\r\n            async for frame_event in video_stream:\r\n                try:\r\n                    video_source.capture_frame(frame=frame_event.frame)\r\n                except Exception as e:\r\n                    logger.error(f\"Video frame processing error: {e}\")\r\n\r\n        async def receive_audio(audio_stream: rtc.AudioStream):\r\n            async for frame_event in audio_stream:\r\n                try:\r\n                    await audio_source.capture_frame(frame=frame_event.frame)\r\n                except Exception as e:\r\n                    logger.error(f\"Audio frame processing error: {e}\")\r\n\r\n        @self.room.on(\"track_subscribed\")\r\n        def on_track_subscribed(\r\n            track: rtc.Track,\r\n            publication: rtc.RemoteTrackPublication,\r\n            participant: rtc.RemoteParticipant,\r\n        ):\r\n            logger.info(f\"Track subscribed: {publication.sid}\")\r\n\r\n            if track.kind == rtc.TrackKind.KIND_VIDEO:\r\n                video_stream = rtc.VideoStream(track)\r\n                asyncio.ensure_future(receive_video(video_stream))\r\n\r\n            elif track.kind == rtc.TrackKind.KIND_AUDIO:\r\n                self.audio_stream = rtc.AudioStream(track)\r\n                asyncio.ensure_future(receive_audio(self.audio_stream))\r\n\r\n        await self.room.connect(\r\n            self.heygen_session.livekit_url, self.heygen_session.access_token\r\n        )\r\n\r\n    async def speak(self, text: str | AsyncIterable[str]) -> bool:\r\n        if not self.heygen_session:\r\n            logger.error(\"No active session\")\r\n            return False\r\n\r\n        if isinstance(text, str):\r\n            return await self.api_client.speak(self.heygen_session.session_id, text)\r\n\r\n        text_to_speak = \"\"\r\n        async for chunk in text:\r\n            text_to_speak += chunk\r\n\r\n        return await self.api_client.speak(\r\n            self.heygen_session.session_id, text_to_speak\r\n        )\r\n\r\n    async def interrupt(self) -> bool:\r\n        if not self.heygen_session:\r\n            return False\r\n\r\n        return await self.api_client.interrupt_speech(self.heygen_session.session_id)\r\n\r\n    async def close(self):\r\n        if self.heygen_session:\r\n            await self.api_client.stop_session(self.heygen_session.session_id)\r\n            self.heygen_session = None\r\n\r\n        if self.room:\r\n            await self.room.disconnect()\r\n            self.room = None\r\n```",
      "state": "closed",
      "author": "firattamurlc",
      "author_type": "User",
      "created_at": "2024-11-22T19:02:25Z",
      "updated_at": "2025-05-14T04:35:10Z",
      "closed_at": "2024-11-25T13:33:48Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1126/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1126",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1126",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:09.053579",
      "comments": [
        {
          "author": "Ibrahim-Isah",
          "body": "@firattamurlc did you figure out a solution with the implementation and how did you resolve the issue ",
          "created_at": "2025-05-14T04:35:09Z"
        }
      ]
    },
    {
      "issue_number": 2222,
      "title": "Realtime Multimodal metrics and transcription callbacks not firing in `livekit-agent@1.0.19`",
      "body": "After upgrading from `livekit-agents@0.12.20` to `livekit-agent@1.0.19`, my Realtime Multimodal session no longer emits any of the old metrics or transcription events:\n\nsession.on('metrics_collected', _on_metrics_collected)\nsession.on('user_speech_committed', text => asyncio.create_task(on_user_speech(text)))\nsession.on('agent_speech_committed', text => asyncio.create_task(on_agent_speech(text)))\n\nI tried with Agent Session with realtime but didnt get any metrics data. Also used metric usageCollector. But no result as well for Realtime.\n",
      "state": "closed",
      "author": "wahidnj",
      "author_type": "User",
      "created_at": "2025-05-07T14:53:37Z",
      "updated_at": "2025-05-14T03:24:11Z",
      "closed_at": "2025-05-14T03:24:11Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2222/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2222",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2222",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:09.307555",
      "comments": [
        {
          "author": "ChenghaoMou",
          "body": "Both have been updated in the newer visions.\n\nYou can check out the docs for more details:\n- [Metrics](https://docs.livekit.io/agents/build/metrics/)\n- [Events](https://docs.livekit.io/agents/build/events/)\n\ntl;dr\n- `conversation_item_added` should be able to replace the old transcription events.\n- ",
          "created_at": "2025-05-07T15:53:48Z"
        },
        {
          "author": "wahidnj",
          "body": "@ChenghaoMou Can you help How I will calculate input and output tokens of realtime openai in latest version.",
          "created_at": "2025-05-08T07:56:56Z"
        },
        {
          "author": "wahidnj",
          "body": "Earlier we used to get from realtime (multimodal) emit event\n`\nEventTypes = Literal[\n    \"user_started_speaking\",\n    \"user_stopped_speaking\",\n    \"agent_started_speaking\",\n    \"agent_stopped_speaking\",\n    \"user_speech_committed\",\n    \"agent_speech_committed\",\n    \"agent_speech_interrupted\",\n    \"f",
          "created_at": "2025-05-08T12:28:57Z"
        },
        {
          "author": "ChenghaoMou",
          "body": "Probably they will be added back soon. They were removed in some commits not long ago ([1](https://github.com/livekit/agents/commit/f12ed5152b62de18c0a5e435b991ffb7ec8e20a8) and [2](https://github.com/livekit/agents/commit/28a0851851dec611bd3a289ef99d5fc675e18d22)) but I have no idea why. \n\ncc @theo",
          "created_at": "2025-05-08T21:04:49Z"
        },
        {
          "author": "wahidnj",
          "body": "@theomonnom please reply whats the problem?",
          "created_at": "2025-05-09T11:39:33Z"
        }
      ]
    },
    {
      "issue_number": 2273,
      "title": "Missing Instruction option in OpenAI Realtime",
      "body": "In previous 0.x version, we're allowed to configured instructions for openai realtime model.\n\n```py\nmodel = openai.realtime.RealtimeModel(\n                api_key=openai_api_key,\n                model=config.model_name,\n                voice=config.voice,\n                temperature=config.temperature,\n                # instructions=config.instructions, (this is missing)\n                input_audio_transcription=InputAudioTranscription(\n                    language='en',\n                    model='gpt-4o-mini-transcribe',\n                    prompt=combined_instructions # voice vibe does not work with this\n                )\n            )\n```\n\nMy main problem is we've a feature called voice vibe using https://www.openai.fm/ which works by passing along to the system prompt. The instructions in AgentSession, Agent class doesn't work for voice vibe either. I noticed google.realtime.RealtimeModel has instruction field to be configurable, can we bring back instruction field to openai realtime as well. ",
      "state": "closed",
      "author": "khantseithu",
      "author_type": "User",
      "created_at": "2025-05-13T05:28:49Z",
      "updated_at": "2025-05-13T19:51:58Z",
      "closed_at": "2025-05-13T19:51:57Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2273/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2273",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2273",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:09.589548",
      "comments": [
        {
          "author": "longcw",
          "body": "Do you have an example \"The instructions in AgentSession, Agent class doesn't work for voice vibe either.\"?\n\nThe instructions are supposed to be set from the agent session or agent. The `google.realtime.RealtimeModel` instruction is not intended, it will be overwritten by the instructions in agent s",
          "created_at": "2025-05-13T09:01:44Z"
        },
        {
          "author": "khantseithu",
          "body": "@longcw Sure, here's an example with Agent class. I don't think AgentSession accepts instruction, sry about the mention previously. To reproduce, try it out with any prompts from https://www.openai.fm/. v1 version voice doesn't change according to the vibe.\n\nAgent\n```py\nclass DemoAgent(Agent):\n    d",
          "created_at": "2025-05-13T09:53:04Z"
        },
        {
          "author": "longcw",
          "body": "I didn't quite follow, you are using the pipeline agent with llm, stt, and tts, you can set a `instructions` for `openai.TTS`\n```\ntts=openai.TTS(instructions=\"\", voice=\"...\")\n```\n\nIf you are using the realtime model (like your example for 0.x), you can set the instructions for the realtime model as ",
          "created_at": "2025-05-13T10:00:16Z"
        },
        {
          "author": "davidzhao",
          "body": "You are talking about TTS instructions. we support the exact same set of things for OpenAI's TTS: `openai.TTS(instructions=...)`\n\nfor a demo of it in action, take a look at https://www.livekit.fm/",
          "created_at": "2025-05-13T19:51:57Z"
        }
      ]
    },
    {
      "issue_number": 2212,
      "title": "Additional data on .say()",
      "body": "Hello. For my own personal need, i've override LiveKit to allow us to send additional_data: dict = {} to the .say().\nThis additional data is then routed and recovered to tts_node.\n\nFor example on my side I can send the parameter volume_factor and modify the volume specifically for a .say() on my tts_node but we can imagine a lot of other usecases and freedom with this parameter.\n\nWould you like a PR ? ",
      "state": "open",
      "author": "AntoineMarcel",
      "author_type": "User",
      "created_at": "2025-05-06T07:23:12Z",
      "updated_at": "2025-05-13T16:10:16Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2212/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2212",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2212",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:09.881560",
      "comments": [
        {
          "author": "theomonnom",
          "body": "That makes a ton of sense, I'm wondering how you're passing around the arguments?\n\nWe can support this but we should be careful about breaking usercode. \n\n\nI was also thinking that it may be very useful to pass around data between nodes too (stt -> llm -> tts) ",
          "created_at": "2025-05-06T09:56:12Z"
        },
        {
          "author": "AntoineMarcel",
          "body": "Actually I made it super simple :\n- new argument to send in .say() -> configuration_data:Optionnal[dict] (agent_session.py and agent_activity.py)\n- on the agent_activity .say() we pass the Optionnal argument to self._tts_task\n- _tts_task() send it to perform_tts_inference\n- perform_tts_inference sen",
          "created_at": "2025-05-07T09:23:04Z"
        },
        {
          "author": "AntoineMarcel",
          "body": "and yes I agree that it should on the long run be available everywhere. so any user have full flexibility",
          "created_at": "2025-05-07T09:23:34Z"
        },
        {
          "author": "AntoineMarcel",
          "body": "@theomonnom you want me to do a PR ? ",
          "created_at": "2025-05-08T18:34:53Z"
        },
        {
          "author": "AntoineMarcel",
          "body": "@theomonnom any news ? :) ",
          "created_at": "2025-05-13T16:10:15Z"
        }
      ]
    },
    {
      "issue_number": 2269,
      "title": "LLMMetrics Not Emitted When Using LLMFallbackAdapter in LiveKit Agent",
      "body": "When using the LLMFallbackAdapter from livekit.agents.llm in the LiveKit Agent, LLMMetrics are not being emitted.\n\nCode for reproduction: \n\n```\n\nfrom livekit.agents.llm import FallbackAdapter as LLMFallbackAdapter\n\nreturn AgentSession[AgentCommonContext](\n            # turn_detection=MultilingualModel(),\n            userdata=context,\n            vad=vad_model,\n            stt=parallel_stt,\n            llm=LLMFallbackAdapter(llm_models, retry_interval=0.1),\n            tts=self._get_voice(agent_voice=self.agent_config.data.voice),\n            min_endpointing_delay=0.0,\n            min_interruption_words=2,\n            allow_interruptions=allow_interruptions,\n        )\n\n@self.session.on(\"metrics_collected\")\nasync def handle_metrics(metrics):\n    print(\"Metrics collected:\", metrics)\n\n\n```\n",
      "state": "closed",
      "author": "hsjun99",
      "author_type": "User",
      "created_at": "2025-05-12T13:52:08Z",
      "updated_at": "2025-05-13T11:37:27Z",
      "closed_at": "2025-05-13T11:37:25Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2269/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2269",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2269",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:10.095157",
      "comments": [
        {
          "author": "longcw",
          "body": "What llms are you using? It should be emitted when using `FallbackAdapter`. Can you share an example that can reproduce the issue?",
          "created_at": "2025-05-13T09:17:15Z"
        },
        {
          "author": "hsjun99",
          "body": "Sorry it was my bad. My logic inside the Agent was causing the issue. Thanks",
          "created_at": "2025-05-13T11:37:25Z"
        }
      ]
    },
    {
      "issue_number": 531,
      "title": "Stub file not found for \"livekit.plugins\"PylancereportMissingTypeStubs",
      "body": "I'm new to python so still finding my way around type hints/stubs/pylance/mypy, so its not immediately clear to me exactly what types are missing since there are no .pyi files in the package.",
      "state": "closed",
      "author": "willsmanley",
      "author_type": "User",
      "created_at": "2024-07-26T20:10:27Z",
      "updated_at": "2025-05-13T07:35:12Z",
      "closed_at": "2025-05-13T07:35:12Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/531/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/531",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/531",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:10.321989",
      "comments": [
        {
          "author": "keepingitneil",
          "body": "Looking into this, I'm able to reproduce",
          "created_at": "2024-07-26T22:06:40Z"
        }
      ]
    },
    {
      "issue_number": 2228,
      "title": "Memory and Connection Issue",
      "body": "Hello, we are facing these issues while using the real-time speech to speech model where the agent is not connecting.\nWe are working on GPUs not CPU and but there is memory and connection errors.\n\nWARNING livekit.agents - process memory usage is high {\"memory_usage_mb\": 617.21875, \"memory_warn_mb\": 500, \"memory_limit_mb\": 0, \"pid\": 421053, \"job_id\": \"AJ_oiXywxFmcSwC\"}\n \n \nWARNING livekit.agents - process memory usage is high {\"memory_usage_mb\": 1094.16796875, \"memory_warn_mb\": 500, \"memory_limit_mb\": 0, \"pid\": 421053, \"job_id\": \"AJ_oiXywxFmcSwC\"}\n \n \nWARNING livekit.agents - The room connection was not established within 10 seconds after calling job_entry. This may indicate that job_ctx.connect() was not called.  {\"pid\": 421053, \"job_id\": \"AJ_oiXywxFmcSwC\"}\n \n \nWARNING livekit.agents - process memory usage is high {\"memory_usage_mb\": 1554.8203125, \"memory_warn_mb\": 500, \"memory_limit_mb\": 0, \"pid\": 421053, \"job_id\": \"AJ_oiXywxFmcSwC\"\n\nThanks in advance.",
      "state": "closed",
      "author": "RidaHajjAli",
      "author_type": "User",
      "created_at": "2025-05-08T08:40:01Z",
      "updated_at": "2025-05-13T07:33:06Z",
      "closed_at": "2025-05-13T07:33:06Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2228/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2228",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2228",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:10.575807",
      "comments": [
        {
          "author": "longcw",
          "body": "can you share an example to reproduce the issue?",
          "created_at": "2025-05-08T08:42:55Z"
        },
        {
          "author": "RidaHajjAli",
          "body": "Thanks for your support.\n\nI am using windows and connected to a linux server (so I am working on the server's terminal).\n\nI'm running the livekit server locally on linux (reference => https://docs.livekit.io/home/self-hosting/local/)\n \n--- In my terminal after running `livekit-server --dev --bind 0.",
          "created_at": "2025-05-08T10:16:43Z"
        },
        {
          "author": "wahidnj",
          "body": "@RidaHajjAli with realtime llm how you manage to get metrics_collected to calculate the session cost with token.",
          "created_at": "2025-05-08T13:00:48Z"
        },
        {
          "author": "longcw",
          "body": "I don't see any issue in your example, could you try removing the `noise_cancellation` import and see if the memory issue is related?",
          "created_at": "2025-05-09T08:20:11Z"
        },
        {
          "author": "longcw",
          "body": "for the connection issue, did you set the room id in playground? Can you try to remove the room id and use a random id if so? The agent won't join a just abnormal closed room.",
          "created_at": "2025-05-09T11:12:20Z"
        }
      ]
    },
    {
      "issue_number": 1684,
      "title": "Gemini sometimes responds to its own question",
      "body": "Using the example provided at https://github.com/livekit/agents/blob/main/examples/multimodal-agent/gemini_agent.py\n\nTalk through to it with multiple different topics where Gemini is expected to ask user a question to get some more clarifications or information. \n\nSometimes, it happens that the gemini spoken audio is asking the question but the transcripts is actually the answer to that very question.\nMoreover, transcripts for the spoken question is not available and the answer available as transcripts is actually not spoken.",
      "state": "closed",
      "author": "meetakshay99",
      "author_type": "User",
      "created_at": "2025-03-20T06:40:07Z",
      "updated_at": "2025-05-13T05:35:43Z",
      "closed_at": "2025-05-13T00:45:01Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1684/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1684",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1684",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:10.824353",
      "comments": [
        {
          "author": "JosephDahan",
          "body": "My experience as well.",
          "created_at": "2025-03-20T12:19:25Z"
        },
        {
          "author": "martin-purplefish",
          "body": "Hah same. We add a bunch to our prompts \"you are the assistant, not the user. Do not answer your own questions\" etc.",
          "created_at": "2025-03-21T10:52:04Z"
        },
        {
          "author": "jayeshp19",
          "body": "> Hah same. We add a bunch to our prompts \"you are the assistant, not the user. Do not answer your own questions\" etc.\n\nThis won't help, Gemini doesn’t offer built‑in transcription, so we added a custom [transcriber](https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-google/",
          "created_at": "2025-03-21T11:18:36Z"
        },
        {
          "author": "meetakshay99",
          "body": "Thanks @jayeshp19 When can we expect this to be fixed?\n\n@martin-purplefish Did it help in the meantime to not hallucinate and work as expected?",
          "created_at": "2025-03-24T06:24:21Z"
        },
        {
          "author": "BhavaniMallapragada",
          "body": "@jayeshp19 We are experiencing hallucinations.\nSome times it working perfectly but sometimes it's skipping function calls and hallucinating.\nIs there any way that we can make it not hallucinate.",
          "created_at": "2025-04-09T15:57:58Z"
        }
      ]
    },
    {
      "issue_number": 2264,
      "title": "\"ImportError: 'livekit.agents.pipeline' module not found in voice assistant project\"",
      "body": "Hello,\nI'm working on a LiveKit voice assistant project and encountering an import error with the [livekit.agents.pipeline] module\n\n`Import \"livekit.agents.pipeline\" could not be resolved (reportMissingImports)`\n\nProject Details\nI'm building a voice assistant application that uses LiveKit's agent system to process audio and respond to users. The application is structured to:\nConnect to a LiveKit room\nWait for a participant\nExtract file content from participant metadata\nSet up a voice pipeline agent with VAD, STT, LLM, and TTS components\n\nThis is the code causing issue:\n```\nfrom livekit.agents import (\n    AutoSubscribe,\n    JobContext,\n    JobProcess,\n    WorkerOptions,\n    cli,\n    llm,\n)\nfrom livekit.agents.pipeline import VoicePipelineAgent  # This line causes the error\nfrom livekit.plugins import silero, openai, elevenlabs\n```\n\nWhat I've Tried\n- Checked my installed packages using `pip list` to verify livekit-agents is installed\n- Tried reinstalling the livekit-agents package with `pip uninstall livekit-agents` followed by `pip install livekit-agents`\n- Searched LiveKit documentation for information about the pipeline module\n- Looked at the repository examples to see how other projects import VoicePipelineAgent\n- Checked for any version-specific requirements in the documentation\n- Checked if there are any additional Python dependencies required for the pipeline module",
      "state": "closed",
      "author": "Walaa-Volidis",
      "author_type": "User",
      "created_at": "2025-05-12T10:26:05Z",
      "updated_at": "2025-05-13T00:43:06Z",
      "closed_at": "2025-05-13T00:43:06Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2264/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2264",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2264",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:11.087007",
      "comments": [
        {
          "author": "longcw",
          "body": "`livekit.agents.pipeline` is for agents 0.x, check https://docs.livekit.io/agents/start/v0-migration/#before-llm-cb-on-user-turn-completed for migration from 0.x to agents 1.0",
          "created_at": "2025-05-12T11:41:45Z"
        }
      ]
    },
    {
      "issue_number": 1985,
      "title": "Chinese Response Streaming Issue in Structured Output Example",
      "body": "## Issue Description\n\nWhen testing the `structured_output.py` example (https://github.com/livekit/agents/blob/main/examples/voice_agents/structured_output.py) in the livekit-agents-playground , there is an inconsistency in how the chat streaming works between different languages in the response.\n\n**Expected behavior:**\n- The text response should be streamed incrementally to the frontend, matching the audio output speed regardless of language used.\n\n**Current behavior:**\n- When the LLM responds in English, the text appears as a proper stream in the agents-playground UI, with incremental updates matching the audio output.\n- When the LLM responds with Chinese text, the entire response appears at once in the UI instead of streaming incrementally. The text is displayed as a complete block rather than following the audio output speed.\n\nThe issue is related to the output language only, not the input language. Even with English input, if the response contains Chinese, the streaming behavior is broken.\n\n## Possible Root Causes\n\nThese are my speculations about potential causes of the issue:\n\n1. The `process_structured_output` function in structured_output.py may have issues handling non-Latin characters in stream mode\n2. The transcription system might not fully support streaming for non-Latin character sets like Chinese\n\nI have not tested Chinese output in other examples yet, so I'm unsure whether this is specific to the structured_output.py implementation or if it's a broader issue with the transcription_node not supporting Chinese streaming at all.\n\n## Reproduction Steps\n\n1. Use the livekit-agents-playground to run the structured_output.py example\n2. First, get the LLM to respond in English and observe the proper streaming behavior\n3. Then prompt the LLM to respond in Chinese, and observe how the response text appears all at once\n",
      "state": "closed",
      "author": "michaelawea",
      "author_type": "User",
      "created_at": "2025-04-13T14:51:34Z",
      "updated_at": "2025-05-12T15:32:47Z",
      "closed_at": "2025-05-12T15:25:46Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1985/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1985",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1985",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:11.336246",
      "comments": [
        {
          "author": "longcw",
          "body": "This is an issue of the sentence and word tokenizers. https://github.com/livekit/agents/issues/1811 this issue is related. I think we're going to improve the tokenizers for better multi language support soon.",
          "created_at": "2025-04-13T15:28:45Z"
        },
        {
          "author": "michaelawea",
          "body": "Thank you very much, and sorry I didn’t see this issue earlier. I hope this feature can be added soon. Thanks again!",
          "created_at": "2025-04-13T15:56:44Z"
        },
        {
          "author": "michaelawea",
          "body": "Thanks for the fix 👍 ",
          "created_at": "2025-05-12T15:32:46Z"
        }
      ]
    },
    {
      "issue_number": 2266,
      "title": "Error when using Gemini model with newly added native MCP support",
      "body": "version = 1.0.20\n\nWhen using GPT for the newly added native MCP support, the functionality works as expected. However, when switching to the Gemini (2.0, 2.5 Flash) model, the following error consistently occurs:\n\n```\nreturn AgentSession[AgentCommonContext](\n    # turn_detection=MultilingualModel(),\n    userdata=context,\n    vad=vad_model,\n    stt=parallel_stt,\n    llm=LLMFallbackAdapter(llm_models, retry_interval=0.1),\n    tts=self._get_voice(agent_voice=self.agent_config.data.voice),\n    min_endpointing_delay=0.0,\n    min_interruption_words=2,\n    allow_interruptions=allow_interruptions,\n    mcp_servers=[\n        mcp.MCPServerHTTP(\n            url=MCP_SERVER_URL\n        )\n    ],\n)\n\n```\n\n\nError Log:\n\n```\n2025-05-12 21:18:38,599 - WARNING livekit.agents - failed to generate LLM completion, retrying in 0.1s\nTraceback (most recent call last):\n  File \"/home/busking/Documents/agentify/voxai-agent-server/app/application/services/livekit/agents/entrypoint.py\", line 950, in _run\n    function_declarations = to_fnc_ctx(self._tools)\n                            ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/busking/Documents/agentify/voxai-agent-server/.venv/lib/python3.12/site-packages/livekit/plugins/google/utils.py\", line 20, in to_fnc_ctx\n    return [_build_gemini_fnc(fnc) for fnc in fncs]\n            ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/busking/Documents/agentify/voxai-agent-server/.venv/lib/python3.12/site-packages/livekit/plugins/google/utils.py\", line 131, in _build_gemini_fnc\n    fnc = llm.utils.build_legacy_openai_schema(function_tool, internally_tagged=True)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/busking/Documents/agentify/voxai-agent-server/.venv/lib/python3.12/site-packages/livekit/agents/llm/utils.py\", line 180, in build_legacy_openai_schema\n    info = get_function_info(function_tool)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/busking/Documents/agentify/voxai-agent-server/.venv/lib/python3.12/site-packages/livekit/agents/llm/tool_context.py\", line 183, in get_function_info\n    return getattr(f, \"__livekit_tool_info\")\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'function' object has no attribute '__livekit_tool_info'. Did you mean: '__livekit_raw_tool_info'?\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/busking/Documents/agentify/voxai-agent-server/.venv/lib/python3.12/site-packages/livekit/agents/llm/llm.py\", line 138, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/busking/Documents/agentify/voxai-agent-server/app/application/services/livekit/agents/entrypoint.py\", line 1035, in _run\n    raise APIConnectionError(\nlivekit.agents._exceptions.APIConnectionError: gemini llm: error generating content 'function' object has no attribute '__livekit_tool_info' {\"llm\": \"application.services.livekit.agents.entrypoint.CustomGoogleLLM\", \"attempt\": 1, \"pid\": 3794107, \"job_id\": \"AJ_4nGr8xLJ7w8D\"}\n\n```",
      "state": "closed",
      "author": "hsjun99",
      "author_type": "User",
      "created_at": "2025-05-12T12:23:32Z",
      "updated_at": "2025-05-12T15:25:36Z",
      "closed_at": "2025-05-12T15:25:36Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2266/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2266",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2266",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:11.640677",
      "comments": [
        {
          "author": "longcw",
          "body": "Created a fix https://github.com/livekit/agents/pull/2270",
          "created_at": "2025-05-12T14:17:57Z"
        }
      ]
    },
    {
      "issue_number": 2267,
      "title": "Facing issue on adding anthropic and google plugins.Iam using version 1.0.20 for both.",
      "body": "     File \"./python3.12/site-packages/livekit/plugins/anthropic/__init__.py\", line 20, in <module>\n    from .llm import LLM, LLMStream\n  File \"./python3.12/site-packages/livekit/plugins/anthropic/llm.py\", line 38, in <module>\n    from .utils import to_chat_ctx, to_fnc_ctx\n  File \"./python3.12/site-packages/livekit/plugins/anthropic/utils.py\", line 9, in <module>\n    CACHE_CONTROL_EPHEMERAL = anthropic.types.CacheControlEphemeralParam(type=\"ephemeral\")\n                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: module 'anthropic.types' has no attribute 'CacheControlEphemeralParam'\n\n\n\n  File \"./python3.12/site-packages/livekit/plugins/google/__init__.py\", line 25, in <module>\n    from .tts import TTS\n  File \"./python3.12/site-packages/livekit/plugins/google/tts.py\", line 47, in <module>\n    class TTS(tts.TTS):\n  File \"./pythonenv/enve/lib/python3.12/site-packages/livekit/plugins/google/tts.py\", line 59, in TTS\n    audio_encoding: texttospeech.AudioEncoding = texttospeech.AudioEncoding.PCM,\n                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: type object 'AudioEncoding' has no attribute 'PCM'",
      "state": "closed",
      "author": "test-24325",
      "author_type": "User",
      "created_at": "2025-05-12T13:17:41Z",
      "updated_at": "2025-05-12T14:31:36Z",
      "closed_at": "2025-05-12T14:31:35Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2267/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2267",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2267",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:11.857987",
      "comments": [
        {
          "author": "longcw",
          "body": "What is your google package versions, you can check it with `pip list | grep google`.\n\nTry to upgrade the `google-cloud-texttospeech` with `pip install -U google-cloud-texttospeech`",
          "created_at": "2025-05-12T13:45:37Z"
        },
        {
          "author": "test-24325",
          "body": "Yes, updating google-cloud-texttospeech to 2.27.0 solved the google plugin issue. Anythign that can be done for anthropic plugin error? @longcw \n",
          "created_at": "2025-05-12T14:06:45Z"
        },
        {
          "author": "longcw",
          "body": "Update `anthropic` with `pip install -U anthropic`?",
          "created_at": "2025-05-12T14:21:13Z"
        },
        {
          "author": "test-24325",
          "body": "yes updating to 0.51.0 worked, thanks.",
          "created_at": "2025-05-12T14:31:35Z"
        }
      ]
    },
    {
      "issue_number": 1862,
      "title": "TTS issue: `APIStatusError: unexpected 11labs message`",
      "body": "Hi! Nothing fancy here, we're using elevenlabs and it works most of the time, but out of 80 sessions in a day we had 8 TTS errors below:\n\n```\nAPIStatusError: unexpected 11labs message {'audio': '', 'isFinal': None, 'normalizedAlignment': None, 'alignment': None}\n  File \"/usr/local/lib/python3.12/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.12/site-packages/livekit/plugins/elevenlabs/tts.py\", line 356, in _process_segments\n    await self._run_ws(word_stream, request_id)\n  File \"/usr/local/lib/python3.12/site-packages/livekit/plugins/elevenlabs/tts.py\", line 501, in _run_ws\n    await asyncio.gather(*tasks)\n  File \"/usr/local/lib/python3.12/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.12/site-packages/livekit/plugins/elevenlabs/tts.py\", line 488, in recv_task\n    raise APIStatusError(\n```\n\nOur agent setup is below:\n```python\nagent = VoicePipelineAgent(\n      vad=ctx.proc.userdata[\"vad\"],\n      stt=stt,\n      llm=openai.LLM(model=\"gpt-4o\", api_key=settings.openai_api_key, temperature=0.6),\n      tts=elevenlabs.TTS(\n          api_key=settings.elevenlabs_api_key,\n          model=\"eleven_multilingual_v2\",\n          voice=replace(DEFAULT_VOICE, id=\"<id>\"),\n      ),\n      turn_detector=turn_detector.EOUModel(),\n      min_endpointing_delay=0.5,\n      max_endpointing_delay=5.0,\n      chat_ctx=initial_ctx,\n      fnc_ctx=fnc_ctx,\n  )\n```\n\nCan't quite understand what the issue is. We've seen some reports of the agent just stopping talking suddenly — it's probably related?\n\nMore data from sentry?\n<img width=\"1444\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/6a318cdb-60b5-4f6e-8e6d-69b39c255862\" />",
      "state": "closed",
      "author": "mdrachuk",
      "author_type": "User",
      "created_at": "2025-04-02T11:37:02Z",
      "updated_at": "2025-05-11T06:07:11Z",
      "closed_at": "2025-05-11T06:07:11Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1862/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1862",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1862",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:12.119716",
      "comments": [
        {
          "author": "ChenghaoMou",
          "body": "<img width=\"913\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/66ee9bf4-43a0-4414-a194-a0a005abc61c\" />\n\nBased on the doc, audio will be null/None if `is_final` is set to True. A possible fix for this I guess is \n\n```python\nif data.get(\"audio\") is None:\n    b64data = base64.b64decode(d",
          "created_at": "2025-04-02T12:02:45Z"
        },
        {
          "author": "davidzhao",
          "body": "in this case, we got a completely empty payload: `{'audio': '', 'isFinal': None, 'normalizedAlignment': None, 'alignment': None}`\n\nthis is rather unexpected according to their docs",
          "created_at": "2025-04-03T06:03:43Z"
        },
        {
          "author": "marcelpallares",
          "body": "We are experiencing the same issue `{'audio': '', 'isFinal': None, 'normalizedAlignment': None, 'alignment': None}`.\nHas anyone been able to figure out a solution yet? When this happens, the audio breaks mid-sentence and the user experience is just terrible.",
          "created_at": "2025-05-08T13:03:46Z"
        }
      ]
    },
    {
      "issue_number": 2257,
      "title": "transcription_output_topic is not in RoomOutputOptions as documented",
      "body": "\nHello! Thanks for taking the time to read the report.\n\n`transcription_output_topic` is not in RoomOutputOptions class as documented (python v1.0 custom-topics) here: \nhttps://docs.livekit.io/agents/build/text/#custom-topics\n\n> You may override the text_input_topic of RoomInputOptions and **transcription_output_topic of RoomOutputOptions** to set a custom text stream topic for text input or output, if desired. The default values are lk.chat and lk.transcription respectively.\n\n\n\nAlso I can't find a way to use custom-topics too, in RoomOutputOptions class \nhttps://github.com/livekit/agents/blob/7730835292f990d5a3835d9c1aae5b71fa8695c4/livekit-agents/livekit/agents/voice/room_io/room_io.py#L76-L84\n\nI was trying to make an agent to chat like chatGPT UI in the chat box.\nTo do so, i need to specifically use text streams topic `lk.chat`, instead of the default `lk.transcription`, to have an interactive chat box. Am i correct?\n```\nsession = AgentSession(\n    ...,\n    room_output_options=RoomOutputOptions(\n        transcription_output_topic='lk.chat'\n    )\n)\n```\nThanks\n\n\n",
      "state": "closed",
      "author": "Denly",
      "author_type": "User",
      "created_at": "2025-05-10T03:05:16Z",
      "updated_at": "2025-05-11T05:39:13Z",
      "closed_at": "2025-05-11T05:39:13Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2257/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2257",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2257",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:12.316952",
      "comments": [
        {
          "author": "longcw",
          "body": "`transcription_output_topic` is not exposed, it's always `lk.transcription`. We will update the document.\n\nFor text input from user, you can use `lk.chat` topic, and listen to the `lk.transcription` for the agent transcription and user transcription from audio recognition.",
          "created_at": "2025-05-11T05:25:27Z"
        }
      ]
    },
    {
      "issue_number": 2235,
      "title": "Distributed LiveKit: Agent worker can only serve the node it registered on",
      "body": "## Summary\n\nIn a 3-node LiveKit cluster, a single **LiveKit Agent worker** registers successfully on **Node C**.\n When a new room request lands on **Node B**, the server cannot hand that job to the worker on Node C. Instead it\n\n1. Tries (and fails) to assign the job on Node B.\n2. Falls back to **Node A**, which creates the room **without any Agent worker attached**.\n\nResult: the room starts, but the Agent never connects and hence there is only silence.\n\n\n------\n\n## Topology\n\n```\nNode A ── LiveKit server\nNode B ── LiveKit server              (receives the room request)\nNode C ── LiveKit server              (worker registers here)\n```\n\n------\n\n## Logs\n\n## Node A\n```\n2025-05-06T05:42:55.411Z  INFO  livekit  service/roomallocator.go:164  selected node for room  {\"room\":\"<room_name>\",\"selectedNodeID\":\"<livekit_node_id>\"}\n2025-05-06T05:42:55.423Z  INFO  livekit.api  service/twirp.go:124  API RoomService.CreateRoom  {\"service\":\"RoomService\",\"method\":\"CreateRoom\",\"room\":\"<room_name>\",\"request\":{\"name\":\"<room_name>\",\"metadata\":\"<metadata>\"},\"duration\":\"16.212838ms\",\"status\":\"200\"}\n2025-05-06T05:42:55.596Z  INFO  livekit.webhook  webhook/url_notifier.go:124  sent webhook  {\"event\":\"room_started\",\"id\":\"<event_id>\",\"webhookTime\":1746510175,\"room\":\"<room_name>\",\"roomID\":\"<room_id>\",\"url\":\"<webhook_url>\",\"queueDuration\":\"42.041µs\",\"sendDuration\":\"173.904564ms\"}\n2025-05-06T05:42:55.646Z  INFO  livekit  agent/client.go:161  failed to send job request  {\"error\":\"no workers with sufficient capacity\",\"namespace\":\"\",\"jobType\":\"JT_ROOM\",\"agentName\":\"\"}\n2025-05-06T05:42:56.493Z  INFO  livekit  service/roommanager.go:405  starting RTC session  {\"room\":\"<room_name>\",\"roomID\":\"<room_id>\",\"participant\":\"<participant_id>\",\"pID\":\"<process_id>\",\"remote\":false,\"nodeID\":\"<livekit_node_id>\",\"numParticipants\":0,\"participantInit\":{\"Identity\":\"<participant_id>\",\"Client\":{\"sdk\":\"<sdk>\",\"version\":\"<sdk_version>\",\"os\":\"<os>\",\"osVersion\":\"<os_version>\",\"deviceModel\":\"<device_model>\",\"browser\":\"<browser>\",\"browserVersion\":\"<browser_version>\"}}}\n2025-05-06T05:42:56.496Z  INFO  livekit  service/roommanager.go:938  created TURN password  {\"username\":\"<turn_username>\",\"password\":\"<turn_pass>\"}\n2025-05-06T05:42:56.808Z  INFO  livekit.transport  rtc/transport.go:546  ice reconnected or switched pair  {\"room\":\"<room_name>\",\"roomID\":\"<room_id>\",\"participant\":\"<participant_id>\",\"pID\":\"<process_id>\",\"remote\":false,\"transport\":\"PUBLISHER\",\"existingPair\":{\"localProtocol\":\"udp\",\"localCandidateType\":\"host\",\"localAddress\":\"<local_ip>\",\"localPort\":\"<local_port>\",\"remoteProtocol\":\"udp\",\"remoteCandidateType\":\"prflx\",\"remoteAddress\":\"<remote_ip>\",\"remotePort\":\"<remote_port>\"},\"newPair\":{\"localProtocol\":\"udp\",\"localCandidateType\":\"host\",\"localAddress\":\"<local_ipv6>\",\"localPort\":\"<local_ipv6_port>\",\"remoteProtocol\":\"udp\",\"remoteCandidateType\":\"host\",\"remoteAddress\":\"<remote_ipv6>\",\"remotePort\":\"<remote_ipv6_port>\"}}}\n2025-05-06T05:42:56.922Z  INFO  livekit.pub  rtc/participant.go:1826  mediaTrack published  {\"room\":\"<room_name>\",\"roomID\":\"<room_id>\",\"participant\":\"<participant_id>\",\"pID\":\"<process_id>\",\"remote\":false,\"kind\":\"audio\",\"trackID\":\"<track_id>\",\"webrtcTrackID\":\"<webrtc_track_id>\",\"rid\":\"\",\"SSRC\":\"<ssrc>\",\"mime\":\"audio/red\",\"trackInfo\":{\"sid\":\"<track_id>\",\"type\":\"AUDIO\",\"source\":\"MICROPHONE\",\"mimeType\":\"audio/red\",\"mid\":\"1\",\"stream\":\"camera\"},\"fromSdp\":true}\n2025-05-06T05:42:56.957Z  INFO  livekit.webhook  webhook/url_notifier.go:124  sent webhook  {\"event\":\"track_published\",\"id\":\"<event_id>\",\"webhookTime\":1346510176,\"room\":\"<room_name>\",\"roomID\":\"<room_id>\",\"participant\":\"<participant_id>\",\"pID\":\"<process_id>\",\"url\":\"<webhook_url>\",\"queueDuration\":\"14.513µs\",\"sendDuration\":\"32.059281ms\"}\n2025-05-06T05:42:57.704Z  INFO  livekit  rtc/room.go:469  participant active  {\"room\":\"<room_name>\",\"roomID\":\"<room_id>\",\"participant\":\"<participant_id>\",\"pID\":\"<process_id>\",\"remote\":false,\"publisherCandidates\":\"<redacted>\",\"subscriberCandidates\":\"<redacted>\",\"connectionType\":\"udp\"}\n2025-05-06T05:42:57.744Z  INFO  livekit.webhook  webhook/url_notifier.go:124  sent webhook  {\"event\":\"participant_joined\",\"id\":\"<event_id>\",\"webhookTime\":1346510177,\"room\":\"<room_name>\",\"roomID\":\"<room_id>\",\"participant\":\"<participant_id>\",\"pID\":\"<process_id>\",\"url\":\"<webhook_url>\",\"queueDuration\":\"34.951µs\",\"sendDuration\":\"39.824442ms\"}\n```\n\n### Node B\n```\n2025-05-06T05:42:55.632Z\tWARN\tlivekit.agents\tservice/agentservice.go:401\tfailed to assign job to worker\t{\"jobID\": \"<job_id>\", \"namespace\": \"\", \"agentName\": \"\", \"jobType\": \"JT_ROOM\", \"room\": \"<room_name>\", \"roomID\": \"<room_id>\", \"workerID\": \"<OLD_WORKER_ID_1>\", \"retry\": true, \"error\": \"worker not available\"}\n2025-05-06T05:42:55.639Z\tWARN\tlivekit.agents\tservice/agentservice.go:401\tfailed to assign job to worker\t{\"jobID\": \"<job_id>\", \"namespace\": \"\", \"agentName\": \"\", \"jobType\": \"JT_ROOM\", \"room\": \"<room_name>\", \"roomID\": \"<room_id>\", \"workerID\": \"<OLD_WORKER_ID_2>\", \"retry\": true, \"error\": \"worker not available\"}\n2025-05-06T05:42:55.644Z\tWARN\tlivekit.agents\tservice/agentservice.go:401\tfailed to assign job to worker\t{\"jobID\": \"<job_id>\", \"namespace\": \"\", \"agentName\": \"\", \"jobType\": \"JT_ROOM\", \"room\": \"<room_name>\", \"roomID\": \"<room_id>\", \"workerID\": \"<OLD_WORKER_ID_3>\", \"retry\": true, \"error\": \"worker not available\"}\n2025-05-06T05:42:55.644Z\tWARN\tlivekit.agents\tservice/agentservice.go:391\tno worker available to handle job\t{\"jobID\": \"<job_id>\", \"namespace\": \"\", \"agentName\": \"\", \"jobType\": \"JT_ROOM\", \"room\": \"<room_name>\", \"roomID\": \"<room_id>\", \"error\": \"no workers with sufficient capacity\"}\n```\n\n### Node C\n```\n2025-05-06T05:42:44.567Z\tINFO\tlivekit.agents\tservice/agentservice.go:292\tworker registered\t{\"namespace\": \"\", \"jobType\": \"JT_ROOM\", \"agentName\": \"\", \"workerID\": \"<CORRECT_WORKED_ID>\"}\n```\n\n------\n\n## Expected behavior\n\n- **Node B** should be able to dispatch the `JT_ROOM` job to the worker already\n   registered on **Node C**, or the cluster should transparently proxy the request.\n\n## Actual behavior\n\n- **Node B** fails to find *any* available worker and eventually the allocator\n   selects **Node A**, which creates the room without an Agent worker.\n\n------\n\n## Reproduction steps\n\n1. Run three LiveKit nodes (A, B, C) backed by the same Redis/state store (running in sentinel with one master node).\n2. Start **one** Agent worker *only* on Node C (job type `JT_ROOM`).\n3. Send a `CreateRoom` request that the allocator routes to Node B.\n4. Observe *worker-not-available* warnings on Node B and room creation on Node A.\n\n------\n\n## Environment\n\n| Component      | Version                                 |\n| -------------- | --------------------------------------- |\n| LiveKit server | `v2.8.0`                                |\n| LiveKit Agent  | `v0.x` (worker)                       |\n| Redis          | `7.2`                                   |\n| Deployment     | Docker Compose (one container per node) |\n| OS             | Ubuntu 22.04                            |\n\n------\n\n## Question\n\n**Why can’t Node B delegate the job to the registered worker on Node C?**\n Is worker discovery limited to the local node by design, or is there an extra\n configuration flag required to make workers globally visible across the cluster?\n\nAny insight or pointers would be greatly appreciated!\n\n\nNote: This is a duplicate of the issue in the [LiveKit repo](https://github.com/livekit/livekit/issues/3645). I can close the other issue once I know which repo is the right place to ask this.",
      "state": "closed",
      "author": "umarniz",
      "author_type": "User",
      "created_at": "2025-05-08T16:55:23Z",
      "updated_at": "2025-05-11T04:19:57Z",
      "closed_at": "2025-05-11T04:19:56Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2235/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2235",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2235",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:12.526067",
      "comments": [
        {
          "author": "davidzhao",
          "body": "Please do not file duplicate issues.",
          "created_at": "2025-05-11T04:19:57Z"
        }
      ]
    },
    {
      "issue_number": 2253,
      "title": "strict mode in OpenAI function calling is breaking xAI plugin",
      "body": "When using xAI LLM I am getting the following error:\n\n```\nlivekit.agents._exceptions.APIStatusError: Error code: 400 - {'code': 'Client specified an invalid argument', 'error': 'Invalid request content: `strict` mode on function call is currently not supported.'} (status_code=400, request_id=None, body=Invalid request content: `strict` mode on function call is currently not supported.)\n```\n\nLooks like strict is hardcoded to `True` here: https://github.com/livekit/agents/blob/main/livekit-agents/livekit/agents/llm/utils.py#L213C13-L213C28\n\n",
      "state": "open",
      "author": "themusicman",
      "author_type": "User",
      "created_at": "2025-05-09T12:11:43Z",
      "updated_at": "2025-05-09T20:16:39Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2253/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "theomonnom"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2253",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2253",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:12.740036",
      "comments": []
    },
    {
      "issue_number": 2199,
      "title": "FT request: Make realtime_input_config and image encoding options configurable in push_video method",
      "body": "Currently, when using the push_video method, the image encoding options are hardcoded with DEFAULT_ENCODE_OPTIONS and there's no way to customize the realtime_input_config when sending video frames. This seems to have been removed in the v1 agents sdk. But is a feature that used to be there in v0. (Not sure why this was removed)\n\n\nAdditionally, Now that gemini live supports the ability to configure their automatic VAD [gemini doc](https://ai.google.dev/gemini-api/docs/live#configure-automatic-vad), can we have this also configurable while setting up the LiveConnectConfig class supports realtime_input_config parameter, it's not exposed in the current implementation of _build_connect_config().\n\nSuggested Implementation:\n\n- Update the push_video method to accept optional encoding parameters:\n\n`   def push_video(self, frame: rtc.VideoFrame, encoding_options: Optional[Dict] = None) -> None:\n       options = encoding_options or DEFAULT_ENCODE_OPTIONS\n       encoded_data = images.encode(frame, options)\n       # rest of the method`\n\n- Update the RealtimeModel constructor to accept the realtime_input_config parameter \n\n`   def __init__(\n       self,\n       *,\n       # existing parameters...\n       realtime_input_config: NotGivenOr[RealtimeInputConfig] = NOT_GIVEN,\n   ) -> None:\n       # Store in options\n       self._opts.realtime_input_config = realtime_input_config`\n\n\nThis enhancement provides greater flexibility by allowing:\n- Configuration of realtime input behavior at model creation time \n- Per-frame customization of video encoding quality and parameters\n- Better control over bandwidth usage and performance in resource-constrained environments",
      "state": "closed",
      "author": "Denin-Siby",
      "author_type": "User",
      "created_at": "2025-05-05T10:23:18Z",
      "updated_at": "2025-05-09T20:15:02Z",
      "closed_at": "2025-05-09T20:15:02Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2199/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2199",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2199",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:12.740062",
      "comments": [
        {
          "author": "longcw",
          "body": "added in #2249 ",
          "created_at": "2025-05-09T09:06:49Z"
        },
        {
          "author": "Denin-Siby",
          "body": "Thank you @longcw ",
          "created_at": "2025-05-09T11:19:26Z"
        }
      ]
    },
    {
      "issue_number": 2098,
      "title": "`conversation_item_added` event not triggering for user role in Gemini Live API",
      "body": "```py\n            model = google.realtime.RealtimeModel(\n                instructions=config.instructions,\n                modalities=[Modality.AUDIO],  # Only use AUDIO modality\n                voice=config.voice,\n                temperature=0.7,\n                api_key=gemini_api_key,\n                model=\"gemini-2.0-flash-live-001\"\n            )\n```\n\n```py\n@session.on(\"conversation_item_added\")\n            def on_conversation_item_added(event: ConversationItemAddedEvent):\n                print(f\"Conversation item added from {event.item.role}: {event.item.text_content}. interrupted: {event.item.interrupted}\")\n```\n\nNo output from user, only assistant event is triggered when using it with Gemini Live API:\n```\nConversation item added from assistant: The weather in San Francisco is currently 12 degrees Celsius, which feels like 10 degrees Celsius. It's overcast with a wind speed of 23 kilometers per hour. The forecast for today is overcast with a high of 11 degrees Celsius and a low of 9 degrees Celsius. Do you need more details?\n. interrupted: True\n```\n\nIt works fine for openai realtime api.\n\nVersions:\n\nlivekit==1.0.6\nlivekit-agents==1.0.14\nlivekit-api==1.0.2\nlivekit-plugins-deepgram==1.0.13\nlivekit-plugins-google==1.0.14\nlivekit-plugins-noise-cancellation==0.2.1\nlivekit-plugins-openai==1.0.13\nlivekit-plugins-turn-detector==1.0.13\nlivekit-protocol==1.0.2",
      "state": "closed",
      "author": "khantseithu",
      "author_type": "User",
      "created_at": "2025-04-24T03:13:17Z",
      "updated_at": "2025-05-09T20:13:30Z",
      "closed_at": "2025-05-09T20:13:30Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2098/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2098",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2098",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:12.931200",
      "comments": [
        {
          "author": "ChenghaoMou",
          "body": "For OpenAI Realtime model, one can configure user transcription with `input_audio_transcription`. For Gemini Realtime model, I think you still have to use a STT model when creating the agent.",
          "created_at": "2025-04-28T13:12:49Z"
        },
        {
          "author": "edengby",
          "body": "@ChenghaoMou can you please elaborate on how to define the STT using Google SST?\nThis is what I tried - it did not worked.\n\n```\nsession = AgentSession(\n        llm = google.beta.realtime.RealtimeModel(model=\"gemini-2.0-flash-exp\", voice=\"Kore\"),\n        stt = google.STT(\n            model=\"chirp\",\n ",
          "created_at": "2025-04-28T14:23:26Z"
        },
        {
          "author": "longcw",
          "body": "@edengby you can use any STT plugin like\n```python\nclass GeminiAgent(Agent):\n    def __init__(self) -> None:\n        super().__init__(\n            instructions=\"You are gemini, a helpful assistant\",\n            llm=google.beta.realtime.RealtimeModel(),\n            stt=deepgram.STT(),\n        )\n```\n\n",
          "created_at": "2025-04-28T14:45:42Z"
        },
        {
          "author": "edengby",
          "body": "I want to use the STT of Google because I think that Deepgram causes the bot to ignore inputs from the user.\nEvery few sentences, the agent ignores a sentence or two, I think it is related to Datagram.\n\nMy previous STT:\n```\ndeepgram.STT(model=\"nova-3\" ,language=\"multi\" ,endpointing_ms=50 ,interim_re",
          "created_at": "2025-04-28T14:49:00Z"
        },
        {
          "author": "davidzhao",
          "body": "this is expected for now, we are working on some improvements to Gemini Live to address some of the limitations there",
          "created_at": "2025-04-28T15:40:49Z"
        }
      ]
    },
    {
      "issue_number": 2242,
      "title": "Gemini Realtime receives entire message history, whenever I send a chat",
      "body": "Hello and thank you for your great work with Livekit!\n\nI'm using a minimal livekit *realtime* worker setup, following the [voice AI quickstart](https://docs.livekit.io/agents/start/voice-ai/) guide. Instead of OpenAI, I'm using Gemini:\n\n```python\nAgentSession(\n  llm=google.beta.realtime.RealtimeModel(\n    model=\"gemini-2.0-flash\",\n  )\n```\n\nThis works fine for voice input, but when I'm sending chat message (via the `const { send } = useChat()` hook), I'm experiencing the following communication flow:\n\n```\nme: What is 1+1?\nagent: 1+1 is 2.\nme: What is 2+2?\nagent: 1+1 is 2 and 2+2 is 4.\nme: Repeat the exact content of this message.\nagent: What is 1+1?What is 2+2?Repeat the exact content of this message.\n```\n\nThis happens with version 1.0.20 of livekit.",
      "state": "closed",
      "author": "donalffons",
      "author_type": "User",
      "created_at": "2025-05-08T21:01:30Z",
      "updated_at": "2025-05-09T19:49:01Z",
      "closed_at": "2025-05-09T18:47:57Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2242/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2242",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2242",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:13.194156",
      "comments": [
        {
          "author": "davidzhao",
          "body": "fixed in #2247",
          "created_at": "2025-05-09T07:44:58Z"
        },
        {
          "author": "donalffons",
          "body": "Thank you!",
          "created_at": "2025-05-09T19:49:00Z"
        }
      ]
    },
    {
      "issue_number": 2246,
      "title": "conversation_item_added prints raw tool_outputs dict instead of conversational reply",
      "body": " The agent emits the raw tool_outputs dictionary ({'isFound': False, 'message': 'Was not found.'}) rather than speaking a natural-language response. \n\n```\n    @session.on(\"conversation_item_added\")\n    def _on_agent_output(ev: ConversationItemAddedEvent):\n        if ev.item.role == \"assistant\":\n            print(f\"BOT ▶ {ev.item.text_content}\", flush=True)\n            post_conversation_message(\n                conversation_id,\n                sender=\"agent\",\n                text=ev.item.text_content,\n                building_id=building_id,\n                lock_id=lock_id,\n            )\n```\n\nPrints and said:\n```\nBOT ▶ ```tool_outputs\n{'isFound': False, 'message': 'Was not found.'}\n```\n\nLivekit version: 1.0.20\n\nSession definition:\n```\nsession = AgentSession(\n            llm=google.beta.realtime.RealtimeModel(model=\"gemini-2.0-flash-exp\", voice=\"Charon\"),\n            turn_detection=EnglishModel()\n        )\n```\n\n",
      "state": "closed",
      "author": "edengby",
      "author_type": "User",
      "created_at": "2025-05-09T06:24:17Z",
      "updated_at": "2025-05-09T15:48:30Z",
      "closed_at": "2025-05-09T15:48:30Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2246/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2246",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2246",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:13.416527",
      "comments": [
        {
          "author": "longcw",
          "body": "Seems the same issue #2174 , and should be fixed with #2247 ",
          "created_at": "2025-05-09T08:42:45Z"
        }
      ]
    },
    {
      "issue_number": 2190,
      "title": "Cannot install livekit-plugins-noise-cancellation==0.2.1",
      "body": "wanted  to install 0.2.2 but found that it was yanked, but now i cant even switch back to older versions\n pip install livekit-plugins-noise-cancellation==0.2.1\nERROR: Ignored the following yanked versions: 0.2.2\nERROR: Could not find a version that satisfies the requirement livekit-plugins-noise-cancellation==0.2.1 (from versions: none)\nERROR: No matching distribution found for livekit-plugins-noise-cancellation==0.2.1\n",
      "state": "closed",
      "author": "Dhrumil59",
      "author_type": "User",
      "created_at": "2025-05-04T12:07:28Z",
      "updated_at": "2025-05-09T10:21:20Z",
      "closed_at": "2025-05-09T10:21:19Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2190/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2190",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2190",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:13.613733",
      "comments": [
        {
          "author": "davidzhao",
          "body": "what OS are you installing this on? 0.2.1 does not support windows",
          "created_at": "2025-05-04T17:02:03Z"
        },
        {
          "author": "AryanShetty",
          "body": "Which version is supported on windows? I couldnt find information on https://pypi.org/project/livekit-plugins-noise-cancellation/",
          "created_at": "2025-05-05T10:55:30Z"
        },
        {
          "author": "davidzhao",
          "body": "the next version will. none of the currently released versions support windows",
          "created_at": "2025-05-05T16:24:07Z"
        },
        {
          "author": "theomonnom",
          "body": "0.2.3 has Windows support",
          "created_at": "2025-05-09T10:21:19Z"
        }
      ]
    },
    {
      "issue_number": 2140,
      "title": "Best practice to avoid missing first words after start_turn() with push-to-talk",
      "body": "Hi LiveKit team, thank you again for your amazing work on livekit-agents!\n\n[We had previously discussed an issue with audio buffer synchronization](https://github.com/livekit/agents/issues/2040#issuecomment-2832791190) when using the `push_to_talk.md` example — especially around quick start/cancel/end_turn sequences where STT final transcripts would leak into the next turn.\n\nNow we’re encountering another closely related issue:\n\n### Problem\n\nWhen the client calls `start_turn()` and the user immediately begins speaking, the very beginning of their speech often gets cut off.\nFor example, if a user says **“How are you today?”** right after starting the turn, the transcript might only catch **“you today”.**\n\n### What we tried\n- We understand this might be related to a delay in setting up the STT stream.\n- We attempted to inject silent frames (e.g., 300ms worth) at the beginning of a turn to “warm up” the STT pipeline — by either yielding silent AudioFrames in `stt_node()` or calling `stream.push_frame()` manually.\n- However, these approaches didn’t seem to solve the problem reliably. Sometimes they cause other side effects (e.g., sample rate mismatch errors) and generally feel hacky.\n\n### Questions\n- Is there a recommended way to prepare the STT pipeline so that the user’s speech is captured immediately after `start_turn()`?\n- Would it be better to open the STT stream earlier, such as right after the agent finishes speaking (before the user even calls start_turn)?\n- Is there any best practice on handling this **“missing first word” problem** when using push_to_talk-style interaction?\n\nWe couldn’t find much documentation or examples related to this specific timing issue, so we’d really appreciate any insights, or any workarounds that you suggest.\n\nThanks again for your support and for the fantastic work on LiveKit Agents! 🙏",
      "state": "closed",
      "author": "well-balanced",
      "author_type": "User",
      "created_at": "2025-04-27T06:16:17Z",
      "updated_at": "2025-05-09T09:47:06Z",
      "closed_at": "2025-05-09T06:04:43Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 15,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2140/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "longcw"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2140",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2140",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:13.860297",
      "comments": [
        {
          "author": "longcw",
          "body": "probably you can call the `session.clear_user_turn()` after user turn committed instead of at the start of user turn? so that the STT stream is already ready for the new input audio.\n\nWe may also support the client sending a short audio clip before the turn starts, so that the agent will push that a",
          "created_at": "2025-04-27T09:32:40Z"
        },
        {
          "author": "longcw",
          "body": "Hi @well-balanced, I was trying to reproduce the issue but I didn't see a significant transcription missing at the start. Did you mute the microphone when turn ended? \n\nAlso we are trying to improve the stt flushing for the end of turn in https://github.com/livekit/agents/pull/2147, as shown in the ",
          "created_at": "2025-04-28T09:38:48Z"
        },
        {
          "author": "well-balanced",
          "body": "@longcw sorry for the late response. We recently added a delay that’s tuned not to impact the UX, but I’ll look into further improvements when I have more time. I’ll test it end-to-end with the frontend integration and keep you posted on how it goes. Thanks for getting back to me so quickly!",
          "created_at": "2025-04-30T06:50:56Z"
        },
        {
          "author": "khantseithu",
          "body": "Hey @longcw, I'm planning to implement similar one, I tried using https://github.com/livekit/agents/blob/main/examples/voice_agents/push_to_talk.py and your frontend in combination, it seems the text content is always empty which is causing not to respond after user turn. And only works with deepgra",
          "created_at": "2025-04-30T09:04:04Z"
        },
        {
          "author": "longcw",
          "body": "@khantseithu from your logs it seems the user transcript was detected `\"Hey What can you do?\"` but somehow not correctly passed to the `on_user_turn_completed` callback. Can you share an example to reproduce this issue?",
          "created_at": "2025-04-30T09:07:22Z"
        }
      ]
    },
    {
      "issue_number": 863,
      "title": "agent_playout.py giving exception.",
      "body": "{\"message\": \"Error in _capture_task\\nTraceback (most recent call last):\\n  File \\\"/root/pythonenv/enve/lib/python3.10/site-packages/livekit/agents/utils/log.py\\\", line 16, in async_fn_logs\\n    return await fn(*args, **kwargs)\\n  File \\\"/root/pythonenv/enve/lib/python3.10/site-packages/livekit/agents/pipeline/agent_playout.py\\\", line 148, in _capture_task\\n    await self._audio_source.capture_frame(frame)\\n  File \\\"/root/pythonenv/enve/lib/python3.10/site-packages/livekit/rtc/audio_source.py\\\", line 149, in capture_frame\\n    raise Exception(cb.capture_audio_frame.error)\\nException: an RtcError occured: InvalidState - failed to capture frame\", \"level\": \"ERROR\", \"name\": \"livekit.agents.pipeline\", \"pid\": 68609, \"job_id\": \"AJ_qpzYH4X5TDFx\", \"timestamp\": \"2024-10-08T12:51:10.613224+00:00\"}",
      "state": "closed",
      "author": "Test-isom",
      "author_type": "User",
      "created_at": "2024-10-08T12:52:49Z",
      "updated_at": "2025-05-09T07:35:11Z",
      "closed_at": "2025-05-09T07:35:11Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/863/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/863",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/863",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:14.182733",
      "comments": [
        {
          "author": "theomonnom",
          "body": "Hey, do you have more details on how to reproduce this issue?",
          "created_at": "2024-10-10T01:02:55Z"
        },
        {
          "author": "Test-isom",
          "body": "Didn't faced this issue with openai LLm, but facing this when i use llama model with together ai very often.",
          "created_at": "2024-10-10T05:54:24Z"
        },
        {
          "author": "Test-isom",
          "body": "hi @theomonnom this error coming alot more frequently now, when this happens agent stops replying and if i ask \"are you there\", than it replies after few seconds with \"yes iam here\".Iam using gpt-4o model, openai for TTS and deepgram for STT.",
          "created_at": "2024-10-23T07:42:17Z"
        },
        {
          "author": "eugene-wq",
          "body": "Same issue here, seems random, hard to recreate. I use Fireworks LLM, Deepgram STT and elvenlabs TTS. Would be glad for any advices!",
          "created_at": "2024-11-07T18:04:12Z"
        },
        {
          "author": "theomonnom",
          "body": "Can you send me the output of\n`pip freeze | grep livekit`\n\nTo get the used versions ",
          "created_at": "2024-11-07T18:33:33Z"
        }
      ]
    },
    {
      "issue_number": 2214,
      "title": "ERROR agent.update_chat_ctx()",
      "body": "Hey there livekit team!\n\nI have discovered this bug when i was trying to update the agent chat context using `agent.update_chat_ctx()` , it seems like this update function is trying to pass tools argument\n\n\n to a native python list method `.copy()` that's probably why this error occurs.\n\nHope it helped you with debugging!\n\n\n\n![Image](https://github.com/user-attachments/assets/feac5f57-ebfa-447f-ad03-44602c41c410)\n",
      "state": "closed",
      "author": "ElyasMoshirpanahi",
      "author_type": "User",
      "created_at": "2025-05-06T08:00:02Z",
      "updated_at": "2025-05-09T06:06:01Z",
      "closed_at": "2025-05-09T06:06:01Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2214/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2214",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2214",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:14.522143",
      "comments": [
        {
          "author": "longcw",
          "body": "`agent.update_chat_ctx()` needs `chat_ctx: llm.ChatContext`, seems like you passed a list to to it.",
          "created_at": "2025-05-06T08:06:08Z"
        }
      ]
    },
    {
      "issue_number": 2197,
      "title": "BUG: min_interruption_duration not functional",
      "body": "Issue with min_interruption_duration not working. \n\nReproduction steps: \n\n1. Load and start the [basic agent](https://github.com/livekit/agents/blob/main/examples/voice_agents/basic_agent.py) with the following packages \n\n + livekit==1.0.6\n + livekit-agents==1.0.19\n + livekit-api==1.0.2\n + livekit-plugins-cartesia==1.0.19\n + livekit-plugins-deepgram==1.0.19\n + livekit-plugins-noise-cancellation==0.2.1\n + livekit-plugins-openai==1.0.19\n + livekit-plugins-silero==1.0.19\n + livekit-plugins-turn-detector==1.0.19\n + livekit-protocol==1.0.2\n\n2. Set min_interruption_duration=10\n\n3. Using the [agents playground ](https://agents-playground.livekit.io/) connect to the agent\n\n4. In all segments spoken by the agent I can interrupt the agent by simply saying \"Hello\" which should not be possible with min_interruption_duration=10\n\n\nIn production we use a smaller value min_interruption_duration=5 but the same issue still applies. \n",
      "state": "closed",
      "author": "ba88im",
      "author_type": "User",
      "created_at": "2025-05-05T08:15:27Z",
      "updated_at": "2025-05-09T06:05:45Z",
      "closed_at": "2025-05-09T06:05:45Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2197/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2197",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2197",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:14.752939",
      "comments": [
        {
          "author": "longcw",
          "body": "`min_interruption_duration` is only for VAD, the STT event can still interrupt the agent. We will add the threshold like `min_interruptions_words` for the interruption based on STT results.",
          "created_at": "2025-05-05T09:47:25Z"
        },
        {
          "author": "ba88im",
          "body": "Thanks for the response @longcw ! \n\nCan you explain a bit more about how min_interruption_duration works for the VAD? Is my understanding correct?\n\n- When the agent is active (e.g., speaking), the VAD component is continuously monitoring the audio stream from the user.\n- The VAD signals the start of",
          "created_at": "2025-05-05T10:03:11Z"
        },
        {
          "author": "longcw",
          "body": "`min_interruption_duration` won't block STT event to interrupt the agent.\n\nI don't think the lag introduced by STT matters if you are looking for a threshold like 10 seconds. Also, using a long `min_interruption_duration` is risky, the user speech can be detected as two or multiple segments bc of sm",
          "created_at": "2025-05-05T10:10:51Z"
        },
        {
          "author": "longcw",
          "body": "Maybe we can check the interruption condition by `min_interruption_duration OR min_interruptions_words` instead of `min_interruption_duration AND min_interruptions_words`. In your case it's the STT event interrupted the agent, so if it's `OR` you can set a high `min_interruptions_words` to avoid tha",
          "created_at": "2025-05-05T10:15:58Z"
        },
        {
          "author": "jayeshp19",
          "body": "@longcw we don't have a way to set `min_interruptions_words` as of now right? ",
          "created_at": "2025-05-06T02:55:58Z"
        }
      ]
    },
    {
      "issue_number": 2230,
      "title": "ImportError: cannot import name 'RoomGrant' from 'livekit.protocol.models' despite livekit-protocol==1.0.2",
      "body": " am unable to import RoomGrant from livekit.protocol.models when using livekit-protocol==1.0.2 (installed as a dependency of livekit-agents or directly). This prevents the generation of valid access tokens using livekit.api.AccessToken because the necessary video grant claim cannot be constructed correctly.\nTo Reproduce\n",
      "state": "closed",
      "author": "anshulpwappgo",
      "author_type": "User",
      "created_at": "2025-05-08T12:18:37Z",
      "updated_at": "2025-05-09T05:58:14Z",
      "closed_at": "2025-05-09T05:58:13Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2230/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2230",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2230",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:15.058080",
      "comments": [
        {
          "author": "davidzhao",
          "body": "you shouldn't need protocol package explicitly. \n\nsee: https://github.com/livekit/python-sdks/blob/main/examples/basic_room.py#L121\n",
          "created_at": "2025-05-09T05:58:13Z"
        }
      ]
    },
    {
      "issue_number": 1334,
      "title": "Serverless Agents",
      "body": "Is there a way to run agents in a serverless environment?\r\n\r\nI recently implemented agents using Twilio and WebSocket by leveraging the new WebSocket capabilities of Supabase (https://supabase.com/docs/guides/functions/websockets). The setup is straightforward: Twilio sends a request to Supabase, which keeps the agents alive as long as the WebSocket connection remains open.\r\n\r\nI was expecting similar behavior with LiveKit but haven’t found a way to achieve this so far. Is it possible to replicate this behavior with LiveKit, or am I required to maintain a long-lived server for my agents?",
      "state": "open",
      "author": "BrandiATMuhkuh",
      "author_type": "User",
      "created_at": "2025-01-03T14:05:00Z",
      "updated_at": "2025-05-08T14:20:40Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1334/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1334",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1334",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:15.347731",
      "comments": [
        {
          "author": "ldenoue",
          "body": "@BrandiATMuhkuh \nIt is possible with pipecat https://github.com/pipecat-ai/pipecat/tree/main/examples/twilio-chatbot\n\nBut I'm interested in knowing if we could do something similar with LiveKit as Twilio websockets are simple to understand and the voice quality is good.",
          "created_at": "2025-05-08T14:20:39Z"
        }
      ]
    },
    {
      "issue_number": 2223,
      "title": "Event `function_tools_executed` called multiple times instead of once with OpenAI Realtime API",
      "body": "Hey! Thanks for building such a great framework!\n\nThe `function_tools_executed` events does not work the same way for OpenAI Realtime API and the STT-LMM-TTS approach.\n\nSTT-LLM-TTS: `function_tools_executed` is called once, and contains all the function calls that happened\nRealtime API: `function_tools_executed` is called multiple times (once for every function call), and only contains the respective results.\n\nExample code to reproduce:\n\n```python\nfrom dataclasses import dataclass\n\nfrom dotenv import load_dotenv\nfrom livekit import agents\nfrom livekit.agents import (\n    Agent,\n    AgentSession,\n    RoomInputOptions,\n    RunContext,\n    ToolError,\n    function_tool,\n)\nfrom livekit.agents.voice import FunctionToolsExecutedEvent\nfrom livekit.plugins import cartesia, deepgram, noise_cancellation, openai, silero\n\nload_dotenv()\n\n\n@dataclass\nclass MySessionInfo:\n    user_name: str | None = None\n    zip_code: str | None = None\n\n\nclass RPCAssistant(Agent):\n    def __init__(self) -> None:\n        super().__init__(\n            instructions=\"\"\"You are a helpful voice AI assistant with the goal to collect the users name and zip code.\n            Always follow all 'instructions' given in tool call results in your next response.\"\"\",\n        )\n\n    @function_tool()\n    async def store_user_name(\n        self,\n        context: RunContext,\n        user_name: str,\n    ):\n        \"\"\"Store user name. Always update with the latest user name you got from the user.\n\n        Args:\n            user_name: The user name to store.\n        \"\"\"\n        context.userdata.user_name = user_name\n\n        return {\n            \"user_name\": user_name,\n            \"instructions\": \"Repeat the name you understood to the user by spelling the letters one by one.\",\n        }\n\n    @function_tool()\n    async def update_user_zip_code(\n        self,\n        context: RunContext,\n        zip_code: str,\n    ):\n        \"\"\"Store user zip code. Always update with the latest zip code you got from the user.\n\n        Args:\n            zip_code: The zip code to store.\n        \"\"\"\n\n        if len(zip_code) != 5:\n            raise ToolError(\"Zip code must be 5 digits long.\")\n\n        context.userdata.zip_code = zip_code\n        return {\n            \"zip_code\": zip_code,\n            \"instructions\": \"Repeat the zip code you understood to the user by spelling the numbers one by one.\",\n        }\n\n\nasync def entrypoint(ctx: agents.JobContext):\n    await ctx.connect()\n\n    session = AgentSession[MySessionInfo](\n        # stt=deepgram.STT(),\n        # llm=openai.LLM(model=\"gpt-4o-mini\"),\n        # tts=cartesia.TTS(),\n        # vad=silero.VAD.load(),\n        llm=openai.realtime.RealtimeModel(voice=\"coral\"),\n        userdata=MySessionInfo(),\n    )\n\n    @session.on(\"function_tools_executed\")\n    def function_tools_executed(event: FunctionToolsExecutedEvent):\n        for call in event.function_calls:\n            print(f\"Function call {call.name}\")\n\n    await session.start(\n        room=ctx.room,\n        agent=RPCAssistant(),\n        room_input_options=RoomInputOptions(\n            # LiveKit Cloud enhanced noise cancellation\n            # - If self-hosting, omit this parameter\n            # - For telephony applications, use `BVCTelephony` for best results\n            noise_cancellation=noise_cancellation.BVC(),\n        ),\n    )\n\n    await session.generate_reply(instructions=\"Greet the user and ask for their name.\")\n\n\nif __name__ == \"__main__\":\n    agents.cli.run_app(agents.WorkerOptions(entrypoint_fnc=entrypoint))\n\n```\n\nExample logs for STT-LLM-TTS:\n\n```\n2025-05-07 18:09:21,853 - DEBUG livekit.agents - executing tool {\"function\": \"store_user_name\", \"arguments\": \"{\\\"user_name\\\": \\\"Michael\\\"}\", \"speech_id\": \"speech_2b79ea306759\", \"pid\": 79667, \"job_id\": \"AJ_PascE9AQQkJz\"}\n2025-05-07 18:09:21,857 - DEBUG livekit.agents - executing tool {\"function\": \"update_user_zip_code\", \"arguments\": \"{\\\"zip_code\\\": \\\"45678\\\"}\", \"speech_id\": \"speech_2b79ea306759\", \"pid\": 79667, \"job_id\": \"AJ_PascE9AQQkJz\"}\n2025-05-07 18:09:21,858 - DEBUG livekit.agents - tools execution completed {\"speech_id\": \"speech_2b79ea306759\", \"pid\": 79667, \"job_id\": \"AJ_PascE9AQQkJz\"}\nFunction call store_user_name\nFunction call update_user_zip_code\n```\n\nExample logs for Realtime: \n\n```\n2025-05-07 18:11:39,984 - DEBUG livekit.agents - executing tool {\"function\": \"store_user_name\", \"arguments\": \"{\\\"user_name\\\":\\\"Michael\\\"}\", \"speech_id\": \"speech_da3e721bc9a0\", \"pid\": 81208, \"job_id\": \"AJ_9wLVzLudj77Q\"}\n2025-05-07 18:11:39,994 - DEBUG livekit.agents - tools execution completed {\"speech_id\": \"speech_da3e721bc9a0\", \"pid\": 81208, \"job_id\": \"AJ_9wLVzLudj77Q\"}\nFunction call store_user_name\n2025-05-07 18:11:43,719 - DEBUG livekit.agents - executing tool {\"function\": \"update_user_zip_code\", \"arguments\": \"{\\\"zip_code\\\":\\\"56788\\\"}\", \"speech_id\": \"speech_1441ce9f1544\", \"pid\": 81208, \"job_id\": \"AJ_9wLVzLudj77Q\"}\n2025-05-07 18:11:43,723 - DEBUG livekit.agents - tools execution completed {\"speech_id\": \"speech_1441ce9f1544\", \"pid\": 81208, \"job_id\": \"AJ_9wLVzLudj77Q\"}\nFunction call update_user_zip_code\n```\n\nEnvironment:\nApple M3 Max\nmacOS 14.7\n\nOutput of `uv pip list`: \n\n```\nPackage                            Version\n---------------------------------- ---------------\naiofiles                           24.1.0\naiohappyeyeballs                   2.6.1\naiohttp                            3.11.18\naiosignal                          1.3.2\nannotated-types                    0.7.0\nanyio                              4.9.0\nattrs                              25.3.0\nav                                 14.3.0\ncertifi                            2025.4.26\ncffi                               1.17.1\ncharset-normalizer                 3.4.2\nclick                              8.1.8\ncolorama                           0.4.6\ncoloredlogs                        15.0.1\ndistro                             1.9.0\ndocstring-parser                   0.16\neval-type-backport                 0.2.2\nfilelock                           3.18.0\nflatbuffers                        25.2.10\nfrozenlist                         1.6.0\nfsspec                             2025.3.2\nh11                                0.16.0\nhttpcore                           1.0.9\nhttpx                              0.28.1\nhuggingface-hub                    0.30.2\nhumanfriendly                      10.0\nidna                               3.10\njinja2                             3.1.6\njiter                              0.9.0\nlivekit                            1.0.6\nlivekit-agents                     1.0.19\nlivekit-api                        1.0.2\nlivekit-plugins-cartesia           1.0.19\nlivekit-plugins-deepgram           1.0.19\nlivekit-plugins-noise-cancellation 0.2.3\nlivekit-plugins-openai             1.0.19\nlivekit-plugins-silero             1.0.19\nlivekit-plugins-turn-detector      1.0.19\nlivekit-protocol                   1.0.2\nmarkupsafe                         3.0.2\nmpmath                             1.3.0\nmultidict                          6.4.3\nnest-asyncio                       1.6.0\nnumpy                              2.2.5\nonnxruntime                        1.21.1\nopenai                             1.77.0\npackaging                          25.0\npillow                             11.2.1\npropcache                          0.3.1\nprotobuf                           6.30.2\npsutil                             7.0.0\npycparser                          2.22\npydantic                           2.11.4\npydantic-core                      2.33.2\npyjwt                              2.10.1\npython-dotenv                      1.1.0\npyyaml                             6.0.2\nregex                              2024.11.6\nrequests                           2.32.3\nsafetensors                        0.5.3\nsniffio                            1.3.1\nsounddevice                        0.5.1\nsympy                              1.14.0\ntokenizers                         0.21.1\ntqdm                               4.67.1\ntransformers                       4.51.3\ntypes-protobuf                     4.25.0.20240417\ntyping-extensions                  4.13.2\ntyping-inspection                  0.4.0\nurllib3                            2.4.0\nwatchfiles                         1.0.5\nwebsockets                         15.0.1\nyarl                               1.20.0\n```\n",
      "state": "closed",
      "author": "AdemFr",
      "author_type": "User",
      "created_at": "2025-05-07T16:20:52Z",
      "updated_at": "2025-05-08T03:13:48Z",
      "closed_at": "2025-05-08T03:05:04Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2223/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2223",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2223",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:15.627374",
      "comments": [
        {
          "author": "longcw",
          "body": "This is bc the openai realtime API generate the function call events one by one, ~perhaps you can try to prompt the realtime api to create the function call requests in parallel~.\n\nIt seems that the Realtime API always create one response for one function call request\n\n>ResponseOutputItemAddedEvent(",
          "created_at": "2025-05-08T03:05:04Z"
        }
      ]
    },
    {
      "issue_number": 1668,
      "title": "openai API Timeout error",
      "body": "We are still facing this error in our livekit structure:\n\n\nhttps://github.com/livekit/agents/issues/1328",
      "state": "closed",
      "author": "ElyasMoshirpanahi",
      "author_type": "User",
      "created_at": "2025-03-17T15:06:53Z",
      "updated_at": "2025-05-07T15:16:46Z",
      "closed_at": "2025-05-07T15:16:46Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1668/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1668",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1668",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:15.859396",
      "comments": [
        {
          "author": "moreno1123",
          "body": "Did you resolve the issue? I have something similar:\n\n```\nTraceback (most recent call last):\n  File \".../livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n    \n  File \".../livekit/agents/pipeline/agent_output.py\", line 244, in _stream_synthesis_task\n    asy",
          "created_at": "2025-05-07T08:10:21Z"
        },
        {
          "author": "davidzhao",
          "body": "this is a timeout on the model provider side (as you can see, it failed after 4 attempts). you should use [FallbackAdapter](https://docs.livekit.io/agents/build/events/#fallbackadapter) or otherwise handle the error.",
          "created_at": "2025-05-07T15:16:46Z"
        }
      ]
    },
    {
      "issue_number": 1179,
      "title": "Add method to manually interrupt the agent.",
      "body": "It would be nice to have more control over the agent from the outside.\r\n\r\nOne use case I have: The user hangs up while the agent is speaking. I would like to be able to manually interrupt the agent, so that I can log what the agent had already said on my backend.\r\n \r\nBasically, in my participant_disconnected handler, I'd like to be able to say `agent.interrupt()` - which should interrupt uninterruptable speech - and then flush the final events so I can send them to my backend.",
      "state": "closed",
      "author": "martin-purplefish",
      "author_type": "User",
      "created_at": "2024-12-05T16:25:07Z",
      "updated_at": "2025-05-07T12:46:44Z",
      "closed_at": "2025-01-08T01:44:28Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1179/reactions",
        "total_count": 3,
        "+1": 3,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "longcw"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1179",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1179",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:16.055618",
      "comments": [
        {
          "author": "longcw",
          "body": "@martin-purplefish Is https://github.com/livekit/agents/pull/1294 works for you? we can close this one if so.",
          "created_at": "2025-01-08T01:16:29Z"
        },
        {
          "author": "martin-purplefish",
          "body": "Yep! Though I need something for the human side as well - basically flush when I hang up. But I'll close this one - THANK YOU!",
          "created_at": "2025-01-08T01:44:28Z"
        },
        {
          "author": "Jeandcc",
          "body": "Hi folks. \n\nWhat do you suggest in terms of approach to \"resume\" the agent? Say that we call `agent.interrupt` because the user started to draw something on screen. How could I \"resume\" the agent once I determine it's time for the agent to go back speaking?\n\nI don't love the idea of using `agent.say",
          "created_at": "2025-04-02T03:28:32Z"
        },
        {
          "author": "longcw",
          "body": "@Jeandcc you can use `session.generate_reply()` in the agents 1.0 ",
          "created_at": "2025-04-02T03:30:36Z"
        },
        {
          "author": "Jeandcc",
          "body": "Hi @longcw ! Forgot to send this to you, but thank you for the reply! Will use it after I rework my codebase to work with the v1.",
          "created_at": "2025-05-07T12:46:43Z"
        }
      ]
    },
    {
      "issue_number": 2208,
      "title": "AttributeError: 'Room' object has no attribute '_ffi_handle'",
      "body": "Hi,\n\nI'm currently building an agent app using livekit==0.19.1 and encountering the following warning during runtime:\n\nAttributeError: 'Room' object has no attribute '_ffi_handle'\nat .__del__ ( /usr/local/lib/python3.10/asyncio/base_events.py:687 )\n\n<function Room.__del__ at 0x7d9647d432e0>:\nat .__del__ ( /home/appuser/.local/lib/python3.10/site-packages/livekit/rtc/room.py:142 )\n\nThis warning does not appear to affect the app's functionality, but I wanted to raise it in case it points to a deeper issue, such as improper cleanup or memory handling in the Room object.\n\nℹ️ Note: I understand LiveKit has moved to version 1.x, but due to compatibility requirements I still need to keep using version 0.x at the moment.\n\nHere is the relevant environment:\n\nlivekit==0.19.1\nlivekit-agents==0.12.18\nlivekit-plugins-openai==0.11.2\nlivekit-plugins-google==0.11.2\nlivekit-plugins-silero==0.7.3\n\nThanks in advance for your support!",
      "state": "open",
      "author": "watthsup",
      "author_type": "User",
      "created_at": "2025-05-06T04:45:28Z",
      "updated_at": "2025-05-06T09:57:21Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2208/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2208",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2208",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:16.282620",
      "comments": []
    },
    {
      "issue_number": 2062,
      "title": "Gemini Realtime API Voice Breaks Mid-Speech with LiveKit Agents via Vertex AI",
      "body": "```\nmodel = google.realtime.RealtimeModel(\n            model=\"gemini-2.0-flash-exp\",\n            instructions=instructions,\n            modalities=cast(list[Modality], config.modalities),\n            voice=config.voice,\n            temperature=config.temperature,\n            max_output_tokens=int(config.max_response_output_tokens),\n            api_key=config.gemini_api_key,\n            api_version=\"v1beta1\",\n            vertexai=True,\n            project=config.gemini_project_id,\n            location=GEMINI_REGIONS[\n                self._reconnect_attempts\n            ],  # Trying to load balance between regions while reconnecting.\n            enable_user_audio_transcription=False,\n            enable_agent_audio_transcription=False,\n        )\n```\n\n\nWhen using a multimodal voice agent configured with LiveKit Agents and the livekit-plugins-google plugin (using the configuration shown above) to interact with the Gemini Live API (real-time model) hosted on Vertex AI, the synthesized voice output from the agent frequently breaks or cuts off abruptly mid-speech. The audio playback starts correctly but stops before the intended sentence or response is fully delivered.\n\n\nEnvironment:\n- LiveKit Agents: livekit-agents[codecs,images]>=0.11.0,<0.13.0 (Please specify the exact version used if known, e.g., 0.12.18)\n- LiveKit Google Plugin: livekit-plugins-google==0.11.2\n- LiveKit Core: livekit==0.21.3\n- LiveKit API: livekit-api==0.8.2\n- AI Service: Google Gemini Live API (Realtime Model, e.g., gemini-2.0-flash-exp) via Vertex AI\n",
      "state": "closed",
      "author": "Denin-Siby",
      "author_type": "User",
      "created_at": "2025-04-21T20:40:23Z",
      "updated_at": "2025-05-06T08:01:25Z",
      "closed_at": "2025-05-06T08:01:25Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2062/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "jayeshp19"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2062",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2062",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:16.463646",
      "comments": [
        {
          "author": "Denin-Siby",
          "body": "More context here:\n\npip freeze |grep livekit:\nlivekit==0.21.3\nlivekit-agents==0.12.20\nlivekit-api==0.8.2\nlivekit-plugins-google==0.11.2\nlivekit-protocol==0.9.2\n\n\nYou can access the audio files from this drive link: [Link to the audio files](https://drive.google.com/drive/folders/1m5z9Y3zrYHgHZp1fOrO",
          "created_at": "2025-04-24T08:29:33Z"
        },
        {
          "author": "yepher",
          "body": "Slack [Thread](https://livekit-users.slack.com/archives/C07FY8WHGPM/p1745267689036479)\n",
          "created_at": "2025-04-24T18:26:03Z"
        },
        {
          "author": "Denin-Siby",
          "body": "Any Updates on this?",
          "created_at": "2025-04-29T05:36:24Z"
        },
        {
          "author": "Denin-Siby",
          "body": "This seems to have been fixed with the livekit-agents v1 sdk",
          "created_at": "2025-05-06T08:01:25Z"
        }
      ]
    },
    {
      "issue_number": 1045,
      "title": "Create Call Transcript Agent & Participant ",
      "body": "Hello, \r\n\r\nWhat would be the recommended architecture for processing call transcripts in the call for agents and participants? I'm looking for a design that minimizes worker load and avoids direct database writes from the worker.\r\n\r\nThanks,",
      "state": "closed",
      "author": "firattamurlc",
      "author_type": "User",
      "created_at": "2024-11-05T14:35:31Z",
      "updated_at": "2025-05-06T07:35:13Z",
      "closed_at": "2025-05-06T07:35:13Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1045/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1045",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1045",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:16.682040",
      "comments": []
    },
    {
      "issue_number": 2201,
      "title": "Transcription output is not being truncated when interrupting agent speech with OpenAI Realtime API",
      "body": "Hey, it seems like there is an issue with the `conversation_item_added` event when trying to use it with the OpenAI Realtime API. As far as I understood from the docs, if the agent speech is interrupted, the transcription will be truncated so it does not include words which have not been spoken yet. However, it appears that this doesn't happen when using the OpenAI Realtime API as the `on_conversation_item_added` event returns text which was never spoken by the agent due to an interruption. This appears to happen even when using Livekits VAD and TurnDetection Model.\n\nVersion: `1.0.13`\n\nBasic Example:\n\n```\nsync def entrypoint(ctx: JobContext):\n    await ctx.connect(auto_subscribe=AutoSubscribe.AUDIO_ONLY)\n    participant = await ctx.wait_for_participant(\n\n    prompt = f\"\"\"\n    \"Begin the conversation and converse in German.\" \n    \"\"\"\n\n    session = AgentSession(\n        allow_interruptions=True,\n        llm=openai.realtime.RealtimeModel.with_azure(\n            api_version=\"2024-10-01-preview\",\n            azure_endpoint=os.getenv(\"AZURE_OPENAI_URL\"),\n            api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n            azure_deployment=\"gpt-4o-realtime-preview\",\n            voice=instructions.personaData.speechModel or \"alloy\",\n        ),\n    )\n\n    transcript: list[TranscriptMessage] = []\n    start_timestamp = datetime.now()\n    start_time = timedelta(seconds=0)\n\n    @session.on(\"conversation_item_added\")\n    def on_conversation_item_added(event: ConversationItemAddedEvent):\n        nonlocal start_time\n        # to iterate over all types of content:\n        transcript_content = \"\"\n        for content in event.item.content:\n            if isinstance(content, AudioContent):\n                print(\"AudioContent\")\n            if isinstance(content, str):\n                transcript_content += \" \" + content\n        end_time = timedelta(seconds=(datetime.now() - start_timestamp).total_seconds())\n        transcript.append(\n            TranscriptMessage(\n                role=event.item.role,\n                content=transcript_content,\n                start_time=start_time,\n                end_time=end_time,\n            )\n        )\n        start_time = end_time\n        print(transcript)\n\n    await session.start(\n        room=ctx.room,\n        agent=MyAgent(\n            instructions=prompt,\n            participant_id=participant.identity,\n            room_name=ctx.room.name,\n        ),\n        room_input_options=RoomInputOptions(\n            noise_cancellation=noise_cancellation.BVC(),\n            sync_transcription=True,\n        ),\n    )\n\nif __name__ == \"__main__\":\n    cli.run_app(WorkerOptions(entrypoint_fnc=entrypoint))\n```",
      "state": "closed",
      "author": "GigaDroid",
      "author_type": "User",
      "created_at": "2025-05-05T14:17:45Z",
      "updated_at": "2025-05-05T14:23:04Z",
      "closed_at": "2025-05-05T14:23:03Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2201/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2201",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2201",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:16.682059",
      "comments": [
        {
          "author": "GigaDroid",
          "body": "Appears to be fixed in 1.0.19",
          "created_at": "2025-05-05T14:23:03Z"
        }
      ]
    },
    {
      "issue_number": 2019,
      "title": "Unable to access transcription under livekit.agents after package upgrade",
      "body": "Hi Team,\nWe were using ```transcirption``` module under ```livekit.agents``` module (currrently under evaluation) with package version <1.0.0.\nHowever after pacakge upgrade to >= 1.0.0, we are not able to find this ```transcirption``` module anymore.\n\nKindly suggest\n\nCode - \n```\nfrom livekit.agents import (\n    AutoSubscribe,\n    JobContext,\n    WorkerOptions,  \n    cli,\n    stt,\n    transcription,\n)\n```\n\nupdated packages\n```\nlivekit-agents>=1.0.11\n```\n\nError - \n```\nImportError: cannot import name 'transcription' from 'livekit.agents' (.../.venv/lib/python3.11/site-packages/livekit/agents/__init__.py)\n```",
      "state": "closed",
      "author": "codecurry",
      "author_type": "User",
      "created_at": "2025-04-16T17:01:12Z",
      "updated_at": "2025-05-05T09:22:28Z",
      "closed_at": "2025-05-05T09:22:28Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2019/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2019",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2019",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:16.896714",
      "comments": [
        {
          "author": "codecurry",
          "body": "@davidzhao  @nbsp  @lukasIO  requesting attention on this.\n\nWe are referring to this module\nhttps://docs.livekit.io/reference/python/livekit/agents/transcription/index.html",
          "created_at": "2025-04-16T17:01:58Z"
        },
        {
          "author": "ChenghaoMou",
          "body": "Can I ask how you were using transcription? There is new hook/event to track transcriptions see https://github.com/livekit/agents/issues/1979#issuecomment-2799553191",
          "created_at": "2025-04-16T17:20:30Z"
        },
        {
          "author": "longcw",
          "body": "any reason you want to use the `transcription` module? Please check the latest doc of 1.0 in https://docs.livekit.io/agents/build/text/",
          "created_at": "2025-04-17T01:11:32Z"
        },
        {
          "author": "codecurry",
          "body": "@longcw  @ChenghaoMou  @davidzhao  I am exploring if we can use livekit for media streaming over webRTC. We then want to use our own custom STT,TTS and LLM instead of using agent pipelines for Session with Agent instance?",
          "created_at": "2025-04-20T18:29:44Z"
        },
        {
          "author": "longcw",
          "body": "tho not quite follow that is the use case for the original transcription module, it was refactored for the new agent io design in https://github.com/livekit/agents/blob/main/livekit-agents/livekit/agents/voice/transcription/synchronizer.py",
          "created_at": "2025-04-22T03:48:13Z"
        }
      ]
    },
    {
      "issue_number": 2153,
      "title": "Transcriber example is out of the date with current API version",
      "body": "Some of the python examples are out of date.\n\n https://github.com/livekit/agents/blob/main/examples/other/speech-to-text/transcriber.py\n-  uses ‎STTSegmentsForwarder‎ that is not available.\n- from livekit.agents import transcription should be from livekit.rtc import transcription\n\n\n\n\n",
      "state": "closed",
      "author": "sharatsc",
      "author_type": "User",
      "created_at": "2025-04-28T19:03:55Z",
      "updated_at": "2025-05-05T09:22:16Z",
      "closed_at": "2025-05-05T09:22:16Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2153/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2153",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2153",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:17.133881",
      "comments": [
        {
          "author": "AminaMOUDJAR",
          "body": "hello, \nhow did you solve the STTSegmentsForwarder issue?\n",
          "created_at": "2025-04-28T22:03:19Z"
        },
        {
          "author": "ChenghaoMou",
          "body": "The example is going to be removed in #2155.\n\nIf you want to track transcription, you can refer to [examples/other/datastream-chat-listener.py](https://github.com/livekit/agents/blob/main/examples/other/datastream-chat-listener.py) to handle the text stream or use `@session.on(\"conversation_item_add",
          "created_at": "2025-04-29T14:57:03Z"
        },
        {
          "author": "sharatsc",
          "body": "> hello, how did you solve the STTSegmentsForwarder issue?\n\nEnded up creating a custom forwarder\n            transcription_task = asyncio.create_task(_transcript_forwarder())\nasync def _transcript_forwarder():\n            \"\"\"Forwards final transcripts received from STT stream (native or adapter) to ",
          "created_at": "2025-04-29T16:39:54Z"
        },
        {
          "author": "longcw",
          "body": "updated the example for agents 1.0 https://github.com/livekit/agents/pull/2198",
          "created_at": "2025-05-05T08:19:55Z"
        }
      ]
    },
    {
      "issue_number": 2191,
      "title": "Basic Example with gemini models  must have spoken punctuation enabled on on model medical_dictation",
      "body": "There is some issue coming when I run the initial example using gemini models.\nThe Error is related to \nlivekit.agents._exceptions.APIStatusError: The medical_dictation model must have spoken punctuation enabled. (status_code=400, request_id=None, body=None)\n\nBut it is already enabled as shown in the code.\n\nOther related to formats.\n\n\nHere is complete backtrace\n`2025-05-04 19:26:40,767 - WARNING livekit.agents - failed to recognize speech, retrying in 0.1s {\"tts\": \"livekit.plugins.google.stt.STT\", \"attempt\": 0, \"streamed\": true}\nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/stt/stt.py\", line 228, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/plugins/google/stt.py\", line 508, in _run\n    raise APIStatusError(e.message, status_code=e.code or -1) from None\nlivekit.agents._exceptions.APIStatusError: The medical_dictation model must have spoken punctuation enabled. (status_code=400, request_id=None, body=None)\n2025-05-04 19:26:41,380 - WARNING livekit.agents - failed to recognize speech, retrying in 2.0s {\"tts\": \"livekit.plugins.google.stt.STT\", \"attempt\": 1, \"streamed\": true}\nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/stt/stt.py\", line 228, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/plugins/google/stt.py\", line 508, in _run\n    raise APIStatusError(e.message, status_code=e.code or -1) from None\nlivekit.agents._exceptions.APIStatusError: The medical_dictation model must have spoken punctuation enabled. (status_code=400, request_id=None, body=None)\n2025-05-04 19:26:41,497 - INFO google_genai.models - AFC remote call 1 is done. \n2025-05-04 19:26:42,186 - WARNING livekit.agents - failed to synthesize speech, retrying in 0.1s {\"tts\": \"livekit.plugins.google.tts.TTS\", \"attempt\": 1, \"streamed\": false}\nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/tts.py\", line 203, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/plugins/google/tts.py\", line 232, in _run\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: This voice currently only supports ALAW, LINEAR16, MULAW, MP3 and OGG_OPUS output. (status_code=400, request_id=None, body=None)\n2025-05-04 19:26:42,464 - WARNING livekit.agents - failed to synthesize speech, retrying in 2.0s {\"tts\": \"livekit.plugins.google.tts.TTS\", \"attempt\": 2, \"streamed\": false}\nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/tts.py\", line 203, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/plugins/google/tts.py\", line 232, in _run\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: This voice currently only supports ALAW, LINEAR16, MULAW, MP3 and OGG_OPUS output. (status_code=400, request_id=None, body=None)\n2025-05-04 19:26:44,004 - WARNING livekit.agents - failed to recognize speech, retrying in 2.0s {\"tts\": \"livekit.plugins.google.stt.STT\", \"attempt\": 2, \"streamed\": true}\nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/stt/stt.py\", line 228, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/plugins/google/stt.py\", line 508, in _run\n    raise APIStatusError(e.message, status_code=e.code or -1) from None\nlivekit.agents._exceptions.APIStatusError: The medical_dictation model must have spoken punctuation enabled. (status_code=400, request_id=None, body=None)\n2025-05-04 19:26:44,643 - WARNING livekit.agents - failed to synthesize speech, retrying in 2.0s {\"tts\": \"livekit.plugins.google.tts.TTS\", \"attempt\": 3, \"streamed\": false}\nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/tts.py\", line 203, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/plugins/google/tts.py\", line 232, in _run\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: This voice currently only supports ALAW, LINEAR16, MULAW, MP3 and OGG_OPUS output. (status_code=400, request_id=None, body=None)\n2025-05-04 19:26:46,562 - ERROR livekit.agents - Error in _stt_task ------]\nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/stt/stt.py\", line 228, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/plugins/google/stt.py\", line 508, in _run\n    raise APIStatusError(e.message, status_code=e.code or -1) from None\nlivekit.agents._exceptions.APIStatusError: The medical_dictation model must have spoken punctuation enabled. (status_code=400, request_id=None, body=None)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/voice/audio_recognition.py\", line 342, in _stt_task\n    async for ev in node:\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/voice/agent.py\", line 420, in stt_node\n    async for event in stream:\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/stt/stt.py\", line 340, in __anext__\n    raise exc  # noqa: B904\n    ^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/stt/stt.py\", line 235, in _main_task\n    raise APIConnectionError(\nlivekit.agents._exceptions.APIConnectionError: failed to recognize speech after 3 attempts\n2025-05-04 19:26:46,810 - WARNING livekit.agents - failed to synthesize speech, retrying in 0.1s {\"tts\": \"livekit.agents.tts.stream_adapter.StreamAdapter\", \"attempt\": 1, \"streamed\": true}\nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/tts.py\", line 203, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/plugins/google/tts.py\", line 232, in _run\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: This voice currently only supports ALAW, LINEAR16, MULAW, MP3 and OGG_OPUS output. (status_code=400, request_id=None, body=None)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/tts.py\", line 301, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/stream_adapter.py\", line 101, in _run\n    await asyncio.gather(*tasks)\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/stream_adapter.py\", line 86, in _synthesize\n    async for audio in self._wrapped_tts.synthesize(ev.token):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/tts.py\", line 253, in __anext__\n    raise exc  # noqa: B904\n    ^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/tts.py\", line 211, in _main_task\n    raise APIConnectionError(\nlivekit.agents._exceptions.APIConnectionError: failed to synthesize speech after 4 attempts\n2025-05-04 19:26:46,915 - ERROR livekit.agents - Error in _inference_task ]\nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/tts.py\", line 445, in __anext__\n    val = await self._event_aiter.__anext__()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nStopAsyncIteration\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/voice/generation.py\", line 146, in _inference_task\n    async for audio_frame in tts_node:\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/voice/agent.py\", line 473, in tts_node\n    async for ev in stream:\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/tts.py\", line 448, in __anext__\n    raise exc  # noqa: B904\n    ^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/tts.py\", line 301, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/stream_adapter.py\", line 101, in _run\n    await asyncio.gather(*tasks)\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/stream_adapter.py\", line 81, in _forward_input\n    self._sent_stream.end_input()\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tokenize/token_stream.py\", line 95, in end_input\n    self.flush()\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tokenize/token_stream.py\", line 71, in flush\n    self._check_not_closed()\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tokenize/token_stream.py\", line 104, in _check_not_closed\n    raise RuntimeError(f\"{cls.__module__}.{cls.__name__} is closed\")\nRuntimeError: livekit.agents.tokenize.token_stream.BufferedSentenceStream is closed\n2025-05-04 19:26:47,088 - WARNING livekit.agents - failed to synthesize speech, retrying in 0.1s {\"tts\": \"livekit.plugins.google.tts.TTS\", \"attempt\": 1, \"streamed\": false}\nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/tts.py\", line 203, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/plugins/google/tts.py\", line 232, in _run\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: This voice currently only supports ALAW, LINEAR16, MULAW, MP3 and OGG_OPUS output. (status_code=400, request_id=None, body=None)\n2025-05-04 19:26:47,364 - WARNING livekit.agents - failed to synthesize speech, retrying in 2.0s {\"tts\": \"livekit.plugins.google.tts.TTS\", \"attempt\": 2, \"streamed\": false}\nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/tts.py\", line 203, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/plugins/google/tts.py\", line 232, in _run\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: This voice currently only supports ALAW, LINEAR16, MULAW, MP3 and OGG_OPUS output. (status_code=400, request_id=None, body=None)\n2025-05-04 19:26:49,541 - WARNING livekit.agents - failed to synthesize speech, retrying in 2.0s {\"tts\": \"livekit.plugins.google.tts.TTS\", \"attempt\": 3, \"streamed\": false}\nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/tts.py\", line 203, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/plugins/google/tts.py\", line 232, in _run\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: This voice currently only supports ALAW, LINEAR16, MULAW, MP3 and OGG_OPUS output. (status_code=400, request_id=None, body=None)\n2025-05-04 19:27:18,300 - ERROR asyncio - Task exception was never retrieved\nfuture: <Task finished name='TTS._synthesize_task' coro=<ChunkedStream._main_task() done, defined at /Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/tts.py:200> exception=APIConnectionError('failed to synthesize speech after 4 attempts')> \nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/tts.py\", line 203, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/plugins/google/tts.py\", line 232, in _run\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: This voice currently only supports ALAW, LINEAR16, MULAW, MP3 and OGG_OPUS output. (status_code=400, request_id=None, body=None)\n\nThe above exception was the direct cause of the following exception:\n\n    raise APIConnectionError(\nlivekit.agents._exceptions.APIConnectionError: failed to synthesize speech after 4 attempts\n\n`\n\n\nThe code is\nimport os\n\nfrom dotenv import load_dotenv\n\nfrom livekit import agents\nfrom livekit.agents import AgentSession, Agent, RoomInputOptions\nfrom livekit.plugins import (\n    noise_cancellation,\n    silero,\n)\n\nfrom livekit.plugins import google\nfrom livekit.plugins.turn_detector.multilingual import MultilingualModel\n\nload_dotenv()\n\n\nclass Assistant(Agent):\n    def __init__(self) -> None:\n        super().__init__(instructions=\"You are a helpful voice AI assistant.\")\n\n\nasync def entrypoint(ctx: agents.JobContext):\n    await ctx.connect()\n    print(os.getenv(\"GOOGLE_API_KEY\"))\n    session = AgentSession(\n        stt=google.STT(\n          model=\"medical_dictation\",\n          spoken_punctuation=True,\n          sample_rate=16000,\n          punctuate=True,\n          languages=\"en-US\",\n          interim_results=True,\n        ),\n        llm=google.LLM(model=\"gemini-2.0-flash-exp\", temperature=0.8),\n        tts=google.TTS(\n          language=\"en-US\",\n          gender=\"female\",\n          voice_name=\"en-US-Chirp3-HD-Leda\",\n          sample_rate=16000\n        ),\n        vad=silero.VAD.load(),\n        turn_detection=MultilingualModel(),\n    )\n    await session.start(\n        room=ctx.room,\n        agent=Assistant(),\n        room_input_options=RoomInputOptions(\n            noise_cancellation=noise_cancellation.BVC(),\n        ),\n    )\n\n    await session.generate_reply(\n        instructions=\"Greet the user and offer your assistance.\",\n    )\n\n\nif __name__ == \"__main__\":\n    agents.cli.run_app(agents.WorkerOptions(entrypoint_fnc=entrypoint))\n\n\nPlease let me know what you need further.\nThanks for the support.",
      "state": "closed",
      "author": "fahadanwaar",
      "author_type": "User",
      "created_at": "2025-05-04T14:31:53Z",
      "updated_at": "2025-05-05T09:15:31Z",
      "closed_at": "2025-05-05T09:15:31Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2191/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2191",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2191",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:19.217883",
      "comments": []
    },
    {
      "issue_number": 2193,
      "title": "Bug: Single-Value Literal Not Supported in Gemini Function Tool (Works in GPT)",
      "body": "Hi — quick bug report about **Literal** types in function_tool parameters when using **Gemini**:\nI'm running into an issue where defining a Literal with a single option like Literal[\"opt1\"] causes an error in Gemini.\nBut if I use multiple options, like Literal[\"opt1\", \"opt2\"], it works just fine.\nInterestingly, this doesn't happen with GPT, which accepts both single and multi-value Literals without any issues.\n\nSample Tool Function Code:\n```\nasync def _get_course_info(\n        location: Literal[\"online\"], # errors with Gemini\n        # location: Literal[\"online\", \"offline\"] # works fine\n        course: str,\n    ) -> str:\n        logger.info(f\"get_course_info called: {location}, {course}\")\n        return f\"Imagine a course about {course}.\"\n\nagent = Agent(\n        instructions=\"You are a helpful assistant that can answer questions and help with tasks.\",\n        tools=[\n            function_tool(\n                _get_course_info,\n                name=\"get_course_info\",\n                description=\"Get information about a course\",\n            )\n        ],\n    )\n```\n\nError Message:\n```\n2025-05-05 12:57:31,510 - WARNING livekit.agents - failed to generate LLM completion, retrying in 2.0s\nTraceback (most recent call last):\n  File \"/Users/ryanhan/Library/Caches/pypoetry/virtualenvs/livekit-1-0-Cmpy5z8A-py3.12/lib/python3.12/site-packages/livekit/plugins/google/llm.py\", line 250, in _run\n    function_declarations = to_fnc_ctx(self._tools)\n                            ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/ryanhan/Library/Caches/pypoetry/virtualenvs/livekit-1-0-Cmpy5z8A-py3.12/lib/python3.12/site-packages/livekit/plugins/google/utils.py\", line 20, in to_fnc_ctx\n    return [_build_gemini_fnc(fnc) for fnc in fncs]\n            ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/ryanhan/Library/Caches/pypoetry/virtualenvs/livekit-1-0-Cmpy5z8A-py3.12/lib/python3.12/site-packages/livekit/plugins/google/utils.py\", line 125, in _build_gemini_fnc\n    return types.FunctionDeclaration(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/ryanhan/Library/Caches/pypoetry/virtualenvs/livekit-1-0-Cmpy5z8A-py3.12/lib/python3.12/site-packages/pydantic/main.py\", line 253, in __init__\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\npydantic_core._pydantic_core.ValidationError: 1 validation error for FunctionDeclaration\nparameters.properties.location.const\n  Extra inputs are not permitted [type=extra_forbidden, input_value='online', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/ryanhan/Library/Caches/pypoetry/virtualenvs/livekit-1-0-Cmpy5z8A-py3.12/lib/python3.12/site-packages/livekit/agents/llm/llm.py\", line 137, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/ryanhan/Library/Caches/pypoetry/virtualenvs/livekit-1-0-Cmpy5z8A-py3.12/lib/python3.12/site-packages/livekit/plugins/google/llm.py\", line 334, in _run\n    raise APIConnectionError(\nlivekit.agents._exceptions.APIConnectionError: gemini llm: error generating content 1 validation error for FunctionDeclaration\nparameters.properties.location.const\n  Extra inputs are not permitted [type=extra_forbidden, input_value='online', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden {\"llm\": \"livekit.plu\n```",
      "state": "closed",
      "author": "hsjun99",
      "author_type": "User",
      "created_at": "2025-05-05T04:07:54Z",
      "updated_at": "2025-05-05T09:11:01Z",
      "closed_at": "2025-05-05T09:11:01Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2193/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2193",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2193",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:19.217921",
      "comments": []
    },
    {
      "issue_number": 1030,
      "title": "BlockingIOError after Dependency Update in Speech-to-Text Example",
      "body": "After updating the dependencies as shown in the attached screenshot, an error started to occur:\r\n```\r\nBlockingIOError: [Errno 11] Resource temporarily unavailable {\"pid\": 4204, \"job_id\": \"AJ_5DcvLZ3JehqG\"}\r\n    csock.send(b'\\0')\r\n  File \"/usr/local/lib/python3.11/asyncio/selector_events.py\", line 139, in _write_to_self\r\n\r\nTraceback (most recent call last):\r\n2024-11-02 07:07:17,839 - DEBUG asyncio - Fail to write a null byte into the self-pipe socket\r\n```\r\n![image](https://github.com/user-attachments/assets/72b682f2-92f8-4a94-bab4-f4dc5bba2e9f)\r\n\r\n\r\nThe error appears in a seemingly random manner.\r\nIt may depend on the number of rooms and participants, but has also occurred with just one room immediately or after several hours.\r\nThe error is cyclical, occurring up to 100,000 times within a few minutes, severely impacting performance.\r\nThe project is based on the speech-to-text example from the examples folder.",
      "state": "closed",
      "author": "wezerr",
      "author_type": "User",
      "created_at": "2024-11-02T07:52:43Z",
      "updated_at": "2025-05-05T07:35:13Z",
      "closed_at": "2025-05-05T07:35:13Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1030/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1030",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1030",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:19.217929",
      "comments": []
    },
    {
      "issue_number": 1022,
      "title": "Non-English text shown on transcription console UI",
      "body": "The logs of the Multimodal agent with OpenAI Realtime API show correct English text on the console but on the UI, it sometimes shows the audio transcription in other languages like Hindi, Chinese, Russian etc while speaking English.",
      "state": "closed",
      "author": "asadullahnaeem-techtics",
      "author_type": "User",
      "created_at": "2024-11-01T08:31:33Z",
      "updated_at": "2025-05-05T07:35:13Z",
      "closed_at": "2025-05-05T07:35:13Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1022/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1022",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1022",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:19.217934",
      "comments": [
        {
          "author": "longcw",
          "body": "I noticed the same issue sometimes. According to the openai's document, the transcription is from a separate process run on a separate ASR model (currently whisper-1), and the transcript may diverge somewhat from the model's interpretation. So it seems it's from the speech recognition error. https:/",
          "created_at": "2024-11-03T15:42:39Z"
        },
        {
          "author": "longcw",
          "body": "oh wait, you mean in the transcripts in logs it's correct but in UI it's wrong? maybe it's a different issue from what I mentioned above.",
          "created_at": "2024-11-03T15:43:54Z"
        },
        {
          "author": "asadullahnaeem-techtics",
          "body": "In the logs, transcription is correct but on the UI it is not.",
          "created_at": "2024-11-04T08:22:48Z"
        },
        {
          "author": "davidzhao",
          "body": "can you share an example with logs or screenshot?",
          "created_at": "2024-11-05T05:36:54Z"
        }
      ]
    },
    {
      "issue_number": 948,
      "title": "Unknown Room disconnect Reason",
      "body": "My agent and my client begin a conversation, and after about 20 seconds, the logs appear as shown below.\r\n```shell\r\n2024-10-18 03:39:59,243 - DEBUG livekit.agents - shutting down job task {\"reason\": \"room disconnected\", \"user_initiated\": false, \"pid\": 180554, \"job_id\": \"AJ_hiX5f7AbW8Lq\"}\r\n```\r\nI am sure that my client did not directly invoke the disconnect room, nor did the agent.\r\nHow can I determine the reason?\r\nI checked the sessions in the web console, and everything looks fine.",
      "state": "closed",
      "author": "BaiMoHan",
      "author_type": "User",
      "created_at": "2024-10-18T03:44:43Z",
      "updated_at": "2025-05-05T07:35:13Z",
      "closed_at": "2025-05-05T07:35:13Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/948/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/948",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/948",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:19.415803",
      "comments": []
    },
    {
      "issue_number": 864,
      "title": "Function call issue: when using mistralai/Mixtral-8x7B-Instruct-v0.1 or mistralai/Mistral-7B-Instruct-v0.1 with together ai.",
      "body": "{\"message\": \"Error in _stream_synthesis_task\\nTraceback (most recent call last):\\n  File \\\"/root/pythonenv/enve/lib/python3.10/site-packages/livekit/agents/utils/log.py\\\", line 16, in async_fn_logs\\n    return await fn(*args, **kwargs)\\n  File \\\"/root/pythonenv/enve/lib/python3.10/site-packages/livekit/agents/pipeline/agent_output.py\\\", line 272, in _stream_synthesis_task\\n    async for seg in tts_source:\\n  File \\\"/root/pythonenv/enve/lib/python3.10/site-packages/livekit/agents/utils/aio/itertools.py\\\", line 47, in tee_peer\\n    item = await iterator.__anext__()\\n  File \\\"/root/pythonenv/enve/lib/python3.10/site-packages/livekit/agents/pipeline/pipeline_agent.py\\\", line 847, in _llm_stream_to_str_iterable\\n    async for chunk in stream:\\n  File \\\"/root/pythonenv/enve/lib/python3.10/site-packages/livekit/plugins/openai/llm.py\\\", line 482, in __anext__\\n    chat_chunk = self._parse_choice(choice)\\n  File \\\"/root/pythonenv/enve/lib/python3.10/site-packages/livekit/plugins/openai/llm.py\\\", line 511, in _parse_choice\\n    self._fnc_raw_arguments += tool.function.arguments  # type: ignore\\nTypeError: unsupported operand type(s) for +=: 'NoneType' and 'str'\", \"level\": \"ERROR\", \"name\": \"livekit.agents.pipeline\", \"pid\": 69585, \"job_id\": \"AJ_yVsysoEsvYLs\", \"timestamp\": \"2024-10-08T13:00:23.301609+00:00\"}",
      "state": "closed",
      "author": "Test-isom",
      "author_type": "User",
      "created_at": "2024-10-08T13:02:31Z",
      "updated_at": "2025-05-05T07:35:13Z",
      "closed_at": "2025-05-05T07:35:13Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/864/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/864",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/864",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:19.415823",
      "comments": [
        {
          "author": "Test-isom",
          "body": "As per their docs, https://docs.together.ai/docs/function-calling, above 2 models supports function calling.",
          "created_at": "2024-10-08T13:03:54Z"
        }
      ]
    },
    {
      "issue_number": 861,
      "title": "Agent starts speaking earlier, in prejoin screen",
      "body": "Not sure if this is relevant to agents or components library, but let's say I have a command like await agent.say(\"<text>\") in entrypoint of agent, even then if someone joins the meet through prejoin screen, our agent speaks before they can join in the room\r\n\r\nessentially what happen then, is when user joins the agent start speaking from middle of sentence (as it has already spoke first parts when user was in prejoin)\r\n\r\nAny way to mitigate this?",
      "state": "closed",
      "author": "hari01584",
      "author_type": "User",
      "created_at": "2024-10-07T19:00:00Z",
      "updated_at": "2025-05-05T07:35:13Z",
      "closed_at": "2025-05-05T07:35:13Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/861/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/861",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/861",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:19.641826",
      "comments": [
        {
          "author": "davidzhao",
          "body": "on the prejoin screen, is your app connecting to a room? \r\n\r\nthe purpose of a prejoin screen is so that user could adjust settings before connecting to the room, so during that time no agent would be dispatched",
          "created_at": "2024-10-15T05:53:43Z"
        },
        {
          "author": "jezell",
          "body": "> essentially what happen then, is when user joins the agent start speaking from middle of sentence (as it has already spoke first parts when user was in prejoin)\r\n> \r\n> Any way to mitigate this?\r\n\r\nI believe the default scheduler activates whenever the first participant connects to the room. If you",
          "created_at": "2024-10-26T06:32:12Z"
        }
      ]
    },
    {
      "issue_number": 846,
      "title": "[BUGS]: PlayHT Plugin: Wrong encoding calculation and sample rate being ignored",
      "body": "I get a `Value Error: Unknown format: wav` error when using defaults for the playht plugin.\r\n\r\n```python\r\ntts=playht.TTS()\r\n```\r\n\r\nI found the following line:\r\n\r\nhttps://github.com/livekit/agents/blob/ff2b6605cb61f26f51a3d64024babd0e747123c2/livekit-plugins/livekit-plugins-playht/livekit/plugins/playht/tts.py#L163\r\n\r\n`_encoding_from_format` expects an argument of type `TTSEncoding` whereas a `_TTSEncoding` arg is being passed. Both are different types and don't have any overlaps.\r\n\r\nhttps://github.com/livekit/agents/blob/ff2b6605cb61f26f51a3d64024babd0e747123c2/livekit-plugins/livekit-plugins-playht/livekit/plugins/playht/tts.py#L58\r\n\r\nhttps://github.com/livekit/agents/blob/ff2b6605cb61f26f51a3d64024babd0e747123c2/livekit-plugins/livekit-plugins-playht/livekit/plugins/playht/models.py#L5-L15\r\n\r\n\r\nAbove TTSEncoding values are also incorrect for PlayHT API and seem to be copied from elevenlab plugin. Also the sample rate provided in the top level config is never provided to the PlayHT api (in the json payload).\r\n\r\nIs the plugin a Work In Progress? I think it should be removed from the README if it is.",
      "state": "closed",
      "author": "divyanshu-shortloop",
      "author_type": "User",
      "created_at": "2024-10-05T10:05:28Z",
      "updated_at": "2025-05-05T07:35:13Z",
      "closed_at": "2025-05-05T07:35:13Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/846/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/846",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/846",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:19.924085",
      "comments": [
        {
          "author": "davidzhao",
          "body": "this was contributed by a community member. would you like to submit a PR to improve/fix the issues?",
          "created_at": "2024-10-07T06:37:19Z"
        }
      ]
    },
    {
      "issue_number": 793,
      "title": "unexpectedly disconnected from room: UnknownReason",
      "body": "**Error description**\r\nAfter the room ends normally, the agent reports an error, \r\n\r\n**Env**\r\nlivekit-server: 1.6.1\r\nagent:0.8.10\r\n\r\n**To Reproduce**\r\n1. lk room join --identity test-lijiliang room-lijiliang, then the agent will automatic join the room.\r\n2. ctrl + c， let participant test-lijiliang leave the room\r\n\r\n**Error log**\r\n{\"message\": \"received job request\", \"level\": \"INFO\", \"job_request\": \"id: \\\"AJ_B2yLRKRhjp4p\\\"\\nroom {\\n  sid: \\\"RM_6Kc33NyNVVui\\\"\\n  name: \\\"room-lijiliang\\\"\\n  empty_timeout: 60\\n  creation_time: 1727233281\\n  turn_password: \\\"Iz9jBq16ekzaIAQrkeeLjrfqSOipff1jAQlZys5HBstL\\\"\\n  enabled_codecs {\\n    mime: \\\"audio/opus\\\"\\n  }\\n  enabled_codecs {\\n    mime: \\\"audio/red\\\"\\n  }\\n  enabled_codecs {\\n    mime: \\\"video/VP8\\\"\\n  }\\n  enabled_codecs {\\n    mime: \\\"video/H264\\\"\\n  }\\n  enabled_codecs {\\n    mime: \\\"video/VP9\\\"\\n  }\\n  enabled_codecs {\\n    mime: \\\"video/AV1\\\"\\n  }\\n  departure_timeout: 1\\n}\\n\", \"resuming\": false, \"agent_name\": \"\", \"timestamp\": \"2024-09-25T03:01:21.650763+00:00\"}\r\n{\"message\": \"livekit_ffi::server:125:livekit_ffi::server - initializing ffi server v0.8.1\", \"level\": \"INFO\", \"pid\": 764192, \"job_id\": \"AJ_B2yLRKRhjp4p\", \"timestamp\": \"2024-09-25T03:01:21.658402+00:00\"}\r\n{\"message\": \"livekit_ffi::cabi:27:livekit_ffi::cabi - initializing ffi server v0.8.1\", \"level\": \"INFO\", \"pid\": 764192, \"job_id\": \"AJ_B2yLRKRhjp4p\", \"timestamp\": \"2024-09-25T03:01:21.658967+00:00\"}\r\n{\"message\": \"livekit_api::signal_client::signal_stream:96:livekit_api::signal_client::signal_stream - connecting to ws://172.22.4.223:7880/rtc?sdk=rust&protocol=15&auto_subscribe=1&adaptive_stream=0&access_token=...\", \"level\": \"INFO\", \"pid\": 764192, \"job_id\": \"AJ_B2yLRKRhjp4p\", \"timestamp\": \"2024-09-25T03:01:21.659897+00:00\"}\r\n{\"message\": \"tungstenite::handshake::client:95:tungstenite::handshake::client - Client handshake done.\", \"level\": \"DEBUG\", \"pid\": 764192, \"job_id\": \"AJ_B2yLRKRhjp4p\", \"timestamp\": \"2024-09-25T03:01:21.665791+00:00\"}\r\n{\"message\": \"livekit::room:1028:livekit::room - unexpectedly disconnected from room: UnknownReason\", \"level\": \"ERROR\", \"pid\": 764192, \"job_id\": \"AJ_B2yLRKRhjp4p\", \"timestamp\": \"2024-09-25T03:03:19.234673+00:00\"}",
      "state": "closed",
      "author": "leejiliang",
      "author_type": "User",
      "created_at": "2024-09-25T03:12:33Z",
      "updated_at": "2025-05-05T07:35:13Z",
      "closed_at": "2025-05-05T07:35:13Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/793/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/793",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/793",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:20.134301",
      "comments": []
    },
    {
      "issue_number": 2130,
      "title": "Server reports no available agents despite CPU utilization being under 20%",
      "body": "I've deployed a livekit agent server to Render.com, running in Docker. The server is configured with 4GB of RAM and 2 CPUs. \n\nThe Livekit server was not spawning new agents and was reporting `\"worker is at full capacity, marking as unavailable\"`. \n\nDuring that time the CPU utilization spiked to 17%, well under the default load threshold of 0.75. ",
      "state": "open",
      "author": "toonverbeek",
      "author_type": "User",
      "created_at": "2025-04-25T15:00:32Z",
      "updated_at": "2025-05-05T06:04:59Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2130/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2130",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2130",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:20.134325",
      "comments": [
        {
          "author": "theomonnom",
          "body": "Could it be because we're not correctly reading the cgroup CPU usage?\nhttps://github.com/livekit/agents/blob/0d608925d3981f9c3734b922ea8053063e6b35ef/livekit-agents/livekit/agents/utils/hw/cpu.py#L77",
          "created_at": "2025-05-03T23:38:31Z"
        },
        {
          "author": "davidzhao",
          "body": "> Could it be because we're not correctly reading the cgroup CPU usage?\n\nIt's possible if this is cgroups v1, but in that case it'd read the entire machine's CPU, so it would overcommit instead of under commit.\n\n@toonverbeek what is the docker base image and platform?",
          "created_at": "2025-05-04T05:13:26Z"
        },
        {
          "author": "toonverbeek",
          "body": "@davidzhao Thanks for getting back to me. We're running on `python:3.11.6-slim`: https://hub.docker.com/layers/library/python/3.11.6-slim/images/sha256-f07bce5332359289dbfb906c9f8007a08f59a411404dcef9be4580b77e0f6951",
          "created_at": "2025-05-05T06:03:51Z"
        }
      ]
    },
    {
      "issue_number": 2179,
      "title": "livekit.agents - process exited with non-zero exit code -4  during microphone stream",
      "body": "When using the [newly published version of livekit-plugins-noise-cancellation](https://pypi.org/project/livekit-plugins-noise-cancellation/0.2.2/), we get the following error after the avatar joins and starts reading the microphone stream.\n\nThis issue happens only on 0.2.2, pinning on 0.2.1 works fine\n\n```\nawait session.start(\n    # ...,\n    room_input_options=room_io.RoomInputOptions(\n        noise_cancellation=noise_cancellation.BVC(),\n    ),\n)\n\n```\n\n\n### Logs\n```\n2025-05-02 13:00:56,136 - \u001b[32mINFO\u001b[0m avatar-example - Avatar runner joined \u001b[90m{\"pid\": 483, \"job_id\": \"AJ_zWY5EczxwEJM\"}\u001b[0m\nDEBUG:livekit.agents:start reading stream\nDEBUG:livekit.agents:start reading stream\n2025-05-02 13:00:56,321 - \u001b[36mDEBUG\u001b[0m livekit.agents - start reading stream \u001b[90m{\"participant\": \"identity-p1Sz\", \"source\": \"SOURCE_MICROPHONE\", \"pid\": 483, \"job_id\": \"AJ_zWY5EczxwEJM\"}\u001b[0m\nERROR:livekit.agents:process exited with non-zero exit code -4\n2025-05-02 13:00:56,728 - \u001b[31mERROR\u001b[0m livekit.agents - process exited with non-zero exit code -4 \u001b[90m{\"pid\": 483, \"job_id\": \"AJ_zWY5EczxwEJM\"}\u001b[0m\n\n```",
      "state": "closed",
      "author": "hekadesbot",
      "author_type": "User",
      "created_at": "2025-05-02T13:08:32Z",
      "updated_at": "2025-05-05T05:43:11Z",
      "closed_at": "2025-05-04T09:51:39Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2179/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2179",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2179",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:20.348993",
      "comments": [
        {
          "author": "longcw",
          "body": "which avatar plugin are you using?",
          "created_at": "2025-05-02T13:15:13Z"
        },
        {
          "author": "hekadesbot",
          "body": "its an in-house version derived from the wave example. Our implementation doesn't mess with anything related to session initialization though, it maintains the same agent_worker.py and avatar_runner.py structure. We only inherit and implement the VideoGenerator class",
          "created_at": "2025-05-02T14:44:54Z"
        },
        {
          "author": "typester",
          "body": "@hekadesbot Thank you for the report. Could you please share more details about your environment, such as: OS, CPU?\n\nAlso, could you try setting the `OPENBLAS_CORETYPE` environment variable (e.g., `OPENBLAS_CORETYPE=Haswell`) and let us know if that changes anything?",
          "created_at": "2025-05-02T20:19:04Z"
        },
        {
          "author": "hekadesbot",
          "body": "We are running an [AWS G6 instance ](https://aws.amazon.com/ec2/instance-types/g6/) with the following AMI:\n\nDeep Learning OSS Nvidia Driver AMI GPU PyTorch 2.3.0 (Amazon Linux 2) 20240625\n\nWill check env variable by EOD",
          "created_at": "2025-05-03T08:03:58Z"
        },
        {
          "author": "hekadesbot",
          "body": "@typester  \nsetting the ENV variable appears to have solved the issue! May I ask why this was occurring and how did it solve the issue?  Thanks!",
          "created_at": "2025-05-03T08:17:50Z"
        }
      ]
    },
    {
      "issue_number": 2116,
      "title": "Google Gemini LLM throws error in `basic_agent` example",
      "body": "## Problem\nThe Google Gemini LLM throws an error in the `basic_agent` example. It was working fine in the previous version (1.0.14).\n\n## Steps to reproduce\n1. Use the Google LLM in the basic_agent example:\n```\ndiff --git a/examples/voice_agents/basic_agent.py b/examples/voice_agents/basic_agent.py\nindex b057795b..8aa9e8bd 100644\n--- a/examples/voice_agents/basic_agent.py\n+++ b/examples/voice_agents/basic_agent.py\n@@ -16,7 +16,7 @@ from livekit.agents import (\n )\n from livekit.agents.llm import function_tool\n from livekit.agents.voice import MetricsCollectedEvent\n-from livekit.plugins import deepgram, openai, silero\n+from livekit.plugins import deepgram, openai, silero, google\n from livekit.plugins.turn_detector.multilingual import MultilingualModel\n \n # uncomment to enable Krisp background voice/noise cancellation\n@@ -82,7 +82,7 @@ async def entrypoint(ctx: JobContext):\n     session = AgentSession(\n         vad=ctx.proc.userdata[\"vad\"],\n         # any combination of STT, LLM, TTS, or realtime API can be used\n-        llm=openai.LLM(model=\"gpt-4o-mini\"),\n+        llm=google.LLM(),\n         stt=deepgram.STT(model=\"nova-3\", language=\"multi\"),\n         tts=openai.TTS(voice=\"ash\"),\n         # use LiveKit's turn detection model\n```\n\n2. Run worker\n```\nuv run examples/voice_agents/basic_agent.py dev\n```\n\n3. You'll see errors from the LLM after connecting\n```\nTraceback (most recent call last):\n  File \"/Users/mateusz/dev/private/agents/livekit-plugins/livekit-plugins-google/livekit/plugins/google/llm.py\", line 290, in _run\n    async for response in stream:\n  File \"/Users/mateusz/dev/private/agents/.venv/lib/python3.12/site-packages/google/genai/models.py\", line 6622, in async_generator\n    response = await self._generate_content_stream(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/mateusz/dev/private/agents/.venv/lib/python3.12/site-packages/google/genai/models.py\", line 5538, in _generate_content_stream\n    request_dict = _GenerateContentParameters_to_mldev(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/mateusz/dev/private/agents/.venv/lib/python3.12/site-packages/google/genai/models.py\", line 622, in _GenerateContentParameters_to_mldev\n    for item in t.t_contents(\n                ^^^^^^^^^^^^^\n  File \"/Users/mateusz/dev/private/agents/.venv/lib/python3.12/site-packages/google/genai/_transformers.py\", line 432, in t_contents\n    raise ValueError('contents are required.')\nValueError: contents are required.\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/mateusz/dev/private/agents/livekit-agents/livekit/agents/llm/llm.py\", line 138, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/mateusz/dev/private/agents/livekit-plugins/livekit-plugins-google/livekit/plugins/google/llm.py\", line 358, in _run\n    raise APIConnectionError(\nlivekit.agents._exceptions.APIConnectionError: gemini llm: error generating content contents are required. {\"room\": \"playground-47y0-nvdi\", \"user_id\": \"your user_id\", \"llm\": \"livekit.plugins.google.llm.LLM\", \"attempt\": 1, \"pid\": 25460, \"job_id\": \"AJ_iN2P2eGrfveT\"}\n```\n",
      "state": "closed",
      "author": "mateuszkulpa",
      "author_type": "User",
      "created_at": "2025-04-24T22:32:04Z",
      "updated_at": "2025-05-03T21:35:02Z",
      "closed_at": "2025-05-03T21:35:01Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2116/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "jayeshp19"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2116",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2116",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:20.548493",
      "comments": [
        {
          "author": "mateuszkulpa",
          "body": "Fixed #2183 ",
          "created_at": "2025-05-03T21:35:01Z"
        }
      ]
    },
    {
      "issue_number": 1987,
      "title": "default value for function tool argument doesn't work for some types",
      "body": "Create an ticket to track this issue:\n\nI was not able to create a tool with default argument like\n```python\n    @function_tool\n    async def get_weather(self, location: str = \"\") -> str:\n        \"\"\"\n        Called when the user asks about the weather.\n\n        Args:\n            location: The location to get the weather for\n        \"\"\"\n```\nOAI raises error Invalid schema for function 'get_weather': In context=('properties', 'location'), 'default' is not permitted.\n```bash\n2025-04-11 15:01:20,350 - WARNING livekit.agents - failed to generate LLM completion, retrying in 2.0s\nTraceback (most recent call last):\n  File \"/home/longc/data/code/agents/livekit-agents/livekit/agents/llm/llm.py\", line 137, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/longc/data/code/agents/livekit-plugins/livekit-plugins-openai/livekit/plugins/openai/llm.py\", line 599, in _run\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: Error code: 400 - {'error': {'message': \"Invalid schema for function 'get_weather': In context=('properties', 'location'), 'default' is not permitted.\", 'type': 'invalid_request_error', 'param': 'tools[0].function.parameters', 'code': 'invalid_function_parameters'}} (status_code=400, request_id=req_6da84b4da8310ea5c55054fa50e9113e, body={'message': \"Invalid schema for function 'get_weather': In context=('properties', 'location'), 'default' is not permitted.\", 'type': 'invalid_request_error', 'param': 'tools[0].function.parameters', 'code': 'invalid_function_parameters'})\n```\n\nBut something like this works, seems it has to be an enum to have the default value?\n```python\n    @function_tool\n    async def toggle_light(\n        self,\n        switch_to: Literal[\"on\", \"off\"] = \"on\",\n    ) -> str:\n        ...\n```\n\ntheir schemas are\n```\n# failed\n{'properties': {'location': {'default': 'New York', 'description': 'The location to get the weather for', 'title': 'Location', 'type': 'string'}}, 'title': 'GetWeatherArgs', 'type': 'object', 'additionalProperties': False, 'required': ['location']}\n\n# succ\n{'properties': {'switch_to': {'default': 'on', 'description': 'The state to turn the light to', 'enum': ['on', 'off'], 'title': 'Switch To', 'type': 'string'}}, 'title': 'ToggleLightArgs', 'type': 'object', 'additionalProperties': False, 'required': ['switch_to']}\n```\nalso, can we remove the arg from required if it has a default value?",
      "state": "closed",
      "author": "longcw",
      "author_type": "User",
      "created_at": "2025-04-14T03:21:58Z",
      "updated_at": "2025-05-03T18:23:32Z",
      "closed_at": "2025-04-22T12:52:07Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1987/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "theomonnom"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1987",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1987",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:20.741636",
      "comments": [
        {
          "author": "nickderobertis",
          "body": "We are running into this as well and it's preventing us from upgrading to 1.0. We noticed that it can be reproduced with the weather example by adding an additional arg. Note that it seems to _only_ affect `LLM` and not `RealtimeModel`, if you use this same script with `RealtimeModel` it works fine.",
          "created_at": "2025-04-21T15:26:45Z"
        },
        {
          "author": "blakemjones",
          "body": "I've upgraded to `livekit-agents==1.0.18` and validated that [the code trying to fix this](https://github.com/livekit/agents/pull/2076/files) is installed locally, but I'm still getting the following error message:\n```\nlivekit.agents._exceptions.APIStatusError: Error code: 400 - {'error': {'message'",
          "created_at": "2025-05-01T14:15:09Z"
        },
        {
          "author": "theomonnom",
          "body": "Thanks for the report @blakemjones, done here https://github.com/livekit/agents/pull/2187 !",
          "created_at": "2025-05-03T18:23:31Z"
        }
      ]
    },
    {
      "issue_number": 2186,
      "title": "function tool arg default value cannot be None",
      "body": "### Issue 1: the default value of the arg of function tool cannot be `None`\n\n```python\n    @function_tool()\n    async def update_caller_status(\n        context: RunContext_T,\n        caller_name: Optional[str] = None,\n    ) -> str:\n        logger.info(f\"Updating caller status to {caller_name}\")\n        return \"ok\"\n\n```\nfor example this one raises \n> livekit.agents._exceptions.APIStatusError: Error code: 400 - {'error': {'message': \"Invalid schema for function 'update_caller_status': In context=('properties', 'caller_name'), 'default' is not permitted.\", 'type': 'invalid_request_error', 'param': 'tools[0].function.parameters', 'code': 'invalid_function_parameters'}} (status_code=400, request_id=req_69d97bdefaaaa6f45cf652fbe439f4b1, body={'message': \"Invalid schema for function 'update_caller_status': In context=('properties', 'caller_name'), 'default' is not permitted.\", 'type': 'invalid_request_error', 'param': 'tools[0].function.parameters', 'code': 'invalid_function_parameters'})\n\nthe schema generated by `build_strict_openai_schema` is\n```python\n{'function': {'description': '',\n              'name': 'update_caller_status',\n              'parameters': {'additionalProperties': False,\n                             'properties': {'caller_name': {'default': None,\n                                                            'type': ['string',\n                                                                     'null']}},\n                             'required': ['caller_name'],\n                             'type': 'object'},\n              'strict': True},\n 'type': 'function'}\n```\n\nA str default works for this case.\n\n~### Issue 2: function_tool without `context: RunContext_T` has a wrong args scehma~\n(it's bc the class method missing the `self`)\n\nfrom slack https://livekit-users.slack.com/archives/C07FY8WHGPM/p1745885751149599",
      "state": "closed",
      "author": "longcw",
      "author_type": "User",
      "created_at": "2025-05-03T15:15:11Z",
      "updated_at": "2025-05-03T15:47:15Z",
      "closed_at": "2025-05-03T15:47:15Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2186/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2186",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2186",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:20.996461",
      "comments": []
    },
    {
      "issue_number": 2180,
      "title": "livekit-agents Sample Basic AI agent Example now working for gemini",
      "body": "Hey, Im trying to run the example code given in this link. https://docs.livekit.io/agents/start/voice-ai/\nAnd change to gemini models using this https://docs.livekit.io/agents/start/voice-ai/.\n\nIt is throwing weird errors, starting from \"generating content contents are required\" which is fixed using this PR.\nhttps://github.com/livekit/agents/pull/2142/files\n\nBut now it is giving these logs.\n`2025-05-02 23:47:34,849 - INFO livekit.agents - starting worker {\"version\": \"1.0.18\", \"rtc-version\": \"1.0.6\"}\n2025-05-02 23:47:34,849 - INFO livekit.agents - starting inference executor \n2025-05-02 23:47:36,849 - INFO livekit.agents - initializing inference process {\"pid\": 56224, \"inference\": true}\n2025-05-02 23:47:36,849 - DEBUG livekit.agents - initializing inference runner {\"runner\": \"lk_end_of_utterance_multilingual\", \"pid\": 56224, \"inference\": true}\n2025-05-02 23:47:42,039 - INFO livekit.agents - inference process initialized {\"pid\": 56224, \"inference\": true}\n2025-05-02 23:47:42,039 - DEBUG asyncio - Using selector: KqueueSelector {\"pid\": 56224, \"inference\": true}\n2025-05-02 23:47:42,043 - INFO livekit.agents - see tracing information at http://localhost:62183/debug \n2025-05-02 23:47:42,045 - INFO livekit.agents - initializing job runner {\"tid\": 7339514}\n2025-05-02 23:47:42,046 - INFO livekit.agents - job runner initialized {\"tid\": 7339514}\n2025-05-02 23:47:42,046 - DEBUG asyncio - Using selector: KqueueSelector \nAIzaSyB_pIr8Hvg_uUJBTGwv9UAvcE73phg5FDw\n2025-05-02 23:47:42,104 - DEBUG google.auth._default - Checking sa.json for explicit credentials as part of auth process... \n2025-05-02 23:47:42,800 - DEBUG grpc._cython.cygrpc - Using AsyncIOEngine.POLLER as I/O engine \n2025-05-02 23:47:42,815 - DEBUG livekit.plugins.google - No turns in chat context, adding minimal user turn with placeholder \n2025-05-02 23:47:42,816 - INFO google_genai.models - AFC is enabled with max remote calls: 10. \n2025-05-02 23:47:43,539 - WARNING livekit.agents - failed to recognize speech, retrying in 0.1s {\"tts\": \"livekit.plugins.google.stt.STT\", \"attempt\": 0, \"streamed\": true}\nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/stt/stt.py\", line 228, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/plugins/google/stt.py\", line 497, in _run\n    raise APIStatusError(e.message, status_code=e.code or -1) from None\nlivekit.agents._exceptions.APIStatusError: The medical_dictation model must have spoken punctuation enabled. (status_code=400, request_id=None, body=None)\n2025-05-02 23:47:44,049 - INFO google_genai.models - AFC remote call 1 is done. \n2025-05-02 23:47:44,315 - WARNING livekit.agents - failed to recognize speech, retrying in 2.0s {\"tts\": \"livekit.plugins.google.stt.STT\", \"attempt\": 1, \"streamed\": true}\nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/stt/stt.py\", line 228, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/plugins/google/stt.py\", line 497, in _run\n    raise APIStatusError(e.message, status_code=e.code or -1) from None\nlivekit.agents._exceptions.APIStatusError: The medical_dictation model must have spoken punctuation enabled. (status_code=400, request_id=None, body=None)\n2025-05-02 23:47:44,755 - WARNING livekit.agents - failed to synthesize speech, retrying in 0.1s {\"tts\": \"livekit.plugins.google.tts.TTS\", \"attempt\": 1, \"streamed\": false}\nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/tts.py\", line 203, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/plugins/google/tts.py\", line 231, in _run\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: This voice currently only supports ALAW, LINEAR16, MULAW, MP3 and OGG_OPUS output. (status_code=400, request_id=None, body=None)\n2025-05-02 23:47:45,024 - WARNING livekit.agents - failed to synthesize speech, retrying in 2.0s {\"tts\": \"livekit.plugins.google.tts.TTS\", \"attempt\": 2, \"streamed\": false}\nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/tts.py\", line 203, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/plugins/google/tts.py\", line 231, in _run\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: This voice currently only supports ALAW, LINEAR16, MULAW, MP3 and OGG_OPUS output. (status_code=400, request_id=None, body=None)\n2025-05-02 23:47:46,838 - WARNING livekit.agents - failed to recognize speech, retrying in 2.0s {\"tts\": \"livekit.plugins.google.stt.STT\", \"attempt\": 2, \"streamed\": true}\nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/stt/stt.py\", line 228, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/plugins/google/stt.py\", line 497, in _run\n    raise APIStatusError(e.message, status_code=e.code or -1) from None\nlivekit.agents._exceptions.APIStatusError: The medical_dictation model must have spoken punctuation enabled. (status_code=400, request_id=None, body=None)\n2025-05-02 23:47:47,192 - WARNING livekit.agents - failed to synthesize speech, retrying in 2.0s {\"tts\": \"livekit.plugins.google.tts.TTS\", \"attempt\": 3, \"streamed\": false}\nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/tts.py\", line 203, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/plugins/google/tts.py\", line 231, in _run\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: This voice currently only supports ALAW, LINEAR16, MULAW, MP3 and OGG_OPUS output. (status_code=400, request_id=None, body=None)\n2025-05-02 23:47:49,371 - WARNING livekit.agents - failed to synthesize speech, retrying in 0.1s {\"tts\": \"livekit.agents.tts.stream_adapter.StreamAdapter\", \"attempt\": 1, \"streamed\": true}\nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/tts.py\", line 203, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/plugins/google/tts.py\", line 231, in _run\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: This voice currently only supports ALAW, LINEAR16, MULAW, MP3 and OGG_OPUS output. (status_code=400, request_id=None, body=None)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/tts.py\", line 301, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/stream_adapter.py\", line 101, in _run\n    await asyncio.gather(*tasks)\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/stream_adapter.py\", line 86, in _synthesize\n    async for audio in self._wrapped_tts.synthesize(ev.token):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/tts.py\", line 253, in __anext__\n    raise exc  # noqa: B904\n    ^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/tts.py\", line 211, in _main_task\n    raise APIConnectionError(\nlivekit.agents._exceptions.APIConnectionError: failed to synthesize speech after 4 attempts\n2025-05-02 23:47:49,477 - ERROR livekit.agents - Error in _inference_task ]\nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/tts.py\", line 445, in __anext__\n    val = await self._event_aiter.__anext__()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nStopAsyncIteration\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/voice/generation.py\", line 146, in _inference_task\n    async for audio_frame in tts_node:\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/voice/agent.py\", line 473, in tts_node\n    async for ev in stream:\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/tts.py\", line 448, in __anext__\n    raise exc  # noqa: B904\n    ^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/tts.py\", line 301, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/stream_adapter.py\", line 101, in _run\n    await asyncio.gather(*tasks)\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/stream_adapter.py\", line 81, in _forward_input\n    self._sent_stream.end_input()\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tokenize/token_stream.py\", line 95, in end_input\n    self.flush()\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tokenize/token_stream.py\", line 71, in flush\n    self._check_not_closed()\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tokenize/token_stream.py\", line 104, in _check_not_closed\n    raise RuntimeError(f\"{cls.__module__}.{cls.__name__} is closed\")\nRuntimeError: livekit.agents.tokenize.token_stream.BufferedSentenceStream is closed\n2025-05-02 23:47:49,486 - DEBUG grpc.aio._call - Client request_iterator raised exception:\nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/grpc/aio/_call.py\", line 452, in _consume_request_iterator\n    await self._write(request)\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/grpc/aio/_call.py\", line 489, in _write\n    raise asyncio.InvalidStateError(_RPC_ALREADY_FINISHED_DETAILS)\nasyncio.exceptions.InvalidStateError: RPC already finished.\n \n2025-05-02 23:47:49,642 - WARNING livekit.agents - failed to synthesize speech, retrying in 0.1s {\"tts\": \"livekit.plugins.google.tts.TTS\", \"attempt\": 1, \"streamed\": false}\nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/tts.py\", line 203, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/plugins/google/tts.py\", line 231, in _run\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: This voice currently only supports ALAW, LINEAR16, MULAW, MP3 and OGG_OPUS output. (status_code=400, request_id=None, body=None)\n2025-05-02 23:47:49,926 - WARNING livekit.agents - failed to synthesize speech, retrying in 2.0s {\"tts\": \"livekit.plugins.google.tts.TTS\", \"attempt\": 2, \"streamed\": false}\nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/tts.py\", line 203, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/plugins/google/tts.py\", line 231, in _run\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: This voice currently only supports ALAW, LINEAR16, MULAW, MP3 and OGG_OPUS output. (status_code=400, request_id=None, body=None)\n2025-05-02 23:47:52,098 - WARNING livekit.agents - failed to synthesize speech, retrying in 2.0s {\"tts\": \"livekit.plugins.google.tts.TTS\", \"attempt\": 3, \"streamed\": false}\nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/tts.py\", line 203, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/plugins/google/tts.py\", line 231, in _run\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: This voice currently only supports ALAW, LINEAR16, MULAW, MP3 and OGG_OPUS output. (status_code=400, request_id=None, body=None)\n2025-05-02 23:48:20,555 - ERROR asyncio - Task exception was never retrieved\nfuture: <Task finished name='TTS._synthesize_task' coro=<ChunkedStream._main_task() done, defined at /Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/tts.py:200> exception=APIConnectionError('failed to synthesize speech after 4 attempts')> \nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/tts.py\", line 203, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/plugins/google/tts.py\", line 231, in _run\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: This voice currently only supports ALAW, LINEAR16, MULAW, MP3 and OGG_OPUS output. (status_code=400, request_id=None, body=None)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/apple/Desktop/projects/zazmic/drivehealth/dh-livekit/venv/lib/python3.11/site-packages/livekit/agents/tts/tts.py\", line 211, in _main_task\n    raise APIConnectionError(\nlivekit.agents._exceptions.APIConnectionError: failed to synthesize speech after 4 attempts\n[Audio] cBook Pro Microphone [-59.07 dBFS] [#####-------------------------]\n`\n\n\n\nAnd this is my code:\n`import os\n\nfrom dotenv import load_dotenv\n\nfrom livekit import agents\nfrom livekit.agents import AgentSession, Agent, RoomInputOptions\nfrom livekit.plugins import (\n    noise_cancellation,\n    silero,\n)\n\nfrom livekit.plugins import google\nfrom livekit.plugins.turn_detector.multilingual import MultilingualModel\n\nload_dotenv()\n\n\nclass Assistant(Agent):\n    def __init__(self) -> None:\n        super().__init__(instructions=\"You are a helpful voice AI assistant.\")\n\n\nasync def entrypoint(ctx: agents.JobContext):\n    await ctx.connect()\n    print(os.getenv(\"GOOGLE_API_KEY\"))\n    session = AgentSession(\n        stt=google.STT(\n          model=\"medical_dictation\",\n          spoken_punctuation=True,\n          sample_rate=16000,\n          punctuate=True,\n          languages=\"en-US\",\n          interim_results=True,\n        ),\n        llm=google.LLM(model=\"gemini-2.0-flash-exp\", temperature=0.8),\n        tts=google.TTS(\n          language=\"en-US\",\n          gender=\"female\",\n          voice_name=\"en-US-Chirp3-HD-Leda\",\n          sample_rate=16000\n        ),\n        vad=silero.VAD.load(),\n        turn_detection=MultilingualModel(),\n    )\n    await session.start(\n        room=ctx.room,\n        agent=Assistant(),\n        room_input_options=RoomInputOptions(\n            noise_cancellation=noise_cancellation.BVC(),\n        ),\n    )\n\n    await session.generate_reply(\n        instructions=\"Greet the user and offer your assistance.\",\n    )\n\n\nif __name__ == \"__main__\":\n    agents.cli.run_app(agents.WorkerOptions(entrypoint_fnc=entrypoint))`\n\n\n\n\nLet me know what im doing wrong and if you need any more details or content.",
      "state": "closed",
      "author": "fahadanwaar",
      "author_type": "User",
      "created_at": "2025-05-02T18:54:59Z",
      "updated_at": "2025-05-03T15:45:47Z",
      "closed_at": "2025-05-03T15:45:46Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2180/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2180",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2180",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:20.996483",
      "comments": []
    },
    {
      "issue_number": 2169,
      "title": "SIP Participant fails to create when in agent context",
      "body": "Hello, I love what you guys are building but I am running into an issue with SIP that I am confused about. \nI am using this code as reference: https://github.com/livekit-examples/outbound-caller-python \nI managed to set up everything correctly because my trunk is working when I run `lk sip participant create sip_outbound.json` \n\nIt correctly calls my number.  So as the readme suggest, I should be able to call myself with the agent in the room using:\n```\nlk dispatch create \\\n  --new-room \\\n  --agent-name outbound-caller \\\n  --metadata '{\"phone_number\": \"my-number\", \"transfer_to\": \"other-number\"}'\n```\n\nBut I get this error\n`2025-04-30 19:59:21,767 - ERROR outbound-caller - error creating SIP participant: twirp error unknown: object cannot be found, SIP status: None None {\"pid\": 90589, \"job_id\": \"AJ_U65yEpH3VAjK\"}`\n\nHow should I go to debug that?\nHere are the input of my sip creation at this line:  https://github.com/livekit-examples/outbound-caller-python/blob/main/agent.py#L212\n```\nRoom Name: my-sip-room\nSIP Trunk ID: TKd3b5c07798d131b1e50f0c2cd724ffe3\nSIP Call To: +33...\nParticipant Identity: +33...\nWait Until Answered: True\n```\nhere are my dependencies in `pyproject.toml`\n```\n[project]\nname = \"outbound-caller-python\"\nversion = \"0.1.0\"\nrequires-python = \">=3.13\"\ndependencies = [\n    \"livekit>=1.0\",\n    \"livekit-agents[cartesia,deepgram,openai,silero,turn-detector]~=1.0rc0\",\n    \"livekit-plugins-noise-cancellation~=0.2\",\n    \"python-dotenv~=1.0\",\n]\n```\n\nI believe its related to https://github.com/livekit-examples/outbound-caller-python/issues/7",
      "state": "closed",
      "author": "pievalentin",
      "author_type": "User",
      "created_at": "2025-05-01T00:45:02Z",
      "updated_at": "2025-05-01T01:34:59Z",
      "closed_at": "2025-05-01T01:34:28Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2169/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2169",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2169",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:20.996495",
      "comments": [
        {
          "author": "pievalentin",
          "body": "It was an error on my part. I used the twilio trunkId instead of the livekit trunk id",
          "created_at": "2025-05-01T01:34:58Z"
        }
      ]
    },
    {
      "issue_number": 1679,
      "title": "Gemini API WebSocket Connection Overload Issue",
      "body": "Issue Description:\n\n- When running the gemini_agent.py example, the application is bombarding the Gemini API with WebSocket connection requests, resulting in extensible_stubs::OVERLOADED_TOO_MANY_RETRIES_PER_REQUEST errors. This causes service degradation and eventually failures.\n\nDetails:\n\n- The multimodal agent appears to be making multiple API calls in rapid succession without proper rate limiting:\n- Each interaction triggers new API calls without respecting rate limits\n- Multiple WebSocket connections are being attempted simultaneously\n- Log shows repeated \"AFC is enabled with max remote calls: 10\" messages followed by overload errors\n\nSteps to Reproduce:\n\n- Run the gemini_agent.py example\n- Interact with the agent through voice\n- Observe terminal logs showing repeated connection attempts and eventual API overload errors\n\n\n\nlog:\n2025-03-19 16:54:11,902 - ERROR livekit.agents - unhandled exception while running the job task \n(venv) PS C:\\Users\\user\\Desktop\\Realtime API\\agents repo to create context from\\agents\\examples\\multimodal-agent> python gemini_agent.py dev\n2025-03-19 16:54:34,778 - DEBUG asyncio - Using proactor: IocpProactor \n2025-03-19 16:54:34,781 - DEV  livekit.agents - Watching C:\\Users\\user\\Desktop\\Realtime API\\agents repo to create context from\\agents\\examples\\multimodal-agent \n2025-03-19 16:54:35,989 - DEBUG asyncio - Using proactor: IocpProactor \n2025-03-19 16:54:36,012 - INFO livekit.agents - starting worker {\"version\": \"0.12.17\", \"rtc-version\": \"0.22.0\"}\n2025-03-19 16:54:36,123 - INFO livekit.agents - registered worker {\"id\": \"AW_6YY6icS5uj8B\", \"region\": \"Israel\", \"protocol\": 15, \"node_id\": \"NC_OJERUSALEM1A_mTEonTq5Kyka\"}\n2025-03-19 16:54:37,626 - INFO livekit.agents - received job request {\"job_id\": \"AJ_Z4ebpzUVEow8\", \"dispatch_id\": \"\", \"room_name\": \"room-5pAV-vtiK\", \"agent_name\": \"\", \"resuming\": false}\n2025-03-19 16:54:37,635 - INFO livekit.agents - initializing job runner {\"tid\": 18460}\n2025-03-19 16:54:37,635 - INFO livekit.agents - job runner initialized {\"tid\": 18460}\n2025-03-19 16:54:37,635 - DEBUG asyncio - Using proactor: IocpProactor \n2025-03-19 16:54:37,637 - INFO my-worker - starting entrypoint \n2025-03-19 16:54:37,639 - INFO livekit - livekit_ffi::server:138:livekit_ffi::server - initializing ffi server v0.12.16 \n2025-03-19 16:54:37,639 - INFO livekit - livekit_ffi::cabi:36:livekit_ffi::cabi - initializing ffi server v0.12.16 \n2025-03-19 16:54:37,640 - INFO livekit - livekit_api::signal_client::signal_stream:96:livekit_api::signal_client::signal_stream - connecting to wss://ai-phone-calling-system-plhbu8ao.livekit.cloud/rtc?sdk=python&protocol=15&auto_subscribe=0&adaptive_stream=0&version=0.22.0&access_token=... \n2025-03-19 16:54:37,652 - DEBUG livekit - rustls::anchors:150:rustls::anchors - add_parsable_certificates processed 49 valid and 0 invalid certs \n2025-03-19 16:54:37,652 - DEBUG livekit - tokio_tungstenite::tls::encryption::rustls:103:tokio_tungstenite::tls::encryption::rustls - Added 49/49 native root certificates (ignored 0)\n2025-03-19 16:54:37,652 - DEBUG livekit - rustls::client::hs:73:rustls::client::hs - No cached session for DnsName(\"ai-phone-calling-system-plhbu8ao.livekit.cloud\")\n2025-03-19 16:54:37,653 - DEBUG livekit - rustls::client::hs:132:rustls::client::hs - Not resuming any session\n2025-03-19 16:54:37,661 - DEBUG livekit - rustls::client::hs:615:rustls::client::hs - Using ciphersuite TLS13_AES_128_GCM_SHA256\n2025-03-19 16:54:37,661 - DEBUG livekit - rustls::client::tls13:142:rustls::client::tls13 - Not resuming\n2025-03-19 16:54:37,661 - DEBUG livekit - rustls::client::tls13:381:rustls::client::tls13 - TLS1.3 encrypted extensions: []\n2025-03-19 16:54:37,662 - DEBUG livekit - rustls::client::hs:472:rustls::client::hs - ALPN protocol is None\n2025-03-19 16:54:37,720 - DEBUG livekit - tungstenite::handshake::client:95:tungstenite::handshake::client - Client handshake done. \nC:\\Users\\user\\Desktop\\Realtime API\\agents repo to create context from\\venv\\Lib\\site-packages\\livekit\\plugins\\google\\beta\\realtime\\realtime_api.py:540: ExperimentalWarning: The live API is experimental and may change in future versions.\n  async with self._client.aio.live.connect(\n2025-03-19 16:54:37,930 - INFO livekit.agents - Session initialized with chat context\n2025-03-19 16:54:38,349 - INFO google_genai.live - b'{\\n  \"setupComplete\": {}\\n}\\n' \n2025-03-19 16:54:38,559 - INFO google_genai.live - b'{\\n  \"setupComplete\": {}\\n}\\n' \n2025-03-19 16:54:39,943 - INFO google_genai.models - AFC is enabled with max remote calls: 10. \n2025-03-19 16:54:41,307 - DEBUG livekit.agents - committed agent speech {\"agent_transcript\": \"Hello, I'm happy to help you.\", \"interrupted\": false}\n2025-03-19 16:54:42,542 - DEBUG livekit.agents - committed user speech {\"user_transcript\": \"Hi, how long?\", \"interrupted\": false}\n2025-03-19 16:54:46,252 - INFO google_genai.models - AFC is enabled with max remote calls: 10. \n2025-03-19 16:54:47,761 - DEBUG livekit.agents - committed agent speech {\"agent_transcript\": \"I'm looking for some advice on planning a trip to Italy. I'm not sure where to start.\", \"interrupted\": false}\n2025-03-19 16:54:57,345 - INFO google_genai.models - AFC is enabled with max remote calls: 10. \n2025-03-19 16:54:58,596 - DEBUG livekit.agents - committed agent speech {\"agent_transcript\": \"Are you planning a trip?\", \"interrupted\": false}\n2025-03-19 16:55:05,575 - DEBUG livekit.agents - committed user speech {\"user_transcript\": \"Are you still in?\", \"interrupted\": false}\n2025-03-19 16:55:07,501 - INFO google_genai.models - AFC is enabled with max remote calls: 10. \n2025-03-19 16:55:09,229 - DEBUG livekit.agents - committed agent speech {\"agent_transcript\": \"Yes, I am. Are you planning a trip?\", \"interrupted\": false}\n2025-03-19 16:55:19,722 - DEBUG livekit.agents - committed user speech {\"user_transcript\": \"Um, it's not about that, it's about testing your uh responsiveness times.\", \"interrupted\": false}\n2025-03-19 16:55:26,855 - INFO google_genai.models - AFC is enabled with max remote calls: 10. \n2025-03-19 16:55:28,082 - DEBUG livekit.agents - committed agent speech {\"agent_transcript\": \"Okay, I understand. So you're testing my response time. Is there anything else you'd like to test or any other questions you have?\", \"interrupted\": false}\n2025-03-19 16:55:30,173 - ERROR livekit.plugins.google - Error in _recv_task \nTraceback (most recent call last):\n  File \"C:\\Users\\user\\Desktop\\Realtime API\\agents repo to create context from\\venv\\Lib\\site-packages\\livekit\\agents\\utils\\log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\Desktop\\Realtime API\\agents repo to create context from\\venv\\Lib\\site-packages\\livekit\\plugins\\google\\beta\\realtime\\realtime_api.py\", line 457, in _recv_task\n    async for response in self._session.receive():\n  File \"C:\\Users\\user\\Desktop\\Realtime API\\agents repo to create context from\\venv\\Lib\\site-packages\\google\\genai\\live.py\", line 136, in receive\n    while result := await self._receive():\n                    ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\Desktop\\Realtime API\\agents repo to create context from\\venv\\Lib\\site-packages\\google\\genai\\live.py\", line 206, in _receive\n    raw_response = await self._ws.recv(decode=False)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\Desktop\\Realtime API\\agents repo to create context from\\venv\\Lib\\site-packages\\websockets\\asyncio\\connection.py\", line 313, in recv\n    raise self.protocol.close_exc from self.recv_exc\nwebsockets.exceptions.ConnectionClosedError: received 1011 (internal error) Request trace id: 21d399562688c813, [ORIGINAL ERROR] extensible_stubs::OVERLOADED_TOO_MANY_RETRIES_PER_REQUEST: You are mos; then sent 1011 (internal error) Request trace id: 21d399562688c813, [ORIGINAL ERROR] extensible_stubs::OVERLOADED_TOO_MANY_RETRIES_PER_REQUEST: You are mos\n2025-03-19 16:55:36,316 - ERROR livekit.plugins.google - Error in _main_task \nTraceback (most recent call last):\n  File \"C:\\Users\\user\\Desktop\\Realtime API\\agents repo to create context from\\venv\\Lib\\site-packages\\livekit\\agents\\utils\\log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\Desktop\\Realtime API\\agents repo to create context from\\venv\\Lib\\site-packages\\livekit\\plugins\\google\\beta\\realtime\\realtime_api.py\", line 550, in _main_task\n    await asyncio.gather(*tasks)\n  File \"C:\\Users\\user\\Desktop\\Realtime API\\agents repo to create context from\\venv\\Lib\\site-packages\\livekit\\agents\\utils\\log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\Desktop\\Realtime API\\agents repo to create context from\\venv\\Lib\\site-packages\\livekit\\plugins\\google\\beta\\realtime\\realtime_api.py\", line 457, in _recv_task\n    async for response in self._session.receive():\n  File \"C:\\Users\\user\\Desktop\\Realtime API\\agents repo to create context from\\venv\\Lib\\site-packages\\google\\genai\\live.py\", line 136, in receive\n    while result := await self._receive():\n                    ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\Desktop\\Realtime API\\agents repo to create context from\\venv\\Lib\\site-packages\\google\\genai\\live.py\", line 206, in _receive\n    raw_response = await self._ws.recv(decode=False)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\Desktop\\Realtime API\\agents repo to create context from\\venv\\Lib\\site-packages\\websockets\\asyncio\\connection.py\", line 313, in recv\n    raise self.protocol.close_exc from self.recv_exc\nwebsockets.exceptions.ConnectionClosedError: received 1011 (internal error) Request trace id: 21d399562688c813, [ORIGINAL ERROR] extensible_stubs::OVERLOADED_TOO_MANY_RETRIES_PER_REQUEST: You are mos; then sent 1011 (internal error) Request trace id: 21d399562688c813, [ORIGINAL ERROR] extensible_stubs::OVERLOADED_TOO_MANY_RETRIES_PER_REQUEST: You are mos\n2025-03-19 16:55:45,090 - INFO livekit.agents - shutting down worker {\"id\": \"AW_6YY6icS5uj8B\"}\n2025-03-19 16:55:45,092 - DEBUG livekit.agents - shutting down job task {\"reason\": \"\", \"user_initiated\": false}\n2025-03-19 16:55:45,093 - DEBUG livekit.agents - job exiting {\"reason\": \"\", \"tid\": 18460, \"job_id\": \"AJ_Z4ebpzUVEow8\"}\n2025-03-19 16:55:45,100 - DEBUG livekit - tungstenite::protocol:666:tungstenite::protocol - Received close frame: None\n2025-03-19 16:55:45,103 - INFO livekit - livekit::room:1191:livekit::room - disconnected from room with reason: ClientInitiated\n2025-03-19 16:55:45,103 - DEBUG livekit.agents - http_session(): closing the httpclient ctx\n2025-03-19 16:55:45,104 - DEBUG livekit.agents - http_session(): creating a new httpclient ctx\n2025-03-19 16:55:45,135 - ERROR asyncio - Task was destroyed but it is pending!\ntask: <Task pending name='Task-33' coro=<MultimodalAgent._main_task() running at C:\\Users\\user\\Desktop\\Realtime API\\agents repo to create context from\\venv\\Lib\\site-packages\\livekit\\agents\\utils\\log.py:16> wait_for=<Future pending cb=[Task.task_wakeup()]>>\n2025-03-19 16:55:45,135 - ERROR asyncio - Task exception was never retrieved\nfuture: <Task finished name='gemini-realtime-session' coro=<GeminiRealtimeSession._main_task() done, defined at C:\\Users\\user\\Desktop\\Realtime API\\agents repo to create context from\\venv\\Lib\\site-packages\\livekit\\agents\\utils\\log.py:13> exception=ConnectionClosedError(Close(code=1011, reason='Request trace id: 21d399562688c813, [ORIGINAL ERROR] extensible_stubs::OVERLOADED_TOO_MANY_RETRIES_PER_REQUEST: You are mos'), Close(code=1011, reason='Request trace id: 21d399562688c813, [ORIGINAL ERROR] extensible_stubs::OVERLOADED_TOO_MANY_RETRIES_PER_REQUEST: You are mos'), True)>\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\Desktop\\Realtime API\\agents repo to create context from\\venv\\Lib\\site-packages\\livekit\\agents\\utils\\log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\Desktop\\Realtime API\\agents repo to create context from\\venv\\Lib\\site-packages\\livekit\\plugins\\google\\beta\\realtime\\realtime_api.py\", line 550, in _main_task\n    await asyncio.gather(*tasks)\n  File \"C:\\Users\\user\\Desktop\\Realtime API\\agents repo to create context from\\venv\\Lib\\site-packages\\livekit\\agents\\utils\\log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\Desktop\\Realtime API\\agents repo to create context from\\venv\\Lib\\site-packages\\livekit\\plugins\\google\\beta\\realtime\\realtime_api.py\", line 457, in _recv_task\n    async for response in self._session.receive():\n  File \"C:\\Users\\user\\Desktop\\Realtime API\\agents repo to create context from\\venv\\Lib\\site-packages\\google\\genai\\live.py\", line 136, in receive\n    while result := await self._receive():\n                    ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\Desktop\\Realtime API\\agents repo to create context from\\venv\\Lib\\site-packages\\google\\genai\\live.py\", line 206, in _receive\n    raw_response = await self._ws.recv(decode=False)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\Desktop\\Realtime API\\agents repo to create context from\\venv\\Lib\\site-packages\\websockets\\asyncio\\connection.py\", line 313, in recv\n    raise self.protocol.close_exc from self.recv_exc\nwebsockets.exceptions.ConnectionClosedError: received 1011 (internal error) Request trace id: 21d399562688c813, [ORIGINAL ERROR] extensible_stubs::OVERLOADED_TOO_MANY_RETRIES_PER_REQUEST: You are mos; then sent 1011 (internal error) Request trace id: 21d399562688c813, [ORIGINAL ERROR] extensible_stubs::OVERLOADED_TOO_MANY_RETRIES_PER_REQUEST: You are mos\n2025-03-19 16:55:45,137 - ERROR asyncio - Task was destroyed but it is pending!\ntask: <Task pending name='Task-35' coro=<STTSegmentsForwarder._run() running at C:\\Users\\user\\Desktop\\Realtime API\\agents repo to create context from\\venv\\Lib\\site-packages\\livekit\\agents\\transcription\\stt_forwarder.py:64> wait_for=<Future pending cb=[Task.task_wakeup()]>>\n2025-03-19 16:55:45,137 - ERROR asyncio - Task was destroyed but it is pending!\ntask: <Task pending name='Task-36' coro=<STTSegmentsForwarder._run() running at C:\\Users\\user\\Desktop\\Realtime API\\agents repo to create context from\\venv\\Lib\\site-packages\\livekit\\agents\\transcription\\stt_forwarder.py:64> wait_for=<Future pending cb=[Task.task_wakeup()]>>\n2025-03-19 16:55:45,137 - ERROR livekit.agents - error in stt transcription\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\miniconda3\\Lib\\asyncio\\queues.py\", line 158, in get\n    await getter\nGeneratorExit\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\Desktop\\Realtime API\\agents repo to create context from\\venv\\Lib\\site-packages\\livekit\\agents\\transcription\\stt_forwarder.py\", line 64, in _run\n    seg = await self._queue.get()\n          ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\miniconda3\\Lib\\asyncio\\queues.py\", line 160, in get\n    getter.cancel()  # Just in case getter is not done yet.\n    ^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\miniconda3\\Lib\\asyncio\\base_events.py\", line 761, in call_soon\n    self._check_closed()\n  File \"C:\\Users\\user\\miniconda3\\Lib\\asyncio\\base_events.py\", line 519, in _check_closed\n    raise RuntimeError('Event loop is closed')\nRuntimeError: Event loop is closed\n2025-03-19 16:55:45,140 - ERROR livekit.agents - error in stt transcription\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\miniconda3\\Lib\\asyncio\\queues.py\", line 158, in get\n    await getter\nGeneratorExit\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\Desktop\\Realtime API\\agents repo to create context from\\venv\\Lib\\site-packages\\livekit\\agents\\transcription\\stt_forwarder.py\", line 64, in _run\n    seg = await self._queue.get()\n          ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\miniconda3\\Lib\\asyncio\\queues.py\", line 160, in get\n    getter.cancel()  # Just in case getter is not done yet.\n    ^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\miniconda3\\Lib\\asyncio\\base_events.py\", line 761, in call_soon\n    self._check_closed()\n  File \"C:\\Users\\user\\miniconda3\\Lib\\asyncio\\base_events.py\", line 519, in _check_closed\n    raise RuntimeError('Event loop is closed')\nRuntimeError: Event loop is closed\n",
      "state": "closed",
      "author": "JosephDahan",
      "author_type": "User",
      "created_at": "2025-03-19T15:51:19Z",
      "updated_at": "2025-04-30T06:23:21Z",
      "closed_at": "2025-03-30T06:54:48Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1679/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1679",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1679",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:21.225524",
      "comments": [
        {
          "author": "davidzhao",
          "body": "what you are observing is rate limits being exceeded. when it exceeds rate limiter, we'd retry the connection, hence the repeated errors in the logs. this is expected",
          "created_at": "2025-03-30T06:54:24Z"
        },
        {
          "author": "Abhishek21k",
          "body": "in the gemini client config you can add this:\n\n```python\n\ndef get_current_weather(location: str) -> str:\n    \"\"\"Returns the current weather.\n\n    Args:\n        location: The city and state, e.g. San Francisco, CA\n    \"\"\"\n    return \"sunny\"\n\nresponse = client.models.generate_content(\n    model=\"gemin",
          "created_at": "2025-04-15T12:41:26Z"
        },
        {
          "author": "Uriyo",
          "body": "could you tell for the agentsession class too\n",
          "created_at": "2025-04-30T06:23:20Z"
        }
      ]
    },
    {
      "issue_number": 2164,
      "title": "Issue with api.S3Upload when integrating with Supabase",
      "body": "Running the following code snippet, livekit api is not properly reading access key and I get: \"the request signature we calculated does not match the signature you provided.\" \n\nThe access key and the secret work perfectly, and the recording is being initialized correctly. Seems to me that S3Upload function is not properly taking in secret key.\n\n\n # Create the recording request\n        req = api.RoomCompositeEgressRequest(\n            room_name=room_name,\n            audio_only=False,\n            file_outputs=[api.EncodedFileOutput(\n                file_type=api.EncodedFileType.MP4,\n                filepath=filepath,\n                # Supabase storage integration\n                s3=api.S3Upload(\n                    bucket=bucket_name,\n                    region=\"auto\",  # us-east-1\n                    access_key=supabase_access_key,  \n                    secret=supabase_secret_key, \n                    endpoint=end_point,\n                    force_path_style=True,\n                ),\n            )],\n        )",
      "state": "closed",
      "author": "JslYoon",
      "author_type": "User",
      "created_at": "2025-04-30T05:57:57Z",
      "updated_at": "2025-04-30T06:13:31Z",
      "closed_at": "2025-04-30T06:13:30Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2164/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2164",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2164",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:21.505295",
      "comments": [
        {
          "author": "davidzhao",
          "body": "the issue is on the Supabase side: https://github.com/supabase/storage/issues/577\n\nthey are currently not compatible with AWS Go SDK v2. Since v1 has been deprecated, we don't have much of a choice on our side",
          "created_at": "2025-04-30T06:13:30Z"
        }
      ]
    },
    {
      "issue_number": 2160,
      "title": "livekit cloud: the room connection was not established within 10 seconds after calling job_entry.",
      "body": "Hello LiveKit team,\n\nWe are getting this issue from time to time: \n\n```\nThe room connection was not established within 10 seconds after calling job_entry. This may indicate that job_ctx.connect() was not called.\n```\n\nWe notice that sometimes the `context.connect()` task can take minutes (after multiple retries) disturbing our LiveKit calls, as the participant won't wait for minutes to start a call.\n\nThe interesting thing is that 2 different sessions are created for the same room:\n\n- Session 1 ([RM_8yqeew7Bcxeh](https://cloud.livekit.io/projects/p_32w6jn5wyzd/sessions/RM_8yqeew7Bcxeh)) when the participant joins but is awaiting for the `context.connect()` to finish. Client will leave after 30 secs as there are no response.\n\n- Session 2 ([RM_qBxLxGPPP6uP](https://cloud.livekit.io/projects/p_32w6jn5wyzd/sessions/RM_qBxLxGPPP6uP)) when the agent joins after the `context.connect()` finished (after many retries). Room will be closed later as there are no participants.\n\nPlease, is there a way to avoid this ? can Region pinning help on this ?\n\nThank you!",
      "state": "open",
      "author": "devniel",
      "author_type": "User",
      "created_at": "2025-04-29T19:21:52Z",
      "updated_at": "2025-04-29T19:21:52Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2160/reactions",
        "total_count": 3,
        "+1": 3,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2160",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2160",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:21.776898",
      "comments": []
    },
    {
      "issue_number": 2154,
      "title": "\"Unrecognized model in livekit/turn-detector\" on Railway",
      "body": "Hi folks. I'm trying to deploy a VoicePipelineAgent on Railway.\n\nThis agents works locally, and was working on Railway several weeks ago as well on the initial deployment. However, I needed to create a fresh instance and now I'm getting the \"Unrecognized model in livekit/turn-detector\"  issue below (I haven't changed requirements or the dockerfile in the meanwhile). I'm on Windows 10 for local dev.\n\n```\n  File \"/app/agent_bab.py\", line 786, in <module>\n\n    cli.run_app(\n\n  File \"/usr/local/lib/python3.12/site-packages/livekit/agents/cli/cli.py\", line 187, in run_app\n\n    cli()\n\n  File \"/usr/local/lib/python3.12/site-packages/click/core.py\", line 1161, in __call__\n\n    return self.main(*args, **kwargs)\n\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n\n  File \"/usr/local/lib/python3.12/site-packages/click/core.py\", line 1082, in main\n\n                           ^^^^^^^^^\n\n    rv = self.invoke(ctx)\n\n         ^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/site-packages/click/core.py\", line 1697, in invoke\n\n^^^^^^^^^^^^^^^^^^^^^^\n\n    return ctx.invoke(self.callback, **ctx.params)\n\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/site-packages/click/core.py\", line 1443, in invoke\n\n  File \"/usr/local/lib/python3.12/site-packages/click/core.py\", line 788, in invoke\n\n^^^^^\n\n    return __callback(*args, **kwargs)\n\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n    raise ValueError(\n\n  File \"/usr/local/lib/python3.12/site-packages/livekit/agents/cli/cli.py\", line 184, in download_files\n\n    plugin.download_files()\n\n  File \"/usr/local/lib/python3.12/site-packages/livekit/plugins/turn_detector/__init__.py\", line 34, in download_files\n\n    AutoTokenizer.from_pretrained(HG_MODEL, revision=MODEL_REVISION)\n\n  File \"/usr/local/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py\", line 966, in from_pretrained\n\n    config = AutoConfig.from_pretrained(\n\nValueError: Unrecognized model in livekit/turn-detector. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, aria, aria_text, audio-spectrogram-transformer, autoformer, aya_vision, bamba, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, cohere2, colpali, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dab-detr, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deepseek_v3, deformable_detr, deit, depth_anything, depth_pro, deta, detr, diffllama, dinat, dinov2, dinov2_with_registers, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, emu3, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, gemma3, gemma3_text, git, glm, glm4, glpn, got_ocr2, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, granitemoeshared, granitevision, graphormer, grounding-dino, groupvit, helium, hiera, hubert, ibert, idefics, idefics2, idefics3, idefics3_vision, ijepa, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llama4, llama4_text, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mistral3, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, modernbert, moonshine, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmo2, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phi4_multimodal, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prompt_depth_anything, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_5_vl, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, qwen3, qwen3_moe, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rt_detr_v2, rwkv, sam, sam_vision_model, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, shieldgemma2, siglip, siglip2, siglip_vision_model, smolvlm, smolvlm_vision, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superglue, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, textnet, time_series_transformer, timesformer, timm_backbone, timm_wrapper, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vitpose, vitpose_backbone, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zamba2, zoedepth\n\n\n  File \"/usr/local/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py\", line 1151, in from_pretrained\n```\n\nThis is my dockerfile:\n```\nARG PYTHON_VERSION=3.12.9\nFROM python:${PYTHON_VERSION}-slim as base\n\n# Prevents Python from writing pyc files.\nENV PYTHONDONTWRITEBYTECODE=1\n\n# Keeps Python from buffering stdout and stderr to avoid situations where\n# the application crashes without emitting any logs due to buffering.\nENV PYTHONUNBUFFERED=1\n\nWORKDIR /app\n\n# Create a non-privileged user that the app will run under.\nARG UID=10001\nRUN adduser \\\n    --disabled-password \\\n    --gecos \"\" \\\n    --home \"/nonexistent\" \\\n    --shell \"/sbin/nologin\" \\\n    --no-create-home \\\n    --uid \"${UID}\" \\\n    appuser\n\n# ✅ Copy only requirements.txt first (allows better Docker caching)\nCOPY requirements.txt .\n\n# ✅ Install dependencies\nRUN python -m pip install --no-cache-dir -r requirements.txt\n\n# ✅ Now copy the rest of the application source code\nCOPY . .\n\n# Switch to the non-privileged user to run the application.\nUSER appuser\n\n# Run the application.\nCMD [\"sh\", \"-c\", \"python agent_bab.py download-files && python agent_bab.py start\"]\n```\n\nThis is my requirements.txt:\n```\nlivekit==0.20.0\nlivekit-agents==0.12.17\nlivekit-plugins-openai==0.10.18\nlivekit-plugins-cartesia==0.4.7\nlivekit-plugins-deepgram==0.6.18\nlivekit-plugins-silero==0.7.4\nlivekit-plugins-elevenlabs==0.8.0\nlivekit-plugins-turn-detector==0.4.1\nlivekit-plugins-assemblyai==0.2.3\npython-dotenv==1.0.1\nllama-index==0.12.17\ngeopy==2.4.1\ntorch==2.6.0\nphonenumbers==9.0.0\ntransformers==4.51.3\nhuggingface-hub==0.30.2\n```\n\nENV variables:\nThe only extra thing I needed on Railway was the environmental variable below to make the first/initial deployment work: `HF_HOME=\"/tmp/huggingface\"`\n\nAny help would be much appreciated, thanks!",
      "state": "open",
      "author": "DKorman",
      "author_type": "User",
      "created_at": "2025-04-28T20:55:47Z",
      "updated_at": "2025-04-29T15:06:58Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2154/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2154",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2154",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:21.776922",
      "comments": [
        {
          "author": "ChenghaoMou",
          "body": "You can check the downloaded files in your docker container to see if the correct model config exists.\n\n`livekit-plugins-turn-detector==0.4.1` points to the v1.2.0 model on the hub and the [config file](https://huggingface.co/livekit/turn-detector/blob/v1.2.0/config.json) does contain a `model_type`",
          "created_at": "2025-04-29T15:06:56Z"
        }
      ]
    },
    {
      "issue_number": 1186,
      "title": "when use  job_executor_type=JobExecutorType.THREAD, the memory not drop when the room is disconnected",
      "body": "worker_options = WorkerOptions(\r\n        agent_name=AGENT_NAME,\r\n        request_fnc=define_request_fnc,\r\n        entrypoint_fnc=entrypoint,\r\n        load_fnc=memory_only_load_function,\r\n        job_executor_type=JobExecutorType.THREAD,\r\n        load_threshold=0.9,\r\n        port=8081\r\n    )\r\n    cli.run_app(worker_options)\r\n\r\nHello, I used job_executor_type=JobExecutorType.THREAD on ubuntu to create 1000 rooms(One agent per room)\r\n，and the memory occupied by the worker process will not drop when the room is disconnected，can you help me, \r\nthanks",
      "state": "open",
      "author": "zhushixia",
      "author_type": "User",
      "created_at": "2024-12-06T11:49:54Z",
      "updated_at": "2025-04-28T18:11:01Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1186/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1186",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1186",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:22.052545",
      "comments": [
        {
          "author": "zhushixia",
          "body": "And every time the room is closed, the memory usage does not decrease, but instead increases",
          "created_at": "2024-12-08T14:27:34Z"
        },
        {
          "author": "zhushixia",
          "body": "env：\r\nsystem: ubuntu 22.04\r\nlivekit agent: 0.11.1",
          "created_at": "2024-12-09T03:09:32Z"
        },
        {
          "author": "theo1893",
          "body": "the same issue. but in my case, both THEAD and PROCESS cause memory leak in Ubuntu, and even the same Python(3.13.2) perform differently in different platform:\nin MacOS, everything is ok (python=3.13.2)\nin Ubuntu, memory always leak (pythoo=3.13.2)",
          "created_at": "2025-04-28T18:11:00Z"
        }
      ]
    },
    {
      "issue_number": 1365,
      "title": "gemini realtime api error",
      "body": "Hello, I have followed the instructions to set up the example gemini realtime agent and ran it in dev mode. When I connect to it using the agents playground, I consistently get this error: 2025-01-10 11:27:31,955 - ERROR livekit.plugins.google - Error in _send_task\r\nTraceback (most recent call last):\r\nFile \"/home/projects/gemini_agent_test/agents/examples/multimodal-agent/venv/lib64/python3.12/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\r\nreturn await fn(*args, **kwargs)\r\n^^^^^^^^^^^^^^^^^^^^^^^^^\r\nFile \"/home/projects/gemini_agent_test/agents/examples/multimodal-agent/venv/lib64/python3.12/site-packages/livekit/plugins/google/beta/realtime/realtime_api.py\", line 289, in _send_task\r\nawait self._session.send(msg)\r\n^^^^^^^^^^^^^^^^^^^^^^^\r\nTypeError: AsyncSession.send() takes 1 positional argument but 2 were given {\"pid\": 3559, \"job_id\": \"AJ_o3zTFVEvP7LQ\"}\r\n2025-01-10 11:27:32,119 - ERROR livekit.plugins.google - Error in _main_task\r\nTraceback (most recent call last):\r\nFile \"/home/projects/gemini_agent_test/agents/examples/multimodal-agent/venv/lib64/python3.12/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\r\nreturn await fn(*args, **kwargs)\r\n^^^^^^^^^^^^^^^^^^^^^^^^^\r\nFile \"/home/projects/gemini_agent_test/agents/examples/multimodal-agent/venv/lib64/python3.12/site-packages/livekit/plugins/google/beta/realtime/realtime_api.py\", line 386, in _main_task\r\nawait asyncio.gather(*tasks)\r\nFile \"/home/projects/gemini_agent_test/agents/examples/multimodal-agent/venv/lib64/python3.12/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\r\nreturn await fn(*args, **kwargs)\r\n^^^^^^^^^^^^^^^^^^^^^^^^^\r\nFile \"/home/projects/gemini_agent_test/agents/examples/multimodal-agent/venv/lib64/python3.12/site-packages/livekit/plugins/google/beta/realtime/realtime_api.py\", line 289, in _send_task\r\nawait self._session.send(msg)\r\n^^^^^^^^^^^^^^^^^^^^^^^\r\nTypeError: AsyncSession.send() takes 1 positional argument but 2 were given {\"pid\": 3559, \"job_id\": \"AJ_o3zTFVEvP7LQ\"}\r\n\r\nPlease advise!",
      "state": "closed",
      "author": "philhosophy",
      "author_type": "User",
      "created_at": "2025-01-13T00:11:21Z",
      "updated_at": "2025-04-28T16:08:25Z",
      "closed_at": "2025-04-28T16:08:25Z",
      "labels": [
        "bug",
        "plugins"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1365/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1365",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1365",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:22.313699",
      "comments": [
        {
          "author": "saadi297",
          "body": "I was having the same issue. Downgrading the google-genai package to 0.3.0 fixed it. `pip install google-genai==0.3.0`",
          "created_at": "2025-01-13T09:16:44Z"
        },
        {
          "author": "philhosophy",
          "body": "Thanks, @saadi297! That fixed it for me. May I ask how you found the solution?",
          "created_at": "2025-01-13T10:03:09Z"
        },
        {
          "author": "davidzhao",
          "body": "this has been fixed in v1, closing",
          "created_at": "2025-04-28T16:08:11Z"
        }
      ]
    },
    {
      "issue_number": 2148,
      "title": "User Transcripts not emitted",
      "body": "Hi team,\nI was using latest livekit version \nI'm using realtime llm model in Agent Session .\nUsing this event conversation_item_added I was only recieved agent transcripts . user Transcripts not getting. Can you please help me on this?\nWhere as I observed if I use voicepipeline - stt, llm , tts then I'm able to get user Transcripts.\nIs it not supported for realtime model?",
      "state": "closed",
      "author": "BhavaniMallapragada",
      "author_type": "User",
      "created_at": "2025-04-28T10:28:03Z",
      "updated_at": "2025-04-28T15:45:26Z",
      "closed_at": "2025-04-28T15:45:25Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2148/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2148",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2148",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:22.527139",
      "comments": [
        {
          "author": "ChenghaoMou",
          "body": "Possible duplicate of #2098 ",
          "created_at": "2025-04-28T12:30:59Z"
        },
        {
          "author": "davidzhao",
          "body": "yeah, this is the same issue as #2098, closing this one",
          "created_at": "2025-04-28T15:45:25Z"
        }
      ]
    },
    {
      "issue_number": 2134,
      "title": "TypeError in console mode: ctx.delete_room fails when Room.name returns MagicMock object",
      "body": "<!--\nHello! Thanks for taking the time to file a bug report.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already reported this issue.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n-->\n\nWhen running in console mode, calling ctx.delete_room() triggers a TypeError because room.name is returning a MagicMock object instead of a string value.\n\nIn console mode, we observed that `ctx.room.name` returns:\n```<MagicMock name='mock.name' id='4517095008'>```\n\nWhen ctx.delete_room() is called, it fails with:\n```\n2025-04-26 18:34:20,827 - ERROR livekit.agents - unhandled exception while running the job task \nTraceback (most recent call last):\n  File \"/Users/komiyariku/voice-agent/mbti_agent.py\", line 337, in entrypoint\n    await ctx.delete_room()\n          ~~~~~~~~~~~~~~~^^\n  File \"/Users/komiyariku/ai/cartesia-livekit-voice-agent/venv/lib/python3.13/site-packages/livekit/agents/job.py\", line 274, in delete_room\n    self.api.room.delete_room(api.DeleteRoomRequest(room=self._room.name))\n                              ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\nTypeError: bad argument type for built-in operation\n```\n",
      "state": "closed",
      "author": "RikuKomiya",
      "author_type": "User",
      "created_at": "2025-04-26T09:53:55Z",
      "updated_at": "2025-04-27T06:23:40Z",
      "closed_at": "2025-04-27T06:23:39Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2134/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2134",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2134",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:22.760738",
      "comments": [
        {
          "author": "davidzhao",
          "body": "thank you for the report.. this is expected because console does not give you full access to a livekit room. testing the agent would be fine, but it'll not be possible to test room interactions",
          "created_at": "2025-04-27T06:23:40Z"
        }
      ]
    },
    {
      "issue_number": 1515,
      "title": "Eleven Labs Deprecated optimize_streaming_latency",
      "body": "ElevenLabs [Doc](https://elevenlabs.io/docs/api-reference/text-to-speech/convert-as-stream#request.query.optimize_streaming_latency)\n\n**[See Agents Plugin ElevenLabs TTS](https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-elevenlabs/livekit/plugins/elevenlabs/tts.py#L553)**\n\n\n```\nHey, did you see that optimize_streaming_latency from ElevenLabs is deprecated now?\n\noptimize_streaming_latency integer Optional Deprecated\n\nYou can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values: 0 - default mode (no latency optimizations) 1 - normal latency optimizations (about 50% of possible latency improvement of option 3) 2 - strong latency optimizations (about 75% of possible latency improvement of option 3) 3 - max latency optimizations 4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\n\nDefaults to None.\n\n```",
      "state": "closed",
      "author": "yepher",
      "author_type": "User",
      "created_at": "2025-02-18T16:24:40Z",
      "updated_at": "2025-04-27T00:16:39Z",
      "closed_at": "2025-04-27T00:16:39Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1515/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1515",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1515",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:22.988606",
      "comments": [
        {
          "author": "davidzhao",
          "body": "what is the right course of action here.. mark this argument deprecated?",
          "created_at": "2025-02-21T08:16:36Z"
        }
      ]
    },
    {
      "issue_number": 2040,
      "title": "Inconsistent transcript buffer behavior with start_turn / cancel_turn / end_turn flow (push-to-talk example)",
      "body": "First of all, thank you for the amazing work on livekit-agents — we’ve been building a new product using it and have found the project incredibly useful and thoughtfully designed.\n\nWe’re currently using the `push_to_talk.md` example as the basis for our client integration. However, we’re encountering an issue with synchronizing the audio buffer across `start_turn`, `cancel_turn`, and `end_turn`. In particular, when users interact quickly (e.g., speaking immediately and cancelling early), the buffer state seems to get into an inconsistent state, which leads to unexpected transcripts being sent to the LLM.\n\n## Example scenario\nHere’s a simplified flow that demonstrates the issue:\n\n1. `start_turn()` is called\n2. User begins speaking: **“How are you today?”**\n3. `cancel_turn()` is called immediately (this calls `session.clear_user_turn()` internally)\n4. In the logs, we see:\n```sh\nlivekit.agents - received user transcript {\"user_transcript\": \"How are.\", ...}\n```\n5. `start_turn()` is called again (again calls `session.clear_user_turn()`)\n6. User says: **“My name is Wynn”**\n7. `end_turn()` is called\n8. In `on_user_turn_completed` method, the new_message is: **\"you today my\"**\n\nSo despite clearing the user turn twice, the transcript still contains parts of the previous utterance. This seems to happen especially when STT final transcripts arrive slightly after the cancel, leading to fragments from earlier input leaking into the final turn.\n\n\n### Additional questions\nIs there a best practice for handling this kind of flow?\nWe’d love to hear how others are dealing with this — whether there’s a canonical way to fully flush/reset the STT buffer or if additional manual logic is recommended on the app side.\n\nThanks again for the fantastic work on the agents — we really appreciate it :)",
      "state": "closed",
      "author": "well-balanced",
      "author_type": "User",
      "created_at": "2025-04-18T05:58:27Z",
      "updated_at": "2025-04-26T23:48:41Z",
      "closed_at": "2025-04-24T07:45:35Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2040/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "longcw"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2040",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2040",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:23.192686",
      "comments": [
        {
          "author": "longcw",
          "body": "Yeah I noticed this as well, if the user turn closed too fast right after the end of user speech, the STT may not return the final user transcription, causing two issues: 1) the transcription of this turn is not completed, 2) the rest text may be added to the next turn.\n\nBasically these [two methods",
          "created_at": "2025-04-18T06:15:44Z"
        },
        {
          "author": "well-balanced",
          "body": "So for now, is adding a short await `asyncio.sleep(...)` after `end_turn` the best workaround to make sure STT has enough time to flush? Just wanna make sure I’m not missing a better way.",
          "created_at": "2025-04-18T06:27:41Z"
        },
        {
          "author": "longcw",
          "body": "@well-balanced yeah please give it a try, add a small delay before disable the input audio (so STT gets the silent audio frame to indicate the user speech done) and end turn. I'll also investigate if there is a better solution.",
          "created_at": "2025-04-18T06:30:53Z"
        },
        {
          "author": "longcw",
          "body": "Btw this works better for OAI realtime model which has the explicit `commit_audio` and `clear_audio`.",
          "created_at": "2025-04-18T06:34:55Z"
        },
        {
          "author": "well-balanced",
          "body": "Thanks so much for the quick and thoughtful reply. I’ll try adding the small delay like you suggested and see how it goes. I might come back with more questions if I run into anything else.",
          "created_at": "2025-04-18T06:57:23Z"
        }
      ]
    },
    {
      "issue_number": 1527,
      "title": "Agent raise an exception when running inside a docker container",
      "body": "I am getting exception when running the demo frontend and demo backend (voice-pipeline), in specific when clicking the \"stop\" button, seconds later I see the shutdown sequence at the agent (backend) initialing but start throwing exceptions. IF i run the backend inside a docker container. My system is an apple m4 pro, macOS: sequoia 15.3. Regarding livekit version, using whatever the `lk app create..` provides.\n\nIF I just run it locally(`python agent.py start`) I don't see this issue. Only when runs in the docker container.\n\nReproducing the issue as follows:\n\n``` console\nlk app create --template voice-pipeline-agent-python demo-agent\n```\n\nI just changed the STT and TTS providers to openai, and update the .env.local file.\n\nThen build a docker images using example from agent directory:\n``` docker\nARG PYTHON_VERSION=3.13.1\nFROM python:${PYTHON_VERSION}-slim\n\n# Prevents Python from writing pyc files.\nENV PYTHONDONTWRITEBYTECODE=1\n\n# Keeps Python from buffering stdout and stderr to avoid situations where\n# the application crashes without emitting any logs due to buffering.\nENV PYTHONUNBUFFERED=1\n\n# Create a non-privileged user that the app will run under.\n# See https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#user\nARG UID=10001\nRUN adduser \\\n    --disabled-password \\\n    --gecos \"\" \\\n    --home \"/home/appuser\" \\\n    --shell \"/sbin/nologin\" \\\n    --uid \"${UID}\" \\\n    appuser\n\n\n# Install gcc and other build dependencies.\nRUN apt-get update && \\\n    apt-get install -y \\\n    gcc \\\n    python3-dev \\\n    && rm -rf /var/lib/apt/lists/*\n\nUSER appuser\n\nRUN mkdir -p /home/appuser/.cache\nRUN chown -R appuser /home/appuser/.cache\n\nWORKDIR /home/appuser\n\nCOPY requirements.txt .\nRUN python -m pip install --user --no-cache-dir -r requirements.txt\n\nCOPY . .\n\n# ensure that any dependent models are downloaded at build-time\nRUN python agent.py download-files\n\n# Run the application.\nENTRYPOINT [\"python\", \"agent.py\"]\nCMD [\"start\"]\n```\n\nThen build the image as follows `docker build -t acme/agent:v1 .`, then run it `docker run -d --name agent-demo acme/agent:v1`\n\nWhen running the container everything works as expected until I stop the conversation, and get the following exceptions:\n``` text\n2025-02-19 19:30:49 agent-demo  | {\"message\": \"starting worker\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"version\": \"0.12.13\", \"rtc-version\": \"0.20.0\", \"timestamp\": \"2025-02-20T02:30:49.255647+00:00\"}\n2025-02-19 19:30:49 agent-demo  | {\"message\": \"starting inference executor\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"timestamp\": \"2025-02-20T02:30:49.255795+00:00\"}\n2025-02-19 19:30:49 agent-demo  | {\"message\": \"initializing inference process\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"pid\": 22, \"inference\": true, \"timestamp\": \"2025-02-20T02:30:49.806036+00:00\"}\n2025-02-19 19:30:49 agent-demo  | None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n2025-02-19 19:30:50 agent-demo  | {\"message\": \"inference process initialized\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"pid\": 22, \"inference\": true, \"timestamp\": \"2025-02-20T02:30:50.193868+00:00\"}\n2025-02-19 19:30:50 agent-demo  | {\"message\": \"registered worker\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"id\": \"AW_USGyABAeoRhx\", \"region\": \"US West\", \"protocol\": 15, \"node_id\": \"NC_OPHOENIX1A_vsdBVyM3E7eY\", \"timestamp\": \"2025-02-20T02:30:50.372122+00:00\"}\n2025-02-19 19:30:50 agent-demo  | {\"message\": \"initializing job process\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"pid\": 54, \"timestamp\": \"2025-02-20T02:30:50.731432+00:00\"}\n2025-02-19 19:30:50 agent-demo  | {\"message\": \"job process initialized\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"pid\": 54, \"timestamp\": \"2025-02-20T02:30:50.764179+00:00\"}\n2025-02-19 19:30:51 agent-demo  | {\"message\": \"initializing job process\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"pid\": 72, \"timestamp\": \"2025-02-20T02:30:51.309169+00:00\"}\n2025-02-19 19:30:51 agent-demo  | {\"message\": \"job process initialized\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"pid\": 72, \"timestamp\": \"2025-02-20T02:30:51.351240+00:00\"}\n2025-02-19 19:30:51 agent-demo  | {\"message\": \"initializing job process\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"pid\": 89, \"timestamp\": \"2025-02-20T02:30:51.870704+00:00\"}\n2025-02-19 19:30:51 agent-demo  | {\"message\": \"job process initialized\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"pid\": 89, \"timestamp\": \"2025-02-20T02:30:51.903042+00:00\"}\n2025-02-19 19:31:01 agent-demo  | {\"message\": \"received job request\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"job_id\": \"AJ_haBctHkGwZe5\", \"dispatch_id\": \"\", \"room_name\": \"kindred_room_LwW4GQDBQwTLMeEdLG2cqQ\", \"agent_name\": \"\", \"resuming\": false, \"timestamp\": \"2025-02-20T02:31:01.163569+00:00\"}\n2025-02-19 19:31:01 agent-demo  | {\"message\": \"connecting to room kindred_room_LwW4GQDBQwTLMeEdLG2cqQ\", \"level\": \"INFO\", \"name\": \"voice-agent\", \"pid\": 54, \"job_id\": \"AJ_haBctHkGwZe5\", \"timestamp\": \"2025-02-20T02:31:01.207427+00:00\"}\n2025-02-19 19:31:01 agent-demo  | {\"message\": \"livekit_ffi::server:134:livekit_ffi::server - initializing ffi server v0.12.10\", \"level\": \"INFO\", \"name\": \"livekit\", \"pid\": 54, \"job_id\": \"AJ_haBctHkGwZe5\", \"timestamp\": \"2025-02-20T02:31:01.211835+00:00\"}\n2025-02-19 19:31:01 agent-demo  | {\"message\": \"livekit_ffi::cabi:36:livekit_ffi::cabi - initializing ffi server v0.12.10\", \"level\": \"INFO\", \"name\": \"livekit\", \"pid\": 54, \"job_id\": \"AJ_haBctHkGwZe5\", \"timestamp\": \"2025-02-20T02:31:01.212021+00:00\"}\n2025-02-19 19:31:01 agent-demo  | {\"message\": \"livekit_api::signal_client::signal_stream:96:livekit_api::signal_client::signal_stream - connecting to wss://kindredpals-demo-playground-afgub1zx.livekit.cloud/rtc?sdk=python&protocol=15&auto_subscribe=0&adaptive_stream=0&version=0.20.0&access_token=...\", \"level\": \"INFO\", \"name\": \"livekit\", \"pid\": 54, \"job_id\": \"AJ_haBctHkGwZe5\", \"timestamp\": \"2025-02-20T02:31:01.213749+00:00\"}\n2025-02-19 19:31:01 agent-demo  | {\"message\": \"starting voice assistant for participant kindred_user_LwW4GQDBQwTLMeEdLG2cqQ\", \"level\": \"INFO\", \"name\": \"voice-agent\", \"pid\": 54, \"job_id\": \"AJ_haBctHkGwZe5\", \"timestamp\": \"2025-02-20T02:31:01.726288+00:00\"}\n2025-02-19 19:31:01 agent-demo  | {\"message\": \"initializing job process\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"pid\": 106, \"timestamp\": \"2025-02-20T02:31:01.768723+00:00\"}\n2025-02-19 19:31:01 agent-demo  | {\"message\": \"job process initialized\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"pid\": 106, \"timestamp\": \"2025-02-20T02:31:01.815912+00:00\"}\n2025-02-19 19:31:03 agent-demo  | {\"message\": \"Pipeline TTS metrics: sequence_id=8c6a4d07c911, ttfb=1.20276662499964, audio_duration=1.53\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"pid\": 54, \"job_id\": \"AJ_haBctHkGwZe5\", \"timestamp\": \"2025-02-20T02:31:03.275300+00:00\"}\n2025-02-19 19:31:08 agent-demo  | {\"message\": \"Pipeline STT metrics: duration=1.46, audio_duration=1.94\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"pid\": 54, \"job_id\": \"AJ_haBctHkGwZe5\", \"timestamp\": \"2025-02-20T02:31:08.173689+00:00\"}\n2025-02-19 19:31:08 agent-demo  | {\"message\": \"Pipeline EOU metrics: sequence_id=a1506070d518, end_of_utterance_delay=2.02, transcription_delay=2.01\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"pid\": 54, \"job_id\": \"AJ_haBctHkGwZe5\", \"timestamp\": \"2025-02-20T02:31:08.188382+00:00\"}\n2025-02-19 19:31:08 agent-demo  | {\"message\": \"Pipeline LLM metrics: sequence_id=a1506070d518, ttft=0.46, input_tokens=83, output_tokens=18, tokens_per_second=26.29\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"pid\": 54, \"job_id\": \"AJ_haBctHkGwZe5\", \"timestamp\": \"2025-02-20T02:31:08.873443+00:00\"}\n2025-02-19 19:31:10 agent-demo  | {\"message\": \"Pipeline TTS metrics: sequence_id=a1506070d518, ttfb=0.9571056670029066, audio_duration=2.16\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"pid\": 54, \"job_id\": \"AJ_haBctHkGwZe5\", \"timestamp\": \"2025-02-20T02:31:10.452359+00:00\"}\n2025-02-19 19:31:11 agent-demo  | {\"message\": \"Pipeline TTS metrics: sequence_id=a1506070d518, ttfb=0.560859666999022, audio_duration=2.39\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"pid\": 54, \"job_id\": \"AJ_haBctHkGwZe5\", \"timestamp\": \"2025-02-20T02:31:11.404396+00:00\"}\n2025-02-19 19:31:23 agent-demo  | {\"message\": \"Pipeline STT metrics: duration=1.53, audio_duration=1.91\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"pid\": 54, \"job_id\": \"AJ_haBctHkGwZe5\", \"timestamp\": \"2025-02-20T02:31:23.117244+00:00\"}\n2025-02-19 19:31:23 agent-demo  | {\"message\": \"Pipeline EOU metrics: sequence_id=c55ff7d49ccc, end_of_utterance_delay=2.08, transcription_delay=2.07\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"pid\": 54, \"job_id\": \"AJ_haBctHkGwZe5\", \"timestamp\": \"2025-02-20T02:31:23.130841+00:00\"}\n2025-02-19 19:31:23 agent-demo  | {\"message\": \"Pipeline LLM metrics: sequence_id=c55ff7d49ccc, ttft=0.35, input_tokens=113, output_tokens=17, tokens_per_second=29.32\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"pid\": 54, \"job_id\": \"AJ_haBctHkGwZe5\", \"timestamp\": \"2025-02-20T02:31:23.711050+00:00\"}\n2025-02-19 19:31:28 agent-demo  | {\"message\": \"Pipeline TTS metrics: sequence_id=c55ff7d49ccc, ttfb=1.1495892089951667, audio_duration=2.65\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"pid\": 54, \"job_id\": \"AJ_haBctHkGwZe5\", \"timestamp\": \"2025-02-20T02:31:28.352008+00:00\"}\n2025-02-19 19:31:29 agent-demo  | {\"message\": \"Pipeline TTS metrics: sequence_id=c55ff7d49ccc, ttfb=0.9210307920002379, audio_duration=1.43\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"pid\": 54, \"job_id\": \"AJ_haBctHkGwZe5\", \"timestamp\": \"2025-02-20T02:31:29.568324+00:00\"}\n2025-02-19 19:31:35 agent-demo  | {\"message\": \"Pipeline STT metrics: duration=0.50, audio_duration=1.91\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"pid\": 54, \"job_id\": \"AJ_haBctHkGwZe5\", \"timestamp\": \"2025-02-20T02:31:35.693680+00:00\"}\n2025-02-19 19:31:35 agent-demo  | {\"message\": \"Pipeline EOU metrics: sequence_id=ded732d4f49c, end_of_utterance_delay=1.06, transcription_delay=1.05\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"pid\": 54, \"job_id\": \"AJ_haBctHkGwZe5\", \"timestamp\": \"2025-02-20T02:31:35.706855+00:00\"}\n2025-02-19 19:31:36 agent-demo  | {\"message\": \"Pipeline LLM metrics: sequence_id=ded732d4f49c, ttft=0.29, input_tokens=142, output_tokens=13, tokens_per_second=30.90\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"pid\": 54, \"job_id\": \"AJ_haBctHkGwZe5\", \"timestamp\": \"2025-02-20T02:31:36.127898+00:00\"}\n2025-02-19 19:31:37 agent-demo  | {\"message\": \"Pipeline TTS metrics: sequence_id=ded732d4f49c, ttfb=1.283880416995089, audio_duration=1.29\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"pid\": 54, \"job_id\": \"AJ_haBctHkGwZe5\", \"timestamp\": \"2025-02-20T02:31:37.763334+00:00\"}\n2025-02-19 19:31:39 agent-demo  | {\"message\": \"Pipeline TTS metrics: sequence_id=ded732d4f49c, ttfb=0.9039698759952444, audio_duration=1.26\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"pid\": 54, \"job_id\": \"AJ_haBctHkGwZe5\", \"timestamp\": \"2025-02-20T02:31:39.133848+00:00\"}\n2025-02-19 19:32:02 agent-demo  | {\"message\": \"process exiting\", \"level\": \"INFO\", \"name\": \"livekit.agents\", \"reason\": \"\", \"pid\": 54, \"job_id\": \"AJ_haBctHkGwZe5\", \"timestamp\": \"2025-02-20T02:32:02.791612+00:00\"}\n2025-02-19 19:32:02 agent-demo  | {\"message\": \"livekit::rtc_engine:446:livekit::rtc_engine - received session close: \\\"signal client closed: \\\\\\\"stream closed\\\\\\\"\\\" UnknownReason Resume\", \"level\": \"WARNING\", \"name\": \"livekit\", \"pid\": 54, \"job_id\": \"AJ_haBctHkGwZe5\", \"timestamp\": \"2025-02-20T02:32:02.789711+00:00\"}\n2025-02-19 19:32:02 agent-demo  | Exception ignored in: <coroutine object HumanInput._recognize_task at 0xffff489d1940>\n2025-02-19 19:32:02 agent-demo  | Traceback (most recent call last):\n2025-02-19 19:32:02 agent-demo  |   File \"/home/appuser/.local/lib/python3.13/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n2025-02-19 19:32:02 agent-demo  |     return await fn(*args, **kwargs)\n2025-02-19 19:32:02 agent-demo  |   File \"/home/appuser/.local/lib/python3.13/site-packages/livekit/agents/pipeline/human_input.py\", line 152, in _recognize_task\n2025-02-19 19:32:02 agent-demo  |     await utils.aio.gracefully_cancel(*tasks)\n2025-02-19 19:32:02 agent-demo  |   File \"/home/appuser/.local/lib/python3.13/site-packages/livekit/agents/utils/aio/__init__.py\", line 12, in gracefully_cancel\n2025-02-19 19:32:02 agent-demo  |     loop = asyncio.get_running_loop()\n2025-02-19 19:32:02 agent-demo  | RuntimeError: no running event loop\n2025-02-19 19:32:02 agent-demo  | Exception ignored in: <coroutine object RecognizeStream._main_task at 0xffff50ea7de0>\n2025-02-19 19:32:02 agent-demo  | Traceback (most recent call last):\n2025-02-19 19:32:02 agent-demo  |   File \"/home/appuser/.local/lib/python3.13/site-packages/livekit/agents/stt/stt.py\", line 219, in _main_task\n2025-02-19 19:32:02 agent-demo  |     return await self._run()\n2025-02-19 19:32:02 agent-demo  |   File \"/home/appuser/.local/lib/python3.13/site-packages/livekit/agents/stt/stream_adapter.py\", line 126, in _run\n2025-02-19 19:32:02 agent-demo  |     await utils.aio.gracefully_cancel(*tasks)\n2025-02-19 19:32:02 agent-demo  |   File \"/home/appuser/.local/lib/python3.13/site-packages/livekit/agents/utils/aio/__init__.py\", line 12, in gracefully_cancel\n2025-02-19 19:32:02 agent-demo  |     loop = asyncio.get_running_loop()\n2025-02-19 19:32:02 agent-demo  | RuntimeError: no running event loop\n```\n\nThen stops working.",
      "state": "closed",
      "author": "alejmrm",
      "author_type": "User",
      "created_at": "2025-02-20T03:02:08Z",
      "updated_at": "2025-04-26T18:49:57Z",
      "closed_at": "2025-04-26T18:49:56Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1527/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "longcw"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1527",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1527",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:23.407625",
      "comments": [
        {
          "author": "davidzhao",
          "body": "can you try using Python 3.12 as the base image?",
          "created_at": "2025-02-20T08:25:54Z"
        },
        {
          "author": "alejmrm",
          "body": "It is still failing with python version 3.12.9.\n\nI performed a small triage, I think it is the docker environment. Currently I have an agent(inside docker container) running in a linux host and seem to be working just fine. But locally (macOS + docker desktop) seem to be an issue with the asyncio li",
          "created_at": "2025-02-20T20:06:49Z"
        },
        {
          "author": "davidzhao",
          "body": "looks like it's seeing issues in aarch64. we should support that platform.. will take a look",
          "created_at": "2025-02-20T23:27:58Z"
        },
        {
          "author": "yepher",
          "body": "I think this is the same issue:\nhttps://github.com/livekit/agents/issues/1518\n\nalso reported by this user but only in his Docker image: [Slack](https://livekit-users.slack.com/archives/C07FY8WHGPM/p1739999379020419)\n\n",
          "created_at": "2025-02-20T23:43:46Z"
        },
        {
          "author": "alejmrm",
          "body": "Yeap. I am that guy. I just found a way to reproduce the issue so I decided to better track it here. 😊",
          "created_at": "2025-02-21T00:13:45Z"
        }
      ]
    },
    {
      "issue_number": 2135,
      "title": "Module does not exist but still being used",
      "body": "# ImportError: cannot import name 'transcription' from 'livekit.agents.utils'\n\nHello,\n\nI am encountering an issue when trying to import the `transcription` module from `livekit.agents.utils`. The error message I receive is as follows:\n```\nImportError: cannot import name 'transcription' from 'livekit.agents.utils'\n```\n\nThis seems to be related to recent changes in the codebase, similar to issue #324 where `AssistantContext` was renamed to `AssistantCallContext`.\n\nI have checked the latest release, which is still at version 0.7.2, and I am wondering if there is a new release planned that would include these updates. As I am new to the Python ecosystem, I might be missing something, so any guidance would be appreciated.\n\nPlease let me know if you need any additional information from my side to help resolve this issue.\n\nThank you!",
      "state": "closed",
      "author": "mukund-rakholiya",
      "author_type": "User",
      "created_at": "2025-04-26T09:59:46Z",
      "updated_at": "2025-04-26T18:49:34Z",
      "closed_at": "2025-04-26T18:49:34Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2135/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2135",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2135",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:23.645859",
      "comments": [
        {
          "author": "longcw",
          "body": "There is agents 1.0 with breaking changes on the transcription module, you can upgrade your agents following https://docs.livekit.io/agents/start/v0-migration/ or set the version < 1.0",
          "created_at": "2025-04-26T10:12:38Z"
        }
      ]
    },
    {
      "issue_number": 2136,
      "title": "prompt_cache support in AWS Bedrock LLM",
      "body": "<!--\nHello! Thanks for taking the time to file a bug report.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already reported this issue.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n-->\nAWS Bedrock support prompt_cache as seen in https://docs.aws.amazon.com/bedrock/latest/userguide/prompt-caching.html and https://github.com/aws-samples/amazon-bedrock-samples/tree/main/introduction-to-bedrock/prompt-caching   \n\nI tried to support it locally but I found that `livekit` uses `aioboto3` which does not support prompt_cache\nbut this support is there in `boto3` since 1.37.24  , so unable to use it.\nWhat are the options available to support this? \n\n\n\n ",
      "state": "open",
      "author": "iRajul",
      "author_type": "User",
      "created_at": "2025-04-26T11:46:29Z",
      "updated_at": "2025-04-26T11:46:29Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2136/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2136",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2136",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:23.883819",
      "comments": []
    },
    {
      "issue_number": 2131,
      "title": "AgentSession's generate_reply method isn't flexible enough for outbound calls",
      "body": "In an outbound call, we need the agent to initiate the conversation with someone by following a specific system prompt. \n\nCurrently, AgentSession's generate_reply method does not enable the user to pass in a `llm.ChatMessage`, which would allow us to set this system message. The method takes in a string that's wrapped in a user message.\n\nAdditionally, the instructions parameter in generate_reply ends up overwriting the Agent's initial instructions through a `AgentActivity#_pipeline_reply_task` call to `update_instructions`. If we could provide temporary instructions to `generate_reply`, that would solve our issue as well. \n\nThis is the method that I'm currently using to wrap `Agent#generate_reply`:\n\n```python\n    async def generate_reply(self, instructions: str):\n        msg = ChatMessage(\n            role=\"system\",\n            content=[instructions],\n        )\n\n        await self.agent_session.interrupt()\n        resp = await self._activity.generate_reply(\n            user_message=msg,\n        )\n\n        return resp\n```",
      "state": "closed",
      "author": "DavidHuie",
      "author_type": "User",
      "created_at": "2025-04-25T16:12:16Z",
      "updated_at": "2025-04-26T06:16:38Z",
      "closed_at": "2025-04-25T19:58:25Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2131/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2131",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2131",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:23.883843",
      "comments": [
        {
          "author": "davidzhao",
          "body": "this is how it already works today.. see [docs](https://docs.livekit.io/agents/build/audio/#generate-reply)",
          "created_at": "2025-04-25T19:58:24Z"
        },
        {
          "author": "DavidHuie",
          "body": "@davidzhao the existing API you linked to takes in a string, which is wrapped in a user message. My example uses the private API to create a system message. The use cases are slightly different in that I want to be able to customize the exact generate_replay environment. Then there's also the issue ",
          "created_at": "2025-04-25T20:57:56Z"
        },
        {
          "author": "davidzhao",
          "body": "it's not wrapped in a user message.. if you read the implementation, it's sent as a system instruction at the beginning of the chat context.\n\nit does not *replace* the agent's instructions.. it would only do so for this turn, but does not cause side effects otherwise",
          "created_at": "2025-04-25T21:02:36Z"
        },
        {
          "author": "DavidHuie",
          "body": "@davidzhao am I looking at the wrong code? https://github.com/livekit/agents/blob/6449c2901b9e1c1c33b354b110c9fb0e19d3e094/livekit-agents/livekit/agents/voice/agent_session.py#L496",
          "created_at": "2025-04-25T23:35:35Z"
        },
        {
          "author": "davidzhao",
          "body": "check the next line\n\n```\nif is_given(user_input)\n```\n\nare you setting instructions or user_input?",
          "created_at": "2025-04-26T06:16:36Z"
        }
      ]
    },
    {
      "issue_number": 1988,
      "title": "OpenAI Realtime API audio cuts off intermittently before finishing playback",
      "body": "We observe that occasionally (once or many times in a 20 minute interval) when the OpenAI Realtime API in livekit responds with a long audio message, the audio cuts out before playback completes (but the transcript is complete). There is no interruption from VAD and we have seen this issue does NOT occur in OpenAI official playground (https://platform.openai.com/playground/realtime) suggesting it is a bug in LiveKit framework.\n\n\n**Reproducibility**\n\nWe can reproduce this issue with new livekit agents v1 and 0.12.18. We provide minimal examples based on the official templates \n\nhttps://github.com/moz164164/test_livekit_v1\nhttps://github.com/scoville/voc-livekit-multimodal-example/tree/main\n\n- To reproduce, ask the model to produce verbose responses and talk to it for at least 20 minutes, and always see this behaviour at least once, sometimes many times\n- We find the same behaviour with livekit whether we use OpenAI provider in livekit, or the Azure flavour of the Realtime API in livekit\n- Importantly we do not observe this behaviour directly when using https://platform.openai.com/playground/realtime suggesting that is a bug in the event handling client side\n- We do not see anything unusual in the logs like errors or warning when this occurs, and we do not see any interrupt: True in the logs, so it is not a VAD issue.\n\n- Video of the issue can be found [here](https://livekit-users.slack.com/archives/C07FY8WHGPM/p1744342624375929?thread_ts=1744100031.837599&cid=C07FY8WHGPM) on relevant slack thread in LiveKit Slack community at  9 mins 42 seconds \n\nAnother user has reported the same issue here: https://livekit-users.slack.com/archives/C0816MD6LCR/p1742425382392459\n\n\n**Potential Explanation**\n\n- We have searched for similar reports, and maybe the most promising lead we have found so far as to a possible explanation is here: https://community.openai.com/t/sharing-experiences-about-realtime-in-the-backend/1107471\n\n> After you finish speaking, you send a response.create request, then the AI ​​sends audio fragments via several response.audio.delta events and sends a response.audio.done event when it finishes. You then play each audio delta and stop the speakers when a finished audio arrives. Because handling audio deltas takes longer, it is necessary to give a small delay before stopping the speakers. This solved the problem I was experiencing.\n\nCould it be in the current livekit code that the client code prematurely sends a response.audio.done before we have guaranteed all response.audio.delta have been played out the speakers to the user?\n\ni.e. in that post they suggest\n\n```\n        // Event handler for the end of an audio response\n        realtime.onEvent(ServerEvent.ResponseAudioDone.class, event -> {\n            delay(1000); // Short delay to ensure all audio is received\n            sound.speaker.stop(); // Stop playback\n            sound.speaker.drain(); // Flush any remaining audio\n        });\n```\nI would be grateful if you could ask a member of the dev team familiar with the livekit openai realtime API client to review this and see if that may be the bug that is occurring here :bow:",
      "state": "open",
      "author": "bml1g12",
      "author_type": "User",
      "created_at": "2025-04-14T07:44:02Z",
      "updated_at": "2025-04-25T09:25:15Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 14,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1988/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1988",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1988",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:24.130588",
      "comments": [
        {
          "author": "yepher",
          "body": "Related slack thread:\n* https://livekit-users.slack.com/archives/C07FY8WHGPM/p1744616668037189?thread_ts=1744100031.837599&cid=C07FY8WHGPM\n* https://livekit-users.slack.com/archives/C0816MD6LCR/p1742425382392459\n",
          "created_at": "2025-04-14T17:00:28Z"
        },
        {
          "author": "yepher",
          "body": "This seems to be an issue from OpenAI’s side \nhttps://community.openai.com/t/realtime-api-audio-is-randomly-cutting-off-at-the-end/980587/82",
          "created_at": "2025-04-15T12:39:15Z"
        },
        {
          "author": "bml1g12",
          "body": "@yepher  I have read through that thread carefully but I have to admit I do not come to the same conclusion, although I see why you would say that. Please let me explain:\n\n- The specific post you link to refers to a possibly unrelated issue which according to OpenAI team has [been resolved ](https:/",
          "created_at": "2025-04-16T05:29:50Z"
        },
        {
          "author": "yuyuma",
          "body": "FWIW I've seen OpenAI acknowledge this issue here https://news.ycombinator.com/item?id=43429295\n\nBased on the response I wouldn't expect these issues to be resolved until a GA release. ",
          "created_at": "2025-04-16T06:08:25Z"
        },
        {
          "author": "longcw",
          "body": "@bml1g12 Can you try this example https://github.com/livekit/agents/blob/main/examples/voice_agents/realtime_turn_detector.py which disables the server side turn detection and uses livekit's semantic turn detection model. You can even disable the interruption with `allow_interruptions=False`. \n\nI am",
          "created_at": "2025-04-16T06:19:41Z"
        }
      ]
    },
    {
      "issue_number": 2117,
      "title": "Is it possible to display agent transcript in sync with audio (instead of waiting for full transcription)?",
      "body": "Hi LiveKit team,\n\nI’m working with LiveKit Agent and would like to display the agent’s transcript text in real time, synchronized with the audio, as the agent is speaking.\n\nI’ve tried listening to the conversation_item_added event, but it seems that this event only fires after the entire agent response (both audio and text) is completed. This results in the text being shown all at once, rather than incrementally.\n\nIs there a way to receive partial transcript updates or otherwise display the agent’s spoken response dynamically, in sync with the audio?\n\nAny guidance would be greatly appreciated!\n\nThanks in advance 🙌\n",
      "state": "open",
      "author": "marcinjackowski",
      "author_type": "User",
      "created_at": "2025-04-24T22:42:57Z",
      "updated_at": "2025-04-25T07:35:40Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2117/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2117",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2117",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:24.465341",
      "comments": [
        {
          "author": "longcw",
          "body": "check the [document here](https://docs.livekit.io/agents/build/text/#transcriptions) for the audio synchronized transcription.",
          "created_at": "2025-04-25T01:57:13Z"
        },
        {
          "author": "marcinjackowski",
          "body": "Thanks for the quick response! I really appreciate it! Unfortunately, I still don’t have the answer I’m looking for.\n\nWhat I’d like to achieve is getting real-time text on the backend side (agent), not on the frontend. On the frontend, I know it’s straightforward to print synchronized text as audio ",
          "created_at": "2025-04-25T05:26:34Z"
        },
        {
          "author": "longcw",
          "body": "If you really want to get that on the agent side, for now you can define a custom `TextOutput` and inject it into the room io\n```python\nfrom livekit.agents.voice.io import TextOutput\n\n\nclass MyTextOutput(TextOutput):\n    def __init__(self, *, next_in_chain: TextOutput | None = None) -> None:\n       ",
          "created_at": "2025-04-25T07:35:39Z"
        }
      ]
    },
    {
      "issue_number": 2053,
      "title": "TTS response_format PCM is not working",
      "body": "I am using livekit 1.0.13 with OpenAI TTS.\nI hosted my own Kokoro-TTS and used it with OpenAI TTS like below,\n\n```\n tts=openai.TTS(\n            base_url=\"http://localhost:8880/v1\",\n            model=\"kokoro\",\n            voice=\"af_sky\",\n            response_format=\"pcm\",\n            speed=1.1,\n        ),\n```\n\nI am facing an issue when using `pcm` response_format; other `wav` and `mp3` are working fine. \nBy investigating, I found an issue in  `AudioStreamDecoder's _decode_loop` method. It used `av` and as pcm is raw format, its throwing error like  `Invalid data found when processing input: `\n",
      "state": "open",
      "author": "cp-sumi-k",
      "author_type": "User",
      "created_at": "2025-04-21T09:03:42Z",
      "updated_at": "2025-04-25T05:16:18Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2053/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2053",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2053",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:24.745477",
      "comments": [
        {
          "author": "prd-tuong-nguyen",
          "body": "I encountered the same problem. I think the issue is with the `OpenAI TTS` server. The live kit works fine with the official OpenAI API.",
          "created_at": "2025-04-25T05:14:06Z"
        }
      ]
    },
    {
      "issue_number": 2120,
      "title": "Debug",
      "body": "<!--\nHello! Thanks for taking the time to file a bug report.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already reported this issue.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n-->\n",
      "state": "closed",
      "author": "OscaeGTX",
      "author_type": "User",
      "created_at": "2025-04-25T04:40:56Z",
      "updated_at": "2025-04-25T04:43:26Z",
      "closed_at": "2025-04-25T04:43:26Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2120/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2120",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2120",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:25.022570",
      "comments": []
    },
    {
      "issue_number": 2088,
      "title": "Google realtime issue regating agent handover",
      "body": "```\nfrom utils import load_prompt\nfrom dotenv import load_dotenv\n\nfrom livekit import agents\nfrom livekit.agents import AgentSession, Agent, RoomInputOptions, function_tool , ChatContext\nfrom livekit.plugins import (\n    openai,\n    noise_cancellation,\n    google\n)\nfrom openai.types.beta.realtime.session import TurnDetection\n\nload_dotenv()\n\n\nadmissions_prompt = load_prompt(\"admissions_agent_prompt.yaml\")\n\n\n\n\nclass AdmissionsAgent(Agent,):\n    def __init__(self, chat_ctx: ChatContext) -> None:\n        super().__init__(instructions=admissions_prompt,chat_ctx=chat_ctx)\n\n    async def on_enter(self):\n        print(\"Admissions Agent entered\")\n        await self.session.generate_reply(\n            instructions=admissions_prompt\n        )\n\n\nclass UniversityAgent(Agent):\n    def __init__(self) -> None:\n        super().__init__(instructions=load_prompt(\"university_agent_prompt.yaml\")) # Assuming a new prompt file for the main agent\n\n    async def on_enter(self):\n        print(\"University Agent entered\")\n        self.session.generate_reply(\n            instructions=\"Greet every user with exactly “Namaste! How may i help you” and then wait for their query.\"\n        )\n\n    @function_tool(\n        name=\"handoff_to_admissions\",\n        description=\"Handoff the conversation to the Admissions Department agent.\"\n    )\n    async def handoff_to_admissions(self):\n        print(\"Handoff to Admissions Agent\")\n        return await AdmissionsAgent(chat_ctx=self.chat_ctx)\n\n\nasync def entrypoint(ctx: agents.JobContext):\n    await ctx.connect()\n\n    session = AgentSession(\n        llm= google.beta.realtime.RealtimeModel(),\n    )\n\n    await session.start(\n        room=ctx.room,\n        agent=UniversityAgent(), # Use the new UniversityAgent\n        room_input_options=RoomInputOptions(\n            noise_cancellation=noise_cancellation.BVC(),\n        ),\n    )\n\n\nif __name__ == \"__main__\":\n    agents.cli.run_app(agents.WorkerOptions(entrypoint_fnc=entrypoint))\n```\n\n\n```\n2025-04-23 11:21:24,785 - DEBUG asyncio - Using selector: KqueueSelector \n==================================================\n     Livekit Agents - Console\n==================================================\nPress [Ctrl+B] to toggle between Text/Audio mode, [Q] to quit.\n\n2025-04-23 11:21:24,785 - INFO livekit.agents - starting worker {\"version\": \"1.0.15\", \"rtc-version\": \"1.0.6\"}\n2025-04-23 11:21:24,787 - INFO livekit.agents - see tracing information at http://localhost:56310/debug \n2025-04-23 11:21:24,788 - INFO livekit.agents - initializing job runner {\"tid\": 14396288}\n2025-04-23 11:21:24,788 - INFO livekit.agents - job runner initialized {\"tid\": 14396288}\n2025-04-23 11:21:24,788 - DEBUG asyncio - Using selector: KqueueSelector \nUniversity Agent entered\n2025-04-23 11:21:26,031 - INFO google_genai.live - b'{\\n  \"setupComplete\": {}\\n}\\n' \n2025-04-23 11:21:29,108 - INFO livekit.plugins.google - Usage metadata {\"usage_metadata\": \"prompt_token_count=751 cached_content_token_count=None response_token_count=59 tool_use_prompt_token_count=None thoughts_token_count=None total_token_count=810 prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=751)] cache_tokens_details=None response_tokens_details=[ModalityTokenCount(modality=<MediaModality.AUDIO: 'AUDIO'>, token_count=59)] tool_use_prompt_tokens_details=None traffic_type=None\"}\n2025-04-23 11:21:42,310 - INFO livekit.plugins.google - Usage metadata {\"usage_metadata\": \"prompt_token_count=904 cached_content_token_count=None response_token_count=188 tool_use_prompt_token_count=None thoughts_token_count=None total_token_count=1092 prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.AUDIO: 'AUDIO'>, token_count=91), ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=813)] cache_tokens_details=None response_tokens_details=[ModalityTokenCount(modality=<MediaModality.AUDIO: 'AUDIO'>, token_count=188)] tool_use_prompt_tokens_details=None traffic_type=None\"}\n2025-04-23 11:22:01,996 - INFO livekit.plugins.google - Usage metadata {\"usage_metadata\": \"prompt_token_count=1342 cached_content_token_count=None response_token_count=233 tool_use_prompt_token_count=None thoughts_token_count=None total_token_count=1575 prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.AUDIO: 'AUDIO'>, token_count=294), ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=1048)] cache_tokens_details=None response_tokens_details=[ModalityTokenCount(modality=<MediaModality.AUDIO: 'AUDIO'>, token_count=233)] tool_use_prompt_tokens_details=None traffic_type=None\"}\n2025-04-23 11:22:14,461 - INFO livekit.plugins.google - Usage metadata {\"usage_metadata\": \"prompt_token_count=1460 cached_content_token_count=None response_token_count=232 tool_use_prompt_token_count=None thoughts_token_count=None total_token_count=1692 prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.AUDIO: 'AUDIO'>, token_count=36), ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=1424)] cache_tokens_details=None response_tokens_details=[ModalityTokenCount(modality=<MediaModality.AUDIO: 'AUDIO'>, token_count=232)] tool_use_prompt_tokens_details=None traffic_type=None\"}\n2025-04-23 11:22:18,302 - DEBUG livekit.agents - executing tool {\"function\": \"handoff_to_admissions\", \"arguments\": \"{}\", \"speech_id\": \"speech_cdb1d9871c9d\"}\n2025-04-23 11:22:18,303 - DEBUG livekit.agents - tools execution completed {\"speech_id\": \"speech_cdb1d9871c9d\"}\n2025-04-23 11:22:18,403 - ERROR livekit.agents - Error in _forward_audio_task \nTraceback (most recent call last):\n  File \"/Users/recro/Documents/Voice_agent_1.0/env/lib/python3.11/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/recro/Documents/Voice_agent_1.0/env/lib/python3.11/site-packages/livekit/agents/voice/agent_session.py\", line 480, in _forward_audio_task\n    self._activity.push_audio(frame)\n  File \"/Users/recro/Documents/Voice_agent_1.0/env/lib/python3.11/site-packages/livekit/agents/voice/agent_activity.py\", line 408, in push_audio\n    self._rt_session.push_audio(frame)\n  File \"/Users/recro/Documents/Voice_agent_1.0/env/lib/python3.11/site-packages/livekit/plugins/google/beta/realtime/realtime_api.py\", line 322, in push_audio\n    self.push_media(frame.data.tobytes(), \"audio/pcm\")\n  File \"/Users/recro/Documents/Voice_agent_1.0/env/lib/python3.11/site-packages/livekit/plugins/google/beta/realtime/realtime_api.py\", line 332, in push_media\n    self._msg_ch.send_nowait(realtime_input)\n  File \"/Users/recro/Documents/Voice_agent_1.0/env/lib/python3.11/site-packages/livekit/agents/utils/aio/channel.py\", line 95, in send_nowait\n    raise ChanClosed\nlivekit.agents.utils.aio.channel.ChanClosed\n[Audio] cBook Pro Microphone [-67.55 dBFS] [#-----------------------------]Admissions Agent entered\n2025-04-23 11:22:29,438 - INFO google_genai.live - b'{\\n  \"setupComplete\": {}\\n}\\n' \n2025-04-23 11:22:32,796 - INFO livekit.plugins.google - Usage metadata {\"usage_metadata\": \"prompt_token_count=514 cached_content_token_count=None response_token_count=67 tool_use_prompt_token_count=None thoughts_token_count=None total_token_count=581 prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=514)] cache_tokens_details=None response_tokens_details=[ModalityTokenCount(modality=<MediaModality.AUDIO: 'AUDIO'>, token_count=67)] tool_use_prompt_tokens_details=None traffic_type=None\"}\n2025-04-23 11:22:36,162 - INFO livekit.agents - shutting down worker {\"id\": \"unregistered\"}\n2025-04-23 11:22:36,163 - DEBUG livekit.agents - shutting down job task {\"reason\": \"\", \"user_initiated\": false}\n2025-04-23 11:22:36,164 - DEBUG livekit.agents - http_session(): closing the httpclient ctx \n2025-04-23 11:22:36,165 - DEBUG livekit.agents - http_session(): creating a new httpclient ctx \n2025-04-23 11:22:36,165 - DEBUG livekit.agents - job exiting {\"reason\": \"\", \"tid\": 14396288, \"job_id\": \"simulated-job-bc6593a60a82\"}\n\n\n```\n\n\nwhen i am trying to hand over to another admisson agent its give this type of error ",
      "state": "closed",
      "author": "Manish06097",
      "author_type": "User",
      "created_at": "2025-04-23T05:58:16Z",
      "updated_at": "2025-04-25T03:52:22Z",
      "closed_at": "2025-04-25T03:52:10Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2088/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "jayeshp19"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2088",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2088",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:25.022593",
      "comments": [
        {
          "author": "jayeshp19",
          "body": "This is fixed in latest version, Thanks for raising :)",
          "created_at": "2025-04-25T03:52:10Z"
        }
      ]
    },
    {
      "issue_number": 2114,
      "title": "How do I use my custom OPENAI fine-tuned model get this error does not exist or you do not have access to it.",
      "body": "Hello, i trained myself a custom GPT-4.1 model and am using the API key that is used but have this issue below.\n\nlivekit.agents._exceptions.APIStatusError: Error code: 404 - {'error': {'message': 'The model `ft:gpt-4.1-2025-04-14:themindexpansionnetwork:skalgrimr:BPsmyr4l` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}} (status_code=404, request_id=req_447cb50ddbbe9133732f56daae98c1fb, body={'message': 'The model `ft:gpt-4.1-2025-04-14:themindexpansionnetwork:skalgrimr:BPsmyr4l` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'})\n\nThe playground works just fine I also look at my models with this\n\ncurl https://api.openai.com/v1/models \\\n  -H \"Authorization: Bearer MY-API-KEY\"\n\nIt shows the model also with the same key I am using.\n\nSorry, been trying to scratch my head, need a break but it should be working\n\nPlease let me know if you need any more infromation\n",
      "state": "open",
      "author": "TheMindExpansionNetwork",
      "author_type": "User",
      "created_at": "2025-04-24T19:10:40Z",
      "updated_at": "2025-04-24T19:10:40Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2114/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2114",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2114",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:25.256951",
      "comments": []
    },
    {
      "issue_number": 2109,
      "title": "CancelledError with Deepgram plugin when updating options (language specifically)",
      "body": "Hi,\n\nI have implemented the approach from this specific example in our own agent:\nhttps://github.com/livekit-examples/python-agents-examples/blob/main/pipeline-tts/elevenlabs_change_language.py\n\nWhen switching for the first time it happens correctly, but the second time and the times after that continuously raise the following error and switching doesn't work anymore:\n\n```\n2025-04-24 14:47:13,993 - ERROR asyncio - _GatheringFuture exception was never retrieved\nfuture: <_GatheringFuture finished exception=CancelledError()>\nTraceback (most recent call last):\n  File \"/Users/vv/vv/vv.voice.agent/venv/lib/python3.12/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/vv/v/vv.voice.agent/venv/lib/python3.12/site-packages/livekit/plugins/deepgram/stt.py\", line 495, in send_task\n    async for data in self._input_ch:\n  File \"/Users/vv/vv/vv.voice.agent/venv/lib/python3.12/site-packages/livekit/agents/utils/aio/channel.py\", line 176, in __anext__\n    return await self.recv()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/vv/vv/vv.voice.agent/venv/lib/python3.12/site-packages/livekit/agents/utils/aio/channel.py\", line 106, in recv\n    await g\nasyncio.exceptions.CancelledError {\"room\": \"call-room-_+32634566785_YysxxxxJSXmD\", \"user_id\": \"your user_id\", \"pid\": 15843, \"job_id\": \"AJ_AVrHexxxxAh\"}\n```\n\nAgent and plugins are on version 1.0.16. From what I see, this is very much related to the Deepgram plugin. Could that be the case?",
      "state": "open",
      "author": "vvv-001",
      "author_type": "User",
      "created_at": "2025-04-24T12:53:25Z",
      "updated_at": "2025-04-24T12:53:25Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2109/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2109",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2109",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:25.256975",
      "comments": []
    },
    {
      "issue_number": 2105,
      "title": "Unable to start Agent Session \"livekit.agents.utils.aio.duplex_unix.DuplexClosed\"",
      "body": "Starting any LiveKit agent session gives me this error after about a minute of hanging.\n\n```log\n2025-04-24 16:04:01,136 - ERROR livekit.agents - initialization timed out, killing process {\"pid\": 24908, \"inference\": true}\n2025-04-24 16:04:01,137 - INFO livekit.agents - killing process {\"pid\": 24908, \"inference\": true}\n2025-04-24 16:04:01,139 - ERROR livekit.agents - worker failed \n2025-04-24 15:57:15,354 - ERROR livekit.agents - Error in _read_ipc_task\nTraceback (most recent call last):\n  File \"D:\\Programming\\Work\\app\\backend\\.venv\\Lib\\site-packages\\livekit\\agents\\utils\\aio\\duplex_unix.py\", line 35, in recv_bytes\n    len_bytes = await self._reader.readexactly(4)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\User\\.pyenv\\pyenv-win\\versions\\3.11.7\\Lib\\asyncio\\streams.py\", line 745, in readexactly\n    raise exceptions.IncompleteReadError(incomplete, n)\nasyncio.exceptions.IncompleteReadError: 0 bytes read on a total of 4 expected bytes\n\nThe above exception was the direct cause of the following exception: \n\nTraceback (most recent call last):\n  File \"D:\\Programming\\Work\\app\\backend\\.venv\\Lib\\site-packages\\livekit\\agents\\utils\\log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Programming\\Work\\app\\backend\\.venv\\Lib\\site-packages\\livekit\\agents\\cli\\watcher.py\", line 120, in _read_ipc_task\n    msg = await channel.arecv_message(self._pch, proto.IPC_MESSAGES) \n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ \n  File \"D:\\Programming\\Work\\app\\backend\\.venv\\Lib\\site-packages\\livekit\\agents\\ipc\\channel.py\", line 47, in arecv_message\n    return _read_message(await dplx.recv_bytes(), messages)\n                         ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Programming\\Work\\app\\backend\\.venv\\Lib\\site-packages\\livekit\\agents\\utils\\aio\\duplex_unix.py\", line 43, in recv_bytes\n    raise DuplexClosed() from e\nlivekit.agents.utils.aio.duplex_unix.DuplexClosed\n```",
      "state": "open",
      "author": "Rickaym",
      "author_type": "User",
      "created_at": "2025-04-24T09:34:10Z",
      "updated_at": "2025-04-24T10:22:58Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2105/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2105",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2105",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:27.164651",
      "comments": [
        {
          "author": "Rickaym",
          "body": "It's apparently due to my internet connection speed.\n\nAfter changing the timeout of 30 seconds to something larger (hardcoding it livekit.agents.worker)\n```diff\n        self._inference_executor: ipc.inference_proc_executor.InferenceProcExecutor | None = None\n        if len(_InferenceRunner.registere",
          "created_at": "2025-04-24T10:22:46Z"
        },
        {
          "author": "Rickaym",
          "body": "Is there a chance this can be made into a configurable option?",
          "created_at": "2025-04-24T10:22:57Z"
        }
      ]
    },
    {
      "issue_number": 2094,
      "title": "Possible regression: duplicated full assistant transcript in Chat Context when interrupted",
      "body": "This is likely a regression in `livekit-agents` >= 1.0.14\n\n\nThe following is printed at the beginning of the chat function:\n\n```python\nfor item in chat_ctx.items:\n    if item.role not in (\"user\", \"assistant\"):\n        continue\n    print(item)\n```\n\nObserving duplicated messages\n```\nid='item_bac397280e97' type='message' role='user' content=['testing testing can you hear me'] interrupted=False hash=None\nid='item_21dc18363f0e' type='message' role='assistant' content=['Yeah, I hear you.\\n'] interrupted=False hash=None\nid='item_c09f76f76643' type='message' role='user' content=['is a test this is a test testing testing'] interrupted=False hash=None\nid='item_8158d506832f' type='message' role='user' content=['this is a test this is a test this is another test'] interrupted=False hash=None\nid='item_9ce2e74f19a3' type='message' role='assistant' content=['Yeah, I hear you.\\n'] interrupted=True hash=None\nid='item_bf99e3cebaa4' type='message' role='assistant' content=['Yeah, I hear you.\\n'] interrupted=True hash=None\nid='item_e1bec513f23d' type='message' role='user' content=['can you hear me can you hear me'] interrupted=False hash=None\nid='item_7d94e6d0e23e' type='message' role='assistant' content=['Yeah, I hear you.\\n'] interrupted=True hash=None\nid='item_f1088dd35cd7' type='message' role='user' content=['testing testing can you hear me'] interrupted=False hash=None\n```\n\nIt is repeating the last successful message `Yeah, I hear you` but I was expecting either:\n1. empty because of interruption\n2. something that's uniquely generated for that interaction even if interruption or sync fails\n\n<img width=\"322\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/7d1e3682-6220-468e-b11a-a71ffd13ff04\" />\n\n\n\nDowngrading `livekit-agents` to <1.0.14 seems to solve the issue:\n\n```\nid='item_f5629ea89c1b' type='message' role='user' content=['testing testing can you hear me'] interrupted=False hash=None\nid='item_81fc2432050a' type='message' role='assistant' content=['Yeah, I can hear you.\\n'] interrupted=False hash=None\nid='item_43e59fe8c920' type='message' role='user' content=['testing testing one two three four five'] interrupted=False hash=None\nid='item_fbc24237468e' type='message' role='assistant' content=[''] interrupted=True hash=None\nid='item_c88f7072795a' type='message' role='user' content=['this is a test can you hear me'] interrupted=False hash=None\nid='item_dbf83a08b626' type='message' role='assistant' content=[''] interrupted=True hash=None\nid='item_a154c1a84d77' type='message' role='user' content=['how about now one two three four five testing testing'] interrupted=False hash=None\nid='item_305a1a641981' type='message' role='assistant' content=[''] interrupted=True hash=None\nid='item_89c6b5e46be3' type='message' role='user' content=['this is a test'] interrupted=False hash=None\n```",
      "state": "closed",
      "author": "ChenghaoMou",
      "author_type": "User",
      "created_at": "2025-04-23T14:17:59Z",
      "updated_at": "2025-04-24T09:01:12Z",
      "closed_at": "2025-04-24T09:01:11Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2094/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2094",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2094",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:27.426069",
      "comments": [
        {
          "author": "longcw",
          "body": "probably related to this one https://github.com/livekit/agents/pull/2071? cc @theomonnom ",
          "created_at": "2025-04-23T15:31:54Z"
        },
        {
          "author": "longcw",
          "body": "oh, seems already have a fix https://github.com/livekit/agents/pull/2095",
          "created_at": "2025-04-23T15:33:20Z"
        },
        {
          "author": "longcw",
          "body": "fixed in https://github.com/livekit/agents/pull/2095",
          "created_at": "2025-04-24T09:01:11Z"
        }
      ]
    },
    {
      "issue_number": 2061,
      "title": "Turn detection in Gemini Realtime not working",
      "body": "Hi all, I'm using Gemini Realtime to build my agent. I'm noticing that my agent is not able to do turn_detection, and it's just interrupting me making it inefficient.\nI'm using the new RealtimeModel here; https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-google/livekit/plugins/google/beta/realtime/realtime_api.py\n\n\n```\nimport os\nimport yaml\nimport logging\nfrom pathlib import Path\nfrom dotenv import load_dotenv\nfrom livekit import api\nfrom livekit.agents import JobContext, WorkerOptions, cli\nfrom livekit.agents.llm import function_tool\nfrom livekit.agents.voice import Agent, AgentSession, RunContext\nfrom livekit.plugins import (\n    noise_cancellation\n    )\nfrom livekit.plugins.google.beta.realtime.realtime_api import RealtimeModel\n\nlogger = logging.getLogger(\"function-calling\")\nlogger.setLevel(logging.INFO)\n\n\nload_dotenv()\n\nclass FunctionAgent(Agent):\n    def __init__(self) -> None:\n        super().__init__(\n            instructions=\"\"\"\n                You are a helpful assistant communicating through voice.\n                Note: If asked to print to the console, use the `print_to_console` function.\n            \"\"\",\n            llm=RealtimeModel(\n            model= \"gemini-2.0-flash-exp\",\n            voice=\"Puck\",\n            temperature=0.8,\n            ),\n        )\n\n    @function_tool\n    async def print_to_console(self, context: RunContext):\n        print(\"Console Print Success!\")\n        return None, \"I've printed to the console.\"\n\n    async def on_enter(self):\n        self.session.generate_reply()\n\nasync def entrypoint(ctx: JobContext):\n    await ctx.connect()\n    session = AgentSession()\n    await session.start(\n        agent=FunctionAgent(),\n        room=ctx.room\n    )\n\nif __name__ == \"__main__\":\n    cli.run_app(WorkerOptions(entrypoint_fnc=entrypoint,))\n```\n\nWhen I run the agent and test in the playground, I see the agent just interrupting me before I have finished my thought which is not good. Please help me implement turn_Detection in Gemini Realtime @jayeshp19 ",
      "state": "closed",
      "author": "Kamal-Moha",
      "author_type": "User",
      "created_at": "2025-04-21T19:42:52Z",
      "updated_at": "2025-04-24T06:53:03Z",
      "closed_at": "2025-04-24T06:53:02Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2061/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "jayeshp19"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2061",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2061",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:27.644816",
      "comments": [
        {
          "author": "khantseithu",
          "body": "Having the same issue, with gemini realtime model, it works fine when I was in livekit 0.x version. Recently upgraded to v1 latest, turn detection for gemini realtime is completely broken. OpenAI realtime works fine for turn detection in v1. ",
          "created_at": "2025-04-22T05:01:36Z"
        },
        {
          "author": "davidzhao",
          "body": "we have a fix for this [here](https://github.com/livekit/agents/pull/2069). it'll be released in 1.0.14",
          "created_at": "2025-04-22T07:58:45Z"
        },
        {
          "author": "khantseithu",
          "body": "@davidzhao when will it be release?",
          "created_at": "2025-04-22T08:36:34Z"
        },
        {
          "author": "davidzhao",
          "body": "it's been released!",
          "created_at": "2025-04-24T06:53:02Z"
        }
      ]
    },
    {
      "issue_number": 2085,
      "title": "Support for force_end_utterance in AssemblyAI STT",
      "body": "It would be nice to be able to manually trigger the final transcript creation using `force_end_utterance` but this doesn't seem to be supported - is this something that could be added or is there a different solution that I should be using\n\nRelevant docs: https://www.assemblyai.com/docs/speech-to-text/streaming#manually-end-current-utterance",
      "state": "open",
      "author": "nathanmedz",
      "author_type": "User",
      "created_at": "2025-04-22T21:08:01Z",
      "updated_at": "2025-04-24T06:52:36Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2085/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2085",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2085",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:27.909394",
      "comments": [
        {
          "author": "davidzhao",
          "body": "do you mind sharing the use case that you have in mind? in what situations would it be useful to call this? there might be another way of accomplishing the same thing",
          "created_at": "2025-04-24T06:52:35Z"
        }
      ]
    },
    {
      "issue_number": 1063,
      "title": "Running agents with connect --room causes worker to receive sometimes two job requests instead of one",
      "body": "Hello! I am running simple livekit worker with command `python main.py connect --room tpapaj-room` (where `tpapaj-room` can be anything) using function\r\n```\r\nfrom livekit.agents import AutoSubscribe, JobContext, WorkerOptions, cli, llm\r\n(...)\r\n    cli.run_app(WorkerOptions(entrypoint_fnc=entrypoint))\r\n```\r\nwhere `entrypoint` is my function where I create `VoiceAssistant` etc.\r\n\r\nSometimes it works correctly and one job request is received:\r\n```\r\n2024-11-09 17:33:47,917 - INFO livekit.agents - starting worker {\"version\": \"0.10.1\", \"rtc-version\": \"0.18.0\"}\r\n2024-11-09 17:33:48,258 - INFO livekit.agents - registered worker {\"id\": \"AW_xxxWY4\", \"region\": \"Germany\", \"protocol\": 15, \"node_id\": \"NC_xxxF3R\"}\r\n2024-11-09 17:33:48,259 - INFO livekit.agents - connecting to room tpapaj-room \r\n2024-11-09 17:33:48,526 - INFO livekit.agents - received job request {\"job_id\": \"AJ_xxxiSW\", \"dispatch_id\": \"\", \"room_name\": \"tpapaj-room\", \"agent_name\": \"\", \"resuming\": false}\r\n```\r\n\r\nSometimes on startup worker receives two job requests:\r\n```\r\n2024-11-09 17:34:15,144 - INFO livekit.agents - starting worker {\"version\": \"0.10.1\", \"rtc-version\": \"0.18.0\"}\r\n2024-11-09 17:34:15,505 - INFO livekit.agents - registered worker {\"id\": \"AW_yxxxWiS\", \"region\": \"Germany\", \"protocol\": 15, \"node_id\": \"NC_xxx39j\"}\r\n2024-11-09 17:34:15,507 - INFO livekit.agents - connecting to room tpapaj-room \r\n2024-11-09 17:34:16,473 - INFO livekit.agents - received job request {\"job_id\": \"AJ_xxxvAt\", \"dispatch_id\": \"\", \"room_name\": \"tpapaj-room\", \"agent_name\": \"\", \"resuming\": false}\r\n2024-11-09 17:34:16,581 - INFO livekit.agents - received job request {\"job_id\": \"AJ_xxxPpE\", \"dispatch_id\": \"\", \"room_name\": \"tpapaj-room\", \"agent_name\": \"\", \"resuming\": false}\r\n```\r\nThis causes application to create two agents(entrypoint function is called twice) who then start talk to each other in a room. As you can see, received job requests have different ids(I masked parts of ids with `xxx` strings, just in case).\r\nIt looks like it has tendency to create two agents when `--room` argument uses a room name that was not used for a while and restarting the worker with the same room usually works correctly and creates a single agent.\r\n\r\nI expected to see just one job request being sent to the worker.\r\n\r\nIt seems to be similar issue to https://github.com/livekit/agents/issues/759 but it is claimed there that the problem was fixed, but I still see the problem.\r\nI tried livekit-agent versions 0.10.1, 0.10.2, 0.11.1 without success.\r\n\r\nCurrent livekit packages in `pip freeze`:\r\n```\r\nlivekit==0.18.0\r\nlivekit-agents==0.11.1\r\nlivekit-api==0.7.1\r\nlivekit-plugins-elevenlabs==0.7.7\r\nlivekit-plugins-openai==0.10.5\r\nlivekit-plugins-silero==0.7.3\r\nlivekit-protocol==0.6.0\r\n```\r\n",
      "state": "open",
      "author": "tpapaj",
      "author_type": "User",
      "created_at": "2024-11-09T20:40:56Z",
      "updated_at": "2025-04-23T21:57:35Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1063/reactions",
        "total_count": 5,
        "+1": 5,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1063",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1063",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:28.141671",
      "comments": [
        {
          "author": "ChenghaoMou",
          "body": "Also seeing the same issue.\r\n\r\nA workaround I found: filter requests with a custom `request_fnc`\r\n\r\n```python\r\nseen = set()\r\nasync def request_fnc(req: JobRequest):\r\n    if req.room.name != room_id or req.room.name in seen:\r\n        await req.reject()\r\n        return\r\n    seen.add(req.room.name)\r\n  ",
          "created_at": "2024-12-09T16:32:39Z"
        },
        {
          "author": "keenborder786",
          "body": "I am also facing the same bug, where for some reason when we perform explicit agent dispatch using `create_dispatch`, the running Worker starts two agent processes.",
          "created_at": "2025-01-17T14:41:22Z"
        },
        {
          "author": "socrait-cameron",
          "body": "FYI, we've also seen this one. We coded around it with an in-memory cache of job request id's similar to ChenghaoMou's solution above.",
          "created_at": "2025-04-23T21:57:34Z"
        }
      ]
    },
    {
      "issue_number": 1335,
      "title": "Multilingual Agent (STT and TTS); is that possible with LiveKit?",
      "body": "Hi,\r\n\r\nI recently started using LiveKit for building an Agent, so far I have been able to make it work with a simple RAG Example.\r\n\r\n```\r\n    stt_google = google.STT(\r\n        languages=[\"nl-NL\", \"en-US\"],\r\n        detect_language=True, interim_results=True)\r\n\r\n    stt_openai = openai.STT(detect_language=True)\r\n    language = stt_openai.\r\n\r\n    tts = google.TTS(language=\"nl-NL\", voice_name=\"nl-NL-Standard-C\")\r\n\r\n    agent = VoicePipelineAgent(\r\n        vad=ctx.proc.userdata[\"vad\"],\r\n        stt=stt_openai,\r\n        llm=openai.LLM(model=\"gpt-4o-mini\"),\r\n        tts=tts,\r\n        chat_ctx=initial_ctx,\r\n        turn_detector=turn_detector.EOUModel(),\r\n        will_synthesize_assistant_reply=will_synthesize_assistant_reply_rag,\r\n    )\r\n```\r\n\r\nThe scenario I am looking to implement is as follows (either using Google Speech or OpenAI Whisper): the user talks in a number of languages, English, Dutch, French, Spanish etc. Based on this I want to be able to get (detect) the spoken language by the user and set the language spoken by the Agent. Have been going through Slack and documentation, but am unable to find out how to best do this.\r\n\r\nAny pointers or tips and experiences are welcome. Thanks in adance.",
      "state": "open",
      "author": "vvv-001",
      "author_type": "User",
      "created_at": "2025-01-03T15:20:19Z",
      "updated_at": "2025-04-23T19:10:42Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 11,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1335/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1335",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1335",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:28.406617",
      "comments": [
        {
          "author": "aalkhulaifi605",
          "body": "I am having the same issue where when selecting two languages it only apply the last language code in the list and not detecting any other languages. I am using google STT:   \n```\n stt_google = google.STT(\n        languages=[\"es-MX\", \"en-US\"],\n        detect_language=True)\n\n```",
          "created_at": "2025-01-27T20:11:19Z"
        },
        {
          "author": "0xLoukman",
          "body": "Have you guys found any solitions for this ?",
          "created_at": "2025-03-20T18:07:10Z"
        },
        {
          "author": "aalkhulaifi605",
          "body": "> Have you guys found any solitions for this ?\n\nUnfortunately, no—I’m still searching for a solution.",
          "created_at": "2025-03-20T18:56:16Z"
        },
        {
          "author": "imsakg",
          "body": "You can achive that by using secondary STT like Whisper on Groq. I made some custamizations on [VoicePipelineAgent](https://github.com/livekit/agents/blob/6015e111eda63d0c9f33d594bf8366fdd3117461/livekit-agents/livekit/agents/pipeline/pipeline_agent.py#L598) by overriding it's `user_stopped_speaking",
          "created_at": "2025-03-21T12:49:43Z"
        },
        {
          "author": "vvv-001",
          "body": "@imsakg interesting, would this also work with other STT providers? Like Deepgram?\n\nSince Whisper by itself already detects language by default. So far we notice that the best STT model in languages other than English is Deepgram. The problem there is, that you need to define the STT model language ",
          "created_at": "2025-03-21T13:14:02Z"
        }
      ]
    },
    {
      "issue_number": 2082,
      "title": "azure tts or stt : WebSocket upgrade failed  (with westeurope endpoints)",
      "body": "on windows I used the latest versions of the packages (with >=0 ) installed on a clean fresh env \n\n`pip install \"livekit-agents[azure,openai,silero,turn-detector]>=0\"  \"python-dotenv\"`\n\nI got the latest versions (from today), 1.0.16 , for example:\n\n```\npip show livekit-plugins-azure\nName: livekit-plugins-azure\nVersion: 1.0.16\n...\npip show livekit-agents\nName: livekit-agents\nVersion: 1.0.16\n```\n\nwith a simple .env:\n\n```\nOPENAI_API_KEY=XXXX\nLIVEKIT_URL=wss://XXXX.livekit.cloud\nLIVEKIT_API_KEY=XXXX\nLIVEKIT_API_SECRET=XXXX\nAZURE_SPEECH_KEY=XXXX\nAZURE_SPEECH_HOST=https://westeurope.api.cognitive.microsoft.com/\n```\n\nthen I create a simple agent:\n\n```python\nfrom dotenv import load_dotenv\n\nfrom livekit import agents\nfrom livekit.agents import AgentSession, Agent, RoomInputOptions\nfrom livekit.plugins import (\n    openai,\n    azure,\n    silero,\n)\nfrom livekit.plugins.turn_detector.multilingual import MultilingualModel\n\nload_dotenv()\n\n\nclass Assistant(Agent):\n    def __init__(self) -> None:\n        super().__init__(instructions=\"You are a helpful voice AI assistant.\")\n\n\nasync def entrypoint(ctx: agents.JobContext):\n    await ctx.connect()\n\n    session = AgentSession(\n        stt=azure.STT(),\n        llm=openai.LLM(model=\"gpt-4o-mini\"),\n        tts=azure.TTS(),\n        vad=silero.VAD.load(),\n        turn_detection=MultilingualModel(),\n    )\n\n    await session.start(\n        room=ctx.room,\n        agent=Assistant(),\n    )\n\n    await session.generate_reply(\n        instructions=\"Greet the user and offer your assistance.\"\n    )\n\n\nif __name__ == \"__main__\":\n    agents.cli.run_app(agents.WorkerOptions(entrypoint_fnc=entrypoint))\n```\n\nand I get an WebSocket upgrade error:\n\n```\npython main.py console\n2025-04-22 22:18:40,924 - DEBUG asyncio - Using proactor: IocpProactor \n==================================================\n     Livekit Agents - Console\n==================================================\nPress [Ctrl+B] to toggle between Text/Audio mode, [Q] to quit.\n\n2025-04-22 22:18:40,924 - INFO livekit.agents - starting worker {\"version\": \"1.0.16\", \"rtc-version\": \"1.0.6\"}\n2025-04-22 22:18:40,924 - INFO livekit.agents - starting inference executor\n2025-04-22 22:18:42,027 - INFO livekit.agents - initializing inference process {\"pid\": 35380, \"inference\": true}\n2025-04-22 22:18:42,027 - DEBUG livekit.agents - initializing inference runner {\"runner\": \"lk_end_of_utterance_multilingual\", \"pid\": 35380, \"inference\": true}\nNone of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n2025-04-22 22:18:43,511 - INFO livekit.agents - inference process initialized {\"pid\": 35380, \"inference\": true}\n2025-04-22 22:18:43,511 - DEBUG asyncio - Using proactor: IocpProactor {\"pid\": 35380, \"inference\": true}\n2025-04-22 22:18:43,511 - INFO livekit.agents - see tracing information at http://localhost:58139/debug\n2025-04-22 22:18:43,511 - INFO livekit.agents - initializing job runner {\"tid\": 23000}\n2025-04-22 22:18:43,511 - INFO livekit.agents - job runner initialized {\"tid\": 23000}\n2025-04-22 22:18:43,511 - DEBUG asyncio - Using proactor: IocpProactor\n2025-04-22 22:18:45,682 - WARNING livekit.agents - failed to synthesize speech, retrying in 0.1s {\"tts\": \"livekit.plugins.azure.tts.TTS\", \"attempt\": 1, \"streamed\": false}\nTraceback (most recent call last):\n  File \"C:\\Users\\remis\\neocertif\\livekit-agent\\.venv\\Lib\\site-packages\\livekit\\agents\\tts\\tts.py\", line 203, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\remis\\neocertif\\livekit-agent\\.venv\\Lib\\site-packages\\livekit\\plugins\\azure\\tts.py\", line 371, in _run\n    raise APIConnectionError(cancel_details.error_details)\nlivekit.agents._exceptions.APIConnectionError: WebSocket upgrade failed: Internal service error (404). Error Details: Failed with HTTP 404 Resource Not Found\nwss://westeurope.api.cognitive.microsoft.com/cognitiveservices/websocket/v1\nX-ConnectionId: dd63ac2e75084906a33e18bd0dd66c8b\napim-request-id: 0dbd61fe-8e37-4541-9b62-80a93f60ee6d\nContent-Type: application/json\n{\"error\":{\"code\":\"404\",\"message\": \"Resource not found\"}} Please check request details. USP state: Sending. Received audio size: 0 bytes.\n2025-04-22 22:18:45,946 - WARNING livekit.agents - failed to synthesize speech, retrying in 2.0s {\"tts\": \"livekit.plugins.azure.tts.TTS\", \"attempt\": 2, \"streamed\": false}\nTraceback (most recent call last):\n  File \"C:\\Users\\remis\\neocertif\\livekit-agent\\.venv\\Lib\\site-packages\\livekit\\agents\\tts\\tts.py\", line 203, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\remis\\neocertif\\livekit-agent\\.venv\\Lib\\site-packages\\livekit\\plugins\\azure\\tts.py\", line 371, in _run\n    raise APIConnectionError(cancel_details.error_details)\nlivekit.agents._exceptions.APIConnectionError: WebSocket upgrade failed: Internal service error (404). Error Details: Failed with HTTP 404 Resource Not Found\nwss://westeurope.api.cognitive.microsoft.com/cognitiveservices/websocket/v1\nX-ConnectionId: 3da5ec37a8c84504aaf10938127f5c1a\napim-request-id: 5466cce9-6db1-4932-b265-98994c98a71a\nContent-Type: application/json\n{\"error\":{\"code\":\"404\",\"message\": \"Resource not found\"}} Please check request details. USP state: Sending. Received audio size: 0 bytes.\n2025-04-22 22:18:46,331 - WARNING livekit.agents - failed to recognize speech, retrying in 0.1s {\"tts\": \"livekit.plugins.azure.stt.STT\", \"attempt\": 0, \"streamed\": true}\nTraceback (most recent call last):\n  File \"C:\\Users\\remis\\neocertif\\livekit-agent\\.venv\\Lib\\site-packages\\livekit\\agents\\stt\\stt.py\", line 228, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\remis\\neocertif\\livekit-agent\\.venv\\Lib\\site-packages\\livekit\\plugins\\azure\\stt.py\", line 225, in _run\n    raise APIConnectionError(\"SpeechRecognition session stopped\")\nlivekit.agents._exceptions.APIConnectionError: SpeechRecognition session stopped\n2025-04-22 22:18:46,466 - WARNING livekit.agents - failed to recognize speech, retrying in 2.0s {\"tts\": \"livekit.plugins.azure.stt.STT\", \"attempt\": 1, \"streamed\": true}\nTraceback (most recent call last):\n  File \"C:\\Users\\remis\\neocertif\\livekit-agent\\.venv\\Lib\\site-packages\\livekit\\agents\\stt\\stt.py\", line 228, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\remis\\neocertif\\livekit-agent\\.venv\\Lib\\site-packages\\livekit\\plugins\\azure\\stt.py\", line 225, in _run\n    raise APIConnectionError(\"SpeechRecognition session stopped\")\nlivekit.agents._exceptions.APIConnectionError: SpeechRecognition session stopped\n2025-04-22 22:18:48,114 - WARNING livekit.agents - failed to synthesize speech, retrying in 2.0s {\"tts\": \"livekit.plugins.azure.tts.TTS\", \"attempt\": 3, \"streamed\": false}\nTraceback (most recent call last):\n  File \"C:\\Users\\remis\\neocertif\\livekit-agent\\.venv\\Lib\\site-packages\\livekit\\agents\\tts\\tts.py\", line 203, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\remis\\neocertif\\livekit-agent\\.venv\\Lib\\site-packages\\livekit\\plugins\\azure\\tts.py\", line 371, in _run\n    raise APIConnectionError(cancel_details.error_details)\nlivekit.agents._exceptions.APIConnectionError: WebSocket upgrade failed: Internal service error (404). Error Details: Failed with HTTP 404 Resource Not Found\nwss://westeurope.api.cognitive.microsoft.com/cognitiveservices/websocket/v1\nX-ConnectionId: b14588513fe647b0926eface78e5174c\napim-request-id: 0fb5951b-c573-49ab-9142-36e314d6bd6e\nContent-Type: application/json\n{\"error\":{\"code\":\"404\",\"message\": \"Resource not found\"}} Please check request details. USP state: Sending. Received audio size: 0 bytes.\n2025-04-22 22:19:01,285 - INFO livekit.agents - shutting down worker {\"id\": \"unregistered\"}\n2025-04-22 22:19:01,287 - DEBUG livekit.agents - shutting down job task {\"reason\": \"\", \"user_initiated\": false}\n2025-04-22 22:19:01,288 - DEBUG livekit.agents - http_session(): closing the httpclient ctx\n2025-04-22 22:19:01,288 - DEBUG livekit.agents - http_session(): creating a new httpclient ctx\n2025-04-22 22:19:01,288 - DEBUG livekit.agents - job exiting {\"reason\": \"\", \"tid\": 23000, \"job_id\": \"simulated-job-ff5d146d1332\"}\n2025-04-22 22:19:01,288 - INFO livekit.agents - process exiting {\"reason\": \"\", \"pid\": 35380, \"inference\": true}\n2025-04-22 22:19:01,523 - ERROR asyncio - Task exception was never retrieved\nfuture: <Task finished name='TTS._synthesize_task' coro=<ChunkedStream._main_task() done, defined at C:\\Users\\remis\\neocertif\\livekit-agent\\.venv\\Lib\\site-packages\\livekit\\agents\\tts\\tts.py:200> exception=APIConnectionError('failed to synthesize speech after 4 attempts')>\nTraceback (most recent call last):\n  File \"C:\\Users\\remis\\neocertif\\livekit-agent\\.venv\\Lib\\site-packages\\livekit\\agents\\tts\\tts.py\", line 203, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\remis\\neocertif\\livekit-agent\\.venv\\Lib\\site-packages\\livekit\\plugins\\azure\\tts.py\", line 371, in _run\n    raise APIConnectionError(cancel_details.error_details)\nlivekit.agents._exceptions.APIConnectionError: WebSocket upgrade failed: Internal service error (404). Error Details: Failed with HTTP 404 Resource Not Found\nwss://westeurope.api.cognitive.microsoft.com/cognitiveservices/websocket/v1\nX-ConnectionId: fd0f0934a0914d23a4350f2cbe40a350\napim-request-id: d0b4baf6-2e7b-4543-a547-5a37214e75fb\nContent-Type: application/json\n{\"error\":{\"code\":\"404\",\"message\": \"Resource not found\"}} Please check request details. USP state: Sending. Received audio size: 0 bytes.\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\remis\\neocertif\\livekit-agent\\.venv\\Lib\\site-packages\\livekit\\agents\\tts\\tts.py\", line 211, in _main_task\n    raise APIConnectionError(\nlivekit.agents._exceptions.APIConnectionError: failed to synthesize speech after 4 attempts\n```",
      "state": "open",
      "author": "remisharrock",
      "author_type": "User",
      "created_at": "2025-04-22T20:22:53Z",
      "updated_at": "2025-04-23T16:51:25Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2082/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2082",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2082",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:28.776122",
      "comments": [
        {
          "author": "remisharrock",
          "body": "@theomonnom salut (à paris aussi ?); \n@jayeshp19 hi;\ncould it be related to : \nhttps://github.com/livekit/agents/pull/2008 ",
          "created_at": "2025-04-22T20:41:19Z"
        },
        {
          "author": "remisharrock",
          "body": "by the way I found something interesting 401 and 404!\n\n```\n curl wss://westeurope.tts.speech.microsoft.com/cognitiveservices/websocket/v1\ncurl: (22) Refused WebSockets upgrade: 401\n curl wss://westeurope.api.cognitive.microsoft.com/cognitiveservices/websocket/v1\ncurl: (22) Refused WebSockets upgrade",
          "created_at": "2025-04-22T20:58:36Z"
        },
        {
          "author": "jayeshp19",
          "body": "It says `{\"error\":{\"code\":\"404\",\"message\": \"Resource not found\"}} Please check request details. `\nplease check if you're using correct credentials",
          "created_at": "2025-04-23T05:09:23Z"
        },
        {
          "author": "remisharrock",
          "body": "dear @jayeshp19 I'm using the correct credentials (it works with many other services like livekit or ten agent etc) and indeed I think the websocket upgrade fails because the URL mentioned in the log is not the good one:\n\nwss://westeurope.api.cognitive.microsoft.com/cognitiveservices/websocket/v1 is",
          "created_at": "2025-04-23T16:29:57Z"
        },
        {
          "author": "remisharrock",
          "body": "and the error line says: \n\nlivekit.agents._exceptions.APIConnectionError: WebSocket upgrade failed: Internal service error (404). Error Details: Failed with HTTP 404 Resource Not Found\nwss://westeurope.api.cognitive.microsoft.com/cognitiveservices/websocket/v1\n\ndo you think I can try the two files i",
          "created_at": "2025-04-23T16:40:51Z"
        }
      ]
    },
    {
      "issue_number": 2084,
      "title": "Agent cannot hear participant for Outbound SIP call in 1.0",
      "body": "Hi, thanks for all the work for 1.0, the new APIs are great. I am noticing a bug that's preventing us from upgrading though.\n\nFor some reason when we do an outbound SIP call from our agent, the call itself works fine, my phone rings and I can pick it up, but then the agent never hears anything for this participant.\n\nInterestingly, if I make some change causing an agent reload, it hangs up the call and then calls me again, and in that second call everything works perfectly normally. But consistently if I just start up the agent and then dispatch it, it cannot hear me. \n\nI am able to recreate this with the [outbound calling example](https://github.com/livekit-examples/outbound-caller-python/blob/main/agent.py). I stripped it down to just the most basic possible, and the issue still occurs with this agent on 1.0.15:\n\n```python\nfrom __future__ import annotations\n\nimport asyncio\nimport logging\n\nfrom livekit import api\nfrom livekit.agents import (\n    Agent,\n    AgentSession,\n    JobContext,\n    WorkerOptions,\n    cli,\n)\nfrom livekit.plugins import (\n    cartesia,\n    deepgram,\n    openai,\n    silero,\n)\n\nlogger = logging.getLogger(\"outbound-caller\")\nlogger.setLevel(logging.INFO)\n\noutbound_trunk_id = \"<my trunk id>\"\nphone = \"<my phone number>\"\n\n\nclass OutboundCaller(Agent):\n    def __init__(\n        self,\n        *,\n        name: str,\n        appointment_time: str,\n    ):\n        super().__init__(\n            instructions=f\"\"\"\n            You are a scheduling assistant for a dental practice. Your interface with user will be voice.\n            You will be on a call with a patient who has an upcoming appointment. Your goal is to confirm the appointment details.\n            As a customer service representative, you will be polite and professional at all times. Allow user to end the conversation.\n\n            When the user would like to be transferred to a human agent, first confirm with them. upon confirmation, use the transfer_call tool.\n            The customer's name is {name}. His appointment is on {appointment_time}.\n            \"\"\"\n        )\n\n\nasync def entrypoint(ctx: JobContext):\n    logger.info(f\"connecting to room {ctx.room.name}\")\n    await ctx.connect()\n\n    agent = OutboundCaller(\n        name=\"Jayden\",\n        appointment_time=\"next Tuesday at 3pm\",\n    )\n\n    session = AgentSession(\n        vad=silero.VAD.load(),\n        stt=deepgram.STT(),\n        tts=cartesia.TTS(),\n        llm=openai.LLM(model=\"gpt-4o\"),\n    )\n\n    asyncio.create_task(\n        session.start(\n            agent=agent,\n            room=ctx.room,\n        )\n    )\n\n    try:\n        await ctx.api.sip.create_sip_participant(\n            api.CreateSIPParticipantRequest(\n                room_name=ctx.room.name,\n                sip_trunk_id=outbound_trunk_id,\n                sip_call_to=phone,\n                participant_identity=phone,\n            )\n        )\n\n        await ctx.wait_for_participant(identity=phone)\n\n    except api.TwirpError as e:\n        logger.error(\n            f\"error creating SIP participant: {e.message}, \"\n            + f\"SIP status: {e.metadata.get('sip_status_code')} \"\n            + f\"{e.metadata.get('sip_status')}\"\n        )\n        ctx.shutdown()\n\n\nif __name__ == \"__main__\":\n    cli.run_app(\n        WorkerOptions(\n            entrypoint_fnc=entrypoint,\n            agent_name=\"outbound-caller\",\n        )\n    )\n```",
      "state": "closed",
      "author": "nickderobertis",
      "author_type": "User",
      "created_at": "2025-04-22T20:54:16Z",
      "updated_at": "2025-04-23T15:24:32Z",
      "closed_at": "2025-04-23T15:24:31Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2084/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2084",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2084",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:29.059412",
      "comments": [
        {
          "author": "davidzhao",
          "body": "the example that you've linked to contains the following, which seems to be stripped from your code above:\n\n```\n        await ctx.api.sip.create_sip_participant(\n            api.CreateSIPParticipantRequest(\n                room_name=ctx.room.name,\n                sip_trunk_id=outbound_trunk_id,\n    ",
          "created_at": "2025-04-22T22:50:22Z"
        },
        {
          "author": "longcw",
          "body": "if the sip participant identity is already know, you can specify it when creating the RoomIO\n```python\n    session = AgentSession(llm=openai.realtime.RealtimeModel())\n    room_io = RoomIO(session, room=ctx.room, participant=phone)\n    await room_io.start()\n    await session.start(\n        agent=Agen",
          "created_at": "2025-04-23T03:12:17Z"
        },
        {
          "author": "nickderobertis",
          "body": "The agent.set_participant in the outbound caller example is just setting the participant for tool calls, which I've removed for simplicity. It doesn't affect anything with connecting the call. I'll give the RoomIO a try here in a bit, as yes our 0.x code did explicitly pass the participant and I did",
          "created_at": "2025-04-23T12:27:04Z"
        },
        {
          "author": "longcw",
          "body": "@nickderobertis I updated the example to use the RoomIO explicitly and fixed some issues in https://github.com/livekit-examples/outbound-caller-python/pull/9, maybe you can give it a try. And pls let us know if that fixes your issue",
          "created_at": "2025-04-23T12:29:04Z"
        },
        {
          "author": "nickderobertis",
          "body": "Ok thank you @longcw , indeed using the `RoomIO` fixes it. Just making the same minimal changes to my example script made it work. And then when I brought those same changes into our real agent it worked as well. So I guess this was just a docs/examples gap rather than a bug.\n\nFor clarity, here's my",
          "created_at": "2025-04-23T15:06:38Z"
        }
      ]
    },
    {
      "issue_number": 2086,
      "title": "Cartesia language support on LiveKit",
      "body": "I noticed that Cartesia’s LiveKit TTS plugin supports the following languages:\n\n`TTSLanguages = Literal[\"en\", \"es\", \"fr\", \"de\", \"pt\", \"zh\", \"ja\"]`\n\nbut Cartesia’s sonic-2 TTS supports the following languages:\n\n`en, fr, de, es, pt, zh, ja, hi, it, ko, nl, pl, ru, sv, tr`\n\ndoes LiveKit currently have a way to specify the full range of Cartesia’s offered TTS languages?",
      "state": "open",
      "author": "farazmsiddiqi",
      "author_type": "User",
      "created_at": "2025-04-23T04:13:57Z",
      "updated_at": "2025-04-23T09:01:21Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2086/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2086",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2086",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:29.268672",
      "comments": [
        {
          "author": "theomonnom",
          "body": "Yes, the language is actually a str :https://github.com/livekit/agents/blob/6faa7ab448ee9ef6f243540e6588695afccd5271/livekit-plugins/livekit-plugins-cartesia/livekit/plugins/cartesia/tts.py#L84",
          "created_at": "2025-04-23T09:01:20Z"
        }
      ]
    },
    {
      "issue_number": 973,
      "title": "agent_name field in WorkerOptions does not work",
      "body": "When I don't add a name in the worker options, the agent joins in the room with no problems.\r\nBut if I add the agent_name in the `WorkerOptions`, then the agent does not join, and there are no logs for any error.\r\n\r\nI tried debugging the issue, the worker is getting registered fine. But when the web socket connection is established it is not able to receive any request. But, with no `agent_name` it works fine\r\n\r\nI also tried a workaround using `request_fnc`, doing this to change the name:\r\n```\r\nasync def request_fnc(req: JobRequest):\r\n    await req.accept(\r\n        name = \"AskMe\"\r\n    )\r\n```\r\n\r\nBut with this I have to add a sleep of 1 second in the `entrypoint` function to make things work, which is not a good solution.\r\nReason for this sleep is that if I don't add it, then in this logic fails:\r\n```\r\nlkapi = api.LiveKitAPI()\r\n        \r\n        response = await lkapi.room.list_rooms(api.ListRoomsRequest(names=[room_name]))\r\n        usecase_id = response.rooms[0].metadata\r\n```\r\nwith an error saying rooms array is empty, so it takes some time for the room to get registered in the backend (I think). Hence added the sleep, which is working for now.\r\n\r\n\r\nAny resolutions for this problem, or is it coming on my system only?",
      "state": "closed",
      "author": "aman-think41",
      "author_type": "User",
      "created_at": "2024-10-23T04:43:20Z",
      "updated_at": "2025-04-23T07:00:16Z",
      "closed_at": "2025-04-23T07:00:16Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/973/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/973",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/973",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:29.467874",
      "comments": []
    },
    {
      "issue_number": 2046,
      "title": "Agent Can hear SIP Participant but cannot hear Browser Participant",
      "body": "When a \"SIP participant\" called in to livekit, a room is created and the Agent with the name inbound-agent is dispatched to the room. The agent and \"SIP participant\" can hear each other.\n\nThen i create a token for a \"browser participant\" to join the same room. once joined, the \"browser participant\" and the \"sip participant\" can hear each other. however the agent cannot hear the \"browser participant\". he can only hear the \"sip participant\".\n\nis this a bug or a setting not done correctly?\n\n\n",
      "state": "open",
      "author": "wansolution",
      "author_type": "User",
      "created_at": "2025-04-19T09:35:08Z",
      "updated_at": "2025-04-23T03:09:09Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2046/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2046",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2046",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:29.467893",
      "comments": [
        {
          "author": "wansolution",
          "body": "\n\nNEW DISPATCH RULE \n\n{\n  \"rule\": {\n    \"dispatchRuleDirect\": {\n      \"roomName\": \"open-room\"\n    }\n  }\n}\n\n\n\nCREATE ROOM  :   lk room create --empty-timeout 600 open-room\n\nSIP DIAL IN to ROOM WITHOUT AGENT\n\n\nBROWSER DIAL INTO SAME ROOM\n\nBoth Browser Participant ans SIP Participant can talk to each o",
          "created_at": "2025-04-19T16:18:51Z"
        },
        {
          "author": "longcw",
          "body": "right now the agent can only hear one participant at a time, you can switch the linked participant using `room_io.set_participant` like that in https://github.com/livekit/agents/blob/main/examples/voice_agents/toggle_io.py#L43",
          "created_at": "2025-04-23T03:09:08Z"
        }
      ]
    },
    {
      "issue_number": 2010,
      "title": "Websocket Connection Concurrency Limit",
      "body": "Here is what I am observing:\n\nIn our dev environment, even when there is only one concurrent LK session, we are observing 429 from Cartesia (with a fallback adapter). The $5 Cartesia plan includes a 3 concurrent limit, which means 3*10=30 concurrent websocket connections.\n\nNot sure if it is relevant: during the simulation, there were multiple interruptions.\n\nHere is the trace back\n\n```\nlivekit.plugins.cartesia.tts.TTS unexpected error, switching to next TTS\nTraceback (most recent call last):\n  File \\\"/usr/local/lib/python3.12/site-packages/livekit/agents/tts/fallback_adapter.py\\\", line 384, in _try_synthesize\n    audio = next_audio_task.result()\n            ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \\\"/usr/local/lib/python3.12/site-packages/ai_worker/utils/tts_wrapper.py\\\", line 185, in __anext__\n    raise exc from None\n  File \\\"/usr/local/lib/python3.12/site-packages/livekit/agents/tts/tts.py\\\", line 302, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \\\"/usr/local/lib/python3.12/site-packages/livekit/plugins/cartesia/tts.py\\\", line 373, in _run\n    async with self._pool.connection() as ws:\n               ^^^^^^^^^^^^^^^^^^^^^^^\n  File \\\"/usr/local/lib/python3.12/contextlib.py\\\", line 210, in __aenter__\n    return await anext(self.gen)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \\\"/usr/local/lib/python3.12/site-packages/livekit/agents/utils/connection_pool.py\\\", line 76, in connection\n    conn = await self.get()\n           ^^^^^^^^^^^^^^^^\n  File \\\"/usr/local/lib/python3.12/site-packages/livekit/agents/utils/connection_pool.py\\\", line 108, in get\n    return await self._connect()\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \\\"/usr/local/lib/python3.12/site-packages/livekit/agents/utils/connection_pool.py\\\", line 59, in _connect\n    connection = await self._connect_cb()\n                 ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \\\"/usr/local/lib/python3.12/site-packages/livekit/plugins/cartesia/tts.py\\\", line 146, in _connect_ws\n    return await asyncio.wait_for(session.ws_connect(url), self._conn_options.timeout)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \\\"/usr/local/lib/python3.12/asyncio/tasks.py\\\", line 520, in wait_for\n    return await fut\n           ^^^^^^^^^\n  File \\\"/usr/local/lib/python3.12/site-packages/aiohttp/client.py\\\", line 949, in _ws_connect\n    raise WSServerHandshakeError(\naiohttp.client_exceptions.WSServerHandshakeError: 429, message='Invalid response status', url='wss://api.cartesia.ai/tts/websocket?api_key=sk_car_bxSmQDNqU95QGyZqxD4YV&cartesia_version=2024-06-10'\"\n```\n\nFrom their documentation:\n\n> If you exceed your WebSocket limit, you will receive a 429 Too Many Requests error on trying to open a new WebSocket connection.\n\nI checked the connection pool implementation, and realized it does not impose any concurrency limit. Could this be the cause for 429? \n\nI will try to do some experiments for this tomorrow to see if I can replicate/confirm this.\n\n\n",
      "state": "closed",
      "author": "ChenghaoMou",
      "author_type": "User",
      "created_at": "2025-04-15T16:23:51Z",
      "updated_at": "2025-04-22T20:24:30Z",
      "closed_at": "2025-04-22T20:24:30Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2010/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2010",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2010",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:29.730416",
      "comments": [
        {
          "author": "ChenghaoMou",
          "body": "Closing it for now since I can't reproduce it.",
          "created_at": "2025-04-16T10:27:13Z"
        },
        {
          "author": "ChenghaoMou",
          "body": "The root issue has been identified in #2027 ",
          "created_at": "2025-04-17T10:08:10Z"
        }
      ]
    },
    {
      "issue_number": 2064,
      "title": "[OAI realtime] generate_reply after interruption may raise Conversation already has an active response",
      "body": "From OAI realtime API side it seems that there is a race condition when calling the `generate_reply` after `interrupt`\nThis happens with the realtime local VAD example https://github.com/livekit/agents/blob/main/examples/voice_agents/realtime_turn_detector.py#L33\n\n```bash\n2025-04-22 11:16:47,225 - INFO livekit.agents - vad interrupted speech {\"pid\": 2103102, \"job_id\": \"AJ_CV9LipuQs3hc\"}\n2025-04-22 11:16:48,025 - INFO livekit.agents - called generate_reply {\"pid\": 2103102, \"job_id\": \"AJ_CV9LipuQs3hc\"}\n2025-04-22 11:16:48,756 - ERROR livekit.plugins.openai - OpenAI Realtime API returned an error {\"error\": \"Error(message='Conversation already has an active response', type='invalid_request_error', code='conversation_already_has_active_response', event_id='response_create_c069c3bd839f', param=None)\", \"pid\": 2103102, \"job_id\": \"AJ_CV9LipuQs3hc\"}\n2025-04-22 11:16:53,027 - ERROR livekit.agents - Error in _realtime_reply_task\nTraceback (most recent call last):\n  File \"/home/longc/data/code/agents/livekit-agents/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/longc/data/code/agents/livekit-agents/livekit/agents/voice/agent_activity.py\", line 1226, in _realtime_reply_task\n    generation_ev = await self._rt_session.generate_reply(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nlivekit.agents.llm.realtime.RealtimeError: generate_reply timed out. {\"pid\": 2103102, \"job_id\": \"AJ_CV9LipuQs3hc\"}\n```",
      "state": "closed",
      "author": "longcw",
      "author_type": "User",
      "created_at": "2025-04-22T03:21:05Z",
      "updated_at": "2025-04-22T10:09:16Z",
      "closed_at": "2025-04-22T10:09:15Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2064/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2064",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2064",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:29.958311",
      "comments": [
        {
          "author": "longcw",
          "body": "I think it's necessary to bring `on_duplicate` option back\n```python\non_duplicate: Literal[\n                \"cancel_existing\", \"cancel_new\", \"keep_both\"\n            ] = \"keep_both\",\n```",
          "created_at": "2025-04-22T03:24:34Z"
        },
        {
          "author": "longcw",
          "body": "actually it's the VAD interruption didn't interrupt the realtime session https://github.com/livekit/agents/pull/2072",
          "created_at": "2025-04-22T10:09:15Z"
        }
      ]
    },
    {
      "issue_number": 2067,
      "title": "Function/tool calling accuracy reduced after upgrading to V1",
      "body": "After upgrading to LiveKit Agents v1.0, we've observed a noticeable decrease in function/tool calling accuracy. The same script that worked reliably in v0.12.15 is now frequently making incorrect calls. Has anyone else experience this issue and any explanations and solutions this behavior is much appreciated.\n",
      "state": "open",
      "author": "udayagiri3",
      "author_type": "User",
      "created_at": "2025-04-22T06:23:46Z",
      "updated_at": "2025-04-22T10:00:09Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2067/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2067",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2067",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:30.177227",
      "comments": [
        {
          "author": "longcw",
          "body": "could you share an example on v1.0 for reproducing? it might be related to the function annotation or the chat ctx.",
          "created_at": "2025-04-22T06:27:58Z"
        },
        {
          "author": "udayagiri3",
          "body": "I suspect the issue may be related to changes in how chat context is maintained or how requests are structured and sent to the OpenAI LLM in the new version. I’d appreciate clarification on whether this understanding is correct and guidance on how to adapt our implementation accordingly.\n\nbelow is t",
          "created_at": "2025-04-22T06:40:35Z"
        },
        {
          "author": "longcw",
          "body": "from the main script it's hard to tell if there is any issue. it would be great if you can share a sample agent with a mock function tool that can see the difference between v0.x and v1.0.",
          "created_at": "2025-04-22T08:02:35Z"
        },
        {
          "author": "udayagiri3",
          "body": "Hi @longcw I will try to share a mock assistant.py meanwhile can you please confirm if there is any change in the way how chat context is maintained or how requests are structured and sent to the OpenAI LLM between previous versions and the new version. If there is a change please let me know which ",
          "created_at": "2025-04-22T09:59:58Z"
        }
      ]
    },
    {
      "issue_number": 2066,
      "title": "_audio_forwarding_task: 'str' object has no attribute 'sample_rate'",
      "body": "I am attempting to upgrade to 1.0 (bug persists in 1.0.13).\n\nThe agent starts correctly and the STT works correctly as well, after the STT when it tries to respond I get:\n\n```\nERROR livekit.agents - Error in _audio_forwarding_task\nTraceback (most recent call last):\n  File \"livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n  File \"livekit/agents/voice/generation.py\", line 221, in _audio_forwarding_task\n    and frame.sample_rate != audio_output.sample_rate\nAttributeError: 'str' object has no attribute 'sample_rate'\n```\n\nI am using AzureSTT and AzureTTS configured with\n`azure.STT(language=language)`\n`azure.TTS(voice=voice, language=self.model_config.language)`\n\nwith the plugin version\n\n`livekit-plugins-azure==1.0.13`\n\nWhat steps can I take to understand where this issue is coming from and how to resolve it?",
      "state": "closed",
      "author": "umarniz",
      "author_type": "User",
      "created_at": "2025-04-22T04:47:36Z",
      "updated_at": "2025-04-22T07:05:13Z",
      "closed_at": "2025-04-22T07:05:12Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2066/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2066",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2066",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:30.402347",
      "comments": [
        {
          "author": "longcw",
          "body": "Can you share how was your agent and agent session configured?",
          "created_at": "2025-04-22T05:09:33Z"
        },
        {
          "author": "umarniz",
          "body": "Apologies, while copy/pasting all my debug information I noticed that my agent overloads \n\n`async def tts_node(self, text: AsyncIterable[str], model_settings: ModelSettings):`\n\nand returns a string instead of `return super().tts_node(text, model_settings)` which was causing the issue I reported.\n\nTT",
          "created_at": "2025-04-22T07:05:12Z"
        }
      ]
    },
    {
      "issue_number": 1970,
      "title": "self.update_chat_ctx() not working",
      "body": "On version 1.0.11:\n\nI am trying to modify the chat-ctx in the `on_user_turn_completed`. \n\nI was trying to follow the example in the docs:\nhttps://docs.livekit.io/agents/start/v0-migration/#before-llm-cb-on-user-turn-completed\n\n--> This leads to an `AttributeError`since items are a property and can not bet set. \n\nThen I wanted to slice the chat history using this code\n```   \nasync def on_user_turn_completed(\n        self, chat_ctx: llm.ChatContext, new_message: llm.ChatMessage\n    ) -> None:\n        # Truncate the context to the last message\n        items = chat_ctx.items\n        # take the last 2 items\n        items = items[-2:]\n        \n        # Create a new context with truncated items\n        new_ctx = ChatContext(items=items)\n            \n        # explicitly update the context\n        await self.update_chat_ctx(new_ctx)\n\n        print(\"--- truncated chat item after user turn and update ---\")\n        for item in self._chat_ctx.items:\n            print(item)\n```\n\n\nAt the same time, I was logging the chat_ctx in the anthropic/llm.py plugin before returning the LLM stream\n```\n        # log anthropic context\n        print(\"--- chat context before llm call ---\")\n        for i in anthropic_ctx:\n            print(i)\n\n        stream = self._client.messages.create(\n            messages=anthropic_ctx,\n            model=self._opts.model,\n            stream=True,\n            **extra,\n        )\n\n        return LLMStream(\n            self,\n            anthropic_stream=stream,\n            chat_ctx=chat_ctx,\n            tools=tools,\n            conn_options=conn_options,\n        )\n```\n\nWhat I see in the logs is that the self.chat_ctx after updating / truncating works fine.\nYet the logs before calling the LLM show that the WHOLE chat_ctx is used and not only the truncated one. Any changes made are not propagated to the LLM call. \n\nSee these example logs\n```\n--- truncated chat item after user turn and update ---\nid='lk.agent_task.instructions' type='message' role='system' content=['Talk to the user in short sentences.'] interrupted=False hash=None\nid='item_31b68170f480' type='message' role='user' content=['Great. Uh, just tell me how you are today.'] interrupted=False hash=None\nid='item_ab95efe9683c' type='message' role='assistant' content=[\"I'm functioning well today. My systems are running smoothly. I'm ready and eager to chat with you. How about yourself?\"] interrupted=False hash=None\n--- chat context before llm call ---\n{'role': 'user', 'content': [{'text': '(empty)', 'type': 'text'}]}\n{'role': 'assistant', 'content': [{'text': \"Sure! I'm ready to chat. What would you like to talk about? I'll keep my responses brief and to the point.\", 'type': 'text', 'cache_control': None}]}\n{'role': 'user', 'content': [{'text': 'Great. Uh, just tell me how you are today.', 'type': 'text', 'cache_control': None}]}\n{'role': 'assistant', 'content': [{'text': \"I'm functioning well today. My systems are running smoothly. I'm ready and eager to chat with you. How about yourself?\", 'type': 'text', 'cache_control': None}]}\n{'role': 'user', 'content': [{'text': \"Yeah. I'm also great. I'm just testing\", 'type': 'text', 'cache_control': None}]}\n```\n\n",
      "state": "closed",
      "author": "NikoLandgraf",
      "author_type": "User",
      "created_at": "2025-04-11T08:52:40Z",
      "updated_at": "2025-04-22T03:48:39Z",
      "closed_at": "2025-04-22T03:48:39Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 10,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1970/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1970",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1970",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:30.644496",
      "comments": [
        {
          "author": "NikoLandgraf",
          "body": "I would love to understand how I can continue with an \"temporarily changed\" chat_ctx after the `on_user_turn_completed` node and how to continue with permanent changes to chat_ctx.\n\n",
          "created_at": "2025-04-11T09:41:01Z"
        },
        {
          "author": "longcw",
          "body": "`chat_ctx` of `on_user_turn_completed` is a reference that you can modify it in-place for the current turn (and only for the current turn), it's renamed to `turn_ctx` now.\n\n`self.update_chat_ctx` will modify the global chat ctx (which is not used for the current turn).\n\nSo to truncate the chat ctx f",
          "created_at": "2025-04-11T09:44:03Z"
        },
        {
          "author": "longcw",
          "body": "and btw, `turn_ctx.items[-10:]` may break the LLM if there are function tools in the chat ctx, openai LLM requires tool calls and tool outputs to be paired, they needs to be removed together. We may provider a helper function for truncating, for now you can check the top of the chat ctx and remove t",
          "created_at": "2025-04-11T09:48:03Z"
        },
        {
          "author": "NikoLandgraf",
          "body": "alright, thanks @longcw! Yeah, updated docs would help in this case. Find it quite unintuitive that changes to the global context are not used for the current run. I guess this explains my other bug ticket about updating the instructions in the on_user_turn_completed f",
          "created_at": "2025-04-11T09:54:00Z"
        },
        {
          "author": "NikoLandgraf",
          "body": "Yet, I was also NOT able to modify the chat_ctx in place for the current run. Appending messages works - but modifying / overriding it would not work",
          "created_at": "2025-04-11T09:55:30Z"
        }
      ]
    },
    {
      "issue_number": 2048,
      "title": "Error when loading agent",
      "body": "terminate called after throwing an instance of 'std::filesystem::__cxx11::filesystem_error'\n  what():  filesystem error: Cannot convert character sequence: Invalid or incomplete multibyte or wide character\nprocess exited with non-zero exit code -6\n\nNote: It also creating an unncessary KMS folder in system",
      "state": "closed",
      "author": "zokkomon",
      "author_type": "User",
      "created_at": "2025-04-19T14:31:21Z",
      "updated_at": "2025-04-21T13:19:31Z",
      "closed_at": "2025-04-21T13:19:31Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2048/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2048",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2048",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:30.906072",
      "comments": []
    },
    {
      "issue_number": 2050,
      "title": "Audio streaming question",
      "body": "Hi team,\nCan someone please clarify for Voice AI agents, does livekit stream audio in chunks as soon as individual chunks are available? Or does it wait to synthesize audio for the whole text and send one single audio chunk for the whole text?\n\n@davidzhao  @nbsp  @lukasIO ",
      "state": "closed",
      "author": "codecurry",
      "author_type": "User",
      "created_at": "2025-04-21T06:53:19Z",
      "updated_at": "2025-04-21T07:10:11Z",
      "closed_at": "2025-04-21T07:10:10Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2050/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2050",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2050",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:30.906096",
      "comments": [
        {
          "author": "longcw",
          "body": "It streams audio as chunks",
          "created_at": "2025-04-21T06:55:09Z"
        }
      ]
    },
    {
      "issue_number": 2009,
      "title": "SIP Agent Not Starting Fresh Call - Resuming Old State/ Stale LLM context?",
      "body": "After stopping SIP agent tests last night (~8 PM), I reconnected the agent today and dialed its number after 10 hours.\n\nInstead of playing a greeting and starting a new call, the agent immediately responded as if continuing a previous conversation. It completely bypassed the initial greeting state.\n\nWhy would the agent resume like this after being inactive overnight, instead of starting fresh? Could there be leftover state in the agent, the LiveKit room, or the SIP connection itself?\n\nLogs below (numbers changed). Looking for possible causes for this stale state behavior:\nhttps://gist.github.com/zt9/aac8ee7d7e9556a852b495346b6a8057\n\nWould you be able to provide any internal logs for :\n\n1. Job ID: AJ_iNLAJJzcH7Gu\n2. worker ID: AW_BkTWrdB8sqMR\n3. Room: RM_9AsrnJqh29gs\n\nFor your reference:\n\nhttps://cloud.livekit.io/projects/p_483jqb1ll5s/sessions/RM_9AsrnJqh29gs\nhttps://cloud.livekit.io/projects/p_483jqb1ll5s/telephony/SCL_qxSiaiN4bfno/inbound\n\n\n```\n{\nproject_id: \"p_483jqb1ll5s\"\nroom_id: \"RM_9AsrnJqh29gs\"\ntimestamp: \"2025-04-13T11:27:19Z\"\ntype: \"Track published\"\nparticipant_id: \"PA_SfQXSEEFU2Dk\"\nparticipant_identity: \"agent-AJ_iNLAJJzcH7Gu\"\nnode_id: \"NM_OASHBURN1A_MicdRXsFf9Lq\"\ntimestamp_us: 1744543639585698\n}\n```\n\nThis morning, I connected a new agent to an existing room (inadvertently - was was using agent playground but not SIP), and the same behavior occurred—the agent continued the previous conversation. Although it makes sense that a new agent joining an existing room would maintain context, I’m perplexed that a brand new SIP call, which should create a separate room, still carried over context from an older call.\n\nI'm still interested in finding out what happened with the logs I posted and the call ids I posted",
      "state": "open",
      "author": "zt9",
      "author_type": "User",
      "created_at": "2025-04-15T13:48:04Z",
      "updated_at": "2025-04-20T15:50:09Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2009/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2009",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2009",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:31.120585",
      "comments": [
        {
          "author": "davidzhao",
          "body": "there is no state stored anywhere here.. the example session you linked to shows a fresh agent joining the room.\n\ndo you load any data from the DB anywhere? ",
          "created_at": "2025-04-18T06:58:18Z"
        },
        {
          "author": "zt9",
          "body": "@davidzhao There is no DB at all what so ever (have not gotten there yet)\n\nThat is what makes it so strange.\n\nIf you are able to pull the transactions for chat completions, you will see what I am taking about . BTW this is the same code that I have deployed and this happened once where I was able to",
          "created_at": "2025-04-20T15:49:55Z"
        }
      ]
    },
    {
      "issue_number": 2036,
      "title": "How to post-process cleanup at time of room completion?",
      "body": "We're in amidst of migrating our v0 code to v1. Our use case involves a possible warm SIP handoff while removing the AI agent so we end up with a Human + Human interaction.\n\nIn v0, the shutdown hook that we register doesn't trigger at time of Agent removal.  It only triggers when the room is removed by Livekit due to 0 participants or if we forcibly delete the room. This was desirable as we run some clean up code after.\n\nIn v1, the shutdown hook triggers when the Agent is removed from the room.  This seems to be intended behavior based on the description here https://docs.livekit.io/agents/worker/job/#post-processing-and-cleanup. But as soon as this happens (e.g. when we have 2 human participants left in the room), we seem to lose all further control. \n\n1. Our ctx.room.on(\"participant_disconnected\") hook ceases to be triggered when one or both of the human participants leave the room.\n2. The documentation at https://docs.livekit.io/agents/worker/job/#disconnecting-everyone implies that we can register a ctx.room.on(\"disconnected\") hook to perform cleanup when the room is removed. I poked around (and might very well be wrong) but can't seem to find anything indicating where this is emitted in the agents framework and given point 1 above unsure whether it would fire even if implemented.\n\nWould appreciate any guidance.",
      "state": "open",
      "author": "yuyuma",
      "author_type": "User",
      "created_at": "2025-04-18T01:59:13Z",
      "updated_at": "2025-04-19T21:15:17Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2036/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2036",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2036",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:31.407635",
      "comments": [
        {
          "author": "yuyuma",
          "body": "Related slack discussion: https://livekit-users.slack.com/archives/C07FY8WHGPM/p1745063954228409?thread_ts=1745063954.228409&cid=C07FY8WHGPM",
          "created_at": "2025-04-19T21:15:16Z"
        }
      ]
    },
    {
      "issue_number": 1103,
      "title": "bug: phantom inputs from google STT library for low confidence / short transcripts",
      "body": "In the voice agent i'm building I see phantom numeric `user_transcript` inputs come through when using the `google` STT library.\r\n\r\nSome example below, you can see 1 being emitted which is detected outside of the  user_started_speaking or user_stopped_speaking VAD .\r\n\r\n```\r\n11-18 11:03:25,816 - DEBUG livekit.agents.pipeline - user_started_speaking {\"pid\": 70217, \"job_id\": \"AJ_LBHQeFbo38VK\"}\r\n2024-11-18 11:03:31,607 - DEBUG livekit.agents.pipeline - received user transcript {\"user_transcript\": \"Uh, let me think about that. Yes.\", \"type\": \"final_transcript\", \"pid\": 70217, \"job_id\": \"AJ_LBHQeFbo38VK\"}\r\nsending state 0\r\n2024-11-18 11:03:32,436 - DEBUG livekit.agents.pipeline - user_stopped_speaking {\"pid\": 70217, \"job_id\": \"AJ_LBHQeFbo38VK\"}\r\n2024-11-18 11:03:32,813 - DEBUG livekit.agents.pipeline - validated agent reply {\"speech_id\": \"67b1b92a6de2\", \"pid\": 70217, \"job_id\": \"AJ_LBHQeFbo38VK\"}\r\n2024-11-18 11:03:35,517 - DEBUG livekit.agents.pipeline - speech playout started {\"speech_id\": \"67b1b92a6de2\", \"pid\": 70217, \"job_id\": \"AJ_LBHQeFbo38VK\"}\r\nsending state 2\r\n2024-11-18 11:03:38,305 - DEBUG livekit.agents.pipeline - received user transcript {\"user_transcript\": \"1\", \"type\": \"final_transcript\", \"pid\": 70217, \"job_id\": \"AJ_LBHQeFbo38VK\"}\r\n2024-11-18 11:03:39,807 - DEBUG livekit.agents.pipeline - skipping validation, agent is speaking and does not allow interruptions {\"speech_id\": \"67b1b92a6de2\", \"pid\": 70217, \"job_id\": \"AJ_LBHQeFbo38VK\"}\r\nsending state 0\r\n2024-11-18 11:03:55,241 - DEBUG livekit.agents.pipeline - speech playout finished {\"speech_id\": \"67b1b92a6de2\", \"interrupted\": false, \"pid\": 70217, \"job_id\": \"AJ_LBHQeFbo38VK\"}\r\n2024-11-18 11:03:55,242 - DEBUG livekit.agents.pipeline - committed agent speech {\"agent_transcript\": \" Take your time., \"interrupted\": false, \"speech_id\": \"67b1b92a6de2\", \"pid\": 70217, \"job_id\": \"AJ_LBHQeFbo38VK\"}\r\n```\r\n\r\nYou can see another instance where a series of numbers are emitted `1 2 3 7 0 9 1 2 0 0 0 0 0` which were not part of the transcript (I've added logging for interim transcripts which shows the additional \"final_transcript\" emitted just prior to the actual final input.\r\n\r\n```\r\n2024-11-18 11:16:08,133 - DEBUG livekit.agents.pipeline - user_started_speaking {\"pid\": 70716, \"job_id\": \"AJ_Kr4GyxgomYyM\"}\r\n2024-11-18 11:16:08,869 - DEBUG livekit.agents.pipeline - received interim transcript {\"user_transcript\": \"uh\", \"type\": \"interim_transcript\", \"pid\": 70716, \"job_id\": \"AJ_Kr4GyxgomYyM\"}\r\n2024-11-18 11:16:09,063 - DEBUG livekit.agents.pipeline - received interim transcript {\"user_transcript\": \"Sorry.\", \"type\": \"interim_transcript\", \"pid\": 70716, \"job_id\": \"AJ_Kr4GyxgomYyM\"}\r\n2024-11-18 11:16:09,370 - DEBUG livekit.agents.pipeline - received interim transcript {\"user_transcript\": \"sorry can\", \"type\": \"interim_transcript\", \"pid\": 70716, \"job_id\": \"AJ_Kr4GyxgomYyM\"}\r\n2024-11-18 11:16:09,487 - DEBUG livekit.agents.pipeline - received interim transcript {\"user_transcript\": \"sorry, can you\", \"type\": \"interim_transcript\", \"pid\": 70716, \"job_id\": \"AJ_Kr4GyxgomYyM\"}\r\n2024-11-18 11:16:09,651 - DEBUG livekit.agents.pipeline - received interim transcript {\"user_transcript\": \"sorry, can you\", \"type\": \"interim_transcript\", \"pid\": 70716, \"job_id\": \"AJ_Kr4GyxgomYyM\"}\r\n2024-11-18 11:16:09,864 - DEBUG livekit.agents.pipeline - received interim transcript {\"user_transcript\": \"sorry, can you repeat\", \"type\": \"interim_transcript\", \"pid\": 70716, \"job_id\": \"AJ_Kr4GyxgomYyM\"}\r\n2024-11-18 11:16:09,948 - DEBUG livekit.agents.pipeline - received interim transcript {\"user_transcript\": \"sorry, can you repeat\", \"type\": \"interim_transcript\", \"pid\": 70716, \"job_id\": \"AJ_Kr4GyxgomYyM\"}\r\n2024-11-18 11:16:10,047 - DEBUG livekit.agents.pipeline - received interim transcript {\"user_transcript\": \"sorry, can you repeat\", \"type\": \"interim_transcript\", \"pid\": 70716, \"job_id\": \"AJ_Kr4GyxgomYyM\"}\r\n2024-11-18 11:16:10,164 - DEBUG livekit.agents.pipeline - received interim transcript {\"user_transcript\": \"Sorry, can you repeat that?\", \"type\": \"interim_transcript\", \"pid\": 70716, \"job_id\": \"AJ_Kr4GyxgomYyM\"}\r\n2024-11-18 11:16:10,436 - DEBUG livekit.agents.pipeline - received interim transcript {\"user_transcript\": \"Sorry, can you repeat that?\", \"type\": \"interim_transcript\", \"pid\": 70716, \"job_id\": \"AJ_Kr4GyxgomYyM\"}\r\nsending state 0\r\n2024-11-18 11:16:16,307 - DEBUG livekit.agents.pipeline - received user transcript {\"user_transcript\": \"1 2 3 7 0 9 1 2 0 0 0 0 0\", \"type\": \"final_transcript\", \"pid\": 70716, \"job_id\": \"AJ_Kr4GyxgomYyM\"}\r\n2024-11-18 11:16:17,203 - DEBUG livekit.agents.pipeline - received user transcript {\"user_transcript\": \"Sorry, can you repeat that?\", \"type\": \"final_transcript\", \"pid\": 70716, \"job_id\": \"AJ_Kr4GyxgomYyM\"}\r\n```\r\n\r\nI've captured the output from the the google speech response in same cases:\r\n\r\n```\r\nSPEECH RESP metadata {\r\n  total_billed_duration {\r\n    seconds: 176\r\n  }\r\n  request_id: \"673b2846-0000-20ff-acb0-089e082cdb00\"\r\n}\r\nresults {\r\n  alternatives {\r\n    transcript: \"3 9 2 0 8 0 8 0 0 0 0\"\r\n    confidence: 0.585391164\r\n    words {\r\n      start_offset {\r\n        seconds: 24\r\n        nanos: 470000000\r\n      }\r\n      end_offset {\r\n        seconds: 24\r\n        nanos: 550000000\r\n      }\r\n      word: \"3\"\r\n      confidence: 0.33627677\r\n    }\r\n    words {\r\n      start_offset {\r\n        seconds: 24\r\n        nanos: 550000000\r\n      }\r\n      end_offset {\r\n        seconds: 24\r\n        nanos: 670000000\r\n      }\r\n      word: \"9\"\r\n      confidence: 0.626038194\r\n    }\r\n    words {\r\n      start_offset {\r\n        seconds: 24\r\n        nanos: 670000000\r\n      }\r\n      end_offset {\r\n        seconds: 24\r\n        nanos: 750000000\r\n      }\r\n      word: \"2\"\r\n      confidence: 0.79240793\r\n    }\r\n    words {\r\n      start_offset {\r\n        seconds: 24\r\n        nanos: 750000000\r\n      }\r\n      end_offset {\r\n        seconds: 24\r\n        nanos: 870000000\r\n      }\r\n      word: \"0\"\r\n      confidence: 0.633162379\r\n    }\r\n    words {\r\n      start_offset {\r\n        seconds: 24\r\n        nanos: 870000000\r\n      }\r\n      end_offset {\r\n        seconds: 24\r\n        nanos: 990000000\r\n      }\r\n      word: \"8\"\r\n      confidence: 0.604495645\r\n    }\r\n    words {\r\n      start_offset {\r\n        seconds: 24\r\n        nanos: 990000000\r\n      }\r\n      end_offset {\r\n        seconds: 25\r\n        nanos: 110000000\r\n      }\r\n      word: \"0\"\r\n      confidence: 0.695137799\r\n    }\r\n    words {\r\n      start_offset {\r\n        seconds: 25\r\n        nanos: 110000000\r\n      }\r\n      end_offset {\r\n        seconds: 25\r\n        nanos: 190000000\r\n      }\r\n      word: \"8\"\r\n      confidence: 0.635257244\r\n    }\r\n    words {\r\n      start_offset {\r\n        seconds: 25\r\n        nanos: 190000000\r\n      }\r\n      end_offset {\r\n        seconds: 25\r\n        nanos: 270000000\r\n      }\r\n      word: \"0\"\r\n      confidence: 0.615414381\r\n    }\r\n    words {\r\n      start_offset {\r\n        seconds: 25\r\n        nanos: 270000000\r\n      }\r\n      end_offset {\r\n        seconds: 25\r\n        nanos: 390000000\r\n      }\r\n      word: \"0\"\r\n      confidence: 0.609516263\r\n    }\r\n    words {\r\n      start_offset {\r\n        seconds: 25\r\n        nanos: 390000000\r\n      }\r\n      end_offset {\r\n        seconds: 25\r\n        nanos: 510000000\r\n      }\r\n      word: \"0\"\r\n      confidence: 0.546232462\r\n    }\r\n    words {\r\n      start_offset {\r\n        seconds: 25\r\n        nanos: 510000000\r\n      }\r\n      end_offset {\r\n        seconds: 25\r\n        nanos: 590000000\r\n      }\r\n      word: \"0\"\r\n      confidence: 0.591834068\r\n    }\r\n  }\r\n  is_final: true\r\n  result_end_offset {\r\n    seconds: 10\r\n    nanos: 630000114\r\n  }\r\n  language_code: \"en-AU\"\r\n}\r\n```\r\n\r\nIn most cases the confidence < 0.6 which indicates, so these could probably be ignored, but in other cases there are numeric inputs with high confidence but that has a duration of 0 (ie start/end offsets are equal).\r\n\r\n```\r\nSPEECH RESP metadata {\r\n  total_billed_duration {\r\n    seconds: 29\r\n  }\r\n  request_id: \"674eec46-0000-2f17-b8b0-ac3eb15a0510\"\r\n}\r\nresults {\r\n  alternatives {\r\n    transcript: \"3688866886886886868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686\"\r\n    confidence: 0.956959367\r\n    words {\r\n      start_offset {\r\n        seconds: 34\r\n        nanos: 330000000\r\n      }\r\n      end_offset {\r\n        seconds: 34\r\n        nanos: 330000000\r\n      }\r\n      word: \"3688866886886886868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686868686\"\r\n      confidence: 0.960090339\r\n    }\r\n  }\r\n  is_final: true\r\n  result_end_offset {\r\n    seconds: 21\r\n    nanos: 370000839\r\n  }\r\n  language_code: \"en-AU\"\r\n}\r\n```",
      "state": "closed",
      "author": "brightsparc",
      "author_type": "User",
      "created_at": "2024-11-18T02:06:06Z",
      "updated_at": "2025-04-19T11:53:16Z",
      "closed_at": "2025-02-16T22:03:02Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1103/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1103",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1103",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:31.614676",
      "comments": [
        {
          "author": "brightsparc",
          "body": "This is seen when using google STT library with `chirp_2` model.  I've tested with the default `long` model and it doesn't happen at all /often. \r\n\r\nSo I think there is probably a fix required specific to google, but also I wonder if these should be some thresholding on the min confidence / duration",
          "created_at": "2024-11-18T03:05:59Z"
        },
        {
          "author": "wnke",
          "body": "@brightsparc Did you find any work around to use the `chirp_2` model?  I am having the same issue, `long` works fine but `chirp_2`  displays those numbers that seem to be metadata.",
          "created_at": "2025-02-10T23:07:46Z"
        },
        {
          "author": "brightsparc",
          "body": "No I didn't, chirp_2 is now the default model, so it might be worth escalating this.",
          "created_at": "2025-02-11T00:40:49Z"
        },
        {
          "author": "wnke",
          "body": "Agree, also the model is really good but this bug renders it unusable.  ",
          "created_at": "2025-02-11T11:01:13Z"
        },
        {
          "author": "davidzhao",
          "body": "thanks for raising this issue. I've confirmed this is an issue with Google STT with chirp. I have a fix for it in #1507 if anyone has a chance to validate",
          "created_at": "2025-02-16T09:01:48Z"
        }
      ]
    },
    {
      "issue_number": 2043,
      "title": "[Livekit Cloud] Not all job requests are emitted to my agent worker with a certain Livekit Cloud project",
      "body": "Hello Livekit team,\n\nI have an issue related to a concurrency scenario and Livekit Cloud (this doesn't happens with a local Livekit server). Basically, when creating rooms and having a participant joining each room, not all the job requests are emitted to my worker.\n\nMy first approach to replicate this issue was by using the UI examples available in the docs, I created a monorepo with it, including the agent worker and instructions:\n\n- https://github.com/devniel/livekit-concurrency-example\n\nBut then, I used the new `agent-load-test` tool in the Livekit CLI as advised by @yepher  in the Livekit Community Slack, getting the same results. To summarize: \n\n- 10 rooms created, 1 participant per room.\n- Worker only receives 7 events.\n\nSurprisingly, I tested using another Livekit Cloud project and it worked 100% ok, so I'm assuming it's an issue of old Livekit Cloud projects or some sort of regions issues.\n\nAnother workaround, can be maybe to add retries based on timeout in the UI.\n\nMore info:\n\n- The problematic Livekit Cloud project (missing job requests): rounded-test-2-nixv6gpj.livekit.cloud\n- The new Livekit Cloud project (ok): rounded-stress-tests-foro8boz.livekit.cloud\n\nSlack thread: https://livekit-users.slack.com/archives/C048FRL1N2C/p1744980267725499\n\nThank you!",
      "state": "open",
      "author": "devniel",
      "author_type": "User",
      "created_at": "2025-04-18T19:29:06Z",
      "updated_at": "2025-04-18T19:29:06Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2043/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2043",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2043",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:31.815105",
      "comments": []
    },
    {
      "issue_number": 2034,
      "title": "RoomIO.start() throws “text stream handler for topic ‘lk.chat’ already set” if called twice",
      "body": "Hi team, first of all—thank you for the fantastic work on LiveKit! I’ve been loving the flexibility of the text‐stream API.\n\nI ran into a “text stream handler for topic ‘lk.chat’ already set” error whenever I call RoomIO.start() a second time.\n\n### Steps to Reproduce:\n1. Create a RoomIO instance and call await roomIO.start().\n2. Tear it down (e.g. call await roomIO.aclose(), but note that this does not unregister the text handler).\n3. Call await roomIO.start() again.\n\nYou’ll immediately see:\n```sh\nValueError: text stream handler for topic 'lk.chat' already set\n```\n\nI wondered if we could guard against any leftover handlers by clearing them up front. For example:\n\n```py\nasync def start(self) -> None:\n    self._room._text_stream_handlers.clear()\n    # … rest of start() …\n```\n\nThank you again for all your hard work!",
      "state": "closed",
      "author": "well-balanced",
      "author_type": "User",
      "created_at": "2025-04-17T20:55:18Z",
      "updated_at": "2025-04-18T01:11:57Z",
      "closed_at": "2025-04-17T23:47:23Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2034/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2034",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2034",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:31.815128",
      "comments": [
        {
          "author": "well-balanced",
          "body": "Hey! 😅\nI just realized that `room_io.start()` was being called explicitly, and then again internally via the `session.start()` call with `ctx.room`:\n```py\nroom_io = RoomIO(session, room=ctx.room)\nawait room_io.start()\nawait session.start(\n    agent=ElseAgent(\n        room_metadata=room_metadata,\n   ",
          "created_at": "2025-04-17T23:47:21Z"
        },
        {
          "author": "longcw",
          "body": "I think it's better to ignore the room in `session.start` when a RoomIO is already set up for the session to avoid this. I'll add a fix for this.",
          "created_at": "2025-04-18T01:11:57Z"
        }
      ]
    },
    {
      "issue_number": 2022,
      "title": "Support for gpt-4o-transcribe , gpt-4o-mini-transcribe , gpt-4o-mini-tts,gpt-4o-mini-tts on Azure.",
      "body": "<!--\nHello! Thanks for taking the time to file a bug report.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already reported this issue.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n-->\nAzure OpenAI released support for gpt-4o-transcribe , gpt-4o-mini-transcribe , gpt-4o-mini-tts,gpt-4o-mini-tts recently. When can we expect support for these models?",
      "state": "closed",
      "author": "levitt72",
      "author_type": "User",
      "created_at": "2025-04-16T22:35:24Z",
      "updated_at": "2025-04-17T17:31:52Z",
      "closed_at": "2025-04-17T17:31:51Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2022/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "jayeshp19"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2022",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2022",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:32.040758",
      "comments": [
        {
          "author": "jayeshp19",
          "body": "Just merged the PR : https://github.com/livekit/agents/pull/2030",
          "created_at": "2025-04-17T17:31:52Z"
        }
      ]
    },
    {
      "issue_number": 2018,
      "title": "Breaking change in LiveKit 1.X – Unable to pass participant to agent",
      "body": "After upgrading from LiveKit Python SDK 0.X to 1.X, the logic that previously worked to start an agent with a specific participant (for outbound calls) is now broken or unsupported. I’m unsure how to pass the outbound_participant in the new version.\n Works in LiveKit 0.X\n```\nagent = VoicePipelineAgent(\n    vad=ctx.proc.userdata[\"vad\"],\n    stt=STTService(stt_service_name, stt_language).stt_service,\n    llm=LLMService(llm_service_name).llm_service,\n    tts=TTSService(tts_service_name, tts_voice_id).tts_service,\n    chat_ctx=initial_ctx,\n    fnc_ctx=fnc_ctx,\n    before_llm_cb=_enrich_with_rag,\n    preemptive_synthesis=True,\n    before_tts_cb=_predicted_text,\n    noise_cancellation=noise_cancellation.BVC()\n)\n\nif source == 3:\n    agent.start(ctx.room, outbound_participant)  # This worked in 0.X\nelse:\n    agent.start(ctx.room)\n```\n\nIn LiveKit 1.X, the new recommended way appears to be:\n```\nif source == 3:\n    my_agent = OutboundCaller()\nelse:\n    my_agent = Assistant()\n\nsession = AgentSession(\n    stt=STTService(stt_service_name).stt_service,\n    llm=LLMService(llm_service_name).llm_service,\n    tts=TTSService(tts_service_name, tts_voice_id).tts_service,\n    vad=silero.VAD.load(),\n    max_tool_steps=1,\n)\n\nawait session.start(\n    room=ctx.room,\n    agent=my_agent,\n    room_input_options=RoomInputOptions(\n        noise_cancellation=noise_cancellation.BVC()\n    )\n)\n```\n\nBut I cannot figure out how to specify or pass outbound_participant to the agent in this new API.\n\n⚙️ Expected Behavior\nA way to attach a specific participant (like outbound_participant) when starting the agent, similar to what was possible in LiveKit 0.X.\n",
      "state": "closed",
      "author": "narendra-bluebash",
      "author_type": "User",
      "created_at": "2025-04-16T15:41:21Z",
      "updated_at": "2025-04-17T16:12:31Z",
      "closed_at": "2025-04-17T16:12:31Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2018/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2018",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2018",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:32.235393",
      "comments": [
        {
          "author": "longcw",
          "body": "By default when `await session.start(agent=..., room=ctx.room)` it will create a RoomIO instance listen to the first participant joins the room, you can specify the participant listen in `RoomIO` explicitly\n```python\n    from livekit.agents import RoomIO\n\n    room_io = RoomIO(\n        agent_session=",
          "created_at": "2025-04-16T15:56:07Z"
        },
        {
          "author": "narendra-bluebash",
          "body": "```\n{\"message\": \"RoomIO audio input is enabled but input.audio is already set, ignoring..\", \"level\": \"WARNING\", \"name\": \"livekit.agents\", \"pid\": 82123, \"job_id\": \"AJ_bQH5wGFdCF4Y\", \"timestamp\": \"2025-04-16T16:49:08.178167+00:00\"}\n{\"message\": \"unhandled exception while running the job task\\nTraceback",
          "created_at": "2025-04-16T17:19:39Z"
        },
        {
          "author": "longcw",
          "body": "@narendra-bluebash You need to remove the `room` from `await session.start(agent=MyAgent())` when an explicit RoomIO is used. Check the example of change participant in https://github.com/livekit/agents/blob/main/examples/voice_agents/toggle_io.py",
          "created_at": "2025-04-17T01:09:14Z"
        },
        {
          "author": "narendra-bluebash",
          "body": "   ```\n from livekit.agents import RoomIO\n\n    room_io = RoomIO(\n        agent_session=session,\n        room=ctx.room,\n        participant=target_participant,\n        output_options=RoomOutputOptions(transcription_enabled=True),\n    )\n    await room_io.start()\n\n    await session.start(agent=MyAgent(",
          "created_at": "2025-04-17T16:12:06Z"
        }
      ]
    },
    {
      "issue_number": 1912,
      "title": "LiveKit 1.0 How to specify voice for Google TTS?",
      "body": "In LiveKit 0.x, we can specify voice for Google TTS using `voice_name` parameter (as string)\n\nIn LiveKit 1.0.0rc6, `voice_name` parameter is not allowed. There is `voice` parameter but not as string: \n(https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-google/livekit/plugins/google/tts.py)\n```\nclass TTS(tts.TTS):\n    def __init__(\n        self,\n        *,\n        voice: NotGivenOr[texttospeech.VoiceSelectionParams] = NOT_GIVEN,\n        sample_rate: int = 24000,\n        pitch: int = 0,\n        effects_profile_id: str = \"\",\n        speaking_rate: float = 1.0,\n        location: str = \"global\",\n        credentials_info: NotGivenOr[dict] = NOT_GIVEN,\n        credentials_file: NotGivenOr[str] = NOT_GIVEN,\n    ) -> None:\n        \"\"\"\n        Create a new instance of Google TTS.\n\n        Credentials must be provided, either by using the ``credentials_info`` dict, or reading\n        from the file specified in ``credentials_file`` or the ``GOOGLE_APPLICATION_CREDENTIALS``\n        environmental variable.\n\n        Args:\n            voice (texttospeech.VoiceSelectionParams, optional): Voice selection parameters.\n            sample_rate (int, optional): Audio sample rate in Hz. Default is 24000.\n            location (str, optional): Location for the TTS client. Default is \"global\".\n            pitch (float, optional): Speaking pitch, ranging from -20.0 to 20.0 semitones relative to the original pitch. Default is 0.\n            effects_profile_id (str): Optional identifier for selecting audio effects profiles to apply to the synthesized speech.\n            speaking_rate (float, optional): Speed of speech. Default is 1.0.\n            credentials_info (dict, optional): Dictionary containing Google Cloud credentials. Default is None.\n            credentials_file (str, optional): Path to the Google Cloud credentials JSON file. Default is None.\n        \"\"\"  # noqa: E501\n```\nAccordingly, the variants \n`tts=google.TTS(voice=\"en-US-Standard-D\") `\nor\n`tts=google.TTS(voice_name=\"en-US-Standard-D\")`\nresult in errors.\n\nBy the way, the docs for LiveKit 1.0 still refer to non-existing `voice_name` parameter (https://docs.livekit.io/agents/v1/integrations/tts/google/)\n\nIt looks like a bug somewhere here",
      "state": "closed",
      "author": "Andhs-eff",
      "author_type": "User",
      "created_at": "2025-04-07T11:48:27Z",
      "updated_at": "2025-04-17T14:31:29Z",
      "closed_at": "2025-04-17T14:31:29Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1912/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1912",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1912",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:32.460220",
      "comments": [
        {
          "author": "ChenghaoMou",
          "body": "Have you tried this?\n\n```python\nfrom google.cloud import texttospeech\n...\n\nvoice = texttospeech.VoiceSelectionParams(\n                name=\"the_name\",\n                language_code=\"en-US\",\n                ssml_gender=SsmlVoiceGender.NEUTRAL,\n            )\n```",
          "created_at": "2025-04-07T13:16:31Z"
        },
        {
          "author": "Andhs-eff",
          "body": "Yeah, it works. But looks a bit cumbersome compared to using other TTS. So, is it a way to go?",
          "created_at": "2025-04-07T14:21:59Z"
        },
        {
          "author": "ChenghaoMou",
          "body": "Honestly, this wouldn't be the first to introduce voice specific settings. e.g. Elevenlabs' voice setting:\n\n```python\nDEFAULT_VOICE = Voice(\n    id=\"EXAVITQu4vr4xnSDxMaL\",\n    name=\"Bella\",\n    category=\"premade\",\n    settings=VoiceSettings(\n        stability=0.71,\n        speed=1.0,\n        similar",
          "created_at": "2025-04-07T18:23:42Z"
        },
        {
          "author": "theomonnom",
          "body": "This is definitely a bit confusing—we’ll work on making it much more user-friendly.",
          "created_at": "2025-04-07T22:56:08Z"
        }
      ]
    },
    {
      "issue_number": 1761,
      "title": "How to run Gemini realtime multimodal on Vertex AI with Livekit agents",
      "body": "Note: I did enable these APIs in my cloud project:\n* Vertex AI\n* Cloud Speech-to-Text API\n* Cloud Text-to-Speech API\n\nHello!\n\nI m using Gemini multimodal live agent with python.\n\nI am trying to use the Vertex AI version, not the Gemini API version (because the Gemini API is very slow right now vs. Vertex AI).\n\nNow, when I follow Google's quickstart, it works.\n\nHere is the code:\n```\nfrom google import genai\nfrom google.genai.types import LiveConnectConfig, HttpOptions, Modality\nimport asyncio\nimport dotenv\nimport os\n\n# Load environment variables\nprint('Before calling dotenv.load_dotenv()')\ndotenv.load_dotenv()\nprint('After calling dotenv.load_dotenv()')\n\nmodel_id = \"gemini-2.0-flash-exp\"\n\n# Determine credentials and initialize client\napi_key = os.getenv('GOOGLE_API_KEY')\nif api_key:\n    print('Using GOOGLE_API_KEY for authentication')\n    client = genai.Client(api_key=api_key, http_options=HttpOptions(api_version='v1beta1'))\nelse:\n    project = os.getenv('GOOGLE_CLOUD_PROJECT')\n    location = os.getenv('GOOGLE_CLOUD_LOCATION')\n    if project and location:\n        print('Using Google Cloud credentials for authentication')\n        client = genai.Client(vertexai=True, project=project, location=location, http_options=HttpOptions(api_version='v1beta1'))\n    else:\n        raise ValueError(\"Missing credentials: Set GOOGLE_API_KEY for Google AI API or set both GOOGLE_CLOUD_PROJECT and GOOGLE_CLOUD_LOCATION for Google Cloud API\")\n\nif os.getenv('GOOGLE_APPLICATION_CREDENTIALS') is not None:\n    print('Environment variable GOOGLE_APPLICATION_CREDENTIALS is loaded:', os.environ['GOOGLE_APPLICATION_CREDENTIALS'])\nelse:\n    print('Environment variable GOOGLE_APPLICATION_CREDENTIALS is NOT loaded!')\n\nasync def main() -> None:\n    print('Inside main function: started')\n    async with client.aio.live.connect(\n        model=model_id,\n        config=LiveConnectConfig(response_modalities=[Modality.TEXT]),\n    ) as session:\n        print('Inside session block: connected')\n        text_input = \"Hello? Gemini, are you there?\"\n        print('Sending text:', text_input)\n        await session.send(input=text_input, end_of_turn=True)\n\n        response = []\n\n        async for message in session.receive():\n            if message.text:\n                response.append(message.text)\n\n        print(\"\".join(response))\n\nif __name__ == \"__main__\":\n    print(\"edwedwedwedwedwedw: \",os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])\n    asyncio.run(main())\n# Example output:\n# >  Hello? Gemini, are you there?\n\n# Yes, I'm here. What would you like to talk about?\n```\n\n\nHere are my env variables:\n```\nGOOGLE_CLOUD_PROJECT=vacationator\nGOOGLE_CLOUD_LOCATION=us-central1\nGOOGLE_GENAI_USE_VERTEXAI=True\nGOOGLE_APPLICATION_CREDENTIALS='./service-account-file.json'\n```\n\n\nAnd here is my livekit agent code: it works if I use Google API Key with Gemini API, but it's very slow - so I think my code for livekit implementation is ok.\nHowever, it does not work for Vertex AI with exactly the same config as the one for the quickstart of Google above.\n\nMy code: \n```\nimport logging\nfrom typing import Annotated, List\nimport threading\nimport asyncio\n\nimport aiohttp\nfrom dotenv import load_dotenv\n\nimport os\n\nfrom livekit.agents.cli.log import setup_logging\nfrom livekit.agents import (\n    AutoSubscribe,\n    JobContext,\n    WorkerOptions,\n    WorkerType,\n    cli,\n    llm,\n    multimodal,\n)\nfrom livekit.plugins import google\n\nfrom utils.otherUtils import handleUnhandledExceptions\nfrom utils.promptUtils import getSystemInstructions\nfrom utils.envUtils import getGeneralConfig\n\nfrom sendVacationBriefToTravelAgency.sendVacationBriefToTravelAgency import (\n    sendVacationBriefToTravelAgency\n)\nfrom searchWeb.searchWeb import searchWeb\n\nfrom userVacationPreferences.getUserVacationPreferences import getUserVacationPreferences\nfrom userVacationPreferences.saveUserVacationPreferences import saveUserVacationPreferences\nfrom userVacationPreferences.getUserPreferredName import getUserPreferredName\n\nfrom flyHealthServer.flyHealthServer import runHealthServer\n\n# ------------------------------------------------------\n# Setup and configuration\n# ------------------------------------------------------\nsetup_logging(\"ERROR\", devmode=False)\nload_dotenv()\ngeneralConfig = getGeneralConfig()\n\nlogger: logging.Logger = logging.getLogger(\"my-worker\")\nlogger.setLevel(logging.ERROR)\n\ngenerateVacationPlanUrl = f\"{generalConfig.MAIN_SERVER_URL}/generate-vacation-plan/\"\nsearchWebUrl = f\"{generalConfig.MAIN_SERVER_URL}/search-web/\"\ngetUserVacationPreferencesUrl = f\"{generalConfig.MAIN_SERVER_URL}/get-user-vacation-preferences/\"\nsaveUserVacationPreferencesUrl = f\"{generalConfig.MAIN_SERVER_URL}/save-user-vacation-preferences/\"\ngetUserPreferredNameUrl = f\"{generalConfig.MAIN_SERVER_URL}/get-user-preferred-name/\"\n\n# ------------------------------------------------------\n# The main async entrypoint\n# ------------------------------------------------------\nasync def entrypoint(ctx: JobContext) -> None:\n    \"\"\"\n    The function that livekit calls to start your worker logic.\n    \"\"\"\n\n    logger.info(\"Starting entrypoint\")\n\n    # Connect to the room and wait for the first participant.\n    # If your environment calls for a different approach (e.g. you wait for multiple participants),\n    # adapt as needed.\n    await ctx.connect(auto_subscribe=AutoSubscribe.AUDIO_ONLY)\n    participant = await ctx.wait_for_participant()\n    clerkUserId = participant.identity\n\n    # We'll use this event to block the entrypoint until the framework \n    # signals a shutdown.\n    shutdown_event = asyncio.Event()\n\n    # Define what to do upon shutdown. We'll set our event so the entrypoint can exit gracefully.\n    async def my_shutdown_hook() -> None:\n        logger.info(\"Shutdown hook called; setting shutdown_event.\")\n        shutdown_event.set()\n\n    # Register the shutdown callback\n    ctx.add_shutdown_callback(my_shutdown_hook)\n\n    # Now wrap everything in a try/finally to ensure we do\n    # any necessary cleanup. \n    async with aiohttp.ClientSession() as session:\n        try:\n            if generalConfig.TOKEN is None:\n                raise Exception(\"No token found in environment variables\")\n\n            # Gather user preferences and name in parallel\n            (userVacationPreferences, vacErr), (userPreferredName, nameErr) = await asyncio.gather(\n                getUserVacationPreferences(\n                    session, clerkUserId, generalConfig.TOKEN, getUserVacationPreferencesUrl\n                ),\n                getUserPreferredName(\n                    session, clerkUserId, generalConfig.TOKEN, getUserPreferredNameUrl\n                ),\n            )\n            if vacErr:\n                logger.error(\n                    \"Error getting userVacationPreferences (proceeding with empty preferences): %s\",\n                    vacErr\n                )\n            if nameErr:\n                logger.error(\n                    \"Error getting userPreferredName (proceeding with empty name): %s\",\n                    nameErr\n                )\n\n            # Setup LLM function context and chat context\n            fnc_ctx = llm.FunctionContext()\n            chat_ctx = llm.ChatContext()\n\n            @fnc_ctx.ai_callable(name=\"sendVacationBriefToTravelAgency\")\n            async def sendVacationBriefToTravelAgencyWrapper(\n                vacationBrief: Annotated[str, llm.TypeInfo(\n                    description=\"A complete description of all user vacation requirements gathered so far.\")\n                ],\n            ) -> str:\n                \"\"\"\n                Called once the vacation brief is finalized so that the travel agency \n                can provide the detailed vacation plan for the user.\n                \"\"\"\n                if generalConfig.TOKEN is None:\n                    raise Exception(\"No token found in environment variables\")\n                logger.info(\"sendVacationBriefToTravelAgencyWrapper called\")\n                async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=600)) as session1:\n                    agencyResponse = await sendVacationBriefToTravelAgency(\n                        session1,\n                        vacationBrief,\n                        generalConfig.TOKEN,\n                        clerkUserId,\n                        generateVacationPlanUrl,\n                    )\n                    return agencyResponse\n\n            @fnc_ctx.ai_callable(name=\"searchWeb\")\n            async def searchWebWrapper(\n                searchQuery: Annotated[str, llm.TypeInfo(\n                    description=\"The search phrase to query the web for up-to-date travel-related information.\")\n                ],\n            ) -> str:\n                \"\"\"\n                Called to search the web for up-to-date travel-related information.\n                \"\"\"\n                if generalConfig.TOKEN is None:\n                    raise Exception(\"No token found in environment variables\")\n                async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=600)) as session2:\n                    searchResponse = await searchWeb(\n                        session2,\n                        searchQuery,\n                        generalConfig.TOKEN,\n                        searchWebUrl,\n                    )\n                    logger.debug(\"Search response from search web API: %s\", searchResponse)\n                    return searchResponse\n\n            # Combine system instructions with user preferences\n            systemInstructionsWithPreferences = getSystemInstructions(\n                userVacationPreferences, userPreferredName\n            )\n            project = os.getenv('GOOGLE_CLOUD_PROJECT')\n            location = os.getenv('GOOGLE_CLOUD_LOCATION')\n            # Create the agent\n            agent = multimodal.MultimodalAgent(\n                model=google.beta.realtime.RealtimeModel(  # type: ignore\n                    voice=\"Aoede\",\n                    temperature=1.2,\n                    vertexai=True,\n                    project=project,\n                    location=location,\n                    enable_agent_audio_transcription=True,\n                    enable_user_audio_transcription=True,\n                    instructions=systemInstructionsWithPreferences,\n                ),\n                fnc_ctx=fnc_ctx,\n                chat_ctx=chat_ctx,\n            )\n\n            # Keep a running log of the conversation\n            conversation: List[str] = []\n\n            @agent.on(\"agent_speech_committed\")\n            def onAgentSpeechCommitted(msg: llm.ChatMessage) -> None:\n                logger.debug(\"agent_speech_committed: %s\", msg)\n                conversation.append(f\"Agent: {msg}\")\n                if generalConfig.TOKEN is None:\n                    raise Exception(\"No token found in environment variables\")\n                # Periodically save conversation\n                if len(conversation) % 3 == 0:\n                    asyncio.create_task(\n                        saveUserVacationPreferences(\n                            session,\n                            \"\\n\".join(conversation),\n                            clerkUserId,\n                            generalConfig.TOKEN,\n                            saveUserVacationPreferencesUrl,\n                        )\n                    )\n\n            @agent.on(\"user_speech_committed\")\n            def onUserSpeechCommitted(msg: llm.ChatMessage) -> None:\n                logger.debug(\"user_speech_committed: %s\", msg)\n                conversation.append(f\"User: {msg}\")\n\n            # Start the agent and immediately generate a reply\n            agent.start(ctx.room, participant)\n            agent.generate_reply()\n\n            logger.info(\"Agent is now active; waiting for shutdown event...\")\n            # This will block until 'shutdown_event.set()' is called in our shutdown hook\n            await shutdown_event.wait()\n\n        finally:\n            logger.info(\"entrypoint: cleaning up after shutdown_event was triggered.\")\n            # If you have tasks you created, gather or cancel them here.\n            # The aiohttp session is automatically closed by 'async with ...'.\n            # The agent itself might not require explicit cleanup, \n            # but if you do have \"agent.stop()\", you can call it here.\n            # agent.stop() if needed\n\n    logger.info(\"entrypoint completed\")\n\n# ------------------------------------------------------\n# Main entry point if run as a script\n# ------------------------------------------------------\nif __name__ == \"__main__\":\n    # Start a simple HTTP health server in the background\n    healthThread = threading.Thread(target=runHealthServer, daemon=True)\n    healthThread.start()\n\n    print(\"Health server started on 0.0.0.0:8080. Running main application...\")\n\n    # Optionally customize event-loop exception handling\n    loop = asyncio.get_event_loop()\n    loop.set_exception_handler(handleUnhandledExceptions)\n\n    # Let livekit manage the loop and run your worker\n    cli.run_app(\n        WorkerOptions(\n            entrypoint_fnc=entrypoint,\n            worker_type=WorkerType.ROOM,\n            shutdown_process_timeout=120.0,\n        )\n    )\n```\n\nAnd my env variables:\n\n```\nENV=dev\n\nLIVEKIT_API_KEY=\"secret fake\"\nLIVEKIT_API_SECRET=\"secret fake\"\nLIVEKIT_URL=\"wss://agentplayground-0dbaz01k.livekit.cloud\"\n\nGOOGLE_CLOUD_PROJECT=vacationator\nGOOGLE_CLOUD_LOCATION=us-central1\nGOOGLE_GENAI_USE_VERTEXAI=True\nGOOGLE_APPLICATION_CREDENTIALS='./service-account-file.json'\n\nTOKEN=secretfake\nMAIN_SERVER_URL=http://localhost:8000\n```\n\n\nI get this error on livekit agent when running it:\n\n{\"message\": \"Error in _main_task\", \"level\": \"ERROR\", \"name\": \"livekit.plugins.google\", \"exc_info\": \"Traceback (most recent call last):\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/livekit/agents/utils/log.py\\\", line 16, in async_fn_logs\\n    return await fn(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/livekit/plugins/google/beta/realtime/transcriber.py\\\", line 160, in _main_task\\n    async with self._client.aio.live.connect(\\n  File \\\"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py\\\", line 204, in __aenter__\\n    return await anext(self.gen)\\n           ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/google/genai/live.py\\\", line 726, in connect\\n    async with connect(uri, additional_headers=headers) as ws:\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/asyncio/client.py\\\", line 487, in __aenter__\\n    return await self\\n           ^^^^^^^^^^\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/asyncio/client.py\\\", line 446, in __await_impl__\\n    await self.connection.handshake(*self.handshake_args)\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/asyncio/client.py\\\", line 104, in handshake\\n    raise self.protocol.handshake_exc\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/client.py\\\", line 340, in parse\\n    self.process_response(response)\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/client.py\\\", line 151, in process_response\\n    raise InvalidStatus(response)\\nwebsockets.exceptions.InvalidStatus: server rejected WebSocket connection: HTTP 400\", \"timestamp\": \"2025-03-27T15:43:58.080936+00:00\"}\n{\"message\": \"Error in _main_task\\nTraceback (most recent call last):\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/livekit/agents/utils/log.py\\\", line 16, in async_fn_logs\\n    return await fn(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/livekit/plugins/google/beta/realtime/transcriber.py\\\", line 160, in _main_task\\n    async with self._client.aio.live.connect(\\n  File \\\"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py\\\", line 204, in __aenter__\\n    return await anext(self.gen)\\n           ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/google/genai/live.py\\\", line 726, in connect\\n    async with connect(uri, additional_headers=headers) as ws:\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/asyncio/client.py\\\", line 487, in __aenter__\\n    return await self\\n           ^^^^^^^^^^\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/asyncio/client.py\\\", line 446, in __await_impl__\\n    await self.connection.handshake(*self.handshake_args)\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/asyncio/client.py\\\", line 104, in handshake\\n    raise self.protocol.handshake_exc\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/client.py\\\", line 340, in parse\\n    self.process_response(response)\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/client.py\\\", line 151, in process_response\\n    raise InvalidStatus(response)\\nwebsockets.exceptions.InvalidStatus: server rejected WebSocket connection: HTTP 400\", \"level\": \"ERROR\", \"name\": \"livekit.plugins.google\", \"pid\": 40360, \"job_id\": \"AJ_v5JQ7UKGDggE\", \"timestamp\": \"2025-03-27T15:43:58.080936+00:00\"}\n2025-03-27 16:43:58,080 - ERROR livekit.plugins.google - Error in _main_task\nTraceback (most recent call last):\n  File \"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/livekit/plugins/google/beta/realtime/transcriber.py\", line 160, in _main_task\n    async with self._client.aio.live.connect(\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py\", line 204, in __aenter__\n    return await anext(self.gen)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/google/genai/live.py\", line 726, in connect\n    async with connect(uri, additional_headers=headers) as ws:\n  File \"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/asyncio/client.py\", line 487, in __aenter__\n    return await self\n           ^^^^^^^^^^\n  File \"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/asyncio/client.py\", line 446, in __await_impl__\n    await self.connection.handshake(*self.handshake_args)\n  File \"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/asyncio/client.py\", line 104, in handshake\n    raise self.protocol.handshake_exc\n  File \"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/client.py\", line 340, in parse\n    self.process_response(response)\n  File \"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/client.py\", line 151, in process_response\n    raise InvalidStatus(response)\nwebsockets.exceptions.InvalidStatus: server rejected WebSocket connection: HTTP 400 {\"pid\": 40360, \"job_id\": \"AJ_v5JQ7UKGDggE\"}\n{\"message\": \"Error in _main_task\", \"level\": \"ERROR\", \"name\": \"livekit.plugins.google\", \"exc_info\": \"Traceback (most recent call last):\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/livekit/agents/utils/log.py\\\", line 16, in async_fn_logs\\n    return await fn(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/livekit/plugins/google/beta/realtime/realtime_api.py\\\", line 540, in _main_task\\n    async with self._client.aio.live.connect(\\n  File \\\"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py\\\", line 204, in __aenter__\\n    return await anext(self.gen)\\n           ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/google/genai/live.py\\\", line 726, in connect\\n    async with connect(uri, additional_headers=headers) as ws:\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/asyncio/client.py\\\", line 487, in __aenter__\\n    return await self\\n           ^^^^^^^^^^\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/asyncio/client.py\\\", line 446, in __await_impl__\\n    await self.connection.handshake(*self.handshake_args)\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/asyncio/client.py\\\", line 104, in handshake\\n    raise self.protocol.handshake_exc\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/client.py\\\", line 340, in parse\\n    self.process_response(response)\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/client.py\\\", line 151, in process_response\\n    raise InvalidStatus(response)\\nwebsockets.exceptions.InvalidStatus: server rejected WebSocket connection: HTTP 400\", \"timestamp\": \"2025-03-27T15:43:58.130659+00:00\"}\n{\"message\": \"Error in _main_task\\nTraceback (most recent call last):\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/livekit/agents/utils/log.py\\\", line 16, in async_fn_logs\\n    return await fn(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/livekit/plugins/google/beta/realtime/realtime_api.py\\\", line 540, in _main_task\\n    async with self._client.aio.live.connect(\\n  File \\\"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py\\\", line 204, in __aenter__\\n    return await anext(self.gen)\\n           ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/google/genai/live.py\\\", line 726, in connect\\n    async with connect(uri, additional_headers=headers) as ws:\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/asyncio/client.py\\\", line 487, in __aenter__\\n    return await self\\n           ^^^^^^^^^^\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/asyncio/client.py\\\", line 446, in __await_impl__\\n    await self.connection.handshake(*self.handshake_args)\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/asyncio/client.py\\\", line 104, in handshake\\n    raise self.protocol.handshake_exc\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/client.py\\\", line 340, in parse\\n    self.process_response(response)\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/client.py\\\", line 151, in process_response\\n    raise InvalidStatus(response)\\nwebsockets.exceptions.InvalidStatus: server rejected WebSocket connection: HTTP 400\", \"level\": \"ERROR\", \"name\": \"livekit.plugins.google\", \"pid\": 40360, \"job_id\": \"AJ_v5JQ7UKGDggE\", \"timestamp\": \"2025-03-27T15:43:58.130659+00:00\"}\n2025-03-27 16:43:58,130 - ERROR livekit.plugins.google - Error in _main_task\nTraceback (most recent call last):\n  File \"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/livekit/plugins/google/beta/realtime/realtime_api.py\", line 540, in _main_task\n    async with self._client.aio.live.connect(\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py\", line 204, in __aenter__\n    return await anext(self.gen)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/google/genai/live.py\", line 726, in connect\n    async with connect(uri, additional_headers=headers) as ws:\n  File \"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/asyncio/client.py\", line 487, in __aenter__\n    return await self\n           ^^^^^^^^^^\n  File \"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/asyncio/client.py\", line 446, in __await_impl__\n    await self.connection.handshake(*self.handshake_args)\n  File \"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/asyncio/client.py\", line 104, in handshake\n    raise self.protocol.handshake_exc\n  File \"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/client.py\", line 340, in parse\n    self.process_response(response)\n  File \"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/client.py\", line 151, in process_response\n    raise InvalidStatus(response)\nwebsockets.exceptions.InvalidStatus: server rejected WebSocket connection: HTTP 400 {\"pid\": 40360, \"job_id\": \"AJ_v5JQ7UKGDggE\"}\n^C{\"message\": \"tungstenite::protocol:666:tungstenite::protocol - Received close frame: Some(CloseFrame { code: Normal, reason: \\\"\\\" })\", \"level\": \"DEBUG\", \"name\": \"livekit\", \"timestamp\": \"2025-03-27T15:44:12.287075+00:00\"}\n{\"message\": \"tungstenite::protocol:666:tungstenite::protocol - Received close frame: Some(CloseFrame { code: Normal, reason: \\\"\\\" })\", \"level\": \"DEBUG\", \"name\": \"livekit\", \"pid\": 40360, \"job_id\": \"AJ_v5JQ7UKGDggE\", \"timestamp\": \"2025-03-27T15:44:12.287075+00:00\"}\n2025-03-27 16:44:12,287 - DEBUG livekit - tungstenite::protocol:666:tungstenite::protocol - Received close frame: Some(CloseFrame { code: Normal, reason: \"\" }) {\"pid\": 40360, \"job_id\": \"AJ_v5JQ7UKGDggE\"}\n{\"message\": \"livekit::room:1191:livekit::room - disconnected from room with reason: ClientInitiated\", \"level\": \"INFO\", \"name\": \"livekit\", \"timestamp\": \"2025-03-27T15:44:12.290327+00:00\"}\n{\"message\": \"livekit::room:1191:livekit::room - disconnected from room with reason: ClientInitiated\", \"level\": \"INFO\", \"name\": \"livekit\", \"pid\": 40360, \"job_id\": \"AJ_v5JQ7UKGDggE\", \"timestamp\": \"2025-03-27T15:44:12.290327+00:00\"}\n2025-03-27 16:44:12,290 - INFO livekit - livekit::room:1191:livekit::room - disconnected from room with reason: ClientInitiated {\"pid\": 40360, \"job_id\": \"AJ_v5JQ7UKGDggE\"}\n{\"message\": \"Task exception was never retrieved\\nfuture: <Task finished name='gemini-realtime-transcriber' coro=<TranscriberSession._main_task() done, defined at /Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/livekit/agents/utils/log.py:13> exception=InvalidStatus(Response(status_code=400, reason_phrase='Bad Request', headers=Headers([('Content-Type', 'text/html; charset=UTF-8'), ('Referrer-Policy', 'no-referrer'), ('Content-Length', '1555'), ('Date', 'Thu, 27 Mar 2025 15:43:58 GMT'), ('Alt-Svc', 'h3=\\\":443\\\"; ma=2592000,h3-29=\\\":443\\\"; ma=2592000'), ('Connection', 'close')]), body=bytearray(b'<!DOCTYPE html>\\\\n<html lang=en>\\\\n  <meta charset=utf-8>\\\\n  <meta name=viewport content=\\\"initial-scale=1, minimum-scale=1, width=device-width\\\">\\\\n  <title>Error 400 (Bad Request)!!1</title>\\\\n  <style>\\\\n    *{margin:0;padding:0}html,code{font:15px/22px arial,sans-serif}html{background:#fff;color:#222;padding:15px}body{margin:7% auto 0;max-width:390px;min-height:180px;padding:30px 0 15px}* > body{background:url(//www.google.com/images/errors/robot.png) 100% 5px no-repeat;padding-right:205px}p{margin:11px 0 22px;overflow:hidden}ins{color:#777;text-decoration:none}a img{border:0}@media screen and (max-width:772px){body{background:none;margin-top:0;max-width:none;padding-right:0}}#logo{background:url(//www.google.com/images/branding/googlelogo/1x/googlelogo_color_150x54dp.png) no-repeat;margin-left:-5px}@media only screen and (min-resolution:192dpi){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat 0% 0%/100% 100%;-moz-border-image:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) 0}}@media only screen and (-webkit-min-device-pixel-ratio:2){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat;-webkit-background-size:100% 100%}}#logo{display:inline-block;height:54px;width:150px}\\\\n  </style>\\\\n  <a href=//www.google.com/><span id=logo aria-label=Google></span></a>\\\\n  <p><b>400.</b> <ins>That\\\\xe2\\\\x80\\\\x99s an error.</ins>\\\\n  <p>Your client has issued a malformed or illegal request.  <ins>That\\\\xe2\\\\x80\\\\x99s all we know.</ins>\\\\n'), _exception=InvalidStatus(...)))>\", \"level\": \"ERROR\", \"name\": \"asyncio\", \"exc_info\": \"Traceback (most recent call last):\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/livekit/agents/utils/log.py\\\", line 16, in async_fn_logs\\n    return await fn(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/livekit/plugins/google/beta/realtime/transcriber.py\\\", line 160, in _main_task\\n    async with self._client.aio.live.connect(\\n  File \\\"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py\\\", line 204, in __aenter__\\n    return await anext(self.gen)\\n           ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/google/genai/live.py\\\", line 726, in connect\\n    async with connect(uri, additional_headers=headers) as ws:\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/asyncio/client.py\\\", line 487, in __aenter__\\n    return await self\\n           ^^^^^^^^^^\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/asyncio/client.py\\\", line 446, in __await_impl__\\n    await self.connection.handshake(*self.handshake_args)\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/asyncio/client.py\\\", line 104, in handshake\\n    raise self.protocol.handshake_exc\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/client.py\\\", line 340, in parse\\n    self.process_response(response)\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/client.py\\\", line 151, in process_response\\n    raise InvalidStatus(response)\\nwebsockets.exceptions.InvalidStatus: server rejected WebSocket connection: HTTP 400\", \"timestamp\": \"2025-03-27T15:44:12.327337+00:00\"}\n{\"message\": \"Task exception was never retrieved\\nfuture: <Task finished name='gemini-realtime-session' coro=<GeminiRealtimeSession._main_task() done, defined at /Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/livekit/agents/utils/log.py:13> exception=InvalidStatus(Response(status_code=400, reason_phrase='Bad Request', headers=Headers([('Content-Type', 'text/html; charset=UTF-8'), ('Referrer-Policy', 'no-referrer'), ('Content-Length', '1555'), ('Date', 'Thu, 27 Mar 2025 15:43:58 GMT'), ('Alt-Svc', 'h3=\\\":443\\\"; ma=2592000,h3-29=\\\":443\\\"; ma=2592000'), ('Connection', 'close')]), body=bytearray(b'<!DOCTYPE html>\\\\n<html lang=en>\\\\n  <meta charset=utf-8>\\\\n  <meta name=viewport content=\\\"initial-scale=1, minimum-scale=1, width=device-width\\\">\\\\n  <title>Error 400 (Bad Request)!!1</title>\\\\n  <style>\\\\n    *{margin:0;padding:0}html,code{font:15px/22px arial,sans-serif}html{background:#fff;color:#222;padding:15px}body{margin:7% auto 0;max-width:390px;min-height:180px;padding:30px 0 15px}* > body{background:url(//www.google.com/images/errors/robot.png) 100% 5px no-repeat;padding-right:205px}p{margin:11px 0 22px;overflow:hidden}ins{color:#777;text-decoration:none}a img{border:0}@media screen and (max-width:772px){body{background:none;margin-top:0;max-width:none;padding-right:0}}#logo{background:url(//www.google.com/images/branding/googlelogo/1x/googlelogo_color_150x54dp.png) no-repeat;margin-left:-5px}@media only screen and (min-resolution:192dpi){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat 0% 0%/100% 100%;-moz-border-image:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) 0}}@media only screen and (-webkit-min-device-pixel-ratio:2){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat;-webkit-background-size:100% 100%}}#logo{display:inline-block;height:54px;width:150px}\\\\n  </style>\\\\n  <a href=//www.google.com/><span id=logo aria-label=Google></span></a>\\\\n  <p><b>400.</b> <ins>That\\\\xe2\\\\x80\\\\x99s an error.</ins>\\\\n  <p>Your client has issued a malformed or illegal request.  <ins>That\\\\xe2\\\\x80\\\\x99s all we know.</ins>\\\\n'), _exception=InvalidStatus(...)))>\", \"level\": \"ERROR\", \"name\": \"asyncio\", \"exc_info\": \"Traceback (most recent call last):\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/livekit/agents/utils/log.py\\\", line 16, in async_fn_logs\\n    return await fn(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/livekit/plugins/google/beta/realtime/realtime_api.py\\\", line 540, in _main_task\\n    async with self._client.aio.live.connect(\\n  File \\\"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py\\\", line 204, in __aenter__\\n    return await anext(self.gen)\\n           ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/google/genai/live.py\\\", line 726, in connect\\n    async with connect(uri, additional_headers=headers) as ws:\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/asyncio/client.py\\\", line 487, in __aenter__\\n    return await self\\n           ^^^^^^^^^^\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/asyncio/client.py\\\", line 446, in __await_impl__\\n    await self.connection.handshake(*self.handshake_args)\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/asyncio/client.py\\\", line 104, in handshake\\n    raise self.protocol.handshake_exc\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/client.py\\\", line 340, in parse\\n    self.process_response(response)\\n  File \\\"/Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/websockets/client.py\\\", line 151, in process_response\\n    raise InvalidStatus(response)\\nwebsockets.exceptions.InvalidStatus: server rejected WebSocket connection: HTTP 400\", \"timestamp\": \"2025-03-27T15:44:12.328325+00:00\"}\n{\"message\": \"Task was destroyed but it is pending!\\ntask: <Task pending name='Task-23' coro=<MultimodalAgent._main_task() running at /Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/livekit/agents/utils/log.py:16> wait_for=<Future pending cb=[Task.task_wakeup()]>>\", \"level\": \"ERROR\", \"name\": \"asyncio\", \"timestamp\": \"2025-03-27T15:44:12.328940+00:00\"}\n{\"message\": \"Task was destroyed but it is pending!\\ntask: <Task pending name='Task-21' coro=<STTSegmentsForwarder._run() running at /Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/livekit/agents/transcription/stt_forwarder.py:64> wait_for=<Future pending cb=[Task.task_wakeup()]>>\", \"level\": \"ERROR\", \"name\": \"asyncio\", \"timestamp\": \"2025-03-27T15:44:12.329022+00:00\"}\n{\"message\": \"Task was destroyed but it is pending!\\ntask: <Task pending name='Task-26' coro=<STTSegmentsForwarder._run() running at /Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/livekit/agents/transcription/stt_forwarder.py:64> wait_for=<Future pending cb=[Task.task_wakeup()]>>\", \"level\": \"ERROR\", \"name\": \"asyncio\", \"timestamp\": \"2025-03-27T15:44:12.329092+00:00\"}\n{\"message\": \"Task was destroyed but it is pending!\\ntask: <Task pending name='gemini-model-transcriber' coro=<ModelTranscriber._main_task() running at /Users/thomasbeaudouin/Documents/dev/personal/livekit-agent-vacationator/venv/lib/python3.11/site-packages/livekit/agents/utils/log.py:16> wait_for=<Future pending cb=[Task.task_wakeup()]>>\", \"level\": \"ERROR\", \"name\": \"asyncio\", \"timestamp\": \"2025-03-27T15:44:12.329143+00:00\"}\n^CException ignored in atexit callback: <function _exit_function at 0x10add0040>\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/util.py\", line 357, in _exit_function\n    p.join()\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 149, in join\n    res = self._popen.wait(timeout)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_fork.py\", line 43, in wait\n    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_fork.py\", line 27, in poll\n    pid, sts = os.waitpid(self.pid, flag)",
      "state": "closed",
      "author": "tbeaudouin05",
      "author_type": "User",
      "created_at": "2025-03-27T15:46:17Z",
      "updated_at": "2025-04-17T14:10:13Z",
      "closed_at": "2025-04-17T14:10:12Z",
      "labels": [
        "bug",
        "question",
        "plugins"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1761/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1761",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1761",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:32.693246",
      "comments": [
        {
          "author": "davidzhao",
          "body": "can you give it a shot on the main branch with Agents 1.0?",
          "created_at": "2025-04-13T07:26:42Z"
        },
        {
          "author": "jayeshp19",
          "body": "This is fixed in latest model closing this.",
          "created_at": "2025-04-17T14:10:12Z"
        }
      ]
    },
    {
      "issue_number": 2026,
      "title": "Unable to import noise_cancellation",
      "body": "below import is failing\n```\nfrom livekit.plugins import (\n    noise_cancellation\n)\n```\n\n\n\nAs per below dependencies\n\n- requirement.txt\n\n```\nlivekit-agents>=1.0.11\nlivekit-plugins-openai>=1.0.11\nlivekit-plugins-azure>=1.0.11\nlivekit-plugins-silero>=1.0.13\nlivekit-plugins-turn-detector>=1.0.11\npython-dotenv~=1.0\nnumpy\ncachetools\n```\n\n\n",
      "state": "closed",
      "author": "codecurry",
      "author_type": "User",
      "created_at": "2025-04-17T07:08:52Z",
      "updated_at": "2025-04-17T07:50:45Z",
      "closed_at": "2025-04-17T07:50:45Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2026/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2026",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2026",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:33.001423",
      "comments": []
    },
    {
      "issue_number": 1847,
      "title": "compability issue",
      "body": "<!--\nHello! Thanks for taking the time to file a bug report.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already reported this issue.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n-->\n\nAnyone have facing with the live kit latest version 1.0rc compatibility issues?  With realtime model\n\n<img width=\"969\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/c57c610d-02ac-441a-9c8d-1c93a86bbd8a\" />",
      "state": "closed",
      "author": "Manish06097",
      "author_type": "User",
      "created_at": "2025-04-01T13:22:32Z",
      "updated_at": "2025-04-17T07:10:37Z",
      "closed_at": "2025-04-17T07:10:36Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1847/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1847",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1847",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:33.001444",
      "comments": [
        {
          "author": "ChenghaoMou",
          "body": "You have to install the RC versions of other related packages as well:\n\nfrom the README\n```bash\npip install livekit-agents[openai,silero,deepgram,cartesia,turn-detector]~=1.0rc\n```\n\nofc, change it to your plugins.",
          "created_at": "2025-04-02T12:10:06Z"
        },
        {
          "author": "Manish06097",
          "body": "<img width=\"984\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/984d5624-5501-406f-b9f7-be7f4201839a\" />\n\nthis is  i have done and i am getting this error\n\n<img width=\"973\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/118c837c-deea-4fd2-85fc-9add5edbf6d6\" />",
          "created_at": "2025-04-02T12:24:00Z"
        },
        {
          "author": "Manish06097",
          "body": "import logging\nfrom dataclasses import dataclass, field\nfrom typing import Annotated, Optional\n\nimport yaml\nfrom dotenv import load_dotenv\nfrom pydantic import Field\n\nfrom livekit.agents import JobContext, WorkerOptions, cli, llm\nfrom livekit.agents.llm import function_tool\nfrom livekit.agents.voice",
          "created_at": "2025-04-02T12:24:42Z"
        },
        {
          "author": "ChenghaoMou",
          "body": "ah, the google realtime. I don't think it works yet. See https://github.com/livekit/agents/issues/1718  ",
          "created_at": "2025-04-02T17:12:56Z"
        },
        {
          "author": "davidzhao",
          "body": "Google realtime has been fixed in the latest version.",
          "created_at": "2025-04-17T07:10:36Z"
        }
      ]
    },
    {
      "issue_number": 1844,
      "title": "text response from OAI realtime model",
      "body": "After update_chat_ctx with some messages for the OAI realtime model, it may response in text mode\n\n```\n2025-04-01 19:50:40,170 - DEBUG livekit.plugins.openai - <<< {'type': 'response.content_part.added', 'event_id': 'event_BHUQaO18qtkV5VSaIZDJC', 'response_id': 'resp_BHUQZxwkT6dfxKQ9McgPW', 'item_id': 'item_BHUQZEFPvyNbuXAHiG4jN', 'output_index': 0, 'content_index': 0, 'part': {'type': 'text', 'text': ''}} {\"pid\": 2880111, \"job_id\": \"AJ_Rav3kLSZ8C8C\"}\n2025-04-01 19:50:40,170 - DEBUG livekit.plugins.openai - <<< {'type': 'response.text.delta', 'event_id': 'event_BHUQaGZmZqRu0z5nmBVWV', 'response_id': 'resp_BHUQZxwkT6dfxKQ9McgPW', 'item_id': 'item_BHUQZEFPvyNbuXAHiG4jN', 'output_index': 0, 'content_index': 0, 'delta': 'Great'} {\"pid\": 2880111, \"job_id\": \"AJ_Rav3kLSZ8C8C\"}\n```\n\nWe may still need the recovery logic from 0.x https://github.com/livekit/agents/blob/0.x/livekit-plugins/livekit-plugins-openai/livekit/plugins/openai/realtime/realtime_model.py#L1144",
      "state": "open",
      "author": "longcw",
      "author_type": "User",
      "created_at": "2025-04-01T11:58:41Z",
      "updated_at": "2025-04-16T11:31:56Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1844/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1844",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1844",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:35.134524",
      "comments": [
        {
          "author": "longcw",
          "body": "add a warning and send the text to output https://github.com/livekit/agents/pull/1855",
          "created_at": "2025-04-02T07:54:12Z"
        },
        {
          "author": "longcw",
          "body": "This is a known issue from OpenAI realtime model https://community.openai.com/t/trouble-loading-previous-messages-with-realtime-api",
          "created_at": "2025-04-02T08:15:26Z"
        },
        {
          "author": "davidzhao",
          "body": "it'd be great to port over the recovery logic.",
          "created_at": "2025-04-03T21:52:28Z"
        },
        {
          "author": "longcw",
          "body": "https://github.com/livekit/agents/pull/2015",
          "created_at": "2025-04-16T11:31:55Z"
        }
      ]
    },
    {
      "issue_number": 2006,
      "title": "Google Realtime Import Causes Runtime Error",
      "body": "The import at https://github.com/livekit/agents/blob/6684eeee61fa8fe5a4967727822a43e69e280023/livekit-agents/livekit/agents/voice/agent_activity.py#L43 can cause Runtime Error when the plugin tries to register itself when initializing, but the initializing could happen in a different thread (the main thread is testing fastapi endpoints)\n\nstack trace when calling a fastapi endpoint:\n\n```\n.venv/lib/python3.12/site-packages/fastapi/routing.py:301: in app\n    raw_response = await run_endpoint_function(\n.venv/lib/python3.12/site-packages/logfire/_internal/integrations/fastapi.py:138: in patched_run_endpoint_function\n    return await instrumentation.run_endpoint_function(\n.venv/lib/python3.12/site-packages/logfire/_internal/integrations/fastapi.py:261: in run_endpoint_function\n    return await original_run_endpoint_function(dependant=dependant, values=values, **kwargs)\n.venv/lib/python3.12/site-packages/fastapi/routing.py:212: in run_endpoint_function\n    return await dependant.call(**values)\nsrc/ai_workflow/ai/meeting.py:239: in leave\n    from ai_worker.utils.metrics import lk_meetings\n.venv/lib/python3.12/site-packages/ai_worker/utils/metrics.py:5: in <module>\n    from ai_worker.utils.logger import logger\n.venv/lib/python3.12/site-packages/ai_worker/utils/logger.py:14: in <module>\n    from livekit.agents import utils\n.venv/lib/python3.12/site-packages/livekit/agents/__init__.py:43: in <module>\n    from .voice import (\n.venv/lib/python3.12/site-packages/livekit/agents/voice/__init__.py:2: in <module>\n    from .agent_session import AgentSession\n.venv/lib/python3.12/site-packages/livekit/agents/voice/agent_session.py:19: in <module>\n    from .agent_activity import AgentActivity\n.venv/lib/python3.12/site-packages/livekit/agents/voice/agent_activity.py:43: in <module>\n    from livekit.plugins.google.beta.realtime.realtime_api import (\n.venv/lib/python3.12/site-packages/livekit/plugins/google/__init__.py:32: in <module>\n    Plugin.register_plugin(GooglePlugin())\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <class 'livekit.agents.plugin.Plugin'>, plugin = <livekit.plugins.google.GooglePlugin object at 0x14826f680>\n\n    @classmethod\n    def register_plugin(cls, plugin: Plugin) -> None:\n        if threading.current_thread() != threading.main_thread():\n>           raise RuntimeError(\"Plugins must be registered on the main thread\")\nE           RuntimeError: Plugins must be registered on the main thread\n\n.venv/lib/python3.12/site-packages/livekit/agents/plugin.py:33: RuntimeError\n```\n\nThe easiest way from what I can see is to add a Runtime Error catch. Let me know if I am missing something.",
      "state": "closed",
      "author": "ChenghaoMou",
      "author_type": "User",
      "created_at": "2025-04-15T12:48:06Z",
      "updated_at": "2025-04-16T10:55:11Z",
      "closed_at": "2025-04-16T10:55:10Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2006/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2006",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2006",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:35.412024",
      "comments": [
        {
          "author": "ChenghaoMou",
          "body": "Fixed in `1.0.13`",
          "created_at": "2025-04-16T10:55:10Z"
        }
      ]
    },
    {
      "issue_number": 1520,
      "title": "Deepgram update_options - Error 400 When Changing Language",
      "body": "<!--\nHello! Thanks for taking the time to file a bug report.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already reported this issue.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n-->\n\nHi,\n\nafter some testing with the `update_options` function, I noticed the one related to plugin `livekit-plugins-deepgram` returns a 400 'Invalid Response Status'. Actually, the STT is able to change language without problems, but just before that, it throws an `aiohttp.client_exceptions.WSServerHandshakeError`.\n\nHere is an example:\n\n```\nagent = AgentCallContext.get_current().agent\n\nlogger.info(f\"setting language to {new_language}\")\n\nmatch new_language:\n    case \"German\":\n        deepgram.STT.update_options(agent.stt, language=\"de\")\n        cartesia.TTS.update_options(agent.tts, language=\"de\", voice=\"119e03e4...de2b6639\")\n```\n\nI think it originates from the SpeechStream keepAlive... does closing and reopening the SpeechStream work in this case?\n\nHere the exception:\n```\n2025-02-19 08:14:44,167 - ERROR livekit.agents.pipeline - Error in _recognize_task\nTraceback (most recent call last):\n  File \"/home/.pyenv/versions/3.13.0/envs/SystemPromptAssistant/lib/python3.13/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/.pyenv/versions/3.13.0/envs/SystemPromptAssistant/lib/python3.13/site-packages/livekit/agents/pipeline/human_input.py\", line 150, in _recognize_task\n    await asyncio.gather(*tasks)\n  File \"/home/.pyenv/versions/3.13.0/envs/SystemPromptAssistant/lib/python3.13/site-packages/livekit/agents/pipeline/human_input.py\", line 136, in _stt_stream_co\n    async for ev in stt_stream:\n    ...<5 lines>...\n            self.emit(\"interim_transcript\", ev)\n  File \"/home/.pyenv/versions/3.13.0/envs/SystemPromptAssistant/lib/python3.13/site-packages/livekit/agents/stt/stt.py\", line 321, in __anext__\n    raise exc from None\n  File \"/home/.pyenv/versions/3.13.0/envs/SystemPromptAssistant/lib/python3.13/site-packages/livekit/agents/stt/stt.py\", line 219, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/.pyenv/versions/3.13.0/envs/SystemPromptAssistant/lib/python3.13/site-packages/livekit/plugins/deepgram/stt.py\", line 527, in _run\n    ws = await self._connect_ws()\n         ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/.pyenv/versions/3.13.0/envs/SystemPromptAssistant/lib/python3.13/site-packages/livekit/plugins/deepgram/stt.py\", line 580, in _connect_ws\n    ws = await asyncio.wait_for(\n         ^^^^^^^^^^^^^^^^^^^^^^^\n    ...<5 lines>...\n    )\n    ^\n  File \"/home/.pyenv/versions/3.13.0/lib/python3.13/asyncio/tasks.py\", line 507, in wait_for\n    return await fut\n           ^^^^^^^^^\n  File \"/home/.pyenv/versions/3.13.0/envs/SystemPromptAssistant/lib/python3.13/site-packages/aiohttp/client.py\", line 1021, in _ws_connect\n    raise WSServerHandshakeError(\n    ...<5 lines>...\n    )\naiohttp.client_exceptions.WSServerHandshakeError: 400, message='Invalid response status', url='wss://api.deepgram.com/v1/listen?model=nova-3&punctuate=true&smart_format=true&no_delay=false&interim_results=true&encoding=linear16&vad_events=true&sample_rate=16000&channels=1&endpointing=25&filler_words=true&profanity_filter=false&language=de'\n```\n\nThank you!",
      "state": "closed",
      "author": "giuliog97",
      "author_type": "User",
      "created_at": "2025-02-19T07:26:00Z",
      "updated_at": "2025-04-16T07:54:25Z",
      "closed_at": "2025-04-16T07:54:23Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1520/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1520",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1520",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:35.714261",
      "comments": [
        {
          "author": "giuliog97",
          "body": "**Note:** this only happens with Deepgram's model `nova-3`. With `nova-2-general` or similar it works just fine",
          "created_at": "2025-02-19T20:32:21Z"
        },
        {
          "author": "giuliog97",
          "body": "TL;DR: only nova-2 / nova-2-general supports German at the moment",
          "created_at": "2025-04-16T07:54:24Z"
        }
      ]
    },
    {
      "issue_number": 1472,
      "title": "AgentDispatches remain active even though the worker is down",
      "body": "During worker node failure, all agent instances in that worker will terminate. Agent dispatches will not be re-created automatically.\nThere is a problem in the agent dispatch handling in Livekit. It appears as if Livekit tries to terminate the jobs, but this is not successful since the worker can't be reached anymore. The AgentDispatches will remain listed as active. \n",
      "state": "open",
      "author": "royatanu94",
      "author_type": "User",
      "created_at": "2025-02-10T10:59:01Z",
      "updated_at": "2025-04-16T07:49:27Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1472/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1472",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1472",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:35.943303",
      "comments": [
        {
          "author": "royatanu94",
          "body": "Our intention is “re-dispatch jobs associated with a worker during worker failure”\n\nThere is a problem in the agent dispatch handling in Livekit. It appears as if Livekit tries to terminate the jobs, but this is not successful since the worker can't be reached anymore. The AgentDispatches will remai",
          "created_at": "2025-03-03T14:28:01Z"
        },
        {
          "author": "davidzhao",
          "body": "LiveKit Cloud handles this automatically. It requires additional services to be able to perform re-dispatches of the same job.\n\nCurrently there aren't plans to port that service into the self-hosted livekit agent, but it's possible to build it externally as an agent-watcher",
          "created_at": "2025-03-04T19:02:51Z"
        },
        {
          "author": "royatanu94",
          "body": "@davidzhao \nCan you please provide some help to build  agent-watcher externally ? ",
          "created_at": "2025-04-16T07:49:26Z"
        }
      ]
    },
    {
      "issue_number": 1924,
      "title": "Noise Cancellation Windows",
      "body": "I am getting the following error when trying to install the requirements file on windows:\n\nERROR: Could not find a version that satisfies the requirement livekit-plugins-noise-cancellation==0.2.1 (from versions: none)\nERROR: No matching distribution found for livekit-plugins-noise-cancellation==0.2.1 \n\n\nAny help would be appreciated.\n\nChris",
      "state": "open",
      "author": "crivera",
      "author_type": "User",
      "created_at": "2025-04-08T14:18:06Z",
      "updated_at": "2025-04-16T06:07:20Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1924/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1924",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1924",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:36.143055",
      "comments": [
        {
          "author": "thaneeshr",
          "body": "Same Error for me while trying in Windows",
          "created_at": "2025-04-14T16:51:33Z"
        },
        {
          "author": "davidzhao",
          "body": "we have not released a windows-compatible build yet. it's being worked on and will be available soon",
          "created_at": "2025-04-16T06:07:20Z"
        }
      ]
    },
    {
      "issue_number": 1973,
      "title": "AttributeError: type object 'RealtimeModel' has no attribute 'with_azure'",
      "body": "Hello team,\nWe are evaluating Livekit for using it for Voice AI agents using Azure Open AI realtime. However we are seeing below error.\n\nError Details: \nAttributeError: type object 'RealtimeModel' has no attribute 'with_azure'\n\nCode -\n\nfrom livekit.plugins import (\n    cartesia,\n    openai)\nllm = openai.realtime.RealtimeModel.with_azure\n\n\nhere is my requirement file - \n\nlivekit-agents>=1.0.11\nlivekit-plugins-openai>=1.0.11\nlivekit-plugins-cartesia>=1.0.11\nlivekit-plugins-azure>=1.0.11\nlivekit-plugins-elevenlabs\npython-dotenv~=1.0\nnumpy",
      "state": "closed",
      "author": "codecurry",
      "author_type": "User",
      "created_at": "2025-04-11T12:03:45Z",
      "updated_at": "2025-04-16T05:05:42Z",
      "closed_at": "2025-04-15T03:54:20Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1973/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1973",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1973",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:36.346608",
      "comments": [
        {
          "author": "mshahbazm",
          "body": "Having the same issue",
          "created_at": "2025-04-14T05:54:30Z"
        },
        {
          "author": "julianrcks",
          "body": "Same Issue!",
          "created_at": "2025-04-14T18:46:23Z"
        },
        {
          "author": "davidzhao",
          "body": "this is fixed in #1975 and will be released soon",
          "created_at": "2025-04-15T06:09:49Z"
        },
        {
          "author": "codecurry",
          "body": "@davidzhao  thanks. THough we were evaluating the same on python, we extensively use nodejs in our organization. Any plans to release the same for nodejs as well?",
          "created_at": "2025-04-15T16:59:45Z"
        },
        {
          "author": "davidzhao",
          "body": "it's available for node today: https://github.com/livekit/agents-js/blob/main/plugins/openai/src/realtime/realtime_model.ts#L316",
          "created_at": "2025-04-16T05:05:41Z"
        }
      ]
    },
    {
      "issue_number": 1996,
      "title": "Crackling sound issues with Cartesia TTS",
      "body": "We're experiencing very weird cracking sounds specifically when using Cartesia TTS. ElevenLabs and OpenAI TTS don't seem to have this issue. The sound issues seem to appear randomly and don't appear in every utterance.\n\nWe're using the v1 Agents SDK.\n\nSome observations:\n\n1. It seems to occur less often when running the worker in production mode instead of development mode (`main.py start` instead of `main.py dev`).\n2. It _could_ be related to system resources, as it doesn't seem to happen when running on my local machine, but does happen in the production Docker containers (tested across different VM sizes)\n\nHere's an example (**warning**, loud noises):\n\nhttps://github.com/user-attachments/assets/3ac35835-754d-4d33-8faf-c65cfdde7f1b\n\nCondensed agent code:\n\n```python\nimport logging\nimport datetime\nfrom typing import Any\nfrom livekit import api, rtc\nfrom livekit.agents import AgentSession, Agent, JobContext, cli, WorkerOptions, BackgroundAudioPlayer, AudioConfig, BuiltinAudioClip, RoomInputOptions, tts, llm, stt\nfrom livekit.agents.voice.events import ConversationItemAddedEvent\nfrom livekit.plugins import google, deepgram, silero, openai, cartesia, noise_cancellation\nfrom livekit.plugins.turn_detector.multilingual import MultilingualModel\nimport os\n\nlogger = logging.getLogger(\"voice-agent\")\n\nclass Assistant(Agent):\n    def __init__(self) -> None:\n        self.conversation_items: list[dict[str, Any]] = []\n\n        super().__init__(\n            instructions=\"You are a helpful assistant that can answer questions and help with tasks.\"\n        )\n\nasync def entrypoint(ctx: JobContext):\n    await ctx.connect()\n    participant = await ctx.wait_for_participant()\n\n    # Set-up recording\n    credentials = \"\"\n    with open(os.getenv(\"GOOGLE_CREDENTIALS_FILE\"), \"r\") as f:\n        credentials = f.read()\n\n    recording_directory = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n    req = api.RoomCompositeEgressRequest(\n        room_name=ctx.room.name,\n        layout=\"speaker\",\n        audio_only=True,\n        segment_outputs=[api.SegmentedFileOutput(\n            filename_prefix=f\"{recording_directory}/\",\n            playlist_name=f\"{recording_directory}/playlist.m3u8\",\n            live_playlist_name=f\"{recording_directory}/live.m3u8\",\n            segment_duration=5,\n            gcp=api.GCPUpload(\n                credentials=credentials,\n                bucket=os.getenv(\"GOOGLE_STORAGE_BUCKET\"),\n            ),\n        )],\n    )\n\n    session = AgentSession(\n        stt=stt.FallbackAdapter(\n            stt=[\n                deepgram.STT(model=\"nova-2\", language=\"de\", punctuate=True, smart_format=True)\n            ],\n        ),\n        llm=llm.FallbackAdapter(\n            llm=[\n                google.LLM(model=\"gemini-2.0-flash\"),\n                openai.LLM(model=\"gpt-4o-mini\")\n            ],\n        ),\n        tts=tts.FallbackAdapter(\n            tts=[\n                cartesia.TTS(model='sonic-2', voice=\"b7187e84-fe22-4344-ba4a-bc013fcb533e\", speed=\"normal\", emotion=[\"curiosity:lowest\", \"positivity\"],),\n                openai.TTS(model=\"gpt-4o-mini-tts\", voice=\"ash\")\n            ],\n        ),\n        vad=silero.VAD.load(),\n        turn_detection=MultilingualModel(),\n        allow_interruptions=False\n    )\n\n    background_audio = BackgroundAudioPlayer(\n    ambient_sound=AudioConfig(BuiltinAudioClip.OFFICE_AMBIENCE, volume=0.8),\n    thinking_sound=[\n            AudioConfig(BuiltinAudioClip.KEYBOARD_TYPING, volume=0.8),\n            AudioConfig(BuiltinAudioClip.KEYBOARD_TYPING2, volume=0.7),\n        ],\n    )\n\n    @session.on(\"conversation_item_added\")\n    def _conversation_item_added(ev: ConversationItemAddedEvent):\n        agent.conversation_items.append({\n            \"role\": ev.item.role,\n            \"content\": ev.item.text_content,\n            \"timestamp\": int(datetime.datetime.now().timestamp() * 1000)\n        })\n\n    try:\n        agent = Assistant()\n\n        await session.start(\n            room=ctx.room,\n            agent=agent,\n            room_input_options=RoomInputOptions(\n                noise_cancellation=noise_cancellation.BVC(),\n            ),\n        )\n\n        try:\n            await ctx.api.egress.start_room_composite_egress(req)\n        except Exception as e:\n            logger.error(f\"Error starting room composite egress: {e}\")\n\n        await background_audio.start(room=ctx.room, agent_session=session)\n        await session.generate_reply(instructions=f\"Say hello.\")\n    except Exception as e:\n        logger.error(f\"Error starting agent session: {e}\")\n\nif __name__ == \"__main__\":\n    cli.run_app(WorkerOptions(entrypoint_fnc=entrypoint))\n```\n\nSDK versions:\n```\nlivekit==1.0.5\nlivekit-agents==1.0.11\nlivekit-api==1.0.2\nlivekit-plugins-cartesia==1.0.11\nlivekit-plugins-deepgram==1.0.11\nlivekit-plugins-elevenlabs==1.0.11\nlivekit-plugins-google==1.0.11\nlivekit-plugins-noise-cancellation==0.2.1\nlivekit-plugins-openai==1.0.11\nlivekit-plugins-silero==1.0.11\nlivekit-plugins-turn-detector==1.0.11\nlivekit-protocol==1.0.1\n```",
      "state": "closed",
      "author": "mfkrause",
      "author_type": "User",
      "created_at": "2025-04-14T17:32:59Z",
      "updated_at": "2025-04-15T18:19:31Z",
      "closed_at": "2025-04-15T18:19:30Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1996/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "longcw"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1996",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1996",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:36.589411",
      "comments": [
        {
          "author": "davidzhao",
          "body": "wow.. this is pretty terrible.. I don't think it's related to system resources.. as that would produce a glitch.. but not nearly at this amplitude.",
          "created_at": "2025-04-15T00:03:39Z"
        },
        {
          "author": "davidzhao",
          "body": "we'll investigate.. it wouldn't make sense that this would only be happening to cartesia either. what OS/version are you running on the docker image?",
          "created_at": "2025-04-15T00:04:21Z"
        },
        {
          "author": "longcw",
          "body": "@mfkrause It seems to be a bug in `rtc.AudioResampler` when resampling cartesia TTS from 24k to 48k when it was used in a TTS fallback adapter with the openai TTS which sample rate is 48k. \n\nBy default the fallback adapter resample the audio to the max sample rate among the TTS providers. Can you tr",
          "created_at": "2025-04-15T01:37:41Z"
        },
        {
          "author": "ChenghaoMou",
          "body": "I think we encountered the same issue before with sampling: https://github.com/livekit/python-sdks/issues/389\n",
          "created_at": "2025-04-15T11:02:47Z"
        },
        {
          "author": "mfkrause",
          "body": "@longcw Thanks for the investigation! Setting the sample rate to 24 kHz seems to have fixed it. I think we introduced Cartesia at the same time as the fallback adapters, so indeed likely the issue comes from those / their resampling instead of the Cartesia TTS itself.",
          "created_at": "2025-04-15T12:10:57Z"
        }
      ]
    },
    {
      "issue_number": 2003,
      "title": "How to dynamically initialize tools in LiveKit Python SDK v1.0 (Migration Help)",
      "body": "I was using dynamic tool initialization in a previous version of the SDK, something like\n```\nclass AssistantFnc(llm.FunctionContext):\n    def __init__(self, tools):\n        super().__init__()\n        self._fncs = {}\n        self._register_all_tools(tools)\n\n    def _register_all_tools(self, tools):\n        try:\n            if not isinstance(tools, list):\n                raise ValueError(\"Tools should be a list.\")\n            for tool_group in tools:\n                if not isinstance(tool_group, list):\n                    raise ValueError(\"Each tool group should be a list.\")\n                for tool in tool_group:\n                    if not isinstance(tool, dict):\n                        raise ValueError(f\"Tool is not a dictionary: {tool}\")\n                    tool_name = tool[\"name\"]\n                    tool_description = tool[\"description\"]\n                    tool_parameters = tool[\"parameters\"]\n\n                    async def dynamic_function(tool_name=tool_name, **kwargs):\n                        tool_instance = AssistantFncInvoker()\n                        class_function = getattr(tool_instance, tool_name)\n                        return await class_function(kwargs)\n\n                    self._fncs[tool_name] = llm.FunctionInfo(\n                        name=tool_name,\n                        description=tool_description,\n                        auto_retry=False,\n                        callable=dynamic_function,\n                        arguments={\n                            param_name: llm.FunctionArgInfo(\n                                name=param_name,\n                                description=param_details[\"description\"],\n                                type=str,\n                                default=inspect._empty,\n                                choices=param_details.get(\"choices\", ()),\n                            )\n                            for param_name, param_details in tool_parameters.items()\n                        },\n                    )\n        except Exception as e:\n            logger.critical(f\"Error in function initialization: {str(e)}\")\n```\n",
      "state": "closed",
      "author": "narendra-bluebash",
      "author_type": "User",
      "created_at": "2025-04-15T05:02:51Z",
      "updated_at": "2025-04-15T15:42:30Z",
      "closed_at": "2025-04-15T15:42:30Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/2003/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/2003",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/2003",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:36.828692",
      "comments": [
        {
          "author": "a6kme",
          "body": "You can use programmatic tool creation as documented here - https://docs.livekit.io/agents/build/tools/#programmatic-tool-creation\n\nThere is an example given in the repo too - https://github.com/livekit/agents/blob/main/examples/voice_agents/dynamic_tool_creation.py\n\nDoes this help?",
          "created_at": "2025-04-15T05:33:33Z"
        }
      ]
    },
    {
      "issue_number": 1858,
      "title": "Agents 1.0 Azure STT language parameter broken",
      "body": "We can't set language in Azure STT like this: \n`azure.STT(language=\"he-IL\")`\n\nIn https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-azure/livekit/plugins/azure/stt.py it is blocked by\n```\n        if not is_given(languages):\n            languages = [\"en-US\"]\n\n        if is_given(language) and not is_given(languages):\n            languages = [language]\n```\n\nThe checks should be swapped over.\n",
      "state": "closed",
      "author": "Andhs-eff",
      "author_type": "User",
      "created_at": "2025-04-02T09:55:48Z",
      "updated_at": "2025-04-15T12:11:47Z",
      "closed_at": "2025-04-03T10:02:31Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1858/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1858",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1858",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:37.023251",
      "comments": [
        {
          "author": "longcw",
          "body": "cc @jayeshp19 ",
          "created_at": "2025-04-02T09:58:48Z"
        },
        {
          "author": "jayeshp19",
          "body": "ah right, that makes sense",
          "created_at": "2025-04-02T11:34:41Z"
        },
        {
          "author": "praveenpnj94",
          "body": "Hi All,\n\nWe are seeing some delay in generating the initial response while using azure stt? Are you not seeing the same? ",
          "created_at": "2025-04-12T00:13:45Z"
        },
        {
          "author": "Andhs-eff",
          "body": "> Hi All,\n> \n> We are seeing some delay in generating the initial response while using azure stt? Are you not seeing the same?\n\nYes, I can also confirm that Azure STT gets enabled with a higher latency compared to other systems, say, Deepgram. This is probably an Azure issue, not LiveKit Agents.\n\nTh",
          "created_at": "2025-04-12T14:46:12Z"
        },
        {
          "author": "praveenpnj94",
          "body": "Whats your azure stt configuration? Which region and language you are using?",
          "created_at": "2025-04-14T18:38:31Z"
        }
      ]
    },
    {
      "issue_number": 1997,
      "title": "[1.0] LLM Response No Longer Split into Segments After Migration",
      "body": "After upgrading to version 1.0, we observed that LLM responses are no longer segmented by sentence. Instead, the entire response is returned **as a single transcription segment**. \nThis behavior differs from previous versions, where responses were split into **multiple**, more digestible segments.\n\n- Is this a regression introduced in 1.0?\n- Or is there a configuration option to restore the previous segmentation behavior?",
      "state": "open",
      "author": "AndrazP",
      "author_type": "User",
      "created_at": "2025-04-14T21:02:59Z",
      "updated_at": "2025-04-15T07:43:00Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1997/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1997",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1997",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:37.282258",
      "comments": [
        {
          "author": "longcw",
          "body": "In 1.0 the agent transcription is sent by one segment per turn, changed from one segment per sentence.\n\nYou can use a sentence tokenizer to split it into sentences if you prefer, for example [nltk](https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-nltk/livekit/plugins/nltk/",
          "created_at": "2025-04-15T01:06:29Z"
        },
        {
          "author": "AndrazP",
          "body": "Can you please provide an example of how to apply a different sentence tokenizer?",
          "created_at": "2025-04-15T04:41:08Z"
        },
        {
          "author": "longcw",
          "body": "You can find the usage in https://github.com/livekit/agents/blob/main/tests/test_tokenizer.py#L62",
          "created_at": "2025-04-15T07:11:36Z"
        },
        {
          "author": "AndrazP",
          "body": "I'm sorry, I still don't understand how to integrate it into an `Agent`. Which part of the pipeline do I need to override?",
          "created_at": "2025-04-15T07:30:47Z"
        },
        {
          "author": "longcw",
          "body": "In 1.0 the transcription is sent as one segment per conversation turn not by sentences, and for now there is no option to change that.\n\nI think you can split the text into sentences that in your client. Or in `transcription_node` of Agent (https://docs.livekit.io/agents/build/nodes/#transcription-no",
          "created_at": "2025-04-15T07:42:59Z"
        }
      ]
    },
    {
      "issue_number": 1994,
      "title": "played_duration is 0.0 on interruption in CLI console, causing empty messages",
      "body": "When using the livekit-agents console mode (e.g., via python example.py console), if the agent’s speech is interrupted by user input, the calculated played_duration consistently appears to be 0.0.\n\nThis occurs within the `_pipeline_reply_task` in `livekit/agents/voice/agent_activity.py` during interruption handling. The incorrect played_duration is then passed to truncate_message in `livekit/agents/voice/generation.py`.\n\nBecause played_duration is 0.0, truncate_message returns an empty string, and the assistant’s interrupted message is saved into the chat context with no content.",
      "state": "open",
      "author": "areiner222",
      "author_type": "User",
      "created_at": "2025-04-14T13:03:16Z",
      "updated_at": "2025-04-14T14:15:52Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1994/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1994",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1994",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:37.504205",
      "comments": []
    },
    {
      "issue_number": 1850,
      "title": "The voice is cutting off at the end when using Kokoro-FastAPI TTS",
      "body": "I build my agent with the pipeline of STT, LLM, and TTS models. I'm trying to integrate Kokoro-fastAPI TTS. https://github.com/remsky/Kokoro-FastAPI\nI run it in docker at http://localhost:8880/v1\nSince It is openAi compatible speech. I call it as follows:\n\ntts=openai.TTS(model=\"tts-1\", voice=\"ff_siwis\", api_key=\"not-needed\", base_url=\"http://localhost:8880/v1\"),\n\nIn the conversation, half the time, the voice is cutting off at the end. The log shows this error \n\n2025-04-01 19:48:28,249 - ERROR livekit.agents - error decoding audio\nTraceback (most recent call last):\n  File \"C:\\my_app\\venv\\lib\\site-packages\\livekit\\agents\\utils\\codecs\\decoder.py\", line 145, in _decode_loop\n    for frame in container.decode(audio_stream):\n  File \"av\\\\container\\\\input.pyx\", line 216, in decode\n  File \"av\\\\packet.pyx\", line 81, in av.packet.Packet.decode\n  File \"av\\\\audio\\\\stream.pyx\", line 34, in av.audio.stream.AudioStream.decode\n  File \"av\\\\audio\\\\stream.pyx\", line 43, in av.audio.stream.AudioStream.decode\n  File \"av\\\\codec\\\\context.pyx\", line 448, in av.codec.context.CodecContext.decode\n  File \"av\\\\codec\\\\context.pyx\", line 340, in av.codec.context.CodecContext._send_packet_and_recv\n  File \"av\\\\error.pyx\", line 423, in av.error.err_check\nav.error.InvalidDataError: [Errno 1094995529] Invalid data found when processing input: 'avcodec_send_packet()'\n\nPlease help. Thanks.\n",
      "state": "closed",
      "author": "LaVivien",
      "author_type": "User",
      "created_at": "2025-04-01T18:49:28Z",
      "updated_at": "2025-04-14T03:00:42Z",
      "closed_at": "2025-04-14T03:00:42Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1850/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1850",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1850",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:37.504227",
      "comments": [
        {
          "author": "yepher",
          "body": "Please provide a PCAP of the issue. It appears something is wrong with the audio that was generated. We can verify that with a PCAP\n\nCan you also provide your Agent code that was used to produce this error?\n\n\nSlack Thread [here](https://livekit-users.slack.com/archives/C07FY8WHGPM/p1744117412303439)",
          "created_at": "2025-04-08T13:53:47Z"
        },
        {
          "author": "LaVivien",
          "body": "@yepher Thanks for taking a look at the issue. I installed wireshark, and uploaded [pcap files](https://github.com/LaVivien/parlez-agent/tree/main/wireshark%20pcap). Hope they provide the information you are looking for.\n\n[Here](https://github.com/LaVivien/parlez-agent/blob/main/agent.py) is the age",
          "created_at": "2025-04-08T17:12:22Z"
        },
        {
          "author": "longcw",
          "body": "@LaVivien can you compare the audio from the `openai.TTS(model=\"kokoro\", voice=\"ff_siwis\", api_key=\"not-needed\", base_url=\"http://localhost:8880/v1\")` and a direct API call to the service, would like to see if it's the issue from the plugin or from the API itself.",
          "created_at": "2025-04-09T03:29:18Z"
        },
        {
          "author": "LaVivien",
          "body": "@longcw [Open WebUI](https://github.com/open-webui/open-webui) is a user interface to run Ollama on a local machine. It has a guide to plugin [Kokoko-FastAPI using docker](https://docs.openwebui.com/tutorials/text-to-speech/Kokoro-FastAPI-integration/). I set it up and it can perfectly speak out wha",
          "created_at": "2025-04-09T07:03:31Z"
        },
        {
          "author": "longcw",
          "body": "I have tested on my end and found that it's the `response_format=\"opus\"` (https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-openai/livekit/plugins/openai/tts.py#L205) supporting issue in the Kokoro-FastAPI https://github.com/remsky/Kokoro-FastAPI/issues/273, it works well w",
          "created_at": "2025-04-09T08:11:24Z"
        }
      ]
    },
    {
      "issue_number": 1856,
      "title": "llama-index plugin with AgentSession not working",
      "body": "Hi all,\nI tried to combined the Readme minimal example with the llama-index chat mode. I run it in the console by toggling to text mode to exclude stt issues.\n\n```python\nimport os\nimport logging\nfrom dotenv import load_dotenv\nfrom livekit.agents import (\n    Agent,\n    AgentSession,\n    JobContext,\n    RunContext,\n    WorkerOptions,\n    cli,\n)\nfrom livekit.plugins import deepgram, openai, silero\nfrom livekit.plugins import  llama_index, openai, silero, turn_detector\n\nfrom llama_index.core import (\n    SimpleDirectoryReader,\n    StorageContext,\n    VectorStoreIndex,\n    load_index_from_storage\n)\n\nfrom llama_index.core.chat_engine.types import ChatMode\nload_dotenv()\n\n#--------------- Prompt ------------------\nwith open(\"prompt.txt\", \"r\") as file:\n    prompt = file.read()\n#--------------- RAG ------------------\nif prompt is None:\n    raise ValueError(\"Prompt cannot be None. Please provide a valid prompt in prompt.txt\")\n# check if storage already exists\nPERSIST_DIR = \"./chat-engine-storage\"\nif not os.path.exists(PERSIST_DIR):\n    # load the documents and create the index\n    documents = SimpleDirectoryReader(\"data\").load_data()\n    index = VectorStoreIndex.from_documents(documents)\n    # store it for later\n    index.storage_context.persist(persist_dir=PERSIST_DIR)\nelse:\n    # load the existing index\n    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n    index = load_index_from_storage(storage_context)\n\n\n\n\nasync def entrypoint(ctx: JobContext):\n    chat_engine = index.as_chat_engine(chat_mode=ChatMode.CONTEXT)\n    await ctx.connect()\n\n    agent = Agent(\n        instructions = prompt,\n    )\n    session = AgentSession(\n        vad=silero.VAD.load(),\n        # any combination of STT, LLM, TTS, or realtime API can be used\n        stt=openai.STT(),\n        llm=llama_index.LLM(chat_engine=chat_engine),\n        # this works\n        #llm=openai.LLM(model=\"gpt-4o-mini\"),\n        tts=openai.TTS(voice=\"ash\"),\n    )\n\n    await session.start(agent=agent, room=ctx.room)\n    await session.generate_reply(instructions=\"greet the user and ask about their day\")\n\n\nif __name__ == \"__main__\":\n    cli.run_app(WorkerOptions(entrypoint_fnc=entrypoint))\n```\n\nthis is error\n\n```bash\nile \"/home/cbhamda/drt-livekit/backend/.venv/lib/python3.13/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cbhamda/drt-livekit/backend/.venv/lib/python3.13/site-packages/livekit/agents/voice/generation.py\", line 76, in _inference_task\n    async for chunk in llm_node:\n    ...<29 lines>...\n            )\n  File \"/home/cbhamda/drt-livekit/backend/.venv/lib/python3.13/site-packages/livekit/agents/voice/agent.py\", line 348, in llm_node\n    async with activity.llm.chat(\n               ~~~~~~~~~~~~~~~~~^\n        chat_ctx=chat_ctx, tools=tools, tool_choice=tool_choice\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ) as stream:\n    ^\nTypeError: LLM.chat() got an unexpected keyword argument 'tools'\n```\n\n\nit appears that tools have not been added to the llama-index plugin llm class. this is related to the question in #1773 ",
      "state": "closed",
      "author": "biouser-abiomix",
      "author_type": "User",
      "created_at": "2025-04-02T08:47:30Z",
      "updated_at": "2025-04-14T03:00:15Z",
      "closed_at": "2025-04-14T03:00:14Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1856/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1856",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1856",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:37.739108",
      "comments": [
        {
          "author": "longcw",
          "body": "will create a fix for llama index soon.",
          "created_at": "2025-04-02T08:48:59Z"
        },
        {
          "author": "longcw",
          "body": "Created a pr for fixing the llama index plugin and bringing back the examples https://github.com/livekit/agents/pull/1857",
          "created_at": "2025-04-02T09:13:11Z"
        },
        {
          "author": "biouser-abiomix",
          "body": "Thank you @longcw  !\nis this branch going to be merged ?",
          "created_at": "2025-04-03T10:21:07Z"
        },
        {
          "author": "longcw",
          "body": "llama-index plugin was removed, you can use the the llama index package directly with customized `llm_node`, see examples in https://github.com/livekit/agents/tree/main/examples/voice_agents/llamaindex-rag ",
          "created_at": "2025-04-14T03:00:14Z"
        }
      ]
    },
    {
      "issue_number": 1972,
      "title": "How can i try the \"Openai realtime response generation failed\" error in my program?",
      "body": "Openai-relatime error like below,How can i try catch it? thank you!\n\n\n{\"message\": \"Openai Director\\u7684\\u540e\\u53f0\\u4efb\\u52a1\\u5f00\\u59cb\\u5faa\\u73af, \\u6d88\\u606f\\u6570\\u91cf\\uff1a 5\", \"level\": \"INFO\", \"name\": \"root\", \"pid\": 203680, \"job_id\": \"AJ_mRbWcTJ4kETD\", \"timestamp\": \"2025-04-11T08:02:07.074275+00:00\"}\n2025/04/11 08:02:07 - INFO - root -  调用访谈进度, 8\n{\"message\": \"\\u8c03\\u7528\\u8bbf\\u8c08\\u8fdb\\u5ea6, 8\", \"level\": \"INFO\", \"name\": \"root\", \"pid\": 203680, \"job_id\": \"AJ_mRbWcTJ4kETD\", \"timestamp\": \"2025-04-11T08:02:07.074657+00:00\"}\n2025/04/11 08:02:07 - INFO - root -  调用访谈进度, max:8\n{\"message\": \"\\u8c03\\u7528\\u8bbf\\u8c08\\u8fdb\\u5ea6, max:8\", \"level\": \"INFO\", \"name\": \"root\", \"pid\": 203680, \"job_id\": \"AJ_mRbWcTJ4kETD\", \"timestamp\": \"2025-04-11T08:02:07.074811+00:00\"}\n2025/04/11 08:02:07 - ERROR - livekit.plugins.openai.realtime -  response generation failed\n2025/04/11 08:02:07 - ERROR - livekit.plugins.openai.realtime -  response generation failed\n{\"message\": \"response generation failed\", \"level\": \"ERROR\", \"name\": \"livekit.plugins.openai.realtime\", \"code\": null, \"error\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at aoai-realtimeapi-dri@microsoft.com if the error persists. (Please include the session ID sess_BL3bHJOWPiQhPu7D1BMKf in your message.)\", \"session_id\": \"sess_BL3bHJOWPiQhPu7D1BMKf\", \"pid\": 203680, \"job_id\": \"AJ_mRbWcTJ4kETD\", \"timestamp\": \"2025-04-11T08:02:07.396192+00:00\"}\n2025/04/11 08:02:07 - INFO - root -  agent stopped speaking\n\n\nlivekit-plugins/livekit-plugins-openai source code\n\n```\n                    elif event == \"response.audio.done\":\n                        self._handle_response_audio_done(data)\n                    elif event == \"response.text.done\":\n                        self._handle_response_text_done(data)\n                    elif event == \"response.audio_transcript.done\":\n                        self._handle_response_audio_transcript_done(data)\n                    elif event == \"response.content_part.done\":\n                        self._handle_response_content_part_done(data)\n                    elif event == \"response.output_item.done\":\n                        self._handle_response_output_item_done(data)\n                    elif event == \"response.done\":\n                        self._handle_response_done(data)\n\n\n    def _handle_response_done(self, response_done: api_proto.ServerEvent.ResponseDone):\n        response_data = response_done[\"response\"]\n        response_id = response_data[\"id\"]\n        response = self._pending_responses[response_id]\n        self._active_response_id = None\n        response.done_fut.set_result(None)\n\n        response.status = response_data[\"status\"]\n        response.status_details = response_data.get(\"status_details\")\n        response.metadata = cast(map, response_data.get(\"metadata\"))\n        response.output = cast(list[RealtimeOutput], response_data.get(\"output\"))\n        response.usage = response_data.get(\"usage\")\n\n        metrics_error = None\n        cancelled = False\n        if response.status == \"failed\":\n            assert response.status_details is not None\n\n            error = response.status_details.get(\"error\", {})\n            code: str | None = error.get(\"code\")  # type: ignore\n            message: str | None = error.get(\"message\")  # type: ignore\n            metrics_error = MultimodalLLMError(\n                type=response.status_details.get(\"type\"),\n                code=code,\n                message=message,\n            )\n\n            logger.error(\n                \"response generation failed\",\n                extra={\"code\": code, \"error\": message, **self.logging_extra()},\n            )\n        elif response.status == \"incomplete\":\n            assert response.status_details is not None\n            reason = response.status_details.get(\"reason\")\n\n            metrics_error = MultimodalLLMError(\n                type=response.status_details.get(\"type\"),\n                reason=reason,  # type: ignore\n            )\n\n            logger.warning(\n                \"response generation incomplete\",\n                extra={\"reason\": reason, **self.logging_extra()},\n            )\n        elif response.status == \"cancelled\":\n            cancelled = True\n\n        self.emit(\"response_done\", response)\n\n        # calculate metrics\n        ttft = -1.0\n        if response._first_token_timestamp is not None:\n            ttft = response._first_token_timestamp - response._created_timestamp\n        duration = time.time() - response._created_timestamp\n\n        usage = response.usage or {}  # type: ignore\n        input_token_details = usage.get(\"input_token_details\", {})\n        metrics = MultimodalLLMMetrics(\n            timestamp=response._created_timestamp,\n            request_id=response.id,\n            ttft=ttft,\n            duration=duration,\n            cancelled=cancelled,\n            label=self._label,\n            completion_tokens=usage.get(\"output_tokens\", 0),\n            prompt_tokens=usage.get(\"input_tokens\", 0),\n            total_tokens=usage.get(\"total_tokens\", 0),\n            tokens_per_second=usage.get(\"output_tokens\", 0) / duration,\n            error=metrics_error,\n            input_token_details=MultimodalLLMMetrics.InputTokenDetails(\n                cached_tokens=input_token_details.get(\"cached_tokens\", 0),\n                text_tokens=usage.get(\"input_token_details\", {}).get(\"text_tokens\", 0),\n                audio_tokens=usage.get(\"input_token_details\", {}).get(\n                    \"audio_tokens\", 0\n                ),\n                cached_tokens_details=MultimodalLLMMetrics.CachedTokenDetails(\n                    text_tokens=input_token_details.get(\n                        \"cached_tokens_details\", {}\n                    ).get(\"text_tokens\", 0),\n                    audio_tokens=input_token_details.get(\n                        \"cached_tokens_details\", {}\n                    ).get(\"audio_tokens\", 0),\n                ),\n            ),\n            output_token_details=MultimodalLLMMetrics.OutputTokenDetails(\n                text_tokens=usage.get(\"output_token_details\", {}).get(\"text_tokens\", 0),\n                audio_tokens=usage.get(\"output_token_details\", {}).get(\n                    \"audio_tokens\", 0\n                ),\n            ),\n        )\n        self.emit(\"metrics_collected\", metrics)\n\n```",
      "state": "open",
      "author": "johnson7788",
      "author_type": "User",
      "created_at": "2025-04-11T10:51:46Z",
      "updated_at": "2025-04-14T01:36:08Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1972/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1972",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1972",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:38.017807",
      "comments": [
        {
          "author": "johnson7788",
          "body": "I catch it like below, is it right?\n    session = model.sessions[0]\n    @session.on(\"response_done\")\n    def on_response_done(response: openai.realtime.RealtimeResponse):\n        if response.status == \"failed\":\n            #让Openai重新的请求\n            chat_ctx.append(\n                role=\"system\",\n   ",
          "created_at": "2025-04-11T11:04:25Z"
        },
        {
          "author": "longcw",
          "body": "It seems like an error from the realtime API \n> The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at [aoai-realtimeapi-dri@microsoft.com](mailto:aoai-realtimeapi-dri@microsoft.com) if the error persists.\n\nTo ret",
          "created_at": "2025-04-14T01:36:07Z"
        }
      ]
    },
    {
      "issue_number": 1976,
      "title": "Agents 1.0: ...message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'...",
      "body": "Related Threads:\n* https://livekit-users.slack.com/archives/C07FY8WHGPM/p1744356171509089\n* https://livekit-users.slack.com/archives/C025KM0S1CK/p1744373470699019\n\n## Steps to reproduce issue:\n\n```\npip freeze |grep livekit      \nlivekit==1.0.4\nlivekit-agents==1.0.11\nlivekit-api==1.0.2\nlivekit-plugins-cartesia==1.0.11\nlivekit-plugins-deepgram==1.0.11\nlivekit-plugins-google==1.0.11\nlivekit-plugins-noise-cancellation==0.2.1\nlivekit-plugins-openai==1.0.11\nlivekit-plugins-silero==1.0.11\nlivekit-plugins-turn-detector==1.0.11\nlivekit-protocol==1.0.1\n```\n\nRunning the attached `tool_call.py` say the following:\n\n1. Say: `What is the weather in Chicago?`\n2. Agent responds: `Wait while I call the function to get the weather`\n3. Before agent responds with weather\n4. Say: `What is the capital of Illinois?`\n5. Agent will respond to both questions\n\nShortly after the agent response the errors shown below will be seen.\n\n## Reproduced with the following LLM:\n\n`llm=openai.LLM(model=\"gpt-4-turbo\"),`\nand\n`llm=openai.LLM(model=\"gpt-4o\", api_key=os.getenv(\"OPENAI_API_KEY_LOCAL\")),`\n\n\n\n## Error Message:\n\n```\n(.venv) > simple_example % python tool_call.py dev\n2025-04-11 11:21:36,358 - DEBUG asyncio - Using selector: KqueueSelector \n2025-04-11 11:21:36,358 - DEV  livekit.agents - Watching /Users/chriswilson/lkworking/livekit/simple_example \n2025-04-11 11:21:36,771 - DEBUG asyncio - Using selector: KqueueSelector \n2025-04-11 11:21:36,773 - INFO livekit.agents - starting worker {\"version\": \"1.0.11\", \"rtc-version\": \"1.0.4\"}\n2025-04-11 11:21:36,774 - INFO livekit.agents - see tracing information at http://localhost:59216/debug \n2025-04-11 11:21:36,907 - INFO livekit.agents - registered worker {\"id\": \"AW_A9rMmbn9gChG\", \"url\": \"wss://chris-test-gk8v3xf8.livekit.cloud\", \"region\": \"US Central\", \"protocol\": 15}\n2025-04-11 11:21:40,183 - INFO livekit.agents - received job request {\"job_id\": \"AJ_reLXXiBu9iUs\", \"dispatch_id\": \"\", \"room_name\": \"9m62-xwj3\", \"agent_name\": \"\", \"resuming\": false}\n2025-04-11 11:21:40,679 - INFO livekit.agents - initializing job process {\"pid\": 34421}\n2025-04-11 11:21:40,679 - INFO livekit.agents - job process initialized {\"pid\": 34421}\n2025-04-11 11:21:40,680 - DEBUG asyncio - Using selector: KqueueSelector {\"pid\": 34421, \"job_id\": \"AJ_reLXXiBu9iUs\"}\n2025-04-11 11:21:41,819 - DEBUG livekit.agents - start reading stream {\"participant\": \"Chris Wilson\", \"source\": \"SOURCE_MICROPHONE\", \"pid\": 34421, \"job_id\": \"AJ_reLXXiBu9iUs\"}\n2025-04-11 11:21:41,820 - DEBUG livekit.agents - http_session(): creating a new httpclient ctx {\"pid\": 34421, \"job_id\": \"AJ_reLXXiBu9iUs\"}\n2025-04-11 11:21:48,149 - DEBUG livekit.agents - received user transcript {\"user_transcript\": \"What is the weather in Chicago?\", \"language\": \"en-US\", \"pid\": 34421, \"job_id\": \"AJ_reLXXiBu9iUs\"}\nget_weather_today called\n2025-04-11 11:21:51,302 - DEBUG livekit.agents - executing tool {\"function\": \"get_weather_today\", \"arguments\": \"{}\", \"speech_id\": \"speech_ed092a6a0d69\", \"pid\": 34421, \"job_id\": \"AJ_reLXXiBu9iUs\"}\nget_weather_tomorrow called\n2025-04-11 11:21:51,306 - DEBUG livekit.agents - executing tool {\"function\": \"get_weather_tomorrow\", \"arguments\": \"{}\", \"speech_id\": \"speech_ed092a6a0d69\", \"pid\": 34421, \"job_id\": \"AJ_reLXXiBu9iUs\"}\n2025-04-11 11:22:00,132 - DEBUG livekit.agents - received user transcript {\"user_transcript\": \"What is the capital of Illinois?\", \"language\": \"en-US\", \"pid\": 34421, \"job_id\": \"AJ_reLXXiBu9iUs\"}\n2025-04-11 11:22:01,307 - DEBUG livekit.agents - tools execution completed {\"speech_id\": \"speech_ed092a6a0d69\", \"pid\": 34421, \"job_id\": \"AJ_reLXXiBu9iUs\"}\nget_weather_today called\n2025-04-11 11:22:02,727 - DEBUG livekit.agents - executing tool {\"function\": \"get_weather_today\", \"arguments\": \"{}\", \"speech_id\": \"speech_f22f4178b319\", \"pid\": 34421, \"job_id\": \"AJ_reLXXiBu9iUs\"}\nget_weather_tomorrow called\n2025-04-11 11:22:02,732 - DEBUG livekit.agents - executing tool {\"function\": \"get_weather_tomorrow\", \"arguments\": \"{}\", \"speech_id\": \"speech_f22f4178b319\", \"pid\": 34421, \"job_id\": \"AJ_reLXXiBu9iUs\"}\n2025-04-11 11:22:12,732 - DEBUG livekit.agents - tools execution completed {\"speech_id\": \"speech_f22f4178b319\", \"pid\": 34421, \"job_id\": \"AJ_reLXXiBu9iUs\"}\n\n2025-04-11 11:22:28,329 - DEBUG livekit.agents - received user transcript {\"user_transcript\": \"You still there?\", \"language\": \"en-US\", \"pid\": 34421, \"job_id\": \"AJ_reLXXiBu9iUs\"}\n2025-04-11 11:22:29,012 - WARNING livekit.agents - failed to generate LLM completion, retrying in 2.0s\nTraceback (most recent call last):\n  File \"/Users/chriswilson/lkworking/livekit/simple_example/.venv/lib/python3.13/site-packages/livekit/agents/llm/llm.py\", line 137, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/chriswilson/lkworking/livekit/simple_example/.venv/lib/python3.13/site-packages/livekit/plugins/openai/llm.py\", line 599, in _run\n    raise APIStatusError(\n    ...<5 lines>...\n    ) from None\nlivekit.agents._exceptions.APIStatusError: Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_FExXKLMrXfNE1pFr51wqMAAa, call_8WAxWYLi2bUlSJeT8ccrKNCR\", 'type': 'invalid_request_error', 'param': 'messages.[3].role', 'code': None}} (status_code=400, request_id=req_9847e623208b655782838254416871e3, body={'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_FExXKLMrXfNE1pFr51wqMAAa, call_8WAxWYLi2bUlSJeT8ccrKNCR\", 'type': 'invalid_request_error', 'param': 'messages.[3].role', 'code': None}) {\"llm\": \"livekit.plugins.openai.llm.LLM\", \"attempt\": 1, \"pid\": 34421, \"job_id\": \"AJ_reLXXiBu9iUs\"}\n2025-04-11 11:22:31,235 - WARNING livekit.agents - failed to generate LLM completion, retrying in 2.0s\nTraceback (most recent call last):\n  File \"/Users/chriswilson/lkworking/livekit/simple_example/.venv/lib/python3.13/site-packages/livekit/agents/llm/llm.py\", line 137, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/chriswilson/lkworking/livekit/simple_example/.venv/lib/python3.13/site-packages/livekit/plugins/openai/llm.py\", line 599, in _run\n    raise APIStatusError(\n    ...<5 lines>...\n    ) from None\nlivekit.agents._exceptions.APIStatusError: Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_FExXKLMrXfNE1pFr51wqMAAa, call_8WAxWYLi2bUlSJeT8ccrKNCR\", 'type': 'invalid_request_error', 'param': 'messages.[3].role', 'code': None}} (status_code=400, request_id=req_60f3d632002c62866380e31d18e981fc, body={'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_FExXKLMrXfNE1pFr51wqMAAa, call_8WAxWYLi2bUlSJeT8ccrKNCR\", 'type': 'invalid_request_error', 'param': 'messages.[3].role', 'code': None}) {\"llm\": \"livekit.plugins.openai.llm.LLM\", \"attempt\": 2, \"pid\": 34421, \"job_id\": \"AJ_reLXXiBu9iUs\"}\n2025-04-11 11:22:33,467 - WARNING livekit.agents - failed to generate LLM completion, retrying in 2.0s\nTraceback (most recent call last):\n  File \"/Users/chriswilson/lkworking/livekit/simple_example/.venv/lib/python3.13/site-packages/livekit/agents/llm/llm.py\", line 137, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/chriswilson/lkworking/livekit/simple_example/.venv/lib/python3.13/site-packages/livekit/plugins/openai/llm.py\", line 599, in _run\n    raise APIStatusError(\n    ...<5 lines>...\n    ) from None\nlivekit.agents._exceptions.APIStatusError: Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_FExXKLMrXfNE1pFr51wqMAAa, call_8WAxWYLi2bUlSJeT8ccrKNCR\", 'type': 'invalid_request_error', 'param': 'messages.[3].role', 'code': None}} (status_code=400, request_id=req_5806fd05a2b00af5543994baaf8d81c3, body={'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_FExXKLMrXfNE1pFr51wqMAAa, call_8WAxWYLi2bUlSJeT8ccrKNCR\", 'type': 'invalid_request_error', 'param': 'messages.[3].role', 'code': None}) {\"llm\": \"livekit.plugins.openai.llm.LLM\", \"attempt\": 3, \"pid\": 34421, \"job_id\": \"AJ_reLXXiBu9iUs\"}\n2025-04-11 11:22:35,633 - ERROR livekit.agents - Error in _inference_task\nTraceback (most recent call last):\n  File \"/Users/chriswilson/lkworking/livekit/simple_example/.venv/lib/python3.13/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/chriswilson/lkworking/livekit/simple_example/.venv/lib/python3.13/site-packages/livekit/agents/voice/generation.py\", line 76, in _inference_task\n    async for chunk in llm_node:\n    ...<29 lines>...\n            )\n  File \"/Users/chriswilson/lkworking/livekit/simple_example/.venv/lib/python3.13/site-packages/livekit/agents/voice/agent.py\", line 445, in llm_node\n    async for chunk in stream:\n        yield chunk\n  File \"/Users/chriswilson/lkworking/livekit/simple_example/.venv/lib/python3.13/site-packages/livekit/agents/llm/llm.py\", line 227, in __anext__\n    raise exc from None\n  File \"/Users/chriswilson/lkworking/livekit/simple_example/.venv/lib/python3.13/site-packages/livekit/agents/llm/llm.py\", line 144, in _main_task\n    raise APIConnectionError(\n        f\"failed to generate LLM completion after {self._conn_options.max_retry + 1} attempts\",  # noqa: E501\n    ) from e\nlivekit.agents._exceptions.APIConnectionError: failed to generate LLM completion after 4 attempts {\"pid\": 34421, \"job_id\": \"AJ_reLXXiBu9iUs\"}\n2025-04-11 11:22:35,672 - DEBUG livekit.agents - stream closed {\"participant\": \"Chris Wilson\", \"source\": \"SOURCE_MICROPHONE\", \"pid\": 34421, \"job_id\": \"AJ_reLXXiBu9iUs\"}\n```\n",
      "state": "closed",
      "author": "yepher",
      "author_type": "User",
      "created_at": "2025-04-11T16:22:50Z",
      "updated_at": "2025-04-14T01:28:31Z",
      "closed_at": "2025-04-14T01:28:31Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1976/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1976",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1976",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:38.235542",
      "comments": [
        {
          "author": "yepher",
          "body": "Code to reproduce issue:\n\n```python\nimport logging\n\nfrom dotenv import load_dotenv\n\nfrom livekit.agents import Agent, AgentSession, JobContext, WorkerOptions, cli\nfrom livekit.agents.llm import function_tool\nfrom livekit.plugins import cartesia, deepgram, openai\n\nimport os\nimport asyncio\nlogger = lo",
          "created_at": "2025-04-11T16:23:36Z"
        }
      ]
    },
    {
      "issue_number": 1981,
      "title": "Issue upgrading from livekit-agents ^0.12.9 to 1.0.11: chat = rtc.ChatManager(ctx.room) no longer supported",
      "body": "I'm currently upgrading livekit-agents from version ^0.12.9 to 1.0.11, and I’ve encountered a breaking change that’s blocking the upgrade.\n\nPreviously, I was using this code:\n\n`chat = rtc.ChatManager(ctx.room)`\n\nAfter updating to 1.0.11, this line throws an error, and it seems the send_message method is no longer supported or has changed in the newer version.\n\nSteps to Reproduce\nInstall livekit-agents==1.0.11\n\nTry using\n`chat = rtc.ChatManager(ctx.room)`\n\nCould you please provide:\nA recommended alternative for sending messages to the chat?\nA migration guide or example for handling chat messaging in v1.0.11?\nAny guidance or workaround would be greatly appreciated! Thanks for the great work on LiveKit Agents 🙏\n",
      "state": "closed",
      "author": "narendra-bluebash",
      "author_type": "User",
      "created_at": "2025-04-12T10:24:33Z",
      "updated_at": "2025-04-13T23:50:59Z",
      "closed_at": "2025-04-13T23:50:19Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1981/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1981",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1981",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:38.453033",
      "comments": [
        {
          "author": "michaelawea",
          "body": "https://github.com/livekit/agents/issues/1766\nI believe this could solve your issue",
          "created_at": "2025-04-12T23:25:13Z"
        },
        {
          "author": "narendra-bluebash",
          "body": "okey input will work but how to send back :\n\n`await chat.send_message(predicted_text)`",
          "created_at": "2025-04-13T05:01:26Z"
        },
        {
          "author": "michaelawea",
          "body": "https://docs.livekit.io/agents/build/text/\nI believe this doc could help you with this",
          "created_at": "2025-04-13T12:16:20Z"
        },
        {
          "author": "theomonnom",
          "body": "You can use\nhttps://github.com/livekit/python-sdks/blob/1057cf2d931b649a4d2b21b256c946daf58b0483/livekit-rtc/livekit/rtc/participant.py#L582\n\n\nThis isn't obvious, we will add a new example on the `examples` folder",
          "created_at": "2025-04-13T23:50:19Z"
        }
      ]
    },
    {
      "issue_number": 1983,
      "title": "Google Gemini Model Function Calling Issue",
      "body": "## Problem Summary\n\nWhen using the livekit-agents framework with Google Gemini model, function tools cannot be properly invoked:\n- Setting `tool_choice=\"required\"` throws an `AttributeError: 'function' object has no attribute 'name'` error\n- Setting `tool_choice=\"auto\"` never results in function tool invocation\n\n## Code Example\n\n```python\nimport logging\nfrom livekit.agents.llm import function_tool\nfrom livekit.agents import Agent, AgentSession, JobContext, WorkerOptions, cli\nfrom livekit.plugins import openai, silero, google\n\nlogger = logging.getLogger(\"weather-agent\")\n\nclass WeatherAgent(Agent):\n    def __init__(self) -> None:\n        super().__init__(\n            instructions=\"You are a weather assistant that helps users with weather information.\",\n            stt=openai.STT.with_groq(model=\"whisper-large-v3\", detect_language=True),\n            llm=google.LLM(\n                model=\"gemini-2.0-flash-001\",\n                temperature=0.8,\n                tool_choice=\"required\",  # This configuration causes the issue\n            ),\n            tts=openai.TTS(model=\"gpt-4o-mini-tts\"),\n        )\n\n    @function_tool\n    async def get_weather(self, location: str):\n        \"\"\"\n        This is the weather query system. Use this method to query weather information when users ask.\n        \n        Args:\n            location: The name of the location to query weather for\n        \"\"\"\n        logger.info(f\"Received query: {location}\")\n        # Process query logic\n        return f\"The weather in {location} today is sunny with a temperature of 25°C.\"\n\nasync def entrypoint(ctx: JobContext):\n    await ctx.connect()\n    session = AgentSession(\n        vad=silero.VAD.load(),\n    )\n    await session.start(agent=WeatherAgent(), room=ctx.room)\n    await session.say(\"Hello, I'm your weather assistant. How can I help you today?\")\n\nif __name__ == \"__main__\":\n    cli.run_app(WorkerOptions(entrypoint_fnc=entrypoint))\n```\n\n## Error Message\n\n```\n2025-04-13 01:43:11,180 - DEBUG livekit.agents - received user transcript {\"user_transcript\": \"Can you check the weather in Beijing for me\", \"language\": \"\", \"pid\": 81816, \"job_id\": \"AJ_z8u3NdZCK7qM\"}\n2025-04-13 01:43:11,184 - ERROR livekit.agents - Error in _inference_task\nTraceback (most recent call last):\n  File \"/Users/username/miniconda3/envs/weather/lib/python3.10/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n  File \"/Users/username/miniconda3/envs/weather/lib/python3.10/site-packages/livekit/agents/voice/generation.py\", line 76, in _inference_task\n    async for chunk in llm_node:\n  File \"/Users/username/miniconda3/envs/weather/lib/python3.10/site-packages/livekit/agents/voice/agent.py\", line 442, in llm_node\n    async with activity_llm.chat(\n  File \"/Users/username/miniconda3/envs/weather/lib/python3.10/site-packages/livekit/plugins/google/llm.py\", line 176, in chat\n    allowed_function_names=[fnc.name for fnc in tools],\n  File \"/Users/username/miniconda3/envs/weather/lib/python3.10/site-packages/livekit/plugins/google/llm.py\", line 176, in <listcomp>\n    allowed_function_names=[fnc.name for fnc in tools],\nAttributeError: 'function' object has no attribute 'name'\n```\n\nI don't know if this problem is caused by when `tool_choice=\"required\"` is set, the code attempts to access the `.name` attribute of each tool, but the `tools` list passed to the `chat` method contains regular Python function objects instead of expected `FunctionTool` objects.\n\nI have tried my best to try to get around, but no success. Is there anyone who can look into this issue? or is it a problem with my usage of function call?",
      "state": "closed",
      "author": "michaelawea",
      "author_type": "User",
      "created_at": "2025-04-13T00:50:34Z",
      "updated_at": "2025-04-13T19:19:34Z",
      "closed_at": "2025-04-13T18:53:13Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1983/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 1
      },
      "assignees": [
        "jayeshp19"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1983",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1983",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:38.671730",
      "comments": [
        {
          "author": "jayeshp19",
          "body": "I've created this PR to fix this : https://github.com/livekit/agents/pull/1984 \n\nUsing tool_choice=\"required\" forces the function to be called every time, which isn’t practical for voice agents.\nI’m still unsure why the function isn’t being called when tool_choice is left unset, it’s working fine on",
          "created_at": "2025-04-13T05:54:31Z"
        },
        {
          "author": "michaelawea",
          "body": "According to your suggestion, I removed the tool_choice parameter from the code. However, for google.llm, it still never uses the function_tool. I tried replacing only the google.llm in the agent with openai.llm, keeping the rest of the code unchanged, and in that case, the openai.llm was able to co",
          "created_at": "2025-04-13T12:29:17Z"
        },
        {
          "author": "jayeshp19",
          "body": "> According to your suggestion, I removed the tool_choice parameter from the code. However, for google.llm, it still never uses the function_tool. I tried replacing only the google.llm in the agent with openai.llm, keeping the rest of the code unchanged, and in that case, the openai.llm was able to ",
          "created_at": "2025-04-13T16:04:05Z"
        },
        {
          "author": "michaelawea",
          "body": "Apologies for the confusion — I just identified and resolved the issue. It turns out the problem was on my end, in the code logic. I was using the structured_output feature, but unlike OpenAI’s LLMs, Gemini doesn’t support a dedicated response_format parameter to define output formatting. As a worka",
          "created_at": "2025-04-13T18:52:58Z"
        },
        {
          "author": "michaelawea",
          "body": "so in the end, it is all about prompt engineering",
          "created_at": "2025-04-13T19:19:33Z"
        }
      ]
    },
    {
      "issue_number": 1719,
      "title": "AWS Credentials Security Issue",
      "body": "## Description\n\nThe AWS plugin currently requires long-term credentials (AWS Access Key and Secret Key) which goes against AWS security best practices. This makes it unsafe to run inside AWS services (EC2, ECS, EKS pods) where temporary credentials from STS are the recommended approach.\n\n### Current Implementation\nThe plugin currently:\n1. Requires explicit AWS credentials through environment variables (`AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`) or constructor parameters\n2. Does not support AWS IAM roles or temporary credentials from STS\n3. Forces users to use long-term credentials even when running in AWS environments\n\n### Impact\n- Security risk when running in AWS environments\n- Incompatible with AWS best practices for credential management\n- Limited usability in containerized environments (ECS, EKS)\n- Forces users to use long-term credentials when temporary credentials would be more appropriate\n\n## Proposed Solution\n\n1. Modify the credential handling to support the AWS credential provider chain:\n   - Support IAM roles for EC2/ECS/EKS\n   - Support temporary credentials from STS\n   - Fall back to environment variables/parameters only when necessary\n\n2. Update the documentation to reflect AWS best practices for credential management\n\n3. Add examples for different deployment scenarios (local development, EC2, ECS, EKS)\n\n## Environment\n- AWS Plugin Version: 0.1.1\n- Python Version: 3.9+\n- AWS SDK Version: boto3==1.36.3\n\n## Additional Context\nThis issue affects all AWS services used by the plugin (Polly, Transcribe, Bedrock) as they all use the same credential handling mechanism.\n\n## Contributor Note\nI am happy to submit a PR to implement these changes and improve the security of the AWS plugin. \n\n## References\n- [AWS Security Best Practices](https://docs.aws.amazon.com/general/latest/gr/aws-access-keys-best-practices.html)\n- [AWS Credentials Provider Chain](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html) ",
      "state": "closed",
      "author": "andormarkus-alcd",
      "author_type": "User",
      "created_at": "2025-03-24T13:50:29Z",
      "updated_at": "2025-04-13T07:27:06Z",
      "closed_at": "2025-04-13T07:27:06Z",
      "labels": [
        "community"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1719/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1719",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1719",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:38.915485",
      "comments": [
        {
          "author": "davidzhao",
          "body": "we'd appreciate PRs on this one!",
          "created_at": "2025-03-29T07:16:17Z"
        },
        {
          "author": "andormarkus",
          "body": "Hi @davidzhao \n\nHere is the PR: https://github.com/livekit/agents/pull/1722\nI'm waiting for next round of review",
          "created_at": "2025-03-29T12:56:14Z"
        },
        {
          "author": "davidzhao",
          "body": "thank you! we'll get it reviewed.",
          "created_at": "2025-03-30T07:19:59Z"
        }
      ]
    },
    {
      "issue_number": 1980,
      "title": "No module named 'livekit.agents.multimodal'",
      "body": "I am trying to use python module livekit.agents.multimodal, I pip installed livekit-agents, I am able to import livekit.agents, so I assume this should also contain multimodal module. I see the documentation for multimodal exists, but I am getting an error No module named 'livekit.agents.multimodal' and I also cannot locate such module in this repo.\n",
      "state": "closed",
      "author": "NerijaK",
      "author_type": "User",
      "created_at": "2025-04-12T08:39:25Z",
      "updated_at": "2025-04-13T06:55:50Z",
      "closed_at": "2025-04-13T06:55:49Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1980/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1980",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1980",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:39.138628",
      "comments": [
        {
          "author": "davidzhao",
          "body": "in Agents v1, multimodal is deprecated. see [migration guide](https://docs.livekit.io/agents/start/v0-migration/#unified-agent-interface)",
          "created_at": "2025-04-13T06:55:49Z"
        }
      ]
    },
    {
      "issue_number": 1870,
      "title": "Example Request: An example for full caller agent",
      "body": "Can you provide a fully fledged phone agent example like [here](https://github.com/pipecat-ai/pipecat/tree/main/examples/phone-chatbot)?\n\nThank you\n",
      "state": "closed",
      "author": "quancore",
      "author_type": "User",
      "created_at": "2025-04-03T14:06:10Z",
      "updated_at": "2025-04-12T17:45:53Z",
      "closed_at": "2025-04-12T17:45:53Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1870/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1870",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1870",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:39.356917",
      "comments": [
        {
          "author": "davidzhao",
          "body": "here's an outbound version of the caller: https://github.com/livekit-examples/outbound-caller-python/",
          "created_at": "2025-04-12T17:45:08Z"
        },
        {
          "author": "davidzhao",
          "body": "here's the full guide: https://docs.livekit.io/agents/start/telephony/",
          "created_at": "2025-04-12T17:45:51Z"
        }
      ]
    },
    {
      "issue_number": 1932,
      "title": "Deepgram STT doesn't work with FallbackAdapter",
      "body": "<!--\nHello! Thanks for taking the time to file a bug report.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already reported this issue.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n-->\nDeepgram STT doesn't work with FallbackAdapter.\n\nSometimes the forward input task exits.",
      "state": "closed",
      "author": "zizhong",
      "author_type": "User",
      "created_at": "2025-04-08T17:44:36Z",
      "updated_at": "2025-04-12T02:40:52Z",
      "closed_at": "2025-04-12T02:40:51Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1932/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1932",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1932",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:39.566972",
      "comments": []
    },
    {
      "issue_number": 1788,
      "title": "OpenAI BadRequestError 400: \"messages with role 'tool' must be a response...\" after successful tool execution [LiveKit Agents V1.03]",
      "body": "Description:\nWe are encountering a persistent openai.BadRequestError (HTTP 400) when using livekit-agents with the OpenAI LLM plugin for tool calling. The error occurs after a custom tool, defined using @function_tool, successfully executes and returns its result.\n\nThe specific error message from OpenAI is:\n'message': \"Invalid parameter: messages with role 'tool' must be a response to a preceeding message with 'tool_calls'.\" (referencing messages.[11].role or similar indices).\n\nExpected Behavior:\nAfter a tool successfully executes, livekit-agents should correctly format the conversation history, including the role: tool message(s) with the correct tool_call_id and content, immediately following the initiating assistant message containing the tool_calls. The subsequent API call to OpenAI should succeed (assuming no other issues), allowing the conversation to continue.",
      "state": "closed",
      "author": "mercuryyy",
      "author_type": "User",
      "created_at": "2025-03-28T19:13:47Z",
      "updated_at": "2025-04-11T23:14:59Z",
      "closed_at": "2025-04-11T23:14:59Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1788/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "longcw"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1788",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1788",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:39.566994",
      "comments": [
        {
          "author": "longcw",
          "body": "Could you share a reproducible example? This happens when the tool message doesn't follow the tool call message, and also if the chat ctx is truncated.",
          "created_at": "2025-03-29T02:22:07Z"
        },
        {
          "author": "mercuryyy",
          "body": "```\nclass MyAgent(Agent):\n    def __init__(self) -> None:\n        super().__init__(\n            instructions=\"Your name is Jenna. You would interact with users via voice.\"\n            \"with that in mind keep your responses concise and to the point.\"\n            \"You are curious and friendly, and hav",
          "created_at": "2025-03-29T04:27:49Z"
        },
        {
          "author": "longcw",
          "body": "The error in EOU was fixed in https://github.com/livekit/agents/pull/1796",
          "created_at": "2025-03-29T04:38:23Z"
        },
        {
          "author": "mercuryyy",
          "body": "Thanks!",
          "created_at": "2025-03-29T04:55:10Z"
        },
        {
          "author": "davidzhao",
          "body": "are you still seeing 400 errors? or was the EOU bug the root cause?",
          "created_at": "2025-03-29T05:40:41Z"
        }
      ]
    },
    {
      "issue_number": 1955,
      "title": "How to define function call argument `enum` values (and other optional fields like description, pattern)?",
      "body": "Previously with agents framework 0.x, we had the ability to define argument descriptions as shown here: https://docs.livekit.io/agents/voice-agent/function-calling/\n\nNow with agents framework 1.x, we've lost the ability to define even descriptions. The suggested approach is to define argument descriptions within the tool description: https://docs.livekit.io/agents/v1/build/tools/#arguments-and-return-value\n\nWhile this might be fine for description, our use case would become much more reliable if for certain fields we can define `enum` values so we can constrain argument output values.  The following two links from OpenAI's Realtime API shows how this might manifest in their agentic voice use case, and obviously in the cascading approach all LLMs support enum definitions as well:\n1. https://github.com/openai/openai-realtime-agents/blob/6f5f0de6c0124aa9ea6d8a98b055c3daa233f1d4/src/app/agentConfigs/customerServiceRetail/authentication.ts#L232\n2. https://github.com/openai/openai-realtime-agents/blob/6f5f0de6c0124aa9ea6d8a98b055c3daa233f1d4/src/app/agentConfigs/customerServiceRetail/authentication.ts#L310\n\nCan `enum` definition (alongside other fields like `description` and `pattern`) be supported?  I would hope that this would be implemented in such a way where the enums can be updated dynamically during a session because sometimes it is context specific.",
      "state": "closed",
      "author": "yuyuma",
      "author_type": "User",
      "created_at": "2025-04-10T06:03:51Z",
      "updated_at": "2025-04-11T20:32:21Z",
      "closed_at": "2025-04-11T20:32:20Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1955/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1955",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1955",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:39.835483",
      "comments": [
        {
          "author": "ChenghaoMou",
          "body": "It is using [docstring_parser](https://pypi.org/project/docstring_parser/) under the hood to get those descriptions. You can just add docstrings instead.",
          "created_at": "2025-04-10T09:00:16Z"
        },
        {
          "author": "yuyuma",
          "body": "@ChenghaoMou thanks for your response.  I only mentioned 0.x's annotated types function argument definition to illustrate how on the surface it seemed to make possible specifying JSON schema features like enums for argument parameters.  But it probably confused my core ask around how I accomplish th",
          "created_at": "2025-04-10T19:01:56Z"
        },
        {
          "author": "ChenghaoMou",
          "body": "I am bit confused. Could you share an example where adding argument description like this \n\n```python\n@function_tool\ndef f(x, y):\n\t\"\"\"\n\tThis is a function to do x, y, and z.\n\n\tParams\n\t------\n\tx : enum\n\t\tDescription: This should be some kind of enum with values (\"a\", \"b\", and \"c\")\n\t\"\"\"\n\t...\n```\n\nin v",
          "created_at": "2025-04-10T19:27:14Z"
        },
        {
          "author": "yuyuma",
          "body": "@ChenghaoMou I don't mean to suggest that v1 is more difficult than v0.  I understand that the Livekit's suggested approach is to just specify everything in the **tool-level** description regardless of version.\n\nI'm asking for the ability to specify additional **argument-level** configurations such ",
          "created_at": "2025-04-10T22:24:02Z"
        },
        {
          "author": "longcw",
          "body": "You can use\n```python\n    @function_tool\n    async def toggle_light(\n        self,\n        switch_to: Literal[\"on\", \"off\"],\n    ):\n        \"\"\"Called when user asks to turn on or off the light.\"\"\"\n        if switch_to == \"on\":\n            self.light_on = True\n        else:\n            self.light_on =",
          "created_at": "2025-04-11T02:13:03Z"
        }
      ]
    },
    {
      "issue_number": 1135,
      "title": "Bug or expected output for STT metrics?",
      "body": "We save the metrics outputted by the `metrics_collected` for STT events without modification, and below is an example of what we have saved for some Deepgram events. Across this and all other calls, for Deepgram the `audio_duration` is always incremented by 5s and the duration is always 5s. We were hoping these metrics would collect more specifically how long it takes to start / fully receive the STT streamed response, and also get how long the audio being transcribed is. Is the below a bug or expected behavior that the metrics are being recorded this way?\r\n\r\n<img width=\"385\" alt=\"Screenshot 2024-11-25 at 5 08 12 PM\" src=\"https://github.com/user-attachments/assets/7c0b8377-c952-4b6f-9b50-38cf27ff35e7\">\r\n\r\nlivekit-agents = \"0.11.3\"",
      "state": "open",
      "author": "cch41",
      "author_type": "User",
      "created_at": "2024-11-26T01:12:28Z",
      "updated_at": "2025-04-11T14:11:48Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1135/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1135",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1135",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:40.110321",
      "comments": [
        {
          "author": "bunsho-rgs",
          "body": "I’m encountering the same issue.\nMy setup: livekit-agent v1.0, using Deepgram as the STT engine.\n\n>  INFO livekit.agents - STT metrics: audio_duration=5.00 ",
          "created_at": "2025-04-11T12:29:26Z"
        },
        {
          "author": "ChenghaoMou",
          "body": "In v1, here is a workaround I found that can collect some approximation of time to first text/transcript:\n\n- `@session.on(\"user_state_changed\")` when user changes to speaking, mark the time and reset a flag `first_transcript`\n- `@session.on(\"user_input_transcribed\")` calculate the time delay here wh",
          "created_at": "2025-04-11T14:11:46Z"
        }
      ]
    },
    {
      "issue_number": 1774,
      "title": "Customizing LLM Output Handling in Voice Pipeline: Dynamic TTS Instruction + Filtered Chat Stream",
      "body": "<!--\nHello! Thanks for taking the time to ask a question.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already asked this question.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n\nFeel free to join us in the #agents channel on our Slack, and ask your question\nthere to get quicker help from us and the community:\n\nhttps://livekit.io/join-slack\n-->\nHello!\n\nHere's the issue I'm facing with the LiveKit Agent Voice Pipeline:\n\nI'm using the Voice Pipeline Agent which follows the STT -> LLM -> TTS workflow. However, in my implementation, I demande LLM to generate responses in JSON format containing two elements: `voice_instruction` and `content`.\n\nfor example:\n```\n{\n  \"voice_instruction\": \"calm, gentle tone\",\n  \"content\": \"Sure, I’ve set the thermostat to 22 degrees.\"\n}\n```\n\nWhen using the `OpenAI 4o-mini-tts` model for speech synthesis, this model accepts an instruction parameter (added in #1701 ). My goal is to:\n\n1. Use the `content` field from the LLM's JSON response as the TTS input text\n2. Use the `voice_instruction` field as the instruction parameter for the TTS model\n3. In the chat context stream output, only display the `content` stream rather than the full JSON\n\nSo far:\n\n- I was able to extract and use content as the TTS input via the `before_tts_cb` hook.\n- although implement TTS instruction also via `before_tts_cb`, but it doesn't seem working.\n\nHowever, I couldn’t find any customization point that lets me filter or transform the output shown in the chat context stream. It always displays the entire JSON output from the LLM, instead of just the content field.\n\nIs there a solution or planned feature that would allow this level of customization in the pipeline? Specifically:\n- How can I dynamically set the instruction for TTS?\n- Is there a way to post-process the LLM output before it gets pushed to the chat context stream?\n\nThanks in advance!\n",
      "state": "closed",
      "author": "michaelawea",
      "author_type": "User",
      "created_at": "2025-03-28T13:46:11Z",
      "updated_at": "2025-04-11T13:17:18Z",
      "closed_at": "2025-04-11T13:17:18Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1774/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1774",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1774",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:40.337445",
      "comments": [
        {
          "author": "michaelawea",
          "body": "The new example in https://github.com/livekit/agents/blob/main/examples/voice_agents/structured_output.py gives a perfect demonstration of the solution. \n\nThank you very much!!",
          "created_at": "2025-04-11T13:17:12Z"
        }
      ]
    },
    {
      "issue_number": 1860,
      "title": "Possibly skipping audio frames in rare cases in FallbackSynthesizeStream",
      "body": "<img width=\"555\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/f09a518e-5f12-4a9a-bced-49e8166e505d\" />\n\nIn the code above in `FallbackSynthesizeStream`, if we follow these steps (hypothetically):\n1. done() returns False, continuing the while loop;\n2. done() returns True when checked in the if statement (I have no idea how unlikely it is though);\n3. task is overwritten by a new task, but the old one's audio frame was never consumed.\n\nI have only looked at the code for a short time, so I might be missing a lot of context. Feel free to close it if it turns out to be a non-issue.",
      "state": "closed",
      "author": "ChenghaoMou",
      "author_type": "User",
      "created_at": "2025-04-02T10:59:22Z",
      "updated_at": "2025-04-11T11:09:17Z",
      "closed_at": "2025-04-11T11:09:17Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1860/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1860",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1860",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:40.569766",
      "comments": []
    },
    {
      "issue_number": 1971,
      "title": "self.update_update_instructions() is lagging",
      "body": "I want to update the instructions in the `on_user_turn_completed` (so before the next LLM call).\nWhat I see is that the instructions are propagated to the LLM only **after the next LLM **call**, so one step too late.\n\nHere is an example\n```\nclass RolePlayAgent(Agent):\n    def __init__(self, room_metadata: RoomMetadata) -> None:\n        chat_ctx = ChatContext()\n        chat_ctx.add_message(\n                role=\"user\",\n                content=[\"hi!\"],\n            )\n        )\n        super().__init__(\n            instructions=\"Respond in 1 sentence.\",\n            chat_ctx=chat_ctx,\n        )\n\n    # override method from superclass to customize behavior\n    async def on_user_turn_completed(\n        self, chat_ctx: llm.ChatContext, new_message: llm.ChatMessage\n    ) -> None:\n        await self.update_instructions(\"Now just say 'yes' or 'no' to the user.\")\n\n        print(\"--- after updating instructions ---\")\n        print(self.instructions)\n```\n\n\nI logged the instruction before the LLM call in the /anthropic/resources/messages/messages.py\n````\n        print(\"--- system message before sending to LLM ---\")\n        print(system)\n return await self._post(\n            \"/v1/messages\",\n            body=await async_maybe_transform(\n                {\n                    \"max_tokens\": max_tokens,\n                    \"messages\": messages,\n                    \"model\": model,\n                    \"metadata\": metadata,\n                    \"stop_sequences\": stop_sequences,\n                    \"stream\": stream,\n                    \"system\": system,\n                    \"temperature\": temperature,\n                    \"thinking\": thinking,\n                    \"tool_choice\": tool_choice,\n                    \"tools\": tools,\n                    \"top_k\": top_k,\n                    \"top_p\": top_p,\n                },\n                message_create_params.MessageCreateParams,\n            ),\n            options=make_request_options(\n                extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n            ),\n            cast_to=Message,\n            stream=stream or False,\n            stream_cls=AsyncStream[RawMessageStreamEvent],\n        )\n```\n\nThese are the logs\n```\n--- after updating instructions ---\nNow just say 'yes' or 'no' to the user.\n--- system message before sending to LLM ---\n[{'text': 'Respond in 1 sentence.', 'type': 'text', 'cache_control': None}]\n--- after updating instructions ---\nNow just say 'yes' or 'no' to the user.\n--- system message before sending to LLM ---\n[{'text': \"Now just say 'yes' or 'no' to the user.\", 'type': 'text', 'cache_control': None}]\n```",
      "state": "closed",
      "author": "NikoLandgraf",
      "author_type": "User",
      "created_at": "2025-04-11T09:35:47Z",
      "updated_at": "2025-04-11T10:03:01Z",
      "closed_at": "2025-04-11T09:55:54Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1971/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1971",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1971",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:40.569784",
      "comments": [
        {
          "author": "longcw",
          "body": "same as https://github.com/livekit/agents/issues/1970",
          "created_at": "2025-04-11T09:55:53Z"
        },
        {
          "author": "longcw",
          "body": "If you want to modify the instructions for this turn, you can modify it in place in the `turn_ctx`",
          "created_at": "2025-04-11T10:03:00Z"
        }
      ]
    },
    {
      "issue_number": 1962,
      "title": "Object of type ChatMessage is not JSON serializable",
      "body": "In the latest version, events like `generate_reply` send the chat message directly into the runner's `tracing_info` but unfortunately ChatMessage is not JSON serializable. So it crashes at the runner endpoint around\n\n```python\ninfo = await asyncio.wait_for(runner.tracing_info(), timeout=5.0)  # proc could be stuck\nreturn web.json_response({\"tracing\": info})\n```\n\nExample info (partial)\n```python\n{'name': 'generate_reply', 'data': {'new_message': ChatMessage(id='item_ee9a54d1647b', type='message', role='user', content=['testing testing can you hear me'], interrupted=False, hash=None), 'instructions': None}\n```",
      "state": "closed",
      "author": "ChenghaoMou",
      "author_type": "User",
      "created_at": "2025-04-10T15:54:24Z",
      "updated_at": "2025-04-10T18:38:07Z",
      "closed_at": "2025-04-10T18:38:07Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1962/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1962",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1962",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:40.768707",
      "comments": []
    },
    {
      "issue_number": 1944,
      "title": "when using Deepgram STT with language=multi the startup times of STT is very slow",
      "body": "compare using Deepgram STT plugin with `language=en` VS `language=multi` in streaming context, it is much slowe, and sometimes takes more than the 10 second default timeout for starting - causing the operation to fail\n\nrelated: https://github.com/deepgram/deepgram-python-sdk/issues/516\n",
      "state": "open",
      "author": "aviadr1",
      "author_type": "User",
      "created_at": "2025-04-09T14:11:08Z",
      "updated_at": "2025-04-09T14:11:08Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1944/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1944",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1944",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:40.768724",
      "comments": []
    },
    {
      "issue_number": 1940,
      "title": "Second speech inputs are not answered immediately with neuphonic TTS",
      "body": "I am using below sample code. Sometimes the second input is not answered immediately when using neuphonic TTS.\nHere are the steps to reproduce the issue:\n- Say Hello. Agent will reply.\n- Say \"tell me Joke\".  There will no reply.\n- Now say \"good one\". It will now respond with a joke (answer to second input above) and also respond to latest input.\n\nTry to talk with the agent a few times and the issue would occur.\nExpected is that second speech input should be answered immediately.\n\n```\nimport asyncio\nimport logging\n\nfrom dotenv import load_dotenv\nfrom livekit import rtc\nfrom livekit.agents import (\n    AutoSubscribe,\n    JobContext,\n    JobProcess,\n    WorkerOptions,\n    cli,\n    llm,\n    metrics,\n)\nfrom livekit.agents.pipeline import VoicePipelineAgent\nfrom livekit.plugins import deepgram, openai, silero, neuphonic\n\nload_dotenv()\nlogger = logging.getLogger(\"voice-assistant\")\n\n\ndef prewarm(proc: JobProcess):\n    proc.userdata[\"vad\"] = silero.VAD.load()\n\n\nasync def entrypoint(ctx: JobContext):\n    initial_ctx = llm.ChatContext().append(\n        role=\"system\",\n        text=(\n            \"You are a voice assistant created by LiveKit. Your interface with users will be voice. \"\n            \"You should use short and concise responses, and avoiding usage of unpronouncable punctuation.\"\n        ),\n    )\n\n    logger.info(f\"connecting to room {ctx.room.name}\")\n    await ctx.connect(auto_subscribe=AutoSubscribe.AUDIO_ONLY)\n\n    # wait for the first participant to connect\n    participant = await ctx.wait_for_participant()\n    logger.info(f\"starting voice assistant for participant {participant.identity}\")\n\n    dg_model = \"nova-3-general\"\n    if participant.kind == rtc.ParticipantKind.PARTICIPANT_KIND_SIP:\n        # use a model optimized for telephony\n        dg_model = \"nova-2-phonecall\"\n\n    agent = VoicePipelineAgent(\n        vad=ctx.proc.userdata[\"vad\"],\n        stt=deepgram.STT(model=dg_model, api_key=\"my_key_here\"),\n        llm=openai.LLM(api_key=\"my_key_here\"),\n        tts=neuphonic.TTS(\n            api_key=\"my_key_here\",\n            speed=\"1\",\n            voice_id=\"79ffd956-872a-4b89-b25b-d99bb4335b82\",\n            model=\"neu_hq\",\n            lang_code=\"en\"\n            ),\n        chat_ctx=initial_ctx,\n    )\n\n    agent.start(ctx.room, participant)\n\n    usage_collector = metrics.UsageCollector()\n\n    @agent.on(\"metrics_collected\")\n    def _on_metrics_collected(mtrcs: metrics.AgentMetrics):\n        metrics.log_metrics(mtrcs)\n        usage_collector.collect(mtrcs)\n\n    async def log_usage():\n        summary = usage_collector.get_summary()\n        logger.info(f\"Usage: ${summary}\")\n\n    ctx.add_shutdown_callback(log_usage)\n\n    # listen to incoming chat messages, only required if you'd like the agent to\n    # answer incoming messages from Chat\n    chat = rtc.ChatManager(ctx.room)\n\n    async def answer_from_text(txt: str):\n        chat_ctx = agent.chat_ctx.copy()\n        chat_ctx.append(role=\"user\", text=txt)\n        stream = agent.llm.chat(chat_ctx=chat_ctx)\n        await agent.say(stream)\n\n    @chat.on(\"message_received\")\n    def on_chat_received(msg: rtc.ChatMessage):\n        if msg.message:\n            asyncio.create_task(answer_from_text(msg.message))\n\n    await agent.say(\"Hey, how can I help you today?\", allow_interruptions=True)\n\n\nif __name__ == \"__main__\":\n    cli.run_app(\n        WorkerOptions(\n            entrypoint_fnc=entrypoint,\n            prewarm_fnc=prewarm,\n        ),\n    )\n```",
      "state": "open",
      "author": "meetakshay99",
      "author_type": "User",
      "created_at": "2025-04-09T10:42:08Z",
      "updated_at": "2025-04-09T10:42:08Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1940/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1940",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1940",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:40.768743",
      "comments": []
    },
    {
      "issue_number": 1926,
      "title": "Access to deployed Agent with FastAPI example",
      "body": "Hi, I would like to know if there is an example or if you could provide me with one showing how to access a voice agent deployed in the cloud that uses FastApi and can be accessed through an endpoint.\n\nI would like to create dynamic variables that can be populated based on the request sent. For example, I could send certain information on my endpoint, such as the name of the caller.\nAnother example could be, depending on the country code where the call is received from, I could redirect to an English-speaking agent or one who speaks Spanish.\n\nThanks.",
      "state": "open",
      "author": "neymartes",
      "author_type": "User",
      "created_at": "2025-04-08T15:07:45Z",
      "updated_at": "2025-04-09T06:04:05Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1926/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1926",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1926",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:40.768749",
      "comments": [
        {
          "author": "shwetd19",
          "body": "Hi @neymartes ! \n\nWhile there isn’t a pre-built example in the LiveKit Agents repository that specifically shows a voice agent deployed in the cloud using FastAPI with an endpoint and dynamic variables, I can guide you with relevant examples,\n\nRelevant Examples from LiveKit Agents\n\n[Voice Pipeline A",
          "created_at": "2025-04-09T06:04:03Z"
        }
      ]
    },
    {
      "issue_number": 1901,
      "title": "Cancel turn feature in manual turn",
      "body": "I’m developing with the [push_to_talk example](https://github.com/livekit/agents/blob/07f03f92fee1d975e0058ce25fbfa7ff59091cfb/examples/voice_agents/push_to_talk.py) as a reference, and I’m using a custom cancel_turn RPC in addition to the existing ones. The issue I’m encountering is that even when I call `cancel_turn` to disable the input audio, the `on_end_of_turn` method still receives the audio input that was spoken before the cancel.\n\nFor example:\n```\nUSER: \"My name is Wynn\"  \n(cancel_turn RPC is called)  \nUSER: \"Do you remember my name?\"  \n(end_turn RPC is called)  \non_end_of_turn is invoked  \nnew_message argument: { role: \"user\", content: [\" My name is Wynn\\nDo you remember my name?\"] }\n```\n\nAs you can see, the first part (“My name is Wynn”) was meant to be canceled, but it still appears in the final transcript. Is there any way to distinguish or discard the portion of the transcript that was spoken before the cancel_turn?",
      "state": "closed",
      "author": "well-balanced",
      "author_type": "User",
      "created_at": "2025-04-06T07:00:26Z",
      "updated_at": "2025-04-09T05:20:21Z",
      "closed_at": "2025-04-09T02:07:31Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1901/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1901",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1901",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:40.975387",
      "comments": [
        {
          "author": "longcw",
          "body": "So you want to drop the buffered text when you cancel a turn? You can write your own `on_end_of_turn` https://github.com/livekit/agents/blob/main/examples/voice_agents/push_to_talk.py#L34-L37 to buffer the text until it the `end_turn` called, if it was canceled you can drop the buffer.",
          "created_at": "2025-04-06T07:51:23Z"
        },
        {
          "author": "well-balanced",
          "body": "@longcw \n\nI’m already implementing on_end_of_turn. As shown in the example I shared earlier, when on_end_of_turn is triggered, I have no clear way to decide whether the previous buffered text like “My name is Wynn” should be updated to chat_ctx or not.\n\nHere’s the flow:\n\nStart turn → Text A → Cancel",
          "created_at": "2025-04-06T16:12:39Z"
        },
        {
          "author": "longcw",
          "body": "I’ll create a pr to make sure the on end of turn is called only once when end user turn happens and you can cancel the user turn to clear the text buffer.",
          "created_at": "2025-04-06T16:40:10Z"
        },
        {
          "author": "longcw",
          "body": "One possible problem is that the stt may buffer the user transcription if the first turn canceled too quick. Will check how to ignore the stt buffer as well.",
          "created_at": "2025-04-06T16:45:14Z"
        },
        {
          "author": "davidzhao",
          "body": "@longcw theo had proposed raising a specific exception inside `on_end_of_turn`. it's currently not implemented but I've [stubbed out](https://github.com/livekit/agents/blob/9c913c7617f77da8a80bf0a69385ddd2ee33aa7a/examples/voice_agents/push_to_talk.py#L34) how it might look in an example.\n\n",
          "created_at": "2025-04-06T17:42:18Z"
        }
      ]
    },
    {
      "issue_number": 1906,
      "title": "Push to talk on rc6",
      "body": "Hello , we are using livekit-agents==1.0.0rc6. We used the code from [here](https://github.com/livekit/agents/blob/dev-1.0/examples/voice_agents/push_to_talk.py)\nHowever, we are seeing something very funky, when pushing on the push2talk button, only the third time it actually send the voice message. \"on_end_of_turn\" code is reached only on the third time the button is clicked, also it seems something is off with the order of messages in the chat context.\n\non the frontend the push2talk button does is:\n\nawait room.localParticipant.performRpc({\ndestinationIdentity: agentIdentity,\nmethod: 'start_turn',\npayload: JSON.stringify({}),\n});\nawait room.localParticipant.setMicrophoneEnabled(true);\n\nwhat is going on",
      "state": "closed",
      "author": "aniche",
      "author_type": "User",
      "created_at": "2025-04-06T12:00:21Z",
      "updated_at": "2025-04-09T02:09:14Z",
      "closed_at": "2025-04-09T02:09:12Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1906/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "longcw"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1906",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1906",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:41.174578",
      "comments": [
        {
          "author": "longcw",
          "body": "`Agent.on_end_of_turn` is called when STT recognized a text message from user speech but not when the `start_turn` or `end_turn` method called. \n\nFor now the `turn_detection=\"manual\"` means the Agent won't trigger a reply automatically, the user transcription will be send to the `Agent.on_end_of_tur",
          "created_at": "2025-04-06T12:13:06Z"
        },
        {
          "author": "longcw",
          "body": "Fixed in #1908 with `session.clear_user_turn` and `session.commit_user_turn` methods, the later will trigger a reply just like the VAD turn detection, but manually.",
          "created_at": "2025-04-09T02:09:12Z"
        }
      ]
    },
    {
      "issue_number": 1872,
      "title": "Connection Timeout Issue with multi_agent.py after Upgrading to Version 1.0",
      "body": "**Title:** Connection Timeout Issue with `multi_agent.py` after Upgrading to Version 1.0\n\n**Description:**\n\nHello,\n\nI encountered a connection timeout issue while running the `multi_agent.py` script following the tutorial. This problem started occurring after I upgraded to version 1.0.\n\nHere are the details of the issue:\n\n- **Steps to Reproduce:**\n  1. Followed the tutorial to set up and run the `multi_agent.py` script.\n  2. Upgraded to version 1.0 of the package.\n  3. Ran the script as instructed.\n\n- **Expected Behavior:**\n  The script should establish a connection to the room and proceed with the job execution.\n\n- **Actual Behavior:**\n  The connection to the room is not established, and the following warnings are logged:\n\n```\n2025-04-03 22:49:41,924 - WARNING livekit.agents - The room connection was not established within 10 seconds after calling job_entry. This may indicate that job_ctx.connect() was not called. {\"pid\": 40658, \"job_id\": \"AJ_QwYKGRJwtVYx\"}\n2025-04-03 22:49:46,980 - WARNING livekit - livekit::rtc_engine:388:livekit::rtc_engine - failed to connect: Connection(\"wait_pc_connection timed out\"), retrying... (1/3) {\"pid\": 40658, \"job_id\": \"AJ_QwYKGRJwtVYx\"}\n```\n\n- **Environment:**\n  - Operating System: [macOS 15.3.2 (24D81)]\n  - Python Version: 3.11\n  - Package Version: 1.0\n  - LiveKit Server: Self-hosted (local deployment)\n\n- **Additional Information:**\n  - I have ensured that the network connection is stable.\n  - I have tried restarting the script multiple times, but the issue persists.\n\nIs there a known issue with the latest version that could be causing this? Any help or suggestions on how to resolve this would be greatly appreciated.\n\nThank you!",
      "state": "open",
      "author": "chenchiwei",
      "author_type": "User",
      "created_at": "2025-04-03T14:55:49Z",
      "updated_at": "2025-04-09T01:54:52Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1872/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1872",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1872",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:41.416996",
      "comments": [
        {
          "author": "boussaidev",
          "body": "try to set the timeout\n```python \n            llm=openai.LLM(api_key=OPENAI_API_KEY, model=\"gpt-4\", timeout=30.0),\n```",
          "created_at": "2025-04-04T15:58:11Z"
        },
        {
          "author": "chenchiwei",
          "body": "> try to set the timeout\n> \n>             llm=openai.LLM(api_key=OPENAI_API_KEY, model=\"gpt-4\", timeout=30.0),\n\nIt doesn't work, it seems the open-source version has issues. The cloud version works fine, though.",
          "created_at": "2025-04-05T03:31:51Z"
        },
        {
          "author": "theomonnom",
          "body": "This seems to be an issue with your local deployment, can you try to use: https://livekit.io/connection-test",
          "created_at": "2025-04-08T12:13:17Z"
        },
        {
          "author": "chenchiwei",
          "body": "> This seems to be an issue with your local deployment, can you try to use: https://livekit.io/connection-test\n\nThe test result seems to be ok\n\n```\n\nConnecting to signal connection via WebSocket\n\nConnected to server, version 1.8.4.\n\nWarning: Server is insecure, clients may block connections to it\n\nE",
          "created_at": "2025-04-09T01:54:52Z"
        }
      ]
    },
    {
      "issue_number": 1915,
      "title": "V1.0 RC8 -- Error in _update_activity_task for Realtime Agents",
      "body": "\n**Environment:**\n- **LK Agent Version:** v1.0 rc8\n- **Agent Type:** SIP realtime voice agent\n- **Platform:** Windows (based on file paths)\n\n**Description:**\n\nWhen starting a new outbound SIP call, my SIP realtime voice agent fails to respond to messages. The error appears to be related to the referencing of the `turn_detection` property. The following error is raised:\n\n> `AttributeError: type object 'myCustomAgent' has no attribute '_turn_detection'. Did you mean: 'turn_detection'?`\n\n**Steps to Reproduce:**\n\n1. **Agent Definition:**  \n   Use the following agent code:\n   ```python\n   class myCustomAgent(Agent):\n       def __init__(self, instructions: str):\n           super().__init__(\n               instructions=instructions,\n               llm=openai.realtime.RealtimeModel(\n                   voice=\"echo\",\n                   turn_detection=None,\n                   input_audio_transcription=None,\n                   max_response_output_tokens=250,\n                   temperature=0.8,\n               ),\n           )\n\n       async def on_enter(self):\n           self.session.generate_reply()\n   ```\n\n2. **Entrypoint Code:**  \n   Use this entrypoint code to initialize the session and start the agent:\n   ```python\n   # --- Entrypoint using AgentSession ---\n   async def entrypoint(ctx: JobContext):\n       await ctx.connect(auto_subscribe=AutoSubscribe.AUDIO_ONLY)\n \n   # More code for SIP implementation here I've left out\n   # More code for SIP implementation here I've left out\n   # More code for SIP implementation here I've left out\n\n       # Create an AgentSession with the new turn detector, VAD, and STT\n       session = AgentSession(\n           turn_detection=EOUModel(),\n           vad=ctx.proc.userdata[\"vad\"],\n           stt=deepgram.STT(api_key=os.getenv(\"DEEPGRAM_API_KEY\")),\n           allow_interruptions=True,\n           # room_output_options=RoomOutputOptions(transcription_enabled=True),\n       )\n       await session.start(agent=myCustomAgent, room=ctx.room)\n\n\n   def prewarm(proc: JobProcess):\n       print('prewarmed my poosie')\n       proc.userdata[\"vad\"] = silero.VAD.load()\n\n\n   if __name__ == \"__main__\":\n       cli.run_app(WorkerOptions(\n           entrypoint_fnc=entrypoint,\n           prewarm_fnc=prewarm,\n           # Add the agent_name parameter to your WorkerOptions\n           agent_name=\"lowballer9k\"\n       ))\n   ```\n\n3. **Execution:**  \n   Start the application and initiate a new outbound SIP call.\n\n**Expected Behavior:**\n\nThe SIP realtime voice agent should start and correctly handle messages without throwing an attribute error.\n\n**Actual Behavior:**\n\nThe agent fails with the following error:\n```\nAttributeError: type object 'myCustomAgent' has no attribute '_turn_detection'. Did you mean: 'turn_detection'?\n```\n\n**Full Logs:**\n```\n2025-04-07 09:16:23,111 - ERROR livekit.agents - Error in _update_activity_task\nTraceback (most recent call last):\n  File \"C:\\Users\\antwo\\Documents\\GitHub\\lk-dialer\\venv\\Lib\\site-packages\\livekit\\agents\\utils\\log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antwo\\Documents\\GitHub\\lk-dialer\\venv\\Lib\\site-packages\\livekit\\agents\\voice\\agent_session.py\", line 393, in _update_activity_task     \n    self._next_activity = AgentActivity(task, self)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antwo\\Documents\\GitHub\\lk-dialer\\venv\\Lib\\site-packages\\livekit\\agents\\voice\\agent_activity.py\", line 82, in __init__\n    self.turn_detection if isinstance(self.turn_detection, str) else None   \n                                      ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antwo\\Documents\\GitHub\\lk-dialer\\venv\\Lib\\site-packages\\livekit\\agents\\voice\\agent_activity.py\", line 169, in turn_detection\n    return self._agent._turn_detection or self._session._turn_detection     \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: type object 'myCustomAgent' has no attribute '_turn_detection'. Did you mean: 'turn_detection'?\n2025-04-07 09:16:23,113 - ERROR livekit.agents - unhandled exception while running the job task\nTraceback (most recent call last):\n  File \"C:\\Users\\antwo\\Documents\\GitHub\\lk-dialer\\watch_agent_new.py\", line 273, in entrypoint\n    await session.start(agent=myCustomAgent, room=ctx.room)\n  File \"C:\\Users\\antwo\\Documents\\GitHub\\lk-dialer\\venv\\Lib\\site-packages\\livekit\\agents\\voice\\agent_session.py\", line 264, in start\n    await self._update_activity_task(self._agent)\n  File \"C:\\Users\\antwo\\Documents\\GitHub\\lk-dialer\\venv\\Lib\\site-packages\\livekit\\agents\\utils\\log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antwo\\Documents\\GitHub\\lk-dialer\\venv\\Lib\\site-packages\\livekit\\agents\\voice\\agent_session.py\", line 393, in _update_activity_task     \n    self._next_activity = AgentActivity(task, self)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antwo\\Documents\\GitHub\\lk-dialer\\venv\\Lib\\site-packages\\livekit\\agents\\voice\\agent_activity.py\", line 82, in __init__\n    self.turn_detection if isinstance(self.turn_detection, str) else None   \n                                      ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antwo\\Documents\\GitHub\\lk-dialer\\venv\\Lib\\site-packages\\livekit\\agents\\voice\\agent_activity.py\", line 169, in turn_detection\n    return self._agent._turn_detection or self._session._turn_detection     \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: type object 'myCustomAgent' has no attribute '_turn_detection'. Did you mean: 'turn_detection'?\n2025-04-07 09:16:23,594 - DEBUG livekit.agents - start reading stream {\"participant\": \"+1234567890\", \"source\": \"SOURCE_MICROPHONE\"}\n```\n\nAny insights or guidance on how to resolve this attribute mismatch would be greatly appreciated.\n\nThanks!",
      "state": "closed",
      "author": "tonyGePT",
      "author_type": "User",
      "created_at": "2025-04-07T16:30:21Z",
      "updated_at": "2025-04-08T17:22:50Z",
      "closed_at": "2025-04-08T03:19:56Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1915/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1915",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1915",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:43.413072",
      "comments": [
        {
          "author": "longcw",
          "body": "It's `await session.start(agent=myCustomAgent, room=ctx.room)` should be `await session.start(agent=myCustomAgent(), room=ctx.room)`, you are passing the type instead of the agent instance to the `session.start`",
          "created_at": "2025-04-08T03:19:18Z"
        },
        {
          "author": "tonyGePT",
          "body": "Thank you! Also you may want to update your docs: \n\n![Image](https://github.com/user-attachments/assets/e9b7e604-c689-4b0b-9cbe-a4bc819f6284)",
          "created_at": "2025-04-08T15:43:18Z"
        },
        {
          "author": "davidzhao",
          "body": "that looks correct.. agent is an instance of the class.",
          "created_at": "2025-04-08T17:22:48Z"
        }
      ]
    },
    {
      "issue_number": 1894,
      "title": "VoicePipelineAgent Custom UseCase",
      "body": "I’m exploring the VoicePipelineAgent feature and wanted to understand if the following use cases are supported and how to best implement them:\n\n1. #### Voice input → STT → LLM → Text-only output:\nI’d like to use voice input for providing instructions, have it transcribed using STT, passed to an LLM, and then receive only the text response (i.e., no TTS or spoken output). Is this achievable with the current VoicePipelineAgent setup?\n\n2. #### Voice input → STT → LLM → Partial TTS + Text:\nIn a similar flow, I’d like to get the first sentence of the LLM response as synthesized voice, and the rest of the content as plain text (for display in a UI).\nIs there a recommended way to split the LLM response and route only part of it to the TTS node?\n\nWould really appreciate guidance or examples on how to configure the pipeline for these cases 🙏\n\nThanks!\n",
      "state": "closed",
      "author": "rahulroshan96",
      "author_type": "User",
      "created_at": "2025-04-05T08:05:37Z",
      "updated_at": "2025-04-08T06:09:34Z",
      "closed_at": "2025-04-08T06:09:34Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1894/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1894",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1894",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:43.843922",
      "comments": [
        {
          "author": "longcw",
          "body": "In agents 1.0 both are supported. You can disable the audio output in [RoomIO](https://github.com/livekit/agents/blob/main/livekit-agents/livekit/agents/voice/room_io/room_io.py#L66) completely, or toggle it on the fly ([example](https://github.com/livekit/agents/blob/main/examples/voice_agents/togg",
          "created_at": "2025-04-05T09:36:05Z"
        },
        {
          "author": "rahulroshan96",
          "body": "@longcw Thanks for the reply. Could you help me to choose the exact versions for above use cases. I am currently using below versions\n```livekit==0.19.1\nlivekit-agents==0.12.11\nlivekit-api==0.8.1\nlivekit-plugins-azure==0.5.3\nlivekit-plugins-deepgram==0.6.17\nlivekit-plugins-elevenlabs==0.7.12\nlivekit",
          "created_at": "2025-04-05T14:42:51Z"
        },
        {
          "author": "longcw",
          "body": "Those are supported in agents 1.0 https://github.com/livekit/agents?tab=readme-ov-file#installation",
          "created_at": "2025-04-05T14:48:43Z"
        }
      ]
    },
    {
      "issue_number": 1917,
      "title": "v1.0rc8: update_instructions does not update chat context",
      "body": "**Test version**: Livekit 1.0 RC8.\n\n**Expected**: `await session.current_agent.update_instructions(...)` updates the agent's instructions and behavior.\n**Actual**: Agent behavior is unchanged because the chat context is not implicitly updated.\n\n**Workaround**: Manually call update_chat_ctx after setting new instructions.\n```\nawait session.current_agent.update_instructions(\"Your name is Marry. You would interact with users via voice.\"\n                                                  \"with that in mind keep your responses concise and to the point.\"\n                                                  \"You are curious and friendly, and have a sense of humor.\")\nawait session.current_agent.update_chat_ctx(context.session.current_agent._chat_ctx)\n```",
      "state": "closed",
      "author": "AndrazP",
      "author_type": "User",
      "created_at": "2025-04-07T19:11:17Z",
      "updated_at": "2025-04-08T03:20:57Z",
      "closed_at": "2025-04-08T03:20:57Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1917/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 1,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1917",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1917",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:44.101681",
      "comments": [
        {
          "author": "longcw",
          "body": "Thanks for reporting! Created a fix in https://github.com/livekit/agents/pull/1921",
          "created_at": "2025-04-08T01:26:37Z"
        }
      ]
    },
    {
      "issue_number": 1919,
      "title": "Metadata output in console unreadable in some themes",
      "body": "Making the metadata from the console \"bright black\" (8) makes the output unreadable in many terminal themes, as many themes have that color set to a color very close to the background color (or on some terminal themes it is the background color).\n\nUnfortunately there isn't really any consistency with what \"bright black\" (8) and \"bright white\" (15) mean, so it's best to just stick with default foreground color and the _non-bright_ colors codes 1-6 for terminal output.\n\n![Image](https://github.com/user-attachments/assets/c5d1153a-14f1-4eee-aaa1-de7969353699)",
      "state": "open",
      "author": "net",
      "author_type": "User",
      "created_at": "2025-04-07T23:08:26Z",
      "updated_at": "2025-04-07T23:08:26Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1919/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1919",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1919",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:44.339942",
      "comments": []
    },
    {
      "issue_number": 1916,
      "title": "Why are there deployments from 2024 still underway?",
      "body": "## Possible Stuck Deployments?\n\n_Am I tripping… or are some CI/CD jobs still marked as “Deploying” from June 2024 and July 2024?_\n\nNoticed that:\n\t•\tfix livekit version (Jul 28, 2024) is still showing as Active.\n\t•\tRuss + KITT (Jun 13, 2024) is still in Deploying state.\n\t•\tOthers like switch back to download-files have been Ready since May 2024.\n\nIf these are indeed stuck, could this be silently incurring compute costs?\nMaybe you guys should force-stop them?\n@theomonnom \n\n<img width=\"1135\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/488022ca-ead4-45cc-b197-8186a348db48\" />",
      "state": "closed",
      "author": "V12Hero",
      "author_type": "User",
      "created_at": "2025-04-07T19:06:56Z",
      "updated_at": "2025-04-07T19:14:10Z",
      "closed_at": "2025-04-07T19:14:10Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1916/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1916",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1916",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:44.339965",
      "comments": [
        {
          "author": "V12Hero",
          "body": "Nevermind, perhaps Zeet never sent back the response to close em.",
          "created_at": "2025-04-07T19:14:07Z"
        }
      ]
    },
    {
      "issue_number": 1885,
      "title": "Feature Request: Restrict Audio Output of Voice Agent to Specific Participant",
      "body": "> Description:\n\nIn the current implementation, when an agent session is created for a participant, all participants in the room are able to hear the voice agent. However, the intended behavior is that only the participant with the identity from_identity, who requested the agent to start, should be able to hear the agent, not all participants in the room.\n\n> Current Code Snippet:\n\n````python if action == \"agent_start\":\n    session = sessions.get(from_identity)\n    if session is None:\n        logger.info(f\"Creating new agent session for {from_identity}\")\n        session = AgentSession(turn_detection=\"manual\")\n        room_io = RoomIO(agent_session=session, room=room, participant=room.remote_participants.get(from_identity))\n        await room_io.start()\n        await session.start(agent=VoiceAgent(from_identity))\n\n        sessions[from_identity] = session\n        room_ios[from_identity] = room_io\n````\n> Expected Behavior:\n\nOnly the participant who initiates the agent session (with from_identity) should be able to hear the voice agent.\n\nOther participants in the room should not hear the voice agent unless they explicitly request the agent.\n\n> Requested Action:\n\nCould you please provide guidance on how to modify the code or the room's configuration so that only the participant associated with from_identity can hear the voice agent's output? Specifically, suggestions on how to route the audio output exclusively to the correct participant would be highly appreciated.\n\n> Additional Context:\n\nAny suggestions on how to handle this in a multi-participant environment, or best practices for ensuring selective audio routing, would be valuable.\n\n",
      "state": "closed",
      "author": "boussaidev",
      "author_type": "User",
      "created_at": "2025-04-04T14:19:54Z",
      "updated_at": "2025-04-07T07:05:21Z",
      "closed_at": "2025-04-07T07:04:09Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1885/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1885",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1885",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:44.583510",
      "comments": [
        {
          "author": "davidzhao",
          "body": "this is possible today. the solution is provided [here](https://github.com/livekit/agents/issues/1663#issuecomment-2781226486)\n\nfor v1, it's a bit simpler:\n\n```python\n# only Peter should hear this \nawait ctx.room.local_participant.set_track_subscription_permissions(\n    allow_all_participants=False,",
          "created_at": "2025-04-07T07:04:09Z"
        }
      ]
    },
    {
      "issue_number": 1663,
      "title": "agent only talk to 1 specific user only in a room.",
      "body": "I have 2 users and 1 agent in a room. most of the time 2 users can hear each other and the agent. But sometimes I want only 1 user to hear the agent. How can I achieve that?\n\n<!--\nHello! Thanks for taking the time to ask a question.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already asked this question.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n\nFeel free to join us in the #agents channel on our Slack, and ask your question\nthere to get quicker help from us and the community:\n\nhttps://livekit.io/join-slack\n-->\n",
      "state": "closed",
      "author": "stevemao",
      "author_type": "User",
      "created_at": "2025-03-16T06:39:29Z",
      "updated_at": "2025-04-07T07:03:58Z",
      "closed_at": "2025-04-06T05:17:35Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1663/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 1
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1663",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1663",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:44.812305",
      "comments": [
        {
          "author": "davidzhao",
          "body": "If you only want one user to hear the agent, you can use [track permissions APIs](https://docs.livekit.io/python/livekit/rtc/participant.html#livekit.rtc.participant.LocalParticipant.set_track_subscription_permissions) from the Agent to ensure that only one of the user could access its tracks.\n\n```p",
          "created_at": "2025-03-17T06:18:09Z"
        },
        {
          "author": "stevemao",
          "body": "@davidzhao Would this mean that only this user can hear the agents, while other users can never hear them?\n\nIn my particular case we need certain responses (or `agent.say()`) from agent to deliver to 1 user only. but most of the time all users can hear all agents.\n",
          "created_at": "2025-03-17T06:53:24Z"
        },
        {
          "author": "davidzhao",
          "body": "have you tried the above?",
          "created_at": "2025-03-17T15:13:20Z"
        },
        {
          "author": "stevemao",
          "body": "@davidzhao Yes, I did. It doesn't work\n\n```python\n# this means only Peter can hear agents. Nobody else can hear them.\nctx.room.local_participant.set_track_subscription_permissions(\n    allow_all_participants=False,\n    participant_permissions=[\n        rtc.ParticipantTrackPermission(\n            par",
          "created_at": "2025-04-06T04:17:57Z"
        },
        {
          "author": "davidzhao",
          "body": "I'm confused.. this is what you had asked for:\n```\nBut sometimes I want only 1 user to hear the agent. How can I achieve that?\n```\n\nwhen you want to allow everyone to hear the agent, flip that permission bit:\n\n```\nctx.room.local_participant.set_track_subscription_permissions(\n    allow_all_participa",
          "created_at": "2025-04-06T04:47:13Z"
        }
      ]
    },
    {
      "issue_number": 1909,
      "title": "`participant_attributes_changed` vs `participant_disconnected` in version 1.0",
      "body": "https://docs.livekit.io/agents/v1/start/telephony/#call-status\n\nIn the example above, when a user or agent hangs up, both `on_attributes_changed` and `on_participant_disconnected` are called. What are the differences between the them?",
      "state": "open",
      "author": "rinarakaki",
      "author_type": "User",
      "created_at": "2025-04-07T04:15:27Z",
      "updated_at": "2025-04-07T04:15:27Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1909/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1909",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1909",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:45.130988",
      "comments": []
    },
    {
      "issue_number": 1891,
      "title": "'participant_connected' doesn't work",
      "body": "<!--\nHello! Thanks for taking the time to file a bug report.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already reported this issue.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n-->\n\n\nHi,\n\n`participant_connected`  event handler doesn't work for some reason. The room works fine. I can chat with the agent just fine, but `on_participant_connect_cb()` function doesn't ever get called when I connect the room using the playground.  Any idea why? Thank you.\n\nBest,\nEmre\n\n**Code**:\n```python\n\ndef on_participant_connect_cb(participant):\n    \"\"\"Sync callback that starts an async task when a participant joins.\"\"\"\n    print(f\"\\n\\nParticipant connected: {participant.identity}\\n\\n\")\n\nasync def entrypoint(ctx: JobContext):\n    initial_ctx = llm.ChatContext().append(\n        role=\"system\",\n        text=LIVEKIT_ROLE,\n    )\n\n    logger.info(f\"connecting to room {ctx.room.name}\")\n    ctx.room.on(\"participant_connected\", on_participant_connect_cb)\n    \n    await ctx.connect(auto_subscribe=AutoSubscribe.AUDIO_ONLY)\n\n    # Wait for the first participant to connect\n    participant = await ctx.wait_for_participant()\n    logger.info(f\"\\nstarting voice assistant for participant {participant.identity}\\n\")\n    \n    agent = VoicePipelineAgent(\n        # vad=silero.VAD.load(),\n        vad=ctx.proc.userdata[\"vad\"],\n        # flexibility to use any models\n        stt=deepgram.STT(model=\"nova-2-general\",\n                         api_key=os.environ.get(\"DEEPGRAM_API_KEY\")),\n        llm=google.LLM(api_key=os.environ.get(\"GOOGLE_API_KEY\"),\n                       max_output_tokens=512,\n                       temperature=0.2\n                       ),\n        tts=cartesia.TTS(voice='97f4b8fb-f2fe-444b-bb9a-c109783a857a'),\n        chat_ctx=initial_ctx,\n        # whether the agent can be interrupted\n        allow_interruptions=True,\n        # sensitivity of when to interrupt\n        interrupt_speech_duration=0.5,\n        interrupt_min_words=0,\n        # minimal silence duration to consider end of turn\n        min_endpointing_delay=0.5,\n        # callback to run before LLM is called, can be used to modify chat context\n        before_llm_cb=truncate_context,\n        # callback to run before TTS is called, can be used to customize pronounciation\n        before_tts_cb=before_tts_cb,\n        turn_detector=turn_detector.EOUModel(),\n        # fnc_ctx=fnc_ctx,\n    )\n\n    ctx.add_shutdown_callback(shutdown_cb)\n\n    logger.info(f\"\\nwaiting for participant to join\\n\")\n    agent.start(ctx.room, participant)\n\n    await agent.say(OPENING_PROMPT, allow_interruptions=True)\n  .\n  .\n  .\n```\n\n",
      "state": "closed",
      "author": "ekurtgl",
      "author_type": "User",
      "created_at": "2025-04-05T04:48:08Z",
      "updated_at": "2025-04-07T03:38:57Z",
      "closed_at": "2025-04-05T05:15:16Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1891/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1891",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1891",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:45.131003",
      "comments": [
        {
          "author": "davidzhao",
          "body": "when the user connects *before* the agent joins the room, this callback does not fire.. see [event definitions](https://docs.livekit.io/home/client/events/#events)\n\ninstead, you can grab the participant with:\n\n` participant = await ctx.wait_for_participant()`",
          "created_at": "2025-04-05T05:15:16Z"
        },
        {
          "author": "ekurtgl",
          "body": "Hi @davidzhao ,\n\nThank you for the clarification. I made a simple solution for now by just calling the function explicitly after the first participant joins as follows, but not sure how to apply this for every new participant:\n\n```python\n    participant = await ctx.wait_for_participant()\n    logger.",
          "created_at": "2025-04-06T19:30:25Z"
        },
        {
          "author": "longcw",
          "body": "This will apply the `on_participant_connect_cb` on both new participants and the existing participants.\n```python\n    ctx.room.on(\"participant_connected\", on_participant_connect_cb)\n\n    for participant in ctx.room.remote_participants.values():\n        on_participant_connect_cb(participant)\n```",
          "created_at": "2025-04-07T01:29:27Z"
        },
        {
          "author": "ekurtgl",
          "body": "Hi @longcw ,\n\nGot it, thank you!",
          "created_at": "2025-04-07T03:38:56Z"
        }
      ]
    },
    {
      "issue_number": 1851,
      "title": "Missing agent version in uv.lock",
      "body": "I'm working on `commit 79b1834be920d688f0d4d6f5970eccd4bc79dfb3`.\nI run agent from source, because I want to customize some features.\n\nWhen I try to setup venv using uv, running commands:\n```sh\nuv venv\nuv sync\n```\nthen there is error:\n```text\nerror: Failed to parse `uv.lock`\n  Caused by: TOML parse error at line 1151, column 1\n     |\n1151 | [[package]]\n     | ^^^^^^^^^^^\nmissing field `version`\n```\nError was on line 1151, so I line 1151~1173 of `uv.lock`, then found:\n```toml\n[[package]]\nname = \"livekit-agents\"\nsource = { editable = \"livekit-agents\" }\ndependencies = [\n    { name = \"aiohttp\" },\n    { name = \"av\" },\n    { name = \"click\" },\n    { name = \"colorama\" },\n    { name = \"docstring-parser\" },\n    { name = \"eval-type-backport\" },\n    { name = \"livekit\" },\n    { name = \"livekit-api\" },\n    { name = \"livekit-protocol\" },\n    { name = \"numpy\", version = \"2.0.2\", source = { registry = \"https://pypi.org/simple\" }, marker = \"python_full_version < '3.10'\" },\n    { name = \"numpy\", version = \"2.2.3\", source = { registry = \"https://pypi.org/simple\" }, marker = \"python_full_version >= '3.10'\" },\n    { name = \"protobuf\" },\n    { name = \"psutil\" },\n    { name = \"pyjwt\" },\n    { name = \"sounddevice\" },\n    { name = \"types-protobuf\" },\n    { name = \"typing-extensions\" },\n    { name = \"watchfiles\" },\n]\n```\nI am guessing the reason is missing version field in `livekit-agents`.\nIs it intended? Or am I doing something wrong?\n\n",
      "state": "open",
      "author": "JonghoKim-jj",
      "author_type": "User",
      "created_at": "2025-04-02T00:45:57Z",
      "updated_at": "2025-04-07T02:38:32Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1851/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1851",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1851",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:45.342264",
      "comments": [
        {
          "author": "longcw",
          "body": "cc @theomonnom ",
          "created_at": "2025-04-02T03:30:54Z"
        },
        {
          "author": "theomonnom",
          "body": "I wasn't able to reproduce the issue, what is your uv version?",
          "created_at": "2025-04-04T12:19:19Z"
        },
        {
          "author": "JonghoKim-jj",
          "body": "It is uv 0.5.1 (Homebrew 2024-11-08)",
          "created_at": "2025-04-07T02:38:31Z"
        }
      ]
    },
    {
      "issue_number": 1907,
      "title": "Missing AudioConfig, BackgroundAudioPlayer, and BuiltinAudioClip in LiveKit-Agents",
      "body": "When attempting to adapt the example script background_audio.py of background audio functionality for a voice agent with the latest version of livekit-agents v0.12.19, the following classes are not found within the library:\n\n- AudioConfig\n- BackgroundAudioPlayer\n- BuiltinAudioClip",
      "state": "closed",
      "author": "ahenawy",
      "author_type": "User",
      "created_at": "2025-04-06T19:31:02Z",
      "updated_at": "2025-04-06T22:03:00Z",
      "closed_at": "2025-04-06T22:03:00Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1907/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1907",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1907",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:45.608112",
      "comments": [
        {
          "author": "AndrazP",
          "body": "In `main` branch, examples are already updated to livekit-agents version 1.0 RC.\n\nIf you’re staying on 0.x, check out this compatible example: [Meditation Helper](https://docs.livekit.io/recipes/meditation-helper/).",
          "created_at": "2025-04-06T21:19:47Z"
        },
        {
          "author": "davidzhao",
          "body": "see comment here: https://github.com/livekit/agents/blob/b4dc0f303717f3a11a55bbd3e5b28bd452d8c226/examples/voice_agents/background_audio.py#L23",
          "created_at": "2025-04-06T22:02:58Z"
        }
      ]
    },
    {
      "issue_number": 1056,
      "title": "\"Conversation already has an active response\" error with MultimodalAgent",
      "body": "We've gotten reports in Slack that when certain function calls are used with MultimodalAgent, it would sometimes error out with:\r\n\r\n```\r\n2024-11-07 17:14:37,898 - ERROR livekit.plugins.openai.realtime - OpenAI S2S error {'type': 'error', 'event_id': 'event_AR7s53avu18NBq2Lk5O4r', 'error': {'type': 'invalid_request_error', 'code': None, 'message': 'Conversation already has an active response', 'param': None, 'event_id': None}} {\"session_id\": \"sess_AR7r1ss6nsPVlPETCgFxi\"}\r\n```\r\n\r\nIt'd be great if anyone could produce a path to reproducing the error.",
      "state": "open",
      "author": "davidzhao",
      "author_type": "User",
      "created_at": "2024-11-08T06:21:12Z",
      "updated_at": "2025-04-06T17:04:14Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 33,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1056/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 1
      },
      "assignees": [
        "longcw"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1056",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1056",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:45.894441",
      "comments": []
    },
    {
      "issue_number": 1789,
      "title": "Anthropic API Error 400: messages: text content blocks must be non-empty when using Tool Results [LiveKit Agents V1.03]",
      "body": "When using the livekit-plugins-anthropic LLM plugin with tools (function calling), an API error occurs after a tool successfully executes and its result is added back to the chat context. The Anthropic API returns a 400 Bad Request with an error message similar to {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'messages: text content blocks must be non-empty'}}.\n\nRoot Cause:\n\nThe issue stems from the to_chat_ctx function within livekit/plugins/anthropic/utils.py. Specifically, in the handling of function_call_output message types (around line 90 in the version analyzed), the code assigns the raw string output from the tool (msg.output) directly to the content field of the anthropic.types.ToolResultBlockParam.\n\n\nPossibly related to \n\nhttps://github.com/livekit/agents/issues/1788",
      "state": "closed",
      "author": "mercuryyy",
      "author_type": "User",
      "created_at": "2025-03-28T19:15:26Z",
      "updated_at": "2025-04-06T13:35:00Z",
      "closed_at": "2025-04-06T13:35:00Z",
      "labels": [
        "bug",
        "plugins"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1789/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1789",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1789",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:45.894461",
      "comments": [
        {
          "author": "longcw",
          "body": "@jayeshp19 can you take a look for the livekit-plugins-anthropic",
          "created_at": "2025-03-29T03:31:09Z"
        },
        {
          "author": "ChenghaoMou",
          "body": "Sometimes, I also observe empty content when the user takes a slightly longer pause:\n\nUser: blah blah [pause]\nModel: {ready to respond but nothing committed, and therefore empty}\nUser: [continue/interrupt] blah blah\nModel: triggers above error in \n\nWill provide more logging details if I ever see thi",
          "created_at": "2025-03-29T21:08:24Z"
        },
        {
          "author": "jayeshp19",
          "body": "@mercuryyy are you seeing this error consistantly, If possible could you share a reproducible example? \n",
          "created_at": "2025-03-31T08:41:21Z"
        },
        {
          "author": "Edwardp17",
          "body": "This is happening to me as well, though through bedrock https://livekit-users.slack.com/archives/C07FY8WHGPM/p1743433142530649",
          "created_at": "2025-03-31T15:26:55Z"
        },
        {
          "author": "jayeshp19",
          "body": "Hi Thanks for reporting It's fixed in https://github.com/livekit/agents/pull/1829 we will release a new version soon",
          "created_at": "2025-04-01T04:35:19Z"
        }
      ]
    },
    {
      "issue_number": 1479,
      "title": "Can you please provide support for Azure Custom Domain (Currently when using custom domain getting Error: failed to establish USP connection)",
      "body": "We are using python sdk and in Agent for TTS and STT we are using azure, we have custom domain for azure speech resource so wanted to use that instead of region and key, but when we are giving the domain value in the format :\nwss://private end point/tts/cognitiveservices/websocket/v1, \nWe are getting this error **APIConnectionError: Error: failed to establish USP connection**.\n",
      "state": "closed",
      "author": "sarthakgoyal23",
      "author_type": "User",
      "created_at": "2025-02-11T12:50:45Z",
      "updated_at": "2025-04-06T12:17:23Z",
      "closed_at": "2025-04-06T12:16:54Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1479/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1479",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1479",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:46.223720",
      "comments": [
        {
          "author": "anoopmittal77",
          "body": "Any update on this?",
          "created_at": "2025-04-05T08:28:06Z"
        },
        {
          "author": "sarthakgoyal23",
          "body": "If you are using private endpoint that should be passed in speech_endpoint config variable and this should be get fixed once this PR is merged.\n\nhttps://github.com/livekit/agents/pull/1884\n\n> Any update on this?\n\n",
          "created_at": "2025-04-06T12:16:54Z"
        }
      ]
    },
    {
      "issue_number": 1746,
      "title": "Push-to-Talk implementation: temporary approach & 1.0 timeline?",
      "body": "I’m currently working on implementing a push-to-talk (manual turn) feature and came across [a PR that adds a manual option for turn detection](https://github.com/livekit/agents/pull/1695). However, I’m not sure when version 1.0 will be released. Since I need to have something working until then, I’m curious about the simplest, most common approach people are using for push-to-talk right now.\n\nAdditionally, I’d like to support canceling mid-speech by completely resetting the input buffer. Does anyone have suggestions on how best to implement this buffer reset or any temporary workarounds?\n\nAny updates on the release timeline or advice on these temporary solutions would be greatly appreciated!",
      "state": "closed",
      "author": "well-balanced",
      "author_type": "User",
      "created_at": "2025-03-26T19:41:41Z",
      "updated_at": "2025-04-06T11:59:27Z",
      "closed_at": "2025-03-27T06:43:22Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1746/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1746",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1746",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:46.443724",
      "comments": [
        {
          "author": "theomonnom",
          "body": "Hey! We're releasing a 1.0 RC candidate today, so you won't have to wait much longer.\n\nIn the meantime, we have an example demonstrating a push-to-talk implementation that should help you get started. Check it out [here](https://github.com/livekit/agents/blob/dev-1.0/examples/voice_agents/push_to_ta",
          "created_at": "2025-03-27T01:16:24Z"
        },
        {
          "author": "well-balanced",
          "body": "@theomonnom, thanks for the quick reply!",
          "created_at": "2025-03-27T06:00:59Z"
        }
      ]
    },
    {
      "issue_number": 1896,
      "title": "Cannot access gemini models via OpenAI client",
      "body": "<!--\nHello! Thanks for taking the time to file a bug report.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already reported this issue.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n-->\n\nhere is how i am trying to access gemini models via OpenAI\n```\nfrom livekit.plugins.openai import LLM\n\ngemini_llm = LLM(\n    model=\"gemini-2.0-flash-001\",\n    api_key=os.getenv(\"GEMINI_API_KEY\"),\n    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n)\n```\n\nerror:\n\n```\n raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - [{'error': {'code': 400, 'message': 'Unable to submit request because it has an empty text parameter. Add a value to the parameter and try again. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/gemini', 'status': 'INVALID_ARGUMENT'}}]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/abhishekrp/Library/Caches/pypoetry/virtualenvs/discovery-call-agent-9MZbE3gS-py3.13/lib/python3.13/site-packages/livekit/agents/llm/llm.py\", line 127, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/abhishekrp/Library/Caches/pypoetry/virtualenvs/discovery-call-agent-9MZbE3gS-py3.13/lib/python3.13/site-packages/livekit/plugins/openai/llm.py\", line 630, in _run\n    raise APIStatusError(  # noqa: B904\n    ...<5 lines>...\n    )\nlivekit.agents._exceptions.APIStatusError: Error code: 400 - [{'error': {'code': 400, 'message': 'Unable to submit request because it has an empty text parameter. Add a value to the parameter and try again. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/gemini', 'status': 'INVALID_ARGUMENT'}}] (status_code=400, request_id=None, body=[{'error': {'code': 400, 'message': 'Unable to submit request because it has an empty text parameter. Add a value to the parameter and try again. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/gemini', 'status': 'INVALID_ARGUMENT'}}])\n2025-04-05 16:15:32,318 - WARNING livekit.agents - failed to generate LLM completion, retrying in 2.0s {\"llm\": \"livekit.plugins.openai.llm.LLM\", \"attempt\": 2}\nTraceback (most recent call last):\n  File \"/Users/abhishekrp/Library/Caches/pypoetry/virtualenvs/discovery-call-agent-9MZbE3gS-py3.13/lib/python3.13/site-packages/livekit/plugins/openai/llm.py\", line 598, in _run\n    ] = await self._client.chat.completions.create(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<6 lines>...\n    )\n    ^\n  File \"/Users/abhishekrp/Library/Caches/pypoetry/virtualenvs/discovery-call-agent-9MZbE3gS-py3.13/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 2000, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n    ...<43 lines>...\n    )\n    ^\n  File \"/Users/abhishekrp/Library/Caches/pypoetry/virtualenvs/discovery-call-agent-9MZbE3gS-py3.13/lib/python3.13/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/abhishekrp/Library/Caches/pypoetry/virtualenvs/discovery-call-agent-9MZbE3gS-py3.13/lib/python3.13/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n    ...<5 lines>...\n    )\n    ^\n  File \"/Users/abhishekrp/Library/Caches/pypoetry/virtualenvs/discovery-call-agent-9MZbE3gS-py3.13/lib/python3.13/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - [{'error': {'code': 400, 'message': 'Unable to submit request because it has an empty text parameter. Add a value to the parameter and try again. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/gemini', 'status': 'INVALID_ARGUMENT'}}]\n\n\n```",
      "state": "closed",
      "author": "AbhishekRP2002",
      "author_type": "User",
      "created_at": "2025-04-05T12:36:47Z",
      "updated_at": "2025-04-06T11:03:07Z",
      "closed_at": "2025-04-06T11:03:07Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1896/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1896",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1896",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:46.623792",
      "comments": [
        {
          "author": "jayeshp19",
          "body": "We've deprecated Google models in the OpenAI client since they don't fully support the Google ecosystem. you can use `google.LLM()` directly instead.",
          "created_at": "2025-04-06T11:02:52Z"
        }
      ]
    },
    {
      "issue_number": 1718,
      "title": "Agents 1.0 - Google plugin No module named 'livekit.plugins.google._utils'",
      "body": "When trying to use any google LLM, TTS, or STT we are seeing the below error. \n```\nFile \"/Users/jakob.mcclanahan/Documents/GitHub/voice-calling/.venv/lib/python3.11/site-packages/livekit/plugins/google/beta/realtime/__init__.py\", line 1, in <module>\n    from .api_proto import ClientEvents, LiveAPIModels, Voice\n  File \"/Users/jakob.mcclanahan/Documents/GitHub/voice-calling/.venv/lib/python3.11/site-packages/livekit/plugins/google/beta/realtime/api_proto.py\", line 8, in <module>\n    from ..._utils import _build_gemini_ctx, _build_tools\nModuleNotFoundError: No module named 'livekit.plugins.google._utils'\n``` \n```python\n    agent = AgentSession(\n        userdata=state,\n        vad=ctx.proc.userdata[\"vad\"],\n        stt=deepgram.STT(model=\"nova-2-phonecall\"),\n        llm=google.LLM(api_key=os.getenv(\"GEMINI_API_KEY\"), model=\"gemini-2.0-flash-001\"),\n        #llm=openai.realtime.RealtimeModel(voice=\"echo\"),\n        tts=cartesia.TTS(voice=\"6f84f4b8-58a2-430c-8c79-688dad597532\"),\n        turn_detector=turn_detector.EOUModel(),\n    )\n``` \n\nEDIT: narrowed the issue down to the realtime model, looks to be a merge issue as it's trying to export files that no longer exist in 1.0 and issue still persists in 1.0.0-rc4\n\n**Versions**\nlivekit-agents: 1.0.0-dev5\nlivekit-plugins-google: 1.0.0-dev5",
      "state": "closed",
      "author": "jmcclanahan13",
      "author_type": "User",
      "created_at": "2025-03-24T13:42:13Z",
      "updated_at": "2025-04-04T14:21:30Z",
      "closed_at": "2025-04-04T14:21:29Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1718/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 1
      },
      "assignees": [
        "jayeshp19"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1718",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1718",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:46.858719",
      "comments": [
        {
          "author": "pabloFuente",
          "body": "I am getting the same error when importing `livekit.plugins.google`",
          "created_at": "2025-03-27T19:23:28Z"
        },
        {
          "author": "jmcclanahan13",
          "body": "@yepher  @longcw @theomonnom  - seems like we're completely blocked on using the google plugin. Tried pulling latest from dev-1.0 branch and seems the issue still persists. Looks to be a merge issue",
          "created_at": "2025-03-27T19:38:22Z"
        },
        {
          "author": "ImaMoonky",
          "body": "pip install livekit-plugins-google \n\nI did the following inside of my environment and that fixed the error if that helps anyone. ",
          "created_at": "2025-03-31T10:15:28Z"
        },
        {
          "author": "yepher",
          "body": "Slack Thread https://livekit-users.slack.com/archives/C07FY8WHGPM/p1743426547987679?thread_ts=1743174554.314259&cid=C07FY8WHGPM\n\n",
          "created_at": "2025-03-31T14:14:34Z"
        },
        {
          "author": "jmcclanahan13",
          "body": "This was fixed with https://github.com/livekit/agents/pull/1753. We can close this",
          "created_at": "2025-04-04T14:21:29Z"
        }
      ]
    },
    {
      "issue_number": 1811,
      "title": "Proposal: blingfire and/or pysbd for better multilingual sentence tokenization",
      "body": "Inspired from #1697 \n\nCurrent, the basic sentence tokenizer handles normal English text well. But it does not work well with other languages (e.g. Chinese) or rare cases like repeated punctuation (e.g. `??` is actually recommended by Cartesia [best-practices](https://docs.cartesia.ai/2024-11-13/build-with-cartesia/formatting-text-for-sonic-2/best-practices).\n\nWith two quick benchmarks provided in [PySBD](https://github.com/nipunsadvilkar/pySBD/tree/master/benchmarks), I tested the basic sentence tokenizer with other tokenizers for reference:\n\n| lib | benchmark | performance | time |\n|-----| ---------- | ---------- | ---------- |\n|blingfire| Golden Rule Set (↑) | 75.00% | **0.19 ms** |\n|nltk| Golden Rule Set (↑) | 56.25% | 0.72 ms |\n|pysbd| Golden Rule Set (↑) | **97.92%** | 7.18 ms |\n|spacy| Golden Rule Set (↑) | 52.08% | 1.24 ms |\n|spacy (dep)| Golden Rule Set (↑) | 60.42% | 105.21 ms |\n|stanza| Golden Rule Set (↑) | 75.00% | 170.21 ms |\n|syntok| Golden Rule Set (↑) | 70.83% | 1.85 ms |\n|basic*| Golden Rule Set (↑) | 33.33% | 0.53 ms |\n|sat-1l-sm| Golden Rule Set (↑) | 25.00% | 1479.20 ms |\n|blingfire| Big Text (↓) | - | **21.69 ms** |\n|nltk| Big Text (↓) | - | 48.77 ms |\n|pysbd| Big Text (↓) | - | 5140.17 ms |\n|spacy| Big Text (↓) | - | 896.53 ms |\n|spacy (dep)| Big Text (↓) | - | 14152.61 ms |\n|stanza| Big Text (↓) | - | 7637.68 ms |\n|syntok| Big Text (↓) | - | 337.19 ms |\n|basic*| Big Text (↓) | - | 51.95 ms |\n|sat-1l-sm| Big Text (↓) | - | 25171.41 ms |\n\n\\*: with `retain_format=False, min_sentence_len=1` settings for the higher score.\n\nQuick illustration:\n\n```text\nMethod: basic\nDoc: Hello, world! This is a test. This is another test. This is a third test?? How about this? I don't know!!!! This is a sentence with something...\nSentences: [Chunk(text='Hello, world!', start=0, end=13), Chunk(text=' This is a test.', start=13, end=29), Chunk(text=' This is another test.', start=29, end=51), Chunk(text=' This is a third test?', start=51, end=73), Chunk(text='? How about this?', start=73, end=90), Chunk(text=\" I don't know!\", start=90, end=104), Chunk(text='!!', start=104, end=106), Chunk(text='! This is a sentence with something...', start=106, end=144)]\nDoc: 这是一句比较短的中文。这是另一句， 但是比较长的， 复杂的中文。\nSentences: [Chunk(text='这是一句比较短的中文。这是另一句， 但是比较长的， 复杂的中文。', start=0, end=32)]\nTime: 0.69ms\n\nMethod: blingfire\nDoc: Hello, world! This is a test. This is another test. This is a third test?? How about this? I don't know!!!! This is a sentence with something...\nSentences: [Chunk(text='Hello, world!', start=0, end=13), Chunk(text='This is a test.', start=14, end=29), Chunk(text='This is another test.', start=30, end=51), Chunk(text='This is a third test??', start=52, end=74), Chunk(text='How about this?', start=75, end=90), Chunk(text=\"I don't know!!!!\", start=91, end=107), Chunk(text='This is a sentence with something...', start=108, end=144)]\nDoc: 这是一句比较短的中文。这是另一句， 但是比较长的， 复杂的中文。\nSentences: [Chunk(text='这是一句比较短的中文。', start=0, end=11), Chunk(text='这是另一句， 但是比较长的， 复杂的中文。', start=11, end=32)]\nTime: 1.10ms\n\nMethod: pysbd\nDoc: Hello, world! This is a test. This is another test. This is a third test?? How about this? I don't know!!!! This is a sentence with something...\nSentences: [Chunk(text='Hello, world! ', start=0, end=14), Chunk(text='This is a test. ', start=14, end=30), Chunk(text='This is another test. ', start=30, end=52), Chunk(text='This is a third test?? ', start=52, end=75), Chunk(text='How about this? ', start=75, end=91), Chunk(text=\"I don't know!!!! This is a sentence with something...\", start=91, end=144)]\nDoc: 这是一句比较短的中文。这是另一句， 但是比较长的， 复杂的中文。\nSentences: [Chunk(text='这是一句比较短的中文。', start=0, end=11), Chunk(text='这是另一句， 但是比较长的， 复杂的中文。', start=11, end=32)]\nTime: 4.68ms\n```\n\nBlingfire is fast enough to be a replacement with performance improvement while PySBD brings mostly quality boost at a price of latency.\n\nDo you think having an option to use blingfire and/or pysbd to have better multilingual/long-tail support merits the addition of those dependencies? If so, happy to work on a PR for this.\n\n",
      "state": "open",
      "author": "ChenghaoMou",
      "author_type": "User",
      "created_at": "2025-03-29T20:55:12Z",
      "updated_at": "2025-04-03T20:56:48Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 11,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1811/reactions",
        "total_count": 4,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 4,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1811",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1811",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:47.077221",
      "comments": [
        {
          "author": "theomonnom",
          "body": "Hey, this is super interesting—thanks for taking the time to benchmark and share this. I definitely agree this functionality should be built into livekit-agents.\n\nI'm quite tempted by pysbd given the accuracy improvements. I wonder if the added latency is even noticeable in practice; my bigger conce",
          "created_at": "2025-03-30T00:17:58Z"
        },
        {
          "author": "theomonnom",
          "body": "This one also looks interesting: https://github.com/segment-any-text/wtpsplit",
          "created_at": "2025-03-30T00:52:28Z"
        },
        {
          "author": "ChenghaoMou",
          "body": "> This one also looks interesting: [segment-any-text/wtpsplit](https://github.com/segment-any-text/wtpsplit?rgh-link-date=2025-03-30T00%3A52%3A28.000Z)\n\nThanks! I have updated the results with sat-1l-sm (800MB in size). But I think the latency on the same CPU is too much to be used in practice.",
          "created_at": "2025-03-30T14:04:38Z"
        },
        {
          "author": "ChenghaoMou",
          "body": "> Hey, this is super interesting—thanks for taking the time to benchmark and share this. I definitely agree this functionality should be built into livekit-agents.\n> \n> I'm quite tempted by pysbd given the accuracy improvements. I wonder if the added latency is even noticeable in practice; my bigger",
          "created_at": "2025-03-30T14:12:22Z"
        },
        {
          "author": "ChenghaoMou",
          "body": "Here is my attempt to add blingfire as a plugin: https://github.com/livekit/agents/pull/1818\n\nHere is a PR to allow Cartesia to take custom sentence tokenizer: https://github.com/livekit/agents/pull/1819",
          "created_at": "2025-03-30T21:18:01Z"
        }
      ]
    },
    {
      "issue_number": 1613,
      "title": "Agent gets wedged after user interruption during `.say(allow_interruptions=False)` call",
      "body": "Running on latest release, can confirm this is not happening as of this commit: 6235bb00072be0fc88a0fe9d5bf69abed876aa9f\n\n```\n// Agent starts the conversation and plays their opening line; user interrupts but it is correctly ignored\n\n2025-03-06 13:18:08,531 - INFO portola.agent_controller - AgentController: Pausing before saying first message\n2025-03-06 13:18:13,532 - INFO portola.agent_controller - AgentController: Saying first message // <-- this is the .say(..., allow_interruptions=False) call\n2025-03-06 13:18:16,057 - INFO portola.agent_controller - AgentController: User started speaking\n2025-03-06 13:18:16,635 - DEBUG livekit.agents.pipeline - speech playout started\n2025-03-06 13:18:17,977 - INFO portola.agent_controller - AgentController: User stopped speaking\n2025-03-06 13:18:17,988 - DEBUG livekit.agents.pipeline - received user transcript\n2025-03-06 13:18:18,007 - DEBUG livekit.plugins.turn_detector - eou prediction {\"eou_probability\": 0.16981594264507294, \"input\": \"<|im_start|><|user|>Yeah, man. It's pretty crazy out there.\", \"duration\": 0.015, \"hostname\": \"gold.local\", \"pid\": 46170, \"job_id\": \"AJ_voQ65kwZs7hZ\"}\n2025-03-06 13:18:18,354 - DEBUG livekit.agents.pipeline - skipping validation, agent is speaking and does not allow interruptions\n\n// After this turn is done, the user starts speaking again but this time the agent ignores all user input!\n\n2025-03-06 13:18:25,887 - INFO portola.agent_controller - AgentController: User started speaking\n2025-03-06 13:18:31,595 - DEBUG livekit.agents.pipeline - received user transcript {\"user_transcript\": \"Super windy. Couldn't see anything. It was crazy.\", \"hostname\": \"gold.local\", \"pid\": 46170, \"job_id\": \"AJ_voQ65kwZs7hZ\"}\n2025-03-06 13:18:31,678 - INFO portola.agent_controller - AgentController: User stopped speaking\n2025-03-06 13:18:31,700 - DEBUG livekit.plugins.turn_detector - eou prediction {\"eou_probability\": 0.6108109951019287, \"input\": \"<|im_start|><|user|>We had to drive to dinner last night, and it was just, like, super snowy. Super windy. Couldn't see anything. It was crazy.\", \"duration\": 0.02, \"hostname\": \"gold.local\", \"pid\": 46170, \"job_id\": \"AJ_voQ65kwZs7hZ\"}\n2025-03-06 13:18:31,971 - DEBUG livekit.agents.pipeline - skipping validation, agent is speaking and does not allow interruptions // <-- this should not be happening!\n```\n\nI think the root cause is somehow the AgentPlayout._agent_task never finishes, because we never see the `speech finished` log line.",
      "state": "open",
      "author": "egoldschmidt",
      "author_type": "User",
      "created_at": "2025-03-06T20:40:27Z",
      "updated_at": "2025-04-03T19:15:56Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 15,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1613/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1613",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1613",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:47.328774",
      "comments": [
        {
          "author": "longcw",
          "body": "Could you share an example that can reproduce the problem. I tried to call `agent.say(..., allow_interruptions=False)` in both entrypoint and a function call but seems they work with `speech playout finished` correctly.",
          "created_at": "2025-03-07T02:14:38Z"
        },
        {
          "author": "egoldschmidt",
          "body": "Sorry I realize my post was a bit vague. So my flow is specifically:\n\n1. Call `agent.say(stream, allow_interruptions=False)`. My stream takes, say, 1 second to fully finish.\n2. Say something *during TTS generation and playback*. It seems that if you interrupt before TTS starts this problem does not ",
          "created_at": "2025-03-07T04:36:41Z"
        },
        {
          "author": "longcw",
          "body": "A few more questions for reproduce: the `stream` is a `str` , `AsyncIterable[str]` or `LLMStream` in your case?  and where the `agent.say` is called, inside a function call or `before_llm_cb`? \n\n",
          "created_at": "2025-03-07T05:00:27Z"
        },
        {
          "author": "egoldschmidt",
          "body": "It's an `AsyncIterable[str]` and it's called from a function call (essentially a delayed task after the user joins the room), not `before_llm_cb`",
          "created_at": "2025-03-07T05:17:34Z"
        },
        {
          "author": "longcw",
          "body": "I was not reproduce it with the following example using elevenlabs TTS and `AsyncIterable[str]` text input. One possible is that the `AsyncIterable[str]` is never closed so the uninterruptible `agent.say` is never finished. Could you give it a try and maybe share a reproducible example, I can help t",
          "created_at": "2025-03-07T08:12:37Z"
        }
      ]
    },
    {
      "issue_number": 1868,
      "title": "TypeError when running livekit.agents with release candidate 1.0.0rc5",
      "body": "I am encountering a `TypeError` when trying to use version `1.0.0rc5` of `livekit-agents`. These are the steps to reproduce:\n\n1. Create a Python virtual environment\n2. Install the `livekit-agents` release candidate package with `pip`\n3. Run `python -m livekit.agents.__init__`\n\nThe following error occurs:\n```\nTypeError: typing.Optional requires a single type. Got <google.protobuf.internal.enum_type_wrapper.EnumTypeWrapper object at 0x7f98526007f0>.\n```\n\n### Environment:\n* Python version: 3.10.16\n* OS: Debian GNU/Linux 11 (bullseye)",
      "state": "closed",
      "author": "niqodea",
      "author_type": "User",
      "created_at": "2025-04-03T10:57:15Z",
      "updated_at": "2025-04-03T18:38:53Z",
      "closed_at": "2025-04-03T18:19:36Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1868/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1868",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1868",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:47.559754",
      "comments": [
        {
          "author": "tscdl",
          "body": "I am new to Python. Experiencing something similar with 1.0.0rc4 as linked from the webpages docs.\n\n`TypeError: typing.Optional requires a single type. Got <google.protobuf.internal.enum_type_wrapper.EnumTypeWrapper object at 0x106acc2e0>.`\n\nThey say: \n\"LiveKit Agents requires Python 3.9 or later.\" ",
          "created_at": "2025-04-03T15:48:36Z"
        },
        {
          "author": "longcw",
          "body": "Do you have a full error log?",
          "created_at": "2025-04-03T16:04:25Z"
        },
        {
          "author": "tscdl",
          "body": "I did stumble upon a thread in Slack, that seemed related. Again Python newbie here.\n\nhttps://livekit-users.slack.com/archives/C07FY8WHGPM/p1743697910579179?thread_ts=1743628708.330239&cid=C07FY8WHGPM\n\nCWilson helped and it turns out, the Python version is critical. 3.9.4 did not work for me. Even t",
          "created_at": "2025-04-03T16:44:10Z"
        },
        {
          "author": "niqodea",
          "body": "I tried upgrading to Python 3.12 like @tscdl suggested and it seems to fix the issue. Initially, I got an error about `pydantic` missing, but after installing it, I was able to run `python -m livekit.agents.__init__` without any problems. Would be nice to have a fix for Python 3.10 as well!\n\n@longcw",
          "created_at": "2025-04-03T17:11:31Z"
        },
        {
          "author": "niqodea",
          "body": "Seems to me like the `Optional` typing class is being used by `livekit.api` in a way that is not compatible with Python 3.10.\n\nIf that's the case, to help prevent similar issues in the future, would it make sense to specify a minimum supported Python version and ensure development happens in an envi",
          "created_at": "2025-04-03T17:13:26Z"
        }
      ]
    },
    {
      "issue_number": 1863,
      "title": "SIP(OUTBOUND) + EGRESS- Agent starts speaking before call is picked.",
      "body": "We are integrating SIP outbound calls, along with EGRESS, facing two issue-\n1.)If we have egress code(for recording), than agents(VoicePipelineAgent) starts speaking even before call is accepted. But if code for egress is not there, than agent starts speaking only after call is picked up.Maybe this has got something to do with hidden egress kind participant joining room.\n2.)Similar behaviour is reproducible if we use MultimodelAgent, whether we have recording enabled or not, agent starts speaking for outbound call, before call has been picked up.",
      "state": "closed",
      "author": "test-24325",
      "author_type": "User",
      "created_at": "2025-04-02T14:08:22Z",
      "updated_at": "2025-04-03T14:39:34Z",
      "closed_at": "2025-04-03T14:39:34Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1863/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1863",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1863",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:47.779295",
      "comments": [
        {
          "author": "test-24325",
          "body": "A similar issue i found for multimodal agent here, https://github.com/livekit/agents/issues/1539 and a discussion here, https://livekit-users.slack.com/archives/C07FRP66XGE/p1737373575304469\n\n",
          "created_at": "2025-04-02T14:12:15Z"
        },
        {
          "author": "IngLP",
          "body": "This is not a bug. Just check participant.attributes[\"sip.callStatus\"] and wait until it becomes \"active\".\nyou will need to do polling. In that sense, it could be better, yes.",
          "created_at": "2025-04-03T14:37:52Z"
        }
      ]
    },
    {
      "issue_number": 1817,
      "title": "stt_audio_duration is always 0 with livekit-plugins-azure",
      "body": "<!--\nHello! Thanks for taking the time to file a bug report.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already reported this issue.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n-->\n\nHi!\n\nI'm using speech to text from `livekit-plugins-azure@0.5.6` (latest as of writing this) and my issue is that `stt_audio_duration` is always 0 in my metrics. The other metrics work fine and it used to work when I was using Deepgram for STT.\n\n```\nUsageSummary(llm_prompt_tokens=702, llm_completion_tokens=8, tts_characters_count=104, stt_audio_duration=0.0)\n```\n\nThis is my setup:\n```py\nstt = azure.STT(\n    languages=[mapped_language]\n)\nagent = VoicePipelineAgent(\n    vad=ctx.proc.userdata[\"vad\"],\n    stt=stt,\n    llm=azure_llm,\n    tts=tts,\n    chat_ctx=initial_ctx,\n    turn_detector=turn_detector.EOUModel(),\n)\n```\n\nand for the metrics:\n```py\nusage_collector = metrics.UsageCollector()\n\n@agent.on(\"metrics_collected\")\ndef _on_metrics_collected(mtrcs: metrics.AgentMetrics):\n    metrics.log_metrics(mtrcs)\n    usage_collector.collect(mtrcs)\n```\n\nHow can I collect this data?",
      "state": "open",
      "author": "benjick",
      "author_type": "User",
      "created_at": "2025-03-30T20:37:16Z",
      "updated_at": "2025-04-03T07:44:06Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1817/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1817",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1817",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:47.968995",
      "comments": [
        {
          "author": "SouthCentralCode",
          "body": "The same issue happens when using gpt-4o-mini-transcribe.",
          "created_at": "2025-04-01T12:02:44Z"
        },
        {
          "author": "benjick",
          "body": "CWilson on Slack said this was fixed in a recent PR",
          "created_at": "2025-04-03T07:44:06Z"
        }
      ]
    },
    {
      "issue_number": 1814,
      "title": "Modify chat context length in Multimodal Agent",
      "body": "<!--\nIn pipeline agent, there's a `before_llm_cb` function that I can use to fix the chat context length to 15, but I can't find the same logic in Multimodal Agent. I badly need it at work please help.\n\nhttps://livekit.io/join-slack\n-->\n",
      "state": "closed",
      "author": "kennethtegrado",
      "author_type": "User",
      "created_at": "2025-03-29T23:44:05Z",
      "updated_at": "2025-04-03T07:10:46Z",
      "closed_at": "2025-04-03T07:10:46Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1814/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1814",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1814",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:48.192560",
      "comments": [
        {
          "author": "kennethtegrado",
          "body": "In pipeline agent there's a `before_llm_cb` method that I can use to fix my chat context but I don't know how to implement it multimodal agent please help.",
          "created_at": "2025-03-29T23:45:57Z"
        },
        {
          "author": "longcw",
          "body": "You can do that in the callback of `agent_speech_committed` and `agent_speech_interrupted` events for 0.x",
          "created_at": "2025-04-01T07:29:38Z"
        }
      ]
    },
    {
      "issue_number": 1853,
      "title": "turn_detector vs turn_detection",
      "body": "https://docs.livekit.io/agents/v1/build/turn-detection/#using-turn-detector\n\n```py\nfrom livekit.plugins import turn_detector\n\nagent = AgentSession(\n    ...\n    turn_detector=turn_detector.EOUModel(),\n)\n```\n\nIn the example above, the argument name is `turn_detector` but true name in implementation is `turn_detection`.\nWe should fix either one.",
      "state": "closed",
      "author": "rinarakaki",
      "author_type": "User",
      "created_at": "2025-04-02T03:42:54Z",
      "updated_at": "2025-04-02T17:57:13Z",
      "closed_at": "2025-04-02T17:57:13Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1853/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1853",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1853",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:48.422017",
      "comments": [
        {
          "author": "longcw",
          "body": "Yes, we are going to fix that in the doc. ",
          "created_at": "2025-04-02T04:05:10Z"
        },
        {
          "author": "davidzhao",
          "body": "this has been fixed, thanks for the report!",
          "created_at": "2025-04-02T17:57:06Z"
        }
      ]
    },
    {
      "issue_number": 1773,
      "title": "toggle_io.py example details",
      "body": "Hi all,\n\n\nThank you for this great framework !\n\nI want to ask if there were starter frontend for the toggle_io.py example and if it can be used with different llms. I have tried to use it with the llam-index chat engine but in the agents-playground i am not getting any response. \n\nbest \n",
      "state": "closed",
      "author": "biouser-abiomix",
      "author_type": "User",
      "created_at": "2025-03-28T10:21:38Z",
      "updated_at": "2025-04-02T08:24:56Z",
      "closed_at": "2025-03-29T06:23:55Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1773/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1773",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1773",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:48.653128",
      "comments": [
        {
          "author": "longcw",
          "body": "It should work with different LLMs the agents supports. It listens to RPC calls (https://docs.livekit.io/home/client/data/rpc/) to toggle the io, you can test it with the agent-playground.\n\nDo you have an example to reproduce the issue you have?",
          "created_at": "2025-03-28T10:44:52Z"
        },
        {
          "author": "davidzhao",
          "body": "you can swap in any LLMs.. what long mentioned is [here](https://agents-playground.livekit.io/)",
          "created_at": "2025-03-29T06:23:36Z"
        },
        {
          "author": "biouser-abiomix",
          "body": "Thank you for the response\n\ni am trying to use the llama_index chat engine for the toggle_io example.\nI get this error\n\n```bash\n   aceback (most recent call last):\n  File \"/home/cbhamda/drt-livekit/backend/.venv/lib/python3.13/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n   ",
          "created_at": "2025-04-02T08:24:55Z"
        }
      ]
    },
    {
      "issue_number": 1854,
      "title": "When OpenAI Realtime returns text, there is an issue of gibberish in the audio",
      "body": "I am using OpenAI Realtime, and I want OpenAI Realtime to continuously return audio. However, when it returns text, LiveKit automatically reconnects and starts producing gibberish. I tested this with OpenAI Realtime speaking Chinese.\n\n<img width=\"1452\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/07797e28-f7ae-4c81-b373-455f12e1410b\" />\n\nI suspect that the gibberish issue in AI speech is caused by the empty audio content created by the _create_empty_user_audio_message function.\n\nFile: livekit/plugins/openai/realtime/realtime_model.py\n```\ndef _create_empty_user_audio_message(self, duration: float) -> llm.ChatMessage:\n    \"\"\"Create an empty audio message with the given duration.\"\"\"\n    samples = int(duration * api_proto.SAMPLE_RATE)\n    return llm.ChatMessage(\n        role=\"user\",\n        content=llm.ChatAudio(\n            frame=rtc.AudioFrame(\n                data=b\"\\x00\\x00\" * (samples * api_proto.NUM_CHANNELS),\n                sample_rate=api_proto.SAMPLE_RATE,\n                num_channels=api_proto.NUM_CHANNELS,\n                samples_per_channel=samples,\n            )\n        ),\n    )\n\n```",
      "state": "open",
      "author": "johnson7788",
      "author_type": "User",
      "created_at": "2025-04-02T05:09:27Z",
      "updated_at": "2025-04-02T08:01:41Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1854/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1854",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1854",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:48.941291",
      "comments": [
        {
          "author": "longcw",
          "body": "This a known issue from OpenAI https://community.openai.com/t/trouble-loading-previous-messages-with-realtime-api and they suggested\n> One workaround is to add an audio message as your first user message, before the other history, which might help coax the model to respond with audio as well.\n\nProba",
          "created_at": "2025-04-02T08:01:40Z"
        }
      ]
    },
    {
      "issue_number": 1258,
      "title": "Google STT times out at 5 minutes and crashes agent",
      "body": "Google STT seems to consistently fail at 5 minutes into the call with the following error:\r\n\r\n```\r\n2024-12-18 15:59:58,786 - ERROR livekit.agents.pipeline - Error in _recognize_task\r\nTraceback (most recent call last):\r\n  File \"/Users/nick/repos/hellopatient/lk_agent/.venv/lib/python3.12/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\r\n    return await fn(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/nick/repos/hellopatient/lk_agent/.venv/lib/python3.12/site-packages/livekit/agents/pipeline/human_input.py\", line 150, in _recognize_task\r\n    await asyncio.gather(*tasks)\r\n  File \"/Users/nick/repos/hellopatient/lk_agent/.venv/lib/python3.12/site-packages/livekit/agents/pipeline/human_input.py\", line 120, in _audio_stream_co\r\n    stt_stream.push_frame(ev.frame)\r\n  File \"/Users/nick/repos/hellopatient/lk_agent/.venv/lib/python3.12/site-packages/livekit/agents/stt/stt.py\", line 265, in push_frame\r\n    self._check_not_closed()\r\n  File \"/Users/nick/repos/hellopatient/lk_agent/.venv/lib/python3.12/site-packages/livekit/agents/stt/stt.py\", line 327, in _check_not_closed\r\n    raise RuntimeError(f\"{cls.__module__}.{cls.__name__} is closed\")\r\nRuntimeError: livekit.plugins.google.stt.SpeechStream is closed {\"pid\": 54793, \"job_id\": \"AJ_zKEGnh4r4ttx\"}\r\n``` \r\n\r\nUnfortunately it's an unhandled error and so even though we were using it with in the `FallbackAdapter` our agent stops responding completely at 5 minutes into the call. \r\n\r\nI have worked with the Google API before and I know it [times out the streaming connection at 5 minutes](https://cloud.google.com/speech-to-text/v2/quotas#streaming_requests) so I imagine that is the issue. There's [an official tutorial on endless streaming](https://cloud.google.com/speech-to-text/docs/transcribe-streaming-audio#endless-streaming) that shows how to switch to a new request and stitch them together in real-time. ",
      "state": "closed",
      "author": "nickderobertis",
      "author_type": "User",
      "created_at": "2024-12-19T00:08:08Z",
      "updated_at": "2025-04-02T04:53:58Z",
      "closed_at": "2025-01-07T08:13:13Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1258/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1258",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1258",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:49.165141",
      "comments": [
        {
          "author": "potate4",
          "body": "![image](https://github.com/user-attachments/assets/8e8c6113-909b-4c47-afe0-02d2c58528a9)\r\nsame issue",
          "created_at": "2024-12-26T15:12:21Z"
        },
        {
          "author": "davidzhao",
          "body": "fixed in #1291, we'll get a build released later today",
          "created_at": "2024-12-30T23:38:01Z"
        },
        {
          "author": "sorokinvj",
          "body": "Using latest version 0.9.0 but still getting stream closure after 5 minutes:\r\n```\r\nRequirement already satisfied: livekit-plugins-google>=0.8.1 in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (0.9.0)\r\n```\r\n\r\n```\r\nINFO:voice-assistant: Session time: 286s (4.8min)\r\nERROR:live",
          "created_at": "2025-01-05T20:57:09Z"
        },
        {
          "author": "davidzhao",
          "body": "reopened.. investigating",
          "created_at": "2025-01-06T07:32:00Z"
        },
        {
          "author": "sorokinvj",
          "body": "> reopened.. investigating\r\n\r\nthank you, I wonder why it is that hard in my code just to catch the error in an agent main entrypoint and just reinstantiate the client whenever there is an exception? is it just me struggling or it is by design encapsulated by the livekit + Python design patterns disa",
          "created_at": "2025-01-06T13:21:16Z"
        }
      ]
    },
    {
      "issue_number": 1806,
      "title": "Enable Thinking for Claude",
      "body": "Hello! I'm trying to enable thinking mode for Claude.\n\n### Workaround\nRight now, I have to proxy out to another endpoint where I inject the right parameters into the requests. Safe to say this is a bit much for a parameter change 😅\n\n### Ideal Solution\nI'd love a solution like this:\n```py\nllm=anthropic.LLM(\n    model=\"claude-3-7-sonnet-20250219\",\n    temperature=1,\n    thinking={\n        \"enabled\": True,\n        \"max_tokens\": 4096,\n    },\n)\n```\n\nCurrently there's no parameter for `thinking` in the anthropic LLM initializer.\n\nBy the way, I've looked into fixing this with a draft PR (#1721), but frankly don't have the context when contributing to feel confident in making a submission. If someone wants to point me in the right direction, I'd be happy to write the code.\n\nThanks!",
      "state": "open",
      "author": "bryanhoulton",
      "author_type": "User",
      "created_at": "2025-03-29T05:32:50Z",
      "updated_at": "2025-04-01T22:18:47Z",
      "closed_at": null,
      "labels": [
        "question",
        "plugins"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1806/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1806",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1806",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:49.451408",
      "comments": [
        {
          "author": "bryanhoulton",
          "body": "Also when using my proxy solution, I have issues with nested tool calling. Not sure if this is because of my proxy or something inside livekit, but it's worth testing if this gets implemented.",
          "created_at": "2025-03-29T05:34:13Z"
        },
        {
          "author": "davidzhao",
          "body": "feel free to open a PR that enables this parameter. do you want to just expose [native Anthropic types](https://github.com/anthropics/anthropic-sdk-python/blob/8b244157a7d03766bec645b0e1dc213c6d462165/src/anthropic/types/message_create_params.py#L171)? \n\nthe nested tool call is an option you can pas",
          "created_at": "2025-03-30T04:30:34Z"
        },
        {
          "author": "bryanhoulton",
          "body": "Yep! In the issue desc I share that I've opened #1721 but would love some guidance on where to go from here. Happy to make the contribution myself. Native anthropic types would be great.",
          "created_at": "2025-04-01T00:13:55Z"
        }
      ]
    },
    {
      "issue_number": 1842,
      "title": "`agent.chat_ctx` is not updated for realtime model",
      "body": "For realtime model we can read the chat ctx from `rt_session.chat_ctx` but the conversation items were not appended to `agent.chat_ctx`. Should we append the conversation item to the `agent.chat_ctx` or overwrite it with `rt_session.chat_ctx` every time a `conversation_item_added` event emitted?",
      "state": "closed",
      "author": "longcw",
      "author_type": "User",
      "created_at": "2025-04-01T11:13:00Z",
      "updated_at": "2025-04-01T14:04:36Z",
      "closed_at": "2025-04-01T14:04:36Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1842/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1842",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1842",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:51.535403",
      "comments": [
        {
          "author": "longcw",
          "body": "cc @theomonnom  wdyt?",
          "created_at": "2025-04-01T11:13:21Z"
        },
        {
          "author": "longcw",
          "body": "Fixed in https://github.com/livekit/agents/pull/1843",
          "created_at": "2025-04-01T11:56:50Z"
        }
      ]
    },
    {
      "issue_number": 1702,
      "title": "Python MultimodalAgent mismatch type error with livekit.plugins openai realtime class",
      "body": "Currently I am using the livekit.plugins-openai (v0.11.0) and the livekit.agents (v0.12.15) where I am trying to initialize the multimodal agent.\n\nWithin the documentation (this one https://docs.livekit.io/agents/voice-agent/multimodal-agent/), it states to create the model to be used for the Multimodal agents with the call to the constructor ```openai.realtime.RealtimeModel```. \n\nThen it states to call the constructor for the MultimodalAgent by doing ```Multimodal(model=model)```, however, the expected argument type to be received is ```_RealtimeAPI``` but the type of the model that we place for this is ```RealtimeModel```.\n\nHere is a small snippet of how it looks like here\n```\nfrom livekit.agents.multimodal import MultimodalAgent\nfrom livekit.plugins import openai\n...\nparticipant = await ctx.wait_for_participant()\nmodel = openai.realtime.RealtimeModel(\n    instructions=\"You are a helpful assistant and you love kittens\",\n    voice=\"shimmer\",\n    temperature=0.8,\n    modalities=[\"audio\", \"text\"],\n)\nassistant = MultimodalAgent(model=model)\nassistant.start(ctx.room)\n```\n",
      "state": "closed",
      "author": "michaelwong3049",
      "author_type": "User",
      "created_at": "2025-03-21T18:10:58Z",
      "updated_at": "2025-04-01T01:23:51Z",
      "closed_at": "2025-03-30T06:46:43Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1702/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1702",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1702",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:51.741120",
      "comments": [
        {
          "author": "davidzhao",
          "body": "@michaelwong3049 I think this is a case of mismatching versions. try updating to the latest versions of both livekit-plugins-openai and livekit-agents",
          "created_at": "2025-03-24T05:21:08Z"
        },
        {
          "author": "michaelwong3049",
          "body": "@davidzhao Even after updating both, I'm still getting this type error (livekit-agents is v0.12.18; livekit-agents-openai is v0.12.2 after updating)\n\nThe expected type for the model in the MultimodalAgent is still _RealtimeAPI, and I still pass the model that is type of RealtimeModel\n",
          "created_at": "2025-03-31T20:06:13Z"
        },
        {
          "author": "longcw",
          "body": "@michaelwong3049 can you provide the logs and the result of `pip list | grep livekit`",
          "created_at": "2025-04-01T01:23:50Z"
        }
      ]
    },
    {
      "issue_number": 1813,
      "title": "Fallback Adapter doesn't properly handle Claude 529 Errors",
      "body": "I keep hitting 529 overloaded errors from Anthropic. Because of this, I added a Fallback adapter just in case, but it doesn't actually help.\n\n```py\nllm=llm.FallbackAdapter(\n    [\n        anthropic.LLM(\n            model=\"claude-3-7-sonnet-20250219\",\n            temperature=0.5,\n        ),\n        anthropic.LLM(\n            model=\"claude-3-5-sonnet-20240620\",\n            temperature=0.5,\n        ),\n        openai.LLM(\n            model=\"gpt-4o-mini\",\n            temperature=0.5,\n        ),\n    ]\n)\n```\n\nI expect this to fall back to Sonnet 3.5 and then GPT 4o Mini if the calls don't work, but it doesn't seem to be doing that.\n\nHere are the logs of the agent itself.\n\n```json\n{\"message\": \"failed to generate LLM completion, retrying in 0.1s\\nTraceback (most recent call last):\\n  File \\\"/opt/render/project/src/.venv/lib/python3.11/site-packages/livekit/plugins/anthropic/llm.py\\\", line 263, in _run\\n    async for event in stream:\\n  File \\\"/opt/render/project/src/.venv/lib/python3.11/site-packages/anthropic/_streaming.py\\\", line 185, in __aiter__\\n    async for item in self._iterator:\\n  File \\\"/opt/render/project/src/.venv/lib/python3.11/site-packages/anthropic/_streaming.py\\\", line 228, in __stream__\\n    raise self._client._make_status_error(\\nanthropic.APIStatusError: {'type': 'error', 'error': {'details': None, 'type': 'overloaded_error', 'message': 'Overloaded'}}\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/opt/render/project/src/.venv/lib/python3.11/site-packages/livekit/agents/llm/llm.py\\\", line 156, in _main_task\\n    return await self._run()\\n           ^^^^^^^^^^^^^^^^^\\n  File \\\"/opt/render/project/src/.venv/lib/python3.11/site-packages/livekit/plugins/anthropic/llm.py\\\", line 287, in _run\\n    raise APIStatusError(\\nlivekit.agents._exceptions.APIStatusError: {'type': 'error', 'error': {'details': None, 'type': 'overloaded_error', 'message': 'Overloaded'}} (status_code=200, request_id=req_017QyMVgGgZMX297ai5tv5Kv, body={'type': 'error', 'error': {'details': None, 'type': 'overloaded_error', 'message': 'Overloaded'}})\", \"level\": \"WARNING\", \"name\": \"livekit.agents\", \"llm\": \"livekit.plugins.anthropic.llm.LLM\", \"attempt\": 1, \"pid\": 168, \"job_id\": \"AJ_mNK7NbLY8PR9\", \"timestamp\": \"2025-03-29T23:12:24.600162+00:00\"}\n```",
      "state": "closed",
      "author": "bryanhoulton",
      "author_type": "User",
      "created_at": "2025-03-29T23:20:35Z",
      "updated_at": "2025-04-01T00:04:16Z",
      "closed_at": "2025-03-31T23:58:46Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1813/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1813",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1813",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:51.964202",
      "comments": [
        {
          "author": "bryanhoulton",
          "body": "I'm not sure if either:\na) it just isn't retrying the request\nb) it isnt actually falling back to the other models",
          "created_at": "2025-03-29T23:21:40Z"
        },
        {
          "author": "davidzhao",
          "body": "I'm not seeing a 529 error here. do you have logs that do show that somewhere? I see the following from the logs:\n\n```python\nlivekit.agents._exceptions.APIStatusError: {'type': 'error', 'error': {'details': None, 'type': 'overloaded_error', 'message': 'Overloaded'}} (status_code=200, request_id=req_",
          "created_at": "2025-03-30T06:32:09Z"
        },
        {
          "author": "bryanhoulton",
          "body": "Oh interesting, Anthropic's docs and logs say it's a 529. Maybe they are returning the wrong code (erroring on a 200).\n\nFWIW this only happens during an Anthropic outage, but that happens more than I'd like it to lol.",
          "created_at": "2025-03-31T23:58:21Z"
        },
        {
          "author": "bryanhoulton",
          "body": "I'll open something on the Anthropic help center and see what they say.",
          "created_at": "2025-03-31T23:58:46Z"
        },
        {
          "author": "bryanhoulton",
          "body": "Anthropic says that they return a 200 because they're just streaming back data :/. The 200 supposedly indicated that the streaming is successful, not that the request is successful. Could the fallback adapter check the error field on Anthropic models?",
          "created_at": "2025-04-01T00:03:48Z"
        }
      ]
    },
    {
      "issue_number": 1828,
      "title": "Agents 1.0 - Google/Anthropic LLM Type Error",
      "body": "When using a google/anthropic LLM the below error occurs on loading of an agent. In a multi-agent setup this error will happen when transitioning between agents. This seems to cause the agent to stop responding initially on load until prompted again\n```\n2025-03-31 09:52:25,387 - ERROR livekit.agents - Error in _inference_task\nTraceback (most recent call last):\n  File \".../.venv/lib/python3.11/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \".../.venv/lib/python3.11/site-packages/livekit/agents/voice/generation.py\", line 76, in _inference_task\n    async for chunk in llm_node:\n  File \".../.venv/lib/python3.11/site-packages/livekit/agents/voice/agent.py\", line 348, in llm_node\n    async with activity.llm.chat(\n               ^^^^^^^^^^^^^^^^^^\n  File \".../.venv/lib/python3.11/site-packages/livekit/plugins/google/llm.py\", line 161, in chat\n    if isinstance(tool_choice, ToolChoice):\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/typing.py\", line 1708, in __instancecheck__\n    return self.__subclasscheck__(type(obj))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/typing.py\", line 1712, in __subclasscheck__\n    if issubclass(cls, arg):\n       ^^^^^^^^^^^^^^^^^^^^\n  File \".../.venv/lib/python3.11/site-packages/typing_extensions.py\", line 1032, in __subclasscheck__\n    raise TypeError('TypedDict does not support instance and class checks')\nTypeError: TypedDict does not support instance and class checks {\"pid\": 72019, \"job_id\": \"AJ_5zSKphUGgH8b\"}\n``` \n\n**Versions**\nAgents: 1.0.0-rc4\ngoogle-plugin: 1.0.0-rc4\nanthropic-plugin: 1.0.0-rc4\n",
      "state": "closed",
      "author": "jmcclanahan13",
      "author_type": "User",
      "created_at": "2025-03-31T14:57:19Z",
      "updated_at": "2025-03-31T18:37:28Z",
      "closed_at": "2025-03-31T18:37:28Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1828/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 1
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1828",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1828",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:52.221907",
      "comments": [
        {
          "author": "jmcclanahan13",
          "body": "cc @jayeshp19 @davidzhao ",
          "created_at": "2025-03-31T14:57:36Z"
        }
      ]
    },
    {
      "issue_number": 1799,
      "title": "console subcommand doesn't work when using the InferenceProcess",
      "body": null,
      "state": "closed",
      "author": "theomonnom",
      "author_type": "User",
      "created_at": "2025-03-28T21:16:36Z",
      "updated_at": "2025-03-31T12:50:21Z",
      "closed_at": "2025-03-31T12:50:21Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1799/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1799",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1799",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:52.441278",
      "comments": []
    },
    {
      "issue_number": 1792,
      "title": "Difficulty Capturing Agent Transcript via Events [V1.03]",
      "body": "Goal:\nTo capture the REALTIME agent's spoken transcript in real-time or upon completion.\n\nProblem:\nThere doesn't appear to be a direct, simple event analogous to user_input_transcribed for capturing the agent's final spoken output. In 0.x we used\n\n        # self.session.on(\"agent_speech_committed\", self.on_agent_speech_committed)\n        # self.session.on(\"agent_speech_interrupted\", self.on_agent_speech_interrupted)\n        # self.session.on(\"user_speech_committed\", self.on_user_speech_committed)\n\nWhich worked well for RealTime agents. But they are removed in v1\n\nAttempts & Findings:\n\nUsing conversation_item_added Event:\n\nThe most intuitive event-based approach seems to be listening to conversation_item_added and filtering for messages where message.role == \"assistant\".\nIssue: Directly accessing message.content.text within this event handler often fails with an AttributeError: 'list' object has no attribute 'text'. This is because message.content can be a list (e.g., [{'type': 'text', 'text': '...'}]) rather than a simple object or string, requiring developers to implement parsing logic to extract the text.\nUsing Custom TextOutput Sink:\n\nAttaching a custom TextOutput class to self.session.output.transcription allows capturing the transcript stream directly as it's generated.\nDrawback: This requires defining a custom class, which is less straightforward than using a simple event listener.\nSuggestion:\nIt would significantly improve the developer experience if the SDK provided a dedicated event for agent speech output, similar to user_input_transcribed. This could be:\n\nAn event like agent_output_transcribed that fires with interim and final transcript segments.\nOr, ensure that the message.content within the conversation_item_added event consistently provides a simple way to access the final text transcript without needing complex type checking and iteration.\nThis would simplify the common task of logging or displaying agent responses alongside user input",
      "state": "closed",
      "author": "mercuryyy",
      "author_type": "User",
      "created_at": "2025-03-28T19:22:58Z",
      "updated_at": "2025-03-31T06:24:43Z",
      "closed_at": "2025-03-31T06:24:43Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1792/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "davidzhao"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1792",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1792",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:52.441299",
      "comments": [
        {
          "author": "longcw",
          "body": "Use `conversation_item_added` is the right way for agent output. The `content` in a `ChatMessage` is always a list \n```python\nclass ChatMessage(BaseModel):\n    id: str = Field(default_factory=lambda: utils.shortuuid(\"item_\"))\n    type: Literal[\"message\"] = \"message\"\n    role: ChatRole\n    content: l",
          "created_at": "2025-03-29T02:30:17Z"
        },
        {
          "author": "davidzhao",
          "body": "since most conversation messages are text, it makes sense to simplify this. opened #1816 to address this",
          "created_at": "2025-03-30T06:44:34Z"
        }
      ]
    },
    {
      "issue_number": 1044,
      "title": "Feature: add after_llm_cb to modify llm generated text",
      "body": "## Question regarding handling special tokens in conversation transcription\r\n \r\nFirst of all, thanks for making this wonderful SDK to easily create voice-enabled applications!\r\n \r\nI'm currently building a quiz agent that asks questions to users. The user's response is evaluated by an LLM, and if it's correct, the agent congratulates the user and adds a special 'QUESTION_END' token in the response. This token is used to identify that the conversation related to the current question is finished. I then create a new chat context with the next question.\r\n \r\n### Issue\r\n \r\nThe issue I'm facing is that while I have removed the special 'QUESTION_END' token in the `before_tts_cb` function, so my agent does not speak 'QUESTION_END', it still appears in the conversation text. It seems that the 'QUESTION_END' text was not removed from the LLM's response before transcription.\r\n \r\nUpon further investigation, I discovered the following code is executed after calling the LLM, which utilizes two different variables, `tts_source` and `transcription_source`, for different purposes:\r\n```python\r\ndef _synthesize_agent_speech(\r\n    self,\r\n    speech_id: str,\r\n    source: str | LLMStream | AsyncIterable[str],\r\n) -> SynthesisHandle:\r\n    assert (\r\n        self._agent_output is not None\r\n    ), \"agent output should be initialized when ready\"\r\n \r\n    if isinstance(source, LLMStream):\r\n        source = _llm_stream_to_str_iterable(speech_id, source)\r\n \r\n    og_source = source\r\n    transcript_source = source\r\n    if isinstance(og_source, AsyncIterable):\r\n        og_source, transcript_source = utils.aio.itertools.tee(og_source, 2)\r\n \r\n    tts_source = self._opts.before_tts_cb(self, og_source)\r\n    if tts_source is None:\r\n        raise ValueError(\"before_tts_cb must return str or AsyncIterable[str]\")\r\n \r\n    return self._agent_output.synthesize(\r\n        speech_id=speech_id,\r\n        tts_source=tts_source,\r\n        transcript_source=transcript_source,\r\n        transcription=self._opts.transcription.agent_transcription,\r\n        transcription_speed=self._opts.transcription.agent_transcription_speed,\r\n        sentence_tokenizer=self._opts.transcription.sentence_tokenizer,\r\n        word_tokenizer=self._opts.transcription.word_tokenizer,\r\n        hyphenate_word=self._opts.transcription.hyphenate_word,\r\n    )\r\n```\r\nThe `tts_source` does not contain the 'QUESTION_END' token, so it won't be played out, but the `transcription_source` contains 'QUESTION_END', causing it to be included in the transcription when committed.\r\n \r\n### Request for Enhancement\r\n \r\nCurrently, I've been unable to find a way to remove the 'QUESTION_END' text from the transcription, forcing me to use a crude hack to remove it from my frontend.\r\n \r\nI am looking for an `after_llm_cb` function or similar hook that would allow for observation and modification of the LLM-generated text before it's committed to transcription.\r\n \r\nThank you!",
      "state": "closed",
      "author": "achapla",
      "author_type": "User",
      "created_at": "2024-11-05T12:40:31Z",
      "updated_at": "2025-03-30T17:03:28Z",
      "closed_at": "2025-03-30T17:03:28Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1044/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1044",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1044",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:52.653795",
      "comments": [
        {
          "author": "davidzhao",
          "body": "this is a good point, we should offer a way to override before it's committed to the context.",
          "created_at": "2024-11-06T01:59:41Z"
        },
        {
          "author": "davidzhao",
          "body": "it's possible to do this now with v1: [https://docs.livekit.io/agents/v1/build/nodes/#llm-node](https://docs.livekit.io/agents/v1/build/nodes/#llm-node)",
          "created_at": "2025-03-30T17:03:24Z"
        }
      ]
    },
    {
      "issue_number": 1111,
      "title": "VoicePipelineAgent.aclose does not stop the agent correctly",
      "body": "`await agent.aclose()` should be tearing down the agent. However, users are reporting that it's not working as intended.",
      "state": "closed",
      "author": "davidzhao",
      "author_type": "User",
      "created_at": "2024-11-20T06:39:06Z",
      "updated_at": "2025-03-30T06:23:01Z",
      "closed_at": "2025-03-30T06:23:01Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1111/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1111",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1111",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:52.867294",
      "comments": [
        {
          "author": "beydogan",
          "body": "@davidzhao if you could provide some guidance about the internals, I would be interested in creating the PR on this because I've been looking into to this issue since a while.",
          "created_at": "2024-11-20T15:07:10Z"
        },
        {
          "author": "davidzhao",
          "body": "@beydogan, that'd be awesome. I'd love to help if you are interested in tackling this.\r\n\r\nBasically when the agent shuts down, it needs to terminate any async tasks that might be running, stop pushing frames to the published tracks, and stop any processing of incoming audio bits. Let me know if ther",
          "created_at": "2024-11-23T03:32:09Z"
        },
        {
          "author": "peng2219",
          "body": "> @davidzhao if you could provide some guidance about the internals, I would be interested in creating the PR on this because I've been looking into to this issue since a while.\r\n\r\nhi, @beydogan great to hear this,  I've blocked by this issue for a while, thanks for your support!\r\n",
          "created_at": "2024-11-27T02:28:56Z"
        },
        {
          "author": "peng2219",
          "body": "@davidzhao @beydogan Hi, sorry but is there any progress for this issue?",
          "created_at": "2024-12-14T10:33:28Z"
        },
        {
          "author": "davidzhao",
          "body": "this is fixed in v1",
          "created_at": "2025-03-30T06:22:55Z"
        }
      ]
    },
    {
      "issue_number": 1107,
      "title": "Root-level logger config in livekit.agents.ipc.proc_lazy_main.proc_main",
      "body": "This code is called dynamically (at runtime, not during import) and prevents me from configuring root-level logger in my application if I use livekit.agents.cli for handling workers.\r\n\r\n```\r\nroot_logger = logging.getLogger()\r\nroot_logger.setLevel(logging.NOTSET)\r\n```\r\nhttps://github.com/dsgolman/agents/blob/ca3e47aed53a8a54a5a8bcff47c7f101cab3e4d9/livekit-agents/livekit/agents/ipc/proc_lazy_main.py#L32",
      "state": "closed",
      "author": "stopdesign",
      "author_type": "User",
      "created_at": "2024-11-19T00:36:04Z",
      "updated_at": "2025-03-30T06:22:35Z",
      "closed_at": "2025-03-30T06:22:35Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1107/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1107",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1107",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:53.105607",
      "comments": [
        {
          "author": "theomonnom",
          "body": "Hey, this is the root_logger of a subprocess, every log is forwarded to the worker process ",
          "created_at": "2024-11-25T08:46:04Z"
        },
        {
          "author": "davidzhao",
          "body": "closing in favor of #1815",
          "created_at": "2025-03-30T06:22:32Z"
        }
      ]
    },
    {
      "issue_number": 936,
      "title": "livekit-plugin-elevenlabs TTS stalls when selecting a custom voice. ",
      "body": "Having a really hard time getting the Elevenlabs voice TTS to work with a dedicated/cloned voice. I'm using the voice-pipeline-agent-python example. It does work with the standard openai.TTS voice.\r\n\r\nElevenlabs.TTS with the standard voice, just set with the API key and model, also works:\r\n\r\n```\r\n\r\nassistant = VoicePipelineAgent(\r\n        vad=ctx.proc.userdata[\"vad\"],\r\n        stt=openai.STT(),\r\n        llm=openai.LLM(model=\"Meta-Llama-3.1-8B-Instruct\", api_key=\"xxxx\"),\r\n\r\n        tts=elevenlabs.TTS(model_id=\"eleven_turbo_v2_5\", api_key=os.getenv(\"ELEVEN_API_KEY\")),\r\n\r\n        chat_ctx=initial_ctx,\r\n    )\r\n```\r\n        \r\n\r\nThen if I try to work with a special cloned voice, using (voice=(Voice(id=\"..<code>..\")  the client never initializes audio (waiting for the Elevenlabs audio) and times out. there are no error messages it seems. \r\n\r\nHelp much appreciated!\r\n\r\n\r\ncode:\r\n```\r\nimport logging\r\nimport os\r\n\r\nfrom dotenv import load_dotenv\r\nfrom livekit.agents import (\r\n    AutoSubscribe,\r\n    JobContext,\r\n    JobProcess,\r\n    WorkerOptions,\r\n    cli,\r\n    llm,\r\n)\r\n\r\nfrom livekit.agents.pipeline import VoicePipelineAgent\r\nfrom livekit.plugins import openai, deepgram, silero, elevenlabs\r\nfrom livekit.plugins.elevenlabs import TTS, Voice, VoiceSettings\r\n\r\n\r\nload_dotenv(dotenv_path=\".env.local\")\r\nlogger = logging.getLogger(\"voice-agent\")\r\n\r\n\r\ndef prewarm(proc: JobProcess):\r\n    proc.userdata[\"vad\"] = silero.VAD.load()\r\n\r\n\r\nasync def entrypoint(ctx: JobContext):\r\n    initial_ctx = llm.ChatContext().append(\r\n        role=\"system\",\r\n        text=(\r\n            \"\"\"You are a helpful assistant \"\"\"\r\n        ),\r\n    )\r\n\r\n    logger.info(f\"connecting to room {ctx.room.name}\")\r\n    await ctx.connect(auto_subscribe=AutoSubscribe.AUDIO_ONLY)\r\n\r\n    # Wait for the first participant to connect\r\n    participant = await ctx.wait_for_participant()\r\n    logger.info(f\"starting voice assistant for participant {participant.identity}\")\r\n\r\n\r\n    assistant = VoicePipelineAgent(\r\n        vad=ctx.proc.userdata[\"vad\"],\r\n        stt=openai.STT(),\r\n         llm=openai.LLM(model=\"Meta-Llama-3.1-8B-Instruct\", api_key=\"xxxx\"),\r\n\r\n        tts = elevenlabs.TTS(\r\n            voice=Voice(id=\"xxx\", settings=VoiceSettings(stability=0.71, similarity_boost=0.5)),\r\n            model=\"eleven_turbo_v2_5\",\r\n            api_key=os.getenv(\"ELEVEN_API_KEY\")\r\n            ),\r\n        chat_ctx=initial_ctx,\r\n    )\r\n\r\n    assistant.start(ctx.room, participant)\r\n\r\n    # The agent should be polite and greet the user when it joins :)\r\n    await assistant.say(\"hi i am an assistant..\", allow_interruptions=True)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    cli.run_app(\r\n        WorkerOptions(\r\n            entrypoint_fnc=entrypoint,\r\n            prewarm_fnc=prewarm,\r\n        ),\r\n    )\r\n```\r\n\r\n\r\n",
      "state": "closed",
      "author": "Don-Chad",
      "author_type": "User",
      "created_at": "2024-10-16T22:44:11Z",
      "updated_at": "2025-03-30T06:09:49Z",
      "closed_at": "2025-03-30T06:09:49Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/936/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/936",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/936",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:53.336714",
      "comments": [
        {
          "author": "GabrielGalatti",
          "body": "I think category and name are required props!",
          "created_at": "2024-10-17T01:26:18Z"
        },
        {
          "author": "Don-Chad",
          "body": "> I think category and name are required props!\r\n\r\nAppreciate the reply! I had those in also, but still *silence* unfortunately. Did it work for you?\r\n\r\nIf anyone is able to share any working code for a custom Elevenlabs voice, it would be very helpful..!\r\n\r\nThanks \r\n\r\n",
          "created_at": "2024-10-17T08:03:41Z"
        },
        {
          "author": "BaiMoHan",
          "body": "> > I think category and name are required props!\r\n> \r\n> Appreciate the reply! I had those in also, but still _silence_ unfortunately. Did it work for you?\r\n> \r\n> If anyone is able to share any working code for a custom Elevenlabs voice, it would be very helpful..!\r\n> \r\n> Thanks\r\n\r\nDo you see any er",
          "created_at": "2024-10-17T08:37:26Z"
        },
        {
          "author": "GabrielGalatti",
          "body": "Yesterday, I could make work, my steps bellow:\r\n\r\n1. Upgrade 11labs to a paid plan\r\n2. Add category and name in the voice (if the voice is not [here](https://elevenlabs.io/docs/voices/default-voices), the category is custom)\r\n3. Add ELEVEN_API_KEY in .env.local\r\n\r\nThis works for me! But now I have a",
          "created_at": "2024-10-17T13:00:44Z"
        },
        {
          "author": "Don-Chad",
          "body": "> Yesterday, I could make work, my steps bellow:\r\n> \r\n> 1. Upgrade 11labs to a paid plan\r\n> 2. Add category and name in the voice (if the voice is not [here](https://elevenlabs.io/docs/voices/default-voices), the category is custom)\r\n> 3. Add ELEVEN_API_KEY in .env.local\r\n> \r\n> This works for me! Bu",
          "created_at": "2024-10-18T18:51:33Z"
        }
      ]
    },
    {
      "issue_number": 1101,
      "title": "@self._llm.on(\"metrics_collected\")",
      "body": "你好，我换了好几个Openai 的服务， 都是不行，总是出@self._llm.on(\"metrics_collected\") 的错误。 \r\n<!--\r\n\r\n\r\n  File \"C:\\Code\\OpenAI\\agents\\venv\\Lib\\site-packages\\livekit\\agents\\utils\\aio\\duplex_unix.py\", line 43, in recv_bytes\r\n    raise DuplexClosed()\r\nlivekit.agents.utils.aio.duplex_unix.DuplexClosed\r\n2024-11-17 21:21:23,920 - INFO livekit.agents - registered worker {\"id\": \"AW_UagNPBYPT4rf\", \"region\": \"US West\", \"protocol\": 15, \"node_id\": \"NC_OPHOENIX1A_saWEmSE4HXbA\"}\r\n2024-11-17 21:21:41,264 - INFO livekit.agents - received job request {\"job_id\": \"AJ_SpNTvnyAkAsX\", \"dispatch_id\": \"\", \"room_name\": \"playground-ZZWY-wfOw\", \"agent_name\": \"\", \"resuming\": false}\r\n2024-11-17 21:21:41,463 - DEBUG asyncio - Using proactor: IocpProactor \r\n2024-11-17 21:21:41,465 - DEBUG livekit.agents - initializing job runner {\"tid\": 20760}\r\n2024-11-17 21:21:41,466 - DEBUG livekit.agents - job runner initialized {\"tid\": 20760}\r\n2024-11-17 21:21:44,036 - ERROR livekit.agents - unhandled exception while running the job task \r\nTraceback (most recent call last):\r\n  File \"C:\\Code\\OpenAI\\agents\\examples\\voice-pipeline-agent\\simple-rag\\assistant.py\", line 92, in entrypoint\r\n    agent.start(ctx.room)\r\n  File \"C:\\Code\\OpenAI\\agents\\venv\\Lib\\site-packages\\livekit\\agents\\pipeline\\pipeline_agent.py\", line 349, in start\r\n    @self._llm.on(\"metrics_collected\")\r\n     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Code\\OpenAI\\agents\\venv\\Lib\\site-packages\\livekit\\rtc\\event_emitter.py\", line 166, in decorator\r\n    self.on(event, callback)\r\n  File \"C:\\Code\\OpenAI\\agents\\venv\\Lib\\site-packages\\livekit\\rtc\\event_emitter.py\", line 159, in on\r\n    if event not in self._events:\r\n                    ^^^^^^^^^^^^\r\nAttributeError: 'LLM' object has no attribute '_events'\r\n\r\n-->\r\n",
      "state": "closed",
      "author": "Walkman1W",
      "author_type": "User",
      "created_at": "2024-11-17T13:26:17Z",
      "updated_at": "2025-03-30T06:07:03Z",
      "closed_at": "2025-03-30T06:07:03Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1101/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1101",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1101",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:53.581698",
      "comments": [
        {
          "author": "FaisalJamil",
          "body": "@Walkman1W I also get the same error, did you figure out the resolution?\r\nMore specifically I get this in my logs, \r\npipeline_agent.py\", line 349, in start\r\n    @self._llm.on(\"metrics_collected\")\r\n     ^^^^^^^^^^^^\r\nAttributeError: 'NoneType' object has no attribute 'on' ",
          "created_at": "2024-11-24T17:25:42Z"
        },
        {
          "author": "Jeandcc",
          "body": "Also facing the same issue",
          "created_at": "2025-03-06T12:17:09Z"
        },
        {
          "author": "Jeandcc",
          "body": "```\n    class CustomAssistantLLM(AssistantLLM):\n        # Fixes issues with metric tracking\n        def on(self, event, handler=None):\n            # Proper implementation that handles event registration\n            if handler is None:\n                return lambda x: self.on(event, x)\n            re",
          "created_at": "2025-03-06T12:37:51Z"
        },
        {
          "author": "davidzhao",
          "body": "we support registering listeners on the Agent/AgentSession itself",
          "created_at": "2025-03-30T06:07:00Z"
        }
      ]
    },
    {
      "issue_number": 1086,
      "title": "AssistantLLM with VoicePipelineAgent not working properly",
      "body": "Hi,\r\n\r\nI've tried creating an agent using an openAI Assistant as the LLM. It joins the room and works as expected until after the it's first utterance. After speaking the string I pass into the agent.say() function and then I respond it will either stay silent or speak sentences with words out of order, sounding like gibberish. When I check the logs I get two errors:\r\n\r\n`2024-11-13 04:03:17,675 - ERROR livekit.agents.pipeline - Error in _stream_synthesis_task\r\nTraceback (most recent call last):\r\n  File \"/home/appuser/.local/lib/python3.11/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\r\n    return await fn(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/appuser/.local/lib/python3.11/site-packages/livekit/agents/pipeline/agent_output.py\", line 273, in _stream_synthesis_task\r\n    async for seg in tts_source:\r\n  File \"/home/appuser/.local/lib/python3.11/site-packages/livekit/agents/utils/aio/itertools.py\", line 47, in tee_peer\r\n    item = await iterator.__anext__()\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/appuser/.local/lib/python3.11/site-packages/livekit/agents/pipeline/pipeline_agent.py\", line 869, in _llm_stream_to_str_generator\r\n    async for chunk in stream:\r\n  File \"/home/appuser/.local/lib/python3.11/site-packages/livekit/agents/llm/llm.py\", line 159, in __anext__\r\n    raise exc from None\r\n  File \"/home/appuser/.local/lib/python3.11/site-packages/livekit/plugins/openai/beta/assistant_llm.py\", line 510, in _main_task\r\n    self._done_future.set_result(None)\r\nasyncio.exceptions.InvalidStateError: invalid state {\"pid\": 138, \"job_id\": \"AJ_Xkw6xdYmimL3\"}`\r\n\r\nAnd sometimes this one along with the first error message:\r\n\r\n`raise self._make_status_error_from_response(err.response) from None\\nopenai.BadRequestError: Error code: 400 - {'error': {'message': 'Thread thread_P5iSwRGvKxYIiEXK1GsVmDto already has an active run run_JlVSXO5euDaOpDaeY9aKyZWX.', 'type': 'invalid_request_error', 'param': None, 'code': None}}`\r\n\r\nThe weird thing is that when I swap out the assistantLLM for the regular openAI LLM then it works perfectly fine.\r\n\r\nHere is the code of the code that isn't working:\r\n\r\n`import asyncio\r\nimport os\r\nimport boto3\r\nimport json\r\nimport logging\r\nimport uuid\r\nfrom dataclasses import asdict, dataclass\r\nfrom typing import Any, Dict\r\n\r\nfrom livekit import rtc\r\nfrom livekit.agents import (\r\n    AutoSubscribe,\r\n    JobContext,\r\n    WorkerOptions,\r\n    JobProcess,\r\n    WorkerType,\r\n    cli,\r\n    llm\r\n)\r\nfrom livekit.plugins.openai.beta import (\r\n    AssistantLoadOptions,\r\n    AssistantLLM,\r\n    AssistantOptions,\r\n    OnFileUploadedInfo,\r\n)\r\nfrom livekit.agents.pipeline import VoicePipelineAgent\r\nfrom livekit.plugins import openai, silero\r\nfrom livekit.agents.multimodal import MultimodalAgent\r\n# from livekit.plugins import openai\r\n# from voicePipelineAgent import prewarm, run_voicepipeline_agent\r\nfrom multiModalAgent import run_multimodal_agent\r\n\r\nlogger = logging.getLogger(\"dynamic-agent\")\r\nlogger.setLevel(logging.INFO)\r\n\r\ndef prewarm(proc: JobProcess):\r\n    proc.userdata[\"vad\"] = silero.VAD.load()\r\n\r\nasync def entrypoint(ctx: JobContext):\r\n    logger.info(f\"connecting to room {ctx.room.name}\")\r\n    await ctx.connect(auto_subscribe=AutoSubscribe.AUDIO_ONLY)\r\n\r\n    participant = await ctx.wait_for_participant()\r\n    metadata = json.loads(participant.metadata)\r\n\r\n    agent_type = metadata.get(\"agent_type\", \"voice_pipeline\")\r\n\r\n    if agent_type == \"multimodal\":\r\n        run_multimodal_agent(ctx, participant)\r\n    else:\r\n        openai_api_key = metadata.get(\"openai_api_key\",\"\")\r\n        openai_model = metadata.get(\"openai_model\",\"gpt-4o-mini\")\r\n        voice = metadata.get(\"voice\",\"alloy\")\r\n        voice_model = metadata.get(\"voice_model\",\"tts-1\")\r\n        assistant_id = metadata.get(\"assistant_id\",\"<assistantID placeholder I took out to post here>\")\r\n\r\n        initial_ctx = llm.ChatContext()\r\n        \r\n        agent = VoicePipelineAgent(\r\n            vad=ctx.proc.userdata[\"vad\"],\r\n            stt=openai.STT(api_key=openai_api_key),\r\n            llm=AssistantLLM(\r\n            assistant_opts=AssistantOptions(\r\n                load_options=AssistantLoadOptions(\r\n                    assistant_id=assistant_id,\r\n                    thread_id=None\r\n                )\r\n            ),\r\n            api_key=openai_api_key,\r\n        ),\r\n            tts=openai.TTS(model=voice_model,voice=voice,api_key=openai_api_key),\r\n            chat_ctx=initial_ctx,\r\n            allow_interruptions=False,\r\n        )\r\n\r\n        agent.start(ctx.room, participant)\r\n        \r\n        await agent.say(\"Hello?\", allow_interruptions=False)\r\n    \r\n    logger.info(\"dynamic agent started\")\r\n\r\nif __name__ == \"__main__\":\r\n    cli.run_app(WorkerOptions(\r\n        entrypoint_fnc=entrypoint,\r\n        worker_type=WorkerType.ROOM, \r\n        prewarm_fnc=prewarm\r\n        ))\r\n`\r\n",
      "state": "closed",
      "author": "xavier-pare-ai",
      "author_type": "User",
      "created_at": "2024-11-14T16:33:22Z",
      "updated_at": "2025-03-30T06:06:13Z",
      "closed_at": "2025-03-30T06:06:13Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1086/reactions",
        "total_count": 9,
        "+1": 9,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1086",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1086",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:53.816714",
      "comments": [
        {
          "author": "xavier-pare-ai",
          "body": "I'm also using the most recent versions of all the livekit packages.\r\nLet me know if I can provide more info.",
          "created_at": "2024-11-14T17:36:13Z"
        },
        {
          "author": "alejomendez1019",
          "body": "I have the same issue, any solution?",
          "created_at": "2024-11-18T22:24:27Z"
        },
        {
          "author": "xavier-pare-ai",
          "body": "@alejomendez1019 Not yet, waiting on the liveKit team to take a look",
          "created_at": "2024-11-19T20:05:41Z"
        },
        {
          "author": "JeisonNovoa",
          "body": "Check the issue I posted with the title \"Solution to \"InvalidStateError\" and Handling of Closed Channels in OpenAI's AssistantLLMStream\" there I found a solution to that problem",
          "created_at": "2024-11-20T15:51:24Z"
        },
        {
          "author": "wakusoftware",
          "body": "This needs to be fixed please",
          "created_at": "2025-01-02T18:44:04Z"
        }
      ]
    },
    {
      "issue_number": 1790,
      "title": "livekit-plugins-openai: Incompatibility with Groq API due to messages.0.content format V1.03",
      "body": "When using the livekit.plugins.openai.LLM plugin from livekit-plugins-openai with a custom base_url pointing to an OpenAI-compatible API like Groq (https://api.groq.com/openai/v1), a BadRequestError (HTTP 400) occurs.\n\nError Message:\n\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"'messages.0' : for 'role:system' the following must be satisfied[('messages.0.content' : value must be a string)]\", 'type': 'invalid_request_error'}}\nAnalysis:\n\nBased on code inspection (livekit-plugins/livekit-plugins-openai/livekit/plugins/openai/utils.py, specifically the to_chat_ctx and _to_chat_item functions), the library consistently formats the content field of messages as a list of parts (e.g., [{\"type\": \"text\", \"text\": \"System prompt\"}]), even for single text parts. This aligns with newer OpenAI API specifications.\n\nHowever, the error message suggests that the Groq API endpoint specifically requires the content of the initial system message (messages.0) to be a simple string, rather than a list containing a single text object.\n\nExpected Behavior:\n\nThe openai.LLM plugin should ideally handle variations in content formatting requirements for different OpenAI-compatible endpoints, or provide a way to configure this behavior.\n\nActual Behavior:\n\nThe library sends the system message content formatted as [{\"type\": \"text\", ...}], which causes a BadRequestError with the Groq API.\n\nSteps to Reproduce (Conceptual):\n\nConfigure livekit.plugins.openai.LLM with base_url=\"https://api.groq.com/openai/v1\" and a valid Groq API key.\nInitiate a chat session that sends a system prompt.\nObserve the BadRequestError related to messages.0.content.\nSuggested Area for Investigation:\n\nReview the to_chat_ctx function in livekit-plugins-openai to see if the formatting for the system message (messages[0]) can be adapted when the content is a single text string, potentially making it compatible with endpoints like Groq that expect a simple string in this case.",
      "state": "closed",
      "author": "mercuryyy",
      "author_type": "User",
      "created_at": "2025-03-28T19:17:29Z",
      "updated_at": "2025-03-29T23:48:19Z",
      "closed_at": "2025-03-29T23:48:19Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1790/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1790",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1790",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:54.086988",
      "comments": [
        {
          "author": "mercuryyy",
          "body": "Here is a more detailed Log \n\n```\n2025-03-29 19:09:04,548 - [ef81adb6-f089-4eb7] - ****-Agent - agents - DEBUG - received user transcript\n2025-03-29 19:09:04,548 - DEBUG livekit.agents - received user transcript {\"user_transcript\": \"Is your name?\", \"pid\": 78, \"job_id\": \"AJ_BDfciiNAKAXM\"}\n2025-03-29 ",
          "created_at": "2025-03-29T19:11:18Z"
        }
      ]
    },
    {
      "issue_number": 1696,
      "title": "core dumped while import noise_cancellation plugin",
      "body": "> Python 3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> from livekit.plugins import noise_cancellation\n\n>>>\n>>> Segmentation fault (core dumped)",
      "state": "closed",
      "author": "ericyue",
      "author_type": "User",
      "created_at": "2025-03-21T08:48:44Z",
      "updated_at": "2025-03-29T07:38:48Z",
      "closed_at": "2025-03-29T07:38:48Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 10,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1696/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1696",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1696",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:54.306108",
      "comments": [
        {
          "author": "ericyue",
          "body": "livekit and plugins are all latest version",
          "created_at": "2025-03-21T08:49:11Z"
        },
        {
          "author": "martin-purplefish",
          "body": "Did you run download-files first?",
          "created_at": "2025-03-21T10:50:53Z"
        },
        {
          "author": "ericyue",
          "body": "> Did you run download-files first?\n\nit's cored when import module.  (cored before download files process)",
          "created_at": "2025-03-21T10:52:39Z"
        },
        {
          "author": "davidzhao",
          "body": "can you list the version of the plugin used? `pip freeze | grep livekit`",
          "created_at": "2025-03-25T16:53:14Z"
        },
        {
          "author": "ericyue",
          "body": "> can you list the version of the plugin used? `pip freeze | grep livekit`\n\nlivekit==0.22.0\nlivekit-agents==0.12.17\nlivekit-api==0.8.2\nlivekit-plugins-anthropic==0.2.13\nlivekit-plugins-cartesia==0.4.11\nlivekit-plugins-deepgram==0.7.1\nlivekit-plugins-elevenlabs==0.8.1\nlivekit-plugins-noise-cancellati",
          "created_at": "2025-03-26T01:19:14Z"
        }
      ]
    },
    {
      "issue_number": 1731,
      "title": "Example implementation: Mediator agent with external consultations",
      "body": "I’m working on a real-time conversational AI system using LiveKit and the OpenAI Realtime API. The system involves a single mediator agent in a LiveKit room that interacts with users via voice. However, instead of generating responses independently, this agent must consult multiple external AI agents (via API calls or even internal livekit non-voice LLMs) before responding.\n\nBasically the requirements of the system are these:\n1. Single Mediator Agent: A single LiveKit MultimodalAgent should handle user interactions in the room.\n2. External Agents for Consultation:\n- The mediator agent should query multiple external agents.\n- The responses from these external agents should be integrated before forming a final reply.\n3. Real-Time Speech Interaction:\n- Convert user speech to text.\n- Query external agents with the transcribed text.\n- Process their responses and generate a final reply.\n- Convert the reply to speech and send it back to the room.\n\nQuestion:\n\nCould you provide an example implementation (or guidance) for achieving this functionality using the LiveKit `MultimodalAgent`? Specifically:\n- How can we intercept the transcribed text before the agent generates a response?\n- What’s the best way to send queries to external APIs and integrate their responses into the final AI-generated answer?\n- If subclassing or extending `MultimodalAgent` is necessary, what approach would you recommend?\n\nI have seen that this is being implemented in v1.0 (#959) but is there any example to implement it right now? I couldn't find any examples.\n\nThanks!\n\n<!--\nHello! Thanks for taking the time to ask a question.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already asked this question.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n\nFeel free to join us in the #agents channel on our Slack, and ask your question\nthere to get quicker help from us and the community:\n\nhttps://livekit.io/join-slack\n-->\n",
      "state": "closed",
      "author": "eyenpi",
      "author_type": "User",
      "created_at": "2025-03-25T17:52:32Z",
      "updated_at": "2025-03-29T06:42:22Z",
      "closed_at": "2025-03-29T06:42:22Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1731/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1731",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1731",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:54.534403",
      "comments": [
        {
          "author": "davidzhao",
          "body": "v1.0 allows for multiple *voice* agents. you can always consult external workflows by using function calls.\n\nfor example, you can register function calls for particular intent that require external data. When that is triggered, simply start a new llm.stream() and receive the desired result before re",
          "created_at": "2025-03-29T06:42:13Z"
        }
      ]
    },
    {
      "issue_number": 1750,
      "title": "Add support for self-hosted Qwen 2.5 Omni",
      "body": "Qwen 2.5 Omni is an LLM, STT, and TTS all in one model. I want to self-host it, and use it with LiveKit Agents.\n\nhttps://qwenlm.github.io/blog/qwen2.5-omni/",
      "state": "closed",
      "author": "jadams777",
      "author_type": "User",
      "created_at": "2025-03-27T01:51:32Z",
      "updated_at": "2025-03-29T06:31:37Z",
      "closed_at": "2025-03-29T06:31:37Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1750/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 1
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1750",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1750",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:54.755239",
      "comments": [
        {
          "author": "davidzhao",
          "body": "we do not have plans to support this as of now. If you are able to get it to work, we'd be open to a PR for a plugin",
          "created_at": "2025-03-29T06:31:32Z"
        }
      ]
    },
    {
      "issue_number": 1763,
      "title": "OPENAI STT error APIStatusError",
      "body": "Hello , we are using VoiceAgentPipeline to serve an end-to-end assistant pipeline ,\n\nin addition are there any good multilingual STT replacement ? \n\n we use the following package versions:\n```\nivekit==0.22.0\nlivekit-agents==0.12.18\nlivekit-api==0.8.2\nlivekit-plugins-anthropic==0.2.13\nlivekit-plugins-deepgram==0.7.1\nlivekit-plugins-elevenlabs==0.8.1\nlivekit-plugins-google==0.11.2\nlivekit-plugins-openai==0.12.0\nlivekit-plugins-rag==0.2.4\nlivekit-plugins-silero==0.7.5\nlivekit-plugins-turn-detector==0.4.3\nlivekit-protocol==0.9.2\n```\n\nThe error log is:\n```\n2025-03-27 17:39:59,252 - \u001b[32mINFO\u001b[0m openai_assistant_dev - Performing agentReady RPC with the payload true and destination identity 435b990e-a5c9-4685-9650-272fd7554bfd -- 2025-03-27 17:39:59.252414 \u001b[90m\u001b[0m\n2025-03-27 17:39:59,252 - \u001b[33mWARNING\u001b[0m livekit.agents - Running <Task pending name='job_user_entrypoint' coro=<entrypoint() running at C:\\Users\\******\\Desktop\\spatial-agents-server\\Agent.py:766> wait_for=<Future pending cb=[Task.task_wakeup()]> cb=[_JobProc._run_job_task.<locals>.<lambda>() at C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\agents\\ipc\\job_proc_lazy_main.py:239, _JobProc._run_job_task.<locals>.log_exception() at C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\agents\\ipc\\job_proc_lazy_main.py:241]> took too long: 2.17 seconds \u001b[90m\u001b[0m\n2025-03-27 17:39:59,253 - \u001b[33mWARNING\u001b[0m livekit.agents - Running <Task pending name='job_user_entrypoint' coro=<entrypoint() running at C:\\Users\\******\\Desktop\\spatial-agents-server\\Agent.py:766> wait_for=<Future pending cb=[Task.task_wakeup()]> cb=[_JobProc._run_job_task.<locals>.<lambda>() at C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\agents\\ipc\\job_proc_lazy_main.py:239, _JobProc._run_job_task.<locals>.log_exception() at C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\agents\\ipc\\job_proc_lazy_main.py:241]> took too long: 2.17 seconds \u001b[90m\u001b[0m\n2025-03-27 17:40:00,729 - \u001b[32mINFO\u001b[0m openai_assistant_dev - RPC response for agentReady is: Received ready agent message , 0:00:01.477218 \u001b[90m\u001b[0m\n2025-03-27 17:40:00,818 - \u001b[36mDEBUG\u001b[0m livekit.agents - http_session(): creating a new httpclient ctx \u001b[90m\u001b[0m\n2025-03-27 17:40:01,625 - \u001b[31mERROR\u001b[0m livekit.plugins.openai - Error in recv_task \u001b[90m\u001b[0m\nTraceback (most recent call last):\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\agents\\utils\\log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\plugins\\openai\\stt.py\", line 416, in recv_task\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: OpenAI Realtime STT connection closed unexpectedly (status_code=-1, request_id=None, body=None)\n2025-03-27 17:40:01,628 - \u001b[31mERROR\u001b[0m livekit.plugins.openai - Error in _run \u001b[90m\u001b[0m\nTraceback (most recent call last):\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\agents\\utils\\log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\plugins\\openai\\stt.py\", line 491, in _run\n    task.result()\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\agents\\utils\\log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\plugins\\openai\\stt.py\", line 416, in recv_task\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: OpenAI Realtime STT connection closed unexpectedly (status_code=-1, request_id=None, body=None)\n2025-03-27 17:40:01,628 - \u001b[33mWARNING\u001b[0m livekit.agents - failed to recognize speech, retrying in 0.1s \u001b[90m{\"tts\": \"livekit.plugins.openai.stt.STT\", \"attempt\": 0, \"streamed\": true}\u001b[0m\nTraceback (most recent call last):\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\agents\\stt\\stt.py\", line 219, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\agents\\utils\\log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\plugins\\openai\\stt.py\", line 491, in _run\n    task.result()\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\agents\\utils\\log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\plugins\\openai\\stt.py\", line 416, in recv_task\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: OpenAI Realtime STT connection closed unexpectedly (status_code=-1, request_id=None, body=None)\n2025-03-27 17:40:02,330 - \u001b[31mERROR\u001b[0m livekit.plugins.openai - Error in recv_task \u001b[90m\u001b[0m\nTraceback (most recent call last):\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\agents\\utils\\log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\plugins\\openai\\stt.py\", line 416, in recv_task\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: OpenAI Realtime STT connection closed unexpectedly (status_code=-1, request_id=None, body=None)\n2025-03-27 17:40:02,331 - \u001b[31mERROR\u001b[0m livekit.plugins.openai - Error in _run \u001b[90m\u001b[0m\nTraceback (most recent call last):\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\agents\\utils\\log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\plugins\\openai\\stt.py\", line 491, in _run\n    task.result()\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\agents\\utils\\log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\plugins\\openai\\stt.py\", line 416, in recv_task\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: OpenAI Realtime STT connection closed unexpectedly (status_code=-1, request_id=None, body=None)\n2025-03-27 17:40:02,332 - \u001b[33mWARNING\u001b[0m livekit.agents - failed to recognize speech, retrying in 2.0s \u001b[90m{\"tts\": \"livekit.plugins.openai.stt.STT\", \"attempt\": 1, \"streamed\": true}\u001b[0m\nTraceback (most recent call last):\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\agents\\stt\\stt.py\", line 219, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\agents\\utils\\log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\plugins\\openai\\stt.py\", line 491, in _run\n    task.result()\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\agents\\utils\\log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\plugins\\openai\\stt.py\", line 416, in recv_task\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: OpenAI Realtime STT connection closed unexpectedly (status_code=-1, request_id=None, body=None)\n2025-03-27 17:40:04,885 - \u001b[31mERROR\u001b[0m livekit.plugins.openai - Error in recv_task \u001b[90m\u001b[0m\nTraceback (most recent call last):\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\agents\\utils\\log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\plugins\\openai\\stt.py\", line 416, in recv_task\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: OpenAI Realtime STT connection closed unexpectedly (status_code=-1, request_id=None, body=None)\n2025-03-27 17:40:04,887 - \u001b[31mERROR\u001b[0m livekit.plugins.openai - Error in _run \u001b[90m\u001b[0m\nTraceback (most recent call last):\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\agents\\utils\\log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\plugins\\openai\\stt.py\", line 491, in _run\n    task.result()\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\agents\\utils\\log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\plugins\\openai\\stt.py\", line 416, in recv_task\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: OpenAI Realtime STT connection closed unexpectedly (status_code=-1, request_id=None, body=None)\n2025-03-27 17:40:04,887 - \u001b[33mWARNING\u001b[0m livekit.agents - failed to recognize speech, retrying in 2.0s \u001b[90m{\"tts\": \"livekit.plugins.openai.stt.STT\", \"attempt\": 2, \"streamed\": true}\u001b[0m\nTraceback (most recent call last):\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\agents\\stt\\stt.py\", line 219, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\agents\\utils\\log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\plugins\\openai\\stt.py\", line 491, in _run\n    task.result()\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\agents\\utils\\log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\plugins\\openai\\stt.py\", line 416, in recv_task\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: OpenAI Realtime STT connection closed unexpectedly (status_code=-1, request_id=None, body=None)\n2025-03-27 17:40:07,739 - \u001b[31mERROR\u001b[0m livekit.plugins.openai - Error in recv_task \u001b[90m\u001b[0m\nTraceback (most recent call last):\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\agents\\utils\\log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\plugins\\openai\\stt.py\", line 416, in recv_task\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: OpenAI Realtime STT connection closed unexpectedly (status_code=-1, request_id=None, body=None)\n2025-03-27 17:40:07,741 - \u001b[31mERROR\u001b[0m livekit.plugins.openai - Error in _run \u001b[90m\u001b[0m\nTraceback (most recent call last):\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\agents\\utils\\log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\plugins\\openai\\stt.py\", line 491, in _run\n    task.result()\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\agents\\utils\\log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\plugins\\openai\\stt.py\", line 416, in recv_task\n    raise APIStatusError(\nlivekit.agents._exceptions.APIStatusError: OpenAI Realtime STT connection closed unexpectedly (status_code=-1, request_id=None, body=None)\n2025-03-27 17:40:07,742 - \u001b[31mERROR\u001b[0m livekit.agents.pipeline - Error in _recognize_task \u001b[90m\u001b[0m\nTraceback (most recent call last):\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\agents\\utils\\log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\agents\\pipeline\\human_input.py\", line 158, in _recognize_task\n    await asyncio.gather(*tasks)\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\agents\\pipeline\\human_input.py\", line 144, in _stt_stream_co\n    async for ev in stt_stream:\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\agents\\stt\\stt.py\", line 321, in __anext__\n    raise exc from None\n  File \"C:\\Users\\******\\Desktop\\spatial-agents-server\\.venv\\Lib\\site-packages\\livekit\\agents\\stt\\stt.py\", line 224, in _main_task\n    raise APIConnectionError(\nlivekit.agents._exceptions.APIConnectionError: failed to recognize speech after 3 attempts\n\n```\n\nAny help is highly appreciated!\n",
      "state": "closed",
      "author": "ElyasMoshirpanahi",
      "author_type": "User",
      "created_at": "2025-03-27T18:08:53Z",
      "updated_at": "2025-03-29T06:27:32Z",
      "closed_at": "2025-03-29T06:27:32Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1763/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1763",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1763",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:55.086542",
      "comments": [
        {
          "author": "davidzhao",
          "body": "assuming this is when setting `detect_languages=True`, this has been fixed in https://github.com/livekit/agents/pull/1755 and released in livekit-plugins-openai 0.12.2",
          "created_at": "2025-03-27T20:36:50Z"
        }
      ]
    },
    {
      "issue_number": 1766,
      "title": "how to use chat stream?",
      "body": "before it works with\n\n```\nchat = rtc.ChatManager(ctx.room)\n@chat.on(\"message_received\")\n    def on_message_received(msg: rtc.ChatMessage):\n...\n```\n\nhow to do it now?",
      "state": "closed",
      "author": "matigumma",
      "author_type": "User",
      "created_at": "2025-03-27T20:57:06Z",
      "updated_at": "2025-03-29T06:26:53Z",
      "closed_at": "2025-03-29T06:26:53Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1766/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1766",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1766",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:55.363185",
      "comments": [
        {
          "author": "longcw",
          "body": "With agent 1.0 you can now send a text to topic `lk.chat` using text stream https://docs.livekit.io/home/client/data/text-streams/, by default the agent will generate reply based on the text\n```python\nTextInputCallback = Callable[\n    [\"AgentSession\", TextInputEvent], Optional[Coroutine[None, None, ",
          "created_at": "2025-03-28T01:55:09Z"
        },
        {
          "author": "sinhpn92",
          "body": "> With agent 1.0 you can now send a text to topic `lk.chat` using text stream https://docs.livekit.io/home/client/data/text-streams/, by default the agent will generate reply based on the text\n> \n> TextInputCallback = Callable[\n>     [\"AgentSession\", TextInputEvent], Optional[Coroutine[None, None, N",
          "created_at": "2025-03-28T16:28:35Z"
        },
        {
          "author": "davidzhao",
          "body": "@sinhpn92 with 0.x, you'd have to manually add it into the chat context, and trigger a manual generation with say. it was a bit hacky to accomplish",
          "created_at": "2025-03-28T16:45:21Z"
        }
      ]
    },
    {
      "issue_number": 1772,
      "title": "APITimeoutError incorrectly thrown",
      "body": "We have been looking for weeks why our VoicePipelineAgent LLM module regularly fails with an \"APITimeoutError\". Also the LiveKit support gave poorly any help about this case.\nTurns out the **APITimeoutError is apparently always raised no matter what error** the actual OpenAI API returns.\n\nThis is a huge flaw! People cannot debug this correctly with a wrong error message.",
      "state": "open",
      "author": "brianzaubar",
      "author_type": "User",
      "created_at": "2025-03-28T10:03:39Z",
      "updated_at": "2025-03-29T06:26:09Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1772/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1772",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1772",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:55.582318",
      "comments": [
        {
          "author": "davidzhao",
          "body": "can you give an example error that is raised incorrectly? here's the code that is handling it. I'm not seeing the behavior you are describing:\n\n```python\nexcept openai.APITimeoutError:\n    raise APITimeoutError(retryable=retryable)\nexcept openai.APIStatusError as e:\n    raise APIStatusError(\n       ",
          "created_at": "2025-03-29T06:26:08Z"
        }
      ]
    },
    {
      "issue_number": 728,
      "title": "Crash while using- before_tts_cb",
      "body": "{\"message\": \"Error in _str_synthesis_task\\nTraceback (most recent call last):\\n  File \\\"/root/pythonenv/enve/lib/python3.10/site-packages/livekit/agents/utils/log.py\\\", line 16, in async_fn_logs\\n    return await fn(*args, **kwargs)\\n  File \\\"/root/pythonenv/enve/lib/python3.10/site-packages/livekit/agents/voice_assistant/agent_output.py\\\", line 195, in _str_synthesis_task\\n    handle.tts_forwarder.push_text(transcript)\\n  File \\\"/root/pythonenv/enve/lib/python3.10/site-packages/livekit/agents/transcription/tts_forwarder.py\\\", line 200, in push_text\\n    self._text_data.pushed_text += text\\nTypeError: can only concatenate str (not \\\"async_generator\\\") to str\", \"level\": \"ERROR\", \"pid\": 772990, \"job_id\": \"AJ_owPeUnBxdvK3\", \"timestamp\": \"2024-09-09T10:18:21.988046+00:00\"}",
      "state": "open",
      "author": "Test-isom",
      "author_type": "User",
      "created_at": "2024-09-09T10:20:00Z",
      "updated_at": "2025-03-29T03:06:30Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/728/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/728",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/728",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:55.777901",
      "comments": [
        {
          "author": "davidzhao",
          "body": "Can you share what your `before_tts_cb` is doing?",
          "created_at": "2024-09-09T15:25:35Z"
        },
        {
          "author": "Test-isom",
          "body": "sure, not sure if iam doing something wrong, aim was to replace asterisk(currently i control it via prompt) before passing them to TTS, \r\n\r\ninitially it was this-\r\n if isinstance(text, AsyncIterable):\r\n            async def process_async_text():\r\n                async for chunk in text:\r\n           ",
          "created_at": "2024-09-10T04:57:26Z"
        },
        {
          "author": "sinhpn92",
          "body": "Did you resolve @Test-isom ?\n",
          "created_at": "2025-03-29T03:06:29Z"
        }
      ]
    },
    {
      "issue_number": 1793,
      "title": "AttributeError: 'FunctionCall' object has no attribute 'role' [V1.03]",
      "body": "When: Occurs within the livekit-agents framework, specifically in the livekit.plugins.turn_detector.eou.predict_end_of_turn function called via livekit.agents.voice.audio_recognition.py's _bounce_eou_task. This happens after a user speaks, seemingly following an interaction involving a **tool call**\n\nIndication: The internal chat context (chat_ctx) being processed by the End-of-Utterance turn detector contains a raw FunctionCall object where a standard message object (with a .role) is expected. The turn detector plugin cannot handle this object type in the message history.\n\n",
      "state": "closed",
      "author": "mercuryyy",
      "author_type": "User",
      "created_at": "2025-03-28T19:40:36Z",
      "updated_at": "2025-03-28T20:20:18Z",
      "closed_at": "2025-03-28T20:20:18Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1793/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1793",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1793",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:55.985869",
      "comments": [
        {
          "author": "theomonnom",
          "body": "This may be an issue inside the LLM plugin, which LLM are you using?",
          "created_at": "2025-03-28T20:04:27Z"
        },
        {
          "author": "theomonnom",
          "body": "Oh I found the issue, gotcha it's the turn-detection code, will push a fix in a min",
          "created_at": "2025-03-28T20:06:18Z"
        },
        {
          "author": "jayeshp19",
          "body": "@theomonnom I raised PR: https://github.com/livekit/agents/pull/1795",
          "created_at": "2025-03-28T20:10:43Z"
        }
      ]
    },
    {
      "issue_number": 1717,
      "title": "Agents 1.0 - OpenAI Realtime Invalid 'item.id'",
      "body": "Trying to test out OpenAI realtime and getting the below error on the Agents 1.0 branch. I'm testing with multiple agents similar to the restaurant example in the repo. Let me know if you need additional details\n```\nERROR livekit.plugins.openai - OpenAI Realtime API returned an error {\"error\": \"Error(message=\\\"Invalid 'item.id': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\\\", type='invalid_request_error', code='invalid_value', event_id='chat_ctx_create_2d3051e3fd6b', param='item.id')\", \"pid\": 15442, \"job_id\": \"AJ_SY9tKVf4Psgj\"}\n``` \n\n```python\n    agent = AgentSession(\n        userdata=state,\n        vad=ctx.proc.userdata[\"vad\"],\n        # stt=deepgram.STT(model=\"nova-2-phonecall\"),\n        llm=openai.realtime.RealtimeModel(voice=\"echo\"),\n        # tts=cartesia.TTS(voice=\"6f84f4b8-58a2-430c-8c79-688dad597532\"),\n        # turn_detector=turn_detector.EOUModel(),\n    )\n``` \n\n**Versions**\nlivekit-agents: 1.0.0-dev5\nlivekit-plugins-openai: 1.0.0.dev5\n\n",
      "state": "closed",
      "author": "jmcclanahan13",
      "author_type": "User",
      "created_at": "2025-03-24T13:36:19Z",
      "updated_at": "2025-03-28T19:54:01Z",
      "closed_at": "2025-03-28T19:54:00Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1717/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1717",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1717",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:56.231962",
      "comments": [
        {
          "author": "longcw",
          "body": "This is a known issue, we will fix it soon.",
          "created_at": "2025-03-24T13:53:51Z"
        },
        {
          "author": "theomonnom",
          "body": "Hey, this is going to get fixed by #1787, thanks for the report!",
          "created_at": "2025-03-28T19:54:00Z"
        }
      ]
    },
    {
      "issue_number": 1693,
      "title": "elevenlabs plugin error:  Non-thread-safe operation invoked on an event loop other than the current one",
      "body": "basic infomation: every related livekit libs are latest version . \nwhen start demo assistant adding \"--asyncio-debug\",  will fail to connect agent and show errors. but old version libs will not raise this exception. \n**update:  I change the minimal_assistant code to use latest elevenlabs tts . So it seems the error is caused by elevenlabs plugin.** \n\n> 2025-03-20 23:11:53,757 - ERROR livekit.agents - error decoding audio\nTraceback (most recent call last):\n  File \"/data/anaconda3/lib/python3.12/site-packages/livekit/agents/utils/codecs/decoder.py\", line 151, in _decode_loop\n    self._output_ch.send_nowait(\n  File \"/data/anaconda3/lib/python3.12/site-packages/livekit/agents/utils/aio/channel.py\", line 95, in send_nowait\n    self._wakeup_next(self._gets)\n  File \"/data/anaconda3/lib/python3.12/site-packages/livekit/agents/utils/aio/channel.py\", line 65, in _wakeup_next\n    waiter.set_result(None)\n  File \"/data/anaconda3/lib/python3.12/asyncio/base_events.py\", line 797, in call_soon\n    self._check_thread()\n  File \"/data/anaconda3/lib/python3.12/asyncio/base_events.py\", line 834, in _check_thread\n    raise RuntimeError(\nRuntimeError: Non-thread-safe operation invoked on an event loop other than the current one {\"pid\": 649754, \"job_id\": \"AJ_PBq9FDg3y4BX\"}\n\npython -u minimal_assistant.py  dev --log-level DEBUG  --asyncio-debug",
      "state": "closed",
      "author": "ericyue",
      "author_type": "User",
      "created_at": "2025-03-21T03:15:06Z",
      "updated_at": "2025-03-28T15:42:20Z",
      "closed_at": "2025-03-28T15:42:19Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1693/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1693",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1693",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:58.315117",
      "comments": [
        {
          "author": "ChenghaoMou",
          "body": "I can confirm it is happening. But this only happens with asyncio debug turned on. If you turn off asyncio debug or change it to thread executor type, it works just fine.\n\n```python\nWorkerOptions(\n    entrypoint_fnc=entrypoint,\n    prewarm_fnc=prewarm,\n    job_executor_type=JobExecutorType.THREAD,\n)",
          "created_at": "2025-03-26T16:21:53Z"
        },
        {
          "author": "ericyue",
          "body": "@davidzhao  could you help to solve this problem? thanks ",
          "created_at": "2025-03-27T02:38:20Z"
        },
        {
          "author": "ChenghaoMou",
          "body": "I don't think the `push_nowait` with `aio.Chan` is thread-safe. Here is one possible fix that is working in my testing\n\n```diff\ndiff --git a/livekit-agents/livekit/agents/utils/codecs/decoder.py b/livekit-agents/livekit/agents/utils/codecs/decoder.py\nindex 3e5f70c8..44c72d9e 100644\n--- a/livekit-age",
          "created_at": "2025-03-27T10:34:28Z"
        },
        {
          "author": "theomonnom",
          "body": "Thanks a lot @ChenghaoMou \nFixed here https://github.com/livekit/agents/pull/1775",
          "created_at": "2025-03-28T15:42:19Z"
        }
      ]
    },
    {
      "issue_number": 1737,
      "title": "Dynamically add `ai_callable` methods to function contexts",
      "body": "<!--\nHello! Thanks for taking the time to ask a question.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already asked this question.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n\nFeel free to join us in the #agents channel on our Slack, and ask your question\nthere to get quicker help from us and the community:\n\nhttps://livekit.io/join-slack\n-->\nI'm not sure if this is a feature request or a question, as I don't know if it's already a supported use case.\n\n## Description\n\nCurrently, you can use `@llm.ai_callable()` to make a method in a `llm.FunctionContext` callable by the agent.\n\n```python\nclass CallActions(llm.FunctionContext):\n    \"\"\"\n    Detect user intent and perform actions\n    \"\"\"\n\n    def __init__(\n        self, *, api: api.LiveKitAPI, participant: rtc.RemoteParticipant, room: rtc.Room\n    ):\n        super().__init__()\n\n        self.api = api\n        self.participant = participant\n        self.room = room\n\n    async def hangup(self):\n        try:\n            await self.api.room.remove_participant(\n                api.RoomParticipantIdentity(\n                    room=self.room.name,\n                    identity=self.participant.identity,\n                )\n            )\n        except Exception as e:\n            # it's possible that the user has already hung up, this error can be ignored\n            logger.info(f\"received error while ending call: {e}\")\n\n    @llm.ai_callable()\n    async def end_call(self):\n        \"\"\"Called when the user wants to end the call\"\"\"\n        logger.info(f\"ending the call for {self.participant.identity}\")\n        await self.hangup()\n```\n\nHowever, these methods are fixed (defined together with the class). I'd like to dynamically add a callable method to the instance at runtime.\n\n```python\n    call_actions = CallActions(api=ctx.api, participant=participant, room=ctx.room)\n\n    async def end_call(self: CallActions):\n        \"\"\"Called when the user wants to end the call\"\"\"\n        logger.info(f\"ending the call for {self.participant.identity}\")\n        await self.hangup()\n\n    # Add `end_call` to `call_actions`\n```\n\nHow would I do that?\n\n## Alternatives\n\nNot that I know of. I was able to hack my way through it, looking to the implementation of `ai_callable`, but I hardly think it's something you should be doing.\n\n```python\n    call_actions = CallActions(api=ctx.api, participant=participant, room=ctx.room)\n\n    async def end_call(self: CallActions):\n        \"\"\"Called when the user wants to end the call\"\"\"\n        logger.info(f\"ending the call for {self.participant.identity}\")\n        await self.hangup()\n\n    # Set the metadata using the internal mechanism\n    llm.function_context._set_metadata(\n        end_call,\n        name=\"end_call\",\n        desc=\"Called when the user wants to end the call\",\n        auto_retry=False\n    )\n\n    # Bind it to the instance\n    bound_method = types.MethodType(end_call, call_actions)\n\n    # Register it with the function context system\n    call_actions._fncs[\"end_call\"] = llm.function_context.FunctionInfo(\n        name=\"end_call\",\n        description=\"Called when the user wants to end the call\",\n        auto_retry=False,\n        callable=bound_method,\n        arguments={}  # No arguments besides self\n    )\n\n    # Set it as an instance method\n    call_actions.end_call = bound_method\n```",
      "state": "closed",
      "author": "luiz00martins",
      "author_type": "User",
      "created_at": "2025-03-26T04:39:08Z",
      "updated_at": "2025-03-28T01:44:56Z",
      "closed_at": "2025-03-28T01:44:55Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1737/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1737",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1737",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:58.528248",
      "comments": [
        {
          "author": "theomonnom",
          "body": "Hey, I just added an [example](https://github.com/livekit/agents/blob/634798d386b795f5e00af03d047ef13127f1dfa0/examples/voice_agents/dynamic_tool_creation.py) on how to do it with agents v1.0\n\nI suggest upgrading to this version, as it offers significantly greater flexibility.",
          "created_at": "2025-03-28T01:44:55Z"
        }
      ]
    },
    {
      "issue_number": 1723,
      "title": "Cannot initialize `VoicePipelineAgent` without a VAD",
      "body": "<!--\nHello! Thanks for taking the time to file a bug report.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already reported this issue.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n-->\n\nThe OpenAI STT plugin has been updated to support both `server_vad` and `semantic_vad`, but when instantiating a `VoicePipelineAgent` object you must provide a VAD parameter (ie the Silero model). If you are trying to use OpenAI turn taking this model is not required since the API handles turn taking on its own.\n\nSimilar issues exist for other plugings (ie Deepgram has Endpointing support which is equally blocked by this VAD param)",
      "state": "closed",
      "author": "chasemcdo",
      "author_type": "User",
      "created_at": "2025-03-24T21:50:56Z",
      "updated_at": "2025-03-28T01:42:24Z",
      "closed_at": "2025-03-28T01:42:24Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1723/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1723",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1723",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:58.726459",
      "comments": [
        {
          "author": "longcw",
          "body": "We are going to release agent 1.0 soon that can specify the turn detection mode, the VAD model will be optional. ",
          "created_at": "2025-03-25T02:36:26Z"
        },
        {
          "author": "chasemcdo",
          "body": "Thanks @longcw ! Is there a timeline for release? Would love to get this into production ASAP as it’ll help alleviate a number of bugs we’ve been facing.",
          "created_at": "2025-03-25T02:58:06Z"
        },
        {
          "author": "well-balanced",
          "body": "> We are going to release agent 1.0 soon that can specify the turn detection mode, the VAD model will be optional.\n\nI’m also really looking forward to 1.0 release. It will be a huge help for our workflow!",
          "created_at": "2025-03-26T19:27:18Z"
        },
        {
          "author": "longcw",
          "body": "We just released the 1.0 RC candidate today, you can try it through `pip install \"livekit-agents[openai, silero, deepgram, cartesia, turn-detector]==1.0.0.rc3\" --prerelease=allow`\n\nand you can find the examples in https://github.com/livekit/agents/tree/dev-1.0/examples, we are going to update the do",
          "created_at": "2025-03-27T02:01:01Z"
        }
      ]
    },
    {
      "issue_number": 1765,
      "title": "Update the last message from chat context",
      "body": "  I’m implementing a **“clear user input buffer”** feature and need to modify the last message in the chat context. In the `before_llm_cb` function, I attempted to update `agent.chat_ctx.messages` or `chat_ctx_messages`, but the changes don’t persist when the next callback is invoked. How can I properly update the last message so that the modifications are recognized in subsequent callbacks?\n  \n  if you need more context, you can referto [my previous question](https://github.com/livekit/agents/issues/1746).\n  \n  thanks :)",
      "state": "closed",
      "author": "well-balanced",
      "author_type": "User",
      "created_at": "2025-03-27T20:52:14Z",
      "updated_at": "2025-03-27T21:47:04Z",
      "closed_at": "2025-03-27T21:47:04Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1765/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1765",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1765",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:58.947066",
      "comments": [
        {
          "author": "well-balanced",
          "body": "I discovered that returning False ignores the last message, so this resolves my original concern. I’m closing the issue now!",
          "created_at": "2025-03-27T21:47:02Z"
        }
      ]
    },
    {
      "issue_number": 1745,
      "title": "How is possible to put in pause an agent and then resume it?",
      "body": "Hello,\n\nafter I create a room and let an agent join it, I would like to be able to put in pause that agent, or some how disable it, and then resume it.\n\nDo you have any idea how to do it?\n\nThanks",
      "state": "closed",
      "author": "gianmaria90",
      "author_type": "User",
      "created_at": "2025-03-26T16:29:54Z",
      "updated_at": "2025-03-27T15:46:55Z",
      "closed_at": "2025-03-27T15:46:55Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1745/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1745",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1745",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:59.253543",
      "comments": [
        {
          "author": "longcw",
          "body": "We just released agents 1.0 RC today, it allows you to disable the audio input / output of the agent, does that work for you? Here is an example https://github.com/livekit/agents/blob/dev-1.0/examples/toggle-io.py#L59",
          "created_at": "2025-03-27T02:21:10Z"
        },
        {
          "author": "gianmaria90",
          "body": "> We just released agents 1.0 RC today, it allows you to disable the audio input / output of the agent, does that work for you? Here is an example https://github.com/livekit/agents/blob/dev-1.0/examples/toggle-io.py#L59\n\nThe link is not working. \n\nI'll try to explain better my current issue. I tried",
          "created_at": "2025-03-27T09:53:13Z"
        },
        {
          "author": "longcw",
          "body": "oh sorry, we are reorg the examples, it's here https://github.com/livekit/agents/blob/dev-1.0/examples/voice_agents/toggle_io.py",
          "created_at": "2025-03-27T09:56:47Z"
        }
      ]
    },
    {
      "issue_number": 1759,
      "title": "TTS transcription is still sent after \"agentStoppedSpeaking\" and \"agentSpeechInterrupted\"",
      "body": "Upon interrupting the agent while he is talking, the events `agentStoppedSpeaking` and `agentSpeechInterrupted` are fired.\nThough after that a TTS transcription is still being sent. \n\nI can see this in my frontend by receiving the TTS transcription events: \n> RoomEvent.TranscriptionReceived, (transcriptions, participant)\n\nAnd our VoicePipelineAgent-Pipeline also sends RPC's to the client when `agentStoppedSpeaking` and `agentSpeechInterrupted` is triggered, so the frontend can see when this happens too.",
      "state": "open",
      "author": "brianzaubar",
      "author_type": "User",
      "created_at": "2025-03-27T13:27:54Z",
      "updated_at": "2025-03-27T13:27:54Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1759/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1759",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1759",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:59.498633",
      "comments": []
    },
    {
      "issue_number": 1744,
      "title": "[dev-1.0] DataStreamAudioOutput Initilization Error",
      "body": "next_in_action is missing from DataStreamAudioOutput's super init function.\n\nI know everything in the dev branch is still WIP. Please feel free to close it if it is already on your radar. Thanks!",
      "state": "closed",
      "author": "ChenghaoMou",
      "author_type": "User",
      "created_at": "2025-03-26T15:00:47Z",
      "updated_at": "2025-03-26T15:30:42Z",
      "closed_at": "2025-03-26T15:30:42Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1744/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1744",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1744",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:59.498655",
      "comments": [
        {
          "author": "longcw",
          "body": "Thanks! fixed in https://github.com/livekit/agents/commit/20dce81cf8b12cb4c98a6e9ec3c7cb38e1f1beb1",
          "created_at": "2025-03-26T15:30:35Z"
        }
      ]
    },
    {
      "issue_number": 1167,
      "title": "AWS ECS Deployment - livekit.plugins.elevenlabs - aiodns.error.DNSError: (12, 'Timeout while contacting DNS servers')",
      "body": "Is there anyone who encounter with this error when working with the 11labs tts ?\r\n\r\nfailed to connect to 11labs, retrying in 5s\r\nTraceback (most recent call last):\r\n  File \"/home/appuser/.local/lib/python3.12/site-packages/aiohttp/resolver.py\", line 105, in resolve\r\n    resp = await self._resolver.getaddrinfo(\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\naiodns.error.DNSError: (12, 'Timeout while contacting DNS servers')\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/appuser/.local/lib/python3.12/site-packages/aiohttp/connector.py\", line 1317, in _create_direct_connection\r\n    hosts = await self._resolve_host(host, port, traces=traces)\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/appuser/.local/lib/python3.12/site-packages/aiohttp/connector.py\", line 946, in _resolve_host\r\n    await future\r\n  File \"/home/appuser/.local/lib/python3.12/site-packages/aiohttp/connector.py\", line 1002, in _resolve_host_with_throttle\r\n    addrs = await self._resolver.resolve(host, port, family=self._family)\r\n      ...\r\n",
      "state": "open",
      "author": "firattamurlc",
      "author_type": "User",
      "created_at": "2024-12-03T14:01:28Z",
      "updated_at": "2025-03-26T12:37:37Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1167/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1167",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1167",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:35:59.758065",
      "comments": [
        {
          "author": "andormarkus",
          "body": "Hi @firattamurlc \n\nPlease can you simple test to determine is your problem limited to `elevenlabs.io` or you got global problem.\n\n```python\nimport socket\nimport time\n\n\ndef test_dns_resolution():\n    \"\"\"Simple DNS resolution test using only standard library\"\"\"\n    domains = [\"google.com\", \"elevenlabs",
          "created_at": "2025-03-26T12:37:36Z"
        }
      ]
    },
    {
      "issue_number": 1459,
      "title": "Hot to let Multimodal Agent say first?",
      "body": "I'm currently using OpenAI's real-time multimodal Agent. It always asks me to greet first. I have to say \"hello\" in voice before it starts to speak. How can I make the AI speak first?",
      "state": "closed",
      "author": "johnson7788",
      "author_type": "User",
      "created_at": "2025-02-07T02:44:03Z",
      "updated_at": "2025-03-26T01:39:26Z",
      "closed_at": "2025-02-07T04:27:15Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1459/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1459",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1459",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:00.043622",
      "comments": [
        {
          "author": "cuongpham-1001",
          "body": "Just mention that in your prompt",
          "created_at": "2025-02-07T03:24:26Z"
        },
        {
          "author": "longcw",
          "body": "you can use `agent.generate_reply()` https://github.com/livekit/agents/blob/main/livekit-agents/livekit/agents/multimodal/multimodal_agent.py#L390",
          "created_at": "2025-02-07T03:53:37Z"
        },
        {
          "author": "notauserx",
          "body": "You can use RealtimeModel to create a custom speech. Here is a sample code\n\n\nhttps://platform.openai.com/docs/api-reference/realtime-client-events/response/create\n\n\n```\nmodel = openai.realtime.RealtimeModel(\n    instructions=instructions,\n    modalities=[\"audio\", \"text\"],\n    temperature=0.8,\n    tu",
          "created_at": "2025-02-07T03:54:25Z"
        },
        {
          "author": "johnson7788",
          "body": "Yes, Great ,Thank all people, @longcw @notauserx , very helpful, Success.\n\nchat_ctx.append(text=\"Hello!\", role=\"user\")\nagent = MultimodalAgent(model=model, fnc_ctx=fnc_ctx, chat_ctx=chat_ctx)\nagent.start(ctx.room, participant)\nagent.generate_reply()",
          "created_at": "2025-02-07T04:27:15Z"
        },
        {
          "author": "meetakshay99",
          "body": "I have a text message that I want MultiModelAgent to speak directly as it is. How can I do that?",
          "created_at": "2025-02-23T18:00:30Z"
        }
      ]
    },
    {
      "issue_number": 1514,
      "title": "When using azure.stt, the agent is falsely dead.",
      "body": "Hello team, I am using VoicePipelineAgent. When using azure.stt, the agent freezes and does not trigger the _stt_stream_co function. Did I miss something?\n\n```\nlivekit-agents>=0.12.12\nlivekit-plugins-openai>=0.10.19\nlivekit-plugins-azure>=0.5.3\nlivekit-plugins-silero>=0.7.4\nlivekit-plugins-turn-detector>=0.4.1\n```\n\n```\nagent = VoicePipelineAgent(\n        vad=ctx.proc.userdata[\"vad\"],\n        stt=azure.STT(),\n        llm=openai.LLM(),\n        tts=azure.TTS(),\n        turn_detector=turn_detector.EOUModel(),\n        chat_ctx=initial_ctx,\n        before_llm_cb=_before_llm_cb,\n        fnc_ctx=fnc_ctx,\n        max_nested_fnc_calls=3,\n        min_endpointing_delay=0.5,\n        max_endpointing_delay=3.0,\n        allow_interruptions=False # Note here\n    )\n```\n\n\n```\n2025-02-19 00:11:00,787 - DEBUG livekit.agents.pipeline - speech playout started {\"speech_id\": \"47306d1cfb50\", \"pid\": 52053, \"job_id\": \"AJ_tyGRpFhYJUAR\"}\nInfo: on_underlying_io_bytes_received: Close frame received\nInfo: on_underlying_io_bytes_received: closing underlying io.\nInfo: on_underlying_io_close_complete: uws_state: 6.\nDEBUG:livekit.agents.pipeline:speech playout finished\nDEBUG:livekit.agents.pipeline:speech playout finished\n2025-02-19 00:11:03,889 - DEBUG livekit.agents.pipeline - speech playout finished {\"speech_id\": \"47306d1cfb50\", \"interrupted\": false, \"pid\": 52053, \"job_id\": \"AJ_tyGRpFhYJUAR\"}\nDEBUG:livekit.agents.pipeline:committed agent speech\nDEBUG:livekit.agents.pipeline:committed agent speech\n2025-02-19 00:11:03,890 - DEBUG livekit.agents.pipeline - committed agent speech {\"agent_transcript\": \"\\u60a8\\u597d\\uff0c\\u8bf7\\u95ee\\u9700\\u8981\\u91c7\\u8d2d\\u4ec0\\u4e48\\u5546\\u54c1\\u5462\\uff1f\", \"interrupted\": false, \"speech_id\": \"47306d1cfb50\", \"pid\": 52053, \"job_id\": \"AJ_tyGRpFhYJUAR\"}\nDEBUG:livekit.agents.pipeline:validated agent reply\nDEBUG:livekit.agents.pipeline:validated agent reply\n2025-02-19 00:11:20,314 - DEBUG livekit.agents.pipeline - validated agent reply {\"speech_id\": \"81c574555974\", \"text\": \"\", \"pid\": 52053, \"job_id\": \"AJ_tyGRpFhYJUAR\"}\nDEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '.........'}, {'role': 'assistant', 'content': '您好，请问需要采购什么商品呢？'}, {'role': 'user', 'content': '<continue>'}], 'model': 'qwen-plus', 'n': 1, 'stream': True, 'stream_options': {'include_usage': True}, 'temperature': 0.3, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'find_goods', 'description': '通过商品关键词查找商品信息，当用户提及商品时调用', 'parameters': {'type': 'object', 'properties': {'goods_names': {'description': '商品名称关键词', 'type': 'array', 'items': {'type': 'string'}}}, 'required': ['goods_names']}}}, {'type': 'function', 'function': {'name': 'switch_language', 'description': '当用户提及切换对话语言时调用', 'parameters': {'type': 'object', 'properties': {'lang': {'description': '语言code', 'type': 'string', 'enum': ('zh-CN', 'en-US', 'it-IT', 'de-DE', 'es-ES', 'fr-FR')}}, 'required': ['lang']}}}]}}\nDEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'eagleeye-traceid', b'b48817e97b7328ef5e59089efd89518f'), (b'vary', b'Origin'), (b'x-request-id', b'22b63348-d500-9ac5-a5d6-d899a40f8fa4'), (b'content-type', b'text/event-stream;charset=UTF-8'), (b'x-dashscope-call-gateway', b'true'), (b'req-cost-time', b'457'), (b'req-arrive-time', b'1739895080436'), (b'resp-start-time', b'1739895080893'), (b'x-envoy-upstream-service-time', b'353'), (b'date', b'Tue, 18 Feb 2025 16:11:20 GMT'), (b'server', b'istio-envoy'), (b'transfer-encoding', b'chunked')])\nINFO:httpx:HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions \"HTTP/1.1 200 OK\"\nDEBUG:openai._base_client:HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions \"200 OK\"\nDEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:livekit.agents.pipeline:speech playout started\nDEBUG:livekit.agents.pipeline:speech playout started\n2025-02-19 00:11:23,116 - DEBUG livekit.agents.pipeline - speech playout started {\"speech_id\": \"81c574555974\", \"pid\": 52053, \"job_id\": \"AJ_tyGRpFhYJUAR\"}\nInfo: on_underlying_io_bytes_received: Close frame received\nInfo: on_underlying_io_bytes_received: closing underlying io.\nInfo: on_underlying_io_close_complete: uws_state: 6.\nDEBUG:livekit.agents.pipeline:speech playout finished\nDEBUG:livekit.agents.pipeline:speech playout finished\nDEBUG:livekit.agents.pipeline:committed agent speech\n2025-02-19 00:11:26,218 - DEBUG livekit.agents.pipeline - speech playout finished {\"speech_id\": \"81c574555974\", \"interrupted\": false, \"pid\": 52053, \"job_id\": \"AJ_tyGRpFhYJUAR\"}\nDEBUG:livekit.agents.pipeline:committed agent speech\n2025-02-19 00:11:26,218 - DEBUG livekit.agents.pipeline - committed agent speech {\"agent_transcript\": \"\\u60a8\\u597d\\uff0c\\u8bf7\\u95ee\\u9700\\u8981\\u91c7\\u8d2d\\u4ec0\\u4e48\\u5546\\u54c1\\u5462\\uff1f\", \"interrupted\": false, \"speech_id\": \"81c574555974\", \"pid\": 52053, \"job_id\": \"AJ_tyGRpFhYJUAR\"}\nDEBUG:livekit.agents.pipeline:validated agent reply\nDEBUG:livekit.agents.pipeline:validated agent reply\n2025-02-19 00:12:31,131 - DEBUG livekit.agents.pipeline - validated agent reply {\"speech_id\": \"69cc03e26a43\", \"text\": \"\", \"pid\": 52053, \"job_id\": \"AJ_tyGRpFhYJUAR\"}\nDEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '.........'}, {'role': 'assistant', 'content': '您好，请问需要采购什么商品呢？'}, {'role': 'assistant', 'content': '您好，请问需要采购什么商品呢？'}, {'role': 'user', 'content': '<continue>'}], 'model': 'qwen-plus', 'n': 1, 'stream': True, 'stream_options': {'include_usage': True}, 'temperature': 0.3, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'find_goods', 'description': '通过商品关键词查找商品信息，当用户提及商品时调用', 'parameters': {'type': 'object', 'properties': {'goods_names': {'description': '商品名称关键词', 'type': 'array', 'items': {'type': 'string'}}}, 'required': ['goods_names']}}}, {'type': 'function', 'function': {'name': 'switch_language', 'description': '当用户提及切换对话语言时调用', 'parameters': {'type': 'object', 'properties': {'lang': {'description': '语言code', 'type': 'string', 'enum': ('zh-CN', 'en-US', 'it-IT', 'de-DE', 'es-ES', 'fr-FR')}}, 'required': ['lang']}}}]}}\nDEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'eagleeye-traceid', b'b61c21e950830bccae778cdaa47984ff'), (b'vary', b'Origin'), (b'x-request-id', b'e15b8601-08dd-9dc9-b2ea-86ee6e3cd711'), (b'content-type', b'text/event-stream;charset=UTF-8'), (b'x-dashscope-call-gateway', b'true'), (b'req-cost-time', b'383'), (b'req-arrive-time', b'1739895151262'), (b'resp-start-time', b'1739895151645'), (b'x-envoy-upstream-service-time', b'381'), (b'date', b'Tue, 18 Feb 2025 16:12:31 GMT'), (b'server', b'istio-envoy'), (b'transfer-encoding', b'chunked')])\nINFO:httpx:HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions \"HTTP/1.1 200 OK\"\nDEBUG:openai._base_client:HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions \"200 OK\"\nDEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:livekit.agents.pipeline:speech playout started\nDEBUG:livekit.agents.pipeline:speech playout started\n2025-02-19 00:12:33,459 - DEBUG livekit.agents.pipeline - speech playout started {\"speech_id\": \"69cc03e26a43\", \"pid\": 52053, \"job_id\": \"AJ_tyGRpFhYJUAR\"}\nInfo: on_underlying_io_bytes_received: Close frame received\nInfo: on_underlying_io_bytes_received: closing underlying io.\nInfo: on_underlying_io_close_complete: uws_state: 6.\nDEBUG:livekit.agents.pipeline:speech playout finished\nDEBUG:livekit.agents.pipeline:speech playout finished\n2025-02-19 00:12:36,564 - DEBUG livekit.agents.pipeline - speech playout finished {\"speech_id\": \"69cc03e26a43\", \"interrupted\": false, \"pid\": 52053, \"job_id\": \"AJ_tyGRpFhYJUAR\"}\nDEBUG:livekit.agents.pipeline:committed agent speech\nDEBUG:livekit.agents.pipeline:committed agent speech\n2025-02-19 00:12:36,566 - DEBUG livekit.agents.pipeline - committed agent speech {\"agent_transcript\": \"\\u60a8\\u597d\\uff0c\\u8bf7\\u95ee\\u9700\\u8981\\u91c7\\u8d2d\\u4ec0\\u4e48\\u5546\\u54c1\\u5462\\uff1f\", \"interrupted\": false, \"speech_id\": \"69cc03e26a43\", \"pid\": 52053, \"job_id\": \"AJ_tyGRpFhYJUAR\"}\nDEBUG:livekit.agents.pipeline:validated agent reply\nDEBUG:livekit.agents.pipeline:validated agent reply\n2025-02-19 00:13:28,403 - DEBUG livekit.agents.pipeline - validated agent reply {\"speech_id\": \"d9e2532d0188\", \"text\": \"\", \"pid\": 52053, \"job_id\": \"AJ_tyGRpFhYJUAR\"}\nDEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '......'}, {'role': 'assistant', 'content': '您好，请问需要采购什么商品呢？'}, {'role': 'user', 'content': '<continue>'}], 'model': 'qwen-plus', 'n': 1, 'stream': True, 'stream_options': {'include_usage': True}, 'temperature': 0.3, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'find_goods', 'description': '通过商品关键词查找商品信息，当用户提及商品时调用', 'parameters': {'type': 'object', 'properties': {'goods_names': {'description': '商品名称关键词', 'type': 'array', 'items': {'type': 'string'}}}, 'required': ['goods_names']}}}, {'type': 'function', 'function': {'name': 'switch_language', 'description': '当用户提及切换对话语言时调用', 'parameters': {'type': 'object', 'properties': {'lang': {'description': '语言code', 'type': 'string', 'enum': ('zh-CN', 'en-US', 'it-IT', 'de-DE', 'es-ES', 'fr-FR')}}, 'required': ['lang']}}}]}}\nDEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'eagleeye-traceid', b'e683465598df8852812d0a4ea58caa3b'), (b'vary', b'Origin'), (b'x-request-id', b'28b1657e-4529-9a33-81d0-e1b860232898'), (b'content-type', b'text/event-stream;charset=UTF-8'), (b'x-dashscope-call-gateway', b'true'), (b'req-cost-time', b'339'), (b'req-arrive-time', b'1739895208791'), (b'resp-start-time', b'1739895209131'), (b'x-envoy-upstream-service-time', b'337'), (b'date', b'Tue, 18 Feb 2025 16:13:29 GMT'), (b'server', b'istio-envoy'), (b'transfer-encoding', b'chunked')])\nINFO:httpx:HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions \"HTTP/1.1 200 OK\"\nDEBUG:openai._base_client:HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions \"200 OK\"\nDEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:livekit.agents.pipeline:speech playout started\nDEBUG:livekit.agents.pipeline:speech playout started\n2025-02-19 00:13:31,215 - DEBUG livekit.agents.pipeline - speech playout started {\"speech_id\": \"d9e2532d0188\", \"pid\": 52053, \"job_id\": \"AJ_tyGRpFhYJUAR\"}\nInfo: on_underlying_io_bytes_received: Close frame received\nInfo: on_underlying_io_bytes_received: closing underlying io.\nInfo: on_underlying_io_close_complete: uws_state: 6.\nDEBUG:livekit.agents.pipeline:speech playout finished\nDEBUG:livekit.agents.pipeline:speech playout finished\n2025-02-19 00:13:34,317 - DEBUG livekit.agents.pipeline - speech playout finished {\"speech_id\": \"d9e2532d0188\", \"interrupted\": false, \"pid\": 52053, \"job_id\": \"AJ_tyGRpFhYJUAR\"}\nDEBUG:livekit.agents.pipeline:committed agent speech\nDEBUG:livekit.agents.pipeline:committed agent speech\n2025-02-19 00:13:34,317 - DEBUG livekit.agents.pipeline - committed agent speech {\"agent_transcript\": \"\\u60a8\\u597d\\uff0c\\u8bf7\\u95ee\\u9700\\u8981\\u91c7\\u8d2d\\u4ec0\\u4e48\\u5546\\u54c1\\u5462\\uff1f\", \"interrupted\": false, \"speech_id\": \"d9e2532d0188\", \"pid\": 52053, \"job_id\": \"AJ_tyGRpFhYJUAR\"}\n\n```",
      "state": "closed",
      "author": "longwQaQ",
      "author_type": "User",
      "created_at": "2025-02-18T16:23:57Z",
      "updated_at": "2025-03-24T06:36:00Z",
      "closed_at": "2025-03-24T06:36:00Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1514/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1514",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1514",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:00.327881",
      "comments": [
        {
          "author": "akkawell",
          "body": "I encountered the same problem.",
          "created_at": "2025-03-14T08:35:59Z"
        }
      ]
    },
    {
      "issue_number": 1282,
      "title": "How can I handle LLM errors?",
      "body": "## Question\r\nIs it currently possible to provide a custom error handler for LLM requests? \r\n\r\n## Context\r\nI'm building a voice agent (`VoicePipelineAgent`) using the latest version of both `livekit-agents` and `livekit-plugins-azure` and Azure as the only provider for all stages of the pipeline (LLM, TTS and STT).\r\n\r\nFor reference:\r\n\r\n```python\r\nassistant = VoicePipelineAgent(\r\n    vad=ctx.proc.userdata[\"vad\"],\r\n    stt=stt.STT(\r\n        speech_key=settings.AZURE_SPEECH_KEY,\r\n        speech_region=settings.AZURE_SPEECH_REGION,\r\n        language=\"es-ES\",\r\n        languages=[\"es-ES\"]\r\n    ),\r\n    llm=openai.LLM.with_azure(\r\n        model=\"gpt-4o\",\r\n        azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,\r\n        azure_deployment=settings.AZURE_OPENAI_DEPLOYMENT,\r\n        api_version=settings.AZURE_OPENAI_API_VERSION,\r\n        api_key=settings.AZURE_OPENAI_API_KEY,\r\n        temperature=settings.LLM_TEMPERATURE,\r\n    ),\r\n    tts=azure.TTS(\r\n        speech_region=settings.AZURE_SPEECH_REGION,\r\n        voice=\"es-ES-LiaNeural\",\r\n        language=\"es-ES\"\r\n    ),\r\n    min_endpointing_delay=0.7,\r\n    interrupt_speech_duration=1.2,\r\n    max_nested_fnc_calls=3,\r\n    preemptive_synthesis=True,\r\n    chat_ctx=initial_ctx,\r\n    fnc_ctx=AssistantToolContext(ctx, participant)\r\n)\r\n```\r\n\r\n## Problem\r\n\r\nWe rely on the Azure OpenAI Service so all inputs and outputs (to and from the LLM) are heavily moderated and the chance of some random sentence being flagged as inappropriate is always non-zero even if we set the moderation to a minimum.  We suspect the root cause is the poor performance of OpenAI's moderation classifiers in non-english languages, flagging some messages as \"sexual\" or \"self-harm\" in a pretty standard conversation.\r\n\r\nIn practice, requesting a completion with an \"inappropriate\" (again, not inappropriate by any means but flagged as such) word/sentence on it results in a 400 status code, which gets handled by `livekit-agents` on [this line](https://github.com/livekit/agents/blob/c7881f3776faa2dc4cea0bda4fd832173c00ac17/livekit-agents/livekit/agents/llm/llm.py#L146) in the `LLMStream` class. \r\n\r\nFor reference, this is how it looks like in the logs\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \".venv/lib/python3.12/site-packages/livekit/agents/llm/llm.py\", line 149, in _main_task\r\n    return await self._run()\r\n           ^^^^^^^^^^^^^^^^^\r\n  File \".venv/lib/python3.12/site-packages/livekit/plugins/openai/llm.py\", line 767, in _run\r\n    raise APIStatusError(\r\nlivekit.agents._exceptions.APIStatusError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': True, 'severity': 'medium'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\r\nfailed to generate LLM completion, retrying in 5.0s\r\n```\r\n\r\nThis causes a chain of errors (because the same message is being sent over and over again) which ultimately prevent the agent from producing any output and a broken conversation state (because the user expects a response that never arrives and the agent just waits for a new human message because its turn is done).\r\n\r\nAfter some research, it looks like the only error handling is done on the [`_main_task`](https://github.com/livekit/agents/blob/c7881f3776faa2dc4cea0bda4fd832173c00ac17/livekit-agents/livekit/agents/llm/llm.py#L146) method of the `LLMStream` class and it's just a simple retry loop with a delay between attempts.\r\n\r\n\r\n## Proposal\r\n\r\nIf this isn't already implemented, I would like to propose an implementation for a new error handling mechanism. \r\n\r\nIdeally, I would be able to provide a custom handler that gets called whenever the API returns an error. This would be provided as a parameter to the `VoicePipelineAgent` in the same way other callbacks are provided.\r\n\r\n\r\n```python\r\nVoicePipelineAgent(\r\n    on_llm_error=...,\r\n    ...\r\n)\r\n```\r\n\r\nThe provided callback would likely receive the `LLMStream` implementation (for example, the [OpenAI one](https://github.com/livekit/agents/blob/c7881f3776faa2dc4cea0bda4fd832173c00ac17/livekit-plugins/livekit-plugins-openai/livekit/plugins/openai/llm.py#L669) when using OpenAI-compatible services) although I'm not sure if this is the most intuitive interface or how this would work in practice. In any case, the proposed `on_llm_error` callback must be able to determine if the agent makes the same completion request again, changes the message contents or returns a default message (the same way it's currently being done with tools, where a default message can be \"said\" using the `.say()` method).\r\n\r\nIf no `on_llm_error` callback is provided, the current [`_main_task`](https://github.com/livekit/agents/blob/c7881f3776faa2dc4cea0bda4fd832173c00ac17/livekit-agents/livekit/agents/llm/llm.py#L146) can be used instead, making this an opt-in feature\r\n\r\nWhat are your thoughts about this? I can work on this myself if it ends up being useful and once (if) we agree on the best approach",
      "state": "open",
      "author": "rmonvfer",
      "author_type": "User",
      "created_at": "2024-12-23T13:40:20Z",
      "updated_at": "2025-03-24T05:47:20Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1282/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1282",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1282",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:00.629545",
      "comments": [
        {
          "author": "davidzhao",
          "body": "thanks for the detailed post. this makes sense to be able to handle errors like this. \r\n\r\nfrom your handler, what would you like to do with the error? would it have a similar interface to `before_llm_cb` so that we could initiate an alternative completion?\r\n\r\nanother related item: we have a Fallback",
          "created_at": "2024-12-24T19:33:52Z"
        },
        {
          "author": "rmonvfer",
          "body": "Thank you for your quick response! I think the handler should receive the raw `APIError` (as it's key in deciding what to do next) in addition to the `LLM` (instead of the `VoicePipelineAgent` directly) and the `ChatContext` (somewhat similar to `before_llm_cb`)\r\n\r\nAs to what happens inside the call",
          "created_at": "2024-12-26T14:17:57Z"
        },
        {
          "author": "narendra-bluebash",
          "body": "i am able to fix this issue but if this error will come then next predicted will come with same error because it is inside the chat history.\r\n\r\nasync def _predicted_text(agent: VoicePipelineAgent, text: str):\r\n        if isinstance(text, str):\r\n            return text\r\n        try:\r\n            pred",
          "created_at": "2025-01-01T09:55:52Z"
        },
        {
          "author": "rmonvfer",
          "body": "I'm very interested in moving this forward, I understand that you (@davidzhao) might be busy now but would appreciate if you could let me know your thoughts about my previous comment so I can work on a PR.\r\n\r\nOn another note: I haven't been able to find any documentation about the `FallbackAdapter` ",
          "created_at": "2025-01-10T13:03:49Z"
        },
        {
          "author": "narendra-bluebash",
          "body": "can somebody tell me why this error is coming. connection error .",
          "created_at": "2025-01-10T13:14:39Z"
        }
      ]
    },
    {
      "issue_number": 1705,
      "title": "function calling with new openai STT introduces partial or unexpected results",
      "body": "Hello,\nI wrote some comments on it here, but it was already closed so might be missed:\n\nhttps://github.com/livekit/agents/issues/1703\n\nIf use function calling, AssistantFnc and expect some Annotated str to be added into the function call (in this case as spoken code such as P010200 in various ways and tempo) the new openAI STT class seems to produce much worse str params into the function that previous. \nOne would expect the new transcribe  with much less WER on all language to be even better. But even if i use whisper-1 it returns worse results that current with using the whispermodel.\n\nopenai_stt = stt.STT(\n        language=\"sv\",\n         model=\"whisper-1\",\n    )\n\nchanging \n_delta_transcript_interval to some higher value in\nhttps://github.com/livekit/agents/blob/f11d7b34d9c26a2ca8b64049408d7f3df674e653/livekit-plugins/livekit-plugins-openai/livekit/plugins/openai/stt.py\n\nSeems to get a bit better, but it is a hit-miss.",
      "state": "closed",
      "author": "lundin",
      "author_type": "User",
      "created_at": "2025-03-22T12:25:05Z",
      "updated_at": "2025-03-22T20:32:29Z",
      "closed_at": "2025-03-22T20:32:27Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1705/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1705",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1705",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:00.859489",
      "comments": [
        {
          "author": "davidzhao",
          "body": "that's rather unexpected to hear about the result. have you tried testing with the new GPT-4o models? they should produce a higher transcription accuracy compared to whisper.\n\ntwo things here:\n1. you can revert back to the old behavior by constructing the STT with `use_realtime=False`.\n2. `_delta_tr",
          "created_at": "2025-03-22T17:21:02Z"
        },
        {
          "author": "lundin",
          "body": "Thanks a lot @davidzhao i think i feel same level of correctnes now again with \"gpt-4o-transcribe\" and use_realtime=False :)",
          "created_at": "2025-03-22T20:32:27Z"
        }
      ]
    },
    {
      "issue_number": 1073,
      "title": "OpenAI S2S Error: Your session hit the maximum duration of 15 minutes.",
      "body": "I'm looking to run sessions in the 30+ minutes range and need to handle disconnects more gracefully, especially a timeout where it is inevitable at the 15 minute mark.\r\n\r\nWould be great if the SDK could create a new connection, pass the messages across (assuming they fit in the context window) and restart the conversation seamlessly.\r\n\r\nHere's the error log I received:\r\n\r\n```\r\n{\"message\": \"OpenAI S2S error {'type': 'error', 'event_id': 'event_ASrZ7rjANnmB9VU5pR7YR', 'error': {'type': 'invalid_request_error', 'code': 'session_expired', 'message': 'Your session hit the maximum duration of 15 minutes.', 'param': None, 'event_id': None}}\", \"level\": \"ERROR\", \"name\": \"livekit.plugins.openai.realtime\", \"session_id\": \"sess_ASrKbnhOx1ypg69LBJTRo\", \"pid\": 10, \"job_id\": \"AJ_KdcwoYrsmwFA\", \"timestamp\": \"2024-11-12T20:14:13.590702+00:00\"}\r\n{\"message\": \"Error in _recv_task\\nTraceback (most recent call last):\\n  File \\\"/home/appuser/.local/lib/python3.11/site-packages/livekit/agents/utils/log.py\\\", line 16, in async_fn_logs\\n    return await fn(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/home/appuser/.local/lib/python3.11/site-packages/livekit/plugins/openai/realtime/realtime_model.py\\\", line 835, in _recv_task\\n    raise Exception(\\\"OpenAI S2S connection closed unexpectedly\\\")\\nException: OpenAI S2S connection closed unexpectedly\", \"level\": \"ERROR\", \"name\": \"livekit.plugins.openai.realtime\", \"pid\": 10, \"job_id\": \"AJ_KdcwoYrsmwFA\", \"timestamp\": \"2024-11-12T20:14:13.600141+00:00\"}\r\n{\"message\": \"Error in _main_task\\nTraceback (most recent call last):\\n  File \\\"/home/appuser/.local/lib/python3.11/site-packages/livekit/agents/utils/log.py\\\", line 16, in async_fn_logs\\n    return await fn(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/home/appuser/.local/lib/python3.11/site-packages/livekit/plugins/openai/realtime/realtime_model.py\\\", line 902, in _main_task\\n    await asyncio.gather(*tasks)\\n  File \\\"/home/appuser/.local/lib/python3.11/site-packages/livekit/agents/utils/log.py\\\", line 16, in async_fn_logs\\n    return await fn(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/home/appuser/.local/lib/python3.11/site-packages/livekit/plugins/openai/realtime/realtime_model.py\\\", line 835, in _recv_task\\n    raise Exception(\\\"OpenAI S2S connection closed unexpectedly\\\")\\nException: OpenAI S2S connection closed unexpectedly\", \"level\": \"ERROR\", \"name\": \"livekit.plugins.openai.realtime\", \"pid\": 10, \"job_id\": \"AJ_KdcwoYrsmwFA\", \"timestamp\": \"2024-11-12T20:14:13.648497+00:00\"}\r\n```",
      "state": "open",
      "author": "ramikalai",
      "author_type": "User",
      "created_at": "2024-11-12T20:21:12Z",
      "updated_at": "2025-03-21T03:52:25Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1073/reactions",
        "total_count": 3,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 3,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1073",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1073",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:01.063860",
      "comments": [
        {
          "author": "cuongpham-1001",
          "body": "I'm migrating from nodejs to python. Look like this issue only happen on python sdk",
          "created_at": "2025-02-12T06:05:47Z"
        },
        {
          "author": "keshav-patil-preplaced",
          "body": "Do we have a fix for this? This is happening very frequesntly? Almost 60% of the time for me.",
          "created_at": "2025-03-21T03:52:24Z"
        }
      ]
    },
    {
      "issue_number": 1661,
      "title": "Bot is speaking and listening at the same time? user cannot interrupt bot, but bot should not ignore user",
      "body": "I want bot always listen to user's voice regardless of who is speaking. I'm using `VoicePipelineAgent` \n\nif I set `allow_interruptions=False`, Bot won't listen any more once user has finished the sentence. \n\nIf I set `allow_interruptions=True`, Bot will stop talking when user starts speaking while bot is also speaking.\n\nI don't want user to be able to interrupt bot, but bot should not ignore user when bot and user are both speaking. User's speech can be appended in the history. This is the behaviour of openai's read-time API when setting interruptions to False.\n\nHow do I achieve this with `VoicePipelineAgent` ?\n\n<!--\nHello! Thanks for taking the time to ask a question.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already asked this question.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n\nFeel free to join us in the #agents channel on our Slack, and ask your question\nthere to get quicker help from us and the community:\n\nhttps://livekit.io/join-slack\n-->\n",
      "state": "open",
      "author": "stevemao",
      "author_type": "User",
      "created_at": "2025-03-16T05:33:46Z",
      "updated_at": "2025-03-18T21:26:56Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1661/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1661",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1661",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:03.132875",
      "comments": [
        {
          "author": "stevemao",
          "body": "This should be a bug. The behaviour is not aligned with most real-time API models.",
          "created_at": "2025-03-18T09:55:30Z"
        },
        {
          "author": "longcw",
          "body": "When it's server-side VAD for the realtime API, `allow_interruptions=False` will only disable the interruption for the speech but actually on the server side it will always listen to the user speech and create new responses that queued after the old agent speech.\n\nI think this is not an expected beh",
          "created_at": "2025-03-18T09:59:45Z"
        },
        {
          "author": "stevemao",
          "body": "@longcw I'm using `VoicePipelineAgent`, not OpenAI realtime API. This bug happens when using `VoicePipelineAgent`.",
          "created_at": "2025-03-18T10:36:34Z"
        },
        {
          "author": "longcw",
          "body": "If it's the `VoicePipelineAgent` I don't think it's a bug, we actually intended to ignore the user transcription during agent is speaking and not interruptible in https://github.com/livekit/agents/blob/main/livekit-agents/livekit/agents/pipeline/pipeline_agent.py#L1166\n\nYou should be able to achieve",
          "created_at": "2025-03-18T10:43:57Z"
        },
        {
          "author": "stevemao",
          "body": "> otherwise there is a problem: should we trigger a reply for the user transcription during the agent speaking?\n\nWhy not? I don't see a reason not to do that. \n\n",
          "created_at": "2025-03-18T21:26:53Z"
        }
      ]
    },
    {
      "issue_number": 1424,
      "title": "Extending `VoicePipelineAgent` with a generative video avatar (we have the model, we need to figure out how to plug it in)",
      "body": "Dear Livekit team,\n\nmy company has a it's own real-time video avatar model and would like to use the abstraction of `VoicePipelineAgent` to run it with different LLMs and your implementation of function calls. (the current demo on your repo only shows how to send video directly to room, not how to use an agent that produces video)\n\nA natural place to plug something like this in would be to extend the `tts` component with video-frame generation or subclass `VoicePipelineAgent` so that it requires an additional `avatar`  service that is fed with the chunks produced by `tts`. Alternatively the `tts` service would be replaced with `avatar` service that produces both audio and video.\n\nWould you be willing to provide an example/stub that does that or guide me in how to best implement this?\n\n \n",
      "state": "open",
      "author": "jmizgajski",
      "author_type": "User",
      "created_at": "2025-01-29T11:03:19Z",
      "updated_at": "2025-03-18T20:07:55Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 18,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1424/reactions",
        "total_count": 4,
        "+1": 3,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 1,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1424",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1424",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:03.334895",
      "comments": [
        {
          "author": "MikeKras",
          "body": "+1 - would be helpful to know this",
          "created_at": "2025-01-29T11:49:35Z"
        },
        {
          "author": "Maelstro",
          "body": "+1, video streaming capabilities for agent are much needed",
          "created_at": "2025-01-29T12:11:56Z"
        },
        {
          "author": "davidzhao",
          "body": "we'll be sharing an integration guide on this very soon",
          "created_at": "2025-01-29T20:54:57Z"
        },
        {
          "author": "jmizgajski",
          "body": "Really glad to hear that!\n\n@davidzhao can you provide a ballpark estimate of how soon is `very soon`? days? weeks? months? ",
          "created_at": "2025-01-29T22:34:36Z"
        },
        {
          "author": "davidzhao",
          "body": "within a week :)",
          "created_at": "2025-01-30T00:23:19Z"
        }
      ]
    },
    {
      "issue_number": 1662,
      "title": "I have 2 agents in agent.py, when a agent is speaking, how do I tell which one is speaking on the frontend?",
      "body": "\nI have 2 agents like this\n\n```python\ncaller_agent = VoicePipelineAgent(...)\nrecipient_agent = VoicePipelineAgent(...)\n\ncaller_agent.start(ctx.room, caller)\nrecipient_agent.start(ctx.room, recipient)\n```\n\nboth `caller_agent` and `recipient_agent` might share context so I cannot invite 2 agent.py.\n\nWhen any agent is speaking, it shows the same identity on the frontend. How do I tell which one is actually speaking?\n\n<!--\nHello! Thanks for taking the time to ask a question.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already asked this question.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n\nFeel free to join us in the #agents channel on our Slack, and ask your question\nthere to get quicker help from us and the community:\n\nhttps://livekit.io/join-slack\n-->\n",
      "state": "closed",
      "author": "stevemao",
      "author_type": "User",
      "created_at": "2025-03-16T06:38:04Z",
      "updated_at": "2025-03-18T10:43:51Z",
      "closed_at": "2025-03-17T15:20:18Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1662/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1662",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1662",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:03.603688",
      "comments": [
        {
          "author": "davidzhao",
          "body": "you'd want to create a new Room object and connecting it to it directly, instead of trying to reuse the same connection.\n\na new Room objet will allow you to connect to it again, as the second agent.",
          "created_at": "2025-03-17T15:20:18Z"
        },
        {
          "author": "stevemao",
          "body": "@davidzhao how do these 2 rooms share the same state (context)?",
          "created_at": "2025-03-17T23:11:26Z"
        },
        {
          "author": "stevemao",
          "body": "And also both users need to hear both agents",
          "created_at": "2025-03-18T00:38:10Z"
        },
        {
          "author": "davidzhao",
          "body": "make sure the second agent also joins the same room..\n\nthough please be warned, while multi-user interactions are possible, we have yet to optimize the framework for that use case. You may end up having to build a few more pieces on your own in order to achieve the right experience.",
          "created_at": "2025-03-18T06:17:04Z"
        },
        {
          "author": "stevemao",
          "body": "Also a new room will double the cost for us.",
          "created_at": "2025-03-18T10:43:50Z"
        }
      ]
    },
    {
      "issue_number": 1597,
      "title": "What is the right way to retrieve users data before function call?",
      "body": "Hi. I am new to Livekit agents.\n\nI want to query my database for users information before calling a function.\n\nFor example:\n- For weather function from the example, i first want to check in the database if I already have the users location stored before asking them for their location to get the weather for. \n\nHow can I achieve this?\n\nThe flow should be--\n- User asks for weather.\n- We first check if we have the users location stored in the database.\n -- If yes, we pass the location to the weather function without asking user for their location.\n -- If no, we ask the user for their location and then pass the location to the weather function.\n\nI tried passing in the entire conversation history to the chat context, and it cant pick the references of location from the chat history either.\n\n\n\n\n",
      "state": "open",
      "author": "thebishalniroula",
      "author_type": "User",
      "created_at": "2025-03-04T19:08:29Z",
      "updated_at": "2025-03-17T06:53:31Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1597/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1597",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1597",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:03.859728",
      "comments": [
        {
          "author": "longcw",
          "body": "you can just trigger a function call for any ask for weather, and the location is an optional arg of the function. If no location provided, query the database in the function call.",
          "created_at": "2025-03-05T01:38:10Z"
        },
        {
          "author": "elio1fiore",
          "body": "@longcw  I think the focus of the question is:\n\n- can the agent talk to the user while performing the function?",
          "created_at": "2025-03-16T22:08:21Z"
        },
        {
          "author": "longcw",
          "body": "Yes, here is an example https://github.com/livekit/agents/blob/main/examples/voice-pipeline-agent/function_calling_weather.py#L50-L53\n\n",
          "created_at": "2025-03-17T06:53:30Z"
        }
      ]
    },
    {
      "issue_number": 1650,
      "title": "LiveKit 1.0 OpenAI Realtime Session Configuration",
      "body": "When using LiveKit 1.0, there is an issue with `SessionUpdateEvent` to configure the `RealtimeModel`. Please refer to [this](https://github.com/openai/openai-python/issues/2199) issue on the `openai` repo. This is more of an OpenAI issue, but mentioning here for visibility.",
      "state": "open",
      "author": "anishnag",
      "author_type": "User",
      "created_at": "2025-03-13T23:09:02Z",
      "updated_at": "2025-03-13T23:22:21Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1650/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1650",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1650",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:04.124164",
      "comments": []
    },
    {
      "issue_number": 1430,
      "title": "Enable `language` Parameter in `input_audio_transcription` for `RealtimeModel`",
      "body": "### Background\n- The `RealtimeModel` includes an `input_audio_transcription` option.\n  - https://github.com/livekit/agents/blob/ab37531589eaed6c645f719988cf7c871056dc6c/livekit-plugins/livekit-plugins-openai/livekit/plugins/openai/realtime/realtime_model.py#L214\n- Currently, this option supports only the model parameter.\n  - https://github.com/livekit/agents/blob/ab37531589eaed6c645f719988cf7c871056dc6c/livekit-plugins/livekit-plugins-openai/livekit/plugins/openai/realtime/realtime_model.py#L148-L150\n- According to OpenAI’s documentation, a language parameter can be specified to enhance transcription accuracy.\n  - https://platform.openai.com/docs/api-reference/realtime-sessions/create#realtime-sessions-create-input_audio_transcription\n\n### Questions\n1.\tLanguage Specification:\n\t- Is it possible to specify the language parameter for the RealtimeModel’s input_audio_transcription option currently?\n2.\tFuture Enhancements:\n\t- If the language parameter is not supported at the moment, are there any plans to update the InputTranscriptionOptions to include this parameter in future releases?\n\n\nThank you for considering this request. I look forward to your response and any updates regarding this feature.",
      "state": "closed",
      "author": "kan-bayashi",
      "author_type": "User",
      "created_at": "2025-01-30T01:23:48Z",
      "updated_at": "2025-03-13T14:54:59Z",
      "closed_at": "2025-03-13T14:54:59Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1430/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1430",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1430",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:04.124184",
      "comments": [
        {
          "author": "davidzhao",
          "body": "we would be glad to open this up. are you interested in opening a PR by any chance?",
          "created_at": "2025-01-30T22:02:00Z"
        },
        {
          "author": "kan-bayashi",
          "body": "Thank you for replying. Either way is fine :)",
          "created_at": "2025-01-31T00:45:30Z"
        }
      ]
    },
    {
      "issue_number": 1646,
      "title": "add ChatTTS、CosyVoice support for streaming TTS",
      "body": "Hi,\n\nThis is such a great work! Thanks.\n\nHere want to check any plan to support ChatTTS、CosyVoice support for streaming TTS?",
      "state": "open",
      "author": "toughhou",
      "author_type": "User",
      "created_at": "2025-03-13T11:24:25Z",
      "updated_at": "2025-03-13T11:24:25Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1646/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1646",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1646",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:04.369132",
      "comments": []
    },
    {
      "issue_number": 1466,
      "title": "Gemini2.0 Example  METHOD_BIDI_GENERATE_CONT error, Can't work with model gemini-2.0-flash-001",
      "body": "Example Code URL:\nhttps://github.com/livekit/agents/blob/main/examples/multimodal-agent/gemini_agent.py\n\nI tried google-genai==1.0.0 and google-genai==0.5.0, Same Error\n\nError Infomation:\n\nConnected to pydev debugger (build 241.18968.29)\n2025-02-08 13:37:32,609 - DEV  livekit.agents - Watching /Users/admin/git/livekitagents/examples/multimodal-agent \n2025-02-08 13:37:34,601 - DEBUG asyncio - Using selector: KqueueSelector \n2025-02-08 13:37:34,629 - INFO livekit.agents - starting worker {\"version\": \"0.12.11\", \"rtc-version\": \"0.18.3\"}\n2025-02-08 13:37:34,666 - INFO livekit.agents - registered worker {\"id\": \"AW_7amqZ9sA8SxX\", \"region\": \"\", \"protocol\": 15, \"node_id\": \"ND_wXBnigSZ9yz6\"}\n2025-02-08 13:37:41,203 - INFO livekit.agents - received job request {\"job_id\": \"AJ_YFzLof7c3HAJ\", \"dispatch_id\": \"AD_qDx4w5m7BxoT\", \"room_name\": \"my-room\", \"agent_name\": \"\", \"resuming\": false}\n2025-02-08 13:37:44,028 - INFO livekit.agents - initializing job process {\"pid\": 26371}\n2025-02-08 13:37:44,029 - INFO livekit.agents - job process initialized {\"pid\": 26371}\n2025-02-08 13:37:44,029 - DEBUG asyncio - Using selector: KqueueSelector {\"pid\": 26371}\n2025-02-08 13:37:44,032 - INFO my-worker - starting entrypoint {\"pid\": 26371, \"job_id\": \"AJ_YFzLof7c3HAJ\"}\n2025-02-08 13:37:44,033 - INFO livekit - livekit_ffi::server:133:livekit_ffi::server - initializing ffi server v0.12.3 {\"pid\": 26371, \"job_id\": \"AJ_YFzLof7c3HAJ\"}\n2025-02-08 13:37:44,033 - INFO livekit - livekit_ffi::cabi:36:livekit_ffi::cabi - initializing ffi server v0.12.3 {\"pid\": 26371, \"job_id\": \"AJ_YFzLof7c3HAJ\"}\n2025-02-08 13:37:44,035 - INFO livekit - livekit_api::signal_client::signal_stream:96:livekit_api::signal_client::signal_stream - connecting to ws://127.0.0.1:7880/rtc?sdk=python&protocol=15&auto_subscribe=0&adaptive_stream=0&version=0.18.3&access_token=... {\"pid\": 26371, \"job_id\": \"AJ_YFzLof7c3HAJ\"}\n2025-02-08 13:37:44,052 - DEBUG livekit - tungstenite::handshake::client:95:tungstenite::handshake::client - Client handshake done. {\"pid\": 26371, \"job_id\": \"AJ_YFzLof7c3HAJ\"}\n2025-02-08 13:37:44,168 - INFO livekit.agents - Session initialized with chat context {\"pid\": 26371, \"job_id\": \"AJ_YFzLof7c3HAJ\"}\n2025-02-08 13:37:45,430 - ERROR livekit.plugins.google - Error in _main_task\nTraceback (most recent call last):\n  File \"/Users/admin/git/livekitagents/livekit-agents/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/admin/git/livekitagents/livekit-plugins/livekit-plugins-google/build/__editable__.livekit_plugins_google-0.10.2-py3-none-any/livekit/plugins/google/beta/realtime/transcriber.py\", line 160, in _main_task\n    async with self._client.aio.live.connect(\n  File \"/Users/admin/miniforge3/envs/pipecat/lib/python3.11/contextlib.py\", line 210, in __aenter__\n    return await anext(self.gen)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/admin/miniforge3/envs/pipecat/lib/python3.11/site-packages/google/genai/live.py\", line 690, in connect\n    logging.info(await ws.recv(decode=False))\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/admin/miniforge3/envs/pipecat/lib/python3.11/site-packages/websockets/asyncio/connection.py\", line 279, in recv\n    raise self.protocol.close_exc from self.recv_exc\nwebsockets.exceptions.ConnectionClosedError: received 1011 (internal error) Request trace id: 8c5e6626c343b97d, [ORIGINAL ERROR] generic::internal: No route found for method METHOD_BIDI_GENERATE_CONT; then sent 1011 (internal error) Request trace id: 8c5e6626c343b97d, [ORIGINAL ERROR] generic::internal: No route found for method METHOD_BIDI_GENERATE_CONT {\"pid\": 26371, \"job_id\": \"AJ_YFzLof7c3HAJ\"}\n2025-02-08 13:37:45,808 - ERROR livekit.plugins.google - Error in _main_task\nTraceback (most recent call last):\n  File \"/Users/admin/git/livekitagents/livekit-agents/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/admin/git/livekitagents/livekit-plugins/livekit-plugins-google/build/__editable__.livekit_plugins_google-0.10.2-py3-none-any/livekit/plugins/google/beta/realtime/realtime_api.py\", line 490, in _main_task\n    async with self._client.aio.live.connect(\n  File \"/Users/admin/miniforge3/envs/pipecat/lib/python3.11/contextlib.py\", line 210, in __aenter__\n    return await anext(self.gen)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/admin/miniforge3/envs/pipecat/lib/python3.11/site-packages/google/genai/live.py\", line 690, in connect\n    logging.info(await ws.recv(decode=False))\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/admin/miniforge3/envs/pipecat/lib/python3.11/site-packages/websockets/asyncio/connection.py\", line 279, in recv\n    raise self.protocol.close_exc from self.recv_exc\nwebsockets.exceptions.ConnectionClosedError: received 1011 (internal error) Request trace id: 9d3e30f588bb4eab, [ORIGINAL ERROR] generic::internal: No route found for method METHOD_BIDI_GENERATE_CONT; then sent 1011 (internal error) Request trace id: 9d3e30f588bb4eab, [ORIGINAL ERROR] generic::internal: No route found for method METHOD_BIDI_GENERATE_CONT {\"pid\": 26371, \"job_id\": \"AJ_YFzLof7c3HAJ\"}\n",
      "state": "closed",
      "author": "johnson7788",
      "author_type": "User",
      "created_at": "2025-02-08T05:38:49Z",
      "updated_at": "2025-03-13T07:14:47Z",
      "closed_at": "2025-02-14T08:50:23Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1466/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1466",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1466",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:04.369153",
      "comments": [
        {
          "author": "jayeshp19",
          "body": "Hi @johnson7788 Thanks for reporting this, Is there a way to reproduce this? ",
          "created_at": "2025-02-08T11:39:18Z"
        },
        {
          "author": "johnson7788",
          "body": "@jayeshp19 \nHow to Reproduce: \n- Step1: git clone https://github.com/livekit/agents\n- Step2: pip install livekit-agents -U\n- Step3: pip install -U livekit-plugins-google\n- Step4: cd agents/examples/multimodal-agent and create .env file\n```\nLIVEKIT_API_KEY=devkey\nLIVEKIT_API_SECRET=secret\nLIVEKIT_URL",
          "created_at": "2025-02-10T07:48:14Z"
        },
        {
          "author": "johnson7788",
          "body": "I test my google genai code, genai package work well.\n```\nimport asyncio\nfrom google import genai\nfrom google.genai import types\nclient = genai.Client(api_key='xxxxxx',\n                      http_options={'api_version': 'v1alpha'})\nasync def generate_text(prompt, client):\n    response = await client",
          "created_at": "2025-02-10T08:02:50Z"
        },
        {
          "author": "johnson7788",
          "body": "@jayeshp19  I found the reason, it is model, When i Change model to gemini-2.0-flash-exp, it works, When use the model gemini-2.0-flash-001, error again.\n\nmodel = google.beta.realtime.RealtimeModel(\n            model=\"gemini-2.0-flash-exp\",\n            voice=\"Puck\",\n            temperature=0.8,\n    ",
          "created_at": "2025-02-11T03:05:46Z"
        },
        {
          "author": "johnson7788",
          "body": "@typester @noahlt @nfma I think this is a Bug, can't work with gemini-2.0-flash-001,  work with gemini-2.0-flash-exp",
          "created_at": "2025-02-11T03:08:21Z"
        }
      ]
    },
    {
      "issue_number": 1632,
      "title": "Code breaks on Livekit-plugins-cartesia version 0.4.9 or later",
      "body": "```\nTraceback (most recent call last):\n  File \"/Work/agents/livekit_agent/main.py\", line 133, in entrypoint\n    tts=cartesia.TTS(\n        ^^^^^^^^^^^^^\n  File \"/Work/.venv/lib/python3.11/site-packages/livekit/plugins/cartesia/tts.py\"\n, line 127, in __init__\n    self._pool = utils.ConnectionPool[aiohttp.ClientWebSocketResponse](\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/anonymous/.local/share/uv/python/cpython-3.11.10-macos-aarch64-none/lib/python3.11/typing.py\", line 13\n37, in __call__\n    result = self.__origin__(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: ConnectionPool.__init__() got an unexpected keyword argument 'mark_refreshed_on_get' {\"pid\": 36730, \"j\nob_id\": \"AJ_w6LBAV6cJ5hZ\"}\n```\nAfter upgrading the plugins to versions 0.4.9 and 0.4.10 (which support Sonic-2), I encountered the above errors when making a SIP phone call.",
      "state": "closed",
      "author": "shi-da-pax",
      "author_type": "User",
      "created_at": "2025-03-11T21:06:20Z",
      "updated_at": "2025-03-12T00:20:50Z",
      "closed_at": "2025-03-12T00:20:50Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1632/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1632",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1632",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:04.587939",
      "comments": [
        {
          "author": "davidzhao",
          "body": "sorry, you'd need to bump the livekit-agent dependency to the latest too: `0.12.17`. this is a new function that was introduced",
          "created_at": "2025-03-12T00:20:06Z"
        }
      ]
    },
    {
      "issue_number": 1625,
      "title": "Returning False to before_llm_cb() does not reset internal transcript buffer",
      "body": "## Title: VoicePipelineAgent retains and concatenates transcripts across turns even when returning False from before_llm_cb\n\n### Description\nWhen implementing a voice assistant using `VoicePipelineAgent`, I've discovered that the agent's speech recognition system concatenates user utterances across multiple turns, even when explicitly returning `False` from `before_llm_cb`. This behavior makes it impossible to handle each utterance independently when building a state machine or similar conversation flow manager.\n\n### Observed Behavior\n1. First turn:\n   - User speaks: \"Apple.\"\n   - `before_llm_cb` receives: \"Apple.\"\n   - We return `False` from `before_llm_cb`\n2. Second turn:\n   - User speaks: \"Barry.\"\n   - `before_llm_cb` receives: \"Apple. Barry.\"\n   - We return `False` from `before_llm_cb`\n3. Third turn:\n   - User speaks: \"Cherry.\"\n   - `before_llm_cb` receives: \"Apple. Barry. Cherry.\"\n   - We return `False` from `before_llm_cb`\n\n### Expected Behavior\nAccording to the documentation, returning `False` from `before_llm_cb` should \"cancel the synthesis of the reply\" and presumably reset the speech processing pipeline. Each turn should only contain the current user utterance:\n- First turn: \"Apple.\"\n- Second turn: \"Barry.\"\n- Third turn: \"Cherry.\"\n\n### Investigation Findings\nLooking at the VoicePipelineAgent implementation, the issue appears to be in the internal `_transcribed_text` buffer which accumulates transcripts over time but is never reset when `before_llm_cb` returns `False`.\n\nIn `pipeline_agent.py`, the `_on_final_transcript` method concatenates new transcripts to this buffer:\n```python\nself._transcribed_text += (\" \" if self._transcribed_text else \"\") + new_transcript\n```\n\nHowever, when `before_llm_cb` returns `False`, this buffer is never cleared, causing all future transcripts to include previous utterances.\n\n### Reproduction Steps\n1. Create a minimal VoicePipelineAgent implementation\n2. Add a `before_llm_cb` that logs the received user message and returns `False`\n3. Have a user make multiple short, separate utterances\n4. Observe the concatenation in the logs\n\n### Workarounds Attempted\n1. Clearing the agent's chat context after each turn\n2. Setting `chat_ctx.messages[-1].content = \"\"` in `before_llm_cb`\n3. Popping the last message with `chat_ctx.messages.pop()`\n4. Maintaining a separate conversation history\n5. Explicitly returning `False` from `before_llm_cb` after each user utterance\n\nNone of these approaches prevent the concatenation.\n\n### Current Workaround\nCurrently, the only workaround is to manually reset the private attributes at the end of the `before_llm_cb` function:\n```\n```python\nasync def before_llm_cb(agent, chat_ctx):\n    # Process message...\n    \n    # Reset the internal transcript buffer\n    agent._transcribed_text = \"\"\n    agent._transcribed_interim_text = \"\"\n    \n    return False\n```\n```\n\nThis works but relies on internal implementation details that could change.\n\n### Proposed Solution\nWhen `before_llm_cb` returns `False`, VoicePipelineAgent should reset its internal transcript buffers (`_transcribed_text` and `_transcribed_interim_text`) to ensure the next turn starts fresh.\n\n### Technical Details\n- **LiveKit Version**: 0.12.8\n- **RTC Version**: 0.19.1\n- **STT Component**: Deepgram STT (nova-3-general)",
      "state": "open",
      "author": "AIGameBoy",
      "author_type": "User",
      "created_at": "2025-03-10T20:50:37Z",
      "updated_at": "2025-03-10T20:50:37Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1625/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1625",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1625",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:04.799402",
      "comments": []
    },
    {
      "issue_number": 1599,
      "title": "tool calling with aws nova models in bedrock issue",
      "body": "I noticed an issue when i tried tool calling with aws nova models for voice pipeline agent it returns the audio response with <thinking> tags. Works fine with claude models tho\n",
      "state": "open",
      "author": "kailashsp",
      "author_type": "User",
      "created_at": "2025-03-05T04:21:13Z",
      "updated_at": "2025-03-10T12:34:20Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1599/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "jayeshp19"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1599",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1599",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:04.799421",
      "comments": [
        {
          "author": "kailashsp",
          "body": "@jayeshp19 @davidzhao turns out for nova models when we call tools it always returns with < thinking > tags https://docs.aws.amazon.com/nova/latest/userguide/prompting-tool-troubleshooting.html\nIs there any way to remove it before tts is done?",
          "created_at": "2025-03-05T10:33:49Z"
        },
        {
          "author": "davidzhao",
          "body": "we are thinking about how to handle this in a more general way. but for now, you can add a `before_tts_cb` callback and then strip the tags there.. it's a bit tricky given the streaming nature of that callback",
          "created_at": "2025-03-08T06:38:54Z"
        },
        {
          "author": "kailashsp",
          "body": "> we are thinking about how to handle this in a more general way. but for now, you can add a `before_tts_cb` callback and then strip the tags there.. it's a bit tricky given the streaming nature of that callback\n\nI tried with the latest changes that @jayeshp19 made it seems to have resolved the issu",
          "created_at": "2025-03-10T12:34:19Z"
        }
      ]
    },
    {
      "issue_number": 1328,
      "title": "Issue with Frequent Timeouts After Upgrading LiveKit Agent and Plugins",
      "body": "Hello everyone,\r\n\r\nI hope you're doing well. I recently upgraded the LiveKit agent and its dependent plugins to their latest versions (I was using an older version installed around October). However, after the update, I've been experiencing frequent timeouts when attempting to request the OpenAI LLM. This issue was not present when I was using the older version of the LiveKit agent and the OpenAI plugin.\r\n\r\nHere are the details of my situation:\r\n\r\nPrevious Version: I was using an older version of LiveKit agent and OpenAI plugin without any issues.\r\nUpgrade: I upgraded to the latest versions of both the LiveKit agent and its plugins.\r\nObservation: After the upgrade, I started experiencing frequent timeouts when making requests to OpenAI LLM.\r\nRegression Test: I reverted back to the older versions, and the timeouts ceased, which is quite puzzling.\r\nI've tried to troubleshoot the issue by checking the logs and ensuring that my network settings haven't changed, but I haven't been able to pinpoint the cause of the problem. I'm wondering if anyone else has encountered a similar issue or if there are any known incompatibilities with the latest versions that could be causing this.\r\n\r\nI'd appreciate any guidance or insights on how to resolve this issue. If there's any additional information you need from me, please let me know.\r\n\r\nThank you in advance for your help!\r\n\r\n```\r\nWARNING  livekit.agents:llm.py:158 failed to generate LLM completion, retrying in 5.0s\r\nTraceback (most recent call last):\r\n  File \"/data/anaconda3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 101, in map_httpcore_exceptions\r\n    yield\r\n  File \"/data/anaconda3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 394, in handle_async_request\r\n    resp = await self._pool.handle_async_request(req)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/anaconda3/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\r\n    raise exc from None\r\n  File \"/data/anaconda3/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\r\n    response = await connection.handle_async_request(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/anaconda3/lib/python3.12/site-packages/httpcore/_async/connection.py\", line 103, in handle_async_request\r\n    return await self._connection.handle_async_request(request)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/anaconda3/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 136, in handle_async_request\r\n    raise exc\r\n  File \"/data/anaconda3/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 106, in handle_async_request\r\n    ) = await self._receive_response_headers(**kwargs)\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/anaconda3/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 177, in _receive_response_headers\r\n    event = await self._receive_event(timeout=timeout)\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/anaconda3/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 217, in _receive_event\r\n    data = await self._network_stream.read(\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/anaconda3/lib/python3.12/site-packages/httpcore/_backends/anyio.py\", line 32, in read\r\n    with map_exceptions(exc_map):\r\n  File \"/data/anaconda3/lib/python3.12/contextlib.py\", line 158, in __exit__\r\n    self.gen.throw(value)\r\n  File \"/data/anaconda3/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\r\n    raise to_exc(exc) from exc\r\nhttpcore.ReadTimeout\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/data/anaconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1576, in _request\r\n    response = await self._client.send(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/anaconda3/lib/python3.12/site-packages/httpx/_client.py\", line 1629, in send\r\n    response = await self._send_handling_auth(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/anaconda3/lib/python3.12/site-packages/httpx/_client.py\", line 1657, in _send_handling_auth\r\n    response = await self._send_handling_redirects(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/anaconda3/lib/python3.12/site-packages/httpx/_client.py\", line 1694, in _send_handling_redirects\r\n    response = await self._send_single_request(request)\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/anaconda3/lib/python3.12/site-packages/httpx/_client.py\", line 1730, in _send_single_request\r\n    response = await transport.handle_async_request(request)\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/anaconda3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 393, in handle_async_request\r\n    with map_httpcore_exceptions():\r\n  File \"/data/anaconda3/lib/python3.12/contextlib.py\", line 158, in __exit__\r\n    self.gen.throw(value)\r\n  File \"/data/anaconda3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 118, in map_httpcore_exceptions\r\n    raise mapped_exc(message) from exc\r\nhttpx.ReadTimeout\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ubuntu/orderbot/livekit/plugins/openai/llm.py\", line 743, in _run\r\n    stream = await self._client.chat.completions.create(\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/anaconda3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1720, in create\r\n    return await self._post(\r\n           ^^^^^^^^^^^^^^^^^\r\n  File \"/data/anaconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1843, in post\r\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/anaconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1537, in request\r\n    return await self._request(\r\n           ^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/anaconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1595, in _request\r\n    raise APITimeoutError(request=request) from err\r\nopenai.APITimeoutError: Request timed out.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ubuntu/orderbot/livekit/agents/llm/llm.py\", line 149, in _main_task\r\n    return await self._run()\r\n           ^^^^^^^^^^^^^^^^^\r\n  File \"/home/ubuntu/orderbot/livekit/plugins/openai/llm.py\", line 776, in _run\r\n    raise APITimeoutError(retryable=retryable)\r\nlivekit.agents._exceptions.APITimeoutError: Request timed out.\r\n```",
      "state": "closed",
      "author": "ericyue",
      "author_type": "User",
      "created_at": "2025-01-02T16:43:34Z",
      "updated_at": "2025-03-10T10:21:14Z",
      "closed_at": "2025-01-09T06:33:19Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1328/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1328",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1328",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:05.025976",
      "comments": [
        {
          "author": "scharalambous3",
          "body": "Also facing the same issue",
          "created_at": "2025-01-07T23:32:58Z"
        },
        {
          "author": "scharalambous3",
          "body": "@ericyue Do you remember what versions of the LiveKit agent and the OpenAI plugin before you upgraded?",
          "created_at": "2025-01-08T21:42:26Z"
        },
        {
          "author": "ericyue",
          "body": "https://github.com/livekit/agents/pull/926 \r\n\r\nthe old version of openai plugins is 30s",
          "created_at": "2025-01-09T06:33:19Z"
        },
        {
          "author": "scharalambous3",
          "body": "@ericyue Why did you close this as completed?",
          "created_at": "2025-01-09T06:40:26Z"
        },
        {
          "author": "ericyue",
          "body": "@scharalambous3    I think the older version set a very long timeout by mistake. you can checkout the pull  926 for detail. The latest version of openai plugins decrease the timeout a lot. So there's more timeout request by using the latest version. ",
          "created_at": "2025-01-09T06:51:31Z"
        }
      ]
    },
    {
      "issue_number": 1610,
      "title": "LiveKit Agent on Google Cloud Run Fails with Initialization Timeout: Container Terminating Prematurely",
      "body": "I've deployed a LiveKit Agent as a containerized service on Google Cloud Run, but I'm experiencing issues where the agent becomes unresponsive and fails to handle client requests. After examining the server logs, I've identified that the agent appears to hang indefinitely. \n\n<img width=\"969\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/f773305b-2958-495c-9b5f-a215ae2a9835\" />\n\nHere is my code:\n\n```\nimport os\nfrom dotenv import load_dotenv\nfrom livekit.agents import AutoSubscribe, JobContext, WorkerOptions, WorkerType, cli, multimodal, JobProcess, pipeline\nfrom livekit.plugins import google\n\nload_dotenv()\n\nLIVEKIT_URL = os.getenv(\"LIVEKIT_URL\")\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\nHEALTHCHECK_PORT = os.getenv(\"HEALTHCHECK_PORT\")\nGOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n\n\nasync def entrypoint(ctx: JobContext):\n    # connect agent\n    await ctx.connect(auto_subscribe=AutoSubscribe.AUDIO_ONLY)\n    print(f\"Agent connected to room: {ctx.room.name}\")\n\n    participant = await ctx.wait_for_participant()\n    print(f\"Participant {participant.name} joined\")\n    voice_actor = 'Aoede'\n    agent = multimodal.MultimodalAgent(\n        model=google.beta.realtime.RealtimeModel(\n            api_key=GOOGLE_API_KEY,\n            voice=voice_actor,\n            temperature=0.8,\n            instructions=participant.attributes[\"system_instruction\"],\n            modalities=[\"AUDIO\"],\n            model=\"gemini-2.0-flash-exp\",\n        ))\n\n    agent.start(ctx.room, participant)\n    print(\"Multimodal agent started and ready for interaction.\")\n\n    # await asyncio.Future()\n\n\nif __name__ == \"__main__\":\n    opts = WorkerOptions(entrypoint_fnc=entrypoint, worker_type=WorkerType.ROOM, port=HEALTHCHECK_PORT)\n    cli.run_app(opts)\n```\n\n",
      "state": "closed",
      "author": "arieefrachman",
      "author_type": "User",
      "created_at": "2025-03-06T08:12:04Z",
      "updated_at": "2025-03-08T08:29:45Z",
      "closed_at": "2025-03-08T08:29:44Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1610/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1610",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1610",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:05.247984",
      "comments": [
        {
          "author": "davidzhao",
          "body": "CloudRun is a bit weird with its initialization timeout. could you try to increase it?",
          "created_at": "2025-03-08T06:39:40Z"
        },
        {
          "author": "arieefrachman",
          "body": "Hi @davidzhao,  I just moved the agent to the k8s cluster and it works. I've been searching and implemented the timeout you suggested, but it still doesn't work.",
          "created_at": "2025-03-08T08:29:44Z"
        }
      ]
    },
    {
      "issue_number": 1564,
      "title": "[dev] user messages missing from chat_ctx",
      "body": "Sorry for opening an issue about the dev branch here. Feel free to close it if it is too noisy.\n\nBackground: I am testing the avatar example so that's why I am on the dev branch.\n\nhttps://github.com/livekit/agents/blob/92f98e7420fddf0d3221da8fb5d901e48a111a2e/livekit-agents/livekit/agents/pipeline/task_activity.py#L568\n\nThe user input is added after the chat ctx copy. From my testing, this would only include the latest user message in the chat_ctx when responding. The simplest way is probably to move the copy after that statement.\n\nThanks for looking into it. I tried to leave a comment on that file, but I am not sure if the message can be delivered properly. cc @theomonnom ",
      "state": "closed",
      "author": "ChenghaoMou",
      "author_type": "User",
      "created_at": "2025-02-27T16:44:38Z",
      "updated_at": "2025-03-07T10:58:52Z",
      "closed_at": "2025-03-07T10:58:51Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1564/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1564",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1564",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:05.447009",
      "comments": [
        {
          "author": "theomonnom",
          "body": "ah right, this is a known issue, I'm going to get it fixed by tomorrow :) ",
          "created_at": "2025-02-27T17:02:26Z"
        },
        {
          "author": "ChenghaoMou",
          "body": "Thank you @theomonnom !",
          "created_at": "2025-03-07T10:58:51Z"
        }
      ]
    },
    {
      "issue_number": 1611,
      "title": "Allow custom logger configuration in livekit.agents.cli.run_app",
      "body": "Currently, run_app calls setup_logging internally, either in development (colored logs) or production (JSON logs). However, this forces a logging configuration on the user, making it difficult to integrate with existing logging setups.\n\nIt would be helpful to have an option to:\n\nDisable the automatic logging setup.\nProvide a custom logging configuration before run_app initializes its own.\nIs there currently a way to override this behavior? If not, would it be possible to introduce a configuration flag or allow users to define their own logger before setup_logging is executed?\n\nThis would make integration with existing logging pipelines much more flexible.\n\nThanks!",
      "state": "open",
      "author": "JCelayaRdz",
      "author_type": "User",
      "created_at": "2025-03-06T15:04:44Z",
      "updated_at": "2025-03-06T15:07:05Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1611/reactions",
        "total_count": 10,
        "+1": 10,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1611",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1611",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:05.659023",
      "comments": []
    },
    {
      "issue_number": 1608,
      "title": "unable to log transcript when agent is interrupted",
      "body": "<!--\nHello! Thanks for taking the time to file a bug report.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already reported this issue.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n-->\n\nI am using `@agent.on(\"agent_speech_committed\")` and `@agent.on(\"user_speech_committed\")` to construct a transcript on my python backend for the multimodal agent using openAI realtime (is there a better way to get the transcript??).\n\nThis approach works quite well, as long as the agent is not interrupted by the user.\n\nIf the agent gets interrupted by the user, I see a log that looks something like this:\n\n```\nDEBUG livekit.agents - committed agent speech {\"agent_transcript\": \"Great! I'll see you outside then. We'll have a...\", \"interrupted\": true, \"pid\": 3797, \"job_id\": \"AJ_ypPdNp6Zt69r\"}\n```\n\nIf `\"interrupted\": \"true\"` is present in the log, i notice that my `@agent.on(\"agent_speech_committed\")` callback DOES NOT pick up the agent speech. \n\nHere is my callback for reference:\n\n```\n@agent.on(\"agent_speech_committed\")\n    def on_agent_speech_committed(msg):\n        log_queue.put_nowait({\"speaker\": \"Agent\", \"utterance\": msg})\n        print(f\"Agent: {msg}\")\n```\n\nWhat is going on here? Is this a bug, or am I missing something. Need help ASAP <3",
      "state": "open",
      "author": "farazmsiddiqi",
      "author_type": "User",
      "created_at": "2025-03-06T06:56:17Z",
      "updated_at": "2025-03-06T09:38:30Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1608/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1608",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1608",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:05.659039",
      "comments": [
        {
          "author": "longcw",
          "body": "There is a `agent_speech_interrupted` event that contains the message. It's basically something like\n```python\n            if interrupted:\n                self.emit(\"agent_speech_interrupted\", msg)\n            else:\n                self.emit(\"agent_speech_committed\", msg)\n```\n\nIf you don't care if i",
          "created_at": "2025-03-06T09:37:14Z"
        }
      ]
    },
    {
      "issue_number": 585,
      "title": "message_received event cannot be triggered. ",
      "body": "message_received event cannot be triggered. \r\n\r\nchat = rtc.ChatManager(ctx.room)\r\n\r\n    async def answer_from_text(txt: str):\r\n        chat_ctx = assistant.chat_ctx.copy()\r\n        chat_ctx.append(role=\"user\", text=txt)\r\n        stream = llm_plugin.chat(chat_ctx=chat_ctx)\r\n        await assistant.say(stream)\r\n\r\n    @chat.on(\"message_received\")\r\n    def on_chat_received(msg: rtc.ChatMessage):\r\n        if msg.message:\r\n            asyncio.create_task(answer_from_text(msg.message))",
      "state": "open",
      "author": "Emotibot5",
      "author_type": "User",
      "created_at": "2024-08-06T04:39:13Z",
      "updated_at": "2025-03-06T07:12:17Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/585/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/585",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/585",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:05.844015",
      "comments": [
        {
          "author": "davidzhao",
          "body": "how are you sending the chat message? the client-side application would need to send it",
          "created_at": "2024-08-06T04:46:08Z"
        },
        {
          "author": "Emotibot5",
          "body": "I am using local stt, llm, and tts, I can talk with the agent.    \r\n\r\n    assistant = VoiceAssistant(\r\n        vad=vad,\r\n        stt=whisper_stt,\r\n        llm=_llm,\r\n        tts=_tts,\r\n        chat_ctx=initial_ctx,\r\n    )\r\n    \r\n    assistant.start(ctx.room)\r\n\r\n    # listen to incoming chat messages",
          "created_at": "2024-08-06T04:52:26Z"
        },
        {
          "author": "Emotibot5",
          "body": "> I am using local stt, llm, and tts, I can talk with the agent.\r\n> \r\n> ```\r\n> assistant = VoiceAssistant(\r\n>     vad=vad,\r\n>     stt=whisper_stt,\r\n>     llm=_llm,\r\n>     tts=_tts,\r\n>     chat_ctx=initial_ctx,\r\n> )\r\n> \r\n> assistant.start(ctx.room)\r\n> \r\n> # listen to incoming chat messages, only requ",
          "created_at": "2024-08-06T04:54:10Z"
        },
        {
          "author": "davidzhao",
          "body": "message_received would not be fired unless you are sending Chat messages from the client. this is expected",
          "created_at": "2024-08-06T04:54:46Z"
        },
        {
          "author": "Emotibot5",
          "body": "> > I am using local stt, llm, and tts, I can talk with the agent.\r\n> > ```\r\n> > assistant = VoiceAssistant(\r\n> >     vad=vad,\r\n> >     stt=whisper_stt,\r\n> >     llm=_llm,\r\n> >     tts=_tts,\r\n> >     chat_ctx=initial_ctx,\r\n> > )\r\n> > \r\n> > assistant.start(ctx.room)\r\n> > \r\n> > # listen to incoming ch",
          "created_at": "2024-08-06T04:55:58Z"
        }
      ]
    },
    {
      "issue_number": 1604,
      "title": "Inconsistent Environment Variable Name Between README and Documentation for ElevenLabs plugin",
      "body": " I noticed a discrepancy in the environment variable name for ElevenLabs plugin between the livekit-plugins-elevenlab README [file](https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-elevenlabs/README.md) and the official [documentation](https://docs.livekit.io/agents/integrations/elevenlabs/#environment-variables) on the livekit website. This could potentially cause confusion for developers trying to set up the project.\n\nCurrent Situation:\n\nREADME: Uses the correct environment variable name, `ELEVEN_API_KEY`\nOfficial Documentation: Contains an incorrect environment variable name `ELEVENLABS_API_KEY`\n\nPlease update the official documentation to match the environment variable name specified in the README ",
      "state": "closed",
      "author": "onur-yildirim-infinitusai",
      "author_type": "User",
      "created_at": "2025-03-05T19:13:15Z",
      "updated_at": "2025-03-05T23:58:46Z",
      "closed_at": "2025-03-05T23:58:46Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1604/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1604",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1604",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:06.108943",
      "comments": []
    },
    {
      "issue_number": 1602,
      "title": "Track Publication Timeout in Certain room.on Callbacks",
      "body": "#### **Description**\nI've encountered a strange issue when trying to publish a video and audio track user the `play_video` function below when inside a `room.on` callback. The function works correctly with the `track_published` and `track_unpublished` event callbacks, but **fails with a timeout** when called from `data_received` or `participant_attributes_changed` events.\n\nThe error I get:\n```\nlivekit.rtc.participant.PublishTrackError: room error engine: internal error: track publication timed out, no response received from the server\n```\nInterestingly, if I **do not publish the audio track**, it works fine in all cases and publishes the video successfuly.\n\n---\n\n#### **Expected Behavior**\nPublishing the video and audio track should work regardless of which event callback triggers `play_video()`.\n\n#### **Actual Behavior**\n- ✅ Works inside `track_published` and `track_unpublished`\n- ❌ Fails inside `data_received` and `participant_attributes_changed`\n- ✅ Works in all cases if the audio track is not published\n\n---\n\n#### **Steps to Reproduce**\n1. Create a function to publish video and audio tracks (see `play_video` below).\n2. Call this function from different `room.on` event callbacks (see _on_track_published implementation as an example).\n3. Observe that it works in some cases but times out in others.\n\n---\n\n#### **Relevant Code**\n##### **Callback Function Example**\n```python\nroom.on(\"track_published\",self._on_track_published)\n\ndef _on_track_published(self, publication: rtc.RemoteTrackPublication, participant: rtc.RemoteParticipant):\n    logger.info(\"Track Published\")\n    asyncio.create_task(self.play_video())\n```\n\n##### **`play_video()` Implementation**\n```python\nasync def play_video(self):\n    try:\n        self._media_streamer = LivekitMediaStreamer(\n            media_file=MEDIA_PATH,\n            resample_sample_rate=22000,\n        )\n        media_info = self._media_streamer.info\n\n        # Create video and audio sources/tracks\n        self._video_source = rtc.VideoSource(\n            width=media_info.video_width,\n            height=media_info.video_height,\n        )\n        logger.info(media_info)\n        self._audio_source = rtc.AudioSource(\n            sample_rate=media_info.audio_sample_rate,\n            num_channels=media_info.audio_channels,\n            queue_size_ms=BUFFER_SIZE_MS,\n        )\n        video_track = rtc.LocalVideoTrack.create_video_track(\"video\", self._video_source)\n        audio_track = rtc.LocalAudioTrack.create_audio_track(\"audio\", self._audio_source)\n\n        # Publish tracks\n        video_options = rtc.TrackPublishOptions(\n            source=rtc.TrackSource.SOURCE_CAMERA,\n            video_encoding=rtc.VideoEncoding(\n                max_framerate=30,\n                max_bitrate=5_000_000,\n            ),\n        )\n        audio_options = rtc.TrackPublishOptions(source=rtc.TrackSource.SOURCE_MICROPHONE)\n\n        await self._job_context.room.local_participant.publish_track(video_track, video_options)\n        await self._job_context.room.local_participant.publish_track(audio_track, audio_options)\n\n        media_info = self._media_streamer.info\n\n        self._av_sync = rtc.AVSynchronizer(\n            audio_source=self._audio_source,\n            video_source=self._video_source,\n            video_fps=media_info.video_fps,\n            video_queue_size_ms=BUFFER_SIZE_MS,\n        )\n\n        self._media_streamer.reset()\n\n        video_stream = self._media_streamer.stream_video()\n        audio_stream = self._media_streamer.stream_audio()\n\n        # Read the head frames and push them at the same time\n        first_video_frame, video_timestamp = await video_stream.__anext__()\n        first_audio_frame, audio_timestamp = await audio_stream.__anext__()\n        logger.info(\n            f\"first video duration: {1 / media_info.video_fps:.3f}s, \"\n            f\"first audio duration: {first_audio_frame.duration:.3f}s\"\n        )\n        await self._av_sync.push(first_video_frame, video_timestamp)\n        await self._av_sync.push(first_audio_frame, audio_timestamp)\n\n        video_task = asyncio.create_task(self._push_frames(video_stream, self._av_sync))\n        audio_task = asyncio.create_task(self._push_frames(audio_stream, self._av_sync))\n\n        log_fps_task = asyncio.create_task(self._log_fps(self._av_sync))\n\n        # Wait for both tasks to complete\n        await asyncio.gather(video_task, audio_task)\n        await self._av_sync.wait_for_playout()\n\n        # Clean up\n        self._av_sync.reset()\n        log_fps_task.cancel()\n        logger.info(\"Playout finished\")\n\n    finally:\n        if self._media_streamer:\n            await self._media_streamer.aclose()\n        if self._av_sync:\n            await self._av_sync.aclose()\n        if self._audio_source:\n            await self._audio_source.aclose()\n        if self._video_source:\n            await self._video_source.aclose()\n```\n\n---\n\n#### **Error Output**\n```\nlivekit.rtc.participant.PublishTrackError: room error engine: internal error: track publication timed out, no response received from the server\n```\n\n[broadcase_video_agent.txt](https://github.com/user-attachments/files/19088600/broadcase_video_agent.txt)\n[livestreamer_implementation.txt](https://github.com/user-attachments/files/19088626/livestreamer_implementation.txt)",
      "state": "open",
      "author": "gigaverse-oz",
      "author_type": "User",
      "created_at": "2025-03-05T12:01:39Z",
      "updated_at": "2025-03-05T12:04:22Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1602/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1602",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1602",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:06.108963",
      "comments": []
    },
    {
      "issue_number": 1601,
      "title": "Unable to Output PNG Images with Same Clarity as Video Frames (Currently Only Getting JPEG)",
      "body": "I want the images to have the same clarity as the video frames, but currently, I can only get them in JPEG format. As we all know, JPEG format involves some compression. Is there a configuration that I missed? If there is a configuration that allows me to get PNG format images, please let me know. Thank you very much.",
      "state": "open",
      "author": "leejiliang",
      "author_type": "User",
      "created_at": "2025-03-05T07:08:25Z",
      "updated_at": "2025-03-05T07:08:25Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1601/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1601",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1601",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:06.108968",
      "comments": []
    },
    {
      "issue_number": 1581,
      "title": "on(\"disconnected\") Event Not Triggering Consistently in Python SDK on Unexpected Process Exits",
      "body": "### Description\nWhile building an application using the LiveKit Agents Python SDK, I noticed that the `on(\"disconnected\")` event wasn’t firing reliably when the process exited unexpectedly. My app depends on this event to send a conversation transcript to a feedback endpoint during cleanup. In cases where the process exit log showed a blank `\"reason\"` field, the event didn’t trigger at all, leaving my cleanup logic stranded. This became a real headache as I couldn’t guarantee the transcript would always be sent.\n\n\n**Steps to Reproduce**:  \n1. Set up a basic agent using the Python SDK with a `JobContext` and a room connection.\n2. Register an `on(\"disconnected\")` handler:\n   ```python\n   @ctx.room.on(\"disconnected\")\n   def on_disconnected(reason: str):\n       print(f\"Disconnected. Reason: {reason}\")\n   ```\n3. Force an abrupt process termination (e.g., `kill -TERM <pid>` or network failure simulation).\n4. Observe logs and handler execution.\n\n**Expected Behavior**:  \nThe `on(\"disconnected\")` event should fire consistently with a meaningful `reason` whenever the room disconnects, even during unexpected process exits, allowing cleanup logic to run.\n\n**Actual Behavior**:  \n- In normal cases (e.g., room closed properly), the event fires with `\"reason\": \"room disconnected\"`.\n- In failing cases (e.g., abrupt termination), the process exits with `\"reason\": \"\"` in the log, and the event does not trigger. Example logs:\n  - Failing: `{\"message\": \"process exiting\", \"reason\": \"\", \"timestamp\": \"2025-02-25T21:29:38.331188+00:00\"}`\n  - Working: `{\"message\": \"process exiting\", \"reason\": \"room disconnected\", \"timestamp\": \"2025-02-25T15:40:25.786824+00:00\"}`\n\n**Workaround**:  \nUsing a `try/finally` block to monitor `ctx.room.connection_state` and force cleanup:\n```python\ntry:\n    while ctx.room.connection_state == rtc.ConnectionState.CONNECTED:\n        await asyncio.sleep(1)\nfinally:\n    await handle_disconnection()\n```\nThis works but bypasses the event-driven design. The LiveKit team suggested “shutdown hooks” as a more reliable alternative, but specific guidance is unclear.\n\n**Proposed Fix**:  \n- Ensure the `on(\"disconnected\")` event is triggered consistently by hooking into process shutdown signals (e.g., SIGTERM) within the SDK.\n- Alternatively, expose a clear shutdown hook API in `JobContext` (e.g., `ctx.on_shutdown(callback)`) that developers can use for cleanup, guaranteed to run on process exit.\n\n**Questions**:  \n1. Is the blank `\"reason\"` a known issue tied to WebRTC connection drops or process termination timing?\n2. Are there existing shutdown hooks in the SDK we should use instead? If so, please document them.\n\n**Impact**:  \nThis affects applications relying on disconnection events for critical cleanup, like sending data to external endpoints. A reliable solution would improve the SDK’s robustness.",
      "state": "open",
      "author": "shwetd19",
      "author_type": "User",
      "created_at": "2025-03-02T05:54:04Z",
      "updated_at": "2025-03-05T05:49:17Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1581/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1581",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1581",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:06.108974",
      "comments": [
        {
          "author": "davidzhao",
          "body": "any reasons the [shutdown hook](https://docs.livekit.io/agents/build/session/#post-processing-and-cleanup) doesn't work for your needs?",
          "created_at": "2025-03-04T19:04:24Z"
        },
        {
          "author": "shwetd19",
          "body": "Thanks for pointing me to the [shutdown hook](https://docs.livekit.io/agents/build/session/#post-processing-and-cleanup)—it does solve the issue for basic cleanup. That said, it’d be great if we could pair it with a fix for the `on('disconnected')` event not triggering consistently in the Python SDK",
          "created_at": "2025-03-05T05:49:16Z"
        }
      ]
    },
    {
      "issue_number": 1518,
      "title": "After Sip Call Hangup [RuntimeError: no running event loop]",
      "body": "#  RuntimeError: no running event loop\n\n```\n2025-02-18 17:04:32,317 - INFO livekit.agents - Pipeline LLM metrics: sequence_id=d42d2773fbd0, ttft=0.38, input_tokens=609, output_tokens=14, tokens_per_second=24.92 {\"pid\": 1182, \"job_id\": \"AJ_Kx8Xy7YKMMW8\"}\n2025-02-18 17:04:32,974 - DEBUG livekit.agents.pipeline - speech playout started {\"speech_id\": \"d42d2773fbd0\", \"pid\": 1182, \"job_id\": \"AJ_Kx8Xy7YKMMW8\"}\n2025-02-18 17:04:33,805 - INFO livekit.agents - Pipeline TTS metrics: sequence_id=d42d2773fbd0, ttfb=0.6398559979999163, audio_duration=2.26 {\"pid\": 1182, \"job_id\": \"AJ_Kx8Xy7YKMMW8\"}\n2025-02-18 17:04:36,413 - INFO livekit.agents - Pipeline TTS metrics: sequence_id=d42d2773fbd0, ttfb=1.9792679519999865, audio_duration=0.48 {\"pid\": 1182, \"job_id\": \"AJ_Kx8Xy7YKMMW8\"}\n2025-02-18 17:04:36,681 - DEBUG livekit.agents.pipeline - speech playout finished {\"speech_id\": \"d42d2773fbd0\", \"interrupted\": false, \"pid\": 1182, \"job_id\": \"AJ_Kx8Xy7YKMMW8\"}\n2025-02-18 17:04:36,681 - DEBUG livekit.agents.pipeline - committed agent speech {\"agent_transcript\": \"Thank you for your time, have a great day. Goodbye!\", \"interrupted\": false, \"speech_id\": \"d42d2773fbd0\", \"pid\": 1182, \"job_id\": \"AJ_Kx8Xy7YKMMW8\"}\n2025-02-18 17:04:55,845 - DEBUG livekit - tungstenite::protocol:666:tungstenite::protocol - Received close frame: Some(CloseFrame { code: Normal, reason: \"\" }) {\"pid\": 1182, \"job_id\": \"AJ_Kx8Xy7YKMMW8\"}\n2025-02-18 17:04:55,846 - DEBUG livekit - tungstenite::protocol:683:tungstenite::protocol - Replying to close with Frame { header: FrameHeader { is_final: true, rsv1: false, rsv2: false, rsv3: false, opcode: Control(Close), mask: None }, payload: [3, 232] } {\"pid\": 1182, \"job_id\": \"AJ_Kx8Xy7YKMMW8\"}\n2025-02-18 17:04:55,848 - INFO livekit.agents - process exiting {\"reason\": \"\", \"pid\": 1182, \"job_id\": \"AJ_Kx8Xy7YKMMW8\"}\n2025-02-18 17:04:55,847 - DEBUG livekit.agents - shutting down job task {\"reason\": \"\", \"user_initiated\": false, \"pid\": 1182, \"job_id\": \"AJ_Kx8Xy7YKMMW8\"}\n2025-02-18 17:04:55,847 - WARNING livekit - livekit::rtc_engine:446:livekit::rtc_engine - received session close: \"signal client closed: \\\"stream closed\\\"\" UnknownReason Resume {\"pid\": 1182, \"job_id\": \"AJ_Kx8Xy7YKMMW8\"}\n2025-02-18 17:04:55,851 - DEBUG livekit.agents - http_session(): closing the httpclient ctx {\"pid\": 1182, \"job_id\": \"AJ_Kx8Xy7YKMMW8\"}\n2025-02-18 17:04:55,851 - DEBUG livekit.agents - http_session(): creating a new httpclient ctx {\"pid\": 1182, \"job_id\": \"AJ_Kx8Xy7YKMMW8\"}\n```\n```\nException ignored in: <coroutine object HumanInput._recognize_task at 0x752785191540>\nTraceback (most recent call last):\n  File \"/home/ubuntu/livekit/env/lib/python3.12/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ubuntu/livekit/env/lib/python3.12/site-packages/livekit/agents/pipeline/human_input.py\", line 152, in _recognize_task\n    await utils.aio.gracefully_cancel(*tasks)\n  File \"/home/ubuntu/livekit/env/lib/python3.12/site-packages/livekit/agents/utils/aio/__init__.py\", line 12, in gracefully_cancel\n    loop = asyncio.get_running_loop()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: no running event loop\nException ignored in: <coroutine object RecognizeStream._main_task at 0x75278517b670>\nTraceback (most recent call last):\n  File \"/home/ubuntu/livekit/env/lib/python3.12/site-packages/livekit/agents/stt/stt.py\", line 219, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/ubuntu/livekit/env/lib/python3.12/site-packages/livekit/agents/stt/stream_adapter.py\", line 126, in _run\n    await utils.aio.gracefully_cancel(*tasks)\n  File \"/home/ubuntu/livekit/env/lib/python3.12/site-packages/livekit/agents/utils/aio/__init__.py\", line 12, in gracefully_cancel\n    loop = asyncio.get_running_loop()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: no running event loop\n```",
      "state": "open",
      "author": "Haroonhsa007",
      "author_type": "User",
      "created_at": "2025-02-18T20:50:20Z",
      "updated_at": "2025-03-04T22:23:41Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1518/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1518",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1518",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:06.385332",
      "comments": [
        {
          "author": "yepher",
          "body": "I think this is a duplicate of this issue: https://github.com/livekit/agents/issues/1527\n",
          "created_at": "2025-02-20T23:44:24Z"
        },
        {
          "author": "Haroonhsa007",
          "body": "ok...",
          "created_at": "2025-03-04T22:23:40Z"
        }
      ]
    },
    {
      "issue_number": 1139,
      "title": "How to Transfer SIP Calls to Another Number in voice-pipeline-agent-python？",
      "body": "Hello,\r\n\r\nI am currently working on a simple demo using voice-pipeline-agent-python and have successfully configured the SIP settings as required. \r\nHowever, I am looking to implement a feature where, after a user dials a number and enters the logic of the VoicePipelineAgent, they can trigger a signal that redirects the call to another number for manual response.\r\n\r\nHere's what I have so far, and I'm wondering how I can proceed to achieve the call transfer functionality:\r\n\r\nThe user dials a number and is connected to the VoicePipelineAgent.\r\n\r\nAt some point during the interaction, the user triggers a specific signal.\r\nUpon receiving this signal, I want the call to be transferred to another predefined number for human manual handling.\r\n\r\nI have reviewed the documentation, but I'm not sure how to implement this feature within the voice-pipeline-agent-python framework. Could someone please guide me on the steps or provide an example of how to achieve this?\r\n\r\nThank you in advance for your help!\r\n\r\n",
      "state": "closed",
      "author": "ericyue",
      "author_type": "User",
      "created_at": "2024-11-27T05:52:19Z",
      "updated_at": "2025-03-04T19:34:55Z",
      "closed_at": "2024-12-23T06:34:17Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1139/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1139",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1139",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:06.593086",
      "comments": [
        {
          "author": "narendra-bluebash",
          "body": "I am also being faced same problem plz solve this as soon as possible",
          "created_at": "2024-12-17T12:12:02Z"
        },
        {
          "author": "davidzhao",
          "body": "Like in the cold transfer docs, you could do the following\r\n\r\n```\r\n# assuming ctx is JobContext, participant is the user (i.e. ctx.wait_for_participant())\r\n\r\nlivekit_api = api.LiveKitAPI()\r\n\r\ntransfer_to = '+14155550100'\r\n\r\n# Create transfer request\r\ntransfer_request = TransferSIPParticipantRequest(",
          "created_at": "2024-12-23T06:34:17Z"
        },
        {
          "author": "shwetd19",
          "body": "Hello, \r\n\r\nI am attempting to handle call transfers using LiveKit in a voice assistant. The assistant listens for user responses (`yes` or `no`) and initiates a transfer to the billing department when the response is affirmative. Despite following the documentation and implementing the SIP transfer ",
          "created_at": "2024-12-27T04:53:35Z"
        },
        {
          "author": "andrewcbuensalida",
          "body": "I get a deadline_exceeded error",
          "created_at": "2025-03-04T19:34:54Z"
        }
      ]
    },
    {
      "issue_number": 1590,
      "title": "Native audio input (STT+LLM combined) for VoicePipeline",
      "body": "Hi! I was wondering if anyone considered supporting native multimodal audio input in VoicePipeline, basically combining STT and LLM into one step?\nMultimodal Realtime API feels a bit limiting right now, but this could be a decent low latency steerable option. Most modern models like 4o, gemini, phi-4 (new llama will likely have it) are supporting it\n\nI want to prototype one and deciding if I should contribute to livekit from start or inherit and build it in my project\n",
      "state": "closed",
      "author": "mrdrprofuroboros",
      "author_type": "User",
      "created_at": "2025-03-03T18:47:00Z",
      "updated_at": "2025-03-04T02:12:52Z",
      "closed_at": "2025-03-04T02:12:52Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1590/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1590",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1590",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:06.837036",
      "comments": [
        {
          "author": "davidzhao",
          "body": "this will be possible to do in the dev-1.0 branch. we've been preparing for native support for multimodal LLMs.\n\nit'd be great to get your contributions!",
          "created_at": "2025-03-03T20:41:14Z"
        },
        {
          "author": "mrdrprofuroboros",
          "body": "OK, I've taken a look at the dev-1.0 branch now. first of all kudos to a much cleaner design compared to what have been there when the realtime API has been released!\n\nI think I'll just implement my own TaskActivity / AgentTask, but since I need even more control over TTS queueing, apparently  it be",
          "created_at": "2025-03-04T00:41:44Z"
        },
        {
          "author": "davidzhao",
          "body": "> I think I'll just implement my own TaskActivity / AgentTask, but since I need even more control over TTS queueing, apparently it becomes rather specific to my case and not really reusable for others.\n\nThat sounds good!\n\n> is it slated for release any soon?\n\nin the next week or two",
          "created_at": "2025-03-04T02:12:41Z"
        }
      ]
    },
    {
      "issue_number": 1589,
      "title": "Should RealtimeModel implementations inherit from _RealtimeAPI",
      "body": "Hi,\n\nI believe all `RealtimeModel` class implementations should inherit from `livekit.agents.multimodal.multimodal_agent._RealtimeAPI`.\n\nStatic type checkers are complaining otherwise when you try to instantiate a `MultimodalAgent`.\n\nIf you agree, I'm happy to open a PR.",
      "state": "closed",
      "author": "adambenali",
      "author_type": "User",
      "created_at": "2025-03-03T17:06:52Z",
      "updated_at": "2025-03-04T02:11:27Z",
      "closed_at": "2025-03-04T02:11:27Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1589/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1589",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1589",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:07.141124",
      "comments": [
        {
          "author": "longcw",
          "body": "The `_RealtimeAPI` is defined as `Protocol` (https://typing.readthedocs.io/en/latest/spec/protocol.html#protocols), you just need to implement the methods and properties defined in the protocol to pass the type check.",
          "created_at": "2025-03-04T01:58:39Z"
        }
      ]
    },
    {
      "issue_number": 1580,
      "title": "OpenAI Multimodel Turn off VAD mid room",
      "body": "Recently the agent added the following feature to turn off server side VAD. The example show that this need to be done before the room start. I wonder if it is possible to disable VAD after the room alrd started.\n\n```\nmodel=openai.realtime.RealtimeModel(\n    voice=\"alloy\",\n    temperature=0.8,\n    instructions=\"You are a helpful assistant\",\n    turn_detection=None,\n)\nagent = multimodal.MultimodalAgent(\n    model=model\n)\nagent.start(ctx.room)\n```",
      "state": "closed",
      "author": "remichu-ai",
      "author_type": "User",
      "created_at": "2025-03-01T16:18:16Z",
      "updated_at": "2025-03-03T15:55:37Z",
      "closed_at": "2025-03-03T15:55:35Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1580/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1580",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1580",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:07.345453",
      "comments": [
        {
          "author": "longcw",
          "body": "Yes, you can use `session_update` https://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-openai/livekit/plugins/openai/realtime/realtime_model.py#L912, and the [API reference from openai](https://platform.openai.com/docs/api-reference/realtime-client-events/session)",
          "created_at": "2025-03-02T15:57:02Z"
        },
        {
          "author": "remichu-ai",
          "body": "Thank you i have managed to turn it off",
          "created_at": "2025-03-03T15:55:35Z"
        }
      ]
    },
    {
      "issue_number": 1178,
      "title": "MultimodalAgent interrupts itself when response is created from function result",
      "body": "During the function call, the model could return audio letting the user know that it's performing an operation.\r\n\r\nWhile that speech is being played back, if the function call finishes with the result, we would have created an additional response that would interrupt that speech:\r\n\r\nFor example:\r\n\r\n```\r\nLet's say I have a tool called turn_on_the_light.\r\nThe agent will say \"I'll turn on the {cut-in}} the light is now on\".\r\n```\r\n\r\nThis is happening because of the `response.create()` line\r\n```\r\nif called_fnc.result is not None:\r\n            self.conversation.item.create(tool_call, item_id)\r\n            self.response.create()\r\n```\r\n\r\nWe should wait until current speech handle is finished before queuing additional speech",
      "state": "closed",
      "author": "davidzhao",
      "author_type": "User",
      "created_at": "2024-12-05T09:10:07Z",
      "updated_at": "2025-03-03T07:33:21Z",
      "closed_at": "2025-03-03T07:33:21Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1178/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 1,
        "eyes": 0
      },
      "assignees": [
        "longcw"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1178",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1178",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:07.539593",
      "comments": [
        {
          "author": "taqiycarbon",
          "body": "Exactly ! I created a function called `end_call` the agent is supposed to notify that it will end the call but ends up ending it abruptly.\n\nWe could call a function that could tell the assistant to tell the user that the call will end and then wait for the proper event to trigger the `end_call`\n\nThi",
          "created_at": "2025-01-26T21:39:59Z"
        },
        {
          "author": "maik-parloa",
          "body": "@davidzhao Do you have any update on this / is there a workaround to wait for the speech being finished?",
          "created_at": "2025-02-19T15:16:56Z"
        },
        {
          "author": "NameICanWrite",
          "body": "Hello, will this be fixed anytime soon. It makes me angry , how do you allowed  this OBVIOUS bug to hang around for 3 months?",
          "created_at": "2025-02-28T20:09:40Z"
        },
        {
          "author": "longcw",
          "body": "@NameICanWrite @maik-parloa Apologies for the delay! A fix https://github.com/livekit/agents/pull/1585 has been created and is currently in review. It will be available in the next release—thanks for your patience! ",
          "created_at": "2025-03-03T03:36:47Z"
        }
      ]
    },
    {
      "issue_number": 1586,
      "title": "Can Azure TTS support setting timeout through conn_options?",
      "body": "I am using livekit-plugins-azure==0.5.4\nCan Azure TTS support setting timeout through conn_options?\n\n```python\nclass TTS(\n    ABC,\n    rtc.EventEmitter[Union[Literal[\"metrics_collected\"], TEvent]],\n    Generic[TEvent],\n):\n    def __init__(\n        self,\n        *,\n        capabilities: TTSCapabilities,\n        sample_rate: int,\n        num_channels: int,\n        conn_options: Optional[APIConnectOptions] = None,\n    ) -> None:\n        super().__init__()\n        self._capabilities = capabilities\n        self._sample_rate = sample_rate\n        self._num_channels = num_channels\n        self._label = f\"{type(self).__module__}.{type(self).__name__}\"\n        self._conn_options = conn_options or DEFAULT_API_CONNECT_OPTIONS\n```\n\n<img width=\"986\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/1dafda9a-af9e-437a-ac99-88638f167052\" />",
      "state": "open",
      "author": "longwQaQ",
      "author_type": "User",
      "created_at": "2025-03-03T04:16:31Z",
      "updated_at": "2025-03-03T04:16:31Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1586/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1586",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1586",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:09.787446",
      "comments": []
    },
    {
      "issue_number": 1578,
      "title": "Dockerfile-example Fails to Build voice-pipeline-agent Due to Missing g++",
      "body": "### Description\nWhen building a Docker image using the provided `examples/Dockerfile-example` with the `requirements.txt` from `examples/voice-pipeline-agent/`, the build fails due to a missing C++ compiler (`g++`). The error occurs while compiling the `annoy` package, which is a transitive dependency of one of the required packages (likely `livekit-plugins-silero` or similar).\n\n\n\n### The build fails with the following error:\n```\ngcc: fatal error: cannot execute ‘cc1plus’: execvp: No such file or directory\ncompilation terminated.\nerror: command '/usr/bin/gcc' failed with exit code 1\nERROR: Failed building wheel for annoy\n```\n\n\n### Root Cause\n- The `annoy` package requires C++ compilation (evident from `.cc` files in its build output).\n- The `Dockerfile-example` installs `gcc` but not `g++`, which is needed to compile C++ code.\n\n### Suggested Fix\nAdd `g++` to the `apt-get install` command in `examples/Dockerfile-example`:\n```dockerfile\nRUN apt-get update && \\\n    apt-get install -y \\\n    gcc \\\n    g++ \\\n    python3-dev \\\n    && rm -rf /var/lib/apt/lists/*\n```\n### Additional Context\nrequirements.txt used: https://github.com/livekit/agents/blob/main/examples/voice-pipeline-agent/requirements.txt\nDockerfile: https://github.com/livekit/agents/blob/main/examples/Dockerfile-example\nTested with python:3.11.6-slim base image.\n\n\nThis seems like a small but impactful fix to make the example more robust. Happy to submit a PR if this aligns with the project’s goals!",
      "state": "closed",
      "author": "shwetd19",
      "author_type": "User",
      "created_at": "2025-03-01T09:26:29Z",
      "updated_at": "2025-03-01T18:51:25Z",
      "closed_at": "2025-03-01T18:51:23Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1578/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1578",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1578",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:09.787471",
      "comments": [
        {
          "author": "davidzhao",
          "body": "fixed in #1579 ",
          "created_at": "2025-03-01T18:51:23Z"
        }
      ]
    },
    {
      "issue_number": 1560,
      "title": "No END_OF_SPEECH from AssemblyAI STT",
      "body": "Currently, there is no END_OF_SPEECH event sent from the Assembly AI STT plugin. For example, in `tests/test_stt.py`, if using Assembly AI STT, the `recv_end` would eventually be `False`.\n\nI guess my question is, does this impact the results in theory? If not, feel free to close this issue. Based on the [docs](https://www.assemblyai.com/docs/api-reference/streaming/realtime) they have, one possible solution is to send such an event at the session termination stage.\n",
      "state": "closed",
      "author": "ChenghaoMou",
      "author_type": "User",
      "created_at": "2025-02-27T10:32:41Z",
      "updated_at": "2025-03-01T15:29:02Z",
      "closed_at": "2025-03-01T15:29:02Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1560/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1560",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1560",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:09.990746",
      "comments": [
        {
          "author": "davidzhao",
          "body": "it should not impact anything. we do not use VAD results from the STT. instead VAD is performed separately",
          "created_at": "2025-03-01T08:39:00Z"
        },
        {
          "author": "ChenghaoMou",
          "body": "@davidzhao Thanks for the answer. Originally, I thought about that but saw those events were present in other STT plugins (e.g. deepgram), hence my ask here. Will close this issue. Thanks!",
          "created_at": "2025-03-01T15:28:56Z"
        }
      ]
    },
    {
      "issue_number": 1550,
      "title": "AWS plugin in Python Package Index?",
      "body": "\nSaw the new merge of aws plugins but was not able to find it in Python Package Index (https://pypi.org/) and not able to run the install using pip.",
      "state": "closed",
      "author": "sunilvb",
      "author_type": "User",
      "created_at": "2025-02-25T16:09:26Z",
      "updated_at": "2025-03-01T08:46:57Z",
      "closed_at": "2025-03-01T08:46:55Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1550/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1550",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1550",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:10.217887",
      "comments": [
        {
          "author": "davidzhao",
          "body": "it's been released. let us know how it works for you! https://pypi.org/project/livekit-plugins-aws/",
          "created_at": "2025-03-01T08:46:55Z"
        }
      ]
    },
    {
      "issue_number": 1558,
      "title": "[dev] Persistent \"agent started without audio or text output\" Warning Despite TTS Integration",
      "body": "#### Description\nI'm encountering a recurring warning in my LiveKit Agents application: `agent started without audio or text output`, even when using a valid TTS plugin (`cartesia.TTS`). The agent is configured to produce audio output via `say`, but the warning persists, suggesting a potential timing or initialization issue within `PipelineAgent`.\n\n#### Minimal Example\n```python\nimport asyncio\nfrom livekit.agents import JobContext, WorkerOptions, WorkerType, cli\nfrom livekit.agents.pipeline import PipelineAgent, AgentTask\nfrom livekit.plugins import cartesia, deepgram, openai\nimport logging\n\nlogger = logging.getLogger(\"test-agent\")\nlogger.setLevel(logging.DEBUG)\n\nclass TestNode(AgentTask):\n    async def on_enter(self):\n        self.agent.say(\"Hello, testing audio output.\")\n\nasync def entrypoint(ctx: JobContext):\n    await ctx.connect()\n    agent = PipelineAgent(\n        task=TestNode(),\n        stt=deepgram.STT(),\n        llm=openai.LLM(),\n        tts=cartesia.TTS(),\n    )\n    await agent.start()\n    await asyncio.sleep(5)  # Keep running briefly\n\nif __name__ == \"__main__\":\n    cli.run_app(WorkerOptions(entrypoint_fnc=entrypoint, worker_type=WorkerType.ROOM))\n```\n\n\n#### Expected Behavior\n- The agent starts without the warning since `cartesia.TTS` is configured and `say` is called shortly after `start()`.\n- Audio output is produced for \"Hello, testing audio output.\"\n\n#### Actual Behavior\n- The warning `agent started without audio or text output` appears in the logs despite a functional TTS setup.\n- Audio is not being produced , but the warning still occurs.\n\n#### Logs\n```\n2025-02-27 04:55:58,619 - WARNING livekit.agents - agent started without audio or text output {\"pid\": 24406, \"job_id\": \"AJ_uJGDj2Fny5k6\"}\n2025-02-27 04:55:58,620 - INFO test-agent - Agent saying: Hello, testing audio output.\n```\n\n#### Additional Context\n- The warning seems to occur because `PipelineAgent.start()` completes before the TTS system (e.g., Cartesia) is fully initialized.\n- Adding a delay (e.g., `await asyncio.sleep(2)`) and forcing an initial `say` call after `start()` sometimes mitigates the issue, but this feels like a workaround rather than a proper fix.\n",
      "state": "open",
      "author": "shwetd19",
      "author_type": "User",
      "created_at": "2025-02-27T05:01:26Z",
      "updated_at": "2025-03-01T08:39:49Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1558/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1558",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1558",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:10.473767",
      "comments": [
        {
          "author": "longcw",
          "body": "I guess you forgot to start the agent with room `await agent.start(room=ctx.room)` or explicitly set the `agent.output.audio` and `agent.output.text`. Here is an example for the dev-1.0 https://github.com/livekit/agents/blob/dev-1.0/examples/roomio_worker.py#L55-L56\n\nThe idea is that the agent suppo",
          "created_at": "2025-02-27T06:35:52Z"
        },
        {
          "author": "longcw",
          "body": "@theomonnom btw, this is the reason I think a warning if agent starts without output is necessary, people may forget to pass the room to `agent.start` and just found that agent has no any response. Probably we can make the message more specific, notifying they may forget the `agent.start(room)`.",
          "created_at": "2025-02-27T06:40:42Z"
        }
      ]
    },
    {
      "issue_number": 1462,
      "title": "elevenlabs TypeError: Can't instantiate abstract class ChunkedStream with abstract method _run",
      "body": "<!--\nHello! Thanks for taking the time to file a bug report.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already reported this issue.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n-->\nUsing the text-to-speech example (elevenlabs) i encountered this error which clearly is a class related error from elevenlabs plugin , how can this be fixed?\n\n\nI am running the following livekit packages :\n\n\nlivekit==0.19.1\nlivekit-agents==0.12.8\nlivekit-api==0.8.0\nlivekit-plugins-azure==0.2.1\nlivekit-plugins-deepgram==0.6.16\nlivekit-plugins-elevenlabs==0.7.7\nlivekit-plugins-openai==0.10.15\nlivekit-plugins-rag==0.2.3\nlivekit-plugins-silero==0.7.4\nlivekit-plugins-turn-detector==0.3.6\nlivekit-protocol==0.7.0\n\nI appreciate any help or idea to fix this\n\n2025-02-07 14:53:21,990 - DEBUG livekit.agents - http_session(): creating a new httpclient ctx 2025-02-07 14:53:21,991 - ERROR livekit.agents - unhandled exception while running the job task Traceback (most recent call last):   File \"C:\\Users\\USER\\Desktop\\spatial-agents-server\\TEST.py\", line 61, in entrypoint     async for output in tts_11labs.synthesize(\"Bonjour, comment allez-vous?\"):                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^   File \"c:\\Users\\USER\\Desktop\\spatial-agents-server\\myenv\\Lib\\site-packages\\livekit\\plugins\\elevenlabs\\tts.py\", line 200, in synthesize     return ChunkedStream(self, text, self._opts, self._ensure_session())            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ TypeError: Can't instantiate abstract class ChunkedStream with abstract method _run",
      "state": "open",
      "author": "ElyasMoshirpanahi",
      "author_type": "User",
      "created_at": "2025-02-07T14:59:21Z",
      "updated_at": "2025-03-01T08:38:12Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1462/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1462",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1462",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:10.668891",
      "comments": [
        {
          "author": "mpsebastianvidiv",
          "body": "Same error on:\n\nlivekit-agents==0.12.16\nlivekit-plugins-openai==1.0.0\nlivekit-plugins-elevenlabs==0.7.4\nlivekit-plugins-deepgram==0.6.20\nlivekit-plugins-silero==0.7.4",
          "created_at": "2025-02-28T12:56:40Z"
        },
        {
          "author": "davidzhao",
          "body": "please update your elevenlabs plugin to the latest version, currently `0.7.14`",
          "created_at": "2025-03-01T08:38:11Z"
        }
      ]
    },
    {
      "issue_number": 1569,
      "title": "[Bug?] Egress participant not triggering participant_connected event",
      "body": "This may or may not be a bug - I just want some clarification. \n\nI'm working on a unique system where i'm using egress to record rooms. I noticed there is a PARTICIPANT_KIND_EGRESS which from the name creates an impression that when egress occurs, a PARTICIPANT_KIND_EGRESS participant will join the room. In fact I confirmed though the Livekit Cloud logs that this is true. In the screenshot it shows that a participant with name \"EG_{uuid}\" is indeed added to the room after the agent joins. \n\n![Image](https://github.com/user-attachments/assets/5d3474a1-0fe0-4013-93af-dc1a1f038524)\n\n\nMy goal is to be notified when the egress user joins the room with the code\n```\nasync def entrypoint(ctx: JobContext):\n    ctx.room.on(\"participant_connected\", lambda participant: logger.info(\"participant connected %s\", participant))\n    await ctx.connect(auto_subscribe=AutoSubscribe.AUDIO_ONLY)\n```\nI never see the egress user joining but recordings are being created as specified in my auto egress setup. \n\nHere's how I create my room:\n```\n  room = None\n    try:\n        room = await lkapi.room.create_room(CreateRoomRequest(\n            name=room_name,\n            max_participants=10,\n            empty_timeout=120,\n            egress=RoomEgress(\n                room=RoomCompositeEgressRequest(\n                    room_name=room_name,\n                    audio_only=True,\n                     file_outputs=[EncodedFileOutput(\n                        file_type=EncodedFileType.MP4,\n                        filepath=\"{}\".format(egress_path),\n                        gcp=GCPUpload(\n                            bucket=\"BUCKET_NAME_HERE\",\n                            credentials=credentials_str\n                        )\n                    )]\n                )\n            )\n        ))\n        print(\"room created\", room)\n    except Exception as e:\n        print(\"error creating room\", e)\n    finally:\n        # before your app exits or when the API client is no longer needed, you must close its session\n        await lkapi.aclose()\n```\n\n\nAm i misunderstanding something?\n\n\n",
      "state": "open",
      "author": "VictorAny",
      "author_type": "User",
      "created_at": "2025-02-28T02:35:10Z",
      "updated_at": "2025-03-01T08:17:09Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1569/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1569",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1569",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:10.935230",
      "comments": [
        {
          "author": "davidzhao",
          "body": "Egress participants are not visible to others in the room. They have a `hidden` property bit set to ensure you don't accidentally start a conversation with an Egress participant\n\nWe do have a `room.isRecording` property that should get set when Egress is in the room. However, Python SDK currently ca",
          "created_at": "2025-02-28T07:13:02Z"
        },
        {
          "author": "VictorAny",
          "body": "Got it -- that makes sense.\n\n@davidzhao is this property available for the javascript client sdk?",
          "created_at": "2025-02-28T15:31:47Z"
        },
        {
          "author": "davidzhao",
          "body": "yes, it's available in JS",
          "created_at": "2025-03-01T08:17:08Z"
        }
      ]
    },
    {
      "issue_number": 1561,
      "title": "Google Realtime Model (Google Multimodal Live) throws AttributeError: 'LiveServerToolCallCancellation' object has no attribute 'function_call_ids'",
      "body": "\nInteruppting Tool call while agent is speaking throws an error and close the Realtime connection. \n\n**Setup**\n- With Goolge Multimodal Live API \n\n**Versions**\n```\nlivekit-agents = \"0.12.15\"\nlivekit-plugins-google = \"0.10.5\"\n```\n\n**Possible Solution**\n\nAccording to Google Multimodal Live API documentation - https://ai.google.dev/gemini-api/docs/multimodal-live?utm_source=chatgpt.com#bidigeneratecontenttoolcallcancellation \n\n`It returns ids instead of function_call_ids`\n\n**Error Log**\n\n```\nAttributeError: 'LiveServerToolCallCancellation' object has no attribute 'function_call_ids' \u001b[90m{\"pid\": 1651, \"job_id\": \"AJ_yYTJMJqd44Ee\"}\u001b[0m\n\nFeb 27 16:53:53.891\ni-07cf631511b012294\nrepo\nraise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')\n\nFeb 27 16:53:53.891\ni-07cf631511b012294\nchat-service-celery-repo\nFile \"/usr/local/lib/python3.11/site-packages/pydantic/main.py\", line 856, in __getattr__\n\nFeb 27 16:53:53.891\ni-07cf631511b012294\nrepo\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nFeb 27 16:53:53.891\ni-07cf631511b012294\nrepo\n\"function_call_ids\": response.tool_call_cancellation.function_call_ids,\n\nFeb 27 16:53:53.891\ni-07cf631511b012294\nchat-service-celery-repo\nFile \"/usr/local/lib/python3.11/site-packages/livekit/plugins/google/beta/realtime/realtime_api.py\", line 482, in _recv_task\n```\n\n",
      "state": "closed",
      "author": "psinojiya",
      "author_type": "User",
      "created_at": "2025-02-27T12:32:54Z",
      "updated_at": "2025-02-28T07:25:32Z",
      "closed_at": "2025-02-28T07:25:32Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1561/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1561",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1561",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:11.154574",
      "comments": [
        {
          "author": "psinojiya",
          "body": "Hi @jayeshp19 , this also seems to be small issue with Google Multimodal Live integration with Realtime Model.",
          "created_at": "2025-02-27T12:34:39Z"
        },
        {
          "author": "jayeshp19",
          "body": "Thanks for reporting this @psinojiya looks like they changed it. https://github.com/livekit/agents/pull/1572",
          "created_at": "2025-02-28T05:42:40Z"
        }
      ]
    },
    {
      "issue_number": 1553,
      "title": "Ensure 1:1 Frontend-Backend Connection in Shared LiveKit Setup",
      "body": "My friend and I share the same LiveKit URL, my frontend can still connect when someone else runs the backend. I want to ensure a 1:1 connection where my frontend only works if my own backend is running. What’s the best way to enforce this using authentication or session management? I think this would ensure better local dev for what we are working on. How is this usually dealt with? I am open to your suggestions. Thanks!",
      "state": "closed",
      "author": "atahanozdemirberkeley",
      "author_type": "User",
      "created_at": "2025-02-26T06:27:39Z",
      "updated_at": "2025-02-27T20:47:29Z",
      "closed_at": "2025-02-27T20:47:29Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1553/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1553",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1553",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:11.402995",
      "comments": [
        {
          "author": "atahanozdemirberkeley",
          "body": "Hey maybe we should self-host and run live kit locally for local dev?",
          "created_at": "2025-02-26T06:57:21Z"
        },
        {
          "author": "atahanozdemirberkeley",
          "body": "Also, although I am not running my backend, an agent still connected, and on the dashboard it says 40 active rooms and 6 participants. What is the cause of this issue and how can I prevent it?",
          "created_at": "2025-02-26T06:58:28Z"
        }
      ]
    },
    {
      "issue_number": 1557,
      "title": "Realtime mode bug with new non_vad mode and generate_reply()",
      "body": "Hi, there seems to be this new bug with the latest version after non vad mode for realtime api is introduced.\n\n```\n2025-02-27 00:13:33,961 - ERROR livekit - failed to emit event playout_stopped\nTraceback (most recent call last):\n  File \"/home/remichu/miniconda3/envs/mlenv_vision/lib/python3.12/site-packages/livekit/rtc/event_emitter.py\", line 58, in emit\n    callback(*callback_args)\n  File \"/home/remichu/miniconda3/envs/mlenv_vision/lib/python3.12/site-packages/livekit/agents/multimodal/multimodal_agent.py\", line 450, in _on_playout_stopped\n    if self._model.capabilities.supports_truncate and collected_text:\n       ^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'RealtimeModel' object has no attribute 'capabilities' {\"pid\": 99551, \"job_id\": \"AJ_prRqsdkdhXsd\"}\n\n```\n\nThis `capabilities` seems to be in the _RealtimeAPI instead:\n```\nclass _CapabilitiesProto(Protocol):\n    supports_truncate: bool\n    input_audio_sample_rate: int | None\n\n\nclass _RealtimeAPI(Protocol):\n    \"\"\"Realtime API protocol\"\"\"\n\n    @property\n    def capabilities(self) -> _CapabilitiesProto: ...\n    def session(\n        self,\n        *,\n        chat_ctx: llm.ChatContext | None = None,\n        fnc_ctx: llm.FunctionContext | None = None,\n    ) -> _RealtimeAPISession:\n        \"\"\"\n        Create a new realtime session with the given chat and function contexts.\n        \"\"\"\n        pass\n```",
      "state": "closed",
      "author": "remichu-ai",
      "author_type": "User",
      "created_at": "2025-02-26T16:22:18Z",
      "updated_at": "2025-02-27T11:51:10Z",
      "closed_at": "2025-02-27T11:51:09Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1557/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1557",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1557",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:11.649533",
      "comments": [
        {
          "author": "longcw",
          "body": "It seems like the openai-plugin is not up-to-date, the capabilities is defined in https://github.com/livekit/agents/blob/livekit-plugins-openai%400.11.0/livekit-plugins/livekit-plugins-openai/livekit/plugins/openai/realtime/realtime_model.py#L296\n\nmaybe you can check the version of the plugin and up",
          "created_at": "2025-02-27T02:15:05Z"
        },
        {
          "author": "remichu-ai",
          "body": "Thanks for the quick reply, let me try and update it. The way the libraries are packaged is quite decoupled hence i missed it",
          "created_at": "2025-02-27T03:06:36Z"
        },
        {
          "author": "remichu-ai",
          "body": "Update livekit openai plugin fixed the issue. Thank you.",
          "created_at": "2025-02-27T11:51:09Z"
        }
      ]
    },
    {
      "issue_number": 1485,
      "title": "Proposal: AWS Nova Support for livekit agent",
      "body": "I would like to inquire if there are any plans to integrate support for AWS Nova into livekit agent. \n\nNova offers significant advantages in terms of generation speed and cost efficiency, which could be very beneficial for users who require rapid deployment and lower operational costs.\n\nCould you please share if there are any current plans for this integration? Additionally, any insights on potential workarounds or alternatives would be greatly appreciated.\n\nThank you for your continuous work on this project!",
      "state": "closed",
      "author": "PotatoWen",
      "author_type": "User",
      "created_at": "2025-02-13T04:23:41Z",
      "updated_at": "2025-02-27T07:15:05Z",
      "closed_at": "2025-02-27T05:49:52Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1485/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1485",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1485",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:11.926914",
      "comments": [
        {
          "author": "PotatoWen",
          "body": "It looks like AWS support was integrated two days ago. I appreciate the effort—thank you! ",
          "created_at": "2025-02-27T05:49:52Z"
        },
        {
          "author": "davidzhao",
          "body": "we'll get a release out shortly!",
          "created_at": "2025-02-27T07:15:04Z"
        }
      ]
    },
    {
      "issue_number": 1113,
      "title": "Solution to \"InvalidStateError\" and Handling of Closed Channels in OpenAI's AssistantLLMStream",
      "body": "Hello everyone,\r\n\r\nRecently, we encountered an error while using the OpenAI Assistants API in our project. Upon investigation, we noticed that several discussions in the community highlighted similar issues experienced by other developers. I’d like to share our experience and the solution we implemented, hoping it will be helpful to those facing the same problem.\r\n\r\nError Description:\r\n\r\nWhen interacting with the assistant, the program intermittently threw the following error:\r\n\r\n`asyncio.exceptions.InvalidStateError: invalid state`\r\n\r\nThis error occurred in the `_main_task ` method of the `AssistantLLMStream `class within the \"`assistant_llm.py`\" file, specifically when trying to set the result of a `Future ` that had already been completed:\r\n\r\n`self._done_future.set_result(None)`\r\n\r\nAdditionally, exceptions related to attempts to send data through a closed channel (`ChanClosed`) were also observed, causing data flow interruptions and the assistant to stop responding.\r\n\r\nCause of the Error:\r\n\r\n1. State of the `Future`: The `InvalidStateError ` occurs when attempting to modify the state of a `Future ` that has already been completed or canceled. In our case, the `Future ` `self._done_future` could already be finished when `set_result(None)` was called.\r\n\r\n2. Improper Exception Handling: Exceptions in asynchronous methods were not being properly managed, leading to attempts to send data through a closed channel and additional exceptions that impacted the program's stability.\r\n\r\nSolution Implemented:\r\n\r\n1. Check the State of the `Future ` Before Modifying It:\r\n\r\nWe added a verification step to ensure that the `Future` was not already completed before calling `set_result(None)`:\r\n\r\n`finally:`\r\n`    if not self._done_future.done():`\r\n`        self._done_future.set_result(None)`\r\n        \r\nThis prevents attempts to modify a `Future` in an invalid state, avoiding the `InvalidStateError`.\r\n\r\n2. Proper Exception Handling and Channel Closure:\r\n\r\nIn the `_main_task` method, we added an `except` block to capture any exceptions during execution, set `self._exception`, and close the event channel `self._event_ch`. This ensures that the stream iterator is aware of the exception and handles the flow appropriately.\r\n\r\n`except Exception as e:`\r\n`    logger.error(f\"Unexpected error in _main_task: {e}\")`\r\n`    self._exception = e`\r\n`    self._event_ch.close()`\r\n    \r\nAdditionally, in the `on_text_delta` method of the `EventHandler` class, we handled exceptions while sending data through the channel, ensuring the program flow is not interrupted if the channel is closed:\r\n\r\n`async def on_text_delta(self, delta: TextDelta, snapshot: Text):`\r\n`    try:`\r\n`        assert self.current_run is not None`\r\n`        self._event_ch.send_nowait(`\r\n`            llm.ChatChunk(`\r\n`                request_id=self.current_run.id,`\r\n`                choices=[`\r\n`                    llm.Choice(`\r\n`                        delta=llm.ChoiceDelta(role=\"assistant\", content=delta.value)`\r\n`                    )`\r\n`                ],`\r\n`            )`\r\n`        )`\r\n`    except utils.aio.ChanClosed:`\r\n`        # The channel is closed, no action needed`\r\n`        pass`\r\n`    except Exception as e:`\r\n`        logger.error(f\"Exception in on_text_delta: {e}\")`\r\n`        self._llm_stream._exception = e`\r\n`        self._llm_stream._event_ch.close()`\r\n        \r\nResults:\r\n\r\nAfter applying these changes, the `InvalidStateError` stopped occurring, and the assistant now functions correctly, responding consistently to user interactions. Proper exception handling and validation of asynchronous object states improved the stability and robustness of the application.",
      "state": "open",
      "author": "JeisonNovoa",
      "author_type": "User",
      "created_at": "2024-11-20T13:49:01Z",
      "updated_at": "2025-02-25T12:27:30Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1113/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1113",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1113",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:12.153807",
      "comments": [
        {
          "author": "ftsef",
          "body": "Thanks for your effort. Works without any exceptions/missbehavior so far",
          "created_at": "2024-11-21T09:11:11Z"
        },
        {
          "author": "fhrzn",
          "body": "by any chance, have you ever faced an issue when the assistant executes a tool but the generated response doesn't reach the livekit?",
          "created_at": "2024-12-01T08:44:24Z"
        },
        {
          "author": "wakusoftware",
          "body": "This should be a PR",
          "created_at": "2025-01-02T18:45:21Z"
        },
        {
          "author": "meetakshay99",
          "body": "Please fix it in git and release.",
          "created_at": "2025-01-30T06:07:09Z"
        },
        {
          "author": "meetakshay99",
          "body": "Any update on this pls?",
          "created_at": "2025-02-19T12:55:03Z"
        }
      ]
    },
    {
      "issue_number": 1356,
      "title": "Flag to better support simultaneous text-to-speech and speech-to-text",
      "body": "hi,\r\nI have a usecase for realtime translation, but i noticed that when the agent is speaking, some of the stt transcripts are missing / not added to the chat context so the agent will not consider those for llm and tts. I had a look at the VoicepipelineAgent internals and noticed the below code\r\n(btw I have these config set `allow_interruptions=False, preemptive_synthesis=True`)\r\n\r\n```\r\ndef _validate_reply_if_possible(self) -> None:\r\n        \"\"\"Check if the new agent speech should be played\"\"\"\r\n\r\n        if self._playing_speech and not self._playing_speech.interrupted:\r\n            should_ignore_input = False\r\n            if not self._playing_speech.allow_interruptions:\r\n                should_ignore_input = True\r\n                logger.debug(\r\n                    \"skipping validation, agent is speaking and does not allow interruptions\",\r\n                    extra={\"speech_id\": self._playing_speech.id},\r\n                )\r\n```\r\n\r\nand\r\n\r\n```\r\nif should_ignore_input:\r\n                self._transcribed_text = \"\"\r\n                return\r\n```\r\n\r\n\r\nI understood the transcribed text is cleared here to allow more natural flow of conversation, to keep a clean chat history of agent replying to the correct speech input.\r\nHowever this does not quite fit my use case which does not tolerate missing speech input. Would it be possible to add a flag to turn this off (clearing out the transcript while speaking)",
      "state": "open",
      "author": "okharedia",
      "author_type": "User",
      "created_at": "2025-01-10T07:57:34Z",
      "updated_at": "2025-02-23T07:12:15Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1356/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1356",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1356",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:12.379475",
      "comments": [
        {
          "author": "davidzhao",
          "body": "user speech is always flowing in.. and STT is always running. since LLM requires the full input to be ready in order to start inference, we would wait until the user has completed their turn before starting inference.\r\n\r\ncan you describe what transcripts you are missing?",
          "created_at": "2025-01-12T22:45:20Z"
        },
        {
          "author": "okharedia",
          "body": "@davidzhao thank you for looking into it.\n\n> since LLM requires the full input to be ready in order to start inference, we would wait until the user has completed their turn before starting inference.\n\n`should_ignore_input` is set to `True` when agent is speaking and should not be interrupted (`allo",
          "created_at": "2025-01-27T09:27:44Z"
        },
        {
          "author": "longwQaQ",
          "body": "@okharedia Hello, when allow_interruptions=False, my business also wants to retain user input as much as possible. Do you have any good solutions?",
          "created_at": "2025-02-23T07:12:13Z"
        }
      ]
    },
    {
      "issue_number": 1542,
      "title": "[Docs]: JobContext does not contain publisher instance variable",
      "body": "In [the documentation](https://docs.livekit.io/agents/build/anatomy/#worker-type) regarding the anatomy of the agent, it is stated that: `For PUBLISHER jobs, the entrypoint function will be called once for each publisher in the room. The JobContext.publisher object will contain a RemoteParticipant representing that publisher.`\n\nAs far as I'm aware, examining the class definition for `JobContext` reveals that there is no `publisher` instance variable for accessing a `RemoteParticipant`. There is one for `JobRequest` but this is very different from `JobContext`. The docs should be updated to reflect this if this is no longer a feature. If I misunderstood or missed something in regards to this line please let me know.",
      "state": "open",
      "author": "jmho",
      "author_type": "User",
      "created_at": "2025-02-21T22:09:32Z",
      "updated_at": "2025-02-21T22:09:32Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1542/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1542",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1542",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:12.665878",
      "comments": []
    },
    {
      "issue_number": 964,
      "title": "Exception: OpenAI S2S connection closed unexpectedly ",
      "body": "i get this error\r\n\r\n\r\n```\r\n(today) arkodeepchatterjee@Arkodeeps-MacBook-Air today % python3 agent.py connect --room my-room\r\n2024-10-21 20:34:49,346 - DEBUG asyncio - Using selector: KqueueSelector \r\n2024-10-21 20:34:49,347 - DEV  livekit.agents - Watching /Users/arkodeepchatterjee/Desktop/today \r\n2024-10-21 20:34:49,725 - DEBUG asyncio - Using selector: KqueueSelector \r\n2024-10-21 20:34:49,728 - INFO livekit.agents - starting worker {\"version\": \"0.10.2\", \"rtc-version\": \"0.17.5\"}\r\n2024-10-21 20:34:50,680 - INFO livekit.agents - registered worker {\"id\": \"AW_7nPLUg6MNDot\", \"region\": \"\", \"protocol\": 14, \"node_id\": \"ND_LyC5ZDiqyX6Z\"}\r\n2024-10-21 20:34:50,681 - INFO livekit.agents - connecting to room my-room \r\n2024-10-21 20:34:51,603 - INFO livekit.agents - received job request {\"job_id\": \"AJ_36h3t5brLLAS\", \"dispatch_id\": \"AD_pGyVXv8LPGvU\", \"room_name\": \"my-room\", \"agent_name\": \"\", \"resuming\": false}\r\n2024-10-21 20:34:51,635 - INFO livekit.agents - received job request {\"job_id\": \"AJ_bjaNW4rj3kf9\", \"dispatch_id\": \"\", \"room_name\": \"my-room\", \"agent_name\": \"\", \"resuming\": false}\r\n2024-10-21 20:34:52,242 - DEBUG asyncio - Using selector: KqueueSelector {\"pid\": 52420}\r\n2024-10-21 20:34:52,243 - INFO livekit.agents - initializing process {\"pid\": 52420}\r\n2024-10-21 20:34:52,243 - INFO livekit.agents - process initialized {\"pid\": 52420}\r\n2024-10-21 20:34:52,244 - INFO my-worker - starting entrypoint {\"pid\": 52420, \"job_id\": \"AJ_36h3t5brLLAS\"}\r\n2024-10-21 20:34:52,626 - DEBUG asyncio - Using selector: KqueueSelector {\"pid\": 52421}\r\n2024-10-21 20:34:52,628 - INFO livekit.agents - initializing process {\"pid\": 52421}\r\n2024-10-21 20:34:52,628 - INFO livekit.agents - process initialized {\"pid\": 52421}\r\n2024-10-21 20:34:52,629 - INFO my-worker - starting entrypoint {\"pid\": 52421, \"job_id\": \"AJ_bjaNW4rj3kf9\"}\r\n2024-10-21 20:34:55,837 - DEBUG livekit.agents - http_session(): creating a new httpclient ctx {\"pid\": 52420, \"job_id\": \"AJ_36h3t5brLLAS\"}\r\n2024-10-21 20:34:56,132 - DEBUG livekit.agents - http_session(): creating a new httpclient ctx {\"pid\": 52421, \"job_id\": \"AJ_bjaNW4rj3kf9\"}\r\n2024-10-21 20:34:57,055 - ERROR livekit.plugins.openai.realtime - OpenAI S2S error {'type': 'error', 'event_id': 'event_AKoFkgQGluOnCWGHP8Eo2', 'error': {'type': 'invalid_request_error', 'code': 'access_not_enabled', 'message': \"Your organization does not have access to the Realtime API. We're in the process of rolling out to all developers.\", 'param': None, 'event_id': None}} {\"session_id\": \"not-connected\", \"pid\": 52420, \"job_id\": \"AJ_36h3t5brLLAS\"}\r\n2024-10-21 20:34:57,056 - ERROR livekit.plugins.openai.realtime - Error in _recv_task\r\nTraceback (most recent call last):\r\n  File \"/Users/arkodeepchatterjee/Desktop/today/today/lib/python3.12/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\r\n    return await fn(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/arkodeepchatterjee/Desktop/today/today/lib/python3.12/site-packages/livekit/plugins/openai/realtime/realtime_model.py\", line 833, in _recv_task\r\n    raise Exception(\"OpenAI S2S connection closed unexpectedly\")\r\nException: OpenAI S2S connection closed unexpectedly {\"pid\": 52420, \"job_id\": \"AJ_36h3t5brLLAS\"}\r\n2024-10-21 20:34:57,059 - ERROR livekit.plugins.openai.realtime - Error in _main_task\r\nTraceback (most recent call last):\r\n  File \"/Users/arkodeepchatterjee/Desktop/today/today/lib/python3.12/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\r\n    return await fn(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/arkodeepchatterjee/Desktop/today/today/lib/python3.12/site-packages/livekit/plugins/openai/realtime/realtime_model.py\", line 900, in _main_task\r\n    await asyncio.gather(*tasks)\r\n  File \"/Users/arkodeepchatterjee/Desktop/today/today/lib/python3.12/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\r\n    return await fn(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/arkodeepchatterjee/Desktop/today/today/lib/python3.12/site-packages/livekit/plugins/openai/realtime/realtime_model.py\", line 833, in _recv_task\r\n    raise Exception(\"OpenAI S2S connection closed unexpectedly\")\r\nException: OpenAI S2S connection closed unexpectedly {\"pid\": 52420, \"job_id\": \"AJ_36h3t5brLLAS\"}\r\n2024-10-21 20:34:57,305 - ERROR livekit.plugins.openai.realtime - OpenAI S2S error {'type': 'error', 'event_id': 'event_AKoFlqov0WMlMEmvkP0QC', 'error': {'type': 'invalid_request_error', 'code': 'access_not_enabled', 'message': \"Your organization does not have access to the Realtime API. We're in the process of rolling out to all developers.\", 'param': None, 'event_id': None}} {\"session_id\": \"not-connected\", \"pid\": 52421, \"job_id\": \"AJ_bjaNW4rj3kf9\"}\r\n2024-10-21 20:34:57,305 - ERROR livekit.plugins.openai.realtime - Error in _recv_task\r\nTraceback (most recent call last):\r\n  File \"/Users/arkodeepchatterjee/Desktop/today/today/lib/python3.12/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\r\n    return await fn(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/arkodeepchatterjee/Desktop/today/today/lib/python3.12/site-packages/livekit/plugins/openai/realtime/realtime_model.py\", line 833, in _recv_task\r\n    raise Exception(\"OpenAI S2S connection closed unexpectedly\")\r\nException: OpenAI S2S connection closed unexpectedly {\"pid\": 52421, \"job_id\": \"AJ_bjaNW4rj3kf9\"}\r\n2024-10-21 20:34:57,307 - ERROR livekit.plugins.openai.realtime - Error in _main_task\r\nTraceback (most recent call last):\r\n  File \"/Users/arkodeepchatterjee/Desktop/today/today/lib/python3.12/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\r\n    return await fn(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/arkodeepchatterjee/Desktop/today/today/lib/python3.12/site-packages/livekit/plugins/openai/realtime/realtime_model.py\", line 900, in _main_task\r\n    await asyncio.gather(*tasks)\r\n  File \"/Users/arkodeepchatterjee/Desktop/today/today/lib/python3.12/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\r\n    return await fn(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/arkodeepchatterjee/Desktop/today/today/lib/python3.12/site-packages/livekit/plugins/openai/realtime/realtime_model.py\", line 833, in _recv_task\r\n    raise Exception(\"OpenAI S2S connection closed unexpectedly\")\r\nException: OpenAI S2S connection closed unexpectedly {\"pid\": 52421, \"job_id\": \"AJ_bjaNW4rj3kf9\"}\r\n```\r\n\r\nwith this code\r\n\r\n```python\r\nfrom __future__ import annotations\r\nimport logging\r\nfrom typing import Annotated\r\nfrom dotenv import load_dotenv\r\nimport os\r\n\r\nimport smtplib\r\nfrom email.message import EmailMessage\r\n\r\nfrom livekit.agents import (\r\n    AutoSubscribe,\r\n    JobContext,\r\n    WorkerOptions,\r\n    WorkerType,\r\n    cli,\r\n    llm,\r\n    multimodal,\r\n)\r\nfrom livekit.plugins import openai\r\n\r\nload_dotenv()\r\nlogger = logging.getLogger(\"my-worker\")\r\nlogger.setLevel(logging.INFO)\r\n\r\n# print(os.getenv(\"LIVEKIT_URL\"))\r\n# print(os.getenv(\"LIVEKIT_API_KEY\"))\r\n# print(os.getenv(\"LIVEKIT_API_SECRET\"))\r\n\r\n\r\ndef send_email(subject, body, to_email):\r\n    msg = EmailMessage()\r\n    msg.set_content(body)\r\n    msg[\"Subject\"] = subject\r\n    msg[\"From\"] = os.getenv(\"EMAIL\")\r\n    msg[\"To\"] = to_email\r\n\r\n    with smtplib.SMTP_SSL(os.getenv(\"SMTP\"), 465) as smtp:\r\n        smtp.login(os.getenv(\"EMAIL\"), os.getenv(\"PASSWORD\"))\r\n        smtp.send_message(msg)\r\n\r\n\r\nasync def entrypoint(ctx: JobContext):\r\n    logger.info(\"starting entrypoint\")\r\n\r\n    fnc_ctx = llm.FunctionContext()\r\n\r\n    @fnc_ctx.ai_callable()\r\n    async def emergency_email(\r\n        location: Annotated[\r\n            str,\r\n            llm.TypeInfo(description=\"The location where to send help in emergency\"),\r\n        ],\r\n    ):\r\n        \"\"\"Called when user asks to send help email in emergency. This function will send help email in emergency.\"\"\"\r\n        logger.info(\"sending help email in emergency\")\r\n        send_email(\r\n            f\"Urgent Help Needed at {location}\",\r\n            f\"This is an emergency situation at {location}. Immediate assistance is required. Please send help as soon as possible to address the critical situation.\",\r\n            \"arkodeep3404@gmail.com\",\r\n        )\r\n        return \"emergency help email sent successfully\"\r\n\r\n    await ctx.connect(auto_subscribe=AutoSubscribe.AUDIO_ONLY)\r\n    participant = await ctx.wait_for_participant()\r\n\r\n    # agent = multimodal.MultimodalAgent(\r\n    #     model=openai.realtime.RealtimeModel.with_azure(\r\n    #         azure_deployment=os.getenv(\"AZURE_OPENAI_MODEL_DEPLOYMENT\"),\r\n    #         azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\r\n    #         api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\r\n    #         api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\r\n    #         voice=\"alloy\",\r\n    #         temperature=0.8,\r\n    #         instructions=\"You are a helpful assistant who has access to emergency_email function to send emails in emergency\",\r\n    #         turn_detection=openai.realtime.ServerVadOptions(\r\n    #             threshold=0.6, prefix_padding_ms=200, silence_duration_ms=500\r\n    #         ),\r\n    #     ),\r\n    #     fnc_ctx=fnc_ctx,\r\n    # )\r\n\r\n    agent = multimodal.MultimodalAgent(\r\n        model=openai.realtime.RealtimeModel(\r\n            voice=\"alloy\",\r\n            temperature=0.8,\r\n            instructions=\"You are a helpful assistant\",\r\n            turn_detection=openai.realtime.ServerVadOptions(\r\n                threshold=0.6, prefix_padding_ms=200, silence_duration_ms=500\r\n            ),\r\n        ),\r\n        fnc_ctx=fnc_ctx,\r\n    )\r\n\r\n    agent.start(ctx.room, participant)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    cli.run_app(WorkerOptions(entrypoint_fnc=entrypoint, worker_type=WorkerType.ROOM))\r\n```\r\n\r\nanybody knows why????",
      "state": "closed",
      "author": "arkodeep3404",
      "author_type": "User",
      "created_at": "2024-10-21T15:06:57Z",
      "updated_at": "2025-02-21T09:39:46Z",
      "closed_at": "2025-01-06T07:07:41Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/964/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/964",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/964",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:12.665905",
      "comments": [
        {
          "author": "GergesBernaba1",
          "body": "i think this is the same error:\r\n\r\n ERROR livekit.plugins.openai.realtime - OpenAI S2S error {'type': 'error', 'event_id': 'event_ANGkyIaX34YNPy9NQphGm', 'error': {'type': 'invalid_request_error', 'code': 'access_not_enabled', 'message': \"Your organization does not have access to the Realtime API. W",
          "created_at": "2024-10-28T10:15:47Z"
        },
        {
          "author": "davidzhao",
          "body": "this should no longer be happening",
          "created_at": "2025-01-06T07:07:37Z"
        },
        {
          "author": "shubham-scaletech",
          "body": "Hey @davidzhao Just stumbled upon this issue again, if possible can you give any clarity on why this should no longer be happening? Any help is appreciated.\nHere is the error:\n```\n2025-02-18 18:38:17,302 - ERROR livekit.plugins.openai.realtime - OpenAI S2S error {'type': 'error', 'event_id': 'event_",
          "created_at": "2025-02-21T09:39:43Z"
        }
      ]
    },
    {
      "issue_number": 1539,
      "title": "OpenAI Realtime Miss some first voice words on Phone.",
      "body": "When OpenAI Realtime initially establishes a connection, Open says something first, and the user misses the first few words. After I upgraded the dependencies to the latest version, the situation improved, and now only two words are missed. This issue only occurs on mobile browsers, not on desktop browsers.\n\nThe dependency versions are as follows:\n```\n- livekit-0.20.1\n- livekit-agents-0.12.15\n- livekit-plugins-turn-detector-0.4.2\n- livekit-protocol-0.9.0\n- livekit-plugins-openai==0.11.0\n```\n\n```\n    agent = MultimodalAgent(model=model, fnc_ctx=fnc_ctx, chat_ctx=chat_ctx)\n    agent.start(ctx.room, participant)\n    await asyncio.sleep(1)  \n    agent.generate_reply()\n```\n\n![Image](https://github.com/user-attachments/assets/025aa271-d13c-4c2f-9032-45e26a0af62a)\nSimilar to the content in the screenshot, the user can only hear the beginning of \"interview will focus...\"\n",
      "state": "open",
      "author": "johnson7788",
      "author_type": "User",
      "created_at": "2025-02-21T09:05:10Z",
      "updated_at": "2025-02-21T09:09:52Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1539/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1539",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1539",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:12.920317",
      "comments": []
    },
    {
      "issue_number": 1533,
      "title": "Deepgram's keyterms should be keyterm, not the plural",
      "body": "<!--\nHello! Thanks for taking the time to file a bug report.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already reported this issue.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n-->\nlivekit-plugins-deepgram = \"0.6.19\"\n\nSee: https://developers.deepgram.com/docs/keyterm\n\nIt's in `SpeechStream._connect_ws`:\n\n```python3\n    async def _connect_ws(self) -> aiohttp.ClientWebSocketResponse:\n        live_config: dict[str, Any] = {\n            \"model\": self._opts.model,\n            \"punctuate\": self._opts.punctuate,\n            \"smart_format\": self._opts.smart_format,\n            \"no_delay\": self._opts.no_delay,\n            \"interim_results\": self._opts.interim_results,\n            \"encoding\": \"linear16\",\n            \"vad_events\": True,\n            \"sample_rate\": self._opts.sample_rate,\n            \"channels\": self._opts.num_channels,\n            \"endpointing\": False\n            if self._opts.endpointing_ms == 0\n            else self._opts.endpointing_ms,\n            \"filler_words\": self._opts.filler_words,\n            \"profanity_filter\": self._opts.profanity_filter,\n        }\n        if self._opts.keywords:\n            live_config[\"keywords\"] = self._opts.keywords\n        if self._opts.keyterms:\n            live_config[\"keyterms\"] = self._opts.keyterms  # <-- should be `keyterm`, not `keyterms`\n\n        if self._opts.language:\n            live_config[\"language\"] = self._opts.language\n```",
      "state": "closed",
      "author": "wdhwg001",
      "author_type": "User",
      "created_at": "2025-02-20T10:56:12Z",
      "updated_at": "2025-02-21T07:30:30Z",
      "closed_at": "2025-02-21T07:30:30Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1533/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1533",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1533",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:12.920340",
      "comments": []
    },
    {
      "issue_number": 1370,
      "title": "assistant.say() called within a before_llm_callback is not played out until after the llm processing of the trun",
      "body": "if I have a before_llm_callback function that does a long outgoing dependency service call. I want to be able to have it say something like \"Let me check\", \"Give me one second\" while the processing is happening. However, the assistant.say() is not played until after the turn is complete (after the LLM response is played out.)",
      "state": "closed",
      "author": "norman-plannerd",
      "author_type": "User",
      "created_at": "2025-01-13T18:55:27Z",
      "updated_at": "2025-02-19T12:26:00Z",
      "closed_at": "2025-02-12T01:52:08Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1370/reactions",
        "total_count": 3,
        "+1": 3,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1370",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1370",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:12.920350",
      "comments": [
        {
          "author": "samfindlay-lyngo",
          "body": "I would like to boost this. I am also trying to implement some Backchannelling with livekit and am encountering this same issue.",
          "created_at": "2025-01-14T00:15:06Z"
        },
        {
          "author": "joeylin",
          "body": "I have this issue too",
          "created_at": "2025-01-14T01:08:20Z"
        },
        {
          "author": "longcw",
          "body": "When running the `before_llm_callback` the speech is already in processing, so the speech from `say` will be queued to after it. There will be a new version to handle this case. But before that if you want to say a filler message before every LLM answer, a solution is to create a custom `LLMStream` ",
          "created_at": "2025-01-14T03:09:44Z"
        },
        {
          "author": "longcw",
          "body": "pr for this feature: https://github.com/livekit/agents/pull/1460",
          "created_at": "2025-02-07T09:11:30Z"
        },
        {
          "author": "longcw",
          "body": "close this one as the feature is supported.",
          "created_at": "2025-02-12T01:52:06Z"
        }
      ]
    },
    {
      "issue_number": 1454,
      "title": "Audio Stuttering in LiveKit TTS Streaming",
      "body": "I have set up a LiveKit-based TTS streaming service, and overall, it works well. However, there’s a problem: when the agent responds, the audio starts clearly, but after some time, it begins to stutter, as if the internet connection is dropping—although this is not the case.\n\nIt feels like WebSocket packets are being lost during transmission. I initially thought switching to the Opus codec might help, but it does not work correctly.\n\nWhat settings or configurations can be adjusted to improve the stability of the audio stream?\n",
      "state": "closed",
      "author": "utya",
      "author_type": "User",
      "created_at": "2025-02-06T14:44:11Z",
      "updated_at": "2025-02-19T11:56:33Z",
      "closed_at": "2025-02-19T11:56:31Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1454/reactions",
        "total_count": 5,
        "+1": 4,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 1
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1454",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1454",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:13.160479",
      "comments": [
        {
          "author": "shivadharmi",
          "body": "I also had the same issue with OpenAI TTS. I'm using the default config.",
          "created_at": "2025-02-10T15:07:30Z"
        },
        {
          "author": "utya",
          "body": "I switched to elevenlabs. All good",
          "created_at": "2025-02-10T15:25:57Z"
        },
        {
          "author": "theomonnom",
          "body": "Hey, this should have been fixed by https://github.com/livekit/agents/pull/1494",
          "created_at": "2025-02-19T11:56:31Z"
        }
      ]
    },
    {
      "issue_number": 1407,
      "title": "Wake word for agent",
      "body": "Hey, I want to implement a wake word so the agent only speaks when the wake word is said first. I can think of 2 ways to do this:\n\n1. Custom module for VoicePipelineAgent which is present either before STT or after (Depending on how wake word detection is implemented)\n2. A if check in before_llm_cb and if not the wake word, then skip\n\nI think the first option is more robust and scalable but I do not know if it is possible without tinkering the livekit codebase. \n\nFor the second one, is there a way to skip rest of the pipeline from before_llm_cb - such that LLM call and TTS is skipped?",
      "state": "open",
      "author": "sudo-prakhar",
      "author_type": "User",
      "created_at": "2025-01-24T02:39:48Z",
      "updated_at": "2025-02-18T20:02:27Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1407/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1407",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1407",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:13.359732",
      "comments": [
        {
          "author": "joeylin",
          "body": "I think the wakeword function is better placed on iot devices, it needs to run continuously. For example: https://docs.espressif.com/projects/esp-sr/en/latest/esp32s3/wake_word_engine/README.html",
          "created_at": "2025-01-24T05:23:48Z"
        },
        {
          "author": "sudo-prakhar",
          "body": "I want to use it for a web app, not an IoT device",
          "created_at": "2025-01-24T20:01:25Z"
        },
        {
          "author": "yepher",
          "body": "Once you speak the wake word, how long does the agent listen for? is the agent listening continually after the wake word is spoken or only until End of Turn?",
          "created_at": "2025-02-04T03:13:32Z"
        },
        {
          "author": "yepher",
          "body": "Here is an IoT example:\nhttps://x.com/shayneparlo/status/1890521986075328949",
          "created_at": "2025-02-18T20:02:25Z"
        }
      ]
    },
    {
      "issue_number": 1511,
      "title": "Stream TTS can't  output PipelineTTSMetrics",
      "body": "**description:**\nStream TTS service can't output PipelineTTSMetrics,for example deepgram、elevenlabs、etc. but,Chunked TTS service can output PipelineTTSMetrics, for example openai、azure.\nI read the underlying source code，i found Stream TTS service not emit(metrics_collected). Chunked TTS service is wrapped StreamAdapter，emit(metrics_collected).\n\n**test_code:**\n```Python\nimport asyncio\nimport logging\nimport os\n\nfrom dotenv import load_dotenv\nfrom livekit import rtc\nfrom livekit.agents import (\n    AutoSubscribe,\n    JobContext,\n    JobProcess,\n    WorkerOptions,\n    cli,\n    llm,\n    metrics,\n)\nfrom livekit.agents.pipeline import VoicePipelineAgent\nfrom livekit.plugins import deepgram, openai, silero\nfrom py_zero.config import load_config\nfrom voice_agent.config import Config\n\nload_dotenv()\nlogger = logging.getLogger(\"voice-assistant\")\n\n\ndef prewarm(proc: JobProcess):\n    proc.userdata[\"vad\"] = silero.VAD.load()\n\n\nasync def entrypoint(ctx: JobContext):\n    config_name = os.environ.get(\"CONFIG_NAME\", \"etc/config.yaml\")\n    cfg = load_config(config_name, Config)\n\n    initial_ctx = llm.ChatContext().append(\n        role=\"system\",\n        text=(\n            \"You are a voice assistant created by LiveKit. Your interface with users will be voice. \"\n            \"You should use short and concise responses, and avoiding usage of unpronouncable punctuation.\"\n        ),\n    )\n\n    logger.info(f\"connecting to room {ctx.room.name}\")\n    await ctx.connect(auto_subscribe=AutoSubscribe.AUDIO_ONLY)\n\n    # wait for the first participant to connect\n    participant = await ctx.wait_for_participant()\n    logger.info(f\"starting voice assistant for participant {participant.identity}\")\n\n    agent = VoicePipelineAgent(\n        vad=ctx.proc.userdata[\"vad\"],\n        stt=deepgram.STT(model=\"nova-3-general\", api_key=cfg.deepgram.key),\n        llm=openai.LLM(api_key=cfg.openai.key),\n        tts=deepgram.TTS(api_key=cfg.deepgram.key),\n        chat_ctx=initial_ctx,\n    )\n\n    agent.start(ctx.room, participant)\n\n    usage_collector = metrics.UsageCollector()\n\n    @agent.on(\"metrics_collected\")\n    def _on_metrics_collected(mtrcs: metrics.AgentMetrics):\n        metrics.log_metrics(mtrcs)\n        usage_collector.collect(mtrcs)\n\n    async def log_usage():\n        summary = usage_collector.get_summary()\n        logger.info(f\"Usage: ${summary}\")\n\n    ctx.add_shutdown_callback(log_usage)\n\n    # listen to incoming chat messages, only required if you'd like the agent to\n    # answer incoming messages from Chat\n    chat = rtc.ChatManager(ctx.room)\n\n    async def answer_from_text(txt: str):\n        chat_ctx = agent.chat_ctx.copy()\n        chat_ctx.append(role=\"user\", text=txt)\n        stream = agent.llm.chat(chat_ctx=chat_ctx)\n        await agent.say(stream)\n\n    @chat.on(\"message_received\")\n    def on_chat_received(msg: rtc.ChatMessage):\n        if msg.message:\n            asyncio.create_task(answer_from_text(msg.message))\n\n    await agent.say(\"Hey, how can I help you today?\", allow_interruptions=True)\n\n\nif __name__ == \"__main__\":\n    cli.run_app(\n        WorkerOptions(\n            entrypoint_fnc=entrypoint,\n            prewarm_fnc=prewarm,\n            api_key=\"you api_key\",\n            api_secret=\"you_secret\",\n            ws_url=\"you ws_url\",\n        ),\n    )\n",
      "state": "closed",
      "author": "wuqiong818",
      "author_type": "User",
      "created_at": "2025-02-17T11:31:30Z",
      "updated_at": "2025-02-18T12:50:45Z",
      "closed_at": "2025-02-18T12:50:45Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1511/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1511",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1511",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:13.594582",
      "comments": [
        {
          "author": "wuqiong818",
          "body": "@typester @noahlt @dsa @nfma \n",
          "created_at": "2025-02-18T07:09:51Z"
        }
      ]
    },
    {
      "issue_number": 1512,
      "title": "`JobContext.add_shutdown_callback` incorrectly tests for number of arguments in `callback` callable",
      "body": "When a `callback` is a bound method, the expression `callback.__code__.co_argcount` has one extra argument, the `self`. So the test is incorrect in \"bound method\" cases.\n\nExample:\n```python\nclass Example:\n    async def aclose(self):\n        pass\n\nexample = Example()\ncallback = example.aclose\nprint(callback.__code__.co_argcount)  # 1\n```\nYour code:\n```python\n    def add_shutdown_callback(\n        self,\n        callback: Union[\n            Callable[[], Coroutine[None, None, None]],\n            Callable[[str], Coroutine[None, None, None]],\n        ],\n    ) -> None:\n        \"\"\"\n        Add a callback to be called when the job is shutting down.\n        Optionally the callback can take a single argument, the shutdown reason.\n        \"\"\"\n        if callback.__code__.co_argcount > 0:\n            self._shutdown_callbacks.append(callback)  # type: ignore\n        else:\n\n            async def wrapper(_: str) -> None:\n                await callback()  # type: ignore\n\n            self._shutdown_callbacks.append(wrapper)\n```\nappends the callback \"as is\" into the list, and later calls it like:\n```python\ncallback(\"reason\")\n```\nwhich causes error `TypeError: Example.aclose() takes 1 positional argument but 2 were given`",
      "state": "open",
      "author": "tvrtkos",
      "author_type": "User",
      "created_at": "2025-02-18T10:51:28Z",
      "updated_at": "2025-02-18T10:51:28Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1512/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1512",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1512",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:13.818687",
      "comments": []
    },
    {
      "issue_number": 1353,
      "title": "protobuf and types-protobuf dependencies in Python are inconsistent",
      "body": "<!--\r\nHello! Thanks for taking the time to file a bug report.\r\n\r\nBefore creating this issue, we kindly ask that you use the search functionality\r\nto see if anyone else has already reported this issue.\r\nPlease include details such as environment, package versions, minimal examples,\r\nand error logs, if applicable.\r\n-->\r\n\r\nThe `setup.py` has the following dependency bounds:\r\n```\r\n\"protobuf>=3\",\r\n\"types-protobuf>=4,<5\",\r\n```\r\nwhich were introduced in https://github.com/livekit/agents/pull/198.\r\n\r\nWhat version(s) of protobuf does the library actually support? I'd like to use this package in a project that requires `protobuf>=5` which it looks like `library-agents` should support, but the `type-protobuf<5` upper-bound is too restrictive.",
      "state": "open",
      "author": "ddeville",
      "author_type": "User",
      "created_at": "2025-01-09T23:59:03Z",
      "updated_at": "2025-02-17T23:46:33Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1353/reactions",
        "total_count": 2,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 2
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1353",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1353",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:13.818709",
      "comments": [
        {
          "author": "flyoozes",
          "body": "Any resolution to this? Also facing it as I need my agent to send data via gRPC",
          "created_at": "2025-02-17T23:46:32Z"
        }
      ]
    },
    {
      "issue_number": 1440,
      "title": "eou.py - wrong messages order",
      "body": "In the code [here](https://github.com/livekit/agents/blob/84c2e90d6be288862a51b40329333b96179bb136/livekit-plugins/livekit-plugins-turn-detector/livekit/plugins/turn_detector/eou.py#L150) you will see a for loop in messages.\nHowever, the order seems to be off.:\nThe conversation goes:\n\n> Assitanat: Hi\n> User: One sec please.\n> Assistant: How can I help you?\n> User:  So, what's up?\n\nBut if I print out the messages like this:\n```\nfor msg in chat_ctx.messages:\n            if msg.role not in (\"user\", \"assistant\"):\n                continue\n            print(msg)\n```\nthe output is:\n```\nChatMessage(role='assistant', id='item_635c676ce586', name=None, content='Hi', tool_calls=None, tool_call_id=None, tool_exception=None)\nChatMessage(role='assistant', id='item_16c6354fb8a6', name=None, content='How can I help you?', tool_calls=None, tool_call_id=None, tool_exception=None)\nChatMessage(role='user', id='item_53a0d796f569', name=None, content='One sec please.So, what's up?', tool_calls=None, tool_call_id=None, tool_exception=None)\n```\nAnd for the turn_decoder this will show the wrong message order.",
      "state": "open",
      "author": "mokra",
      "author_type": "User",
      "created_at": "2025-02-02T11:26:24Z",
      "updated_at": "2025-02-17T06:40:08Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1440/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1440",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1440",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:14.043697",
      "comments": [
        {
          "author": "davidzhao",
          "body": "how do you reproduce this? could you share a minimal repro?",
          "created_at": "2025-02-17T06:40:07Z"
        }
      ]
    },
    {
      "issue_number": 1458,
      "title": "Proper approach to stop and restart the VoicePipelineAgent",
      "body": "<!--\nHello! Thanks for taking the time to ask a question.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already asked this question.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n\nFeel free to join us in the #agents channel on our Slack, and ask your question\nthere to get quicker help from us and the community:\n\nhttps://livekit.io/join-slack\n-->\nHi team,\n\nWe are creating a call receptionist AI with a function where the AI makes an outbound SIP call to invite someone into the room.\n\nSo, we need to \"pause\" the agent until the outbound call hangs up, but we couldn't figure out how to do this without using private fields.\n\nIt's that the `await agent.aclose()` of `VoicePipelineAgent` doesn't really close the agent, the `_main_atask`, STT and VAD are still running, and there's no practical way to restart the agent.\n\n```python3\n    async def aclose(self) -> None:\n        \"\"\"Close the voice assistant\"\"\"\n        if not self._started:\n            return\n\n        self._room.off(\"participant_connected\", self._on_participant_connected)\n        await self._deferred_validation.aclose()\n```\n\nAlso, it doesn't reset the `_started`, and the `_deferred_validation` will not be reinitiated by the `start()`.\n\nQuitting the local participant could be a solution, but it's also a bit clunky. In this way, we need a dummy participant in the room for event handling, as the room should be deleted when the main participant leaves.\n\nDo you have any recommendations for handling this approach?\n\nI'm happy to make a PR for the first approach, which involves aclose an agent cleanly for reopening.",
      "state": "open",
      "author": "wdhwg001",
      "author_type": "User",
      "created_at": "2025-02-07T01:12:20Z",
      "updated_at": "2025-02-16T02:06:22Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1458/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1458",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1458",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:14.290293",
      "comments": [
        {
          "author": "narendra-bluebash",
          "body": "I have a solution DM  me on linkedin:-  https://www.linkedin.com/in/narendra1721/",
          "created_at": "2025-02-13T06:59:12Z"
        },
        {
          "author": "longcw",
          "body": "Stop and restart the agent is a solution and we should fix it soon. I am just wondering if you can add an Event to wait for the participant join the room or the call hangs up before starting the agent, so that you can do something like\n```python\nparticipant_joined_fut = asyncio.Future()\nagent = Agen",
          "created_at": "2025-02-15T07:20:31Z"
        },
        {
          "author": "wdhwg001",
          "body": "Setting participant permission could work, but it would require special handling if an egress track is started.\n\nawaiting a future in function call can be a bit more tricky, as I need to make sure the function call won't be interrupted.",
          "created_at": "2025-02-15T08:17:42Z"
        },
        {
          "author": "narendra-bluebash",
          "body": "bro DM me I have a solutiion:  https://www.linkedin.com/in/narendra1721/",
          "created_at": "2025-02-15T10:14:02Z"
        },
        {
          "author": "wdhwg001",
          "body": "Hi @narendra-bluebash I've seen your workaround in my email, thanks for providing the workaround!\n\nYes, I agree that setting `CanSubscribe` to false can force the agent to unsubscribe the primary participant. But I feel that this can be a overkill since this should be an internal function of the age",
          "created_at": "2025-02-15T12:15:41Z"
        }
      ]
    },
    {
      "issue_number": 1503,
      "title": "_main_task gets a RuntimeError if it says something in before_llm_cb without waiting for the handle and we interrupt it",
      "body": "<!--\nHello! Thanks for taking the time to file a bug report.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already reported this issue.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n-->\nlivekit-agent version: 0.12.13\n\nIt's that if in a `before_llm_cb` we do:\n```python3\nawait agent.say(backchannel_str, allow_interruptions=True)\n```\n\nwithout waiting for the response, as otherwise we'll first wait for the speech then wait for the llm. However, if this got interrupted, `_main_task` will throw an error:\n```\n2025-02-15 12:25:51,603 - ERROR livekit.agents.pipeline - Error in _main_task\nTraceback (most recent call last):\n  File \".venv/lib/python3.12/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \".venv/lib/python3.12/site-packages/livekit/agents/pipeline/pipeline_agent.py\", line 684, in _main_task\n    await self._play_speech(speech)\n  File \".venv/lib/python3.12/site-packages/livekit/agents/pipeline/pipeline_agent.py\", line 840, in _play_speech\n    play_handle = synthesis_handle.play()\n                  ^^^^^^^^^^^^^^^^^^^^^^^\n  File \".venv/lib/python3.12/site-packages/livekit/agents/pipeline/agent_output.py\", line 70, in play\n    raise RuntimeError(\"synthesis was interrupted\")\n```\n\nThis is because in `VoicePipelineAgent._play_speech`:\n```python3\n        await self._agent_publication.wait_for_subscription()\n\n        synthesis_handle = speech_handle.synthesis_handle\n        if synthesis_handle.interrupted:  # <-- we check the interruption here\n            return\n\n        user_question = speech_handle.user_question\n\n        # wait for all pre-added nested speech to be played\n        while speech_handle.nested_speech_handles:\n            await nested_speech_played.wait()  # <-- but it's interrupted here\n\n        await playing_lock.acquire()\n        play_handle = synthesis_handle.play()  # <-- so this will raise a RuntimeError\n        join_fut = play_handle.join()\n```",
      "state": "closed",
      "author": "wdhwg001",
      "author_type": "User",
      "created_at": "2025-02-15T05:40:50Z",
      "updated_at": "2025-02-16T02:04:57Z",
      "closed_at": "2025-02-16T02:04:57Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1503/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "longcw"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1503",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1503",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:14.605299",
      "comments": [
        {
          "author": "longcw",
          "body": "Thanks for debugging this. Here is a fix https://github.com/livekit/agents/pull/1504",
          "created_at": "2025-02-15T07:04:24Z"
        }
      ]
    },
    {
      "issue_number": 1471,
      "title": "Is it possible to spin up agents with dynamic parameters?",
      "body": "Hi,\nIs it possible for us to spin up agent with custom parameters?\n\nFor example, I would like to spin up an agent with a sessionId or some sort of unique identifier so that when the model call the function, it will insert that specific unique Id.\n\nAnother use case is to spin up an agent, with customised prompt just for that one session.\n\nThanks!",
      "state": "closed",
      "author": "yos1p",
      "author_type": "User",
      "created_at": "2025-02-10T07:46:51Z",
      "updated_at": "2025-02-14T00:28:42Z",
      "closed_at": "2025-02-14T00:28:42Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1471/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1471",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1471",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:14.837127",
      "comments": [
        {
          "author": "jayeshp19",
          "body": "There's an unique job id for each job - https://github.com/livekit/agents/blob/main/livekit-agents/livekit/agents/worker.py#L706",
          "created_at": "2025-02-12T05:00:39Z"
        },
        {
          "author": "davidzhao",
          "body": "you can dispatch agents explicitly and setting the job metadata field: https://docs.livekit.io/agents/build/dispatch/#dispatch-via-api",
          "created_at": "2025-02-14T00:28:39Z"
        }
      ]
    },
    {
      "issue_number": 1481,
      "title": "Generate Reply for OpenAI real-time - unexpected behaviour",
      "body": "I'm using openAI realtime model and I've noticed a regression in the model behavior in the latest version of livekit-agents (this wasn't an issue in 0.12.8). When I trigger the agent to start the conversation with a first message, using generate_reply (in the latest version of the package) or calling session.conversation.item.create + session.response.create, the agent starts with a generic message such as \"Hello, how can I help you\" and completely disregards the system instructions. If I reply however, the subsequent message will be relevant and aligned with the system instructions.\n\nIt feels like that first message is being generated without the system instructions being passed in the call to openAI?",
      "state": "closed",
      "author": "guillaumeboniface",
      "author_type": "User",
      "created_at": "2025-02-11T18:48:15Z",
      "updated_at": "2025-02-12T06:05:48Z",
      "closed_at": "2025-02-12T06:05:48Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1481/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1481",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1481",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:16.937880",
      "comments": [
        {
          "author": "guillaumeboniface",
          "body": "I've investigated this more by trying different version of the package. I realised that the problem is actually coming from the openai-plugin and not livekit-agents. It appears in version 0.10.17 of livekit-plugins-openai",
          "created_at": "2025-02-11T21:48:46Z"
        },
        {
          "author": "longcw",
          "body": "Here is a fix for the issue https://github.com/livekit/agents/pull/1469",
          "created_at": "2025-02-12T01:41:06Z"
        }
      ]
    },
    {
      "issue_number": 1470,
      "title": "Cannot use o3-mini model",
      "body": "<!--\nHello! Thanks for taking the time to file a bug report.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already reported this issue.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n-->\n\nWhen we use the o3-mini model of open ai we get an error \n\nlivekit.agents._exceptions.APIStatusError: Error code: 400 - {'error': {'message': \"Unsupported parameter: 'temperature' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}\n\nWe will have to update LLM plugin to exclude temperature in the case of o3 and other models which does not support temperature parameter. ",
      "state": "closed",
      "author": "nuttyroll",
      "author_type": "User",
      "created_at": "2025-02-10T06:15:16Z",
      "updated_at": "2025-02-11T06:38:15Z",
      "closed_at": "2025-02-11T06:38:15Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1470/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1470",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1470",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:17.172749",
      "comments": []
    },
    {
      "issue_number": 1473,
      "title": "Unable to reconnect -  Agent",
      "body": "There is a problem in the Python SDK related to reconnection. The agent can reconnect successfully only in some cases. During reconnection, the RTC Python SDK will create up to 10 reconnection attempts in rapid sequence and this sometimes fails.\n\nPlease provide suggestions to fix the issue.",
      "state": "open",
      "author": "royatanu94",
      "author_type": "User",
      "created_at": "2025-02-10T11:05:08Z",
      "updated_at": "2025-02-10T11:05:08Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1473/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1473",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1473",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:17.172769",
      "comments": []
    },
    {
      "issue_number": 1155,
      "title": "I am facing an issue when using Azure OpenAI in function calling",
      "body": "I encountered a problem where Azure OpenAI fails during function calling. Interestingly, the same functionality works correctly with OpenAI's function calling.\r\n\r\nWhen this error occurs, OpenAI does not respond or speak, which is critical for my use case.\r\n\r\n*Observed Behavior*:\r\nWhen an exception is raised in Azure OpenAI function calling, no response is emitted, causing the application to remain silent.\r\nProposed Solution:\r\nTo address this issue, I implemented a solution in which any exception raised is explicitly emitted. This allows my code to:\r\n\r\n*Capture the error effectively.*:\r\nUse the voicepipeline.agent.say method to speak out the error, ensuring that the user is informed audibly when an error occurs.\r\n*Expected Behavior*:\r\nThe application should capture the error seamlessly and respond audibly via the voicepipeline.agent.say method when an exception occurs.\r\n\r\n",
      "state": "open",
      "author": "narendra-bluebash",
      "author_type": "User",
      "created_at": "2024-12-01T13:26:38Z",
      "updated_at": "2025-02-09T21:44:43Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1155/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1155",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1155",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:17.172776",
      "comments": [
        {
          "author": "narendra-bluebash",
          "body": "Error in _stream_synthesis_task\r\nTraceback (most recent call last):\r\n  File \"/home/narendras/.cache/pypoetry/virtualenvs/kickcall-agents-dBnRIQRQ-py3.12/lib/python3.12/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\r\n    return await fn(*args, **kwargs)\r\n           ^^^^^^^^^^^^",
          "created_at": "2024-12-02T05:05:17Z"
        },
        {
          "author": "jayeshp19",
          "body": "Hi @narendra-bluebash,  Is there a way to reproduce this? are you trying to call tools parallelly?",
          "created_at": "2024-12-04T21:36:43Z"
        },
        {
          "author": "narendra-bluebash",
          "body": "Hi @jayeshp19 ,\r\nI'm working with the tool \"calling,\" and it works fine with OpenAI, but when using Microsoft OpenAI, sometimes it works well, and other times I get an error like \"Error in _stream_synthesis_task.\"\r\n\r\nI believe this happens when the tool name, like \"book_appointment,\" is triggered. T",
          "created_at": "2024-12-10T11:16:31Z"
        },
        {
          "author": "longwQaQ",
          "body": "I have encountered the same problem.",
          "created_at": "2025-01-12T15:40:03Z"
        },
        {
          "author": "robertvy",
          "body": "facing a similar issue on Azure with function calling. Working with Azure deployed GPT-4o but not with GPT-4o mini where I regularly get this error when LLM tries to call a function. this is with openai plugin version v0.10.16.",
          "created_at": "2025-02-09T21:44:42Z"
        }
      ]
    },
    {
      "issue_number": 995,
      "title": "Interruptions during function execution can cause tool_result message to be orphaned causing agent to fall silent.",
      "body": "First off, love what you're doing. I am struggling to fix the following issue, which I can recreate consistently. \r\n\r\n\r\nWhen a couple of function executions are interrupted in relatively quick succession this causes the agent to fall silent:\r\n\r\nanthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'messages.0: `tool_result` block(s) provided when previous message does not contain any `tool_use` blocks'}} {\"pid\": 18061, \"job_id\": \"AJ_DM5he9c6Fvki\"}\r\n\r\nI believe this is because the message history gets corrupted causing the tool blocks to be decoupled.\r\n\r\nThanks for any help in advance :)\r\n",
      "state": "open",
      "author": "CrackheadCode",
      "author_type": "User",
      "created_at": "2024-10-28T19:16:22Z",
      "updated_at": "2025-02-09T12:35:34Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 11,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/995/reactions",
        "total_count": 4,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 4
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/995",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/995",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:17.375549",
      "comments": [
        {
          "author": "laag-deploy",
          "body": "i got this error too occasionally, please fix it",
          "created_at": "2024-12-17T23:00:34Z"
        },
        {
          "author": "jenfic",
          "body": "similar error. see the trace below:\n\nERROR asyncio - _GatheringFuture exception was never retrieved\nfuture: <_GatheringFuture finished exception=CancelledError()>\nTraceback (most recent call last):\n  File \".../lib/python3.12/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    r",
          "created_at": "2025-01-28T19:57:47Z"
        },
        {
          "author": "sunilvb",
          "body": "Possible Solution\n\nTo fix the HTTP 400 Bad Request error with the message \"Requests which include tool_use or tool_result blocks must define tools,\" you need to ensure the following:\n\nDefine Tools: Include the necessary tool definitions in your API request.\n\nCorrect JSON Structure: Ensure the tools ",
          "created_at": "2025-01-28T20:12:42Z"
        },
        {
          "author": "eshamanideep",
          "body": "Yeah this happens because livekit just sets fnc_ctx = None when they dont want the LLM to not call a tool instead of setting tool_choice",
          "created_at": "2025-01-30T06:00:56Z"
        },
        {
          "author": "davidzhao",
          "body": "@jenfic do you happen to have a reproduction for this?\n\n@eshamanideep do you mind elaborating on what the expected behavior would be?",
          "created_at": "2025-01-30T21:59:14Z"
        }
      ]
    },
    {
      "issue_number": 1435,
      "title": "Improve MultiModal Agent with turn detection and noise cancellation",
      "body": "<!--\nHello! Thanks for taking the time to ask a question.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already asked this question.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n\nFeel free to join us in the #agents channel on our Slack, and ask your question\nthere to get quicker help from us and the community:\n\nhttps://livekit.io/join-slack\n-->\n\nI am using the MultiModal agent to make outbound calls, but I’ve noticed that the model struggles to perform well in noisy environments. This affects transcription accuracy and overall interaction quality. Moreover, there is no turn_detection on the multimodal agent.\n\nWould it be possible to apply server-side noise cancellation and turn_detection in MultiModal agent?",
      "state": "closed",
      "author": "notauserx",
      "author_type": "User",
      "created_at": "2025-01-31T06:06:40Z",
      "updated_at": "2025-02-08T01:38:38Z",
      "closed_at": "2025-02-04T13:46:31Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1435/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1435",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1435",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:17.611331",
      "comments": [
        {
          "author": "cuongpham-1001",
          "body": "Hi @notauserx , are you using python google plugins? I got the same issues when try to setup realtime ai agent with gemini. I haven't that issue when working with google ai and nodejs sdk",
          "created_at": "2025-02-04T05:12:41Z"
        },
        {
          "author": "notauserx",
          "body": "I am using OpenAI's realtime api with python agents.\n\nI am referring to this part, where their is no option for turn_detection. I've read in the slack group that it's work in progress, so maybe it'll be there\n\nhttps://github.com/livekit/agents/blob/84c2e90d6be288862a51b40329333b96179bb136/livekit-ag",
          "created_at": "2025-02-04T13:46:31Z"
        },
        {
          "author": "taqiycarbon",
          "body": "Yes exactly it’s a WIP right now.\n\nThey just updated the VAD which you can now disable and do manually.\n\nSo either you wait or you do turn detection and manually trigger. They updated the article in the doc.",
          "created_at": "2025-02-08T01:38:37Z"
        }
      ]
    },
    {
      "issue_number": 1463,
      "title": "Request to include Job ID in livekit.plugins.turn_detector Logs",
      "body": "Could we add Job ID to the list of parameters logged in the logger associated with the `livekit.plugins.turn_detector` plugin?\n\nExample of a current log : \n```\n{\"message\": \"eou prediction\", \"level\": \"DEBUG\", \"name\": \"livekit.plugins.turn_detector\", \"eou_probability\": \"0.6258791\", \"input\": \"<|im_start|><|assistant|> I appreciate the \n....\n...\n\", \"duration\": 0.15, \"pid\": 10, \"inference\": true, \"timestamp\": \"2025-02-07T16:01:32.115110+00:00\"}\n```\n\nUsing the following version\n`livekit-plugins-turn-detector==0.4.0`\n\nExample of a log containing Job ID, from the Pipeline Agent\n```\n{\"message\": \"speech playout started\", \"level\": \"DEBUG\", \"name\": \"livekit.agents.pipeline\", \"speech_id\": \"bce286d22445\", \"pid\": 27, \"job_id\": \"AJ_nDDbrbRU6jYT\", \"timestamp\": \"2025-02-07T16:01:06.124273+00:00\"}\n```\n\nHaving Job ID included in the Turn Detector logs would allow us to include them while looking through logs associated with a Job ID.\n\nFeel free to recategorize this issue type as a request/enhancement.",
      "state": "open",
      "author": "vramesh1",
      "author_type": "User",
      "created_at": "2025-02-07T18:31:02Z",
      "updated_at": "2025-02-07T18:31:02Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1463/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1463",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1463",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:17.867600",
      "comments": []
    },
    {
      "issue_number": 1450,
      "title": "The links to the example codes are not working.",
      "body": "The links for the example code **Voice Agent using Gemini 2.0 Flash** and **Simple agent that echoes back the last utterance** are not working in the README.",
      "state": "closed",
      "author": "DevRadhy",
      "author_type": "User",
      "created_at": "2025-02-05T12:03:40Z",
      "updated_at": "2025-02-07T06:19:57Z",
      "closed_at": "2025-02-07T06:19:57Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1450/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1450",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1450",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:17.867616",
      "comments": []
    },
    {
      "issue_number": 1449,
      "title": "process for each room took long time to shutdown",
      "body": "I found that sometime a process took very long time to shutdown. So I need to call `job.shutdown()` to close the process. But sometime this function yield this error log\n```\nAssertionError:\nException ignored in: <function FfiHandle.__del__ at 0x106dc3ba0>\nTraceback (most recent call last):\n  File \"/Users/daominhthuc/anaconda3/envs/livekit-agent/lib/python3.11/site-packages/livekit/rtc/_ffi_client.py\", line 90, in __del__\n    self.dispose()\n  File \"/Users/daominhthuc/anaconda3/envs/livekit-agent/lib/python3.11/site-packages/livekit/rtc/_ffi_client.py\", line 99, in dispose\n    assert ffi_lib.livekit_ffi_drop_handle(ctypes.c_uint64(self.handle))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError:\nException ignored in: <function FfiHandle.__del__ at 0x106dc3ba0>\nTraceback (most recent call last):\n  File \"/Users/daominhthuc/anaconda3/envs/livekit-agent/lib/python3.11/site-packages/livekit/rtc/_ffi_client.py\", line 90, in __del__\n    self.dispose()\n  File \"/Users/daominhthuc/anaconda3/envs/livekit-agent/lib/python3.11/site-packages/livekit/rtc/_ffi_client.py\", line 99, in dispose\n    assert ffi_lib.livekit_ffi_drop_handle(ctypes.c_uint64(self.handle))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n```\n",
      "state": "open",
      "author": "Max-Thuc",
      "author_type": "User",
      "created_at": "2025-02-05T04:45:01Z",
      "updated_at": "2025-02-07T03:15:09Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1449/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1449",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1449",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:17.867621",
      "comments": [
        {
          "author": "theomonnom",
          "body": "Hey, can you run `pip freeze` to see which version of python-sdks you're running?",
          "created_at": "2025-02-05T19:23:23Z"
        },
        {
          "author": "Max-Thuc",
          "body": "Hi @theomonnom , this is our version\n```\nlivekit==0.17.4\nlivekit-agents==0.10.0\nlivekit-api==0.6.0\nlivekit-protocol==0.6.0\n```",
          "created_at": "2025-02-07T03:15:07Z"
        }
      ]
    },
    {
      "issue_number": 1444,
      "title": "agent transcriptions cannot be disabled in the frontend - is it a bug?",
      "body": "I'm trying to get transcriptions in the frontend using a component from the example https://docs.livekit.io/agents/voice-agent/transcriptions/\n\nIt works, but I can't disable forwarding the agent transcription to the client in the Agent settings. However, user transcriptions can be disabled\n\n```\nfrom livekit.agents.pipeline import VoicePipelineAgent, AgentTranscriptionOptions\n\nassistant = VoiceAssistant(\n        vad=silero.VAD.load(),\n        stt=deepgram.STT(),\n        llm=openai.LLM(model=\"gpt-4o-mini\"),\n        tts=openai.TTS(),\n        chat_ctx=initial_ctx,\n        transcription=AgentTranscriptionOptions(user_transcription=False, agent_transcription=False)\n    )\n```\n\nWith these settings I don't get user transcription, but I still get agent transcription\n",
      "state": "closed",
      "author": "Andhs-eff",
      "author_type": "User",
      "created_at": "2025-02-04T14:36:07Z",
      "updated_at": "2025-02-06T06:26:24Z",
      "closed_at": "2025-02-06T06:26:24Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1444/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1444",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1444",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:18.065334",
      "comments": [
        {
          "author": "davidzhao",
          "body": "@Andhs-eff yeah this is a bug in the current version. fixed in #1448",
          "created_at": "2025-02-05T03:01:13Z"
        }
      ]
    },
    {
      "issue_number": 1264,
      "title": "TTS Forwarder doesn't clean up pending task on aclose",
      "body": "```\r\n{\"message\": \"Task was destroyed but it is pending!\\ntask: <Task pending name='Task-1350' coro=<TTSSegmentsForwarder._main_task.<locals>._forward_task() running at /app/.venv/lib/python3.12/site-packages/livekit/agents/utils/log.py:16> wait_for=<Future pending cb=[Task.task_wakeup()]>>\", \"level\": \"ERROR\", \"name\": \"asyncio\", \"pid\": 4808, \"job_id\": \"AJ_kdBy2UWgYF7h\", \"timestamp\": \"2024-12-19T21:14:32.253480+00:00\"}\r\n```",
      "state": "closed",
      "author": "martin-purplefish",
      "author_type": "User",
      "created_at": "2024-12-19T21:44:19Z",
      "updated_at": "2025-02-05T21:52:38Z",
      "closed_at": "2025-01-06T22:31:45Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1264/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1264",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1264",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:18.279871",
      "comments": [
        {
          "author": "vramesh1",
          "body": "Hi, I'm still seeing this error with `livekit-agents==0.12.10`, unfortunately.\n\nhere's an example : \n```\n{\"message\": \"Task was destroyed but it is pending!\\ntask: <Task pending name='Task-410' coro=<TTSSegmentsForwarder._main_task.<locals>._forward_task() running at /home/appuser/.local/lib/python3.",
          "created_at": "2025-02-05T21:52:37Z"
        }
      ]
    },
    {
      "issue_number": 1182,
      "title": "Auto-discover new frontend function calls (rpc register, unregister)",
      "body": "I am attempting to build an agent that leverages the openai-realtime voice approach, but have frontend rpc calling be registered & unregistered dynamically... and in the middle of a single user's input. \r\n\r\nFrom the docs: https://docs.livekit.io/agents/voice-agent/function-calling/ is it possible to have auto-discovery of the frontend RPC functions which are loaded. We want to dynamically load frontend actions based on which components are currently on the users screen. (e.g. the \"insert text\" function would only loaded up / shown to the agent if the \"document\" component was rendered, because there would be no way for the function to run unless the document component was available. Similarly the agent shouldn't \"see\" functions which can't be run on the frontend.)\r\n\r\nIdeally, this auto-discovery of frontend actions should be dynamically updated in the middle of an agent run... e.g. the user asks for a document to be created and text to be inserted... the agent flow would be:\r\n\r\n1. user asks \"create a document and insert a poem into it\" with no document UI component loaded\r\n2. agent receives request and sees only 1 action available: \"createDocument\"\r\n3. agent calls \"createDocument\" and waits for the response and re-checks what frontend actions may have been introduced... in this case the \"createDocument\" function created a document component which has an RPC register function... which then surfaces 2 actions available: \"createDocument\" and \"insertText\"\r\n4. the agent would continue operating calling the \"insertText\" function and then voice response",
      "state": "closed",
      "author": "bgeils",
      "author_type": "User",
      "created_at": "2024-12-05T22:09:35Z",
      "updated_at": "2025-02-04T21:54:57Z",
      "closed_at": "2025-02-04T21:54:56Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1182/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1182",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1182",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:18.546502",
      "comments": [
        {
          "author": "bcherry",
          "body": "@bgeils this is a nice idea but not something we're currently planning to integrate at the framework level. I think it would be easy to use participant attributes for this, however. so in the frontend whenever you register/unregister just update a related attribute and then observe those on the agen",
          "created_at": "2025-02-04T21:54:56Z"
        }
      ]
    },
    {
      "issue_number": 835,
      "title": "Sometimes VAD Freezes/Unable to detect speech end",
      "body": "We are encountering a very weird bug where sometimes in conversation, VAD/Agent cannot detect end of speech.. the usual flow is that user starts speaking and we can get live transcripts for it but when they stop there is no OpenAI call or subsequent agent response (even after waiting for long time), the solution here is to add on something more (user speaks one or two more words and then again stop), then it detects the whole speech segment and now agent replies back.\r\n\r\nVery peculiar but annoying bug, Please fix\r\n",
      "state": "open",
      "author": "hari01584",
      "author_type": "User",
      "created_at": "2024-10-04T12:37:21Z",
      "updated_at": "2025-02-04T07:51:54Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 17,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/835/reactions",
        "total_count": 6,
        "+1": 6,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "theomonnom"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/835",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/835",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:18.809738",
      "comments": [
        {
          "author": "martin-purplefish",
          "body": "We're experiencing this too.",
          "created_at": "2024-10-04T17:34:46Z"
        },
        {
          "author": "martin-purplefish",
          "body": "it's strange that I still get the user finished speaking events, but the message never comes.",
          "created_at": "2024-10-04T20:03:37Z"
        },
        {
          "author": "hari01584",
          "body": "Indeed, my team is creating automated interviewing solutions and we are rigorously using live kit, there is few bugs popping up but overall this is amazing",
          "created_at": "2024-10-04T20:14:19Z"
        },
        {
          "author": "theomonnom",
          "body": "Hey, I just took a look at the VAD implementation and I'm quite sure it isn't coming from it.\n\nSo I think something froze inside the VoicePipelineAgent?\n\nCan you share the debug logs of your agent when this is happening? It would be useful to track where the pipeline hangs.",
          "created_at": "2024-10-04T20:47:48Z"
        },
        {
          "author": "martin-purplefish",
          "body": "@theomonnom I'll get some debug logs, but here are some info level ones:\r\n\r\n```\r\n{\"message\": \"Agent state thinking -> speaking\", \"level\": \"INFO\", \"name\": \"livekit.agents.pipeline\", \"pid\": 23642, \"job_id\": \"AJ_6Z4b4mTfh6eR\", \"timestamp\": \"2024-10-04T21:10:32.386400+00:00\"}\r\n{\"message\": \"Agent stopped",
          "created_at": "2024-10-04T21:14:48Z"
        }
      ]
    },
    {
      "issue_number": 1185,
      "title": "Optional values in @llm.ai_callable cause ValueError",
      "body": "**How to replicate**\r\n1. Set tool call params as below:\r\n2. LLM sets this parameter to None\r\n\r\n```\r\n@llm.ai_callable(\r\n    description=\"\"\"\r\n    \"Returns a list of transactions during a specified period and filters...blah blah\r\n    \"\"\"\r\n)\r\nasync def a_tool_call(\r\n    self,\r\n    start_date: Annotated[\r\n        Optional[str],\r\n        llm.TypeInfo(\r\n            description=\"\"\"\r\n                The start date in the format %Y-%m-%d, \r\n                for example, 2020-09-01 for 1st September 2020.\r\n                If you don't think this field is relevant for the question then set this parameter to None.\r\n                \"\"\"\r\n        ),\r\n    ] = None,\r\n...more parameters\r\n``` \r\n\r\n**Expected behaviour**\r\nTool call proceeds as usual with `None` set as a parameter\r\n\r\n**Actual behaviour**\r\nWe receive the following error message and the tool call is now able to proceed\r\n```\r\n2024-11-29 17:34:13,600 - ERROR livekit.plugins.openai.realtime - failed to handle OpenAI S2S message\r\nTraceback (most recent call last):\r\n  File \"/Users/paula.muldoon/dev/ai/ai-livekit-agent/.venv/lib/python3.11/site-packages/livekit/plugins/openai/realtime/realtime_model.py\", line 1038, in _recv_task\r\n    self._handle_response_output_item_done(data)\r\n  File \"/Users/paula.muldoon/dev/ai/ai-livekit-agent/.venv/lib/python3.11/site-packages/livekit/plugins/openai/realtime/realtime_model.py\", line 1341, in _handle_response_output_item_done\r\n    fnc_call_info = _oai_api.create_ai_function_info(\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/paula.muldoon/dev/ai/ai-livekit-agent/.venv/lib/python3.11/site-packages/livekit/agents/llm/_oai_api.py\", line 72, in create_ai_function_info\r\n    sanitized_value = _sanitize_primitive(\r\n                      ^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/paula.muldoon/dev/ai/ai-livekit-agent/.venv/lib/python3.11/site-packages/livekit/agents/llm/_oai_api.py\", line 148, in _sanitize_primitive\r\n    raise ValueError(f\"expected str, got {type(value)}\")\r\n\r\nValueError: expected str, got <class 'NoneType'>\r\n```\r\n\r\nI've managed to print out these lines from `livekit/agents/llm/_oai_api.py`\r\nline 50:\r\n```\r\n\r\n         arg_value = parsed_arguments[arg_info.name]\r\n        print(f\"arg info: {arg_info.name}\")\r\n        print(f\"arg value: {arg_value}\")\r\n        print(f\"arg type: {arg_info.type}\")\r\n```\r\nand the result is:\r\n```\r\narg info: start_date\r\narg value: None\r\narg type: <class 'str'>\r\n```\r\nVersions\r\nlivekit = \"0.18.1\"\r\nlivekit-agents = \"0.11.3\"\r\nlivekit-plugins-openai = \"0.10.7\"\r\nlivekit-protocol = \"0.7.0\"",
      "state": "closed",
      "author": "FiddlersCode",
      "author_type": "User",
      "created_at": "2024-12-06T08:27:28Z",
      "updated_at": "2025-01-31T06:38:35Z",
      "closed_at": "2024-12-12T08:33:55Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1185/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1185",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1185",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:19.046963",
      "comments": [
        {
          "author": "davidzhao",
          "body": "fixed in #1211",
          "created_at": "2024-12-12T08:33:55Z"
        },
        {
          "author": "lomalan",
          "body": "Hey @davidzhao I have the same issue on the livekit-agents = \"0.12.8\"\n\n```\nValue None is optional True\nI'm sanitizing value to_account, None, <class 'str'>, ()\n2025-01-30 16:03:47,060 - ERROR livekit.plugins.openai.realtime - failed to handle OpenAI S2S message\nTraceback (most recent call last):\n  F",
          "created_at": "2025-01-30T17:02:11Z"
        }
      ]
    },
    {
      "issue_number": 1417,
      "title": "How can I set up track subscription permissions",
      "body": "How can I set up track subscription permissions where:\n1. One specific participant (agent) should only be able to subscribe to a specific audio track\n2. All other participants should be able to subscribe to all tracks EXCEPT that specific audio track\n```js\nif (localParticipant && localAudioTrack) {\n    try {\n        // Set default permission to false (deny all by default)\n        localParticipant.setTrackSubscriptionPermissions(false, [\n            // For agent: can only subscribe to localAudioTrack\n            {\n                participantIdentity: getAgentParticipantId(),\n                allowedTrackSids: [localAudioTrack.sid]\n            },\n            // For all other participants: allow all tracks except localAudioTrack\n            {\n                participantIdentity: '*',\n                allowAll: true  // allow all tracks for non-agent participants\n            }\n        ]);\n    } catch (error) {\n        console.error('Error setting track subscription permissions:', error);\n    }\n}\n```",
      "state": "open",
      "author": "boussaidev",
      "author_type": "User",
      "created_at": "2025-01-27T13:58:28Z",
      "updated_at": "2025-01-31T00:06:52Z",
      "closed_at": null,
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1417/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1417",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1417",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:19.263892",
      "comments": [
        {
          "author": "davidzhao",
          "body": "we are missing a couple of APIs from the Python SDK in order to be able to do this",
          "created_at": "2025-01-31T00:06:50Z"
        }
      ]
    },
    {
      "issue_number": 1422,
      "title": "User transcribed text is not cleared when before_llm_cb is returned Flase",
      "body": "Currently, `self._transcribed_text` is not cleared when `before_llm_cb` is returned false. This means that any new transcript will be appended to the \"cancelled\" user text as part of `self._transcribed_text`.\n",
      "state": "closed",
      "author": "s-hamdananwar",
      "author_type": "User",
      "created_at": "2025-01-28T23:24:32Z",
      "updated_at": "2025-01-30T22:01:26Z",
      "closed_at": "2025-01-30T22:01:26Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1422/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "s-hamdananwar"
      ],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1422",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1422",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:19.494363",
      "comments": []
    },
    {
      "issue_number": 1406,
      "title": "Do not allow blank empty content to be sent to Anthropic Claude LLM",
      "body": "# Description\n\nIn some cases, an empty message is sent to the LLM but Anthropic's Claude does not allow that.  It returns `messages.12: all messages must have non-empty content except for the optional final assistant message` error.  \n\n```\n2025-01-21 15:40:05,457 - ERROR livekit.agents.pipeline - Error in _stream_synthesis_task\nTraceback (most recent call last):\n  File \"/Users/noah/livekit-cartesia-claude-deepgram/venv/lib/python3.13/site-packages/livekit/agents/utils/log.py\", line 16, in async_fn_logs\n    return await fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/noah/livekit-cartesia-claude-deepgram/venv/lib/python3.13/site-packages/livekit/agents/pipeline/agent_output.py\", line 273, in _stream_synthesis_task\n    async for seg in tts_source:\n    ...<9 lines>...\n        tts_stream.push_text(seg)\n  File \"/Users/noah/livekit-cartesia-claude-deepgram/venv/lib/python3.13/site-packages/livekit/agents/utils/aio/itertools.py\", line 47, in tee_peer\n    item = await iterator.__anext__()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/noah/livekit-cartesia-claude-deepgram/venv/lib/python3.13/site-packages/livekit/agents/pipeline/pipeline_agent.py\", line 1055, in _llm_stream_to_str_generator\n    async for chunk in stream:\n    ...<7 lines>...\n        yield content\n  File \"/Users/noah/livekit-cartesia-claude-deepgram/venv/lib/python3.13/site-packages/livekit/agents/llm/llm.py\", line 239, in __anext__\n    raise exc from None\n  File \"/Users/noah/livekit-cartesia-claude-deepgram/venv/lib/python3.13/site-packages/livekit/agents/llm/llm.py\", line 149, in _main_task\n    return await self._run()\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/noah/livekit-cartesia-claude-deepgram/venv/lib/python3.13/site-packages/livekit/plugins/anthropic/llm.py\", line 234, in _run\n    raise APIStatusError(\n    ...<4 lines>...\n    )\nlivekit.agents._exceptions.APIStatusError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'messages.12: all messages must have non-empty content except for the optional final assistant message'}} {\"pid\": 9123, \"job_id\": \"AJ_zFDs8T7P9A59\"}\n```\n\n# How to reproduce\nIt seems to be more easily reproducible when there is a lot of background noise.  See details in [this Slack thread](https://livekit-users.slack.com/archives/C07FY8WHGPM/p1737503578871819).",
      "state": "closed",
      "author": "mike-r-mclaughlin",
      "author_type": "User",
      "created_at": "2025-01-23T17:11:42Z",
      "updated_at": "2025-01-30T00:24:11Z",
      "closed_at": "2025-01-30T00:24:11Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1406/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1406",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1406",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:19.494381",
      "comments": [
        {
          "author": "davidzhao",
          "body": "fixed by #1410",
          "created_at": "2025-01-26T00:46:03Z"
        }
      ]
    },
    {
      "issue_number": 1418,
      "title": "PLEASE ADD DEEPSEEK R1 & V3 (REALLY NEED THEM URGENTLY)",
      "body": "<!--\nHello! Thanks for taking the time to file a bug report.\n\nBefore creating this issue, we kindly ask that you use the search functionality\nto see if anyone else has already reported this issue.\nPlease include details such as environment, package versions, minimal examples,\nand error logs, if applicable.\n-->\nPLEASE ADD DEEPSEEK R1 & V3 (REALLY NEED THEM URGENTLY) ",
      "state": "closed",
      "author": "MaheshDhingra",
      "author_type": "User",
      "created_at": "2025-01-28T06:10:43Z",
      "updated_at": "2025-01-29T21:00:27Z",
      "closed_at": "2025-01-29T21:00:27Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1418/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1418",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1418",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:19.711450",
      "comments": [
        {
          "author": "lchavasse",
          "body": "You should be able to using llm=openai.LLM.with_deepseek()\nSee: https://docs.livekit.io/agents/integrations/openai-compatible-llms/\nhttps://github.com/livekit/agents/blob/main/livekit-plugins/livekit-plugins-openai/livekit/plugins/openai/llm.py\nhttps://api-docs.deepseek.com/quick_start/pricing",
          "created_at": "2025-01-28T10:41:53Z"
        }
      ]
    },
    {
      "issue_number": 1425,
      "title": "The training code for EOU model is missing despite being labeled as open-source",
      "body": "Dear Livekit Team,\n\nI can't find the EOU model's training code. I wish to contribute a model for another language (Polish) but all I can find is the weights and different quantizations of the model. To make this model open source the training code and preferably data should be available as well. Can you publish them or point me to where I can find them? \n\nThank you!",
      "state": "closed",
      "author": "jmizgajski",
      "author_type": "User",
      "created_at": "2025-01-29T12:02:42Z",
      "updated_at": "2025-01-29T21:00:00Z",
      "closed_at": "2025-01-29T20:59:59Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1425/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1425",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1425",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:19.929564",
      "comments": [
        {
          "author": "davidzhao",
          "body": "the model is open weight, similar to Llama, Mistral and others. We do not claim that the training process is open source.\n\nthe team is working on multi-lingual support as we speak.",
          "created_at": "2025-01-29T20:59:59Z"
        }
      ]
    },
    {
      "issue_number": 1180,
      "title": "Sentence chunking for Cartesia TTS",
      "body": "<!--\r\nHello! Thanks for taking the time to file a bug report.\r\n\r\nBefore creating this issue, we kindly ask that you use the search functionality\r\nto see if anyone else has already reported this issue.\r\nPlease include details such as environment, package versions, minimal examples,\r\nand error logs, if applicable.\r\n-->\r\nHi, sometimes our LK agent when saying a two sentence phrase will say \"{sentence1} dot {sentence2}\", and in speaking to Cartesia it appears to be because the space at the start of sentence2 is being removed. Also from their [docs](https://docs.cartesia.ai/build-with-sonic/capability-guides/stream-inputs-using-continuations) on streaming inputs:\r\n<img width=\"745\" alt=\"Screenshot 2024-12-05 at 8 51 35 AM\" src=\"https://github.com/user-attachments/assets/55ebdf4a-e448-406c-80c7-3f2305f0a048\">\r\n\r\n\r\n\r\nThis is causing some confusion for our customer's interactions, happy to help or provide additional examples just let me know.",
      "state": "open",
      "author": "cch41",
      "author_type": "User",
      "created_at": "2024-12-05T16:55:22Z",
      "updated_at": "2025-01-28T23:19:08Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1180/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 1
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1180",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1180",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:20.191601",
      "comments": [
        {
          "author": "chongzluong",
          "body": "Hey @cch41, Cartesia dev here - are you still running into this issue?",
          "created_at": "2025-01-28T23:18:54Z"
        }
      ]
    },
    {
      "issue_number": 1421,
      "title": "When i use connect --room <room_name> the agent enters the room and sends the initial message but it is not detected , but when i use the same agent in dev or start mode, i recieve the messages but the audio track is not attache",
      "body": "I am trying to make a connection to a room whenever i press a button , so when i enter the room , the agent should automatically enters the room , i am using js in the client side and python for server side \n\nlike nothing have changed from both codes but if i force entering the room , then it works normally and it start speaks but when it is in dev mode , it detects the room and joins but the audio doesn't work and the console and the cmd doesn't show any error ",
      "state": "open",
      "author": "MohamedZaky0",
      "author_type": "User",
      "created_at": "2025-01-28T21:19:05Z",
      "updated_at": "2025-01-28T21:19:05Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1421/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1421",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1421",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:20.428623",
      "comments": []
    },
    {
      "issue_number": 1402,
      "title": "High Latency in ElevenLabs TTS Streaming Due to Lack of HTTPS Session Reuse",
      "body": "**Description**\nWhen using the ElevenLabs TTS model for streaming, there is significant latency (~1000 ms) observed before the first word is streamed. This latency occurs even when multiple predictions are made in quick succession.\n\nUpon reviewing the [ElevenLabs Latency Documentation](https://elevenlabs.io/docs/developer-guides/reducing-latency?utm_source=chatgpt.com), it is mentioned that reusing HTTPS sessions for WebSocket streaming can mitigate this issue. Specifically, reusing an SSL/TLS session allows subsequent requests to skip the handshake process, reducing latency.\n\nHowever, there appears to be no straightforward way to reuse the session for multiple predictions, which forces each request to undergo a full handshake, leading to repeated high latency.\n\n**Steps to Reproduce**\nUse the ElevenLabs TTS API to stream a response for a prediction.\nSend another prediction within the same application context.\nObserve that the handshake process is repeated, causing ~1000 ms latency before the first word is streamed.\nExpected Behavior\nSubsequent predictions should reuse the same HTTPS session established during the first request, skipping the handshake process and reducing the latency for streaming responses.\n\n**Actual Behavior**\nEach prediction initiates a new HTTPS handshake, resulting in a ~1000 ms latency before streaming begins.\n\n**Impact**\nThis significantly affects real-time applications that rely on low-latency TTS responses, such as voice assistants or live feedback systems.\n\nSuggested Fix or Improvement\nProvide an option or mechanism in the SDK or API to reuse HTTPS sessions for WebSocket streaming. This would allow subsequent predictions to benefit from an already established SSL/TLS session, thus improving the latency for all requests after the first one",
      "state": "closed",
      "author": "narendra-bluebash",
      "author_type": "User",
      "created_at": "2025-01-22T17:06:11Z",
      "updated_at": "2025-01-26T13:11:30Z",
      "closed_at": "2025-01-26T01:26:33Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1402/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 1
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1402",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1402",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:20.428638",
      "comments": [
        {
          "author": "joeylin",
          "body": "how do you use it ?",
          "created_at": "2025-01-23T06:01:32Z"
        },
        {
          "author": "narendra-bluebash",
          "body": "currently geeting approx 500 ms latency in when i yeild the first word to betwen the agent speak so i am saying how to use the perious session so that it will syas in 100 ms",
          "created_at": "2025-01-23T10:56:30Z"
        },
        {
          "author": "davidzhao",
          "body": "we are using their websocket interface. the same HTTPSession is always reused.",
          "created_at": "2025-01-26T01:16:58Z"
        },
        {
          "author": "davidzhao",
          "body": "I'm unable to reproduce the latency you are experiencing. I'm seeing 350ms TTFB with 11labs, connecting from my laptop in US West.\n\nthe latency you are seeing is not related to HTTPS negotiations, that only happens upfront.",
          "created_at": "2025-01-26T01:26:33Z"
        },
        {
          "author": "narendra-bluebash",
          "body": "Yes, you're correct about the TTFB being around 350 ms. Do you have any suggestions to reduce it to approximately 100 ms? Currently, we’re using US region servers.",
          "created_at": "2025-01-26T13:11:29Z"
        }
      ]
    },
    {
      "issue_number": 1343,
      "title": "How to Send and Display a Link from Function Call to Frontend in LiveKit and agent-playground?",
      "body": "I want to ask a question about LiveKit: The result contains a link. When this function call is invoked, I want to send this link to the frontend and display it in the chat window of the agent-playground project or in a separately developed component. How can this be implemented?\r\n\r\n@llm.ai_callable()\r\n    async def take_photo(self):\r\n        \"\"\"This function is called when the user requests to take a photo. It captures an image from the latest video frame and saves it.\"\"\"\r\n        call_ctx = AgentCallContext.get_current()\r\n        message = \"Okay, I'll take a photo for you.\"\r\n        speech_handle = await call_ctx.agent.say(message)  # noqa: F841\r\n        call_ctx.chat_ctx.append(text=message, role=\"assistant\")\r\n\r\n        logger.info(\"Capturing and saving the image\")\r\n        # Access JobContext via self.job_context\r\n        latest_image = self.job_context.proc.userdata.get(\"latest_image\", None)\r\n        if latest_image is None:\r\n            logger.error(\"No available image frame.\")\r\n            return \"No available image.\"\r\n\r\n        #result = await capture_image(latest_image, \"photo\")\r\n        result=await save_frame(latest_image)\r\n        # Return the path\r\n        return result ",
      "state": "closed",
      "author": "zxh263",
      "author_type": "User",
      "created_at": "2025-01-07T10:14:02Z",
      "updated_at": "2025-01-26T01:27:49Z",
      "closed_at": "2025-01-26T01:27:49Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1343/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1343",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1343",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:20.615874",
      "comments": [
        {
          "author": "johnson7788",
          "body": "I think RPC will help you! https://docs.livekit.io/home/client/data/rpc/",
          "created_at": "2025-01-17T08:10:59Z"
        }
      ]
    },
    {
      "issue_number": 1047,
      "title": "Cannot chain tool calls. Only 1 tool called per use query",
      "body": "My application requires multiple tools to be used on conjunction with each other for a robotics application. I am testing the tool call ability of livekit before building my application but only 1 tool is called at a time. Even when explicitly modifying to system instructions to allow multiple tools to be called and modifying the tools to say this can be used in conjunction with other tools , nothing works\r\n\r\n![image](https://github.com/user-attachments/assets/9bf3f17b-6c09-45cc-8741-d9edd20f8ddf)\r\n\r\nWhen i begin the agent and ask `what is the current year` it should first call the epoch tool and then call the get year tool to find the current year given the epoch\r\n\r\nUnfortunately only the epoch tool gets called and the agent attempts to convert this to a year by itself without calling the `get_year` tool. \r\n\r\n![image](https://github.com/user-attachments/assets/f3121df2-aa0f-4c23-9a63-e91ef12797ff)\r\n\r\nLangChain handles the agent tool calling perfectly and can chain tools exactly as intended. This however cannot.\r\n\r\n![image](https://github.com/user-attachments/assets/581f4e7b-c980-4a4b-ace2-f119cbdb32f5)\r\n",
      "state": "closed",
      "author": "TheHassanShahzad",
      "author_type": "User",
      "created_at": "2024-11-05T21:46:18Z",
      "updated_at": "2025-01-26T00:45:38Z",
      "closed_at": "2025-01-26T00:45:37Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1047/reactions",
        "total_count": 3,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 3
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1047",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1047",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:20.810590",
      "comments": [
        {
          "author": "onur-yildirim-infinitusai",
          "body": "Did you try to set a higher `max_nested_fnc_calls`? By default it's 1 and it's recommended to update that value in another [issue](https://github.com/livekit/agents/issues/1065)\n\nhttps://github.com/livekit/agents/blob/main/livekit-agents/livekit/agents/pipeline/pipeline_agent.py#L195",
          "created_at": "2025-01-22T03:46:18Z"
        },
        {
          "author": "davidzhao",
          "body": "setting `max_nested_fnc_calls` to a higher value would indeed allow the LLMs to use nested function calls. Closing issue",
          "created_at": "2025-01-26T00:45:37Z"
        }
      ]
    },
    {
      "issue_number": 1399,
      "title": "Feature Request: Allow Selective Track Subscription for VoiceAssistant",
      "body": "Description: Currently, the VoiceAssistant automatically subscribes to all participant audio tracks when instantiated, even when AutoSubscribe.SUBSCRIBE_NONE is used. This behavior prevents the ability to selectively subscribe to specific tracks and ignore others.\n\nIn use cases like the WebRTC web app, there is a need for the voice assistant to subscribe only to a specific participant's audio track, while ensuring that the other participant cannot hear the audio. The track should have a unique identifier (e.g., a custom name) so that the agent can subscribe to it while other participants' audio is ignored.\n\nProposed Solution: It would be beneficial if the VoiceAssistant instance could support more granular control over track subscriptions. Specifically, adding a feature to allow the agent to subscribe to specific tracks based on a unique identifier, while ignoring other tracks.\n\nThis would allow better flexibility in managing track subscriptions and would be especially useful for applications where private communication with the agent is required without broadcasting audio to other participants.\n\nUse Case:\n\nIn a WebRTC web app, a user can interact with the voice assistant while ensuring the other participant does not hear the audio.\nThe agent can subscribe to a participant's specific audio track using its unique name or identifier, while other tracks are ignored.\nBenefits:\n\nEnhanced control over which audio tracks the agent subscribes to.\nImproved privacy and user experience in scenarios with multiple participants.\nWould love to see this functionality added to the VoiceAssistant!",
      "state": "open",
      "author": "boussaidev",
      "author_type": "User",
      "created_at": "2025-01-21T14:19:10Z",
      "updated_at": "2025-01-24T17:31:18Z",
      "closed_at": null,
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/livekit/agents/issues/1399/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/livekit/agents/issues/1399",
      "api_url": "https://api.github.com/repos/livekit/agents/issues/1399",
      "repository": "livekit/agents",
      "extraction_date": "2025-06-22T00:36:21.037611",
      "comments": [
        {
          "author": "boussaidev",
          "body": "@dsa \n@nfma ",
          "created_at": "2025-01-22T14:07:02Z"
        },
        {
          "author": "longcw",
          "body": "Thanks for the suggestion. The current agent will automatically subscribe to the first participant to join the room. An upcoming major release will allow subscribing to any specific participant and switching the audio input to the agent 🚀  ",
          "created_at": "2025-01-23T01:34:12Z"
        },
        {
          "author": "boussaidev",
          "body": "i implemented this feature in https://github.com/livekit/agents/pull/1413 !!",
          "created_at": "2025-01-24T17:31:17Z"
        }
      ]
    }
  ]
}