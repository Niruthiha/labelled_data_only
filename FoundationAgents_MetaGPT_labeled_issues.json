{
  "repository": "FoundationAgents/MetaGPT",
  "repository_info": {
    "repo": "FoundationAgents/MetaGPT",
    "stars": 56571,
    "language": "Python",
    "description": "🌟 The Multi-Agent Framework: First AI Software Company, Towards Natural Language Programming",
    "url": "https://github.com/FoundationAgents/MetaGPT",
    "topics": [
      "agent",
      "gpt",
      "llm",
      "metagpt",
      "multi-agent"
    ],
    "created_at": "2023-06-30T09:04:55Z",
    "updated_at": "2025-06-21T22:59:20Z",
    "search_query": "ai agent language:python stars:>3 -framework",
    "total_issues_estimate": 124,
    "labeled_issues_estimate": 97,
    "labeling_rate": 78.9,
    "sample_labeled": 30,
    "sample_total": 38,
    "has_issues": true,
    "repo_id": 660551251,
    "default_branch": "main",
    "size": 184017
  },
  "extraction_date": "2025-06-21T22:47:50.016125",
  "extraction_type": "LABELED_ISSUES_ONLY",
  "total_labeled_issues": 212,
  "issues": [
    {
      "issue_number": 1836,
      "title": "openai.types.completion_usage.CompletionUsage() argument after ** must be a mapping, not NoneType",
      "body": "[/CONTENT]2025-05-22 15:39:19.772 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 28.469(s), this was the 1st time calling it. exp: openai.types.completion_usage.CompletionUsage() argument after ** must be a mapping, not NoneType\n\n解决:\n只能使用官方deepseek的api，使用非官方的deepseek api会出现上述问题(我使用百炼平台和超算中心提供免费api，一直会出现上述问题)。",
      "state": "open",
      "author": "HappyVing",
      "author_type": "User",
      "created_at": "2025-05-22T07:56:58Z",
      "updated_at": "2025-06-22T00:40:41Z",
      "closed_at": null,
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1836/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1836",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1836",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:46.994241",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-22T00:40:10Z"
        },
        {
          "author": "HappyVing",
          "body": "已经收到你的邮件啦~~~~~~",
          "created_at": "2025-06-22T00:40:41Z"
        }
      ]
    },
    {
      "issue_number": 1816,
      "title": "怎样让Alex工作？",
      "body": "**Feature description**\n我让MG为我开发一个工具，首先Alice完成了PRD，然后Bob设计了系统架构，但Alixe没有开发就结束了\n\n![Image](https://github.com/user-attachments/assets/269245c1-5ffa-4440-b7b2-64beac41f301)",
      "state": "closed",
      "author": "pulj26pulj26",
      "author_type": "User",
      "created_at": "2025-04-24T03:22:01Z",
      "updated_at": "2025-06-22T00:40:14Z",
      "closed_at": "2025-06-22T00:40:14Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1816/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1816",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1816",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:47.186578",
      "comments": [
        {
          "author": "muchengxuev587",
          "body": "我也是。。。很久以前的版本貌似不会这样",
          "created_at": "2025-04-29T06:48:04Z"
        },
        {
          "author": "leason-lyx",
          "body": "我用最新的be6921c版本，遇到同样的问题",
          "created_at": "2025-05-08T12:30:31Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-08T00:39:57Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-06-22T00:40:14Z"
        }
      ]
    },
    {
      "issue_number": 1831,
      "title": "mgx_env环境与teamleader设置的问题bug",
      "body": "报错内容：\n\nAttributeError: 'NoneType' object has no attribute 'profile'\n\n运行debate.py等示例时，都会报错。添加了`TeamLeader()`后，最终的`SimpleCoder(Role)`，不会执行_act等方法，导致效果有问题。\n\n原因分析：\n首先不加 `TeamLeader()` 类报错的原因是因为在mgx_env.py的文件中，调用publish_message方法，其中获取到所有的role，如下：\n```\ndef publish_message(self, message: Message, user_defined_recipient: str = \"\", publicer: str = \"\") -> bool:\n    \"\"\"let the team leader take over message publishing\"\"\"\n    print(\"MDXEnv.....  publish_message .....\")\n    message = self.attach_images(message)  # for multi-modal message\n\n    tl = self.get_role(TEAMLEADER_NAME)  # TeamLeader's name is Mike\n```\n如果不设置添加了`TeamLeader()`，则tl返回是个None，导致后续就会抛错，因为会获取`profile`属性，如下：\n` elif publicer == tl.profile:`；而添加了`TeamLeader()`，`self.get_role`就能返回数据，相当于是把teamleader注册进去了，但后面会导致多智能体运行时，效果有问题。\n\n在之前的版本中，是不需要添加这个`TeamLeader()`，而且env环境好像也不是mgx，直接就能运行，估计是哪里改错了，希望可以检查下。\n\n解决方案：\n跟了源码，最后发现，压根就没有调用到`self.set_actions([xxxx])`中的actions；因为在`_observe`中的判断有问题，如下：\n\n`self.rc.news = [msg for msg in self.rc.news if msg.send_to == {self.name} ]`\n\nmsg的内容是：{'程序员Ryan', '\\<all\\>'}，第一个是添加的teamleader，第二个一个常数标记，具体业务意义我不清楚，按我理解来看，应该是全体的roles/actions。因此我改了下代码如下：\n`self.rc.news = [msg for msg in self.rc.news if (msg.send_to == {self.name} or MESSAGE_ROUTE_TO_ALL in msg.send_to)]`\n最后是ok了。\n\n还有一个改法，官方的run_project源码中有问题，如下：\n\n```\n    def run_project(self, idea, send_to: str = \"\"):\n        \"\"\"Run a project from publishing user requirement.\"\"\"\n        self.idea = idea\n\n        # Human requirement.\n        self.env.publish_message(Message(content=idea))\n```\n\n这里没有用上`send_to`参数，在debate.py示例中，用户在初始化的时候，是需要传参指定接收人send_to的，而且从代码逻辑来看本就是应该在Message中增加参数send_to，改为如下：\n```\n\n    def run_project(self, idea, send_to: str = \"\"):\n        \"\"\"Run a project from publishing user requirement.\"\"\"\n        self.idea = idea\n        # Human requirement.\n        self.env.publish_message(Message(content=idea, send_to = send_to))\n```\n\ndebate.py中也需要修改：\n```\n\n    async def _observe(self) -> int:\n        await super()._observe()\n        # accept messages sent (from opponent) to self, disregard own messages from the last round\n        # 应该用 in 来判断，因为msg.send_to是一个set集合对象\n        self.rc.news = [msg for msg in self.rc.news if self.name in msg.send_to]\n        return len(self.rc.news)\n```\n\n\n期望：\n希望官方出个官方解决方案，感谢。\n",
      "state": "open",
      "author": "RyanOvO",
      "author_type": "User",
      "created_at": "2025-05-17T03:15:52Z",
      "updated_at": "2025-06-22T00:40:13Z",
      "closed_at": null,
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1831/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1831",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1831",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:47.456522",
      "comments": [
        {
          "author": "cranyy",
          "body": "Hi, i had the same issue as you -- I used translate to follow your solution, which was much better than mine, because I have no need for a leader, and this new env is completely redundant for me -- so my solution was in team.py:\n```\nclass Team(BaseModel):\n    '''\n    Team: Possesses one or more role",
          "created_at": "2025-05-21T16:03:11Z"
        },
        {
          "author": "RyanOvO",
          "body": "> Hi, i had the same issue as you -- I used translate to follow your solution, which was much better than mine, because I have no need for a leader, and this new env is completely redundant for me -- so my solution was in team.py:\n> \n> ```\n> class Team(BaseModel):\n>     '''\n>     Team: Possesses one",
          "created_at": "2025-05-22T05:32:12Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-22T00:40:12Z"
        }
      ]
    },
    {
      "issue_number": 1835,
      "title": "Do you have any plan about supporting Python 3.12 ?",
      "body": "As I said in Title",
      "state": "open",
      "author": "william8188",
      "author_type": "User",
      "created_at": "2025-05-21T08:16:45Z",
      "updated_at": "2025-06-21T00:35:39Z",
      "closed_at": null,
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1835/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1835",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1835",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:47.675019",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-21T00:35:38Z"
        }
      ]
    },
    {
      "issue_number": 1740,
      "title": "debug执行DI的时候报错",
      "body": "/Users/majin/PycharmProjects/metagpt-tesst/.venv/lib/python3.9/site-packages/debugpy/_vendored/force_pydevd.py:18: UserWarning: incompatible copy of pydevd already imported:\n /Users/majin/Applications/PyCharm Professional Edition.app/Contents/plugins/python-ce/helpers/pydev/_pydev_bundle/__init__.py\n你好，debug运行DataInterpreter的时候报错。帮忙看下如何解决",
      "state": "open",
      "author": "WuJingLearn",
      "author_type": "User",
      "created_at": "2025-03-05T04:00:06Z",
      "updated_at": "2025-06-20T00:36:15Z",
      "closed_at": null,
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1740/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1740",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1740",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:47.871392",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-05T00:32:13Z"
        },
        {
          "author": "stellaHSR",
          "body": "能否提供更多报错截图？看着是调试器本身配置",
          "created_at": "2025-05-18T09:26:33Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-20T00:36:14Z"
        }
      ]
    },
    {
      "issue_number": 1833,
      "title": "The output content of llm is confused with that of the log, and it seems as if it has been truncated",
      "body": "The output content of llm is confused with that of the log, and it seems as if it has been truncated：\n\n![Image](https://github.com/user-attachments/assets/afdea662-fd25-416c-a50d-3043f41887f8)\n\nHow can the source code within metagpt not output the content returned by the LLM, and even if it is output, it should not be mixed with the log",
      "state": "open",
      "author": "RyanOvO",
      "author_type": "User",
      "created_at": "2025-05-20T01:17:02Z",
      "updated_at": "2025-06-20T00:36:11Z",
      "closed_at": null,
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1833/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1833",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1833",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:48.103531",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-20T00:36:10Z"
        }
      ]
    },
    {
      "issue_number": 1834,
      "title": "class SimpleEngine has duplication _from_nodes methods",
      "body": "\n![Image](https://github.com/user-attachments/assets/ba523147-4253-4fe6-87c7-4ec9ce662b16)\n\n```\n\n @classmethod\n    def _from_nodes(\n        cls,\n        nodes: list[BaseNode],\n        transformations: Optional[list[TransformComponent]] = None,\n        embed_model: BaseEmbedding = None,\n        llm: LLM = None,\n        retriever_configs: list[BaseRetrieverConfig] = None,\n        ranker_configs: list[BaseRankerConfig] = None,\n    ) -> \"SimpleEngine\":\n        embed_model = cls._resolve_embed_model(embed_model, retriever_configs)\n        llm = llm or get_rag_llm()\n\n        retriever = get_retriever(configs=retriever_configs, nodes=nodes, embed_model=embed_model)\n        rankers = get_rankers(configs=ranker_configs, llm=llm)  # Default []\n\n        return cls(\n            retriever=retriever,\n            node_postprocessors=rankers,\n            response_synthesizer=get_response_synthesizer(llm=llm),\n            transformations=transformations,\n        )\n\n    @classmethod\n    def _from_nodes(\n        cls,\n        nodes: list[BaseNode],\n        transformations: Optional[list[TransformComponent]] = None,\n        embed_model: BaseEmbedding = None,\n        llm: LLM = None,\n        retriever_configs: list[BaseRetrieverConfig] = None,\n        ranker_configs: list[BaseRankerConfig] = None,\n    ) -> \"SimpleEngine\":\n        embed_model = cls._resolve_embed_model(embed_model, retriever_configs)\n        llm = llm or get_rag_llm()\n\n        retriever = get_retriever(configs=retriever_configs, nodes=nodes, embed_model=embed_model)\n        rankers = get_rankers(configs=ranker_configs, llm=llm)  # Default []\n\n        return cls(\n            retriever=retriever,\n            node_postprocessors=rankers,\n            response_synthesizer=get_response_synthesizer(llm=llm),\n            transformations=transformations,\n        )\n```\n\n\nthe `_from_nodes  `method is repeated. \n",
      "state": "open",
      "author": "RyanOvO",
      "author_type": "User",
      "created_at": "2025-05-20T05:45:49Z",
      "updated_at": "2025-06-20T00:36:09Z",
      "closed_at": null,
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1834/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1834",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1834",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:48.290388",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-20T00:36:09Z"
        }
      ]
    },
    {
      "issue_number": 1706,
      "title": "Aflow 运行报错",
      "body": "\n运行Aflow 命令，只运行完成round1的执行。然后就都报错，是否不支持qwen 和 deepseek模型来实现？\n\n### 命令：\n\npython -m examples.aflow.optimize  --dataset MATH --opt_model_name deepseek-v3  --exec_model_name qwen2.5\n --if_first_optimize=false\n\n### 模型配置：\nmodels:\n    \"qwen2.5\": \n        api_type: \"dashscope\" \n        model: \"qwen2.5-72b-instruct\"\n        base_url: \"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n        api_key: \"sk-xxxx\"\n        temperature: 0.5\n    \"deepseek-v3\": \n        api_type: \"dashscope\" \n        model: \"deepseek-v3\"\n        base_url: \"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n        api_key: \"sk-xxxx\"\n        temperature: 0.5\n\n\n报错信息：\n\n**Bug description**\n<!-- Clearly and directly describe the current bug -->\n2025-02-20 16:25:18.965 | INFO     | metagpt.ext.aflow.scripts.optimizer:optimize:93 - Error occurred: Unable to serialize unknown type: <class 'numpy.int64'>. Retrying... (Attempt 1/1)\n2025-02-20 16:25:18.968 | INFO     | metagpt.ext.aflow.scripts.optimizer:optimize:95 - Max retries reached. Moving to next round.\n2025-02-20 16:25:23.971 | INFO     | metagpt.ext.aflow.scripts.optimizer:optimize:106 - Score for round 2: None\nTraceback (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"C:\\work\\spaces\\MetaGPT\\examples\\aflow\\optimize.py\", line 133, in <module>\n    optimizer.optimize(\"Graph\")\n  File \"C:\\work\\spaces\\MetaGPT\\metagpt\\ext\\aflow\\scripts\\optimizer.py\", line 108, in optimize\n    converged, convergence_round, final_round = self.convergence_utils.check_convergence(top_k=3)\n                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\work\\spaces\\MetaGPT\\metagpt\\ext\\aflow\\scripts\\optimizer_utils\\convergence_utils.py\", line 74, in check_convergence\n    self.avg_scores, self.stds = self.calculate_avg_and_std()\n                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\work\\spaces\\MetaGPT\\metagpt\\ext\\aflow\\scripts\\optimizer_utils\\convergence_utils.py\", line 58, in calculate_avg_and_std\n    self.rounds = self.process_rounds()\n                  ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\work\\spaces\\MetaGPT\\metagpt\\ext\\aflow\\scripts\\optimizer_utils\\convergence_utils.py\", line 44, in process_rounds\n    self.data = self.load_data(root_path=self.root_path)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\work\\spaces\\MetaGPT\\metagpt\\ext\\aflow\\scripts\\optimizer_utils\\convergence_utils.py\", line 38, in load_data\n    return json.load(file)\n           ^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ThinkPad\\.conda\\envs\\metagpt\\Lib\\json\\__init__.py\", line 293, in load\n    return loads(fp.read(),\n           ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ThinkPad\\.conda\\envs\\metagpt\\Lib\\json\\__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ThinkPad\\.conda\\envs\\metagpt\\Lib\\json\\decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ThinkPad\\.conda\\envs\\metagpt\\Lib\\json\\decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 6 column 23 (char 112)\n",
      "state": "open",
      "author": "qjs2000",
      "author_type": "User",
      "created_at": "2025-02-20T10:10:06Z",
      "updated_at": "2025-06-19T00:36:16Z",
      "closed_at": null,
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1706/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1706",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1706",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:48.470363",
      "comments": [
        {
          "author": "Clairegggg",
          "body": "Did you solve it?",
          "created_at": "2025-03-10T13:34:48Z"
        },
        {
          "author": "Guo-Jintao",
          "body": "请问一下用的是哪个版本的metagpt，用Version: 0.8.1似乎于aflow代码不太兼容，\n2025-03-14 15:51:04.570 | INFO     | metagpt.ext.aflow.benchmark.gsm8k:evaluate_problem:53 - Maximum retries reached. Skipping this sample. Error: ActionNode.fill() got an unexpected keyword argument 'context'，\n最新版本的metagpt，ActionNode.fill()变成了req，将",
          "created_at": "2025-03-17T08:50:46Z"
        },
        {
          "author": "helloword1",
          "body": "问题+1\n",
          "created_at": "2025-03-17T08:56:06Z"
        },
        {
          "author": "Guo-Jintao",
          "body": "解决了，将action_node换成这个链接的就行了https://github.com/geekan/MetaGPT/pull/1510/files?short_path=66cde96",
          "created_at": "2025-03-18T02:46:30Z"
        },
        {
          "author": "Guo-Jintao",
          "body": "坏了，遇到一楼老哥的错误了，@qjs2000 哥，问题解决了吗",
          "created_at": "2025-03-18T03:22:46Z"
        }
      ]
    },
    {
      "issue_number": 1768,
      "title": "user_requirement missed in plan_and_act mode",
      "body": "**Bug description**\nThe LLM generated code in plan_and_act mode does not contain data path info. Found that self.user_requirement (containing the data info) is empty. So the prompt does not contain data info for LLM to write the correct code. \n\n**Bug solved method**\nAdd ` self.user_requirement = self.get_memories()[-1].content `\nto DataInterpreter's plan_and_act method may solve the issue. However, I'm not sure if it affects other functionalities.   \n\n**Environment information**\nSystem version (mac os), Python version (conda python 3.9), LLM type and model (Zhipu glm-4-plus)",
      "state": "open",
      "author": "AdaChambers",
      "author_type": "User",
      "created_at": "2025-03-17T05:24:33Z",
      "updated_at": "2025-06-19T00:36:14Z",
      "closed_at": null,
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1768/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1768",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1768",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:48.679256",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-18T00:38:06Z"
        },
        {
          "author": "stellaHSR",
          "body": "yes, thank you for report the bug. We will add ` user_requirement = self.get_memories()[0].content` here: https://github.com/FoundationAgents/MetaGPT/blob/ba2868974b2ecc3fe4218ad29dd334867c07f678/metagpt/roles/di/data_interpreter.py#L159",
          "created_at": "2025-05-18T09:42:26Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-19T00:36:14Z"
        }
      ]
    },
    {
      "issue_number": 1828,
      "title": "默认embbedding模型出现问题 ：TypeError: 'NoneType' object is not iterable",
      "body": "我在指定了了本地的大模型路径之后，使用MetaGPT的默认嵌入模型会报错：\nTraceback (most recent call last):\n  File \"/mnt/d/MetaGPT-main/MetaGPT-main/examples/mytest.py\", line 28, in <module>\n    asyncio.run(main())\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/asyncio/runners.py\", line 190, in run\n    return runner.run(main)\n           ^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/asyncio/runners.py\", line 118, in run\n    return self._loop.run_until_complete(task)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n    return future.result()\n           ^^^^^^^^^^^^^^^\n  File \"/mnt/d/MetaGPT-main/MetaGPT-main/examples/mytest.py\", line 23, in main\n    engine = SimpleEngine.from_docs(input_files=[DOC_PATH])\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/d/MetaGPT-main/MetaGPT-main/metagpt/rag/engines/simple.py\", line 128, in from_docs\n    return cls._from_nodes(\n           ^^^^^^^^^^^^^^^^\n  File \"/mnt/d/MetaGPT-main/MetaGPT-main/metagpt/rag/engines/simple.py\", line 301, in _from_nodes\n    retriever = get_retriever(configs=retriever_configs, nodes=nodes, embed_model=embed_model)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/d/MetaGPT-main/MetaGPT-main/metagpt/rag/factories/retriever.py\", line 69, in get_retriever\n    return self._create_default(**kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/d/MetaGPT-main/MetaGPT-main/metagpt/rag/factories/retriever.py\", line 76, in _create_default\n    index = self._extract_index(None, **kwargs) or self._build_default_index(**kwargs)\n                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/d/MetaGPT-main/MetaGPT-main/metagpt/rag/factories/retriever.py\", line 117, in _build_default_index\n    index = VectorStoreIndex(\n            ^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/llama_index/core/indices/vector_store/base.py\", line 74, in __init__\n    super().__init__(\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/llama_index/core/indices/base.py\", line 91, in __init__\n    index_struct = self.build_index_from_nodes(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/llama_index/core/indices/vector_store/base.py\", line 307, in build_index_from_nodes\n    return self._build_index_from_nodes(nodes, **insert_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/llama_index/core/indices/vector_store/base.py\", line 279, in _build_index_from_nodes\n    self._add_nodes_to_index(\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/llama_index/core/indices/vector_store/base.py\", line 232, in _add_nodes_to_index\n    nodes_batch = self._get_node_with_embedding(nodes_batch, show_progress)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/llama_index/core/indices/vector_store/base.py\", line 140, in _get_node_with_embedding\n    id_to_embed_map = embed_nodes(\n                      ^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/llama_index/core/indices/utils.py\", line 138, in embed_nodes\n    new_embeddings = embed_model.get_text_embedding_batch(\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/llama_index/core/base/embeddings/base.py\", line 255, in get_text_embedding_batch\n    embeddings = self._get_text_embeddings(cur_batch)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/llama_index/embeddings/openai/base.py\", line 419, in _get_text_embeddings\n    return get_embeddings(\n           ^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/tenacity/__init__.py\", line 289, in wrapped_f\n    return self(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/tenacity/__init__.py\", line 379, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/tenacity/__init__.py\", line 314, in iter\n    return fut.result()\n           ^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/tenacity/__init__.py\", line 382, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/llama_index/embeddings/openai/base.py\", line 180, in get_embeddings\n    data = client.embeddings.create(input=list_of_text, model=engine, **kwargs).data\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/openai/resources/embeddings.py\", line 114, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/openai/_base_client.py\", line 1271, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/openai/_base_client.py\", line 942, in request\n    return self._request(\n           ^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/openai/_base_client.py\", line 1048, in _request\n    return self._process_response(\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/openai/_base_client.py\", line 1147, in _process_response\n    return api_response.parse()\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/openai/_response.py\", line 318, in parse\n    parsed = self._options.post_parser(parsed)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/openai/resources/embeddings.py\", line 102, in parser\n    for embedding in obj.data:\nTypeError: 'NoneType' object is not iterable\nERROR conda.cli.main_run:execute(124): `conda run python /mnt/d/MetaGPT-main/MetaGPT-main/examples/mytest.py` failed. (See above for error)\n\n我自己认为是因为网络原因无法访问openai的embedding模型，但是我查阅了MetaGPT文档中支持的其他embedding模型，发现大多数embedding模型与MetaGPT的运行环境不相适配，请问你们有更好的访问openai的方法或者有其他支持MetaGPT可本地部署的embedding模型吗？",
      "state": "closed",
      "author": "lcj1069864078",
      "author_type": "User",
      "created_at": "2025-05-15T00:34:04Z",
      "updated_at": "2025-06-18T00:38:43Z",
      "closed_at": "2025-06-18T00:38:43Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1828/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1828",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1828",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:48.892923",
      "comments": [
        {
          "author": "seehi",
          "body": "1. 可以用下面代码验证embedding服务是否正常：\n```python\nfrom llama_index.embeddings.openai import OpenAIEmbedding\n\n\nembedding = OpenAIEmbedding(api_base=\"YOUR_API_BASE\", api_key=\"YOUR_API_KEY\")\nprint(embedding.get_text_embedding(\"hello world\"))\n```\n2. 当前可通过配置设置的embedding模型，可查看：[配置embedding](https://docs.deepwisdom.a",
          "created_at": "2025-05-18T11:30:41Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-18T00:35:47Z"
        }
      ]
    },
    {
      "issue_number": 1748,
      "title": "AttributeError: 'NoneType' object has no attribute 'name'",
      "body": "我在使用示例demo生成代码的时候遇到了`AttributeError: 'NoneType' object has no attribute 'name'`这个报错，查看代码后发现name是self.rc上面的一个属性，请问该属性有什么作用，我该如何修复这个bug\n",
      "state": "open",
      "author": "2645283289",
      "author_type": "User",
      "created_at": "2025-03-09T10:02:02Z",
      "updated_at": "2025-06-18T00:35:55Z",
      "closed_at": null,
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1748/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1748",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1748",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:49.081279",
      "comments": [
        {
          "author": "YiFraternity",
          "body": "我也遇到这个问题，正在debug",
          "created_at": "2025-04-04T09:55:44Z"
        },
        {
          "author": "limboys",
          "body": "Can you provide more context, such as the\nPython version\nmachine architecture\ndemo example",
          "created_at": "2025-05-18T13:27:42Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-18T00:35:55Z"
        }
      ]
    },
    {
      "issue_number": 1761,
      "title": "如何将响应保存到工作空间，我调用相应的api错误信息也不是很明确",
      "body": "**Bug description**\n我想在Action响应的时候，将相应结果保存为一个文件，我调用了这行代码\n`await self.repo.resources.code_summary.save(filename=\"prd.md\", content=response)`，我却得到一个错误\n`2025-03-13 20:21:05.436 | ERROR    | metagpt.utils.common:wrapper:631 - Exception occurs, start to serialize the project, exp:\nTraceback (most recent call last):\n  File \"/Users/huanhu/PycharmProjects/hello_metagpt/.venv/lib/python3.11/site-packages/metagpt/utils/common.py\", line 640, in wrapper\n    return await func(self, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/huanhu/PycharmProjects/hello_metagpt/.venv/lib/python3.11/site-packages/metagpt/roles/role.py\", line 550, in run\n    rsp = await self.react()\n          ^^^^^^^^^^^^^^^^^^\nValueError: Invalid root\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/huanhu/PycharmProjects/hello_metagpt/.venv/lib/python3.11/site-packages/metagpt/utils/common.py\", line 626, in wrapper\n    result = await func(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/huanhu/PycharmProjects/hello_metagpt/.venv/lib/python3.11/site-packages/metagpt/team.py\", line 134, in run\n    await self.env.run()\nException: Traceback (most recent call last):\n  File \"/Users/huanhu/PycharmProjects/hello_metagpt/.venv/lib/python3.11/site-packages/metagpt/utils/common.py\", line 640, in wrapper\n    return await func(self, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/huanhu/PycharmProjects/hello_metagpt/.venv/lib/python3.11/site-packages/metagpt/roles/role.py\", line 550, in run\n    rsp = await self.react()\n          ^^^^^^^^^^^^^^^^^^\n  File \"/Users/huanhu/PycharmProjects/hello_metagpt/.venv/lib/python3.11/site-packages/metagpt/roles/role.py\", line 517, in react\n    rsp = await self._react()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"/Users/huanhu/PycharmProjects/hello_metagpt/.venv/lib/python3.11/site-packages/metagpt/roles/role.py\", line 463, in _react\n    rsp = await self._act()\n          ^^^^^^^^^^^^^^^^^\n  File \"/Users/huanhu/PycharmProjects/hello_metagpt/huhuan_soft_company.py\", line 41, in _act\n    response = await todo.run(msg.content)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/huanhu/PycharmProjects/hello_metagpt/huhuan_soft_company.py\", line 24, in run\n    await self.repo.resources.code_summary.save(filename=\"prd.md\", content=response)\n          ^^^^^^^^^\n  File \"/Users/huanhu/PycharmProjects/hello_metagpt/.venv/lib/python3.11/site-packages/metagpt/actions/action.py\", line 42, in repo\n    self.context.repo = ProjectRepo(self.context.git_repo)\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/huanhu/PycharmProjects/hello_metagpt/.venv/lib/python3.11/site-packages/metagpt/utils/project_repo.py\", line 97, in __init__\n    raise ValueError(\"Invalid root\")\nValueError: Invalid root\n`\n\n**code**\n`from metagpt.actions import Action\nfrom metagpt.roles import Role\nfrom metagpt.schema import Message\nfrom metagpt.logs import logger\nimport asyncio\n\nfrom metagpt.team import Team\n\n\nclass WritePrd(Action):\n    PROMPT_TEMPLATE: str = \"{instruction}\"\n\n    name: str = \"编写项目需求文档\"\n\n    async def run(self, instruction: str):\n        prompt = self.PROMPT_TEMPLATE.format(instruction=instruction)\n        response = await self._aask(prompt)\n        await self.repo.resources.code_summary.save(filename=\"prd.md\", content=response)\n        return response\n\n\nclass ProductManage(Role):\n    name: str = \"huhuan\"\n\n    profile: str = \"ProductManage\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([WritePrd])\n\n    async def _act(self) -> Message:\n        logger.info(f\"{self._setting}: to do {self.rc.todo}({self.rc.todo.name})\")\n        todo = self.todo\n        msg = self.get_memories(k=1)[0]\n        response = await todo.run(msg.content)\n        msg = Message(content=response, role=self.profile, cause_by=type(todo))\n\n        return msg\n\n\nasync def main():\n    company = Team()\n    company.hire([\n        ProductManage()\n    ])\n    company.invest(investment=3)\n\n    idea = \"你好\"\n    company.run_project(idea)\n    await company.run(n_round=5)\n\n\nif __name__ == '__main__':\n    asyncio.run(main())\n`",
      "state": "open",
      "author": "youbiaokachi123",
      "author_type": "User",
      "created_at": "2025-03-13T12:22:00Z",
      "updated_at": "2025-06-18T00:35:54Z",
      "closed_at": null,
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1761/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1761",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1761",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:49.300139",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-13T00:59:25Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-18T00:35:53Z"
        }
      ]
    },
    {
      "issue_number": 1772,
      "title": "rag功能不能正常使用",
      "body": "安装稳定版（截止2025-3-19）无法使用rag功能，无法运行示例代码，会显示以下错误：\nRetrying llama_index.embeddings.openai.base.get_embeddings in 1.7915908865025045 seconds as it raised NotFoundError: Error code: 404 - {'event_id': '30-inst-228-20250319170241-4fed467a', 'error_msg': 'Not Found. Please check the configuration.'}.\n....\nFile \"E:\\Anaconda\\envs\\metagpt_stable\\lib\\site-packages\\openai\\_base_client.py\", line 930, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.NotFoundError: Error code: 404 - {'event_id': '30-inst-5-20250319170244-9280c94d', 'error_msg': 'Not Found. Please check the configuration.'}\n\n**安装最新的稳定版metagpt==0.8.2会有依赖冲突，试过git clone方法和pip install --upgrade metagpt（pip install --upgrade git+https://github.com/geekan/MetaGPT.git）后会出现缺失包的情况：**\n\nTraceback (most recent call last):\n  File \"D:\\Metagpt\\MetaGPT81\\test.py\", line 3, in <module>\n    from metagpt.rag.engines import SimpleEngine\n  File \"E:\\Anaconda\\envs\\metagpt_stable\\lib\\site-packages\\metagpt\\rag\\engines\\__init__.py\", line 3, in <module>\n    from metagpt.rag.engines.simple import SimpleEngine\n  File \"E:\\Anaconda\\envs\\metagpt_stable\\lib\\site-packages\\metagpt\\rag\\engines\\simple.py\", line 35, in <module>\n    from metagpt.rag.factories import (\n  File \"E:\\Anaconda\\envs\\metagpt_stable\\lib\\site-packages\\metagpt\\rag\\factories\\__init__.py\", line 3, in <module>\n    from metagpt.rag.factories.retriever import get_retriever\n  File \"E:\\Anaconda\\envs\\metagpt_stable\\lib\\site-packages\\metagpt\\rag\\factories\\retriever.py\", line 16, in <module>\n    from llama_index.vector_stores.milvus import MilvusVectorStore\nModuleNotFoundError: No module named 'llama_index.vector_stores.milvus'；\n安装'llama_index.vector_stores.milvus就会有冲突，无法解决！！！\n具体是metagpt==1.0.0依赖setuptools==65.6.3，但是pymilvus 2.5.5 requires setuptools>69等等，有很多冲突无法解决！！\n\n\n\n\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nllama-index-embeddings-azure-openai 0.1.6 requires llama-index-core<0.11.0,>=0.10.11.post1, but you have llama-index-core 0.12.25 which is incompatible.\nllama-index-embeddings-openai 0.1.5 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.25 which is incompatible.\nllama-index-llms-azure-openai 0.1.4 requires llama-index-core<0.11.0,>=0.10.11.post1, but you have llama-index-core 0.12.25 which is incompatible.\nllama-index-llms-openai 0.1.8 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.25 which is incompatible.\nllama-index-readers-file 0.1.4 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.25 which is incompatible.\nllama-index-retrievers-bm25 0.1.3 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.25 which is incompatible.\nllama-index-vector-stores-chroma 0.1.6 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.25 which is incompatible.\nllama-index-vector-stores-elasticsearch 0.1.6 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.25 which is incompatible.\nllama-index-vector-stores-faiss 0.1.1 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.25 which is incompatible.\nmetagpt 1.0.0 requires setuptools==65.6.3, but you have setuptools 76.1.0 which is incompatible.\nmetagpt 1.0.0 requires typing-extensions==4.11.0, but you have typing-extensions 4.12.2 which is incompatible.\nsemantic-kernel 0.4.3.dev0 requires python-dotenv==1.0.0, but you have python-dotenv 1.0.1 which is incompatible.",
      "state": "open",
      "author": "zing-else",
      "author_type": "User",
      "created_at": "2025-03-19T09:40:12Z",
      "updated_at": "2025-06-18T00:35:52Z",
      "closed_at": null,
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1772/reactions",
        "total_count": 4,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 4
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1772",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1772",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:49.522932",
      "comments": [
        {
          "author": "YyKMfight",
          "body": "确实，尝试解决了一上午一直失败",
          "created_at": "2025-03-30T04:40:52Z"
        },
        {
          "author": "seehi",
          "body": "由于依赖冲突，临时去掉RAG的milvus，可用main分支再试看看，[相关PR](https://github.com/geekan/MetaGPT/pull/1794)",
          "created_at": "2025-03-31T08:04:36Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-02T00:34:13Z"
        },
        {
          "author": "lcj1069864078",
          "body": "我也遇到过rag环境的问题，我按照官方手册的命令： pip install metagpt[rag]   一次性将metagpt环境和rag装好 这样安装的rag是正常的，不过embedding出现了报错，你可以试试（我的python版本是3.11）",
          "created_at": "2025-05-15T12:22:25Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-18T00:35:52Z"
        }
      ]
    },
    {
      "issue_number": 1819,
      "title": "Issue when running baseline set-up",
      "body": "**Bug description**\nI am unable to completely generate a workspace.\n\n**Environment information**\n\n- LLM type and model name:\n- System version: macOS 15.4.1\n- Python version: Python 3.10.16\n- MetaGPT version or branch: main\n\nSet-up from: `git clone https://github.com/geekan/MetaGPT && cd MetaGPT && pip install --upgrade -e .`\n\n**Instructions**\n- metagpt --init-config\n- modify `/Users/cmodi/.metagpt/config2.yaml` to use openrouter (via this example: https://github.com/FoundationAgents/MetaGPT/blob/main/config/examples/openrouter-llama3-70b-instruct.yaml)\n- `metagpt \"write a cli blackjack game\"`\n\n**Screenshots or logs**\n```\n(metagpt) cmodi@cmodi-mbp MetaGPT % metagpt \"write a cli blackjack game\"\n2025-04-30 13:59:38.982 | INFO     | metagpt.const:get_metagpt_package_root:15 - Package root set to /Users/cmodi/Documents/ai/llama-api/MetaGPT\n2025-04-30 13:59:38.982 | INFO     | metagpt.const:get_metagpt_package_root:15 - Package root set to /Users/cmodi/Documents/ai/llama-api/MetaGPT\n/opt/anaconda3/envs/metagpt/lib/python3.10/site-packages/pydantic/main.py:214: UserWarning: A custom validator is returning a value other than `self`.\nReturning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\nSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\n  warnings.warn(\n2025-04-30 14:00:32.188 | INFO     | metagpt.team:invest:96 - Investment: $3.0.\nThought: This is a detailed software development task that requires multiple steps, including designing and implementing a command-line interface for a blackjack game.\nResponse Category: TASK\n2025-04-30 14:00:33.267 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.009 | Max budget: $3.000 | Current cost: $0.009, prompt_tokens: 1073, completion_tokens: 32\nEnglish\n2025-04-30 14:00:34.162 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.010 | Max budget: $3.000 | Current cost: $0.002, prompt_tokens: 196, completion_tokens: 2\nBased on the user requirement to write a CLI blackjack game, I will create a plan to assign tasks to team members. Since this is a software development requirement, I will decompose it into multiple tasks and assign them to different team members based on their expertise.\n\nHere is my plan:\n\n```json\n[\n    {\n        \"command_name\": \"Plan.append_task\",\n        \"args\": {\n            \"task_id\": \"1\",\n            \"dependent_task_ids\": [],\n            \"instruction\": \"Create a product requirement document (PRD) for the CLI blackjack game.\",\n            \"assignee\": \"Alice\"\n        }\n    },\n    {\n        \"command_name\": \"Plan.append_task\",\n        \"args\": {\n            \"task_id\": \"2\",\n            \"dependent_task_ids\": [\"1\"],\n            \"instruction\": \"Design a concise, usable, complete software system for the CLI blackjack game based on the PRD.\",\n            \"assignee\": \"Bob\"\n        }\n    },\n    {\n        \"command_name\": \"Plan.append_task\",\n        \"args\": {\n            \"task_id\": \"3\",\n            \"dependent_task_ids\": [\"2\"],\n            \"instruction\": \"Implement the CLI blackjack game using Vite, React, MUI, Tailwind CSS, and deploy the web app.\",\n            \"assignee\": \"Alex\"\n        }\n    },\n    {\n        \"command_name\": \"TeamLeader.publish_message\",\n        \"args\": {\n            \"content\": \"Write a cli blackjack game.\",\n            \"send_to\": \"Alice\"\n        }\n    },\n    {\n        \"command_name\": \"RoleZero.reply_to_human\",\n        \"args\": {\n            \"content\": \"I have assigned the tasks to the team members. Alice will create the PRD, Bob will design the software architecture, and Alex will implement the CLI blackjack game.\"\n        }\n    }\n]\n```\n2025-04-30 14:00:55.774 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.046 | Max budget: $3.000 | Current cost: $0.035, prompt_tokens: 4048, completion_tokens: 375\n2025-04-30 14:00:55.776 | INFO     | metagpt.roles.di.role_zero:_act:322 - Commands: \n[{'command_name': 'Plan.append_task', 'args': {'task_id': '1', 'dependent_task_ids': [], 'instruction': 'Create a product requirement document (PRD) for the CLI blackjack game.', 'assignee': 'Alice'}}, {'command_name': 'Plan.append_task', 'args': {'task_id': '2', 'dependent_task_ids': ['1'], 'instruction': 'Design a concise, usable, complete software system for the CLI blackjack game based on the PRD.', 'assignee': 'Bob'}}, {'command_name': 'Plan.append_task', 'args': {'task_id': '3', 'dependent_task_ids': ['2'], 'instruction': 'Implement the CLI blackjack game using Vite, React, MUI, Tailwind CSS, and deploy the web app.', 'assignee': 'Alex'}}, {'command_name': 'TeamLeader.publish_message', 'args': {'content': 'Write a cli blackjack game.', 'send_to': 'Alice'}}, {'command_name': 'RoleZero.reply_to_human', 'args': {'content': 'I have assigned the tasks to the team members. Alice will create the PRD, Bob will design the software architecture, and Alex will implement the CLI blackjack game.'}}]\n2025-04-30 14:00:55.777 | INFO     | metagpt.roles.di.role_zero:_act:324 - Commands outputs: \nCommand Plan.append_task executed\n\nCommand Plan.append_task executed\n\nCommand Plan.append_task executed\n\nCommand TeamLeader.publish_message executed\n\nCommand RoleZero.reply_to_human executed: SUCCESS, human has received your reply. Refrain from resending duplicate messages.  If you no longer need to take action, use the command ‘end’ to stop.\nEnglish\n2025-04-30 14:00:57.313 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.047 | Max budget: $3.000 | Current cost: $0.001, prompt_tokens: 106, completion_tokens: 2\nI understand that I need to create a CLI Blackjack game. To start, I will create a new task to design the game's architecture and then implement the game logic.\n\nHere is my plan:\n\n```json\n[\n    {\n        \"command_name\": \"Task.create\",\n        \"args\": {\"task_id\": \"Design Game Architecture\", \"instruction\": \"Design the architecture of the CLI Blackjack game\", \"task_type\": \"Design\", \"assignee\": \"Alice\"}\n    },\n    {\n        \"command_name\": \"Task.create\",\n        \"args\": {\"task_id\": \"Implement Game Logic\", \"instruction\": \"Implement the game logic for the CLI Blackjack game\", \"task_type\": \"Implementation\", \"assignee\": \"Alice\"}\n    }\n]\n```\n2025-04-30 14:00:58.395 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.062 | Max budget: $3.000 | Current cost: $0.016, prompt_tokens: 1818, completion_tokens: 153\n2025-04-30 14:00:58.395 | INFO     | metagpt.roles.di.role_zero:_act:322 - Commands: \n[{'command_name': 'Task.create', 'args': {'task_id': 'Design Game Architecture', 'instruction': 'Design the architecture of the CLI Blackjack game', 'task_type': 'Design', 'assignee': 'Alice'}}, {'command_name': 'Task.create', 'args': {'task_id': 'Implement Game Logic', 'instruction': 'Implement the game logic for the CLI Blackjack game', 'task_type': 'Implementation', 'assignee': 'Alice'}}]\n2025-04-30 14:00:58.396 | INFO     | metagpt.roles.di.role_zero:_act:324 - Commands outputs: \nCommand Task.create not found.\nI understand that I need to create a CLI Blackjack game. To start, I will create a new task to design the game's architecture and then implement the game logic.\n\nHere is my plan:\n\n```json\n[\n    {\n        \"command_name\": \"Task.create\",\n        \"args\": {\"task_id\": \"Design Game Architecture\", \"instruction\": \"Design the architecture of the CLI Blackjack game\", \"task_type\": \"Design\", \"assignee\": \"Alice\"}\n    },\n    {\n        \"command_name\": \"Task.create\",\n        \"args\": {\"task_id\": \"Implement Game Logic\", \"instruction\": \"Implement the game logic for the CLI Blackjack game\", \"task_type\": \"Implementation\", \"assignee\": \"Alice\"}\n    }\n]\n```\n2025-04-30 14:01:08.609 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.092 | Max budget: $3.000 | Current cost: $0.030, prompt_tokens: 3584, completion_tokens: 152\n2025-04-30 14:01:08.610 | WARNING  | metagpt.roles.di.role_zero:_check_duplicates:436 - Duplicate response detected: I understand that I need to create a CLI Blackjack game. To start, I will create a new task to design the game's architecture and then implement the game logic.\n\nHere is my plan:\n\n```json\n[\n    {\n        \"command_name\": \"Task.create\",\n        \"args\": {\"task_id\": \"Design Game Architecture\", \"instruction\": \"Design the architecture of the CLI Blackjack game\", \"task_type\": \"Design\", \"assignee\": \"Alice\"}\n    },\n    {\n        \"command_name\": \"Task.create\",\n        \"args\": {\"task_id\": \"Implement Game Logic\", \"instruction\": \"Implement the game logic for the CLI Blackjack game\", \"task_type\": \"Implementation\", \"assignee\": \"Alice\"}\n    }\n]\n```\nUpon reviewing the history, I realize that I need to create a plan to write a CLI Blackjack game. Since there is no existing plan, I will create a new plan with the required tasks.\n\nHere are the commands to create a plan:\n\n```json\n[\n    {\n        \"command_name\": \"Plan.create\",\n        \"args\": {\"plan_id\": \"Write CLI Blackjack Game\", \"description\": \"Create a CLI Blackjack game\"}\n    },\n    {\n        \"command_name\": \"Task.create\",\n        \"args\": {\"task_id\": \"Define Game Requirements\", \"instruction\": \"Define the requirements for the CLI Blackjack game\", \"task_type\": \"Research\", \"assignee\": \"Alice\"}\n    }\n]\n```\n2025-04-30 14:01:10.601 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.100 | Max budget: $3.000 | Current cost: $0.007, prompt_tokens: 762, completion_tokens: 145\n2025-04-30 14:01:10.601 | INFO     | metagpt.roles.di.role_zero:_act:322 - Commands: \n[{'command_name': 'Plan.create', 'args': {'plan_id': 'Write CLI Blackjack Game', 'description': 'Create a CLI Blackjack game'}}, {'command_name': 'Task.create', 'args': {'task_id': 'Define Game Requirements', 'instruction': 'Define the requirements for the CLI Blackjack game', 'task_type': 'Research', 'assignee': 'Alice'}}]\n2025-04-30 14:01:10.601 | INFO     | metagpt.roles.di.role_zero:_act:324 - Commands outputs: \nCommand Plan.create not found.\nBased on the goal to write a CLI Blackjack game, I will create a plan to achieve this goal. Since there is no existing plan, I will start by defining the game requirements.\n\nHere are my thoughts:\nI need to define the game requirements, design the game architecture, implement the game logic, and test the game. \n\nHere are the commands to create a plan:\n\n```json\n[\n    {\n        \"command_name\": \"Task.create\",\n        \"args\": {\"task_id\": \"Define Game Requirements\", \"instruction\": \"Define the requirements for the CLI Blackjack game\", \"task_type\": \"Research\", \"assignee\": \"Alice\"}\n    },\n    {\n        \"command_name\": \"Task.create\",\n        \"args\": {\"task_id\": \"Design Game Architecture\", \"instruction\": \"Design the architecture of the CLI Blackjack game\", \"task_type\": \"Design\", \"assignee\": \"Alice\", \"dependent_task_ids\": [\"Define Game Requirements\"]}\n    },\n    {\n        \"command_name\": \"Task.create\",\n        \"args\": {\"task_id\": \"Implement Game Logic\", \"instruction\": \"Implement the game logic for the CLI Blackjack game\", \"task_type\": \"Implementation\", \"assignee\": \"Alice\", \"dependent_task_ids\": [\"Design Game Architecture\"]}\n    },\n    {\n        \"command_name\": \"Task.create\",\n        \"args\": {\"task_id\": \"Test Game\", \"instruction\": \"Test the CLI Blackjack game\", \"task_type\": \"Testing\", \"assignee\": \"Alice\", \"dependent_task_ids\": [\"Implement Game Logic\"]}\n    }\n]\n```\n2025-04-30 14:01:29.290 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.117 | Max budget: $3.000 | Current cost: $0.018, prompt_tokens: 1881, completion_tokens: 321\n2025-04-30 14:01:29.291 | INFO     | metagpt.roles.di.role_zero:_act:322 - Commands: \n[{'command_name': 'Task.create', 'args': {'task_id': 'Define Game Requirements', 'instruction': 'Define the requirements for the CLI Blackjack game', 'task_type': 'Research', 'assignee': 'Alice'}}, {'command_name': 'Task.create', 'args': {'task_id': 'Design Game Architecture', 'instruction': 'Design the architecture of the CLI Blackjack game', 'task_type': 'Design', 'assignee': 'Alice', 'dependent_task_ids': ['Define Game Requirements']}}, {'command_name': 'Task.create', 'args': {'task_id': 'Implement Game Logic', 'instruction': 'Implement the game logic for the CLI Blackjack game', 'task_type': 'Implementation', 'assignee': 'Alice', 'dependent_task_ids': ['Design Game Architecture']}}, {'command_name': 'Task.create', 'args': {'task_id': 'Test Game', 'instruction': 'Test the CLI Blackjack game', 'task_type': 'Testing', 'assignee': 'Alice', 'dependent_task_ids': ['Implement Game Logic']}}]\n2025-04-30 14:01:29.291 | INFO     | metagpt.roles.di.role_zero:_act:324 - Commands outputs: \nCommand Task.create not found.\nBased on the goal to write a CLI Blackjack game, I will create a plan to achieve this goal. Since there is no existing plan, I will start by defining the game requirements.\n\nHere are my thoughts:\nI need to define the game requirements, design the game architecture, implement the game logic, and test the game.\n\nHere are the commands to create a plan:\n\n```json\n[\n    {\"command_name\": \"RoleZero.ask_human\", \"args\": {\"question\": \"Can you provide more details about the CLI Blackjack game, such as the rules and features required?\"}},\n    {\"command_name\": \"Task.create\", \"args\": {\"task_id\": \"Define Game Requirements\", \"instruction\": \"Define the requirements for the CLI Blackjack game\", \"task_type\": \"Research\", \"assignee\": \"Alice\"}}\n]\n```\n2025-04-30 14:01:30.224 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.134 | Max budget: $3.000 | Current cost: $0.017, prompt_tokens: 1986, completion_tokens: 167\n2025-04-30 14:01:30.225 | INFO     | metagpt.roles.di.role_zero:_act:322 - Commands: \n[{'command_name': 'RoleZero.ask_human', 'args': {'question': 'Can you provide more details about the CLI Blackjack game, such as the rules and features required?'}}, {'command_name': 'Task.create', 'args': {'task_id': 'Define Game Requirements', 'instruction': 'Define the requirements for the CLI Blackjack game', 'task_type': 'Research', 'assignee': 'Alice'}}]\nCan you provide more details about the CLI Blackjack game, such as the rules and features required?each card is worth the value indicated in the number. Jack, Queen, and King cards are worth 10. Aces are worth 11 or 1. The objective is to achieve 21 points or the closest to 21. If you beat the dealer then you win.\n2025-04-30 14:02:43.895 | INFO     | metagpt.roles.di.role_zero:_act:324 - Commands outputs: \nCommand RoleZero.ask_human executed:Human response: each card is worth the value indicated in the number. Jack, Queen, and King cards are worth 10. Aces are worth 11 or 1. The objective is to achieve 21 points or the closest to 21. If you beat the dealer then you win.\n\nCommand Task.create not found.\nBased on the goal to write a CLI Blackjack game, I will create a plan to achieve this goal. Since there is no existing plan, I will start by defining the game requirements.\n\nHere are my thoughts:\nI have received the game requirements from the human user, which include the card values and the objective of the game. Next, I will create a task to design the game architecture.\n\nHere are the commands to create a plan:\n\n```json\n[\n    {\"command_name\": \"Task.create\", \"args\": {\"task_id\": \"Define Game Requirements\", \"instruction\": \"Define the requirements for the CLI Blackjack game\", \"task_type\": \"Research\", \"assignee\": \"Alice\", \"status\": \"Completed\"}},\n    {\"command_name\": \"Task.create\", \"args\": {\"task_id\": \"Design Game Architecture\", \"instruction\": \"Design the architecture of the CLI Blackjack game\", \"task_type\": \"Design\", \"assignee\": \"Alice\"}}\n]\n```\n2025-04-30 14:02:47.588 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.152 | Max budget: $3.000 | Current cost: $0.018, prompt_tokens: 2045, completion_tokens: 196\n2025-04-30 14:02:47.589 | INFO     | metagpt.roles.di.role_zero:_act:322 - Commands: \n[{'command_name': 'Task.create', 'args': {'task_id': 'Define Game Requirements', 'instruction': 'Define the requirements for the CLI Blackjack game', 'task_type': 'Research', 'assignee': 'Alice', 'status': 'Completed'}}, {'command_name': 'Task.create', 'args': {'task_id': 'Design Game Architecture', 'instruction': 'Design the architecture of the CLI Blackjack game', 'task_type': 'Design', 'assignee': 'Alice'}}]\n2025-04-30 14:02:47.590 | INFO     | metagpt.roles.di.role_zero:_act:324 - Commands outputs: \nCommand Task.create not found.\nBased on the goal to write a CLI Blackjack game, I will create a plan to achieve this goal. Since there is no existing plan, I will start by defining the game requirements and designing the game architecture.\n\nHere are my thoughts:\nI have received the game requirements from the human user, which include the card values and the objective of the game. Next, I will create a task to design the game architecture.\n\n```json\n[\n    {\"command_name\": \"RoleZero.reply_to_human\", \"args\": {\"content\": \"I have received the game requirements. Next, I will design the game architecture.\"}},\n    {\"command_name\": \"RoleZero.ask_human\", \"args\": {\"question\": \"Can you provide more details about the game architecture, such as the classes and methods required?\"}}\n]\n```\n2025-04-30 14:02:48.619 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.171 | Max budget: $3.000 | Current cost: $0.018, prompt_tokens: 2125, completion_tokens: 163\n2025-04-30 14:02:48.620 | INFO     | metagpt.roles.di.role_zero:_act:322 - Commands: \n[{'command_name': 'RoleZero.reply_to_human', 'args': {'content': 'I have received the game requirements. Next, I will design the game architecture.'}}, {'command_name': 'RoleZero.ask_human', 'args': {'question': 'Can you provide more details about the game architecture, such as the classes and methods required?'}}]\nCan you provide more details about the game architecture, such as the classes and methods required?we want to get the hand value, points per card value, and other general utility functions.\n2025-04-30 14:03:37.899 | INFO     | metagpt.roles.di.role_zero:_act:324 - Commands outputs: \nCommand RoleZero.reply_to_human executed: SUCCESS, human has received your reply. Refrain from resending duplicate messages.  If you no longer need to take action, use the command ‘end’ to stop.\n\nCommand RoleZero.ask_human executed:Human response: we want to get the hand value, points per card value, and other general utility functions.\nBased on the goal to write a CLI Blackjack game, I will create a plan to achieve this goal. Since there is no existing plan, I will start by defining the game requirements and designing the game architecture.\n\nI have received the game requirements from the human user, which include the card values and the objective of the game. I have also received the details about the game architecture, which include getting the hand value, points per card value, and other general utility functions.\n\nNext, I will create tasks to implement the game logic and test the game.\n\n```json\n[\n    {\"command_name\": \"Task.create\", \"args\": {\"task_id\": \"Design Game Architecture\", \"instruction\": \"Design the architecture of the CLI Blackjack game\", \"task_type\": \"Design\", \"assignee\": \"Alice\", \"status\": \"Completed\"}},\n    {\"command_name\": \"Task.create\", \"args\": {\"task_id\": \"Implement Game Logic\", \"instruction\": \"Implement the game logic for the CLI Blackjack game\", \"task_type\": \"Implementation\", \"assignee\": \"Alice\"}},\n    {\"command_name\": \"Task.create\", \"args\": {\"task_id\": \"Test Game\", \"instruction\": \"Test the CLI Blackjack game\", \"task_type\": \"Testing\", \"assignee\": \"Alice\", \"dependent_task_ids\": [\"Implement Game Logic\"]}}\n]\n```\n2025-04-30 14:03:42.564 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.190 | Max budget: $3.000 | Current cost: $0.019, prompt_tokens: 2161, completion_tokens: 275\n2025-04-30 14:03:42.565 | INFO     | metagpt.roles.di.role_zero:_act:322 - Commands: \n[{'command_name': 'Task.create', 'args': {'task_id': 'Design Game Architecture', 'instruction': 'Design the architecture of the CLI Blackjack game', 'task_type': 'Design', 'assignee': 'Alice', 'status': 'Completed'}}, {'command_name': 'Task.create', 'args': {'task_id': 'Implement Game Logic', 'instruction': 'Implement the game logic for the CLI Blackjack game', 'task_type': 'Implementation', 'assignee': 'Alice'}}, {'command_name': 'Task.create', 'args': {'task_id': 'Test Game', 'instruction': 'Test the CLI Blackjack game', 'task_type': 'Testing', 'assignee': 'Alice', 'dependent_task_ids': ['Implement Game Logic']}}]\n2025-04-30 14:03:42.565 | INFO     | metagpt.roles.di.role_zero:_act:324 - Commands outputs: \nCommand Task.create not found.\nBased on the goal to write a CLI Blackjack game, I will create a plan to achieve this goal. Since there is no existing plan, I will start by defining the game requirements and designing the game architecture.\n\nI have received the game requirements from the human user, which include the card values and the objective of the game. I have also received the details about the game architecture, which include getting the hand value, points per card value, and other general utility functions.\n\nNext, I will create tasks to implement the game logic and test the game.\n\n```json\n[\n    {\"command_name\": \"Editor.create_file\", \"args\": {\"filename\": \"blackjack_game.py\"}},\n    {\"command_name\": \"Editor.append_file\", \"args\": {\"file_name\": \"blackjack_game.py\", \"content\": \"class Card:\\n    def __init__(self, value, suit):\\n        self.value = value\\n        self.suit = suit\\n\\n    def __repr__(self):\\n        return f'{self.value} of {self.suit}'}\"},\n    {\"command_name\": \"Editor.append_file\", \"args\": {\"file_name\": \"blackjack_game.py\", \"content\": \"\\n\\ndef calculate_hand_value(hand):\\n    # implement hand value calculation logic\\n    pass\"}}\n]\n```\n2025-04-30 14:03:57.308 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.221 | Max budget: $3.000 | Current cost: $0.031, prompt_tokens: 3563, completion_tokens: 265\n2025-04-30 14:03:57.309 | WARNING  | metagpt.roles.di.role_zero:_parse_commands:459 - Failed to parse JSON for: Based on the goal to write a CLI Blackjack game, I will create a plan to achieve this goal. Since there is no existing plan, I will start by defining the game requirements and designing the game architecture.\n\nI have received the game requirements from the human user, which include the card values and the objective of the game. I have also received the details about the game architecture, which include getting the hand value, points per card value, and other general utility functions.\n\nNext, I will create tasks to implement the game logic and test the game.\n\n```json\n[\n    {\"command_name\": \"Editor.create_file\", \"args\": {\"filename\": \"blackjack_game.py\"}},\n    {\"command_name\": \"Editor.append_file\", \"args\": {\"file_name\": \"blackjack_game.py\", \"content\": \"class Card:\\n    def __init__(self, value, suit):\\n        self.value = value\\n        self.suit = suit\\n\\n    def __repr__(self):\\n        return f'{self.value} of {self.suit}'}\"},\n    {\"command_name\": \"Editor.append_file\", \"args\": {\"file_name\": \"blackjack_game.py\", \"content\": \"\\n\\ndef calculate_hand_value(hand):\\n    # implement hand value calculation logic\\n    pass\"}}\n]\n```. Trying to repair...\nI'd be happy to help you with that.\n\nAfter reviewing the JSON data, I noticed that there are some formatting issues. Here is the corrected JSON data:\n\n```json\n[\n    {\"command_name\": \"Editor.create_file\", \"args\": {\"filename\": \"blackjack_game.py\"}},\n    {\"command_name\": \"Editor.append_file\", \"args\": {\"file_name\": \"blackjack_game.py\", \"content\": \"class Card:\\n    def __init__(self, value, suit):\\n        self.value = value\\n        self.suit = suit\\n\\n    def __repr__(self):\\n        return f'{self.value} of {self.suit}'}},\n    {\"command_name\": \"Editor.append_file\", \"args\": {\"file_name\": \"blackjack_game.py\", \"content\": \"\\ndef calculate_hand_value(hand):\\n    # implement hand value calculation logic\\n    pass\"}}\n]\n```\n\nThe issues were:\n\n1. The JSON data was not properly formatted, with inconsistent indentation and missing commas.\n2. The file paths were not enclosed in double quotes, which is required in JSON.\n\nI've corrected these issues, and the JSON data should now be loadable by the `json.loads()` function.\n2025-04-30 14:04:11.195 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.226 | Max budget: $3.000 | Current cost: $0.006, prompt_tokens: 453, completion_tokens: 249\n2025-04-30 14:04:11.246 | ERROR    | metagpt.utils.common:wrapper:683 - Exception occurs, start to serialize the project, exp:\nTraceback (most recent call last):\n  File \"/Users/cmodi/Documents/ai/llama-api/MetaGPT/metagpt/roles/di/role_zero.py\", line 457, in _parse_commands\n    commands = json.loads(repair_llm_raw_output(output=commands, req_keys=[None], repair_type=RepairType.JSON))\n  File \"/opt/anaconda3/envs/metagpt/lib/python3.10/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\njson.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 4 column 5 (char 373)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/cmodi/Documents/ai/llama-api/MetaGPT/metagpt/roles/di/role_zero.py\", line 464, in _parse_commands\n    commands = json.loads(CodeParser.parse_code(block=None, lang=\"json\", text=commands))\n  File \"/opt/anaconda3/envs/metagpt/lib/python3.10/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\njson.decoder.JSONDecodeError: Invalid control character at: line 3 column 279 (char 367)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/cmodi/Documents/ai/llama-api/MetaGPT/metagpt/utils/common.py\", line 692, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"/Users/cmodi/Documents/ai/llama-api/MetaGPT/metagpt/roles/role.py\", line 548, in run\n    rsp = await self.react()\njson.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 4 column 5 (char 373)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/cmodi/Documents/ai/llama-api/MetaGPT/metagpt/utils/common.py\", line 678, in wrapper\n    result = await func(self, *args, **kwargs)\n  File \"/Users/cmodi/Documents/ai/llama-api/MetaGPT/metagpt/team.py\", line 134, in run\n    await self.env.run()\nException: Traceback (most recent call last):\n  File \"/Users/cmodi/Documents/ai/llama-api/MetaGPT/metagpt/roles/di/role_zero.py\", line 457, in _parse_commands\n    commands = json.loads(repair_llm_raw_output(output=commands, req_keys=[None], repair_type=RepairType.JSON))\n  File \"/opt/anaconda3/envs/metagpt/lib/python3.10/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n  File \"/opt/anaconda3/envs/metagpt/lib/python3.10/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File \"/opt/anaconda3/envs/metagpt/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n    obj, end = self.scan_once(s, idx)\njson.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 4 column 5 (char 373)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/cmodi/Documents/ai/llama-api/MetaGPT/metagpt/roles/di/role_zero.py\", line 464, in _parse_commands\n    commands = json.loads(CodeParser.parse_code(block=None, lang=\"json\", text=commands))\n  File \"/opt/anaconda3/envs/metagpt/lib/python3.10/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n  File \"/opt/anaconda3/envs/metagpt/lib/python3.10/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File \"/opt/anaconda3/envs/metagpt/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n    obj, end = self.scan_once(s, idx)\njson.decoder.JSONDecodeError: Invalid control character at: line 3 column 279 (char 367)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/cmodi/Documents/ai/llama-api/MetaGPT/metagpt/utils/common.py\", line 692, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"/Users/cmodi/Documents/ai/llama-api/MetaGPT/metagpt/roles/role.py\", line 548, in run\n    rsp = await self.react()\n  File \"/Users/cmodi/Documents/ai/llama-api/MetaGPT/metagpt/roles/role.py\", line 515, in react\n    rsp = await self._react()\n  File \"/Users/cmodi/Documents/ai/llama-api/MetaGPT/metagpt/roles/di/role_zero.py\", line 354, in _react\n    rsp = await self._act()\n  File \"/Users/cmodi/Documents/ai/llama-api/MetaGPT/metagpt/roles/di/role_zero.py\", line 316, in _act\n    commands, ok, self.command_rsp = await self._parse_commands(self.command_rsp)\n  File \"/Users/cmodi/Documents/ai/llama-api/MetaGPT/metagpt/roles/di/role_zero.py\", line 469, in _parse_commands\n    commands = json.loads(\n  File \"/opt/anaconda3/envs/metagpt/lib/python3.10/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n  File \"/opt/anaconda3/envs/metagpt/lib/python3.10/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File \"/opt/anaconda3/envs/metagpt/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n    obj, end = self.scan_once(s, idx)\njson.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 4 column 5 (char 373)\n\n\n/opt/anaconda3/envs/metagpt/lib/python3.10/site-packages/pydantic/_internal/_std_types_schema.py:319: UserWarning: Pydantic serializer warnings:\n  Expected `enum` but got `str` with value `'react'` - serialized value may not be as expected\n  return handler(v)\n/Users/cmodi/Documents/ai/llama-api/MetaGPT/metagpt/base/base_serialization.py:26: UserWarning: Pydantic serializer warnings:\n  Expected `enum` but got `str` with value `'react'` - serialized value may not be as expected\n  ret = default_serializer(self)\n```",
      "state": "open",
      "author": "cmodi-meta",
      "author_type": "User",
      "created_at": "2025-04-30T21:39:09Z",
      "updated_at": "2025-06-18T00:35:50Z",
      "closed_at": null,
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1819/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1819",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1819",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:49.716217",
      "comments": [
        {
          "author": "better629",
          "body": "@cmodi-meta the output of the llm \n\n```\n[\n    {\"command_name\": \"Editor.create_file\", \"args\": {\"filename\": \"blackjack_game.py\"}},\n    {\"command_name\": \"Editor.append_file\", \"args\": {\"file_name\": \"blackjack_game.py\", \"content\": \"class Card:\\n    def __init__(self, value, suit):\\n        self.value = v",
          "created_at": "2025-05-14T05:53:03Z"
        },
        {
          "author": "cmodi-meta",
          "body": "Thank you for the reply @better629 . I've tried using other models like from OpenAI as well and I run into the same issue. I suspect there may be an issue with env set-up? Would you be able to provide a step by step with a openrouter provider (or any other provider) model to help get started?\n\nI'd l",
          "created_at": "2025-05-15T01:15:20Z"
        },
        {
          "author": "cmodi-meta",
          "body": "@better629 or rather is there a set of instructions you can provide to work with the [openrouter-llama3-70b-instruct.yaml](https://github.com/FoundationAgents/MetaGPT/blob/main/config/examples/openrouter-llama3-70b-instruct.yaml)) since that's a pre-config'd yaml file that we can use out of the box.",
          "created_at": "2025-05-15T08:22:03Z"
        },
        {
          "author": "limboys",
          "body": "llmapi configration doc here:https://docs.deepwisdom.ai/main/en/guide/get_started/configuration/llm_api_configuration.html",
          "created_at": "2025-05-18T09:35:39Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-18T00:35:49Z"
        }
      ]
    },
    {
      "issue_number": 1821,
      "title": "Gemini Models -  504 Deadline Exceeded and BlockedPromptException",
      "body": "**Bug description**\n<!-- Clearly and directly describe the current bug -->\nHi, when I use Gemini models, I keep running into 504 Deadline exceeded and BlockedPromptException errors. \nGuess the Gemini_Api code inside the /provider needs to be tweaked with better timeout and safety settings. \n\n\n**Environment information**\n<!-- Environment：System version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\nUbuntu 24.04\nGemini 2.5 pro\nPython 3.11.7\nMetagpt 0.0.8\n",
      "state": "closed",
      "author": "krish240574",
      "author_type": "User",
      "created_at": "2025-05-02T01:08:15Z",
      "updated_at": "2025-06-18T00:35:49Z",
      "closed_at": "2025-06-18T00:35:49Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1821/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1821",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1821",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:49.903985",
      "comments": [
        {
          "author": "krish240574",
          "body": "errors: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\nresponse:\nGenerateContentResponse(\n    done=True,\n    iterator=None,\n    result=glm.GenerateContentResponse",
          "created_at": "2025-05-03T11:54:18Z"
        },
        {
          "author": "krish240574",
          "body": "this makes the Gemini models pretty much unusable with MetaGPT - context of 1 million tokens ! ",
          "created_at": "2025-05-03T11:54:36Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-03T00:36:23Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-06-18T00:35:48Z"
        }
      ]
    },
    {
      "issue_number": 1773,
      "title": "AttributeError: 'NoneType' object has no attribute 'profile'",
      "body": "在运行“辩论：智能体对抗”的代码时，[MetaGPT](https://github.com/geekan/MetaGPT/tree/main)/[examples](https://github.com/geekan/MetaGPT/tree/main/examples)\n/debate.py\n报错：\nAttributeError: 'NoneType' object has no attribute 'profile'\n\n\n添加teamleader能运行，但输出不是辩论内容，而只有一段话。",
      "state": "open",
      "author": "xukaizhao",
      "author_type": "User",
      "created_at": "2025-03-19T14:27:38Z",
      "updated_at": "2025-06-17T00:35:53Z",
      "closed_at": null,
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1773/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1773",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1773",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:50.119063",
      "comments": [
        {
          "author": "RatexMak",
          "body": "一样的故障，请问解决了吗？",
          "created_at": "2025-04-16T02:30:30Z"
        },
        {
          "author": "stayfoo",
          "body": "修改配置：MetaGPT/metagpt/const.py  中的 TEAMLEADER_NAME 为自己定义的\n\n```\n# TEAMLEADER_NAME = \"Mike\"\nTEAMLEADER_NAME = \"程序员Alice\"\n```",
          "created_at": "2025-04-26T09:32:02Z"
        },
        {
          "author": "Xinyuz26",
          "body": "> 修改配置：MetaGPT/metagpt/const.py 中的 TEAMLEADER_NAME 为自己定义的\n> \n> ```\n> # TEAMLEADER_NAME = \"Mike\"\n> TEAMLEADER_NAME = \"程序员Alice\"\n> ```\n\n请问teamleader在这里的作用是什么呢\n",
          "created_at": "2025-04-29T03:26:52Z"
        },
        {
          "author": "qianweijiujiu",
          "body": "Have you ever fixed it. I tried to modify the const TEAMLEADER_NAME but it didn't work.",
          "created_at": "2025-04-29T11:12:36Z"
        },
        {
          "author": "Zha-Miku",
          "body": "> > 修改配置：MetaGPT/metagpt/const.py 中的 TEAMLEADER_NAME 为自己定义的\n> > ```\n> > # TEAMLEADER_NAME = \"Mike\"\n> > TEAMLEADER_NAME = \"程序员Alice\"\n> > ```\n> \n> 请问teamleader在这里的作用是什么呢\n\nnot work",
          "created_at": "2025-05-01T08:04:50Z"
        }
      ]
    },
    {
      "issue_number": 1832,
      "title": "Is this project being abondoned?",
      "body": "I see very few updates and bug fixes, things have slowed down here drastically - is this project dying? \nIt will be very sad to see it go, it is a brilliant piece of work. ",
      "state": "open",
      "author": "krish240574",
      "author_type": "User",
      "created_at": "2025-05-17T12:27:52Z",
      "updated_at": "2025-06-17T00:35:51Z",
      "closed_at": null,
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1832/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 1,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1832",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1832",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:50.463606",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-17T00:35:51Z"
        }
      ]
    },
    {
      "issue_number": 1778,
      "title": "ImportError: cannot import name 'model_validator' from 'pydantic'",
      "body": "**Bug description**\n当采用python 3.10的时候，执行：\n```sh\npython -m examples.spo.optimize\n```\n有 File \"N:\\Python-virtual-envir\\MetaGPT_programs\\lib\\site-packages\\semantic_kernel\\connectors\\ai\\function_choice_behavior.py\", line 12, in <module>\n    from semantic_kernel.kernel_pydantic import KernelBaseModel\n  File \"N:\\Python-virtual-envir\\MetaGPT_programs\\lib\\site-packages\\semantic_kernel\\kernel_pydantic.py\", line 7, in <module>        \n    from pydantic.networks import Url\nImportError: cannot import name 'Url' from 'pydantic.networks' (N:\\Python-virtual-envir\\MetaGPT_programs\\lib\\site-packages\\pydantic\\networks.py) 这个问题；\n然而GPT 的分析结果为：\n问题原因：\n\n根据 [Pydantic 官方迁移指南](https://pydantic.com.cn/migration/)，在 Pydantic V2 中，pydantic.networks 中的 Url 类型已被移除或重构。这意味着，如果您的项目或其依赖项（如 semantic-kernel）仍在尝试从 pydantic.networks 导入 Url，且您使用的是 Pydantic V2，则会出现此导入错误。\n因此我采用了\n```sh\npip install pydantic==1.10.*\n```\n再次执行：\n```sh\npython -m examples.spo.optimize\n```\n出现了如下错误：\n  File \"N:\\Python-virtual-envir\\MetaGPT_programs\\lib\\site-packages\\semantic_kernel\\connectors\\ai\\prompt_execution_settings.py\", line 6, in <module>\n    from pydantic import Field, model_validator\nImportError: cannot import name 'model_validator' from 'pydantic' (N:\\Python-virtual-envir\\MetaGPT_programs\\lib\\site-packages\\pydantic\\__init__.cp310-win_amd64.pyd)\n分析得到 ：\n这通常是由于 pydantic 版本兼容性问题引起的。根据 [Pydantic 官方文档](https://docs.pydantic.dev/2.0/usage/validators/)，model_validator 是在 Pydantic V2 中引入的。如果您的代码或其依赖项尝试导入 model_validator，但当前环境中安装的是 Pydantic V1，则会出现此错误。\n因此这个问题总的来说是，pydantic 小于2.0和大于等于2.0 也就是整个项目中存在引用pydantic这个库时候出现依赖冲突错误；\n\n**Environment information**\n<!-- Environment：System version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\n\n- LLM type and model name:\n- System version:\n- Python version:\n- MetaGPT version or branch:\n\n<!-- Dependent packagess：the packages version cause the bug(like `pydantic 1.10.8`), installation method（like `pip install metagpt` or `pip install from source` or `run in docker`） -->\n\n- packages version:\n- installation method: \n\n**Screenshots or logs**\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->",
      "state": "open",
      "author": "lijiandao",
      "author_type": "User",
      "created_at": "2025-03-21T07:08:53Z",
      "updated_at": "2025-06-16T00:37:52Z",
      "closed_at": null,
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1778/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1778",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1778",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:50.662268",
      "comments": [
        {
          "author": "Lluvia-Tang",
          "body": "怎么解决呢？\n",
          "created_at": "2025-04-21T11:10:42Z"
        },
        {
          "author": "better629",
          "body": "use `pydantic 2.x` and remove `semantic_kernel`",
          "created_at": "2025-05-16T12:58:41Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-16T00:37:51Z"
        }
      ]
    },
    {
      "issue_number": 1417,
      "title": "humaneval",
      "body": "请问可以提供测试humaneval的相关方法吗，现在想要进行测试但是完全不知道该如何下手，generate_repo返回的是一个Projectrepo类型不能被转换成jsonl，希望作者能加上去，谢谢。\r\n",
      "state": "closed",
      "author": "codeAlwaysPass",
      "author_type": "User",
      "created_at": "2024-07-27T09:28:01Z",
      "updated_at": "2025-06-11T16:16:43Z",
      "closed_at": "2025-02-01T00:32:41Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1417/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "stellaHSR"
      ],
      "milestone": "1.0",
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1417",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1417",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:50.864930",
      "comments": [
        {
          "author": "iorisa",
          "body": "ProjectRepo对应的是一个文件夹路径。如果要转JSON，本质上是将一个文件夹转JSON。\r\n你希望转成什么样的JSON？\r\n@codeAlwaysPass ",
          "created_at": "2024-07-29T07:41:05Z"
        },
        {
          "author": "codeAlwaysPass",
          "body": "我希望转成一个可以让humaneval评估的jsonl文件，目前我是自己写python脚本把文件夹里面的代码写入jsonl，但可能是由于我的代码问题这样得到的jsonl获得的准确率只有0.27。",
          "created_at": "2024-07-29T08:14:13Z"
        },
        {
          "author": "stellaHSR",
          "body": "由于版本迭代新增功能且迭代较快，engineer 中增加了不少 repo 级别的处理和设计。针对 HumanEval，我建议你先熟悉并使用 v0.4-release 或者之前的版本。在这个版本中，你可以获取 engineer 的执行结果（`msg = Message(content=code, role=self.profile, cause_by=WriteCode)`）。你可以选择在 msg 生成之前直接将code保存到JSONL文件，或者在 engineer 执行结束后，通过 memory 的 `get_by_action`s 函数来获取代码，再将其写入 JSONL 文件。:)",
          "created_at": "2024-10-11T06:35:21Z"
        },
        {
          "author": "geekan",
          "body": "There will be some scripts related to humaneval in version 1.0",
          "created_at": "2024-10-20T07:05:45Z"
        },
        {
          "author": "wkwk-ai",
          "body": "请问现在有可以测试humaneval的script了吗？",
          "created_at": "2024-12-17T06:47:49Z"
        }
      ]
    },
    {
      "issue_number": 1811,
      "title": "ui_with_chainlit 界面无响应",
      "body": "![Image](https://github.com/user-attachments/assets/03b1c325-9ade-4d3d-9309-a21a94b51da7)",
      "state": "closed",
      "author": "liang-tian-tian",
      "author_type": "User",
      "created_at": "2025-04-15T11:18:38Z",
      "updated_at": "2025-06-11T00:35:56Z",
      "closed_at": "2025-06-11T00:35:56Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1811/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1811",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1811",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:51.103899",
      "comments": [
        {
          "author": "HuntZhaozq",
          "body": "遇到了同样的问题，请问你解决了吗",
          "created_at": "2025-04-27T06:49:28Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-28T00:35:18Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-06-11T00:35:56Z"
        }
      ]
    },
    {
      "issue_number": 1817,
      "title": "manual_example.png missing in android_assistant",
      "body": "https://github.com/geekan/MetaGPT/blob/be6921cae61471bf1ffaf9cb9fe7375a6cfd00c5/metagpt/ext/android_assistant/README.md?plain=1#L32\n\n`./resources` is not exist. And I try find in repo but get nothing. `manual_example.png` not exist in examples/android_assistant, docs/resources. README_CN.md has same issue.",
      "state": "closed",
      "author": "BackMountainDevil",
      "author_type": "User",
      "created_at": "2025-04-26T02:52:16Z",
      "updated_at": "2025-06-10T00:35:47Z",
      "closed_at": "2025-06-10T00:35:47Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1817/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1817",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1817",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:51.293114",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-27T00:34:35Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-06-10T00:35:46Z"
        }
      ]
    },
    {
      "issue_number": 1823,
      "title": "the for-loop didn't really carry out in the check of backpropagation",
      "body": "**Bug description**\n<!-- Clearly and directly describe the current bug -->\n  https://github.com/FoundationAgents/MetaGPT/blob/be6921cae61471bf1ffaf9cb9fe7375a6cfd00c5/metagpt/ext/sela/experimenter.py#L87\nHere `i` didn't really be placed in the index\n\n**Bug solved method**\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\n\n**Environment information**\n<!-- Environment：System version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\n\n- LLM type and model name:\n- System version:\n- Python version:\n- MetaGPT version or branch:\n\n<!-- Dependent packagess：the packages version cause the bug(like `pydantic 1.10.8`), installation method（like `pip install metagpt` or `pip install from source` or `run in docker`） -->\n\n- packages version:\n- installation method: \n\n**Screenshots or logs**\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->",
      "state": "closed",
      "author": "zuxfoucault",
      "author_type": "User",
      "created_at": "2025-05-05T03:14:49Z",
      "updated_at": "2025-06-06T01:01:37Z",
      "closed_at": "2025-06-06T01:01:37Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1823/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1823",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1823",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:51.453925",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-05T00:35:51Z"
        }
      ]
    },
    {
      "issue_number": 1814,
      "title": "agent 跑到一半卡住了，不会再运行了， 2025-04-22 17:36:21.365 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.000 | Max budget: $1000.000 | Current cost: $0.000, prompt_tokens: 2048, completion_tokens: 381",
      "body": "2025-04-22 17:36:21.365 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.000 | Max budget: $1000.000 | Current cost: $0.000, prompt_tokens: 2048, completion_tokens: 381\n\n这是那个受限制了吗",
      "state": "closed",
      "author": "wangxiaohangxdu",
      "author_type": "User",
      "created_at": "2025-04-22T09:43:04Z",
      "updated_at": "2025-06-06T00:35:27Z",
      "closed_at": "2025-06-06T00:35:27Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1814/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1814",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1814",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:51.627130",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-23T00:35:22Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-06-06T00:35:27Z"
        }
      ]
    },
    {
      "issue_number": 1813,
      "title": "0.8.2版本无法识别提示词中的文件地址，0.8.1版本可以，提示词要求是否有变化？",
      "body": "问题：在利用machine_learning.py分析数据文件时，提示词中有指定的文件，但任务无法识别\n\n版本：0.8.2\n\n提示词：将所有文件的[工作表1]中大区为\"大区K\"的数据合并为一个新的文件 输入文件保存在/home/admin/ai-metagpt-task/2025-04-07/d20783dc-5a86-48f4-9eb5-4ec817b87664/国民饮水守护计划0118.xlsx 输入文件保存在/home/admin/ai-metagpt-task/2025-04-07/d20783dc-5a86-48f4-9eb5-4ec817b87664/国民饮水守护计划0119.xlsx 输入文件保存在home/admin/ai-metagpt-task/2025-04-07/d20783dc-5a86-48f4-9eb5-4ec817b87664/国民饮水守护计划0120.xlsx 输出文件保存在/home/admin/ai-metagpt-task/2025-04-20/1e1ceb76-e1c4-47cf-8886-d1605966f00a/res_时间戳.xlsx\n\n<img width=\"602\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/6900c933-6b70-493f-a0ba-754d1d1d6956\" />",
      "state": "closed",
      "author": "dingdangmaozj",
      "author_type": "User",
      "created_at": "2025-04-20T10:41:05Z",
      "updated_at": "2025-06-04T00:36:09Z",
      "closed_at": "2025-06-04T00:36:08Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1813/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1813",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1813",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:51.814844",
      "comments": [
        {
          "author": "dingdangmaozj",
          "body": "上述接入的模型为gpt-4o",
          "created_at": "2025-04-20T10:45:05Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-21T00:35:34Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-06-04T00:36:07Z"
        }
      ]
    },
    {
      "issue_number": 1783,
      "title": "Crash after running for a period of time",
      "body": "### Bug Description\n\nI followed the steps in the README and ran the command to create a simple NestJS module. However, after running for a while, it crashed.\n\n### Bug solved method\n\n- None\n\n### Environment information\n\n- System version: Linux\n- Python version: 3.10\n- OpenManus version or branch: main\n- Installation method:\n```bash\ngit clone https://github.com/geekan/MetaGPT && cd MetaGPT && pip install --upgrade -e .\nmetagpt --init-config\n```\n- ollama version is 0.6.2\n#### config\n```\nllm:\napi_type: ollama\nmodel: \"phi4\"\nbase_url: \"http://localhost:11434/api\"\ntimeout: 9000\n\nbrowser:\nengine: \"playwright\" # playwright/selenium\nbrowser_type: \"firefox\"\n```\n\n\n### Extra information\n\n![Image](https://github.com/user-attachments/assets/c8e7e79c-0d9a-4873-9c81-bc66a9805217)\n\n#### logs\n\n```\nTo fix it, ensure all keys are in double quotes:\n\njson\n{\n  \"name\": \"John Doe\",\n  \"age\": 30,\n  \"courses\": [\"Math\", \"Science\"]\n}\n\n\n### Conclusion\n\nIf you provide the JSON data that is causing issues, I can help identify specific problems. Otherwise, follow the above guidelines to ensure your JSON is correctly formatted for `json.loads()` to process without errors. If no issues are detected in your input, it should be returned unchanged.\n2025-03-22 11:09:35.662 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.000 | Max budget: $3.000 | Current cost: $0.000, prompt_tokens: 1541, completion_tokens: 640\n2025-03-22 11:09:35.663 | ERROR    | metagpt.utils.common:wrapper:683 - Exception occurs, start to serialize the project, exp:\nTraceback (most recent call last):\n  File \"/mnt/ForAI/workspaces/MetaGPT/metagpt/utils/common.py\", line 692, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"/mnt/ForAI/workspaces/MetaGPT/metagpt/roles/role.py\", line 548, in run\n    rsp = await self.react()\nKeyError: 'command_name'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/mnt/ForAI/workspaces/MetaGPT/metagpt/utils/common.py\", line 678, in wrapper\n    result = await func(self, *args, **kwargs)\n  File \"/mnt/ForAI/workspaces/MetaGPT/metagpt/team.py\", line 134, in run\n    await self.env.run()\nException: Traceback (most recent call last):\n  File \"/mnt/ForAI/workspaces/MetaGPT/metagpt/utils/common.py\", line 692, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"/mnt/ForAI/workspaces/MetaGPT/metagpt/roles/role.py\", line 548, in run\n    rsp = await self.react()\n  File \"/mnt/ForAI/workspaces/MetaGPT/metagpt/roles/role.py\", line 515, in react\n    rsp = await self._react()\n  File \"/mnt/ForAI/workspaces/MetaGPT/metagpt/roles/di/role_zero.py\", line 354, in _react\n    rsp = await self._act()\n  File \"/mnt/ForAI/workspaces/MetaGPT/metagpt/roles/di/role_zero.py\", line 316, in _act\n    commands, ok, self.command_rsp = await self._parse_commands(self.command_rsp)\n  File \"/mnt/ForAI/workspaces/MetaGPT/metagpt/roles/di/role_zero.py\", line 483, in _parse_commands\n    command_flag = [command[\"command_name\"] not in self.exclusive_tool_commands for command in commands]\n  File \"/mnt/ForAI/workspaces/MetaGPT/metagpt/roles/di/role_zero.py\", line 483, in <listcomp>\n    command_flag = [command[\"command_name\"] not in self.exclusive_tool_commands for command in commands]\nKeyError: 'command_name'\n\n\n/home/xdien/.venv/lib/python3.10/site-packages/pydantic/_internal/_std_types_schema.py:319: UserWarning: Pydantic serializer warnings:\n  Expected `enum` but got `str` with value `'react'` - serialized value may not be as expected\n  return handler(v)\n/mnt/ForAI/workspaces/MetaGPT/metagpt/base/base_serialization.py:26: UserWarning: Pydantic serializer warnings:\n  Expected `enum` but got `str` with value `'react'` - serialized value may not be as expected\n  ret = default_serializer(self)\n```",
      "state": "closed",
      "author": "xdien",
      "author_type": "User",
      "created_at": "2025-03-22T05:07:28Z",
      "updated_at": "2025-06-03T00:36:29Z",
      "closed_at": "2025-06-03T00:36:26Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1783/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1783",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1783",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:52.043175",
      "comments": [
        {
          "author": "nileshkokane01",
          "body": "this error occurs for most of the examples. For instance : write_design.py , write_game_code.py etc.  Can anyone let us know the fix?",
          "created_at": "2025-04-19T11:38:44Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-20T00:35:57Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-06-03T00:36:26Z"
        }
      ]
    },
    {
      "issue_number": 1770,
      "title": "openai api配置-提示错误，已经在项目文件下配置好config2.yaml",
      "body": "详细操作中的“在当前工作目录中创建一个名为config的文件夹”，  当前工作目录指的是哪里，有没有详细配置openai api的步骤？",
      "state": "closed",
      "author": "hold-zt",
      "author_type": "User",
      "created_at": "2025-03-18T10:43:05Z",
      "updated_at": "2025-06-02T00:37:47Z",
      "closed_at": "2025-06-02T00:37:47Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1770/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1770",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1770",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:52.237503",
      "comments": [
        {
          "author": "xukaizhao",
          "body": "可以在终端输入：metagpt --init-config \n会自动创建config2.yaml，然后会显示路径，比如我的是Configuration file initialized at C:\\Users\\THUNDEROBOT\\.metagpt\\config2.yaml\n需要在这个文件里改配置",
          "created_at": "2025-03-19T14:29:42Z"
        },
        {
          "author": "hold-zt",
          "body": "> 可以在终端输入：metagpt --init-config 会自动创建config2.yaml，然后会显示路径，比如我的是Configuration file initialized at C:\\Users\\THUNDEROBOT.metagpt\\config2.yaml 需要在这个文件里改配置\n\n已经创建好并配置完成，还是相同的报错。\n2025-03-20 10:19:23.396 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode.",
          "created_at": "2025-03-20T02:23:25Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-19T00:37:36Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-06-02T00:37:46Z"
        }
      ]
    },
    {
      "issue_number": 1810,
      "title": "运行报错 validation errors for CompletionUsage",
      "body": "**Bug description**\n无论是pip安装metagpt，还是git clone，均报错如下 3 validation errors for CompletionUsage。\n测试多组生成： metagpt \"write a snake game\"、metagpt \"Create a 2048 game\"、 metagpt \"write a cli blackjack game\" \n\n**Bug solved method**\n无\n\n**Environment information**\n- LLM type and model name: \n-   api_type: 'openai' \n    model: 'gpt-4o' # gpt-3.5-turbo现象同\n    base_url: 'https://zzzzapi.com/v1' \n- System version: mac osx (15.3.2 (24D81))\n- Python version: 3.9.20\n- MetaGPT version or branch: main\n\n<!-- Dependent packagess：the packages version cause the bug(like `pydantic 1.10.8`), installation method（like `pip install metagpt` or `pip install from source` or `run in docker`） -->\n\n- packages version:\n- installation method:  pip install metagpt和git clone现象相同\n\n**Screenshots or logs**\n2025-04-14 10:40:01.384 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 78.980(s), this was the 6th time calling it. exp: 3 validation errors for CompletionUsage\ncompletion_tokens\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\nprompt_tokens\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\ntotal_tokens\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\n2025-04-14 10:40:01.385 | WARNING  | metagpt.utils.common:wrapper:649 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.\n2025-04-14 10:40:01.398 | ERROR    | metagpt.utils.common:wrapper:631 - Exception occurs, start to serialize the project, exp:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 50, in __call__\n    result = await fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/actions/action_node.py\", line 420, in _aask_v1\n    content = await self.llm.aask(prompt, system_msgs, images=images, timeout=timeout)\npydantic_core._pydantic_core.ValidationError: 3 validation errors for CompletionUsage\ncompletion_tokens\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\nprompt_tokens\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\ntotal_tokens\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/utils/common.py\", line 640, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/roles/role.py\", line 550, in run\n    rsp = await self.react()\ntenacity.RetryError: RetryError[<Future at 0x14591ddf0 state=finished raised ValidationError>]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/utils/common.py\", line 626, in wrapper\n    result = await func(self, *args, **kwargs)\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/team.py\", line 134, in run\n    await self.env.run()\nException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 50, in __call__\n    result = await fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/actions/action_node.py\", line 420, in _aask_v1\n    content = await self.llm.aask(prompt, system_msgs, images=images, timeout=timeout)\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/provider/base_llm.py\", line 150, in aask\n    rsp = await self.acompletion_text(message, stream=stream, timeout=self.get_timeout(timeout))\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\n    return await fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 47, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/__init__.py\", line 314, in iter\n    return fut.result()\n  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py\", line 439, in result\n    return self.__get_result()\n  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py\", line 391, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 50, in __call__\n    result = await fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/provider/openai_api.py\", line 141, in acompletion_text\n    return await self._achat_completion_stream(messages, timeout=timeout)\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/provider/openai_api.py\", line 94, in _achat_completion_stream\n    usage = CompletionUsage(**chunk.usage)\n  File \"/usr/local/lib/python3.9/site-packages/pydantic/main.py\", line 171, in __init__\n    self.__pydantic_validator__.validate_python(data, self_instance=self)\npydantic_core._pydantic_core.ValidationError: 3 validation errors for CompletionUsage\ncompletion_tokens\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\nprompt_tokens\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\ntotal_tokens\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/utils/common.py\", line 640, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/roles/role.py\", line 550, in run\n    rsp = await self.react()\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/roles/role.py\", line 517, in react\n    rsp = await self._react()\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/roles/role.py\", line 463, in _react\n    rsp = await self._act()\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/roles/role.py\", line 392, in _act\n    response = await self.rc.todo.run(self.rc.history)\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/actions/write_prd.py\", line 87, in run\n    return await self._handle_new_requirement(req)\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/actions/write_prd.py\", line 108, in _handle_new_requirement\n    node = await WRITE_PRD_NODE.fill(context=context, llm=self.llm, exclude=exclude)  # schema=schema\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/actions/action_node.py\", line 505, in fill\n    return await self.simple_fill(schema=schema, mode=mode, images=images, timeout=timeout, exclude=exclude)\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/actions/action_node.py\", line 457, in simple_fill\n    content, scontent = await self._aask_v1(\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\n    return await fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 47, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/__init__.py\", line 326, in iter\n    raise retry_exc from fut.exception()\ntenacity.RetryError: RetryError[<Future at 0x14591ddf0 state=finished raised ValidationError>]\n\n![Image](https://github.com/user-attachments/assets/c26a513e-2b42-433d-8aaf-8b3d71c08333)",
      "state": "closed",
      "author": "wang498505194",
      "author_type": "User",
      "created_at": "2025-04-14T02:50:23Z",
      "updated_at": "2025-06-02T00:37:46Z",
      "closed_at": "2025-06-02T00:37:46Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1810/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1810",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1810",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:52.429837",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-19T00:37:31Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-06-02T00:37:45Z"
        }
      ]
    },
    {
      "issue_number": 1789,
      "title": "agent干到一半自己停止了，也没有任何报错",
      "body": "![Image](https://github.com/user-attachments/assets/203664cc-5be6-4c9f-ae19-2d101fbea23d)\n我测试了两次，安装方式为pip install git+https://github.com/geekan/MetaGPT\n模型使用的是deepseek-chat，余额充足\n启动命令为metagpt \"创建一个语音克隆的网站，要求页面好看，模块清晰，看着非常有逼格\"",
      "state": "closed",
      "author": "TheHonestBob",
      "author_type": "User",
      "created_at": "2025-03-27T09:03:42Z",
      "updated_at": "2025-05-31T00:34:24Z",
      "closed_at": "2025-05-31T00:34:24Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 10,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1789/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1789",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1789",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:52.608713",
      "comments": [
        {
          "author": "userInner",
          "body": "请问你是如何使用的，我使用pip install metaGPT，无法使用deepseek",
          "created_at": "2025-03-30T08:16:21Z"
        },
        {
          "author": "TheHonestBob",
          "body": "> 请问你是如何使用的，我使用pip install metaGPT，无法使用deepseek\n\npip install git+https://github.com/geekan/MetaGPT  这样安装1.0.0版本\n",
          "created_at": "2025-03-31T02:33:08Z"
        },
        {
          "author": "userInner",
          "body": "谢谢，我尝试了这个，但是发现总是停留在alex实现代码这一步就不再执行了\r\n\r\n\r\n\r\n---原始邮件---\r\n发件人: ***@***.***&gt;\r\n发送时间: 2025年3月31日(周一) 上午10:33\r\n收件人: ***@***.***&gt;;\r\n抄送: ***@***.******@***.***&gt;;\r\n主题: Re: [geekan/MetaGPT] agent干到一半自己停止了，也没有任何报错 (Issue #1789)\r\n\r\n\r\n    \r\n请问你是如何使用的，我使用pip install metaGPT，无法使用deepseek\r\n  \r\npip install ",
          "created_at": "2025-03-31T02:37:28Z"
        },
        {
          "author": "TheHonestBob",
          "body": "> 谢谢，我尝试了这个，但是发现总是停留在alex实现代码这一步就不再执行了\n> […](#)\n\n是的，这个问题不仅仅在1.0.0版本，是生成任务流程那步就出错了，导致任务提前结束，我试了openai的模型，一样各种问题，成功率相当低，我已放弃这个项目，尝试使用其他搭建agent方便的框架，你的测试效果咋样",
          "created_at": "2025-03-31T02:40:37Z"
        },
        {
          "author": "userInner",
          "body": "他在构建blackjack game，成功构建出了代码，但是我让他编写其他工程，例如管理系统 | 网页开发，都始终停在alex这一步\r\n\r\n\r\n\r\n---原始邮件---\r\n发件人: ***@***.***&gt;\r\n发送时间: 2025年3月31日(周一) 上午10:41\r\n收件人: ***@***.***&gt;;\r\n抄送: ***@***.******@***.***&gt;;\r\n主题: Re: [geekan/MetaGPT] agent干到一半自己停止了，也没有任何报错 (Issue #1789)\r\n\r\n\r\n    \r\n谢谢，我尝试了这个，但是发现总是停留在alex实现代码这一步就不再",
          "created_at": "2025-03-31T02:59:43Z"
        }
      ]
    },
    {
      "issue_number": 1806,
      "title": "希望提供一个完整一点的“为角色或动作配置不同LLM” 示例",
      "body": "希望提供一个完整一点的“为角色或动作配置不同LLM”\n\n我按照官方的文档来不能实现这个 功能",
      "state": "closed",
      "author": "Minhat-GitHub",
      "author_type": "User",
      "created_at": "2025-04-10T04:02:05Z",
      "updated_at": "2025-05-29T00:35:22Z",
      "closed_at": "2025-05-29T00:35:22Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 13,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1806/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1806",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1806",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:52.827454",
      "comments": [
        {
          "author": "lwjin-1112",
          "body": "我这里是为action配置不同LLM\n![Image](https://github.com/user-attachments/assets/cfdf6677-9731-4570-b576-565822544d4f)",
          "created_at": "2025-04-11T04:44:05Z"
        },
        {
          "author": "Minhat-GitHub",
          "body": "> 我这里是为action配置不同LLM ![Image](https://github.com/user-attachments/assets/cfdf6677-9731-4570-b576-565822544d4f)\n\n还是看不懂啊",
          "created_at": "2025-04-11T05:51:40Z"
        },
        {
          "author": "lwjin-1112",
          "body": "> > 我这里是为action配置不同LLM![Image](https://github.com/user-attachments/assets/cfdf6677-9731-4570-b576-565822544d4f)\n> \n> 还是看不懂啊\n\n首先导入模块读取默认的配置\nfrom metagpt.config2 import Config\n然后修改model的值，在为action类配置时，因为是在role中添加动作，添加时指定config即可（第一个框那样）；若是为role配置时，在env添加role时，指定config即可（像第一个框），简而言之，在哪里添加action或role，就在",
          "created_at": "2025-04-11T06:21:15Z"
        },
        {
          "author": "Minhat-GitHub",
          "body": "> > > 我这里是为action配置不同LLM![Image](https://github.com/user-attachments/assets/cfdf6677-9731-4570-b576-565822544d4f)\n> > \n> > \n> > 还是看不懂啊\n> \n> 首先导入模块读取默认的配置 from metagpt.config2 import Config 然后修改model的值，在为action类配置时，因为是在role中添加动作，添加时指定config即可（第一个框那样）；若是为role配置时，在env添加role时，指定config即可（像第一个框），简而言之，在哪里添",
          "created_at": "2025-04-11T06:34:29Z"
        },
        {
          "author": "lwjin-1112",
          "body": "> > > > 我这里是为action配置不同LLM![Image](https://github.com/user-attachments/assets/cfdf6677-9731-4570-b576-565822544d4f)\n> > > \n> > > \n> > > 还是看不懂啊\n> > \n> > \n> > 首先导入模块读取默认的配置 from metagpt.config2 import Config 然后修改model的值，在为action类配置时，因为是在role中添加动作，添加时指定config即可（第一个框那样）；若是为role配置时，在env添加role时，指定config即可",
          "created_at": "2025-04-11T07:04:54Z"
        }
      ]
    },
    {
      "issue_number": 1809,
      "title": "如何获取MetaGPT运行时所有role按照顺序对话的轨迹（trajectory）? 同时是否有功能可以自定义仓库路径？",
      "body": "**Feature description**\n<!-- Clear and direct description of the functionality of the currently submitted or proposed feature -->\nFeature 1\n我想尝试将所有role之间的对话，保存为json文件，可以便于处理text类型的结果，便于分析，目前的功能好像无法做到？\nFeature 2\n同时，我想自定义一个project path，我尝试使用--project-name与--project-path,都不奏效。\n\n**Your Feature**\n<!-- Describe the idea or process of implementing the current feature. Of course, you can also paste the URL address of your Pull Request. -->\n<!-- When submitting features, you need to complete the corresponding doc/tests/examples to facilitate verification by reviewers. -->\n我目前的思路是在每一个role那边配置一个全局变量，保存msg信息，但是由于代码能力比较弱，metagpt封装完善，有点难以操作，没有改对。",
      "state": "closed",
      "author": "YuanDaoze",
      "author_type": "User",
      "created_at": "2025-04-12T12:35:03Z",
      "updated_at": "2025-05-28T00:35:21Z",
      "closed_at": "2025-05-28T00:35:20Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1809/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1809",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1809",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:53.056677",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-13T00:35:08Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-28T00:35:19Z"
        }
      ]
    },
    {
      "issue_number": 1807,
      "title": "Is there any plan for MetaGPT to support the MCP tool?",
      "body": "**Feature description**\nAs MCP becomes an industry trend, does MetaGPT have any plans to support the integration of a wide variety of MCP tools?\n",
      "state": "closed",
      "author": "zhouxiao999",
      "author_type": "User",
      "created_at": "2025-04-11T00:44:47Z",
      "updated_at": "2025-05-27T00:34:38Z",
      "closed_at": "2025-05-27T00:34:37Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1807/reactions",
        "total_count": 2,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 2,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1807",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1807",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:53.282704",
      "comments": [
        {
          "author": "lwjin-1112",
          "body": "都快有1年没更新迭代了，可能需要自己开发了",
          "created_at": "2025-04-11T04:41:49Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-12T00:37:13Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-27T00:34:37Z"
        }
      ]
    },
    {
      "issue_number": 1705,
      "title": "How to configure colab to use Azure OpenAI API",
      "body": "I am trying to run the [colab](https://colab.research.google.com/drive/1xlReN7EIpKzgZO1If29-zsw7QNUUfEbx?usp=sharing) found on the documentation. \nHow to set the env variables to use Azure OpenAI API?\nI can't find  the \n\n> ~/.metagpt/config2.yaml\n\n to update with Azure OpenAI API env variables.",
      "state": "closed",
      "author": "quartermaine",
      "author_type": "User",
      "created_at": "2025-02-20T08:27:59Z",
      "updated_at": "2025-05-26T05:55:44Z",
      "closed_at": "2025-05-26T05:55:44Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1705/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1705",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1705",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:53.528271",
      "comments": [
        {
          "author": "seehi",
          "body": "可参考：#1690 ",
          "created_at": "2025-02-20T08:35:00Z"
        },
        {
          "author": "quartermaine",
          "body": "Hello @seehi, \n\nThanks for the quick response. I used the following to set the env variables \n\n```\nmetagpt.const.API_KEY = userdata.get('OPENAI_API_KEY')\nmetagpt.const.MODEL = userdata.get('MODEL_NAME')\nmetagpt.const.API_TYPE = userdata.get('OPENAI_API_TYPE')\nmetagpt.const.API_VERSION = userdata.get",
          "created_at": "2025-02-20T08:53:10Z"
        },
        {
          "author": "seehi",
          "body": "Such as:\n```\nfrom pathlib import Path\n\nimport metagpt.const\n\n# 1. Change CONFIG_ROOT\nmetagpt.const.CONFIG_ROOT = Path.cwd()\n\n# 2. Create config2.yaml\ncontent = '''llm:\n  api_type: \"openai\"  # or azure / ollama / open_llm etc. Check LLMType for more options\n  model: \"gpt-4-turbo-preview\"  # or gpt-3.",
          "created_at": "2025-02-20T09:17:36Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-23T00:35:22Z"
        },
        {
          "author": "quartermaine",
          "body": "I will check the proposed solution and let you know.\n\nThanks",
          "created_at": "2025-03-28T07:41:37Z"
        }
      ]
    },
    {
      "issue_number": 1677,
      "title": "ERROR: Failed building wheel for volcengine-python-sdk   Running setup.py clean for volcengine-python-sdk Failed to build volcengine-python-sdk ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects",
      "body": "      copying volcenginesdktransitrouter\\models\\transit_router_forward_policy_entry_for_describe_transit_router_forward_policy_entries_output.py -> build\\lib\\volcenginesdktransitrouter\\models\n      copying volcenginesdktransitrouter\\models\\transit_router_forward_policy_table_for_describe_transit_router_forward_policy_tables_output.py -> build\\lib\\volcenginesdktransitrouter\\models\n      copying volcenginesdktransitrouter\\models\\transit_router_for_describe_transit_routers_output.py -> build\\lib\\volcenginesdktransitrouter\\models\n      copying volcenginesdktransitrouter\\models\\transit_router_grant_rule_for_describe_transit_router_grant_rules_output.py -> build\\lib\\volcenginesdktransitrouter\\models\n      copying volcenginesdktransitrouter\\models\\transit_router_route_entry_for_describe_transit_router_route_entries_output.py -> build\\lib\\volcenginesdktransitrouter\\models\n      copying volcenginesdktransitrouter\\models\\transit_router_route_policy_entry_for_describe_transit_router_route_policy_entries_output.py -> build\\lib\\volcenginesdktransitrouter\\models\n      copying volcenginesdktransitrouter\\models\\transit_router_route_policy_table_for_describe_transit_router_route_policy_tables_output.py -> build\\lib\\volcenginesdktransitrouter\\models\n      copying volcenginesdktransitrouter\\models\\transit_router_route_table_association_for_describe_transit_router_route_table_associations_output.py -> build\\lib\\volcenginesdktransitrouter\\models\n      copying volcenginesdktransitrouter\\models\\transit_router_route_table_for_describe_transit_router_route_tables_output.py -> build\\lib\\volcenginesdktransitrouter\\models\n      copying volcenginesdktransitrouter\\models\\transit_router_route_table_propagation_for_describe_transit_router_route_table_propagations_output.py -> build\\lib\\volcenginesdktransitrouter\\models\n      copying volcenginesdktransitrouter\\models\\transit_router_traffic_qos_marking_entry_for_describe_transit_router_traffic_qos_marking_entries_output.py -> build\\lib\\volcenginesdktransitrouter\\models\n      error: could not create 'build\\lib\\volcenginesdktransitrouter\\models\\transit_router_traffic_qos_marking_entry_for_describe_transit_router_traffic_qos_marking_entries_output.py': No such file or directory\n      [end of output]\n\n  note: This error originates from a subprocess, and is likely not a problem with pip.\n  ERROR: Failed building wheel for volcengine-python-sdk\n  Running setup.py clean for volcengine-python-sdk\nFailed to build volcengine-python-sdk\nERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (volcengine-python-sdk)",
      "state": "closed",
      "author": "gokulcoder7",
      "author_type": "User",
      "created_at": "2025-01-22T16:00:12Z",
      "updated_at": "2025-05-24T00:33:47Z",
      "closed_at": "2025-05-24T00:33:47Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1677/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1677",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1677",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:53.740861",
      "comments": [
        {
          "author": "iorisa",
          "body": "**1. Check Python Version**\n\nEnsure that the Python version you are using is compatible with `volcengine-python-sdk`. According to the official documentation, Python 3.7 or higher is recommended. If you are using a higher version (e.g., Python 3.11), there might be compatibility issues. You can try ",
          "created_at": "2025-01-23T02:39:12Z"
        },
        {
          "author": "chen2438",
          "body": "+1\n\nI use macOS 15.4\n\n```bash\nCollecting volcengine-python-sdk~=1.0.94 (from volcengine-python-sdk[ark]~=1.0.94->-r requirements.txt (line 78))\n  Downloading volcengine-python-sdk-1.0.123.tar.gz (3.2 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 5.7 MB/s eta 0:00:00\n  Preparing metadata (setu",
          "created_at": "2025-02-12T08:33:54Z"
        },
        {
          "author": "chen2438",
          "body": "> +1\n> \n> Collecting volcengine-python-sdk~=1.0.94 (from volcengine-python-sdk[ark]~=1.0.94->-r requirements.txt (line 78))\n>   Downloading volcengine-python-sdk-1.0.123.tar.gz (3.2 MB)\n>      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 5.7 MB/s eta 0:00:00\n>   Preparing metadata (setup.py) ... erro",
          "created_at": "2025-02-12T08:49:54Z"
        },
        {
          "author": "Miiiikasa",
          "body": "take a look at this: https://blog.csdn.net/steamedobun/article/details/142848303?ops_request_misc=%257B%2522request%255Fid%2522%253A%252219acde4f6ba6277a6c10be80ea91ed17%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=19acde4f6ba6277a6c10be80ea91ed17&biz_id=0&utm_medium=dis",
          "created_at": "2025-03-09T08:41:54Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-11T00:33:35Z"
        }
      ]
    },
    {
      "issue_number": 1682,
      "title": "openai new models dont work",
      "body": "The new models give max_temperature unknown error and cannot be used.",
      "state": "closed",
      "author": "cranyy",
      "author_type": "User",
      "created_at": "2025-02-03T00:17:40Z",
      "updated_at": "2025-05-24T00:33:46Z",
      "closed_at": "2025-05-24T00:33:45Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1682/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1682",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1682",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:53.938827",
      "comments": [
        {
          "author": "seehi",
          "body": "temperature?",
          "created_at": "2025-02-12T09:08:18Z"
        },
        {
          "author": "cranyy",
          "body": "my bad, i meant tokens --            ^^^^^^^^^^^^^^^^^^^^\n ```\n File \"E:\\MetaStocky\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1625, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Unsupport",
          "created_at": "2025-02-12T14:20:51Z"
        },
        {
          "author": "seehi",
          "body": "https://github.com/geekan/MetaGPT/pull/1710",
          "created_at": "2025-02-25T08:00:07Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-01T00:38:08Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-24T00:33:45Z"
        }
      ]
    },
    {
      "issue_number": 1734,
      "title": "FileNotFoundError: [Errno 2] No such file or directory: 'my_env/bin/Activate.ps1'",
      "body": "/mnt/d/.github/MetaGPT/my_env/bin/Activate.ps1\nin my root this file already here\n\n2025-03-03 15:50:01.275 | ERROR    | metagpt.utils.common:wrapper:631 - Exception occurs, start to serialize the project, exp:\nTraceback (most recent call last):\n  File \"/mnt/d/.github/MetaGPT/my_env/lib/python3.9/site-packages/metagpt/utils/common.py\", line 626, in wrapper\n    result = await func(self, *args, **kwargs)\n  File \"/mnt/d/.github/MetaGPT/my_env/lib/python3.9/site-packages/metagpt/team.py\", line 135, in run\n    self.env.archive(auto_archive)\nFileNotFoundError: [Errno 2] No such file or directory: 'my_env/bin/Activate.ps1'",
      "state": "closed",
      "author": "yuuuuuuan",
      "author_type": "User",
      "created_at": "2025-03-03T08:04:27Z",
      "updated_at": "2025-05-22T00:34:56Z",
      "closed_at": "2025-05-22T00:34:56Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1734/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1734",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1734",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:54.166912",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-03T00:32:40Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-22T00:34:55Z"
        }
      ]
    },
    {
      "issue_number": 1738,
      "title": "metagpt/provider/openai_api.py 94行存在bug",
      "body": "```\nif hasattr(chunk, \"usage\"):\n# Some services have usage as an attribute of the chunk, such as Fireworks\n    usage = CompletionUsage(**chunk.usage)\nusage会出现None的情况\n最好加上\nif chunk.usage:\n   usage = CompletionUsage(**chunk.usage)\n\n```\n\n日志\nChatCompletionChunk(id='chatcmpl-B7OpXSFxuj3RCEYCnFslLUchlZDiJ', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=None), finish_reason='stop', index=0, logprobs=None)], created=1741103443, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None)\n",
      "state": "closed",
      "author": "moseshu",
      "author_type": "User",
      "created_at": "2025-03-04T15:50:06Z",
      "updated_at": "2025-05-22T00:34:55Z",
      "closed_at": "2025-05-22T00:34:55Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1738/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1738",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1738",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:54.395740",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-04T00:32:42Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-22T00:34:54Z"
        }
      ]
    },
    {
      "issue_number": 1739,
      "title": "计算tokens的费用的时候存在bug",
      "body": "```python\n_calc_usage 在计算不同的gpt的价格的时候映射一下，gpt-4o有很多版本，价格都是按照gpt-4o算的，不然无法找到具体的4o 版本\n\n\n metagpt.provider.openai_api:_calc_usage:246 - usage calculation failed: num_tokens_from_messages() is not implemented for model chatgpt-4o-latest. See https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken for information on how messages are converted to tokens.\n 15\n```",
      "state": "closed",
      "author": "moseshu",
      "author_type": "User",
      "created_at": "2025-03-05T01:49:11Z",
      "updated_at": "2025-05-21T00:35:42Z",
      "closed_at": "2025-05-21T00:35:42Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1739/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1739",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1739",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:54.704104",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-05T00:32:14Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-21T00:35:41Z"
        }
      ]
    },
    {
      "issue_number": 1769,
      "title": "Several issues persist - prevents using metagpt for anything serious.",
      "body": "After extensive testing running metagpt for ~100 hours using openrouter:anthropic/claude-3.7-sonnet:thinking, I've concluded the following:\n\n1. json parsing fails when documents/code grow larger than it can handle.  Sometimes I was successful in instructing it to work in smaller chunks and it would actually do it, however, most times it would not and continue to fail and exit/crashes.  \n2. Context limit being exceeded and it does not appear that the \"middle-out\" / compression features of openrouter are implemented to prevent this.\n3. No easily observable way to just resume when it crashes. Instead, it will try sometimes and rebuild the docs it has already built, even when I specify that the docs are there for it to review.   \n4. Token usage is very high per api requests making using metagpt for any sizable project not optimal. \n\nThe project shows promise, but there are many other projects that seem to have managed to address these simple issues well.  It appears that the activity around this project is limited and reduced as compared to the past.  Are there any plans to get things up to speed?  Do you need help?",
      "state": "closed",
      "author": "myevolve",
      "author_type": "User",
      "created_at": "2025-03-17T20:45:24Z",
      "updated_at": "2025-05-21T00:35:40Z",
      "closed_at": "2025-05-21T00:35:39Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1769/reactions",
        "total_count": 3,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 1
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1769",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1769",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:54.884694",
      "comments": [
        {
          "author": "ODAncona",
          "body": "> there are many other projects that seem to have managed to address these simple issues well \n\nSuch as ?",
          "created_at": "2025-03-19T02:00:51Z"
        },
        {
          "author": "myevolve",
          "body": "I have been working extensively with both open source and closed source projects:\n\nCLI/Web: aider, openhands (similar to devin) -- This project has come a long way and does a pretty good job.\n\nIDE: Roo Code, Cline, Windsurf, Cursor  -- My testing for these has been mainly around configuring autonomo",
          "created_at": "2025-03-21T08:03:45Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-07T00:34:50Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-21T00:35:39Z"
        }
      ]
    },
    {
      "issue_number": 1744,
      "title": "本地部署如何配置在终端和浏览器中进行生成代码的测试",
      "body": "如何像mgx.dev中在Terminal中进行测试以及会自动部署web服务在浏览器中看到实时效果",
      "state": "closed",
      "author": "yuuuuuuan",
      "author_type": "User",
      "created_at": "2025-03-07T06:17:26Z",
      "updated_at": "2025-05-20T00:36:03Z",
      "closed_at": "2025-05-20T00:36:02Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1744/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1744",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1744",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:55.085257",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-07T00:34:30Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-20T00:36:02Z"
        }
      ]
    },
    {
      "issue_number": 1745,
      "title": "FileNotFoundError with Log file",
      "body": "**Bug description**\n<!-- Clearly and directly describe the current bug -->\n\nWhen trying to create any application, such as the 2048 game, I encounter this exception:\n\n![Image](https://github.com/user-attachments/assets/feaf91ad-dfef-459f-ac2f-d339d7833017)\n\n```\n2025-03-07 22:00:05.878 | ERROR    | metagpt.utils.common:wrapper:631 - Exception occurs, start to serialize the project, exp:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/site-packages/metagpt/utils/common.py\", line 626, in wrapper\n    result = await func(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/site-packages/metagpt/team.py\", line 135, in run\n    self.env.archive(auto_archive)\nFileNotFoundError: [Errno 2] No such file or directory: 'logs/20250307.txt'\n```\n\nThis is running inside a Docker container \n```bash\npython --version\nPython 3.11.11\n```\n\n**Bug solved method**\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\n\n**Environment information**\n<!-- Environment：System version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\n\n- LLM type and model name: Claude\n- System version: `Docker: python:3.11.11-bullseye`\n- Python version: `3.11.11`\n- MetaGPT version or branch: Whatever comes with `pip install --upgrade metagpt`\n\n<!-- Dependent packagess：the packages version cause the bug(like `pydantic 1.10.8`), installation method（like `pip install metagpt` or `pip install from source` or `run in docker`） -->\n\n- packages version:\n- installation method: \n\n**Screenshots or logs**\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\nThe `logs` folder, as well as the logfile itself do exist:\n![Image](https://github.com/user-attachments/assets/89826544-b5cd-47d6-8b0d-f539110efb77)\n\n<details><summary>Logs preceeding the exception</summary>\n\n```\n2025-03-07 22:00:05.149 | DEBUG    | metagpt.roles.role:run:547 - Bob(Architect): no news. waiting.\n2025-03-07 22:00:05.150 | DEBUG    | metagpt.roles.role:run:547 - Eve(Project Manager): no news. waiting.\n2025-03-07 22:00:05.150 | DEBUG    | metagpt.roles.role:run:547 - Alex(Engineer): no news. waiting.\n2025-03-07 22:00:05.150 | DEBUG    | metagpt.environment.base_env:run:168 - is idle: True\n2025-03-07 22:00:05.515 | INFO     | metagpt.utils.git_repository:archive:168 - Archive: ['logs/20250307.txt', 'metagpt/tools/schemas/CatCount.yml', 'metagpt/tools/schemas/CatCross.yml', 'metagpt/tools/schemas/FillMissingValue.yml', 'metagpt/tools/schemas/GPTvGenerator.yml', 'metagpt/tools/schemas/GeneralSelection.yml', 'metagpt/tools/schemas/GroupStat.yml', 'metagpt/tools/schemas/KFoldTargetMeanEncoder.yml', 'metagpt/tools/schemas/LabelEncode.yml', 'metagpt/tools/schemas/MaxAbsScale.yml', 'metagpt/tools/schemas/MinMaxScale.yml', 'metagpt/tools/schemas/OneHotEncode.yml', 'metagpt/tools/schemas/OrdinalEncode.yml', 'metagpt/tools/schemas/PolynomialExpansion.yml', 'metagpt/tools/schemas/RobustScale.yml', 'metagpt/tools/schemas/SDEngine.yml', 'metagpt/tools/schemas/SplitBins.yml', 'metagpt/tools/schemas/StandardScale.yml', 'metagpt/tools/schemas/TargetMeanEncoder.yml', 'metagpt/tools/schemas/VarianceBasedSelection.yml', 'metagpt/tools/schemas/email_login_imap.yml', 'metagpt/tools/schemas/scrape_web_playwright.yml', 'prompt.md', 'workspace/20250307215742/docs/prd/20250307215811.json', 'workspace/20250307215742/resources/competitive_analysis/20250307215811.mmd', 'workspace/20250307215742/resources/prd/20250307215811.md', 'workspace/20250307215930/docs/prd/20250307220002.json', 'workspace/20250307215930/resources/competitive_analysis/20250307220002.mmd', 'workspace/20250307215930/resources/prd/20250307220002.md', 'workspace/ecs_jira_integration/', 'workspace/jira_ecs_api/docs/prd/20250307220002.json', 'workspace/jira_ecs_api/resources/competitive_analysis/20250307220002.mmd', 'workspace/jira_ecs_api/resources/prd/20250307220002.md', 'workspace/storage/team/team.json']\n2025-03-07 22:00:05.878 | ERROR    | metagpt.utils.common:wrapper:631 - Exception occurs, start to serialize the project, exp:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/site-packages/metagpt/utils/common.py\", line 626, in wrapper\n    result = await func(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/site-packages/metagpt/team.py\", line 135, in run\n    self.env.archive(auto_archive)\nFileNotFoundError: [Errno 2] No such file or directory: 'logs/20250307.txt'\n```\n</details> ",
      "state": "closed",
      "author": "shmolf",
      "author_type": "User",
      "created_at": "2025-03-07T22:28:19Z",
      "updated_at": "2025-05-20T00:36:02Z",
      "closed_at": "2025-05-20T00:36:01Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1745/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1745",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1745",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:55.286853",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-07T00:34:29Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-20T00:36:01Z"
        }
      ]
    },
    {
      "issue_number": 1747,
      "title": "metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 18.375(s), this was the 5th time calling it. exp: 'async for' requires an object with __aiter__ method, got bytes",
      "body": "2025-03-09 15:35:23.233 | INFO     | metagpt.const:get_metagpt_package_root:29 - Package root set to D:\\work\\AI\\MetaGPT\n2025-03-09 15:35:26.399 | INFO     | metagpt.team:invest:90 - Investment: $3.0.\n2025-03-09 15:35:26.402 | INFO     | metagpt.roles.role:_act:391 - Alice(Product Manager): to do PrepareDocuments(PrepareDocuments)\n2025-03-09 15:35:26.660 | INFO     | metagpt.utils.file_repository:save:57 - save to: D:\\work\\AI\\MetaGPT\\workspace\\20250309153526\\docs\\requirement.txt\n2025-03-09 15:35:26.662 | INFO     | metagpt.roles.role:_act:391 - Alice(Product Manager): to do WritePRD(WritePRD)\n2025-03-09 15:35:26.664 | INFO     | metagpt.actions.write_prd:run:86 - New requirement detected: Create a 2048 game\n2025-03-09 15:35:28.723 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 2.063(s), this was the 1st time calling it. exp: 'async for' requires an object with __aiter__ method, got bytes2025-03-09 15:35:30.981 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 4.313(s), this was the 2nd time calling it. exp: 'async for' requires an object with __aiter__ method, got bytes2025-03-09 15:35:34.583 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 7.922(s), this was the 3rd time calling it. exp: 'async for' requires an object with __aiter__ method, got bytes2025-03-09 15:35:37.469 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 10.797(s), this was the 4th time calling it. exp: 'async for' requires an object with __aiter__ method, got bytes\n2025-03-09 15:35:45.041 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 18.375(s), this was the 5th time calling it. exp: 'async for' requires an object with __aiter__ method, got bytes\n2025-03-09 15:35:51.742 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 25.078(s), this was the 6th time calling it. exp: 'async for' requires an object with __aiter__ method, got bytes\n2025-03-09 15:35:51.743 | WARNING  | metagpt.utils.common:wrapper:649 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.\n2025-03-09 15:35:51.746 | ERROR    | metagpt.utils.common:wrapper:631 - Exception occurs, start to serialize the project, exp:\nTraceback (most recent call last):\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n    result = await fn(*args, **kwargs)\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\actions\\action_node.py\", line 420, in _aask_v1\n    content = await self.llm.aask(prompt, system_msgs, images=images, timeout=timeout)\nTypeError: 'async for' requires an object with __aiter__ method, got bytes\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\utils\\common.py\", line 640, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\roles\\role.py\", line 550, in run\n    rsp = await self.react()\ntenacity.RetryError: RetryError[<Future at 0x1e838289f40 state=finished raised TypeError>]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\utils\\common.py\", line 626, in wrapper\n    result = await func(self, *args, **kwargs)\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\team.py\", line 134, in run\n    await self.env.run()\nException: Traceback (most recent call last):\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n    result = await fn(*args, **kwargs)\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\actions\\action_node.py\", line 420, in _aask_v1\n    content = await self.llm.aask(prompt, system_msgs, images=images, timeout=timeout)\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\provider\\base_llm.py\", line 150, in aask\n    rsp = await self.acompletion_text(message, stream=stream, timeout=self.get_timeout(timeout))\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n    return await fn(*args, **kwargs)\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n    return fut.result()\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\concurrent\\futures\\_base.py\", line 439, in result\n    return self.__get_result()\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\concurrent\\futures\\_base.py\", line 391, in __get_result\n    raise self._exception\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n    result = await fn(*args, **kwargs)\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\provider\\base_llm.py\", line 200, in acompletion_text\n    return await self._achat_completion_stream(messages, timeout=self.get_timeout(timeout))\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\provider\\ollama_api.py\", line 79, in _achat_completion_stream\n    async for raw_chunk in stream_resp:\nTypeError: 'async for' requires an object with __aiter__ method, got bytes\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\utils\\common.py\", line 640, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\roles\\role.py\", line 550, in run\n    rsp = await self.react()\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\roles\\role.py\", line 517, in react\n    rsp = await self._react()\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\roles\\role.py\", line 463, in _react\n    rsp = await self._act()\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\roles\\role.py\", line 392, in _act\n    response = await self.rc.todo.run(self.rc.history)\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\actions\\write_prd.py\", line 87, in run\n    return await self._handle_new_requirement(req)\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\actions\\write_prd.py\", line 108, in _handle_new_requirement\n    node = await WRITE_PRD_NODE.fill(context=context, llm=self.llm, exclude=exclude)  # schema=schema\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\actions\\action_node.py\", line 505, in fill\n    return await self.simple_fill(schema=schema, mode=mode, images=images, timeout=timeout, exclude=exclude)\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\actions\\action_node.py\", line 457, in simple_fill\n    content, scontent = await self._aask_v1(\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n    return await fn(*args, **kwargs)\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\tenacity\\__init__.py\", line 326, in iter\n    raise retry_exc from fut.exception()\ntenacity.RetryError: RetryError[<Future at 0x1e838289f40 state=finished raised TypeError>]",
      "state": "closed",
      "author": "459936800",
      "author_type": "User",
      "created_at": "2025-03-09T07:36:56Z",
      "updated_at": "2025-05-20T00:36:00Z",
      "closed_at": "2025-05-20T00:36:00Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1747/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 1
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1747",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1747",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:55.475115",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-09T00:33:07Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-20T00:35:59Z"
        }
      ]
    },
    {
      "issue_number": 1758,
      "title": "Tools should be in which directory to tool registry?",
      "body": "[tutorials](https://docs.deepwisdom.ai/main/en/guide/tutorials/create_and_use_tools.html):\nCraft functions or classes tailored to enable specific interactions with the external environment and place them in the metagpt/tools/libs directory.\n\nBut the directory should be in `metagpt/tools/libs` or `miniconda3\\envs\\metagpt\\Lib\\site-packages\\metagpt\\tools\\libs`?\n\nIf it is placed in `metagpt/tools/libs`, importErr will appear. \nPutting it in `miniconda3\\envs\\metagpt\\Lib\\site-packages\\metagpt\\tools\\libs` is obviously unreasonable in a production environment.",
      "state": "closed",
      "author": "AstridRylan",
      "author_type": "User",
      "created_at": "2025-03-12T07:54:22Z",
      "updated_at": "2025-05-19T00:37:40Z",
      "closed_at": "2025-05-19T00:37:39Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1758/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1758",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1758",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:55.668678",
      "comments": [
        {
          "author": "AstridRylan",
          "body": "Same as #1622 ",
          "created_at": "2025-03-12T07:56:39Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-12T00:32:28Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-19T00:37:39Z"
        }
      ]
    },
    {
      "issue_number": 1804,
      "title": "Unused send_to parameter in run_project method in metagpt/team.py",
      "body": "In the Team class's run_project method ( `team.py` ), there's an unused parameter send_to :\n\n```python\ndef run_project(self, idea, send_to: str = \"\"):\n    \"\"\"Run a project from publishing user requirement.\"\"\"\n    self.idea = idea\n    # Human requirement.\n    self.env.publish_message(Message(content=idea))\n ```\n\nThe parameter send_to is defined with a default value but never used within the method body. This could lead to confusion about its purpose and potential misuse.\n",
      "state": "closed",
      "author": "li-aolong",
      "author_type": "User",
      "created_at": "2025-04-03T16:15:46Z",
      "updated_at": "2025-05-19T00:37:36Z",
      "closed_at": "2025-05-19T00:37:35Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1804/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1804",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1804",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:55.901002",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-04T00:38:22Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-19T00:37:34Z"
        }
      ]
    },
    {
      "issue_number": 1785,
      "title": "install error PEP 668",
      "body": "pip install --upgrade metagpt\n\n\nerror: externally-managed-environment\n\n× This environment is externally managed\n╰─> To install Python packages system-wide, try apt install\n    python3-xyz, where xyz is the package you are trying to\n    install.\n    \n    If you wish to install a non-Debian-packaged Python package,\n    create a virtual environment using python3 -m venv path/to/venv.\n    Then use path/to/venv/bin/python and path/to/venv/bin/pip. Make\n    sure you have python3-full installed.\n    \n    If you wish to install a non-Debian packaged Python application,\n    it may be easiest to use pipx install xyz, which will manage a\n    virtual environment for you. Make sure you have pipx installed.\n    \n    See /usr/share/doc/python3.12/README.venv for more information.\n\nnote: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\nhint: See PEP 668 for the detailed specification.\n",
      "state": "closed",
      "author": "athuljayaram",
      "author_type": "User",
      "created_at": "2025-03-23T15:06:28Z",
      "updated_at": "2025-05-18T13:12:17Z",
      "closed_at": "2025-05-17T00:34:19Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1785/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1785",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1785",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:56.102405",
      "comments": [
        {
          "author": "athuljayaram",
          "body": "pip install --upgrade metagpt  --break-system-packages\nDefaulting to user installation because normal site-packages is not writeable\nCollecting metagpt\n  Using cached metagpt-0.8.1-py3-none-any.whl.metadata (15 kB)\nCollecting aiohttp==3.8.6 (from metagpt)\n  Using cached aiohttp-3.8.6.tar.gz (7.4 MB)",
          "created_at": "2025-03-23T15:07:12Z"
        },
        {
          "author": "athuljayaram",
          "body": "python3 --version\nPython 3.12.3\n",
          "created_at": "2025-03-23T15:08:47Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-01T00:38:39Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-17T00:34:19Z"
        },
        {
          "author": "limboys",
          "body": "you can try pip install numpy==1.26.0 or Use Python 3.11 instead of 3.12",
          "created_at": "2025-05-18T13:12:16Z"
        }
      ]
    },
    {
      "issue_number": 1771,
      "title": "Unused argument",
      "body": "https://github.com/geekan/MetaGPT/blob/main/metagpt/ext/sela/search/tree_search.py#L334\nit seems the `node` argument is not used",
      "state": "closed",
      "author": "zuxfoucault",
      "author_type": "User",
      "created_at": "2025-03-19T06:15:14Z",
      "updated_at": "2025-05-18T00:38:05Z",
      "closed_at": "2025-05-18T00:38:05Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1771/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1771",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1771",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:56.325424",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-03T00:33:29Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-18T00:38:05Z"
        }
      ]
    },
    {
      "issue_number": 1776,
      "title": "can metagpt support TPM setting?",
      "body": "2025-03-21 13:36:02.044 | ERROR    | metagpt.utils.common:wrapper:683 - Exception occurs, start to serialize the project, exp:\nTraceback (most recent call last):\n  File \"/mnt/d/.github/MetaGPT/metagpt/utils/common.py\", line 692, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"/mnt/d/.github/MetaGPT/metagpt/roles/role.py\", line 548, in run\n    rsp = await self.react()\nopenai.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `llama3-70b-8192` in organization `org_01jjvzqkd4frf9g3awzsx7d5vx` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 6042, please reduce your message size and try again. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/mnt/d/.github/MetaGPT/metagpt/utils/common.py\", line 678, in wrapper\n    result = await func(self, *args, **kwargs)\n  File \"/mnt/d/.github/MetaGPT/metagpt/team.py\", line 134, in run\n    await self.env.run()\nException: Traceback (most recent call last):\n  File \"/mnt/d/.github/MetaGPT/metagpt/utils/common.py\", line 692, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"/mnt/d/.github/MetaGPT/metagpt/roles/role.py\", line 548, in run\n    rsp = await self.react()\n  File \"/mnt/d/.github/MetaGPT/metagpt/roles/role.py\", line 515, in react\n    rsp = await self._react()\n  File \"/mnt/d/.github/MetaGPT/metagpt/roles/di/role_zero.py\", line 349, in _react\n    has_todo = await self._think()\n  File \"/mnt/d/.github/MetaGPT/metagpt/roles/product_manager.py\", line 56, in _think\n    return await super()._think()\n  File \"/mnt/d/.github/MetaGPT/metagpt/roles/di/role_zero.py\", line 257, in _think\n    self.command_rsp = await self.llm_cached_aask(req=req, system_msgs=[system_prompt], state_data=state_data)\n  File \"/mnt/d/.github/MetaGPT/metagpt/exp_pool/decorator.py\", line 187, in async_wrapper\n    return await wrapped_func(args, kwargs)\n  File \"/mnt/d/.github/MetaGPT/metagpt/exp_pool/decorator.py\", line 65, in get_or_create\n    return await rsp if asyncio.iscoroutine(rsp) else rsp\n  File \"/mnt/d/.github/MetaGPT/metagpt/roles/di/role_zero.py\", line 268, in llm_cached_aask\n    return await self.llm.aask(req, system_msgs=system_msgs)\n  File \"/mnt/d/.github/MetaGPT/metagpt/provider/base_llm.py\", line 206, in aask\n    rsp = await self.acompletion_text(compressed_message, stream=stream, timeout=self.get_timeout(timeout))\n  File \"/mnt/d/.github/MetaGPT/myenv/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\n    return await fn(*args, **kwargs)\n  File \"/mnt/d/.github/MetaGPT/myenv/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 47, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"/mnt/d/.github/MetaGPT/myenv/lib/python3.9/site-packages/tenacity/__init__.py\", line 314, in iter\n    return fut.result()\n  File \"/root/.pyenv/versions/3.9.21/lib/python3.9/concurrent/futures/_base.py\", line 439, in result\n    return self.__get_result()\n  File \"/root/.pyenv/versions/3.9.21/lib/python3.9/concurrent/futures/_base.py\", line 391, in __get_result\n    raise self._exception\n  File \"/mnt/d/.github/MetaGPT/myenv/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 50, in __call__\n    result = await fn(*args, **kwargs)\n  File \"/mnt/d/.github/MetaGPT/metagpt/provider/openai_api.py\", line 174, in acompletion_text\n    return await self._achat_completion_stream(messages, timeout=timeout)\n  File \"/mnt/d/.github/MetaGPT/metagpt/provider/openai_api.py\", line 92, in _achat_completion_stream\n    response: AsyncStream[ChatCompletionChunk] = await self.aclient.chat.completions.create(\n  File \"/mnt/d/.github/MetaGPT/myenv/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n  File \"/mnt/d/.github/MetaGPT/myenv/lib/python3.9/site-packages/openai/_base_client.py\", line 1856, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/mnt/d/.github/MetaGPT/myenv/lib/python3.9/site-packages/openai/_base_client.py\", line 1550, in request\n    return await self._request(\n  File \"/mnt/d/.github/MetaGPT/myenv/lib/python3.9/site-packages/openai/_base_client.py\", line 1651, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `llama3-70b-8192` in organization `org_01jjvzqkd4frf9g3awzsx7d5vx` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 6042, please reduce your message size and try again. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
      "state": "closed",
      "author": "yuuuuuuan",
      "author_type": "User",
      "created_at": "2025-03-21T05:43:25Z",
      "updated_at": "2025-05-17T00:34:24Z",
      "closed_at": "2025-05-17T00:34:23Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1776/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1776",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1776",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:56.545435",
      "comments": [
        {
          "author": "Terrdi",
          "body": "I implemented the feature.You can tried it. [feature/rate-limit](https://github.com/Terrdi/MetaGPT/tree/feature/rate_limit)",
          "created_at": "2025-03-21T18:42:27Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-02T00:34:12Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-17T00:34:23Z"
        }
      ]
    },
    {
      "issue_number": 1777,
      "title": "请问Message在什么情况下会被使用到？",
      "body": "MetaGPT中只会在LLM输入和输出的时候用`Message`传递吗？\n调用工具、工具返回结果、Agent与Agent间通信会使用`Message`传递消息吗？",
      "state": "closed",
      "author": "GoldenFishes",
      "author_type": "User",
      "created_at": "2025-03-21T06:59:56Z",
      "updated_at": "2025-05-17T00:34:23Z",
      "closed_at": "2025-05-17T00:34:22Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1777/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1777",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1777",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:56.788960",
      "comments": [
        {
          "author": "Clairegggg",
          "body": "同问\n",
          "created_at": "2025-03-23T02:59:53Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-01T00:38:45Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-17T00:34:22Z"
        }
      ]
    },
    {
      "issue_number": 1779,
      "title": "Role里面的working_memory和memory有什么区别？",
      "body": "我只知道Planner规划器使用的是working_memory，想问working_memory和memory有什么区分？",
      "state": "closed",
      "author": "GoldenFishes",
      "author_type": "User",
      "created_at": "2025-03-21T08:30:39Z",
      "updated_at": "2025-05-17T00:34:22Z",
      "closed_at": "2025-05-17T00:34:21Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1779/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1779",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1779",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:57.018857",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-01T00:38:44Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-17T00:34:21Z"
        }
      ]
    },
    {
      "issue_number": 1784,
      "title": "The TreeofThought.solve method can trigger an RCE vulnerability",
      "body": "### Summary\nWhile using the latest version (<=v0.8.1) of MetaGPT's `TreeofThought.solve` method, we discovered that users can guide the large language model through dialogue to generate malicious code. This code can then be executed by triggering the `eval` method within the `ThoughtSolverBase.generate_thoughts` function, enabling the execution of arbitrary commands. The risky code is shown in the figure below.\n\n<img width=\"335\" alt=\"image\" src=\"https://github.com/user-attachments/assets/33585033-dc79-4bc4-9c9e-6259952c160e\">\n\n### Details\nWe used the template provided in [creative_writing.py](https://github.com/geekan/MetaGPT/blob/main/tests/metagpt/strategy/prompt_templates/creative_writing.py) and the test code in [test_creative_writing.py](https://github.com/geekan/MetaGPT/blob/main/tests/metagpt/strategy/examples/test_creative_writing.py) to validate that a malicious user can pass malicious code to the eval method in ThoughtSolverBase.generate_thoughts. By utilizing the jailbreak technique provided in the PoC, we bypassed the restrictions imposed by the creative_writing template on malicious user inputs. This allowed us to embed malicious code within the conversation, guide the large language model to return the malicious code, and subsequently trigger the RCE vulnerability.\n\n### PoC\nPlease review the file tot_demo.py.\n\n### Impact\nThe following diagram illustrates the process of executing the aforementioned code sample, which triggers the execution of malicious code. This code then reads relevant files from the server's local system (other actions, such as deleting files, can also be performed).\n\n<img width=\"316\" alt=\"image\" src=\"https://github.com/user-attachments/assets/a8a24ccf-e521-4351-9604-38a668cbfbbb\">\n\n### Weaknesses\nImproper Neutralization of Directives in Dynamically Evaluated Code ('Eval Injection') (CWE-95)\n\n### Environment information\nLLM type and model name: OpenAI gpt-3.5-turbo\n\nSystem version: ubuntu18.04\n\nPython version: python3.11\n\nMetaGPT version or branch: 68b7dc6\n",
      "state": "closed",
      "author": "BACMiao",
      "author_type": "User",
      "created_at": "2025-03-23T06:59:53Z",
      "updated_at": "2025-05-17T00:34:21Z",
      "closed_at": "2025-05-17T00:34:20Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1784/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1784",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1784",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:57.219611",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-01T00:38:41Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-17T00:34:20Z"
        }
      ]
    },
    {
      "issue_number": 1671,
      "title": "Value error, Please set your API key in config2.yaml [type=value_error, input_value='YOUR_API_KEY', input_type=str]",
      "body": "**Bug description**\n<!-- Clearly and directly describe the current bug -->\n\n**Bug solved method**\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\n\n**Environment information**\n<!-- Environment：System version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\n\n- LLM type and model name: ollama qwen 2.5 coder 14b\n- System version: windows 11\n- Python version:Python 3.9.21\n- MetaGPT version or branch:\n\n<!-- Dependent packagess：the packages version cause the bug(like `pydantic 1.10.8`), installation method（like `pip install metagpt` or `pip install from source` or `run in docker`） -->\n\n- packages version:\n- installation method: \n\n\n\n\n\n\n\nllm:\n  api_type: \"ollama\"  # or azure / ollama / open_llm etc. Check LLMType for more options\n  model: \"qwen2.5-coder:14b\"  # or gpt-3.5-turbo-1106 / gpt-4-1106-preview\n  base_url: \"http://localhost:11434\"  # or forward url / other llm url\n  api_key: \"YOUR_API_KEY\"\n\n\n\n\n**Screenshots or logs**\n\n![Image](https://github.com/user-attachments/assets/6988573b-1bbb-47f6-aae7-3c57f76913a7)\n\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\n",
      "state": "closed",
      "author": "gokulcoder7",
      "author_type": "User",
      "created_at": "2025-01-17T15:49:03Z",
      "updated_at": "2025-05-16T13:12:10Z",
      "closed_at": "2025-05-16T13:12:10Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1671/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1671",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1671",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:57.411399",
      "comments": [
        {
          "author": "gokulcoder7",
          "body": "how to find api key for ollama models ?",
          "created_at": "2025-01-17T15:49:29Z"
        },
        {
          "author": "iorisa",
          "body": "For the configuration of ollama's config2.yaml, you can refer to this document: [ollama-api](https://docs.deepwisdom.ai/main/en/guide/get_started/configuration/llm_api_configuration.html#ollama-api)\nIf it is a local ollama model, you can fill in any string, but it cannot be an empty string, left unf",
          "created_at": "2025-01-18T03:22:30Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-18T00:30:22Z"
        },
        {
          "author": "gokulcoder7",
          "body": "Tried this but I got new errror",
          "created_at": "2025-02-22T02:49:24Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-02T00:33:37Z"
        }
      ]
    },
    {
      "issue_number": 1717,
      "title": "兼容火山方舟的代码删了？？？",
      "body": "**Feature description**\n<!-- Clear and direct description of the functionality of the currently submitted or proposed feature -->\n\n**Your Feature**\n<!-- Describe the idea or process of implementing the current feature. Of course, you can also paste the URL address of your Pull Request. -->\n<!-- When submitting features, you need to complete the corresponding doc/tests/examples to facilitate verification by reviewers. -->\n\n\n![Image](https://github.com/user-attachments/assets/b9734680-eafe-47a6-aac3-b2e412a07472)",
      "state": "closed",
      "author": "RoeGross",
      "author_type": "User",
      "created_at": "2025-02-24T07:29:48Z",
      "updated_at": "2025-05-16T13:09:23Z",
      "closed_at": "2025-05-16T13:09:23Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1717/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1717",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1717",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:57.654439",
      "comments": [
        {
          "author": "RoeGross",
          "body": "![Image](https://github.com/user-attachments/assets/42182178-a543-40b5-8895-f35fbf4916df)\n\n  这样使用起来了火山方舟的 deepSeel R1   但是解析好像要报错    \n\n![Image](https://github.com/user-attachments/assets/03ab5ffe-47a1-4383-ba7a-e5af3701ae8b)",
          "created_at": "2025-02-24T07:49:42Z"
        },
        {
          "author": "seehi",
          "body": "[配置火山方舟的API](https://docs.deepwisdom.ai/main/zh/guide/get_started/configuration/llm_api_configuration.html#%E7%81%AB%E5%B1%B1%E6%96%B9%E8%88%9F%E7%9A%84api)",
          "created_at": "2025-02-24T12:05:58Z"
        },
        {
          "author": "diesers",
          "body": "先在火山云那边创建在线接入点，接入点选择指定的模型。然后 model 填写 ep-xxxx （接入点 id）就行",
          "created_at": "2025-03-12T10:26:40Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-12T00:32:32Z"
        }
      ]
    },
    {
      "issue_number": 1721,
      "title": "Unable to configure ollama via 3rd party url",
      "body": "**Bug description**\n\nI am trying to use MetaGPT via a third party url wrapper. It works for me with openai and claude:\n\n```\nllm:\n  api_type: \"openai\"  # or azure / ollama / groq etc.\n  model: \"gpt-4-turbo\"  # or gpt-3.5-turbo\n  base_url: \"http://localhost:8989/openai\"\n  api_key: \"xxxx\"\n```\n\nBut when i configure ollama, i have a problem:\n\n```\nllm:\n  api_type: \"ollama\"  # or azure / ollama / groq etc.\n  model: \"llama2\"  # or gpt-3.5-turbo\n  base_url: \"http://localhost:8989/ollama\"\n```\n\nBut it fails with a 404 not found, because the base URL needs to be:\n/api/chat and it just gets /chat\n\n```\n    @property\n    def api_suffix(self) -> str:\n        return \"/chat\"\n```\n\nI also tried to setup a proxy:\n\n```\nllm:\n  api_type: \"ollama\"  # or azure / ollama / groq etc.\n  model: \"llama2\"  # or gpt-3.5-turbo\n  base_url: \"http://localhost:11434/api\"  # or forward url / other llm url\n  proxy: \"http://localhost:8989\"\n```\n\nBut it doesn't seem to be even picked. How can i configure ollama via this wrapper url?\n\n\n**Environment information**\nmac os m2\nllm type -> ollama\n\n",
      "state": "closed",
      "author": "yrobla",
      "author_type": "User",
      "created_at": "2025-02-26T09:46:17Z",
      "updated_at": "2025-05-16T13:08:56Z",
      "closed_at": "2025-05-16T13:08:56Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1721/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1721",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1721",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:02.847305",
      "comments": [
        {
          "author": "iorisa",
          "body": "```yaml\nllm:\n  api_type: \"ollama\" \n  model: \"llama3.2\"  # or gpt-3.5-turbo\n  base_url: \"http://localhost:11434/api\" \n  api_key: \"any string will be ok\"\n```\nSovled by: #1710 ",
          "created_at": "2025-03-04T10:40:06Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-04T00:32:44Z"
        }
      ]
    },
    {
      "issue_number": 1741,
      "title": "Title",
      "body": "**Bug description**\n<!-- Clearly and directly describe the current bug -->\n\n**Bug solved method**\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\n\n**Environment information**\n<!-- Environment：System version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\n\n- LLM type and model name:\n- System version:\n- Python version:\n- MetaGPT version or branch:\n\n<!-- Dependent packagess：the packages version cause the bug(like `pydantic 1.10.8`), installation method（like `pip install metagpt` or `pip install from source` or `run in docker`） -->\n\n- packages version:\n- installation method: \n\n**Screenshots or logs**\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->",
      "state": "closed",
      "author": "zainabalzawjalfaisal",
      "author_type": "User",
      "created_at": "2025-03-06T05:49:28Z",
      "updated_at": "2025-05-16T13:06:58Z",
      "closed_at": "2025-05-16T13:06:58Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1741/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1741",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1741",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:03.069862",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-06T00:35:37Z"
        }
      ]
    },
    {
      "issue_number": 1742,
      "title": "Is Web interface in SaaS version only?",
      "body": "So a web interface, presumably MetaGPT X, is shown on website, but while reading the doc,  I only see that there are CLI interactions. So is this different product? ",
      "state": "closed",
      "author": "MaximFworks",
      "author_type": "User",
      "created_at": "2025-03-06T08:34:37Z",
      "updated_at": "2025-05-16T13:06:45Z",
      "closed_at": "2025-05-16T13:06:45Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1742/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 1
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1742",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1742",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:03.243997",
      "comments": [
        {
          "author": "gitgo1994",
          "body": "yeah i think its different im not sure if they provide a web interface for the opensource version. ",
          "created_at": "2025-03-10T18:31:20Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-10T00:32:51Z"
        },
        {
          "author": "better629",
          "body": "The open source version is the open source version of most functions of the product (mgx.dev)",
          "created_at": "2025-05-16T13:06:43Z"
        }
      ]
    },
    {
      "issue_number": 1801,
      "title": "250+ repos analyzed: MetaGPT is fast, efficient, and refreshingly human",
      "body": "Hi @geekan, @better629, @garylin2099, and @seehi, \n\nWe analyzed how teams handle pull request workflows across 250+ open source projects — and MetaGPT stood out to us with 0s wait times and 100% human participation (rather than bots), which is exceptionally rare. \n\nCould we get your thoughts on how well the analysis matches your process? 👉 https://collab.dev/geekan/MetaGPT \n\nThanks for setting a great example! \n— Alissa\n",
      "state": "closed",
      "author": "alissav0",
      "author_type": "User",
      "created_at": "2025-04-02T20:44:33Z",
      "updated_at": "2025-05-16T12:55:31Z",
      "closed_at": "2025-05-16T12:55:31Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1801/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1801",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1801",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:03.459923",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-03T00:33:23Z"
        }
      ]
    },
    {
      "issue_number": 1790,
      "title": "Is there a way to use meta gpt with already existing project that is not been created with it?",
      "body": "**Feature description**\nUsing it with the old projects.",
      "state": "closed",
      "author": "Canahmetozguven",
      "author_type": "User",
      "created_at": "2025-03-28T02:16:31Z",
      "updated_at": "2025-05-16T00:35:28Z",
      "closed_at": "2025-05-16T00:35:27Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1790/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1790",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1790",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:03.646257",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-01T00:38:38Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-16T00:35:27Z"
        }
      ]
    },
    {
      "issue_number": 1791,
      "title": "代码缺少必填字段",
      "body": "Exception occurs, start to serialize the project, exp:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 50, in __call__\n    result = await fn(*args, **kwargs)\n  File \"/app/metagpt/metagpt/actions/action_node.py\", line 449, in _aask_v1\n    instruct_content = output_class(**parsed_data)\npydantic_core._pydantic_core.ValidationError: 1 validation error for WritePRD_AN\n  Value error, Missing fields: {'UI Design draft', 'Requirement Analysis', 'Anything UNCLEAR', 'Requirement Pool', 'Competitive Quadrant Chart'} [type=value_error, input_value={'Language': 'zh_cn', 'Pr...跳跃、吃金币等'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.5/v/value_error\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/app/metagpt/metagpt/utils/common.py\", line 664, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"/app/metagpt/metagpt/roles/role.py\", line 551, in run\n    rsp = await self.react()\ntenacity.RetryError: RetryError[<Future at 0x7f7f82e462e0 state=finished raised ValidationError>]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/app/metagpt/metagpt/utils/common.py\", line 650, in wrapper\n    result = await func(self, *args, **kwargs)\n  File \"/app/metagpt/metagpt/team.py\", line 134, in run\n    await self.env.run()\nException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 50, in __call__\n    result = await fn(*args, **kwargs)\n  File \"/app/metagpt/metagpt/actions/action_node.py\", line 449, in _aask_v1\n    instruct_content = output_class(**parsed_data)\n  File \"/usr/local/lib/python3.9/site-packages/pydantic/main.py\", line 164, in __init__\n    __pydantic_self__.__pydantic_validator__.validate_python(data, self_instance=__pydantic_self__)\npydantic_core._pydantic_core.ValidationError: 1 validation error for WritePRD_AN\n  Value error, Missing fields: {'UI Design draft', 'Requirement Analysis', 'Anything UNCLEAR', 'Requirement Pool', 'Competitive Quadrant Chart'} [type=value_error, input_value={'Language': 'zh_cn', 'Pr...跳跃、吃金币等'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.5/v/value_error\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/app/metagpt/metagpt/utils/common.py\", line 664, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"/app/metagpt/metagpt/roles/role.py\", line 551, in run\n    rsp = await self.react()\n  File \"/app/metagpt/metagpt/roles/role.py\", line 520, in react\n    rsp = await self._react()\n  File \"/app/metagpt/metagpt/roles/role.py\", line 475, in _react\n    rsp = await self._act()\n  File \"/app/metagpt/metagpt/roles/role.py\", line 404, in _act\n    response = await self.rc.todo.run(self.rc.history)\n  File \"/app/metagpt/metagpt/actions/write_prd.py\", line 87, in run\n    return await self._handle_new_requirement(req)\n  File \"/app/metagpt/metagpt/actions/write_prd.py\", line 108, in _handle_new_requirement\n    node = await WRITE_PRD_NODE.fill(context=context, llm=self.llm, exclude=exclude)  # schema=schema\n  File \"/app/metagpt/metagpt/actions/action_node.py\", line 648, in fill\n    return await self.simple_fill(schema=schema, mode=mode, images=images, timeout=timeout, exclude=exclude)\n  File \"/app/metagpt/metagpt/actions/action_node.py\", line 473, in simple_fill\n    content, scontent = await self._aask_v1(\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\n    return await fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 47, in __call__\n\n\n缺少字段：\n\n系统要求 WritePRD_AN（写PRD的Action Node）必须包含以下字段：\n\nUI Design draft（UI设计稿）\n\nRequirement Analysis（需求分析）\n\nCompetitive Quadrant Chart（竞争象限图）\n\nRequirement Pool（需求池）\n\nAnything UNCLEAR（不明确的内容）\n\n但你传入的数据（input_value）缺少这些字段",
      "state": "closed",
      "author": "ruan121212",
      "author_type": "User",
      "created_at": "2025-03-28T02:27:04Z",
      "updated_at": "2025-05-16T00:35:27Z",
      "closed_at": "2025-05-16T00:35:26Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1791/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1791",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1791",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:03.857835",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-01T00:38:36Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-16T00:35:26Z"
        }
      ]
    },
    {
      "issue_number": 1793,
      "title": "Every time I generate code, it gets stuck at this point. Why?",
      "body": "![Image](https://github.com/user-attachments/assets/9488395c-6778-4381-8f98-51fd21669f0d)",
      "state": "closed",
      "author": "liang-tian-tian",
      "author_type": "User",
      "created_at": "2025-03-30T09:24:42Z",
      "updated_at": "2025-05-16T00:35:26Z",
      "closed_at": "2025-05-16T00:35:25Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1793/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1793",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1793",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:04.045806",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-01T00:38:35Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-16T00:35:25Z"
        }
      ]
    },
    {
      "issue_number": 1795,
      "title": "[Dependency] Incompatibility with numpy>=2.0",
      "body": "**Bug description**\nWhen attempting to install both metagpt (>=0.8.0) and langchain-ark (>=0.1.5) using uv/pip, dependency resolution fails due to incompatible numpy version requirements.\n\n**Environment information**\n- System version: Ubuntu 24.04.1 LTS (WSL)\n- Python version: 3.11.11\n- uv version: 0.6.11\n- LLM Model: volcengine\n\n**Bug reproduction method**\n```bash\nuv add metagpt>=0.8.0 langchain_ark>=0.1.5\n```\n\n**Error Message**\n```text\n× No solution found when resolving dependencies for split (python_full_version == '3.11.*'):\n  ╰─▶ Because only the following versions of metagpt are available:\n          .........\n          .........\n          metagpt==0.8.0\n          metagpt==0.8.1\n          metagpt==0.8.2\n      and all of:\n          metagpt<=0.6.4\n          metagpt>=0.8.0,<=0.8.1\n      depend on numpy==1.24.3, we can conclude that all of:\n          metagpt<0.6.5\n          metagpt>0.7.7,<0.8.2\n      depend on numpy==1.24.3.\n      And because all versions of langchain-ark depend on numpy>=2.1.3, we can conclude that all versions of langchain-ark and all of:\n          metagpt<0.6.5\n          metagpt>0.7.7,<0.8.2\n       are incompatible. (1)\n```\n\nIt seems that the error report says that `metagpt` does not support `numpy` versions above 2.0. \n\nIn fact, although it requires numpy>=2.1.3, `langchain-ark` currently can works with numpy==1.24.3, and I can solve my problem with some not-so-elegant methods. \n\nHowever, Numpy is a extremely important fundamental library in the field of scientific computing, and it's a pity that a project like metagpt with considerable influence does not support its latest version. Do we have plans to support latest Numpy in the future?",
      "state": "closed",
      "author": "zzkluck",
      "author_type": "User",
      "created_at": "2025-04-01T02:36:27Z",
      "updated_at": "2025-05-16T00:35:24Z",
      "closed_at": "2025-05-16T00:35:24Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1795/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1795",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1795",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:04.228607",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-02T00:34:09Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-16T00:35:23Z"
        }
      ]
    },
    {
      "issue_number": 1796,
      "title": "Aflow文件缺失",
      "body": "aflow模块中的readme中有optimized_path/template/operator.py和optimized_path/template/operator.json，但是在代码中并没有找到这两个文件，也没有提供这两个文件的配置方法，可以介绍一下吗",
      "state": "closed",
      "author": "aajing",
      "author_type": "User",
      "created_at": "2025-04-01T09:41:21Z",
      "updated_at": "2025-05-16T00:35:23Z",
      "closed_at": "2025-05-16T00:35:23Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1796/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1796",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1796",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:04.479733",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-02T00:34:08Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-16T00:35:22Z"
        }
      ]
    },
    {
      "issue_number": 1780,
      "title": "to run the example app of hello_world.py with the llm config of ollama encounter the exception when json.loads the response",
      "body": "**Bug description**\n<!-- Clearly and directly describe the current bug -->\nto run the example app of hello_world.py with the llm config of ollama encounter the exception when json.loads the response\n\n**Bug solved method**\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\n\n**Environment information**\n<!-- Environment：System version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\nPRETTY_NAME=\"Ubuntu 22.10\"\nNAME=\"Ubuntu\"\nVERSION_ID=\"22.10\"\nVERSION=\"22.10 (Kinetic Kudu)\"\n\nPython 3.9.21\n\nLLM config:\nllm:\n  api_type: \"ollama\"  # or azure / ollama / groq etc.\n  model: \"llama2:7b\"  # or gpt-3.5-turbo  llama2:7b  gemma3:1b\n  base_url: \"http://localhost:11435/v1/\"  # or forward url / other llm url\n  api_key: \"\"\n\n- LLM type and model name: llama2:7b\n- System version: ollama 0.6.0\n- Python version: Python 3.9.21\n- MetaGPT version or branch:- latest code of main branch\n\n<!-- Dependent packagess：the packages version cause the bug(like `pydantic 1.10.8`), installation method（like `pip install metagpt` or `pip install from source` or `run in docker`） -->\nconda create -n metagpt python=3.9 && conda activate metagpt\ngit clone https://github.com/geekan/MetaGPT && cd MetaGPT && pip install --upgrade -e .\n\n- packages version:\n- latest code of main branch\n- \n- installation method: \nconda create -n metagpt python=3.9 && conda activate metagpt\ngit clone https://github.com/geekan/MetaGPT && cd MetaGPT && pip install --upgrade -e .\n\n**Screenshots or logs**\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\nException has occurred: JSONDecodeError\nExtra data: line 1 column 5 (char 4)\n  File \"/home/cienet/ollama_model/MetaGPT/metagpt/provider/ollama_api.py\", line 41, in decode\n    return json.loads(response.data.decode(\"utf-8\"))\n  File \"/home/cienet/ollama_model/MetaGPT/metagpt/provider/ollama_api.py\", line 257, in _processing_openai_response\n    resp = self.ollama_message.decode(openai_resp)\n  File \"/home/cienet/ollama_model/MetaGPT/metagpt/provider/ollama_api.py\", line 252, in _achat_completion_stream\n    return self._processing_openai_response(resp)\n  File \"/home/cienet/ollama_model/MetaGPT/metagpt/provider/base_llm.py\", line 259, in acompletion_text\n    return await self._achat_completion_stream(messages, timeout=self.get_timeout(timeout))\n  File \"/home/cienet/ollama_model/MetaGPT/metagpt/provider/base_llm.py\", line 206, in aask\n    rsp = await self.acompletion_text(compressed_message, stream=stream, timeout=self.get_timeout(timeout))\n  File \"/home/cienet/ollama_model/MetaGPT/examples/hello_world.py\", line 16, in ask_and_print\n    rsp = await llm.aask(question, system_msgs=[system_prompt], stream=True)\n  File \"/home/cienet/ollama_model/MetaGPT/examples/hello_world.py\", line 41, in main\n    await ask_and_print(\"what's your name?\", llm, \"I'm a helpful AI assistant.\")\n  File \"/home/cienet/ollama_model/MetaGPT/examples/hello_world.py\", line 47, in <module>",
      "state": "closed",
      "author": "Leif-Liu",
      "author_type": "User",
      "created_at": "2025-03-21T08:56:39Z",
      "updated_at": "2025-05-06T00:43:45Z",
      "closed_at": "2025-05-06T00:43:45Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1780/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1780",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1780",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:04.693568",
      "comments": [
        {
          "author": "Leif-Liu",
          "body": "base_url: \"http://127.0.0.1:11435/api\"\n\ncould connect the cli with the local ollama llm. but encounter another issue:\n\ndef role_raise_decorator(func):\n    async def wrapper(self, *args, **kwargs):\n        try:\n            return await func(self, *args, **kwargs)\n        except KeyboardInterrupt as k",
          "created_at": "2025-03-24T08:24:04Z"
        },
        {
          "author": "Leif-Liu",
          "body": "Exception has occurred: Exception\nTraceback (most recent call last):\n  File \"/home/liufeng/MetaGPT/metagpt/utils/common.py\", line 692, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"/home/liufeng/MetaGPT/metagpt/roles/role.py\", line 548, in run\n    rsp = await self.react()\n  File \"/",
          "created_at": "2025-03-24T08:24:32Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-01T00:38:42Z"
        }
      ]
    },
    {
      "issue_number": 1716,
      "title": "mac python3.13. can not install",
      "body": "**Bug description**\nduring install:\n      FAILED: pandas/_libs/tslibs/base.cpython-313-darwin.so.p/meson-generated_pandas__libs_tslibs_base.pyx.c.o\n      cc -Ipandas/_libs/tslibs/base.cpython-313-darwin.so.p -Ipandas/_libs/tslibs -I../../pandas/_libs/tslibs -I../../../../pip-build-env-g78rnw_k/overlay/lib/python3.13/site-packages/numpy/_core/include -I../../pandas/_libs/include -I/Library/Frameworks/Python.framework/Versions/3.13/include/python3.13 -fvisibility=hidden -fcolor-diagnostics -DNDEBUG -w -std=c99 -O3 -DNPY_NO_DEPRECATED_API=0 -DNPY_TARGET_VERSION=NPY_1_21_API_VERSION -MD -MQ pandas/_libs/tslibs/base.cpython-313-darwin.so.p/meson-generated_pandas__libs_tslibs_base.pyx.c.o -MF pandas/_libs/tslibs/base.cpython-313-darwin.so.p/meson-generated_pandas__libs_tslibs_base.pyx.c.o.d -o pandas/_libs/tslibs/base.cpython-313-darwin.so.p/meson-generated_pandas__libs_tslibs_base.pyx.c.o -c pandas/_libs/tslibs/base.cpython-313-darwin.so.p/pandas/_libs/tslibs/base.pyx.c\n      pandas/_libs/tslibs/base.cpython-313-darwin.so.p/pandas/_libs/tslibs/base.pyx.c:5399:70: error: too few arguments to function call, expected 6, have 5\n       5397 |                 int ret = _PyLong_AsByteArray((PyLongObject *)v,\n            |                           ~~~~~~~~~~~~~~~~~~~\n\n\n\n**Environment information**\nMac OS Sequoia 15.3\nPython 3.13\n\n",
      "state": "closed",
      "author": "leogong99",
      "author_type": "User",
      "created_at": "2025-02-23T18:06:27Z",
      "updated_at": "2025-04-10T00:32:55Z",
      "closed_at": "2025-04-10T00:32:54Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1716/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1716",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1716",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:06.567326",
      "comments": [
        {
          "author": "seehi",
          "body": "Try python3.9/3.10/3.11",
          "created_at": "2025-02-24T03:03:22Z"
        },
        {
          "author": "TheGreatCorrine",
          "body": "I guess you need to use **python3.9** or **python3.10**.\nThis is because Python 3.12+ has compatibility issues: `pkgutil.ImpImporter` was removed in Python 3.12, but `setuptools` still depends on it, causing the `numpy` build to fail.\n`metagpt` requires numpy==1.24.3, which may not be fully compatib",
          "created_at": "2025-02-24T16:44:16Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-27T00:32:31Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-04-10T00:32:53Z"
        }
      ]
    },
    {
      "issue_number": 1711,
      "title": "TypeError: __init__() got an unexpected keyword argument 'proxies'",
      "body": "我的config\n`llm:`\n`  api_key: 'sk-...' `\n`  model: 'xdeepseekr1' `\n`  base_url: 'https://maas-api.cn-huabei-1.xf-yun.com/v1' `",
      "state": "closed",
      "author": "Kattentions",
      "author_type": "User",
      "created_at": "2025-02-21T10:38:52Z",
      "updated_at": "2025-04-09T00:33:13Z",
      "closed_at": "2025-04-09T00:33:13Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1711/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1711",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1711",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:06.803762",
      "comments": [
        {
          "author": "jackymaxzzz",
          "body": "same",
          "created_at": "2025-02-22T19:08:05Z"
        },
        {
          "author": "destiny0326",
          "body": "httpx的版本太高了\nhttpx包在11.28进行更新，安装了httpx 0.28.0 版本的包导致报错\n\n解决办法\npip install httpx==0.27.2",
          "created_at": "2025-02-23T02:47:49Z"
        },
        {
          "author": "jackymaxzzz",
          "body": "> httpx的版本太高了 httpx包在11.28更新，安装了httpx 0.28.0版本的包导致报错\n> \n> 解决方法 pip install httpx==0.27.2\n\n非常感谢，问题解决",
          "created_at": "2025-02-23T03:14:16Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-26T00:32:22Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-04-09T00:33:12Z"
        }
      ]
    },
    {
      "issue_number": 1709,
      "title": "openai o1 raise BadRequestError: Unsupported parameter: 'max_tokens' is not supported with this model",
      "body": "**Bug description**\n```\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.\", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}}\n```\n\nllm config:\n```yaml\nllm:\n  api_type: \"openai\"  # or azure / ollama / groq etc.\n  model: \"o1\"  # or gpt-3.5-turbo\n  base_url: \"https://api.openai.com/v1\"  # or forward url / other llm url\n  api_key:\n```\n",
      "state": "closed",
      "author": "iorisa",
      "author_type": "User",
      "created_at": "2025-02-21T07:23:04Z",
      "updated_at": "2025-04-07T00:34:33Z",
      "closed_at": "2025-04-07T00:34:33Z",
      "labels": [
        "bug",
        "inactive"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1709/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1709",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1709",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:07.045709",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-24T00:34:03Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-04-07T00:34:33Z"
        }
      ]
    },
    {
      "issue_number": 1703,
      "title": "Researcher一直重复 | INFO     | metagpt.utils.token_counter:count_output_tokens:486 - Warning: model GLM-4 not found in tiktoken. Using cl100k_base encoding.",
      "body": "现有的网页搜索功能只能用ChatGPT做吗，用质谱进入WebBrowseAndSummarize时一直重复Warning: model GLM-4 not found in tiktoken. Using cl100k_base encoding.的警告，等了大概7,8分钟也不出结果，是不是只能重写代码，还是其他模型性能问题？",
      "state": "closed",
      "author": "1729256800",
      "author_type": "User",
      "created_at": "2025-02-19T12:57:21Z",
      "updated_at": "2025-04-06T00:35:41Z",
      "closed_at": "2025-04-06T00:35:41Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1703/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1703",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1703",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:07.240869",
      "comments": [
        {
          "author": "seehi",
          "body": "这个warning是因为找不到模型对应的token encoding，而使用默认值cl100k_base。\n没有结果，应该是跟模型能力有关，可以看下logs或者输出更多日志。",
          "created_at": "2025-02-20T08:33:58Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-23T00:35:23Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-04-06T00:35:40Z"
        }
      ]
    },
    {
      "issue_number": 1689,
      "title": "Team serialization may fail when the program exits abnormally",
      "body": "**Bug description**\nWhen I tried to run the Werewolf example, the model call failed due to platform flow restrictions. At this time, the program failed to serialize when it tried to write the current state to the storage/team.json file.\nAfter debugging, I found that the attribute special_actions in BasePlayer contained Action classes such as Speak, which caused the serialization failure\n\n**Bug solved method**\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\nI tried to add a custom serializer to Team so that it can be customized by users\nhttps://github.com/geekan/MetaGPT/pull/1688\n\n**Environment information**\n<!-- Environment：System version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\n\n- LLM type and model name: deepseek-r1\n- System version: MacOS\n- Python version: python3.9\n- MetaGPT version or branch: main\n\n<!-- Dependent packagess：the packages version cause the bug(like `pydantic 1.10.8`), installation method（like `pip install metagpt` or `pip install from source` or `run in docker`） -->\n\n- packages version:\n- installation method: pip install -e \".[rag,test,dev]\"\n\n",
      "state": "closed",
      "author": "Terrdi",
      "author_type": "User",
      "created_at": "2025-02-11T04:07:24Z",
      "updated_at": "2025-04-05T00:32:22Z",
      "closed_at": "2025-04-05T00:32:21Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1689/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1689",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1689",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:07.454990",
      "comments": [
        {
          "author": "seehi",
          "body": "The PR is large.",
          "created_at": "2025-02-13T06:34:52Z"
        },
        {
          "author": "Terrdi",
          "body": "OK, I changed the target branch and submitted some new changes. \nThe aflow example also uses json serialization to save the results. The total_cost field is numpy.int64, which cannot be serialized directly. Then I fixed this problem.",
          "created_at": "2025-02-19T07:11:15Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-22T00:31:42Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-04-05T00:32:21Z"
        }
      ]
    },
    {
      "issue_number": 1698,
      "title": "key中用的是serpapi，但运行researcher时报错信息显示用的是ddg是什么问题导致的？",
      "body": "search:\n  api_type: 'serpapi' # serpapi/google/serper/ddg\n  api_key: ''\n  # cse_id: 'YOUR_CSE_ID' # only for google\n  params:\n    engine: google # google/bing/yahoo/baidu/yandex, check https://serpapi.com/bing-search-api for more details\n    google_domain: 'google.com'\n    gl: us\n    hl: en\n\n2025-02-18 15:28:19.229 | INFO     | metagpt.const:get_metagpt_package_root:21 - Package root set to D:\\Code\\python\\pycharm\\MetaGPT\n2025-02-18 15:28:26.195 | INFO     | __main__:_act:44 - David(Researcher): to do CollectLinks(CollectLinks)\n[\"2025 Spring Fashion Trends\", \"Women's Fashion\"]\n2025-02-18 15:28:33.048 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.001 | Max budget: $10.000 | Current cost: $0.001, prompt_tokens: 74, completion_tokens: 16\n2025-02-18 15:28:43.059 | ERROR    | metagpt.tools.search_engine:run:142 - fail to search 2025 Spring Fashion Trends for _get_url() https://duckduckgo.com Timeout: Failed to perform, curl: (28) Connection timed out after 10006 milliseconds. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.",
      "state": "closed",
      "author": "1729256800",
      "author_type": "User",
      "created_at": "2025-02-18T07:44:30Z",
      "updated_at": "2025-04-05T00:32:20Z",
      "closed_at": "2025-04-05T00:32:20Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1698/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1698",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1698",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:07.657686",
      "comments": [
        {
          "author": "seehi",
          "body": "默认值是[ddg](https://github.com/geekan/MetaGPT/blob/main/metagpt/configs/search_config.py#L19)，看着像配置没正确解析，可以把config的值打印出来看下",
          "created_at": "2025-02-19T06:08:56Z"
        },
        {
          "author": "1729256800",
          "body": "确实没正常解析，不知道什么原因，只能手动把默认值改了",
          "created_at": "2025-02-19T12:44:46Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-22T00:31:40Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-04-05T00:32:19Z"
        }
      ]
    },
    {
      "issue_number": 1697,
      "title": "When testing researcher.py, there is a BUG ModuleNotFoundError: No module named 'sparkai', hoping to have a big boss to solve the confusion",
      "body": "I have tried pip install sparkai, but this only results in missing sparkai.core\nThat seems to be the main problem spark_api.py,but I use the moonshot\n\nTraceback (most recent call last):\n  File \"D:\\Code\\python\\pycharm\\MetaGPT\\metagpt\\roles\\researcher.py\", line 13, in <module>\n    from metagpt.actions import Action, CollectLinks, ConductResearch, WebBrowseAndSummarize\n  File \"D:\\Code\\python\\pycharm\\MetaGPT\\metagpt\\actions\\__init__.py\", line 10, in <module>\n    from metagpt.actions.action import Action\n  File \"D:\\Code\\python\\pycharm\\MetaGPT\\metagpt\\actions\\action.py\", line 15, in <module>\n    from metagpt.actions.action_node import ActionNode\n  File \"D:\\Code\\python\\pycharm\\MetaGPT\\metagpt\\actions\\action_node.py\", line 22, in <module>\n    from metagpt.llm import BaseLLM\n  File \"D:\\Code\\python\\pycharm\\MetaGPT\\metagpt\\llm.py\", line 11, in <module>\n    from metagpt.context import Context\n  File \"D:\\Code\\python\\pycharm\\MetaGPT\\metagpt\\context.py\", line 16, in <module>\n    from metagpt.provider.base_llm import BaseLLM\n  File \"D:\\Code\\python\\pycharm\\MetaGPT\\metagpt\\provider\\__init__.py\", line 16, in <module>\n    from metagpt.provider.spark_api import SparkLLM\n  File \"D:\\Code\\python\\pycharm\\MetaGPT\\metagpt\\provider\\spark_api.py\", line 4, in <module>\n    from sparkai.core.messages import _convert_to_message, convert_to_messages\nModuleNotFoundError: No module named 'sparkai'\n\n",
      "state": "closed",
      "author": "1729256800",
      "author_type": "User",
      "created_at": "2025-02-17T13:33:53Z",
      "updated_at": "2025-04-04T00:32:49Z",
      "closed_at": "2025-04-04T00:32:48Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1697/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1697",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1697",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:07.881634",
      "comments": [
        {
          "author": "1729256800",
          "body": "找到问题了是包没安装对，可以参考requirement.txt文件，还得更改一下安装路径字数上限",
          "created_at": "2025-02-18T07:47:09Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-21T00:32:25Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-04-04T00:32:48Z"
        }
      ]
    },
    {
      "issue_number": 1700,
      "title": "Feature Request: Enable default authentication method with Amazon EC2 Instance Profile for Amazon Bedrock LLM provider",
      "body": "**Feature description**\n\nBy default, all of the AWS SDKs (including `boto3`) attempt to dynamically retrieve temporary credentials using a \"metadata endpoint\" on EC2 instances, Lambda Functions, and AWS Fargate tasks. This authentication mechanism avoids the requirement of providing static credentials from an AWS IAM User account, in favor of creating an IAM **Role** identity.\n\nAccording to the documentation for MetaGPT, the only supported authentication mechanism for Amazon Bedrock is to create an IAM User, with a static access key and secret key.\n\nCould you please support using the default IAM Instance Profile, which requires no additional configuration, provided that MetaGPT is running on AWS Fargate or EC2 instances?\n\n<img width=\"567\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/964fc1ae-5fb6-4b83-b734-4bee6c9450cc\" />\n\nIn AWS Fargate, it's called a \"Task Role\": https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html\n\nFor EC2 instances it's called the \"IAM Instance Profile\": https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2_instance-profiles.html\n\nHere's the `boto3` documentation that describes the process that the AWS SDK uses to \"find\" credentials: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html\n\nBoto3 will look in several locations when searching for credentials. The mechanism in which Boto3 looks for credentials is to search through a list of possible locations and stop as soon as it finds credentials. The order in which Boto3 searches for credentials is:\n\n- Passing credentials as parameters in the boto3.client() method\n- Passing credentials as parameters when creating a Session object\n- Environment variables\n- Assume role provider\n- Assume role with web identity provider\n- AWS IAM Identity Center credential provider\n- Shared credential file (~/.aws/credentials)\n- AWS config file (~/.aws/config)\n- Boto2 config file (/etc/boto.cfg and ~/.boto)\n- Container credential provider\n- Instance metadata service on an Amazon EC2 instance that has an IAM role configured.\n\n<img width=\"791\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/a64b803c-69e4-40d5-b69d-ba2f33e4d4ef\" />\n\nI'm referring to 10 and 11 in the above screenshot, rather than specifying static credentials.\n\nHonestly, it's quite possible that MetaGPT already supports this authentication mechanism for Bedrock, but I don't see documentation (for MetaGPT) on how to configure it to use the default credential chain.",
      "state": "closed",
      "author": "trevorstr",
      "author_type": "User",
      "created_at": "2025-02-18T21:59:51Z",
      "updated_at": "2025-04-04T00:32:47Z",
      "closed_at": "2025-04-04T00:32:47Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1700/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1700",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1700",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:08.075806",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-21T00:32:24Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-04-04T00:32:47Z"
        }
      ]
    },
    {
      "issue_number": 1708,
      "title": "配置deepseek的api之后，metagpt重复在think，但无法执行action动作",
      "body": "2025-02-21 10:06:54.840 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 231.734(s), this was the 6th time calling it. exp: 1 validation error for WritePRD_AN\n  Value error, Missing fields: {'UI Design draft', 'Anything UNCLEAR'} [type=value_error, input_value={'Language': 'zh_cn', 'Pr...示': '屏幕底部'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.5/v/value_error\n2025-02-21 10:06:54.842 | WARNING  | metagpt.utils.common:wrapper:673 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.\n2025-02-21 10:06:54.855 | ERROR    | metagpt.utils.common:wrapper:655 - Exception occurs, start to serialize the project, exp:\nTraceback (most recent call last):\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n    result = await fn(*args, **kwargs)\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\metagpt\\actions\\action_node.py\", line 449, in _aask_v1\n    instruct_content = output_class(**parsed_data)\npydantic_core._pydantic_core.ValidationError: 1 validation error for WritePRD_AN\n  Value error, Missing fields: {'UI Design draft', 'Anything UNCLEAR'} [type=value_error, input_value={'Language': 'zh_cn', 'Pr...示': '屏幕底部'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.5/v/value_error\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\metagpt\\utils\\common.py\", line 664, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\metagpt\\roles\\role.py\", line 551, in run\n    rsp = await self.react()\ntenacity.RetryError: RetryError[<Future at 0x1b156176a60 state=finished raised ValidationError>]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\metagpt\\utils\\common.py\", line 650, in wrapper\n    result = await func(self, *args, **kwargs)\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\metagpt\\team.py\", line 134, in run\n    await self.env.run()\nException: Traceback (most recent call last):\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n    result = await fn(*args, **kwargs)\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\metagpt\\actions\\action_node.py\", line 449, in _aask_v1\n    instruct_content = output_class(**parsed_data)\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\pydantic\\main.py\", line 164, in __init__\n    __pydantic_self__.__pydantic_validator__.validate_python(data, self_instance=__pydantic_self__)\npydantic_core._pydantic_core.ValidationError: 1 validation error for WritePRD_AN\n  Value error, Missing fields: {'UI Design draft', 'Anything UNCLEAR'} [type=value_error, input_value={'Language': 'zh_cn', 'Pr...示': '屏幕底部'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.5/v/value_error\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\metagpt\\utils\\common.py\", line 664, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\metagpt\\roles\\role.py\", line 551, in run\n    rsp = await self.react()\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\metagpt\\roles\\role.py\", line 520, in react\n    rsp = await self._react()\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\metagpt\\roles\\role.py\", line 475, in _react\n    rsp = await self._act()\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\metagpt\\roles\\role.py\", line 404, in _act\n    response = await self.rc.todo.run(self.rc.history)\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\metagpt\\actions\\write_prd.py\", line 87, in run\n    return await self._handle_new_requirement(req)\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\metagpt\\actions\\write_prd.py\", line 108, in _handle_new_requirement\n    node = await WRITE_PRD_NODE.fill(context=context, llm=self.llm, exclude=exclude)  # schema=schema\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\metagpt\\actions\\action_node.py\", line 648, in fill\n    return await self.simple_fill(schema=schema, mode=mode, images=images, timeout=timeout, exclude=exclude)\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\metagpt\\actions\\action_node.py\", line 473, in simple_fill\n    content, scontent = await self._aask_v1(\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n    return await fn(*args, **kwargs)\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\tenacity\\__init__.py\", line 326, in iter\n    raise retry_exc from fut.exception()\ntenacity.RetryError: RetryError[<Future at 0x1b156176a60 state=finished raised ValidationError>]",
      "state": "closed",
      "author": "zhulf11",
      "author_type": "User",
      "created_at": "2025-02-21T02:15:09Z",
      "updated_at": "2025-04-03T07:09:40Z",
      "closed_at": "2025-04-03T07:09:40Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1708/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1708",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1708",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:08.284066",
      "comments": [
        {
          "author": "seehi",
          "body": "deepseek-chat还是deepseek-reasoner",
          "created_at": "2025-02-24T03:01:38Z"
        },
        {
          "author": "annian101",
          "body": "> 2025-02-21 10:06:54.840 | 错误 | metagpt.utils.common:log_it:554 - 在 231.734(s) 之后完成对“metagpt.actions.action_node.ActionNode._aask_v1”的调用，这是第 6 次调用它。 exp: WritePRD_AN 的 1 个验证错误 值错误，缺少字段：{'UI 设计草稿'，'任何不清楚的内容'} [type=value_error, input_value={'Language': 'zh_cn', 'Pr...示': '屏幕底部'}}, input_type=dict] 有",
          "created_at": "2025-02-24T05:46:13Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-27T00:32:34Z"
        },
        {
          "author": "mei-Tom",
          "body": "我也遇到了这个问题，DeepSeek-R1一直在思考，最后返回的结果是空字符串，目前只能用V3或其他LLM来代替，请问后续是如何解决的？",
          "created_at": "2025-04-03T02:38:30Z"
        },
        {
          "author": "zhulf11",
          "body": "我后面再次换了一个时间调用了R1接口，deepseek给出了action。但实际我并没有做任何改动。\n据我的推测，无法返回action是因为我使用的gpu卡使用率过高导致，各位遇到这个问题可以查看一下gpu使用率，避开高使用率的情况下看是否还有这个问题。",
          "created_at": "2025-04-03T07:09:28Z"
        }
      ]
    },
    {
      "issue_number": 1696,
      "title": "我怎么把DataInterpreter加入到我的Team中呢",
      "body": "例如我希望我的Team中有Researcher和DataInterpreter两个角色，其中Researcher输出文件地址，DataInterpreter访问文件进行可视化，我希望用如下代码\n    team.hire(\n        [\n            Researcher(),\n            DataInterpreter(),\n        ]\n这可以实现吗",
      "state": "closed",
      "author": "chaos-max",
      "author_type": "User",
      "created_at": "2025-02-16T07:04:09Z",
      "updated_at": "2025-04-03T00:32:46Z",
      "closed_at": "2025-04-03T00:32:45Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1696/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1696",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1696",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:08.541707",
      "comments": [
        {
          "author": "seehi",
          "body": "当前版本要实现的话，角色DataInterpreter要watch角色Researcher的action。可关注后续的版本更新。",
          "created_at": "2025-02-17T04:01:45Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-20T00:31:45Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-04-03T00:32:44Z"
        }
      ]
    },
    {
      "issue_number": 1690,
      "title": "MetaGPT 在 modelscope 环境中出现这样的问题，读取 config 读取不到",
      "body": "<img width=\"2002\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/5e41a8c1-9a54-47d8-a670-0354f7a34d85\" />\n\n<img width=\"937\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/3e4d46b8-21e7-429d-a467-74aa86a1b91c\" />",
      "state": "closed",
      "author": "WangLaoShi",
      "author_type": "User",
      "created_at": "2025-02-12T09:34:51Z",
      "updated_at": "2025-04-03T00:32:46Z",
      "closed_at": "2025-04-03T00:32:46Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1690/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1690",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1690",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:08.772034",
      "comments": [
        {
          "author": "WangLaoShi",
          "body": "在 Google Colab 上，也会存在使用的问题\n\n<img width=\"1519\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/708a42de-830d-48b8-93d1-1ad521ded9bc\" />\n\n没有办法编辑 `config2.yml`，所以，是不是有办法自己定义这个文件的位置呢。",
          "created_at": "2025-02-12T09:50:07Z"
        },
        {
          "author": "seehi",
          "body": "一种方法是修改全局变量CONFIG_ROOT\n```python\nimport metagpt.const\n\nmetagpt.const.CONFIG_ROOT = \"config2.yml文件的目录\"\n```",
          "created_at": "2025-02-13T06:26:02Z"
        },
        {
          "author": "LiangMiSan",
          "body": "这个问题我也遇到了，是因为把后缀写错了，将”.yml“改成\".yaml\"就可以了",
          "created_at": "2025-02-17T06:39:48Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-20T00:31:47Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-04-03T00:32:46Z"
        }
      ]
    },
    {
      "issue_number": 1685,
      "title": "How to Use Third-Party Proxy with MetaGPT?",
      "body": "I have configured my parameters as follows:\n\n```yaml\napi_type: 'open_llm'  # or azure / ollama / open_llm etc. Check LLMType for more options\nmodel: \"gpt-4o-mini\"  # or gpt-3.5-turbo-1106 / gpt-4-1106-preview\napi_key: \"sk-xxx\"\nbase_url: \"https://xiaoai.plus/v1\"\n```\nOf course, I have also tried setting api_type to openai, but I keep encountering the following error:\n\n`metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 92.768(s), this was the 6th time calling it. exp: openai.types.completion_usage.CompletionUsage() argument after ** must be a mapping, not NoneType`\n\nIs it possible that the issue arises from the use of a third-party proxy?",
      "state": "closed",
      "author": "jingyaolliu",
      "author_type": "User",
      "created_at": "2025-02-08T10:24:46Z",
      "updated_at": "2025-04-01T00:38:08Z",
      "closed_at": "2025-04-01T00:38:08Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1685/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1685",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1685",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:09.047505",
      "comments": [
        {
          "author": "seehi",
          "body": "[Supported LLMs](https://docs.deepwisdom.ai/main/en/guide/get_started/configuration/llm_api_configuration.html)",
          "created_at": "2025-02-12T09:12:07Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-15T00:31:35Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-04-01T00:38:07Z"
        }
      ]
    },
    {
      "issue_number": 1693,
      "title": "When running metagpt with Ollama Mistral, I face errors TypeError: 'async for' requires an object with __aiter__ method, got bytes",
      "body": "I used conda to metagpt and so I dont know how to find the source code and edit it. \n2025-02-13 20:37:01.345 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 29.328(s), this was the 6th time calling it. exp: 'async for' requires an object with __aiter__ method, got bytes\n2025-02-13 20:37:01.347 | WARNING  | metagpt.utils.common:wrapper:649 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.\n2025-02-13 20:37:01.379 | ERROR    | metagpt.utils.common:wrapper:631 - Exception occurs, start to serialize the project, exp:\nTraceback (most recent call last):\n  File \"C:\\Users\\Naveen Raam V\\anaconda3\\envs\\metagpt\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n    result = await fn(*args, **kwargs)\n  File \"C:\\Users\\Naveen Raam V\\anaconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\actions\\action_node.py\", line 420, in _aask_v1\n    content = await self.llm.aask(prompt, system_msgs, images=images, timeout=timeout)\nTypeError: 'async for' requires an object with __aiter__ method, got bytes\n\nThis is the detailed error message I have received. ",
      "state": "closed",
      "author": "naveen-raam",
      "author_type": "User",
      "created_at": "2025-02-13T15:46:12Z",
      "updated_at": "2025-03-31T00:35:26Z",
      "closed_at": "2025-03-31T00:35:25Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1693/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1693",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1693",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:09.238005",
      "comments": [
        {
          "author": "naveen-raam",
          "body": "Please provide me solutions on how to handle the issues in latest version. I used conda, so please point out how to change the source code if the solution needs it. ",
          "created_at": "2025-02-13T15:48:42Z"
        },
        {
          "author": "seehi",
          "body": "#1218 ",
          "created_at": "2025-02-14T09:10:27Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-17T00:33:54Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-31T00:35:24Z"
        }
      ]
    },
    {
      "issue_number": 1691,
      "title": "运行狼人杀后<class 'pydantic._internal._model_construction.ModelMetaclass'>",
      "body": "**windows环境运行狼人杀后一段对话报错**\n```2025-02-13 20:11:20.007 | ERROR    | metagpt.utils.common:wrapper:631 - Exception occurs, start to serialize the project, exp:\nTraceback (most recent call last):\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n    result = await fn(*args, **kwargs)\n  File \"E:\\Project_python\\llm_related\\knowledge_distillation_llm\\Agent\\werewolf\\actions\\common_actions.py\", line 237, in run\n    rsp = await self._aask(prompt)\nTypeError: openai.types.completion_usage.CompletionUsage() argument after ** must be a mapping, not CompletionUsage\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\metagpt\\utils\\common.py\", line 640, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\metagpt\\roles\\role.py\", line 550, in run\n    rsp = await self.react()\ntenacity.RetryError: RetryError[<Future at 0x1e8ddda8b80 state=finished raised TypeError>]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\metagpt\\utils\\common.py\", line 626, in wrapper\n    result = await func(self, *args, **kwargs)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\metagpt\\team.py\", line 134, in run\n    await self.env.run()\nException: Traceback (most recent call last):\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n    result = await fn(*args, **kwargs)\n  File \"E:\\Project_python\\llm_related\\knowledge_distillation_llm\\Agent\\werewolf\\actions\\common_actions.py\", line 237, in run\n    rsp = await self._aask(prompt)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\metagpt\\actions\\action.py\", line 93, in _aask\n    return await self.llm.aask(prompt, system_msgs)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\metagpt\\provider\\base_llm.py\", line 150, in aask\n    rsp = await self.acompletion_text(message, stream=stream, timeout=self.get_timeout(timeout))\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n    return await fn(*args, **kwargs)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n    return fut.result()\n  File \"D:\\ProgramData\\envs\\agent\\lib\\concurrent\\futures\\_base.py\", line 439, in result\n    return self.__get_result()\n  File \"D:\\ProgramData\\envs\\agent\\lib\\concurrent\\futures\\_base.py\", line 391, in __get_result\n    raise self._exception\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n    result = await fn(*args, **kwargs)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\metagpt\\provider\\openai_api.py\", line 141, in acompletion_text\n    return await self._achat_completion_stream(messages, timeout=timeout)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\metagpt\\provider\\openai_api.py\", line 94, in _achat_completion_stream\n    usage = CompletionUsage(**chunk.usage)\nTypeError: openai.types.completion_usage.CompletionUsage() argument after ** must be a mapping, not CompletionUsage\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\metagpt\\utils\\common.py\", line 640, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\metagpt\\roles\\role.py\", line 550, in run\n    rsp = await self.react()\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\metagpt\\roles\\role.py\", line 517, in react\n    rsp = await self._react()\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\metagpt\\roles\\role.py\", line 463, in _react\n    rsp = await self._act()\n  File \"E:\\Project_python\\llm_related\\knowledge_distillation_llm\\Agent\\werewolf\\roles\\base_player.py\", line 101, in _act\n    await Reflect().run(\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n    return await fn(*args, **kwargs)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\tenacity\\__init__.py\", line 326, in iter\n    raise retry_exc from fut.exception()\ntenacity.RetryError: RetryError[<Future at 0x1e8ddda8b80 state=finished raised TypeError>]\n\n\nTraceback (most recent call last):\n  File \"E:\\Project_python\\llm_related\\knowledge_distillation_llm\\Agent\\werewolf\\start_game.py\", line 68, in <module>\n    fire.Fire(main)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\fire\\core.py\", line 141, in Fire\n    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\fire\\core.py\", line 466, in _Fire\n    component, remaining_args = _CallAndUpdateTrace(\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\fire\\core.py\", line 681, in _CallAndUpdateTrace\n    component = fn(*varargs, **kwargs)\n  File \"E:\\Project_python\\llm_related\\knowledge_distillation_llm\\Agent\\werewolf\\start_game.py\", line 53, in main\n    asyncio.run(\n  File \"D:\\ProgramData\\envs\\agent\\lib\\asyncio\\runners.py\", line 44, in run\n    return loop.run_until_complete(main)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\asyncio\\base_events.py\", line 647, in run_until_complete\n    return future.result()\n  File \"E:\\Project_python\\llm_related\\knowledge_distillation_llm\\Agent\\werewolf\\start_game.py\", line 40, in start_game\n    await game.run(n_round=n_round)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\metagpt\\utils\\common.py\", line 632, in wrapper\n    self.serialize()  # Team.serialize\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\metagpt\\team.py\", line 60, in serialize\n    write_json_file(team_info_path, self.model_dump())\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\metagpt\\utils\\common.py\", line 581, in write_json_file\n    json.dump(data, fout, ensure_ascii=False, indent=indent, default=to_jsonable_python)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\json\\__init__.py\", line 179, in dump\n    for chunk in iterable:\n  File \"D:\\ProgramData\\envs\\agent\\lib\\json\\encoder.py\", line 431, in _iterencode\n    yield from _iterencode_dict(o, _current_indent_level)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\json\\encoder.py\", line 405, in _iterencode_dict\n    yield from chunks\n  File \"D:\\ProgramData\\envs\\agent\\lib\\json\\encoder.py\", line 405, in _iterencode_dict\n    yield from chunks\n  File \"D:\\ProgramData\\envs\\agent\\lib\\json\\encoder.py\", line 405, in _iterencode_dict\n    yield from chunks\n  [Previous line repeated 1 more time]\n  File \"D:\\ProgramData\\envs\\agent\\lib\\json\\encoder.py\", line 325, in _iterencode_list\n    yield from chunks\n  File \"D:\\ProgramData\\envs\\agent\\lib\\json\\encoder.py\", line 438, in _iterencode\n    o = _default(o)\npydantic_core._pydantic_core.PydanticSerializationError: Unable to serialize unknown type: <class 'pydantic._internal._model_construction.ModelMetaclass'>\n\n**Screenshots or logs**\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\n",
      "state": "closed",
      "author": "QiXingRan",
      "author_type": "User",
      "created_at": "2025-02-13T12:12:21Z",
      "updated_at": "2025-03-31T00:35:26Z",
      "closed_at": "2025-03-31T00:35:26Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1691/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1691",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1691",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:09.440461",
      "comments": [
        {
          "author": "Terrdi",
          "body": "我修复了这个bug,但是还没有merge\nhttps://github.com/Terrdi/MetaGPT/tree/fix-serialize-error\n你试试这个分支呢",
          "created_at": "2025-02-14T11:00:13Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-17T00:33:55Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-31T00:35:25Z"
        }
      ]
    },
    {
      "issue_number": 1687,
      "title": "自研推理引擎性能问题",
      "body": "我们自研的推理引擎是基于vllm做了深度优化的，但是用metagpt跑2048游戏比vllm慢了七八分钟，这是哪的问题呢，理论上讲是应该比vllm更快的",
      "state": "closed",
      "author": "zainlau",
      "author_type": "User",
      "created_at": "2025-02-10T11:45:18Z",
      "updated_at": "2025-03-30T00:36:14Z",
      "closed_at": "2025-03-30T00:36:14Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1687/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1687",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1687",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:09.664137",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-13T00:32:22Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-30T00:36:13Z"
        }
      ]
    },
    {
      "issue_number": 1722,
      "title": "Release artifacts (models, dataset) on Hugging Face",
      "body": "Hi @better629 🤗\n\nNiels here from the open-source team at Hugging Face. I discovered your work through Hugging Face's daily papers as yours got featured: https://huggingface.co/papers/2410.10762.\nThe paper page lets people discuss about your paper and lets them find artifacts about it (your models, datasets or demo for instance), you can also claim\nthe paper as yours which will show up on your public profile at HF.\n\nIt'd be great to make the model and any relevant datasets available on the 🤗 hub, to improve their discoverability/visibility.\nWe can add tags so that people find them when filtering https://huggingface.co/models and https://huggingface.co/datasets.\n\n## Uploading models\n\nSee here for a guide: https://huggingface.co/docs/hub/models-uploading. \n\nIn this case, we could leverage the [PyTorchModelHubMixin](https://huggingface.co/docs/huggingface_hub/package_reference/mixins#huggingface_hub.PyTorchModelHubMixin) class which adds `from_pretrained` and `push_to_hub` to any custom `nn.Module`. Alternatively, one can leverages the [hf_hub_download](https://huggingface.co/docs/huggingface_hub/en/guides/download#download-a-single-file) one-liner to download a checkpoint from the hub. \n\nWe encourage researchers to push each model checkpoint to a separate model repository, so that things like download stats also work. We can then also link the checkpoints to the paper page.\n\n## Uploading dataset\n\nWould be awesome to make the dataset available on 🤗 , so that people can do:\n\n```python\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"your-hf-org-or-username/your-dataset\")\n```\nSee here for a guide: https://huggingface.co/docs/datasets/loading.\n\nBesides that, there's the [dataset viewer](https://huggingface.co/docs/hub/en/datasets-viewer) which allows people to quickly explore the first few rows of the data in the browser.\n\nLet me know if you're interested/need any help regarding this!\n\nCheers,\n\nNiels\nML Engineer @ HF 🤗",
      "state": "closed",
      "author": "NielsRogge",
      "author_type": "User",
      "created_at": "2025-02-26T10:21:39Z",
      "updated_at": "2025-03-29T12:39:46Z",
      "closed_at": "2025-03-29T12:39:46Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1722/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 1,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1722",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1722",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:10.941027",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-29T00:32:24Z"
        }
      ]
    },
    {
      "issue_number": 1681,
      "title": "Baidu_Qianfan needs base_url in Config",
      "body": "**Bug description**\nI have read document of Config,[https://docs.deepwisdom.ai/main/zh/guide/get_started/configuration/llm_api_configuration.html]\n\nwhich said:\n\n![Image](https://github.com/user-attachments/assets/496ae28d-c12d-4de1-91a8-86da3e3e9b06)\n\n\nIf I set these config parameters as same as above, request or url will use default base url:\n\n![Image](https://github.com/user-attachments/assets/dc25cc1d-9e8d-4407-8824-985810a4eccb)\n\n**Bug solved method**\n1. \n![Image](https://github.com/user-attachments/assets/4457335f-40f3-48a9-9f2d-7dd827f9799f)\n\nMay be extract to a abstract function or other way.\n\n2. If I add base_url in Config2.yaml, that will be right. But add the description into document.\n\n**Environment information**\n<!-- Environment：System version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\n\n- LLM type and model name:\n- System version: Ubuntu 24.04\n- Python version: 3.11\n- MetaGPT version or branch: git main branch\n\n<!-- Dependent packagess：the packages version cause the bug(like `pydantic 1.10.8`), installation method（like `pip install metagpt` or `pip install from source` or `run in docker`） -->\n\n- packages version:\n- installation method: \n\n**Screenshots or logs**\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\n",
      "state": "closed",
      "author": "peterxia-chn",
      "author_type": "User",
      "created_at": "2025-01-31T03:24:07Z",
      "updated_at": "2025-03-23T00:35:27Z",
      "closed_at": "2025-03-23T00:35:26Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1681/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1681",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1681",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:11.196826",
      "comments": [
        {
          "author": "Terrdi",
          "body": "I configured base_url such as \n\n base_url: \"https://qianfan.baidubce.com/v2\"\n\nthen it works.",
          "created_at": "2025-02-06T07:51:14Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-09T00:28:39Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-23T00:35:26Z"
        }
      ]
    },
    {
      "issue_number": 1701,
      "title": "ModuleNotFoundError: No module named 'semantic_kernel.orchestration'",
      "body": "I encountered a ModuleNotFoundError when trying to use Semantic Kernel. The error message is as follows:\n![Image](https://github.com/user-attachments/assets/9429eb34-7609-4f57-b233-ada7480566be)\nMy Enviroment:\nOS: Windows 11\nPython Version: 3.12\nSemantic Kernel Version: 1.21.1\n![Image](https://github.com/user-attachments/assets/aa9b33d1-4350-475e-881c-168c8285e627)\n",
      "state": "closed",
      "author": "yuhua88",
      "author_type": "User",
      "created_at": "2025-02-19T00:52:54Z",
      "updated_at": "2025-03-22T01:17:24Z",
      "closed_at": "2025-03-22T01:17:24Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1701/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1701",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1701",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:11.416807",
      "comments": [
        {
          "author": "seehi",
          "body": "\"semantic-kernel==0.4.3.dev0\" in the [requirements.txt](https://github.com/geekan/MetaGPT/blob/main/requirements.txt#L44), try python3.9/3.10/3.11",
          "created_at": "2025-02-19T08:21:16Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-22T00:31:39Z"
        }
      ]
    },
    {
      "issue_number": 1684,
      "title": "about memory",
      "body": "When will it be updated: \n[doc](https://docs.deepwisdom.ai/main/en/guide/in_depth_guides/memory.html)",
      "state": "closed",
      "author": "philogos",
      "author_type": "User",
      "created_at": "2025-02-05T13:03:32Z",
      "updated_at": "2025-03-22T00:31:44Z",
      "closed_at": "2025-03-22T00:31:44Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1684/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1684",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1684",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:11.651379",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-08T00:25:40Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-22T00:31:43Z"
        }
      ]
    },
    {
      "issue_number": 1666,
      "title": "Can MetaGPT still running on colab?",
      "body": "**Bug description**\r\n\r\nRun the example Colab on Quickstart and install it using `!pip install --upgrade metagpt.`\r\nBut got some error.\r\n\r\n**Bug solved method**\r\n\r\nhttps://colab.research.google.com/drive/1xlReN7EIpKzgZO1If29-zsw7QNUUfEbx?usp=sharing\r\n\r\n**Environment information**\r\n<!-- Environment：System version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\r\n\r\n- LLM type and model name: `gpt-4-1106-preview`\r\n- System version: `colab`\r\n- Python version:  `3.10.12`\r\n- MetaGPT version or branch: `newest`\r\n\r\n<!-- Dependent packagess：the packages version cause the bug(like `pydantic 1.10.8`), installation method（like `pip install metagpt` or `pip install from source` or `run in docker`） -->\r\n\r\n- packages version:\r\n- installation method:  `!pip install --upgrade metagpt`\r\n\r\n**Screenshots or logs**\r\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\r\n\r\n> 2025-01-13 13:21:18.135 | INFO     | metagpt.team:invest:90 - Investment: $3.0.\r\n> 2025-01-13 13:21:18.142 | INFO     | metagpt.roles.role:_act:391 - Alice(Product Manager): to do PrepareDocuments(PrepareDocuments)\r\n> 2025-01-13 13:21:18.176 | INFO     | metagpt.utils.file_repository:save:57 - save to: /usr/local/lib/python3.10/dist-packages/workspace/20250113132118/docs/requirement.txt\r\n> 2025-01-13 13:21:18.182 | INFO     | metagpt.roles.role:_act:391 - Alice(Product Manager): to do WritePRD(WritePRD)\r\n> 2025-01-13 13:21:18.187 | INFO     | metagpt.actions.write_prd:run:86 - New requirement detected: write a 2048 game\r\n> 2025-01-13 13:21:26.995 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 8.805(s), this was the 1st time calling it. exp: 400 Unknown error trying to retrieve streaming response. Please retry with `stream=False` for more details.\r\n> 2025-01-13 13:21:35.140 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 16.950(s), this was the 2nd time calling it. exp: 400 Unknown error trying to retrieve streaming response. Please retry with `stream=False` for more details.\r\n> 2025-01-13 13:21:44.283 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 26.093(s), this was the 3rd time calling it. exp: 400 Unknown error trying to retrieve streaming response. Please retry with `stream=False` for more details.\r\n> 2025-01-13 13:21:49.758 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 31.568(s), this was the 4th time calling it. exp: 400 Unknown error trying to retrieve streaming response. Please retry with `stream=False` for more details.\r\n> 2025-01-13 13:22:01.147 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 42.957(s), this was the 5th time calling it. exp: 400 Unknown error trying to retrieve streaming response. Please retry with `stream=False` for more details.\r\n> 2025-01-13 13:22:19.540 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 61.350(s), this was the 6th time calling it. exp: 400 Unknown error trying to retrieve streaming response. Please retry with `stream=False` for more details.\r\n> 2025-01-13 13:22:19.541 | WARNING  | metagpt.utils.common:wrapper:649 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.\r\n> 2025-01-13 13:22:19.554 | ERROR    | metagpt.utils.common:wrapper:631 - Exception occurs, start to serialize the project, exp:\r\n> Traceback (most recent call last):\r\n>   File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/types/generation_types.py\", line 385, in rewrite_stream_error\r\n>     yield\r\n>   File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 263, in generate_content_async\r\n>     iterator = await self._async_client.stream_generate_content(\r\n> AttributeError: 'ResponseIterator' object has no attribute '__await__'. Did you mean: '__init__'?\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"/usr/local/lib/python3.10/dist-packages/tenacity/_asyncio.py\", line 50, in __call__\r\n>     result = await fn(*args, **kwargs)\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/actions/action_node.py\", line 420, in _aask_v1\r\n>     content = await self.llm.aask(prompt, system_msgs, images=images, timeout=timeout)\r\n> google.api_core.exceptions.BadRequest: 400 Unknown error trying to retrieve streaming response. Please retry with `stream=False` for more details.\r\n> \r\n> The above exception was the direct cause of the following exception:\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/utils/common.py\", line 640, in wrapper\r\n>     return await func(self, *args, **kwargs)\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/roles/role.py\", line 550, in run\r\n>     rsp = await self.react()\r\n> tenacity.RetryError: RetryError[<Future at 0x7848cbac7820 state=finished raised BadRequest>]\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/utils/common.py\", line 626, in wrapper\r\n>     result = await func(self, *args, **kwargs)\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/team.py\", line 134, in run\r\n>     await self.env.run()\r\n> Exception: Traceback (most recent call last):\r\n>   File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/types/generation_types.py\", line 385, in rewrite_stream_error\r\n>     yield\r\n>   File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 263, in generate_content_async\r\n>     iterator = await self._async_client.stream_generate_content(\r\n>   File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary_async.py\", line 230, in retry_wrapped_func\r\n>     return await retry_target(\r\n>   File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary_async.py\", line 160, in retry_target\r\n>     _retry_error_helper(\r\n>   File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\r\n>     raise final_exc from source_exc\r\n>   File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary_async.py\", line 155, in retry_target\r\n>     return await target()\r\n>   File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers_async.py\", line 85, in __await__\r\n>     response = yield from self._call.__await__()\r\n> AttributeError: 'ResponseIterator' object has no attribute '__await__'. Did you mean: '__init__'?\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"/usr/local/lib/python3.10/dist-packages/tenacity/_asyncio.py\", line 50, in __call__\r\n>     result = await fn(*args, **kwargs)\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/actions/action_node.py\", line 420, in _aask_v1\r\n>     content = await self.llm.aask(prompt, system_msgs, images=images, timeout=timeout)\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/provider/base_llm.py\", line 150, in aask\r\n>     rsp = await self.acompletion_text(message, stream=stream, timeout=self.get_timeout(timeout))\r\n>   File \"/usr/local/lib/python3.10/dist-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\r\n>     return await fn(*args, **kwargs)\r\n>   File \"/usr/local/lib/python3.10/dist-packages/tenacity/_asyncio.py\", line 47, in __call__\r\n>     do = self.iter(retry_state=retry_state)\r\n>   File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 314, in iter\r\n>     return fut.result()\r\n>   File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\r\n>     return self.__get_result()\r\n>   File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\r\n>     raise self._exception\r\n>   File \"/usr/local/lib/python3.10/dist-packages/tenacity/_asyncio.py\", line 50, in __call__\r\n>     result = await fn(*args, **kwargs)\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/provider/base_llm.py\", line 200, in acompletion_text\r\n>     return await self._achat_completion_stream(messages, timeout=self.get_timeout(timeout))\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/provider/google_gemini_api.py\", line 141, in _achat_completion_stream\r\n>     resp: AsyncGenerateContentResponse = await self.llm.generate_content_async(\r\n>   File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 262, in generate_content_async\r\n>     with generation_types.rewrite_stream_error():\r\n>   File \"/usr/lib/python3.10/contextlib.py\", line 153, in __exit__\r\n>     self.gen.throw(typ, value, traceback)\r\n>   File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/types/generation_types.py\", line 387, in rewrite_stream_error\r\n>     raise google.api_core.exceptions.BadRequest(\r\n> google.api_core.exceptions.BadRequest: 400 Unknown error trying to retrieve streaming response. Please retry with `stream=False` for more details.\r\n> \r\n> The above exception was the direct cause of the following exception:\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/utils/common.py\", line 640, in wrapper\r\n>     return await func(self, *args, **kwargs)\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/roles/role.py\", line 550, in run\r\n>     rsp = await self.react()\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/roles/role.py\", line 517, in react\r\n>     rsp = await self._react()\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/roles/role.py\", line 463, in _react\r\n>     rsp = await self._act()\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/roles/role.py\", line 392, in _act\r\n>     response = await self.rc.todo.run(self.rc.history)\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/actions/write_prd.py\", line 87, in run\r\n>     return await self._handle_new_requirement(req)\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/actions/write_prd.py\", line 108, in _handle_new_requirement\r\n>     node = await WRITE_PRD_NODE.fill(context=context, llm=self.llm, exclude=exclude)  # schema=schema\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/actions/action_node.py\", line 505, in fill\r\n>     return await self.simple_fill(schema=schema, mode=mode, images=images, timeout=timeout, exclude=exclude)\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/actions/action_node.py\", line 457, in simple_fill\r\n>     content, scontent = await self._aask_v1(\r\n>   File \"/usr/local/lib/python3.10/dist-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\r\n>     return await fn(*args, **kwargs)\r\n>   File \"/usr/local/lib/python3.10/dist-packages/tenacity/_asyncio.py\", line 47, in __call__\r\n>     do = self.iter(retry_state=retry_state)\r\n>   File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 326, in iter\r\n>     raise retry_exc from fut.exception()\r\n> tenacity.RetryError: RetryError[<Future at 0x7848cbac7820 state=finished raised BadRequest>]",
      "state": "closed",
      "author": "HiHelloTW",
      "author_type": "User",
      "created_at": "2025-01-13T14:06:46Z",
      "updated_at": "2025-03-21T00:32:28Z",
      "closed_at": "2025-03-21T00:32:28Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1666/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1666",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1666",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:11.861511",
      "comments": [
        {
          "author": "iorisa",
          "body": "Based on the log `/usr/local/lib/python3.10/dist-packages/metagpt/provider/google_gemini_api.py`, I infer that you are probably using the Gemini model instead of `gpt-4-1106-preview`. \nCould you please post your `config2.yaml` configuration?",
          "created_at": "2025-01-16T13:53:48Z"
        },
        {
          "author": "HiHelloTW",
          "body": "Oh! Thanks, it worked after I adjusted my `config2.yaml`.",
          "created_at": "2025-02-03T14:51:53Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-06T00:31:50Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-21T00:32:28Z"
        }
      ]
    },
    {
      "issue_number": 1674,
      "title": "Pip install error",
      "body": "**Bug description**\nI am facing the following issue when I try to do pip install on my \n\nPS C:\\Users\\jawwa\\Downloads\\AI Agents> pip install metagpt\nCollecting metagpt\n  Using cached metagpt-0.8.1-py3-none-any.whl.metadata (15 kB)\nCollecting aiohttp==3.8.6 (from metagpt)\n  Using cached aiohttp-3.8.6.tar.gz (7.4 MB)\n  Installing build dependencies ... done\n  Getting requirements to build wheel ... done\n  Preparing metadata (pyproject.toml) ... done\nCollecting channels==4.0.0 (from metagpt)\n  Using cached channels-4.0.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting faiss-cpu==1.7.4 (from metagpt)\n  Using cached faiss-cpu-1.7.4.tar.gz (57 kB)\n  Installing build dependencies ... done\n  Getting requirements to build wheel ... done\n  Preparing metadata (pyproject.toml) ... done\nCollecting fire==0.4.0 (from metagpt)\n  Using cached fire-0.4.0.tar.gz (87 kB)\n  Preparing metadata (setup.py) ... done\nCollecting typer==0.9.0 (from metagpt)\n  Using cached typer-0.9.0-py3-none-any.whl.metadata (14 kB)\nCollecting lancedb==0.4.0 (from metagpt)\n  Using cached lancedb-0.4.0-py3-none-any.whl.metadata (16 kB)\nCollecting loguru==0.6.0 (from metagpt)\n  Using cached loguru-0.6.0-py3-none-any.whl.metadata (21 kB)\nCollecting meilisearch==0.21.0 (from metagpt)\n  Using cached meilisearch-0.21.0-py3-none-any.whl.metadata (8.8 kB)\nCollecting numpy==1.24.3 (from metagpt)\n  Using cached numpy-1.24.3.tar.gz (10.9 MB)\n  Installing build dependencies ... done\n  Getting requirements to build wheel ... error\n  error: subprocess-exited-with-error\n\n  × Getting requirements to build wheel did not run successfully.\n  │ exit code: 1\n  ╰─> [33 lines of output]\n      Traceback (most recent call last):\n        File \"C:\\Users\\jawwa\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n          main()\n        File \"C:\\Users\\jawwa\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n          json_out['return_val'] = hook(**hook_input['kwargs'])\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        File \"C:\\Users\\jawwa\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 112, in get_requires_for_build_wheel\n          backend = _build_backend()\n                    ^^^^^^^^^^^^^^^^\n        File \"C:\\Users\\jawwa\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 77, in _build_backend\n          obj = import_module(mod_path)\n                ^^^^^^^^^^^^^^^^^^^^^^^\n        File \"C:\\Users\\jawwa\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n          return _bootstrap._gcd_import(name[level:], package, level)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n        File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n        File \"<frozen importlib._bootstrap>\", line 1310, in _find_and_load_unlocked\n        File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n        File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n        File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n        File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n        File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n        File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n        File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n        File \"C:\\Users\\jawwa\\AppData\\Local\\Temp\\pip-build-env-kdnmwm9n\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\", line 16, in <module>\n          import setuptools.version\n        File \"C:\\Users\\jawwa\\AppData\\Local\\Temp\\pip-build-env-kdnmwm9n\\overlay\\Lib\\site-packages\\setuptools\\version.py\", line 1, in <module>\n          import pkg_resources\n        File \"C:\\Users\\jawwa\\AppData\\Local\\Temp\\pip-build-env-kdnmwm9n\\overlay\\Lib\\site-packages\\pkg_resources\\__init__.py\", line 2172, in <module>\n          register_finder(pkgutil.ImpImporter, find_on_path)\n                          ^^^^^^^^^^^^^^^^^^^\n      AttributeError: module 'pkgutil' has no attribute 'ImpImporter'. Did you mean: 'zipimporter'?\n      [end of output]\n\n  note: This error originates from a subprocess, and is likely not a problem with pip.\nerror: subprocess-exited-with-error\n\n× Getting requirements to build wheel did not run successfully.\n│ exit code: 1\n╰─> See above for output.\n\nnote: This error originates from a subprocess, and is likely not a problem with pip.\n\nPS C:\\Users\\jawwa\\Downloads\\AI Agents> pip show metagpt\n\nWARNING: Package(s) not found: metagpt\n\nWhat do  I do to install it properly?\n",
      "state": "closed",
      "author": "jawwad-ahmed2809",
      "author_type": "User",
      "created_at": "2025-01-21T02:06:42Z",
      "updated_at": "2025-03-20T00:31:50Z",
      "closed_at": "2025-03-20T00:31:49Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1674/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1674",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1674",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:12.070720",
      "comments": [
        {
          "author": "iorisa",
          "body": "You need to first install a Linux OS simulator, such as MinGW or Cygwin, and then install MetaGPT.",
          "created_at": "2025-01-21T02:11:44Z"
        },
        {
          "author": "peterxia-chn",
          "body": "The version of Python should be >=3.9 and <=3.11, I have used 3.12 , faced the same question.",
          "created_at": "2025-02-03T01:19:50Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-06T00:31:47Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-20T00:31:49Z"
        }
      ]
    },
    {
      "issue_number": 149,
      "title": "MetaGPT and possible enhancements",
      "body": "I have used your interesting software and it produces very nice output.\r\nI propose these possible ehancements.\r\n1) To provide the possibility, in an iterative fashion, to enhance the software product itself and update all it's architectural views and implementation details until the user stop this iteration.\r\n2) To save checkpoints of such iteration with some versioning control\r\n3) To provide the possibility to restart the iteration from the last checkpoint saved\r\n4) To analyze the code produced and identify any possible manual modification as a part of the produced software lifecycle itself\r\n\r\nFirstly point 1.\r\n\r\nOther points are more complex.",
      "state": "closed",
      "author": "gnovelli",
      "author_type": "User",
      "created_at": "2023-08-08T07:28:04Z",
      "updated_at": "2025-03-19T00:32:23Z",
      "closed_at": "2025-03-19T00:32:23Z",
      "labels": [
        "enhancement",
        "inactive"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/149/reactions",
        "total_count": 5,
        "+1": 5,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/149",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/149",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:12.248109",
      "comments": [
        {
          "author": "voidking",
          "body": "Good suggestion, thanks a lot. We will take it into consideration. Some of your suggestions are in the roadmap.",
          "created_at": "2023-08-09T02:16:33Z"
        },
        {
          "author": "gnovelli",
          "body": "To make the software development cycle iterative and integrate agents that examine and modify the code, you can adopt an approach similar to the Agile development model. Here's a possible solution:\r\n\r\n1. **Phase Definition**:\r\n\r\n    a. **Requirements**: Receive the description of the requirements fr",
          "created_at": "2023-08-12T10:54:14Z"
        },
        {
          "author": "geekan",
          "body": "Great idea, this is what we most want to do",
          "created_at": "2023-09-09T03:28:37Z"
        },
        {
          "author": "kripper",
          "body": "Any update on enhancing existing software products?",
          "created_at": "2024-03-04T03:55:05Z"
        },
        {
          "author": "iorisa",
          "body": "Well, the functionality to incrementally add requirements was already supported in version 0.6, and this feature was further enhanced in version 0.7. \r\nHowever, the incremental development mode indeed encountered some issues:\r\n1. Larger models tend to gradually lose track during the accumulation of ",
          "created_at": "2024-03-08T06:12:04Z"
        }
      ]
    },
    {
      "issue_number": 164,
      "title": "Limit error when running program",
      "body": "When running the program, I get the following error. Is there a way to resolve the limitations?\r\n\r\nopenai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4264 tokens (1264 in the messages, 3000 in the completion). Please reduce the length of the messages or completion.",
      "state": "closed",
      "author": "mandarin77",
      "author_type": "User",
      "created_at": "2023-08-08T17:41:09Z",
      "updated_at": "2025-03-19T00:32:22Z",
      "closed_at": "2025-03-19T00:32:22Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/164/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/164",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/164",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:12.449244",
      "comments": [
        {
          "author": "voidking",
          "body": "Modify the config in `config/key.yaml`.\r\n1. `OPENAI_API_MODEL` change to `gpt-3.5-turbo-16k` or `gpt-4`.\r\n2. `MAX_TOKENS` change to `5000`.",
          "created_at": "2023-08-09T03:14:23Z"
        },
        {
          "author": "mandarin77",
          "body": "Thank you for your response. I tried setting to turbo as you stated, and 5000 MAX_TOKENS, but I now get this error. Please advise and thanks for your help.\r\n\r\n    result = await fn(*args, **kwargs)\r\n  File \"C:\\MetaGPT\\metagpt\\actions\\action.py\", line 62, in _aask_v1\r\n    instruct_content = output_cl",
          "created_at": "2023-08-09T11:55:47Z"
        },
        {
          "author": "geekan",
          "body": "This problem actually comes from the poor Instruction Following of gpt-3.5-turbo. gpt-4 basically does not have this problem",
          "created_at": "2023-09-09T03:21:59Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-05T00:31:45Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-19T00:32:21Z"
        }
      ]
    },
    {
      "issue_number": 195,
      "title": "Doesn't produce anything close to working code for example \"cli snake game\" given in readme",
      "body": "Cool idea. Thanks for creating it. Interesting to try it out. However the example given in the readme doesn't lead to working code. Unfortunately it tries to instantiate classes without providing necessary properties.\r\n\r\nUsing chatgpt4 and code review. Unfortunately it doesn't seem suitable for any task.\r\n\r\nNote I don't think it is necessarily your fault. ChatGPT4 I think has gotten much worse.",
      "state": "closed",
      "author": "Benzidrine",
      "author_type": "User",
      "created_at": "2023-08-11T08:53:28Z",
      "updated_at": "2025-03-19T00:32:21Z",
      "closed_at": "2025-03-19T00:32:20Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/195/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/195",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/195",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:12.746974",
      "comments": [
        {
          "author": "voidking",
          "body": "Yes, we cannot guarantee that the generated code will work, it relies heavily on gpt. There is some work in the roadmap that may improve the success rate of the first run.",
          "created_at": "2023-08-12T08:38:19Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-05T00:31:43Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-19T00:32:20Z"
        }
      ]
    },
    {
      "issue_number": 249,
      "title": "create an HR role that can create roles as needed ",
      "body": "When a need arises for a specific skill or role that doesn't currently exist in the company (such as API Integration), a higher authority like the Project Manager or CEO could request the HR role to create that position, recruit an agent for it, and integrate it back into the project. Here's how you could implement this:\r\n\r\nStep 1: Define a Mechanism for Role Requests\r\nCreate a mechanism where roles like the Project Manager or CEO can request a new position. This could be a method in the HR role or a separate communication channel within the system.\r\n\r\npython\r\nCopy code\r\nclass HumanResources(Role):\r\n    # ...\r\n\r\n    def request_new_role(self, role_name, description, requester):\r\n        \"\"\"\r\n        Request a new role based on the company's needs.\r\n        \"\"\"\r\n        # Logic to handle the request for a new role\r\n        self.recruit_agent(role_name, description)\r\n        # Notify the requester (e.g., Project Manager, CEO) about the recruitment\r\nStep 2: Implement Recruitment and Integration\r\nIn the HR role, define methods to recruit a new agent for the requested role and integrate it into the existing project.\r\n\r\npython\r\nCopy code\r\n    def recruit_agent(self, role_name, description):\r\n        \"\"\"\r\n        Recruit a new agent and create the specified role.\r\n        \"\"\"\r\n        # Create a new role class if it doesn't exist\r\n        new_role = self.create_role(role_name, description)\r\n        # Create a new agent and assign the new role\r\n        new_agent = self.assign_role(new_role)\r\n        # Integrate the new agent into the project\r\n        self.integrate_agent(new_agent, role_name)\r\n\r\n    def integrate_agent(self, agent, role_name):\r\n        \"\"\"\r\n        Integrate the new agent into the existing project.\r\n        \"\"\"\r\n        # Logic to integrate the new agent into the project\r\nStep 3: Define New Roles Dynamically\r\nDepending on the design of the system, you may need a way to define new roles dynamically based on the request. This could involve creating new classes, configurations, or behaviors for the role.\r\n\r\npython\r\nCopy code\r\n    def create_role(self, role_name, description):\r\n        \"\"\"\r\n        Create a new role based on the given name and description.\r\n        \"\"\"\r\n        # Logic to define a new role dynamically\r\nStep 4: Coordinate with Existing Roles\r\nEnsure that existing roles like Project Manager, Architect, and Engineers can communicate with the HR role and that the new agent integrates smoothly into the existing workflow.\r\n\r\nConclusion\r\nThis approach adds a dynamic and responsive dimension to the MetaGPT project, allowing it to adapt to changing needs and requirements. It simulates how real-world companies identify needs, create new roles, recruit talents, and integrate them into ongoing projects.\r\n\r\nThe complexity of implementing this feature would depend on the existing architecture of the MetaGPT project and the level of realism and flexibility desired. It would likely involve careful design, integration, and testing to ensure that the new roles and agents behave as expected and enhance the overall functionality of the system.",
      "state": "closed",
      "author": "Aaronminer1",
      "author_type": "User",
      "created_at": "2023-08-18T16:40:56Z",
      "updated_at": "2025-03-18T00:32:05Z",
      "closed_at": "2025-03-18T00:32:04Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/249/reactions",
        "total_count": 6,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 3,
        "eyes": 1
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/249",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/249",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:12.965130",
      "comments": [
        {
          "author": "voidking",
          "body": "Good idea! We will think about it. Our current plan is to expand the capabilities of metagpt by accessing third-party roles.",
          "created_at": "2023-08-20T02:54:58Z"
        },
        {
          "author": "geekan",
          "body": "CEO -> raise JD -> HR -> generate role -> evaluate?",
          "created_at": "2023-09-09T03:05:51Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-04T00:31:38Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-18T00:32:04Z"
        }
      ]
    },
    {
      "issue_number": 260,
      "title": "M1 and metaGPT malfunction",
      "body": "It seems some issues occur when a computer with an M1 or M2 apple chip tries to set up metaGpt on their computer. Both my boss and I tried and ran into a lot of errors. Have you heard anything about this issue. Could you please help me figure out how to set it up? I need to test it and analyze it.",
      "state": "closed",
      "author": "mklimov24",
      "author_type": "User",
      "created_at": "2023-08-23T17:43:23Z",
      "updated_at": "2025-03-17T00:34:00Z",
      "closed_at": "2025-03-17T00:33:58Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/260/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/260",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/260",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:13.151456",
      "comments": [
        {
          "author": "voidking",
          "body": "Can you describe the details? For example, what command was executed and what error was reported.",
          "created_at": "2023-08-24T11:38:48Z"
        },
        {
          "author": "mklimov24",
          "body": "mirraklimov@Mirras-MacBook-Pro metagpt % python3 setup.py install\r\nrunning install\r\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-ba",
          "created_at": "2023-08-24T17:25:58Z"
        },
        {
          "author": "anmol098",
          "body": "+1",
          "created_at": "2023-08-30T09:56:11Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-03T00:33:10Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-17T00:33:58Z"
        }
      ]
    },
    {
      "issue_number": 300,
      "title": "Add support for Vertex AI",
      "body": "**_If you are looking for a powerful and affordable platform for text generation, I highly recommend Vertex AI._**\r\n\r\nVertex AI offers a variety of generative models, such as Text Bison, Chat Bison, Code Generation, Code Chat, and Code Completion. These models are fine-tuned for code generation, code chat, and code completion.\r\n\r\nThe pricing for Vertex AI generative models is very reasonable compared to OpenAI. You only pay for the input and output characters that you use, and the price per 1,000 characters is $0.0005 for most models.[Vertex AI Pricing](https://cloud.google.com/vertex-ai/pricing)\r\n\r\n[Vertex AI Code Models](https://cloud.google.com/vertex-ai/docs/generative-ai/code/code-models-overview)\r\n",
      "state": "closed",
      "author": "haseeb-heaven",
      "author_type": "User",
      "created_at": "2023-09-09T03:55:19Z",
      "updated_at": "2025-03-17T00:33:58Z",
      "closed_at": "2025-03-17T00:33:57Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/300/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/300",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/300",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:13.376158",
      "comments": [
        {
          "author": "geekan",
          "body": "Is there any paper or complete comparison document with OpenAI?",
          "created_at": "2023-09-09T07:06:41Z"
        },
        {
          "author": "haseeb-heaven",
          "body": "This [Medium Article](https://medium.com/google-cloud/generative-ai-pricing-openai-vs-google-cloud-8fe708a5636a) is only one i can find for reference now.",
          "created_at": "2023-09-09T10:12:48Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-03T00:33:09Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-17T00:33:57Z"
        }
      ]
    },
    {
      "issue_number": 1567,
      "title": "[Bug]: Rate Limit Exceeded in DDGAPIWrapper Search Function",
      "body": "## Describe the Bug\r\n\r\nThe original `DDGAPIWrapper` raises a `DuckDuckGoSearchException` due to exceeding DuckDuckGo API's rate limits. This prevents the application from retrieving search results effectively.\r\n\r\n### **Error Message**\r\n\r\n```python\r\nduckduckgo_search.exceptions.DuckDuckGoSearchException: _get_url() https://duckduckgo.com/ DuckDuckGoSearchException: Ratelimit\r\n```\r\n\r\n### **Steps to Reproduce**\r\n\r\n- Integrate the original `DDGAPIWrapper` class into your project.\r\n\r\n- Invoke the `run` method multiple times rapidly, for example:\r\n```python\r\npython -m metagpt.roles.researcher \"tensorflow vs. pytorch\r\n```\r\n\r\n- The application raises a `DuckDuckGoSearchException` with the message `Ratelimit`.\r\n\r\n**Sample Code of the original `DDGAPIWrapper`:**\r\n\r\n```python\r\nimport asyncio, json\r\nfrom concurrent import futures\r\nfrom typing import Literal, Optional, overload\r\nfrom pydantic import BaseModel, ConfigDict\r\nfrom duckduckgo_search import DDGS\r\n\r\nclass DDGAPIWrapper(BaseModel):\r\n    model_config = ConfigDict(arbitrary_types_allowed=True)\r\n    loop: Optional[asyncio.AbstractEventLoop] = None\r\n    executor: Optional[futures.Executor] = None\r\n    proxy: Optional[str] = None\r\n\r\n    @property\r\n    def ddgs(self):\r\n        return DDGS(proxies=self.proxy)\r\n\r\n    @overload\r\n    def run(self, query: str, max_results: int = 8, as_string: Literal[True] = True, focus: list[str] | None = None) -> str:\r\n        ...\r\n\r\n    @overload\r\n    def run(self, query: str, max_results: int = 8, as_string: Literal[False] = False, focus: list[str] | None = None) -> list[dict[str, str]]:\r\n        ...\r\n\r\n    async def run(self, query: str, max_results: int = 8, as_string: bool = True) -> str | list[dict]:\r\n        loop = self.loop or asyncio.get_event_loop()\r\n        future = loop.run_in_executor(self.executor, self._search_from_ddgs, query, max_results)\r\n        search_results = await future\r\n\r\n        if as_string:\r\n            return json.dumps(search_results, ensure_ascii=False)\r\n        return search_results\r\n\r\n    def _search_from_ddgs(self, query: str, max_results: int):\r\n        return [\r\n            {\"link\": i[\"href\"], \"snippet\": i[\"body\"], \"title\": i[\"title\"]}\r\n            for (_, i) in zip(range(max_results), self.ddgs.text(query))\r\n        ]\r\n\r\nif __name__ == \"__main__\":\r\n    import fire\r\n    fire.Fire(DDGAPIWrapper().run)\r\n```\r\n\r\n### **Expected Behavior**\r\n\r\nThe `DDGAPIWrapper.run` method should perform DuckDuckGo searches and return the specified number of results without triggering rate limit errors, even under multiple concurrent requests.\r\n\r\n### **Actual Behavior**\r\n\r\nThe method intermittently raises a `DuckDuckGoSearchException` with the message `Ratelimit`, indicating that the application is sending too many requests to the DuckDuckGo API in a short period.\r\n\r\n### **Analysis**\r\n\r\n**Cause:**\r\nThe original script lacks mechanisms to control the frequency of API requests. Rapid or concurrent calls to the `run` method exceed DuckDuckGo's rate limits, resulting in exceptions.\r\n\r\n**Impact:**\r\nFailed search operations disrupt the application's functionality, leading to an inability to retrieve necessary search results.\r\n\r\n### **Proposed Solution**\r\n\r\nEnhance the `DDGAPIWrapper` by implementing rate limiting, retry mechanisms, and caching to prevent exceeding DuckDuckGo's API rate limits.\r\n\r\n**Modifications in `DDGAPIWrapper` (Script 2):**\r\n\r\n- Introduced libraries for rate limiting (`aiolimiter`), caching (`aiocache`), and retries (`tenacity`).\r\n\r\n - Defined `DuckDuckGoSearchException` to handle specific search-related errors.\r\n\r\n - Implemented `AsyncLimiter` to restrict to 1 request per second.\r\n\r\n - Utilized `tenacity` to retry failed requests with exponential backoff upon encountering rate limit exceptions.\r\n\r\n - Added caching to store search results for 5 minutes, reducing redundant API calls.\r\n\r\n - Improved exception handling to differentiate between rate limit errors and other issues.\r\n\r\n- Changed the main execution to use the `cached_run` method, leveraging caching and enhanced functionalities.\r\n\r\n**Modified `DDGAPIWrapper`:**\r\n\r\n```python\r\nimport asyncio, json\r\nfrom concurrent import futures\r\nfrom typing import Literal, Optional, overload\r\nfrom pydantic import BaseModel, ConfigDict\r\nfrom aiolimiter import AsyncLimiter\r\nfrom aiocache import cached, Cache\r\nfrom aiocache.serializers import JsonSerializer\r\nfrom tenacity import retry, wait_exponential, stop_after_attempt, retry_if_exception_type\r\nfrom duckduckgo_search import DDGS\r\n\r\n# Custom exception for DuckDuckGo search errors\r\nclass DuckDuckGoSearchException(Exception):\r\n    pass\r\n\r\nclass DDGAPIWrapper(BaseModel):\r\n    model_config = ConfigDict(arbitrary_types_allowed=True)\r\n    loop: Optional[asyncio.AbstractEventLoop] = None\r\n    executor: Optional[futures.Executor] = None\r\n    proxy: Optional[str] = None\r\n    rate_limiter: AsyncLimiter = AsyncLimiter(max_rate=1, time_period=1)\r\n\r\n    @property\r\n    def ddgs(self):\r\n        return DDGS(proxies=self.proxy)\r\n\r\n    @overload\r\n    def run(self, query: str, max_results: int = 8, as_string: Literal[True] = True, focus: list[str] | None = None) -> str:\r\n        ...\r\n\r\n    @overload\r\n    def run(self, query: str, max_results: int = 8, as_string: Literal[False] = False, focus: list[str] | None = None) -> list[dict[str, str]]:\r\n        ...\r\n\r\n    @retry(\r\n        retry=retry_if_exception_type(DuckDuckGoSearchException),\r\n        wait=wait_exponential(multiplier=1, min=4, max=10),\r\n        stop=stop_after_attempt(5),\r\n        reraise=True\r\n    )\r\n    async def run(self, query: str, max_results: int = 8, as_string: bool = True) -> str | list[dict]:\r\n        loop = self.loop or asyncio.get_event_loop()\r\n\r\n        async with self.rate_limiter:\r\n            try:\r\n                future = loop.run_in_executor(self.executor, self._search_from_ddgs, query, max_results)\r\n                search_results = await future\r\n            except Exception as e:\r\n                if 'Ratelimit' in str(e):\r\n                    print(f\"Rate limit hit for query: {query}. Retrying...\")\r\n                    raise DuckDuckGoSearchException(\"Rate limit exceeded\") from e\r\n                else:\r\n                    print(f\"An error occurred: {e}\")\r\n                    raise DuckDuckGoSearchException(\"An error occurred during search\") from e\r\n\r\n        if as_string:\r\n            return json.dumps(search_results, ensure_ascii=False)\r\n        return search_results\r\n\r\n    def _search_from_ddgs(self, query: str, max_results: int):\r\n        return [\r\n            {\"link\": i[\"href\"], \"snippet\": i[\"body\"], \"title\": i[\"title\"]}\r\n            for (_, i) in zip(range(max_results), self.ddgs.text(query))\r\n        ]\r\n\r\n    @cached(ttl=300, cache=Cache.MEMORY, serializer=JsonSerializer())\r\n    async def cached_run(self, query: str, max_results: int = 8, as_string: bool = True) -> str | list[dict]:\r\n        \"\"\"Cached version of the run method.\"\"\"\r\n        return await self.run(query, max_results, as_string)\r\n\r\nif __name__ == \"__main__\":\r\n    import fire\r\n    api_wrapper = DDGAPIWrapper()\r\n    fire.Fire(api_wrapper.cached_run)\r\n```\r\n\r\n### **Outcome**\r\n\r\nThe application seems to have successfully mitigated rate limit issues. \r\n\r\nI am saying this because I am using models inferred by ollama API endpoints, such that I have encountered issues with respect to token counting, which ollama community is still [tackling](https://github.com/ollama/ollama/issues/3582). \r\n\r\nSo, it would be grateful for anyone who is able to test this proposed solution and see whether it does solve problems relating to DDG while not introducing other errors.\r\n\r\nBut overall, some comments on the proposed fix: \r\n\r\n - The `AsyncLimiter` ensures that search requests do not exceed 1 request per second, adhering to DuckDuckGo's rate limits.\r\n\r\n - The retry mechanism automatically handles transient rate limit errors by retrying failed requests with exponential backoff.\r\n\r\n - Caching reduces redundant API calls for identical queries, optimizing performance and further preventing rate limit breaches.\r\n\r\n- Boiler-plate for custom exceptions for future debugging and maintenance.\r\n",
      "state": "closed",
      "author": "cnm13ryan",
      "author_type": "User",
      "created_at": "2024-11-01T19:22:06Z",
      "updated_at": "2025-03-14T23:54:45Z",
      "closed_at": "2024-12-21T00:30:15Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1567/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "shenchucheng"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1567",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1567",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:13.571974",
      "comments": [
        {
          "author": "shenchucheng",
          "body": "@cnm13ryan  Thank you very much for your advice. Using tenacity is indeed an effective approach. However, I suggest defining a separate DDGSearchRatelimitException, and only retry when a DDGSearchRatelimitException is triggered, rather than retrying on any exception.\r\n\r\n",
          "created_at": "2024-11-05T04:02:20Z"
        },
        {
          "author": "shenchucheng",
          "body": "@cnm13ryan  And, feel free to raise a PR :)\r\n\r\n",
          "created_at": "2024-11-05T04:04:43Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-06T00:33:09Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-21T00:30:15Z"
        },
        {
          "author": "zuxfoucault",
          "body": "> ## Describe the Bug\n> The original `DDGAPIWrapper` raises a `DuckDuckGoSearchException` due to exceeding DuckDuckGo API's rate limits. This prevents the application from retrieving search results effectively.\n> \n> ### **Error Message**\n> duckduckgo_search.exceptions.DuckDuckGoSearchException: _get",
          "created_at": "2025-03-06T20:02:17Z"
        }
      ]
    },
    {
      "issue_number": 558,
      "title": "KeyError: 'Could not automatically map chatglm_turbo to a tokeniser. Please use `tiktok.get_encoding` to explicitly get the tokeniser you expect.'",
      "body": "运行 examples/research.py 时出现错误，\r\n\r\n```python\r\nimport asyncio\r\n\r\nfrom metagpt.roles.researcher import RESEARCH_PATH, Researcher\r\n\r\n\r\nasync def main():\r\n    topic = (\"XXX\")\r\n    role = Researcher(language=\"zh-cn\")\r\n    await role.run(topic)\r\n\r\n    print(f\"save report to {RESEARCH_PATH / f'{topic}.md'}.\")\r\n\r\n\r\nif __name__ == '__main__':\r\n    asyncio.run(main())\r\n```\r\n\r\n```bash\r\n2023-12-14 15:27:28.767 | INFO     | metagpt.const:get_project_root:21 - PROJECT_ROOT set to D:\\_GitHubProjects\\Clones\\MetaGPT\r\n2023-12-14 15:27:28.848 | INFO     | metagpt.config:__init__:44 - Config loading done.\r\n2023-12-14 15:27:30.221 | INFO     | metagpt.roles.researcher:_act:40 - David(Researcher): ready to CollectLinks\r\n [\"artificial intelligence\", \"machine learning\"]2023-12-14 15:27:31.683 | INFO     | metagpt.provider.openai_api:update_cost:91 - Total running cost: $0.000 | Max budget: $10.000 | Current cost: $0.000, prompt_tokens: 36, completion_tokens: 11\r\nTraceback (most recent call last):\r\n  File \"D:\\_GitHubProjects\\Clones\\MetaGPT\\examples\\research.py\", line 24, in <module>\r\n    asyncio.run(main())\r\n  File \"D:\\_firefly\\Python310\\lib\\asyncio\\runners.py\", line 44, in run\r\n    return loop.run_until_complete(main)\r\n  File \"D:\\_firefly\\Python310\\lib\\asyncio\\base_events.py\", line 649, in run_until_complete\r\n    return future.result()\r\n  File \"D:\\_GitHubProjects\\Clones\\MetaGPT\\examples\\research.py\", line 18, in main\r\n    await role.run(topic)\r\n  File \"D:\\_GitHubProjects\\Clones\\MetaGPT\\metagpt\\roles\\role.py\", line 330, in run\r\n    rsp = await self.react()\r\n  File \"D:\\_GitHubProjects\\Clones\\MetaGPT\\metagpt\\roles\\researcher.py\", line 68, in react\r\n    msg = await super().react()\r\n  File \"D:\\_GitHubProjects\\Clones\\MetaGPT\\metagpt\\roles\\role.py\", line 291, in react\r\n    rsp = await self._act_by_order()\r\n  File \"D:\\_GitHubProjects\\Clones\\MetaGPT\\metagpt\\roles\\role.py\", line 278, in _act_by_order\r\n    rsp = await self._act()\r\n  File \"D:\\_GitHubProjects\\Clones\\MetaGPT\\metagpt\\roles\\researcher.py\", line 51, in _act\r\n    links = await todo.run(topic, 4, 4)\r\n  File \"D:\\_GitHubProjects\\Clones\\MetaGPT\\metagpt\\actions\\research.py\", line 130, in run\r\n    prompt = reduce_message_length(gen_msg(), self.llm.model, system_text, CONFIG.max_tokens_rsp)\r\n  File \"D:\\_GitHubProjects\\Clones\\MetaGPT\\metagpt\\utils\\text.py\", line 21, in reduce_message_length\r\n    max_token = TOKEN_MAX.get(model_name, 2048) - count_string_tokens(system_text, model_name) - reserved\r\n  File \"D:\\_GitHubProjects\\Clones\\MetaGPT\\metagpt\\utils\\token_counter.py\", line 105, in count_string_tokens\r\n    encoding = tiktoken.encoding_for_model(model_name)\r\n  File \"D:\\_GitHubProjects\\Clones\\MetaGPT\\.venv\\lib\\site-packages\\tiktoken\\model.py\", line 70, in encoding_for_model\r\n    raise KeyError(\r\nKeyError: 'Could not automatically map chatglm_turbo to a tokeniser. Please use `tiktok.get_encoding` to explicitly get the tokeniser you expect.'\r\n\r\n```",
      "state": "closed",
      "author": "QIN2DIM",
      "author_type": "User",
      "created_at": "2023-12-14T07:30:01Z",
      "updated_at": "2025-03-14T00:31:37Z",
      "closed_at": "2025-03-14T00:31:36Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/558/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/558",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/558",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:13.840116",
      "comments": [
        {
          "author": "shenchucheng",
          "body": "目前仅在openai下做了测试，其他模型需要进一步适配",
          "created_at": "2023-12-21T08:10:53Z"
        },
        {
          "author": "redlion99",
          "body": "chatglm_turbo 使用的encoding是哪个呢？",
          "created_at": "2023-12-29T02:46:13Z"
        },
        {
          "author": "HuntZhaozq",
          "body": "@shenchucheng 请问现在researcher还是只能在openai上使用吗？",
          "created_at": "2024-01-26T02:54:25Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-28T00:31:29Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-14T00:31:36Z"
        }
      ]
    },
    {
      "issue_number": 532,
      "title": "[Suggestion]Gradio Web intefrace",
      "body": "As stated in the title, simple gradio interface that could manage the MetaGPT and its settings (Number of agents, instruction for each agent, OpenAI API key or Local machine hosted Model... etc.)",
      "state": "closed",
      "author": "NightFuryPrime",
      "author_type": "User",
      "created_at": "2023-12-05T13:50:54Z",
      "updated_at": "2025-03-13T00:32:27Z",
      "closed_at": "2025-03-13T00:32:26Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/532/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "voidking"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/532",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/532",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:14.044453",
      "comments": [
        {
          "author": "stellaHSR",
          "body": "You can use https://huggingface.co/spaces/deepwisdom/MetaGPT",
          "created_at": "2023-12-20T09:49:22Z"
        },
        {
          "author": "yvrjsharma",
          "body": "Hi, this space is not accessible, maybe because it is set up as 'private'. Would you be able to check? ",
          "created_at": "2024-11-04T10:45:49Z"
        },
        {
          "author": "geekan",
          "body": "@voidking could you plz help us to check this?",
          "created_at": "2024-11-04T10:48:55Z"
        },
        {
          "author": "voidking",
          "body": "@yvrjsharma Try this: https://huggingface.co/spaces/deepwisdom/MetaGPT-SoftwareCompany",
          "created_at": "2024-11-04T12:24:26Z"
        },
        {
          "author": "yvrjsharma",
          "body": "> @yvrjsharma Try this: https://huggingface.co/spaces/deepwisdom/MetaGPT-SoftwareCompany\r\n\r\nThanks! Yes, this one is Public, however, is in an error state atm. I've restarted the app to see if that helps put it back up.",
          "created_at": "2024-11-04T15:30:48Z"
        }
      ]
    },
    {
      "issue_number": 656,
      "title": "Add Security Engineer role",
      "body": "## User Story\r\nAs a user of MetaGPT, I want to have the option to include a Security Engineer role in my software development process. \r\n\r\n## Feature Description\r\nThe Security Engineer role would be responsible for:\r\n\r\n- Reviewing system architecture diagrams and interface definitions from an application security perspective\r\n- Performing threat modeling to identify potential security vulnerabilities in the design\r\n- Developing and executing security test cases (e.g. input validation, authentication, access control etc.)\r\n- Providing recommendations to mitigate identified security risks\r\n- Ensuring secure coding practices are followed in the implemented code\r\n- Performing security auditing on the final product\r\n\r\n## Benefits\r\nAdding a Security Engineer role would enhance the security posture and trustworthiness of solutions built using MetaGPT. It would act as an additional quality gate to catch security issues early in the development lifecycle. This is especially important for solutions dealing with sensitive data or deployed in security-critical environments.\r\n\r\nHaving security as a first-class concern via a dedicated role would encourage more secure software development practices overall.\r\n\r\n## Acceptance Criteria \r\n- Ability to initialize a Security Engineer agent with specialized skills and knowledge\r\n- Security Engineer can interoperate with other agents via existing message passing mechanisms \r\n- Security test cases are generated and executed\r\n- Recommendations provided to mitigate identified issues\r\n- Metrics capture the number of vulnerabilities detected and remediation rate\r\n\r\nLet me know if any clarification or additional detail is required!",
      "state": "closed",
      "author": "ei-grad",
      "author_type": "User",
      "created_at": "2023-12-29T13:48:57Z",
      "updated_at": "2025-03-13T00:32:25Z",
      "closed_at": "2025-03-13T00:32:25Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/656/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/656",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/656",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:14.260927",
      "comments": [
        {
          "author": "Rchenyu",
          "body": "@ei-grad  It sounds like a very good suggestion！If Metagpt is to create deployable applications, adding a security control module is necessary. You can try developing and submitting a pull request (PR), and if you need any assistance, please let me know. Additionally, we have a developer group. If y",
          "created_at": "2024-02-14T05:46:32Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-27T00:31:20Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-13T00:32:24Z"
        }
      ]
    },
    {
      "issue_number": 731,
      "title": "[Vulnerability] Arbitrary code execution when use QaEngineer role",
      "body": "**Vulnerability description**\r\nWhen we use QaEngineer role, arbitrary code execution could happen because QaEngineer adopt a dangerous action `RunCode` to test codes generated by Engineer. `RunCode.run_script()` method invokes `subprocess.Popen` without any check. Evil guys can manipulate prompts to execute some sensitive operations.\r\n\r\n**Proof of concept**\r\nMy PoC code was designed with slight modifications in your [tutorial example](https://docs.deepwisdom.ai/main/en/guide/get_started/quickstart.html)\r\n```python\r\nimport os\r\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\r\n\r\nimport asyncio\r\nfrom metagpt.roles import (\r\n    ProductManager,\r\n    Architect,\r\n    ProjectManager,\r\n    Engineer,\r\n    QaEngineer\r\n)\r\nfrom metagpt.team import Team\r\n\r\nasync def startup(idea: str):\r\n    company = Team()\r\n    company.hire(\r\n        [\r\n            ProductManager(),\r\n            Architect(),\r\n            ProjectManager(),\r\n            Engineer(),\r\n            QaEngineer()\r\n        ]\r\n    )\r\n    company.invest(investment=1.0)\r\n    company.run_project(idea=idea)\r\n\r\n    await company.run(n_round=16)\r\n\r\nasync def app(user_prompt):\r\n    await startup(idea=user_prompt)\r\n\r\nif __name__ == \"__main__\":\r\n    user_input = \"I want to execute shell command `ls -l`. Please help me write a piece of code and test this code.\"\r\n    asyncio.run(app(user_input))\r\n```\r\nAnd in the path `MetaGPT/workspace/.../test_outputs/`, we can notice the output of `ls -l` in a json file. It means that `ls -l` executes successfully.\r\n![rce](https://github.com/geekan/MetaGPT/assets/17444844/cd0c6905-8971-4b0f-a6da-d7a5327fbb2c)\r\n\r\nNote that in this PoC I only execute `ls -l`, but in real sceanario, attacker could execute dangerous operations such as file deletions, backdoor opening.\r\n\r\n**Vulnerability solved suggestion**\r\nUsing docker to execute python is a good choice. Restricting some sensitive codes via whitelist or blacklist could also be considered.\r\n",
      "state": "closed",
      "author": "fubuki8087",
      "author_type": "User",
      "created_at": "2024-01-10T02:21:24Z",
      "updated_at": "2025-03-12T00:31:49Z",
      "closed_at": "2025-03-12T00:31:48Z",
      "labels": [
        "enhancement",
        "inactive"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/731/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/731",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/731",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:14.539932",
      "comments": [
        {
          "author": "voidking",
          "body": "Good advice. We will take this into consideration.\r\nMaybe you can also contribute a PR? 😁",
          "created_at": "2024-01-17T12:14:23Z"
        },
        {
          "author": "fubuki8087",
          "body": "> Good advice. We will take this into consideration. Maybe you can also contribute a PR? 😁\r\n\r\nThank you, but I am usually quite busy with work. However, I can offer some suggestions here.\r\n\r\n1. **Using docker**. Docker offers an isolated environment. Even if attackers gain remote command execution p",
          "created_at": "2024-01-22T02:17:37Z"
        },
        {
          "author": "geekan",
          "body": "sandbox requirements. I think it is reasonable in a certain sense, but there is always a tradeoff between security and functionality.",
          "created_at": "2024-03-21T13:12:21Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-26T00:31:18Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-12T00:31:47Z"
        }
      ]
    },
    {
      "issue_number": 1178,
      "title": "Wishlist.",
      "body": "(Love the project, awesome work).\r\n\r\nI see Devin/this project doing demos like \"do this simple video game from scratch\", or \"do a to-do list web app\", starting from zero and using whatever libraries/technologies it prefers.\r\n\r\nThose are neat, but I don't think they are the most useful, at least for some people.\r\n\r\nHere's what *I* would want/need these projects to do, in case that would be useful to know, in the form of the prompts as I'd ask them of the agents:\r\n\r\n1. (Coming into my *existing* project/database), tell it: « in src/lib/Editor.ts, there's a function to resize images according to the specs it finds in the database, I'd like that function (and the other sub-functions it calls) to be put into a new library named Resizer.ts in src/lib/utils/, and change Editor.ts to use that library »\r\n\r\n2. « Once that's done, find other places in the code where we resize images, and for each, change them to use the new Resizer library. »\r\n\r\n3. « In src/test, using the same format and testing library as I am already using in my tools, write a series of tests for the Resizer library. You can find \"sample\" images to resize inside of data/samples/resized-images/ »\r\n\r\n4. « My project is made of two parts, the scripts (run with Node) in src/, and the ui (written in Vuejs, run in the browser) in ui/src/. Each part has its own \"Page\" class/abstraction with different functions/properties. I'd like you to join both of these into a single file/class that both the scripts and the UI can call/use. This is tricky because a few of the libraries the \"scripts\"-side class uses will not work in the browser. You must find a solution that allows us to have only one class everything imports, but to not have errors in the browser despite this. Propose and explain in detail a possible solution to this problem for me to review, then if I like the solution I'll ask you to implement it. »\r\n\r\nIf your project was able to do this, it would completely change my life.\r\n\r\nJust a wishlist :) \r\n\r\nAwesome work by the way.\r\n\r\n",
      "state": "closed",
      "author": "arthurwolf",
      "author_type": "User",
      "created_at": "2024-04-10T17:24:29Z",
      "updated_at": "2025-03-12T00:31:47Z",
      "closed_at": "2025-03-12T00:31:47Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1178/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1178",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1178",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:14.751765",
      "comments": [
        {
          "author": "krish240574",
          "body": "I second that, brilliant work !\r\nOne feature I would find really useful - \r\nCache requests and outputs that work, so they could be re-used during future executions. \r\nThanks. \r\n",
          "created_at": "2024-04-11T03:04:39Z"
        },
        {
          "author": "geekan",
          "body": "Sorry, we are currently at a high intensity of work, so the response is very slow. We are solving the scenario you mentioned, please wait for a while.",
          "created_at": "2024-05-18T11:02:30Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-26T00:30:59Z"
        },
        {
          "author": "arthurwolf",
          "body": "I still wish this :)",
          "created_at": "2025-01-26T01:57:22Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-26T00:31:17Z"
        }
      ]
    },
    {
      "issue_number": 1639,
      "title": "集成DesignReview时报错",
      "body": "**Bug description**\r\n我的程序在集成DesignReview时，报错如下：TypeError: DesignReview.run() missing 1 required positional argument: 'api_design'，查了下是 role.py中的代码 async def _act(self) -> Message:\r\n    logger.info(f\"{self._setting}: to do {self.rc.todo}({self.rc.todo.name})\")\r\n    response = await self.rc.todo.run(self.rc.history)只传了一下参数，但DesignReview.run中有两个参数导致的\r\n具体报错信息及代码位置截图显示\r\n\r\n**Bug solved method**\r\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\r\n\r\n**Environment information**\r\n- LLM type and model name:\r\n- System version: windows 11\r\n- Python version: python 3.11\r\n- MetaGPT version or branch: master\r\n\r\n<!-- Dependent packagess：the packages version cause the bug(like `pydantic 1.10.8`), installation method（like `pip install metagpt` or `pip install from source` or `run in docker`） -->\r\n\r\n- packages version:\r\n- installation method: \r\n\r\n**Screenshots or logs**\r\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\r\n![image](https://github.com/user-attachments/assets/cc5dbcad-ff33-42ee-b801-0af74ce39368)\r\n![image](https://github.com/user-attachments/assets/c1cb7663-eb7f-41f6-831f-90ba5eef34be)",
      "state": "closed",
      "author": "deger2012",
      "author_type": "User",
      "created_at": "2024-12-14T07:09:53Z",
      "updated_at": "2025-03-07T00:32:08Z",
      "closed_at": "2025-03-07T00:32:07Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1639/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1639",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1639",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:14.983705",
      "comments": [
        {
          "author": "deger2012",
          "body": "![image](https://github.com/user-attachments/assets/5f662ba0-d915-49ab-87bb-2da7640397bf)\r\n",
          "created_at": "2024-12-14T07:10:49Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-14T00:29:21Z"
        },
        {
          "author": "iorisa",
          "body": "你应该传`prompt`，而不是那两个参数。\n整个MetaGPT框架，agent之间、action之间都是传message。",
          "created_at": "2025-01-16T14:47:05Z"
        },
        {
          "author": "deger2012",
          "body": "嗯 好的 谢谢\r\n\r\n________________________________\r\n发件人: Guess ***@***.***>\r\n发送时间: 2025年1月16日 22:47\r\n收件人: geekan/MetaGPT ***@***.***>\r\n抄送: Luo Min ***@***.***>; Author ***@***.***>\r\n主题: Re: [geekan/MetaGPT] 集成DesignReview时报错 (Issue #1639)\r\n\r\n\r\n你应该传prompt，而不是那两个参数\r\n\r\n―\r\nReply to this email directly, view it",
          "created_at": "2025-01-21T07:52:23Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-21T00:31:02Z"
        }
      ]
    },
    {
      "issue_number": 1672,
      "title": "MetaGPT response: ValueError: Detected source code \"docs/prd/20250119145241.json\" from an unknown origin.",
      "body": "ValueError: Detected source code \"docs/prd/20250119145241.json\" from an unknown origin.\n<!-- Clearly and directly describe the current bug -->\n\n**Environment information**\nUsing Windows 11, installed using docker.\n- LLM type and model name: ollama llama3\n- System version: Windows 11\n- Python version:3.12.4\n- MetaGPT version or branch:latest\n\n<!-- Dependent packagess：the packages version cause the bug(like `pydantic 1.10.8`), installation method（like `pip install metagpt` or `pip install from source` or `run in docker`） -->\n\nCONFIGURATION FILE: \n(config2.yml)\nllm:\n  api_type: \"ollama\"  # Change this to 'ollama'\n  model: \"llama3\"     # Use the name of the model you pulled\n  base_url: \"http://192.168.1.102:11434/api\"  # Default URL for the Ollama API\n  api_key: \"dummy_api_key_123456\"         # Leave this empty for Ollama, no API key needed\n  repair_llm_output: true\n\n\nmermaid:\n  engine: \"nodejs\"\n  path: \"mmdc\"\n  puppeteer_config: \"/app/metagpt/config/puppeteer-config.json\"\n  pyppeteer_path: \"/usr/bin/chromium\"\n\n\n\n\nMy input in powershell:\ndocker run --rm -v D:\\metagpt\\config\\config2.yaml:/app/metagpt/config/config2.yaml -v D:\\metagpt\\workspace:/app/metagpt/workspace metagpt/metagpt:latest metagpt \"Write a cli snake game\"\n\n\nOutput in powershell:-\nPS D:\\metagpt> docker run --rm -v D:\\metagpt\\config\\config2.yaml:/app/metagpt/config/config2.yaml -v D:\\metagpt\\workspace:/app/metagpt/workspace metagpt/metagpt:latest metagpt \"Write a cli snake game\"\n2025-01-19 14:58:54.539 | INFO     | metagpt.const:get_metagpt_package_root:21 - Package root set to /app/metagpt\n2025-01-19 14:58:56.983 | INFO     | metagpt.team:invest:93 - Investment: $3.0.\n2025-01-19 14:58:56.984 | INFO     | metagpt.roles.role:_act:403 - Alice(Product Manager): to do PrepareDocuments(PrepareDocuments)\n2025-01-19 14:58:57.739 | INFO     | metagpt.utils.file_repository:save:57 - save to: /app/metagpt/workspace/20250119145856/docs/requirement.txt\n2025-01-19 14:58:57.740 | INFO     | metagpt.roles.role:_act:403 - Alice(Product Manager): to do WritePRD(WritePRD)\n2025-01-19 14:58:57.745 | INFO     | metagpt.actions.write_prd:run:86 - New requirement detected: Write a cli snake game\n2025-01-19 15:00:06.783 | WARNING  | metagpt.utils.cost_manager:update_cost:49 - Model llama3 not found in TOKEN_COSTS.\n2025-01-19 15:00:06.802 | INFO     | metagpt.utils.git_repository:rename_root:203 - Delete directory /app/metagpt/workspace/game_snake_cli\n2025-01-19 15:00:07.111 | WARNING  | metagpt.utils.git_repository:rename_root:217 - Failed to move /app/metagpt/workspace/20250119145856 to /app/metagpt/workspace/game_snake_cli\n2025-01-19 15:00:07.156 | INFO     | metagpt.utils.file_repository:save:57 - save to: /app/metagpt/workspace/20250119145856/docs/prd/20250119150007.json\n2025-01-19 15:00:07.196 | INFO     | metagpt.utils.file_repository:save:57 - save to: /app/metagpt/workspace/20250119145856/resources/prd/20250119150007.md\n2025-01-19 15:00:07.199 | INFO     | metagpt.roles.role:_act:403 - Bob(Architect): to do WriteDesign(WriteDesign)\n2025-01-19 15:00:07.727 | INFO     | metagpt.actions.design_api:run:67 - Nothing has changed.\n2025-01-19 15:00:07.729 | INFO     | metagpt.roles.role:_act:403 - Eve(Project Manager): to do WriteTasks(WriteTasks)\n2025-01-19 15:00:08.068 | INFO     | metagpt.actions.project_management:run:54 - Nothing has changed.\n2025-01-19 15:00:09.325 | ERROR    | metagpt.roles.engineer:_new_coding_context:280 - Detected source code \"docs/prd/20250119150007.json\" from an unknown origin.\n2025-01-19 15:00:09.326 | WARNING  | metagpt.utils.common:wrapper:673 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.\n2025-01-19 15:00:09.327 | ERROR    | metagpt.utils.common:wrapper:655 - Exception occurs, start to serialize the project, exp:\nTraceback (most recent call last):\n  File \"/app/metagpt/metagpt/utils/common.py\", line 664, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"/app/metagpt/metagpt/roles/role.py\", line 551, in run\n    rsp = await self.react()\nValueError: Detected source code \"docs/prd/20250119150007.json\" from an unknown origin.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/app/metagpt/metagpt/utils/common.py\", line 650, in wrapper\n    result = await func(self, *args, **kwargs)\n  File \"/app/metagpt/metagpt/team.py\", line 134, in run\n    await self.env.run()\nException: Traceback (most recent call last):\n  File \"/app/metagpt/metagpt/utils/common.py\", line 664, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"/app/metagpt/metagpt/roles/role.py\", line 551, in run\n    rsp = await self.react()\n  File \"/app/metagpt/metagpt/roles/role.py\", line 520, in react\n    rsp = await self._react()\n  File \"/app/metagpt/metagpt/roles/role.py\", line 470, in _react\n    todo = await self._think()\n  File \"/app/metagpt/metagpt/roles/engineer.py\", line 256, in _think\n    await self._new_code_actions()\n  File \"/app/metagpt/metagpt/roles/engineer.py\", line 347, in _new_code_actions\n    coding_doc = await self._new_coding_doc(filename=filename, dependency=dependency)\n  File \"/app/metagpt/metagpt/roles/engineer.py\", line 292, in _new_coding_doc\n    context = await self._new_coding_context(filename, dependency)\n  File \"/app/metagpt/metagpt/roles/engineer.py\", line 281, in _new_coding_context\n    raise ValueError(f'Detected source code \"{filename}\" from an unknown origin.')\nValueError: Detected source code \"docs/prd/20250119150007.json\" from an unknown origin.\n\n\n[CONTENT]\n{\n    \"Language\": \"en_us\",\n    \"Programming Language\": \"Python\",\n    \"Original Requirements\": \"Create a CLI snake game\",\n    \"Project Name\": \"game_snake_cli\",\n    \"Product Goals\": [\n        \"Create an engaging user experience\",\n        \"Improve accessibility, be responsive\",\n        \"More beautiful UI\"\n    ],\n    \"User Stories\": [\n        \"As a player, I want to be able to choose difficulty levels\",\n        \"As a player, I want to see my score after each game\",\n        \"As a player, I want to get restart button when I lose\",\n        \"As a player, I want to see beautiful UI that make me feel good\",\n        \"As a player, I want to play game via command line interface\"\n    ],\n    \"Competitive Analysis\": [\n        \"Snake Game A: Simple interface, lacks responsive features\",\n        \"play2048.co: Beautiful and responsive UI with my best score shown\",\n        \"snakegame.com: Responsive UI with my best score shown, but many ads\"\n    ],\n    \"Competitive Quadrant Chart\": \"\",\n    \"Requirement Analysis\": \"\",\n    \"Requirement Pool\": [\n        [\n            \"P0\",\n            \"The main code for snake game logic...\"\n        ]\n    ],\n    \"UI Design draft\": \"Basic function description with a simple style and layout.\",\n    \"Anything UNCLEAR\": \"\"\n}\n[/CONTENT]",
      "state": "closed",
      "author": "IshpreetSingh8264",
      "author_type": "User",
      "created_at": "2025-01-19T15:00:41Z",
      "updated_at": "2025-03-06T00:31:51Z",
      "closed_at": "2025-03-06T00:31:50Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1672/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1672",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1672",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:15.237540",
      "comments": [
        {
          "author": "iorisa",
          "body": "According to the logs you provided, the LLaMA3 model you used did not successfully complete the design work for the PRD, which subsequently triggered the following issues. I suggest you try other llm.\n\nMy log from the design phase of the GPT-4O-Mini model is as follows:\n```\n2025-01-20 02:40:53.434 |",
          "created_at": "2025-01-20T02:59:11Z"
        },
        {
          "author": "IshpreetSingh8264",
          "body": "```\nC:\\Users\\acer>docker run --rm -v D:\\metagpt\\config\\config2.yaml:/app/metagpt/config/config2.yaml -v D:\\metagpt\\workspace:/app/metagpt/workspace metagpt/metagpt:latest metagpt \"Write a cli snake game\"\n2025-01-20 07:05:29.623 | INFO     | metagpt.const:get_metagpt_package_root:21 - Package root se",
          "created_at": "2025-01-20T07:11:24Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-20T00:30:58Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-06T00:31:49Z"
        }
      ]
    },
    {
      "issue_number": 1660,
      "title": "SoftwareDev dataset",
      "body": "Hello Developer,\r\nMay I ask where I can obtain the contents of the SoftwareDev dataset? Or is this dataset a closed-source dataset?",
      "state": "closed",
      "author": "yuanhao2023",
      "author_type": "User",
      "created_at": "2025-01-10T03:23:38Z",
      "updated_at": "2025-03-04T00:31:37Z",
      "closed_at": "2025-03-04T00:31:36Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1660/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1660",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1660",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:15.546842",
      "comments": [
        {
          "author": "iorisa",
          "body": "Sorry, I don't quite understand what the `SoftwareDev dataset` is used for. To avoid any misunderstanding, could you please describe it in detail?\r\n",
          "created_at": "2025-01-11T07:37:56Z"
        },
        {
          "author": "yuanhao2023",
          "body": "> 抱歉，我不太明白 this 是做什么用的。为避免任何误解，您能详细描述一下吗？`SoftwareDev dataset`\r\n\r\nThanks for your reply. According to the MetaGPT paper, the performance comparison between MetaGPT and ChatDev is based on the SoftwareDev dataset. I am currently working on a research project based on MetaGPT and would like to evaluat",
          "created_at": "2025-01-11T08:17:24Z"
        },
        {
          "author": "iorisa",
          "body": "The SoftwareDev related to the MetaGPT paper is not open to the public. After the release of MetaGPT 1.0 and MGX, we will open an open-source version similar to SoftwareDev.",
          "created_at": "2025-01-18T03:45:18Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-18T00:30:25Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-04T00:31:36Z"
        }
      ]
    },
    {
      "issue_number": 1663,
      "title": "遇到个bug  tenacity.RetryError: RetryError[<Future at 0x7f0b05a80c40 state=finished raised RetryError>]",
      "body": "**Bug description**\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/__init__.py\", line 382, in __call__\r\n    result = fn(*args, **kwargs)\r\n  File \"/app/metagpt/metagpt/utils/repair_llm_raw_output.py\", line 296, in retry_parse_json_text\r\n    parsed_data = CustomDecoder(strict=False).decode(output)\r\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 50, in __call__\r\n    result = await fn(*args, **kwargs)\r\n  File \"/app/metagpt/metagpt/actions/action_node.py\", line 442, in _aask_v1\r\n    parsed_data = llm_output_postprocess(\r\ntenacity.RetryError: RetryError[<Future at 0x7f0b05a80cd0 state=finished raised JSONDecodeError>]\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/app/metagpt/metagpt/utils/common.py\", line 664, in wrapper\r\n    return await func(self, *args, **kwargs)\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 551, in run\r\n    rsp = await self.react()\r\ntenacity.RetryError: RetryError[<Future at 0x7f0b05a80c40 state=finished raised RetryError>]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/app/metagpt/metagpt/utils/common.py\", line 650, in wrapper\r\n    result = await func(self, *args, **kwargs)\r\n  File \"/app/metagpt/metagpt/team.py\", line 134, in run\r\n    await self.env.run()\r\nException: Traceback (most recent call last):\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/__init__.py\", line 382, in __call__\r\n    result = fn(*args, **kwargs)\r\n  File \"/app/metagpt/metagpt/utils/repair_llm_raw_output.py\", line 296, in retry_parse_json_text\r\n    parsed_data = CustomDecoder(strict=False).decode(output)\r\n  File \"/app/metagpt/metagpt/utils/custom_decoder.py\", line 297, in decode\r\n    return super().decode(s)\r\n  File \"/usr/local/lib/python3.9/json/decoder.py\", line 337, in decode\r\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\r\n  File \"/usr/local/lib/python3.9/json/decoder.py\", line 355, in raw_decode\r\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\r\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 50, in __call__\r\n    result = await fn(*args, **kwargs)\r\n  File \"/app/metagpt/metagpt/actions/action_node.py\", line 442, in _aask_v1\r\n    parsed_data = llm_output_postprocess(\r\n  File \"/app/metagpt/metagpt/provider/postprocess/llm_output_postprocess.py\", line 19, in llm_output_postprocess\r\n    result = postprocess_plugin.run(output=output, schema=schema, req_key=req_key)\r\n  File \"/app/metagpt/metagpt/provider/postprocess/base_postprocess_plugin.py\", line 68, in run\r\n    new_output = self.run_repair_llm_output(output=output, schema=schema, req_key=req_key)\r\n  File \"/app/metagpt/metagpt/provider/postprocess/base_postprocess_plugin.py\", line 32, in run_repair_llm_output\r\n    parsed_data = self.run_retry_parse_json_text(content)\r\n  File \"/app/metagpt/metagpt/provider/postprocess/base_postprocess_plugin.py\", line 47, in run_retry_parse_json_text\r\n    parsed_data = retry_parse_json_text(output=content)  # should use output=content\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/__init__.py\", line 289, in wrapped_f\r\n    return self(f, *args, **kw)\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/__init__.py\", line 379, in __call__\r\n    do = self.iter(retry_state=retry_state)\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/__init__.py\", line 326, in iter\r\n    raise retry_exc from fut.exception()\r\ntenacity.RetryError: RetryError[<Future at 0x7f0b05a80cd0 state=finished raised JSONDecodeError>]\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/app/metagpt/metagpt/utils/common.py\", line 664, in wrapper\r\n    return await func(self, *args, **kwargs)\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 551, in run\r\n    rsp = await self.react()\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 520, in react\r\n    rsp = await self._react()\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 475, in _react\r\n    rsp = await self._act()\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 404, in _act\r\n    response = await self.rc.todo.run(self.rc.history)\r\n  File \"/app/metagpt/metagpt/actions/write_prd.py\", line 87, in run\r\n    return await self._handle_new_requirement(req)\r\n  File \"/app/metagpt/metagpt/actions/write_prd.py\", line 108, in _handle_new_requirement\r\n    node = await WRITE_PRD_NODE.fill(context=context, llm=self.llm, exclude=exclude)  # schema=schema\r\n  File \"/app/metagpt/metagpt/actions/action_node.py\", line 648, in fill\r\n    return await self.simple_fill(schema=schema, mode=mode, images=images, timeout=timeout, exclude=exclude)\r\n  File \"/app/metagpt/metagpt/actions/action_node.py\", line 473, in simple_fill\r\n    content, scontent = await self._aask_v1(\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\r\n    return await fn(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 47, in __call__\r\n    do = self.iter(retry_state=retry_state)\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/__init__.py\", line 326, in iter\r\n    raise retry_exc from fut.exception()\r\ntenacity.RetryError: RetryError[<Future at 0x7f0b05a80c40 state=finished raised RetryError>]\r\n\r\n**Environment information**\r\nlmstudio  部署的 qwen1.5-0.5b-chat。\r\n在你们提供的docker容器运行。\r\n\r\n\r\n能够输出code代码。不知道什么原因造成的。\r\n",
      "state": "closed",
      "author": "Salary-only-17k",
      "author_type": "User",
      "created_at": "2025-01-12T13:45:31Z",
      "updated_at": "2025-03-04T00:31:36Z",
      "closed_at": "2025-03-04T00:31:35Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1663/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1663",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1663",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:15.844384",
      "comments": [
        {
          "author": "Salary-only-17k",
          "body": "\r\n random\r\nfrom random import randint\r\n\r\nclass Game:\r\n    def __init__(self):\r\n        self.score = 0\r\n        self difficulty = 1\r\n        self.user_stories = []\r\n\r\n    def play(self, player_id):\r\n        # Generate random number between 0 and 2047\r\n        player_number = randint(0, 2048)\r\n       ",
          "created_at": "2025-01-12T13:46:13Z"
        },
        {
          "author": "Salary-only-17k",
          "body": "生成的代码运行不起来",
          "created_at": "2025-01-12T13:48:12Z"
        },
        {
          "author": "iorisa",
          "body": "你可以试试用[增量开发功能](https://docs.deepwisdom.ai/main/en/guide/in_depth_guides/incremental_development.html)来修这个bug。\n不过我更推荐你使用[Data Interpreter模式](https://docs.deepwisdom.ai/main/en/guide/use_cases/agent/interpreter/intro.html)来解决这种非SOP场景。软件公司SOP是一个用来展示MetaGPT框架能力的示例，但实际上软件开发流程并不是一个SOP场景。",
          "created_at": "2025-01-18T03:35:02Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-18T00:30:24Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-04T00:31:35Z"
        }
      ]
    },
    {
      "issue_number": 1668,
      "title": "关于调用千帆api",
      "body": "请问如何更新model列表？像一些比较新的模型如ERNIE 4.0\\3.5 都不在qianfan支持的模型列表内。",
      "state": "closed",
      "author": "Akihiiii",
      "author_type": "User",
      "created_at": "2025-01-16T14:01:47Z",
      "updated_at": "2025-03-03T00:33:08Z",
      "closed_at": "2025-03-03T00:33:07Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1668/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1668",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1668",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:16.051564",
      "comments": [
        {
          "author": "iorisa",
          "body": "qianfan模型代码是这个`metagpt/provider/qianfan_api.py`。\n是模型调不通还是说扣费结算问题？\n如果是扣费结算问题，可以在`metagpt/utils/token_counter.py`中添加：\n```python\n\"\"\"\nQianFan Token Price https://cloud.baidu.com/doc/WENXINWORKSHOP/s/hlrk4akp7#tokens%E5%90%8E%E4%BB%98%E8%B4%B9\nDue to QianFan has multi price strategies, we unify `Tokens p",
          "created_at": "2025-01-16T14:24:56Z"
        },
        {
          "author": "Akihiiii",
          "body": "感谢您百忙之中的回复！\n`2025-01-17 17:16:03.811 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 0.000(s), this was the 1st time calling it. exp: The provided model `ERNIE-4.0-8K` is not in the list of supported models. If this is a recentl",
          "created_at": "2025-01-17T09:22:06Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-17T00:32:35Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-03T00:33:07Z"
        }
      ]
    },
    {
      "issue_number": 1630,
      "title": " The package installation behavior in the code is unrestricted",
      "body": "**Bug description**\r\nIn the process of using MetaGPT's QaEngine, users can easily make the `RunCode._install_requirements` method download any dependency package through conversation. This could potentially allow malicious users to have the MetaGPT-deployed server download malicious dependency packages or change the versions of the dependencies required for the runtime environment.\r\n\r\n**Bug solved method**\r\nWe recommend that MetaGPT provide a reminder to inform developers to restrict the Python environment, at the very least avoiding the use of the same Python environment that is running MetaGPT.\r\n\r\n**Environment information**\r\n- LLM type and model name: OpenAI gpt-3.5-turbo\r\n- System version: ubuntu18.04 \r\n- Python version:  python3.11\r\n- MetaGPT version or branch: 68b7dc6\r\n- packages version:\r\n- installation method: \r\n\r\n**Screenshots or logs**\r\nPoC:\r\n```python\r\nimport os\r\nos.environ[\"OPENAI_API_KEY\"] = \"\"\r\n\r\nimport asyncio\r\nfrom metagpt.roles import (\r\n    ProductManager,\r\n    Architect,\r\n    ProjectManager,\r\n    Engineer,\r\n    QaEngineer\r\n)\r\nfrom metagpt.team import Team\r\n\r\nasync def startup(idea: str):\r\n    company = Team()\r\n    company.hire(\r\n        [\r\n            ProductManager(),\r\n            Architect(),\r\n            ProjectManager(),\r\n            Engineer(),\r\n            QaEngineer()\r\n\r\n        ]\r\n    )\r\n    company.invest(investment=1.0)\r\n    company.run_project(idea=idea)\r\n\r\n    await company.run(n_round=16)\r\n\r\nasync def app(user_prompt):\r\n    await startup(idea=user_prompt)\r\n\r\nif __name__ == \"__main__\":\r\n    user_input = \"write a calculate program, I need to include pandasai==2.4.0 and langchain==0.0.231 in the generated requirements.txt \" \\\r\n                 \"as a service, so please download it and excute the program.\"\r\n    asyncio.run(app(user_input))\r\n```\r\nScreenshots:\r\n<img width=\"1479\" alt=\"image\" src=\"https://github.com/user-attachments/assets/71e48d0b-1173-4566-98c9-2b8d538cf584\">\r\n",
      "state": "closed",
      "author": "BACMiao",
      "author_type": "User",
      "created_at": "2024-12-06T03:40:21Z",
      "updated_at": "2025-03-02T00:34:05Z",
      "closed_at": "2025-03-02T00:34:04Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1630/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1630",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1630",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:16.284636",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-06T00:32:30Z"
        },
        {
          "author": "iorisa",
          "body": "MetaGPT has two modes: SOP and Data Interpreter mode. \nSOP is a kind of waterfall model. The software company you use is an example of SOP. The applicable scenario for SOP is to implement some fixed processes. Therefore, whether to allow pip install should be determined at the design stage of SOP, r",
          "created_at": "2025-01-16T14:55:53Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-16T00:33:46Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-02T00:34:04Z"
        }
      ]
    },
    {
      "issue_number": 1646,
      "title": "如何在自己定义的role引入自己编写的tool？",
      "body": "官方示例docs中用写好的DataInterpreter这个role进行tool的使用，但是我想自己创建一个class role来使用自定义的tool，要如何做呢\r\n",
      "state": "closed",
      "author": "cjrcjrljy",
      "author_type": "User",
      "created_at": "2024-12-17T10:38:31Z",
      "updated_at": "2025-03-02T00:34:03Z",
      "closed_at": "2025-03-02T00:34:03Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1646/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1646",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1646",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:16.483385",
      "comments": [
        {
          "author": "shenchucheng",
          "body": "可以继承DataInterpreter，然后tools传入你的工具",
          "created_at": "2024-12-17T14:07:03Z"
        },
        {
          "author": "cjrcjrljy",
          "body": "> \r\n\r\n但是DataInterpreter的一些功能我不需要，并且写了新的提示词后还是会执行一些我不需要的步骤，所以怎样自己创建一个新的role然后可以使用tools",
          "created_at": "2025-01-10T01:45:16Z"
        },
        {
          "author": "iorisa",
          "body": "DI的用法有示例：https://github.com/geekan/MetaGPT/blob/main/examples/di/crawl_webpage.py\n主要是2部分：\n1. 创建对象的时候，把你要使用的工具注册进去，像这样(注意要确保`import scrape_web_playwright`成功)：\n```python\ndi = DataInterpreter(tools=[\"scrape_web_playwright\"])\n```\n2. 创建工具的时候要使用`@register_tool`装饰器，还要添加google docstring格式的注释，DI根据这些注释来理解工具的用",
          "created_at": "2025-01-16T14:35:44Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-16T00:33:43Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-02T00:34:02Z"
        }
      ]
    },
    {
      "issue_number": 1667,
      "title": "Can you release some examples about how to use RoleReactMode",
      "body": "**Feature description**\r\n<!-- Clear and direct description of the functionality of the currently submitted or proposed feature -->\r\nAll examples is `react_mode = BY_ORDER`. \r\nI know MetaGPT   supporting `REACT or PLAN_AND_ACT` model, so could you release more example how to use `REACT or PLAN_AND_ACT`.\r\n",
      "state": "closed",
      "author": "GitEasonXu",
      "author_type": "User",
      "created_at": "2025-01-15T06:10:21Z",
      "updated_at": "2025-03-02T00:34:02Z",
      "closed_at": "2025-03-02T00:34:01Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1667/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1667",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1667",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:16.707731",
      "comments": [
        {
          "author": "iorisa",
          "body": "The `Data Interpreter` utilizes the `PLAN_AND_ACT` mode. \nYou can find the detailed code in `metagpt/roles/di/data_interpreter.py`. \nYou can also find relevant demos at [Data Interpreter (DI) | MetaGPT](https://docs.deepwisdom.ai/main/en/guide/use_cases/agent/interpreter/intro.html).\n\nRegarding `REA",
          "created_at": "2025-01-16T14:11:43Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-16T00:33:42Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-02T00:34:01Z"
        }
      ]
    },
    {
      "issue_number": 1664,
      "title": "Frustration in Environment Setup",
      "body": "**Bug description**\r\nI have followed the environement setup guide in github listed below:\r\n1) conda create -n metagpt python=3.9 && conda activate metagpt\r\n2) pull the git repo\r\n3) pip install -r requirement.txt\r\n4) pip install --upgrade metagpt\r\n5) initilize the llm configuration\r\n6) now I try to run my code that is fine with importing statements like from metagpt.actions import Action, and from metagpt.team import Team, however, the importing statement from metagpt.rag.engines import SimpleEngine really gives me a headache.\r\nFirst, I encountered an error \r\ncannot import name 'Url' from 'pydantic.networks', which I found the reason was that the pydantic version is too new on my side, which is pydantic-2.10.5 that replaces Url with AnyUrl or HttpUrl\r\nSo, I downgrade my pydantic verison to 2.6.4 and install the corresponding llama-index version 0.10.0, however, I found that it now gives me another error \r\nmodule not Found Error, no module named 'llama_index.vector_stores\" which is because my llama index version is too old, the version 0.12.10 has vector stores\r\nBut when I update my llama_index version I found that llama_index 0.12.10 depends on pydantic version 2.10.5 so it is a cicular dependency now. I do not know how to solve it \r\n\r\n**Bug solved method**\r\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\r\nI do not know how to solve it with the conflict on pydantic and llama_inndex, even if I disable the import statement, the system seems to import the SimpleEngine automatically \r\n\r\n**Environment information**\r\n<!-- Environment：System version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\r\n\r\n- LLM type and model name: api_type: \"ollama\", model: \"llama3.2\",base_url: \"http://localhost:11434\", api_key: \"dummy\"\r\n- System version: MacOS\r\n- Python version: conda 3.9 \r\n- MetaGPT version or branch: 0.8.1\r\n\r\n<!-- Dependent packagess：the packages version cause the bug(like `pydantic 1.10.8`), installation method（like `pip install metagpt` or `pip install from source` or `run in docker`） -->\r\n\r\n- packages version: pydantic 2.6.4/2.10.5, llama_index 0.10.0/0.12.10\r\n- installation method:  pip install\r\n\r\n**Screenshots or logs**\r\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\r\n",
      "state": "closed",
      "author": "JustinGao20",
      "author_type": "User",
      "created_at": "2025-01-12T15:30:51Z",
      "updated_at": "2025-03-01T00:34:27Z",
      "closed_at": "2025-03-01T00:34:26Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1664/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1664",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1664",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:16.971090",
      "comments": [
        {
          "author": "iorisa",
          "body": "Recommended package version list: #1653 ",
          "created_at": "2025-01-15T02:26:00Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-15T00:30:02Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-01T00:34:25Z"
        }
      ]
    },
    {
      "issue_number": 1661,
      "title": "为什么不支持qwen-coder?",
      "body": "支持列表没看到这一api",
      "state": "closed",
      "author": "daviddavid97",
      "author_type": "User",
      "created_at": "2025-01-12T06:30:10Z",
      "updated_at": "2025-02-26T00:31:16Z",
      "closed_at": "2025-02-26T00:31:15Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1661/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1661",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1661",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:18.925710",
      "comments": [
        {
          "author": "iorisa",
          "body": "千问大模型已经支持openai接口了，可以参考issue #1650 的解决方法，换一下模型名字就行了\r\n\r\n",
          "created_at": "2025-01-12T09:49:15Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-12T00:30:21Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-26T00:31:15Z"
        }
      ]
    },
    {
      "issue_number": 763,
      "title": "ActionNode 是否可以支持列表式的children？",
      "body": "**Feature description**\r\n<!-- Clear and direct description of the functionality of the currently submitted or proposed feature -->\r\n\r\n**Your Feature**\r\n<!-- Describe the idea or process of implementing the current feature. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- When submitting features, you need to complete the corresponding doc/tests/examples to facilitate verification by reviewers. -->\r\n我的代码如下：\r\n```python\r\nfrom typing import Dict, List\r\nfrom metagpt.actions.action_node import ActionNode\r\nNAME = ActionNode(\r\n    key=\"name\",\r\n    expected_type=str,\r\n    instruction=\"\"\"name of the objective\"\"\",\r\n    example=\"color\"\r\n)\r\n\r\nVARIABLE_TYPE = ActionNode(\r\n    key=\"type\",\r\n    expected_type=str,\r\n    instruction=\"\"\"type of the varialbe. can be String, Int, Float etc, or a self defined type\"\"\",\r\n    example=\"AgentPopulation\")\r\nDESC = ActionNode(\r\n    key=\"desc\",\r\n    expected_type=str,\r\n    instruction=\"\"\"description\"\"\",\r\n    example=\"im a description\"\r\n)\r\nVariable_Type = ActionNode.from_children(\r\n    \"variable\", [NAME, VARIABLE_TYPE, DESC])\r\nVARIABLE_LIST = ActionNode(\r\n    key=\"variables\",\r\n    expected_type=List[Variable_Type],\r\n    instruction=\"\"\"list of variables\"\"\",\r\n    # example=[{\r\n    #     \"name\": \"current_patch\",\r\n    #     \"type\": \"Discrete2DPatch\",\r\n    #     \"desc\": \"当前网格\"\r\n    # }]\r\n    example=[]\r\n)\r\nInput_Type = ActionNode.from_children(\"input\", [NAME, VARIABLE_TYPE, DESC])\r\nINPUTS = ActionNode(\r\n    key=\"inputs\",\r\n    expected_type=List[Input_Type],\r\n    instruction=\"\"\"list of inputs\"\"\",\r\n    example=[]\r\n)\r\n```\r\n我想创建一个INPUTS类型，用来生成一系列变量。由于需要的变量数量不能提前确定，我需要将他们放到一个list中，但是目前好像不支持      expected_type=List[Variable_Type] 这种方式。\r\n报错的信息：\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/jovyan/LLM_agent/MetaGen/action_node.py\", line 29, in <module>\r\n    expected_type=List[Variable_Type],\r\n  File \"/home/jovyan/.conda/envs/metagpt/lib/python3.10/typing.py\", line 312, in inner\r\n    return func(*args, **kwds)\r\n  File \"/home/jovyan/.conda/envs/metagpt/lib/python3.10/typing.py\", line 1143, in __getitem__\r\n    params = tuple(_type_check(p, msg) for p in params)\r\n  File \"/home/jovyan/.conda/envs/metagpt/lib/python3.10/typing.py\", line 1143, in <genexpr>\r\n    params = tuple(_type_check(p, msg) for p in params)\r\n  File \"/home/jovyan/.conda/envs/metagpt/lib/python3.10/typing.py\", line 176, in _type_check\r\n    raise TypeError(f\"{msg} Got {arg!r:.100}.\")\r\nTypeError: Parameters to generic types must be types. Got variable, <class 'str'>, , , , {'name': name, <class 'str'>, name of the objective, color, , {}, 'ty.\r\n```\r\n请问是否有其他方式能够实现让他动态的生成一组不定数量的Variable_Type类型的数据？",
      "state": "closed",
      "author": "wujiren",
      "author_type": "User",
      "created_at": "2024-01-16T09:33:13Z",
      "updated_at": "2025-02-25T00:31:39Z",
      "closed_at": "2025-02-25T00:31:39Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/763/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "geekan"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/763",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/763",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:19.142659",
      "comments": [
        {
          "author": "geekan",
          "body": "It's still in the design stage, and further design is needed to complete and stabilize the output, so if you're interested, you can participate in this part together",
          "created_at": "2024-01-17T12:49:10Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-10T00:31:49Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-25T00:31:38Z"
        }
      ]
    },
    {
      "issue_number": 774,
      "title": "Encountered a bug where unable to generate and save report while trying examples/research.py.",
      "body": "**Bug description**\r\nWhen trying the examples/research.py, encountered a bug where unable to generate and save report. The process stops at the step to do ConductResearch, with prompt_tokens: 1874, completion_tokens: 0, and the content is empty ('').\r\n\r\n**Environment information**\r\n- LLM type and model name: gpt-4-1106-preview\r\n- System version: ubuntu 22.04\r\n- Python version: 3.10.12\r\n- packages version: 0.6.0, 0.6.4, 0.6.5\r\n- installation method: pip install metagpt\r\n\r\n**Screenshots or logs**\r\n2024-01-18 15:29:10.095 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.545 | Max budget: $10.000 | Current cost: $0.037, prompt_tokens: 2735, completion_tokens: 321\r\n2024-01-18 15:29:21.722 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.572 | Max budget: $10.000 | Current cost: $0.027, prompt_tokens: 2290, completion_tokens: 122\r\n2024-01-18 15:29:21.722 | INFO     | metagpt.roles.researcher:_act:56 - David(Researcher): to do ConductResearch(David)\r\n2024-01-18 15:29:23.129 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.590 | Max budget: $10.000 | Current cost: $0.019, prompt_tokens: 1874, completion_tokens: 0\r\n",
      "state": "closed",
      "author": "zbwxp",
      "author_type": "User",
      "created_at": "2024-01-18T15:37:41Z",
      "updated_at": "2025-02-25T00:31:38Z",
      "closed_at": "2025-02-25T00:31:37Z",
      "labels": [
        "bug",
        "inactive"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/774/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "shenchucheng"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/774",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/774",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:19.379633",
      "comments": [
        {
          "author": "voidking",
          "body": "If you installed metagpt by `pip install metagpt`, there should be no examples/research.py\r\nWhat commands did you execute? And what is the order of these commands?",
          "created_at": "2024-01-19T05:40:09Z"
        },
        {
          "author": "zbwxp",
          "body": "> If you installed metagpt by `pip install metagpt`, there should be no examples/research.py What commands did you execute? And what is the order of these commands?\r\n\r\n\r\n```python\r\nimport asyncio\r\nfrom metagpt.roles.researcher import Researcher\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    async def main(top",
          "created_at": "2024-01-19T06:18:17Z"
        },
        {
          "author": "zbwxp",
          "body": "> If you installed metagpt by `pip install metagpt`, there should be no examples/research.py What commands did you execute? And what is the order of these commands?\r\n\r\nFound the cause of the error.\r\n\r\nopenai.BadRequestError: Error code: 400 - {'error': {'message': 'max_tokens is too large: 10964. Th",
          "created_at": "2024-01-19T06:47:11Z"
        },
        {
          "author": "geekan",
          "body": "@shenchucheng could you plz take a look at this?",
          "created_at": "2024-03-21T07:14:26Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-08T00:29:29Z"
        }
      ]
    },
    {
      "issue_number": 1022,
      "title": "Generated Python code for Game of 2048 largely inconsistent",
      "body": "**Bug description**\r\nI tried to create the Game of 2048 as instructed in the Intro section and I used the OpenAI model \"gpt-4-turbo-preview\". I set up MetaGPT using conda on my macOS system, using Python 3.9. I initialized the config to use OpenAI with a valid API-KEY and the best model available (see above).\r\n\r\nUnfortunately, the generated code is not self-consistent. MetaGPT created multiple Python files and the generated code looked superficiously good. But when trying to run the main.py code, many errors were raised. Most errors are the result of code references to either Python constants, methods, or constructors of generated Python code that did not exist or were referenced with an incorrect name.\r\n\r\nThe errors are too numerous to fix. I have attached the generated Python code for further details. I renamed all Python files to use the filename extension '.txt', since an upload of Python files seems to be prohibited by Github.\r\n[main.txt](https://github.com/geekan/MetaGPT/files/14628057/main.txt)\r\n[game.txt](https://github.com/geekan/MetaGPT/files/14628058/game.txt)\r\n[ui.txt](https://github.com/geekan/MetaGPT/files/14628059/ui.txt)\r\n[logic.txt](https://github.com/geekan/MetaGPT/files/14628060/logic.txt)\r\n[constants.txt](https://github.com/geekan/MetaGPT/files/14628061/constants.txt)",
      "state": "closed",
      "author": "crjaensch",
      "author_type": "User",
      "created_at": "2024-03-17T16:19:07Z",
      "updated_at": "2025-02-25T00:31:36Z",
      "closed_at": "2025-02-25T00:31:36Z",
      "labels": [
        "todo",
        "inactive"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1022/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "geekan"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1022",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1022",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:19.622039",
      "comments": [
        {
          "author": "crjaensch",
          "body": "Let me add that I tried the --code-review as well as the -no-code-review option. Moreover, the --run-tests option does not seem to work. Here I would have expected that MetaGPT recognizes that there are errors and tries to incrementally fix the errors through revised code generation trials.",
          "created_at": "2024-03-17T20:59:45Z"
        },
        {
          "author": "iorisa",
          "body": "1. About `the generated code is not self-consistent`: LLM does not always produce good design and then write good code. I suggest you retry if it failed. \r\n\r\n2. About `--run-tests option does not work`: The value of `--n-round` is  too small. `--n-round` is a safety valve that will terminate the inf",
          "created_at": "2024-03-19T05:53:14Z"
        },
        {
          "author": "crjaensch",
          "body": "Thanks for the specific suggestions on how to get better results with MetaGPT. I will certainly try the suggestions.",
          "created_at": "2024-03-20T07:34:15Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-07T00:30:32Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-25T00:31:36Z"
        }
      ]
    },
    {
      "issue_number": 1050,
      "title": "Running \"researcher\" example fails when using gemini-pro model. ",
      "body": "**Bug description**\r\nRunning \"researcher\" example fails when using gemini-pro model. It appears that the first step where David(Researcher) is passing the user query to CollectLinks(David) is not passing correct data. I'm not sure how to provide additional move verbose logging but will be happy to if someone would let me know.\r\n\r\n**Environment information**\r\nSystem version - Windows 11\r\nPython version - Python 3.10.9\r\nLLM type and model - Gemini\r\n\r\nInstallation method: \"development mode\"\r\ngit clone https://github.com/geekan/MetaGPT.git\r\n\r\nconfig2.example.yaml:\r\nllm:\r\napi_type: 'gemini'\r\napi_key: 'XXXXXXXXXXXXXXXXXXXXXXXXXXX'\r\nmodel: 'gemini-pro'\r\n\r\nsearch:\r\napi_type: \"google\"\r\napi_key: \"XXXXXXXXXXXXXXXXXXXXXXXXXXX\"\r\ncse_id: \"XXXXXXXXXXXXXX\"\r\n\r\n(metagpt) PS C:\\Users\\user\\code\\MetaGPT>  python -m metagpt.roles.researcher \"meat vs icecream\"\r\n2024-03-19 13:08:32.406 | INFO     | metagpt.const:get_metagpt_package_root:29 - Package root set to C:\\Users\\user\\code\\MetaGPT\r\n2024-03-19 13:08:37.393 | INFO     | __main__:_act:56 - David(Researcher): to do CollectLinks(David)\r\n[\"Computer Vision\", \"Object Detection\"]\r\n2024-03-19 13:08:38.442 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.000 | Max budget: $10.000 | Current cost: $0.000, prompt_tokens: 37, completion_tokens: 9\r\nWarning: model not found. Using cl100k_base encoding.\r\nWarning: model not found. Using cl100k_base encoding.\r\n[\"What are the applications of computer vision in the healthcare industry?\", \"How can object detection be used to improve safety in autonomous vehicles?\", \"What are the challenges and limitations of computer vision in real-world applications?\", \"How is computer vision being used to advance scientific research?\"]\r\n2024-03-19 13:08:42.291 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.000 | Max budget: $10.000 | Current cost: $0.000, prompt_tokens: 1251, completion_tokens: 57\r\n[ ...snip...]\r\n\r\n\r\nPS C:\\Users\\user\\code\\MetaGPT\\logs> less .\\20240319.txt\r\n2024-03-19 13:08:37.393 | DEBUG    | metagpt.roles.role:_observe:431 - David(Researcher) observed: ['user: meat vs icecream...']\r\n2024-03-19 13:08:37.393 | DEBUG    | metagpt.roles.role:_set_state:325 - actions=[CollectLinks, WebBrowseAndSummarize, ConductResearch], state=0\r\n2024-03-19 13:08:37.393 | INFO     | __main__:_act:56 - David(Researcher): to do CollectLinks(David)\r\n2024-03-19 13:08:37.393 | DEBUG    | metagpt.provider.base_llm:aask:126 - [{'role': 'user', 'parts': ['Please provide up to 2 necessary keywords related to\r\n your research topic for Google search. Your response must be in JSON format, for example: [\"keyword1\", \"keyword2\"].']}]\r\n2024-03-19 13:08:38.442 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.000 | Max budget: $10.000 | Current cost: $0.000, p\r\nrompt_tokens: 37, completion_tokens: 9\r\n2024-03-19 13:08:40.106 | DEBUG    | metagpt.actions.research:run:138 - ### Requirements\r\n1. The keywords related to your research topic and the search results are shown in the \"Search Result Information\" section.\r\n2. Provide up to 4 queries related to your research topic base on the search results.\r\n3. Please respond in the following JSON format: [\"query1\", \"query2\", \"query3\", ...].\r\n\r\n### Search Result Information\r\n#### Keyword: Computer Vision\r\n Search Result: [{'title': 'Computer vision - Wikipedia', 'link': 'https://en.wikipedia.org/wiki/Computer_vision', 'snippet': 'Computer vision covers the core technology of automated image analysis which is used in many fields. Machine vision usually refers to a process of combining\\xa0...'}, {'title': 'What is Computer Vision? | IBM', 'link': 'https://www.ibm.com/topics/computer-vision', 'snippet': 'Computer vision is a field of artificial intelligence (AI) enabling computers to derive information from images, videos and other inputs.'}, {'title': 'What Is Computer Vision? | Microsoft Azure', 'link': 'https://azure.microsoft.com/en-us/resources/cloud-computing-dictionary/what-is-computer-vision', 'snippet': 'Computer vision. Computer vision is a field of computer science that focuses on enabling computers to identify and understand objects and people in images and\\xa0...'}, {'title': 'Computer Vision: What it is and why it matters | SAS', 'link': 'https://www.sas.com/en_us/insights/analytics/computer-vision.html', 'snippet': 'Computer vision can help agencies perform\r\npredictive maintenance by analyzing equipment and infrastructure images to make better decisions on which of these\\xa0...'}, {'title': 'Azure AI Vision with OCR and AI | Microsoft Azure', 'link': 'https://azure.microsoft.com/en-us/products/ai-services/ai-vision', 'snippet': 'Accelerate computer vision development with Microsoft Azure. Unlock insights from image and video content using OCR, object detection, and image analysis.'}, {'title': 'Everything You Ever Wanted To Know About Computer Vision. | by ...', 'link': 'https://towardsdatascience.com/everything-you-ever-wanted-to-know-about-computer-vision-heres-a-look-why-it-s-so-awesome-e8a58dfb641e', 'snippet': \"Computer vision also plays an important role in facial recognition applications, the technology that enables computers to match images of people's faces to\\xa0...\"}, {'title': 'Azure AI Vision documentation - Quickstarts, Tutorials, API Reference', 'link': 'https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/', 'snippet': 'The cloud-based Azure AI Vision API provides developers with access to advanced algorithms for processing images and returning information.'}, {'title': 'What is Computer Vision? - Image recognition AI/ML Explained - AWS', 'link': 'https://aws.amazon.com/what-is/computer-vision/', 'snippet': 'Computer vision applications use artificial intelligence and machine learning (AI/ML) to process this data accurately for object identification and facial\\xa0...'}]\r\n\r\n#### Keyword: Object Detection\r\n Search Result: [{'title': 'Object detection - Wikipedia', 'link': 'https://en.wikipedia.org/wiki/Object_detection', 'snippet': 'Object detection ... Object detection is a computer technology related to computer vision and image processing that deals with detecting instances of semantic\\xa0...'}, {'title': 'Object Detection | Papers With Code', 'link': 'https://paperswithcode.com/task/object-detection', 'snippet': 'Object Detection is a computer vision task in which the goal is to detect and locate objects of interest in an image or video. The task involves identifying\\xa0...'}, {'title': 'What Is Object Detection? - MATLAB & Simulink', 'link': 'https://www.mathworks.com/discovery/object-detection.html', 'snippet': 'Object detection algorithms typically leverage machine learning or deep learning to produce meaningful results. When humans look at images or video, we can\\xa0...'}, {'title': 'https://github.com/tensorflow/models/tree/master/r...', 'link': 'https://github.com/tensorflow/models/tree/master/research/object_detection'}, {'title': 'What is Object Detection? The Ultimate Guide.', 'link': 'https://blog.roboflow.com/object-detection/', 'snippet': 'Aug 22, 2023 ... Object detection can be used for any problem where\r\n[...snip...]\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "state": "closed",
      "author": "vmsysadm",
      "author_type": "User",
      "created_at": "2024-03-19T19:41:59Z",
      "updated_at": "2025-02-24T00:32:24Z",
      "closed_at": "2025-02-24T00:32:23Z",
      "labels": [
        "bug",
        "inactive"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1050/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "shenchucheng"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1050",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1050",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:19.848815",
      "comments": [
        {
          "author": "iorisa",
          "body": "It seems still running, since 'save report to ...' does not present in the log.\r\n```python\r\nasync def main():\r\n    topic = \"dataiku vs. datarobot\"\r\n    role = Researcher(language=\"en-us\")\r\n    await role.run(topic)\r\n    print(f\"save report to {RESEARCH_PATH / f'{topic}.md'}.\")\r\n```",
          "created_at": "2024-03-20T12:33:02Z"
        },
        {
          "author": "vmsysadm",
          "body": "The log that's provided is truncated - in the command line I'm attempting to ask to research \"meat vs icecream\" question, but the output indicates that the research topic is [\"Computer Vision\", \"Object Detection\"] or something equally irrelevant.\r\n\r\n\r\n(metagpt) PS C:\\Users\\user\\code\\MetaGPT> python ",
          "created_at": "2024-03-20T13:09:37Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-07T00:30:30Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-24T00:32:22Z"
        }
      ]
    },
    {
      "issue_number": 1106,
      "title": "Enhancing Code Refactoring Capability for Advanced Code Generation",
      "body": "**Feature description**\r\nRefactoring code is an essential aspect of software development, aiding in improving code readability, maintainability, and performance. However, the process of identifying which methods or functions need refactoring, along with understanding their dependencies and potential impact on the overall software, can be challenging.\r\n\r\n**Your Feature**\r\nThe goal of this issue is to enhance code generation agent's ability to perform advanced code refactoring. By improving its capability to analyze code, identify refactor opportunities, and understand the implications of those changes, we can significantly improve the efficiency and effectiveness of our code generation process.\r\n\r\nWhat strategies or methodologies can we employ to further enhance code generation agent's capability to intelligently identify refactor opportunities and predict their impact on the software system?\r\n\r\n",
      "state": "closed",
      "author": "moamen270",
      "author_type": "User",
      "created_at": "2024-03-25T20:31:10Z",
      "updated_at": "2025-02-24T00:32:22Z",
      "closed_at": "2025-02-24T00:32:22Z",
      "labels": [
        "discussion",
        "inactive"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1106/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1106",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1106",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:20.107659",
      "comments": [
        {
          "author": "geekan",
          "body": "Very good demand! Do you have any specific implementation suggestions?",
          "created_at": "2024-03-26T07:32:26Z"
        },
        {
          "author": "moamen270",
          "body": "I started this issue to discuss about how to implement this thing 😄 ",
          "created_at": "2024-03-26T08:23:34Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-07T00:30:29Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-24T00:32:21Z"
        }
      ]
    },
    {
      "issue_number": 1635,
      "title": "How to add RAG into Data Interpreter",
      "body": "Hi! Thanks for your great work. I'm wondering whether you could add an example or documentation for integrating RAG into Data Interpreter. It seems that there are only examples for RAG Retrieval and Rerank, but I have no idea how to utilize this ability into the current Data Interpreter Machine learning modeling procedure. Thanks!",
      "state": "closed",
      "author": "cjl0222",
      "author_type": "User",
      "created_at": "2024-12-09T01:21:06Z",
      "updated_at": "2025-02-24T00:32:21Z",
      "closed_at": "2025-02-24T00:32:20Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1635/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1635",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1635",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:20.339024",
      "comments": [
        {
          "author": "iorisa",
          "body": "When the `Data Interpreter` object's `rc.memory` content is too large, you can use the RAG approach to retrieve this memory, which reduces the cost of a single interaction and avoids exceeding the maximum token limit of the LLM.\r\n\r\nFor example, using RAG to override the `self.get_memories()` functio",
          "created_at": "2025-01-09T03:39:30Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-09T00:32:54Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-24T00:32:20Z"
        }
      ]
    },
    {
      "issue_number": 1641,
      "title": "can we use customize tools in role or action?",
      "body": "i just now saw the docs ,finding \" role = DataInterpreter(tools=[\"calculate_factorial\"])\" by this way using customize  tools ,however, i want \r\nto use my tools in defining 'role' or 'action',how can to that\r\n",
      "state": "closed",
      "author": "cjrcjrljy",
      "author_type": "User",
      "created_at": "2024-12-16T07:16:31Z",
      "updated_at": "2025-02-23T00:33:36Z",
      "closed_at": "2025-02-23T00:33:34Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1641/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1641",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1641",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:20.603606",
      "comments": [
        {
          "author": "shenchucheng",
          "body": "Would you mind providing an example to help clarify your requirement?",
          "created_at": "2024-12-17T14:10:58Z"
        },
        {
          "author": "iorisa",
          "body": "In MetaGPT, `action` and `tool` are equivalent concepts, and `role` can be represented using either `action` or `tool`.\r\n",
          "created_at": "2025-01-09T03:28:41Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-09T00:32:52Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-23T00:33:34Z"
        }
      ]
    },
    {
      "issue_number": 1657,
      "title": "Exception in role's execution, deletion of newest role communication message throws another exception and exits application process",
      "body": "**Bug description**\r\n<!-- Clearly and directly describe the current bug -->\r\nWhile executing and preparing files, the following logs show initializing failed for one of the roles and in order to fix it, entire metagpt process crashed and exited out. Attached logs below from the project specifying stacktrace as is from console:\r\n`2025-01-07 01:28:33.166 | WARNING  | metagpt.utils.common:wrapper:649 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.\r\n2025-01-07 01:28:33.275 | ERROR    | metagpt.utils.common:wrapper:631 - Exception occurs, start to serialize the project, exp:\r\nTraceback (most recent call last):\r\n  File \"<PATH>\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\r\n    result = await fn(*args, **kwargs)\r\n  File \"<PATH>/venv\\lib\\site-packages\\metagpt\\actions\\action_node.py\", line 432, in _aask_v1\r\n    instruct_content = output_class(**parsed_data)`\r\n\r\n**Bug solved method**\r\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\r\n\r\n**Environment information**\r\n<!-- Environment：System version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\r\n\r\n- LLM type and model name: qwen-2.5-coder 32b\r\n- System version: Windows 11\r\n- Python version: 3.9.11 (VirtualEnv)\r\n- MetaGPT version or branch: master cli\r\n\r\n<!-- Dependent packagess：the packages version cause the bug(like `pydantic 1.10.8`), installation method（like `pip install metagpt` or `pip install from source` or `run in docker`） -->\r\n\r\n- packages version: used venv to initialize and write wrapper to create crud application in Java\r\n- installation method: pip install --upgrade metagpt\r\n\r\n**Screenshots or logs**\r\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\r\n\r\n> 2025-01-07 01:28:33.162 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 343.484(s), this was the 6th time calling it. exp: 1 validation error for PM_NODE_AN\r\n\r\n>   Value error, Missing fields: {'Required Python packages'} [type=value_error, input_value={'Required Java packages'...or terminal operators.'}, input_type=dict]\r\n>     For further information visit https://errors.pydantic.dev/2.6/v/value_error\r\n> 2025-01-07 01:28:33.166 | WARNING  | metagpt.utils.common:wrapper:649 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.\r\n> 2025-01-07 01:28:33.275 | ERROR    | metagpt.utils.common:wrapper:631 - Exception occurs, start to serialize the project, exp:\r\n> Traceback (most recent call last):\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\r\n>     result = await fn(*args, **kwargs)\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\actions\\action_node.py\", line 432, in _aask_v1\r\n>     instruct_content = output_class(**parsed_data)\r\n> pydantic_core._pydantic_core.ValidationError: 1 validation error for PM_NODE_AN\r\n>   Value error, Missing fields: {'Required Python packages'} [type=value_error, input_value={'Required Java packages'...or terminal operators.'}, input_type=dict]\r\n\r\n   \r\n\r\n>  For further information visit https://errors.pydantic.dev/2.6/v/value_error\r\n> \r\n> The above exception was the direct cause of the following exception:\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\utils\\common.py\", line 640, in wrapper\r\n>     return await func(self, *args, **kwargs)\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\roles\\role.py\", line 550, in run\r\n>     rsp = await self.react()\r\n> tenacity.RetryError: RetryError[<Future at 0x224aceb39d0 state=finished raised ValidationError>]\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\utils\\common.py\", line 626, in wrapper\r\n>     result = await func(self, *args, **kwargs)\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\team.py\", line 134, in run\r\n>     await self.env.run()\r\n> Exception: Traceback (most recent call last):\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\r\n>     result = await fn(*args, **kwargs)\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\actions\\action_node.py\", line 432, in _aask_v1\r\n>     instruct_content = output_class(**parsed_data)\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\pydantic\\main.py\", line 171, in __init__\r\n>     self.__pydantic_validator__.validate_python(data, self_instance=self)\r\n> pydantic_core._pydantic_core.ValidationError: 1 validation error for PM_NODE_AN\r\n>   Value error, Missing fields: {'Required Python packages'} [type=value_error, input_value={'Required Java packages'...or terminal operators.'}, input_type=dict]\r\n>     For further information visit https://errors.pydantic.dev/2.6/v/value_error\r\n\r\n> The above exception was the direct cause of the following exception:\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\utils\\common.py\", line 640, in wrapper\r\n>     return await func(self, *args, **kwargs)\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\roles\\role.py\", line 550, in run\r\n>     rsp = await self.react()\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\roles\\role.py\", line 517, in react\r\n>     rsp = await self._react()\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\roles\\role.py\", line 463, in _react\r\n>     rsp = await self._act()\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\roles\\role.py\", line 392, in _act\r\n>     response = await self.rc.todo.run(self.rc.history)\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\actions\\project_management.py\", line 43, in run\r\n>     task_doc = await self._update_tasks(filename=filename)\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\actions\\project_management.py\", line 66, in _update_tasks\r\n>     rsp = await self._run_new_tasks(context=system_design_doc.content)\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\actions\\project_management.py\", line 76, in _run_new_tasks\r\n>     node = await PM_NODE.fill(context, self.llm, schema=self.prompt_schema)\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\actions\\action_node.py\", line 505, in fill\r\n>     return await self.simple_fill(schema=schema, mode=mode, images=images, timeout=timeout, exclude=exclude)\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\actions\\action_node.py\", line 457, in simple_fill\r\n>     content, scontent = await self._aask_v1(\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\r\n>     return await fn(*args, **kwargs)\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\r\n>     do = self.iter(retry_state=retry_state)\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\tenacity\\__init__.py\", line 326, in iter\r\n>     raise retry_exc from fut.exception()\r\n> tenacity.RetryError: RetryError[<Future at 0x224aceb39d0 state=finished raised ValidationError>]\r\n",
      "state": "closed",
      "author": "katemamba",
      "author_type": "User",
      "created_at": "2025-01-06T20:15:39Z",
      "updated_at": "2025-02-23T00:33:34Z",
      "closed_at": "2025-02-23T00:33:33Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1657/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1657",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1657",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:20.803172",
      "comments": [
        {
          "author": "iorisa",
          "body": "> 2025-01-07 01:28:33.162 | ERROR | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 343.484(s), this was the 6th time calling it. exp: 1 validation error for PM_NODE_AN\r\n> \r\n> Value error, Missing fields: {'Required Python packages'} [type=v",
          "created_at": "2025-01-09T02:03:19Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-09T00:32:51Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-23T00:33:33Z"
        }
      ]
    },
    {
      "issue_number": 1149,
      "title": "Build Action for DB operation such as connection and analysis",
      "body": "**Feature description**\r\n<!-- Clear and direct description of the functionality of the currently submitted or proposed feature -->\r\n\r\nSuggest to build a Action (and Role) for DB operation such as DB connection and make data visualization from DB basic on LLM.\r\n\r\nThe Aciton/Role can be:\r\n1. connect to DB with user conf.\r\n2. data analysis and visualization (such as LLM-based BI).\r\n\r\n**Your Feature**\r\n<!-- Describe the idea or process of implementing the current feature. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- When submitting features, you need to complete the corresponding doc/tests/examples to facilitate verification by reviewers. -->\r\n\r\n",
      "state": "closed",
      "author": "jinchihe",
      "author_type": "User",
      "created_at": "2024-04-01T12:46:16Z",
      "updated_at": "2025-02-22T00:29:47Z",
      "closed_at": "2025-02-22T00:29:46Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1149/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "iorisa"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1149",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1149",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:20.995837",
      "comments": [
        {
          "author": "geekan",
          "body": "Outstanding concept! Can you write more about this idea?",
          "created_at": "2024-04-02T02:47:08Z"
        },
        {
          "author": "krish240574",
          "body": "1. Connect to a dB with creds., or to a BI system. \r\n2. Get data based on query\r\n3. Plot, train models based on data\r\n\r\nThis could simply become a tool, that returns data to the DI, which is then consumed by the DI for analysis   ",
          "created_at": "2024-04-09T08:26:30Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-06T00:30:39Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-22T00:29:46Z"
        }
      ]
    },
    {
      "issue_number": 1160,
      "title": "save_role for the data interpreter would be great if it saved individual files instead of a jupyter notebook",
      "body": "**Feature description**\r\nBasically the title. If you add save_role to any of the di files it saves the plan and then it saves the code as a jupyter notebook. would be incredibly usefull after everything has been completed successfully for it to save the final working copies of the files it has created into individual/single script. Because the current jupyter notebook includes everything - the broken code, the outputs, the new code with fixes, so its not very useful. \r\n\r\nmuch love to this project",
      "state": "closed",
      "author": "cranyy",
      "author_type": "User",
      "created_at": "2024-04-05T01:17:51Z",
      "updated_at": "2025-02-20T00:31:06Z",
      "closed_at": "2025-02-20T00:31:05Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1160/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1160",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1160",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:21.186138",
      "comments": [
        {
          "author": "geekan",
          "body": "I think this feature will be very useful indeed @garylin2099",
          "created_at": "2024-04-05T14:10:59Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-06T00:30:38Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-20T00:31:05Z"
        }
      ]
    },
    {
      "issue_number": 1167,
      "title": "Datainterpreter Message history, available for usage like chat?",
      "body": "**Feature description**\r\n<!-- Clear and direct description of the functionality of the currently submitted or proposed feature -->\r\nIs the message history for DI available , like a chat feature? I need to use it in a web app, so the user is updated frequently. \r\nThe history is dumped to data/<timestamp>/plan.json, I see that, but that happens only after the run completes.\r\nAre running messages available? \r\n\r\nI see inside metagpt/roles/role.py, the following :\r\ndef get_memories(self, k=0) -> list[Message]:\r\n        \"\"\"A wrapper to return the most recent k memories of this role, return all when k=0\"\"\"\r\n        return self.rc.memory.get(k=k)\r\nand a variable called working_memory\r\n\r\nCan they be useful somehow?\r\n        \r\n\r\n**Your Feature**\r\n<!-- Describe the idea or process of implementing the current feature. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- When submitting features, you need to complete the corresponding doc/tests/examples to facilitate verification by reviewers. -->\r\n",
      "state": "closed",
      "author": "krish240574",
      "author_type": "User",
      "created_at": "2024-04-09T05:37:35Z",
      "updated_at": "2025-02-19T00:30:51Z",
      "closed_at": "2025-02-19T00:30:50Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1167/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1167",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1167",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:21.415623",
      "comments": [
        {
          "author": "geekan",
          "body": "There are some codes that have not yet been merged, perhaps u'll need to wait for serveral weeks.",
          "created_at": "2024-05-18T11:06:00Z"
        },
        {
          "author": "krish240574",
          "body": "Any updates on this, please ? I'd love to be able to echo messages to the user, as the DI executes. For now, the user has to wait till all execution completes, then I can retrieve the dumped history from save_history and send to user. It would be great if I could access regular updates. \r\n",
          "created_at": "2024-11-09T17:22:20Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-04T00:29:56Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-19T00:30:50Z"
        }
      ]
    },
    {
      "issue_number": 1170,
      "title": "When will it be made a plugin for VSCode and IDEA",
      "body": "**Feature description**\r\nI hope it could be used as a plugin with VSCode or IDEA, and could work with an exist software project. Because this is the real daily job actually.\r\n\r\n**Your Feature**\r\n<!-- Describe the idea or process of implementing the current feature. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- When submitting features, you need to complete the corresponding doc/tests/examples to facilitate verification by reviewers. -->\r\n",
      "state": "closed",
      "author": "azlanxun",
      "author_type": "User",
      "created_at": "2024-04-09T09:31:58Z",
      "updated_at": "2025-02-19T00:30:50Z",
      "closed_at": "2025-02-19T00:30:49Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1170/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1170",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1170",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:21.603361",
      "comments": [
        {
          "author": "seehi",
          "body": "Can you provide a corresponding scenario combined with your current use of metagpt?",
          "created_at": "2024-04-11T07:25:31Z"
        },
        {
          "author": "azlanxun",
          "body": "As a software engineer in company, there is few opportunities to start a project from scratch, most job is programming on an existing project, which was started some years ago. \r\nFor example, there is an project about 100K lines, and I make some new modules on it daily.\r\nAnd usually we write a new f",
          "created_at": "2024-04-29T07:01:35Z"
        },
        {
          "author": "geekan",
          "body": "Sorry, we are currently at a high intensity of work, so the response is very slow. We are solving the scenario you mentioned, please wait for a while.",
          "created_at": "2024-05-18T11:04:30Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-04T00:29:55Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-19T00:30:48Z"
        }
      ]
    },
    {
      "issue_number": 1650,
      "title": "can not use qwen-vl-max",
      "body": "**Bug description**\r\n<!-- Clearly and directly describe the current bug -->\r\ncan not use the qwen-vl-max API\r\n**Bug solved method**\r\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\r\n\r\n**Environment information**\r\n<!-- Environment：System version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\r\n\r\n- LLM type and model name: dashscope, qwen-vl-max-latest\r\n- System version: ubuntu22.04\r\n- Python version: 3.10\r\n- MetaGPT version or branch: 0.8.1\r\n\r\n<!-- Dependent packagess：the packages version cause the bug(like `pydantic 1.10.8`), installation method（like `pip install metagpt` or `pip install from source` or `run in docker`） -->\r\n\r\n- packages version:\r\n- installation method: pip\r\n\r\n**Screenshots or logs**\r\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\r\nException: Traceback (most recent call last):\r\n  File \"/cpfs01/user/conda/envs/agent/lib/python3.10/site-packages/metagpt/utils/common.py\", line 640, in wrapper\r\n    return await func(self, *args, **kwargs)\r\n  File \"/cpfs01/user/conda/envs/agent/lib/python3.10/site-packages/metagpt/roles/role.py\", line 550, in run\r\n    rsp = await self.react()\r\n  File \"/cpfs01/user/conda/envs/agent/lib/python3.10/site-packages/metagpt/roles/role.py\", line 519, in react\r\n    rsp = await self._act_by_order()\r\n  File \"/cpfs01/user/conda/envs/agent/lib/python3.10/site-packages/metagpt/roles/role.py\", line 473, in _act_by_order\r\n    rsp = await self._act()\r\n  File \"/nas/shared/landmark_3dgen/yangyuhang/Agent/test.py\", line 147, in _act\r\n    result = await todo.run(msg.content)\r\n  File \"/nas/shared/landmark_3dgen/yangyuhang/Agent/test.py\", line 36, in run\r\n    rsp = await self._aask(prompt)\r\n  File \"/cpfs01/user/conda/envs/agent/lib/python3.10/site-packages/metagpt/actions/action.py\", line 93, in _aask\r\n    return await self.llm.aask(prompt, system_msgs)\r\n  File \"/cpfs01/user/conda/envs/agent/lib/python3.10/site-packages/metagpt/provider/base_llm.py\", line 150, in aask\r\n    rsp = await self.acompletion_text(message, stream=stream, timeout=self.get_timeout(timeout))\r\n  File \"/cpfs01/user/conda/envs/agent/lib/python3.10/site-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\r\n    return await fn(*args, **kwargs)\r\n  File \"/cpfs01/user/conda/envs/agent/lib/python3.10/site-packages/tenacity/_asyncio.py\", line 47, in __call__\r\n    do = self.iter(retry_state=retry_state)\r\n  File \"/cpfs01/user/conda/envs/agent/lib/python3.10/site-packages/tenacity/__init__.py\", line 314, in iter\r\n    return fut.result()\r\n  File \"/cpfs01/user/conda/envs/agent/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\r\n    return self.__get_result()\r\n  File \"/cpfs01/user/conda/envs/agent/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\r\n    raise self._exception\r\n  File \"/cpfs01/user/conda/envs/agent/lib/python3.10/site-packages/tenacity/_asyncio.py\", line 50, in __call__\r\n    result = await fn(*args, **kwargs)\r\n  File \"/cpfs01/user/conda/envs/agent/lib/python3.10/site-packages/metagpt/provider/base_llm.py\", line 200, in acompletion_text\r\n    return await self._achat_completion_stream(messages, timeout=self.get_timeout(timeout))\r\n  File \"/cpfs01/user/conda/envs/agent/lib/python3.10/site-packages/metagpt/provider/dashscope_api.py\", line 220, in _achat_completion_stream\r\n    self._check_response(chunk)\r\n  File \"/cpfs01/user/conda/envs/agent/lib/python3.10/site-packages/metagpt/provider/dashscope_api.py\", line 194, in _check_response\r\n    raise RuntimeError(f\"code: {resp.code}, request_id: {resp.request_id}, message: {resp.message}\")\r\nRuntimeError: code: InvalidParameter, request_id: bd2b84b8-7989-93d3-b942-5f1af2ff129a, message: url error, please check url！",
      "state": "closed",
      "author": "yyvhang",
      "author_type": "User",
      "created_at": "2024-12-27T13:35:27Z",
      "updated_at": "2025-02-17T00:32:39Z",
      "closed_at": "2025-02-17T00:32:38Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1650/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1650",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1650",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:21.820211",
      "comments": [
        {
          "author": "iorisa",
          "body": "Ok, I'll follow up on this issue.",
          "created_at": "2025-01-02T14:28:47Z"
        },
        {
          "author": "iorisa",
          "body": "The follow `config/config2.yaml` configuration is working:\r\n```yaml\r\nllm:\r\n  api_type: \"openai\"\r\n  model: \"qwen-vl-max\"\r\n  base_url: \"https://dashscope.aliyuncs.com/compatible-mode/v1\"\r\n  api_key: \"sk-3b9e***\"\r\n  max_token: 1500\r\n  temperature: 0.5\r\n```",
          "created_at": "2025-01-03T11:36:19Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-03T00:31:01Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-17T00:32:38Z"
        }
      ]
    },
    {
      "issue_number": 1636,
      "title": "Fail to run demo: module 'proto' has no attribute 'module'",
      "body": "**Bug description**\r\nFirst, thank you for making this fantastic project! I'm not able to run the demo after installation.\r\n\r\nI tried several means to install metagpt but all of them raised the \"module 'proto' has no attribute 'module'\" error. Is that because I'm using Debian?\r\n\r\n\r\n$ metagpt \"write a cli blackjack game\"\r\n2024-12-10 18:01:10.074 | INFO     | metagpt.const:get_metagpt_package_root:21 - Package root set to /opt/tiger/MetaGPT\r\n╭─────────────────────────────── Traceback (most recent call last) ────────────────────────────────╮\r\n│ /opt/tiger/MetaGPT/metagpt/software_company.py:117 in startup                                    │\r\n│                                                                                                  │\r\n│   114 │   │   typer.echo(\"Missing argument 'IDEA'. Run 'metagpt --help' for more information.\"   │\r\n│   115 │   │   raise typer.Exit()                                                                 │\r\n│   116 │                                                                                          │\r\n│ ❱ 117 │   return generate_repo(                                                                  │\r\n│   118 │   │   idea,                                                                              │\r\n│   119 │   │   investment,                                                                        │\r\n│   120 │   │   n_round,                                                                           │\r\n│                                                                                                  │\r\n│ /opt/tiger/MetaGPT/metagpt/software_company.py:32 in generate_repo                               │\r\n│                                                                                                  │\r\n│    29 ) -> ProjectRepo:                                                                          │\r\n│    30 │   \"\"\"Run the startup logic. Can be called from CLI or other Python scripts.\"\"\"           │\r\n│    31 │   from metagpt.config2 import config                                                     │\r\n│ ❱  32 │   from metagpt.context import Context                                                    │\r\n│    33 │   from metagpt.roles import (                                                            │\r\n│    34 │   │   Architect,                                                                         │\r\n│    35 │   │   Engineer,                                                                          │\r\n│                                                                                                  │\r\n│ /opt/tiger/MetaGPT/metagpt/context.py:16 in <module>                                             │\r\n│                                                                                                  │\r\n│    13                                                                                            │\r\n│    14 from metagpt.config2 import Config                                                         │\r\n│    15 from metagpt.configs.llm_config import LLMConfig, LLMType                                  │\r\n│ ❱  16 from metagpt.provider.base_llm import BaseLLM                                              │\r\n│    17 from metagpt.provider.llm_provider_registry import create_llm_instance                     │\r\n│    18 from metagpt.utils.cost_manager import (                                                   │\r\n│    19 │   CostManager,                                                                           │\r\n│                                                                                                  │\r\n│ /opt/tiger/MetaGPT/metagpt/provider/__init__.py:9 in <module>                                    │\r\n│                                                                                                  │\r\n│    6 @File    : __init__.py                                                                      │\r\n│    7 \"\"\"                                                                                         │\r\n│    8                                                                                             │\r\n│ ❱  9 from metagpt.provider.google_gemini_api import GeminiLLM                                    │\r\n│   10 from metagpt.provider.ollama_api import OllamaLLM                                           │\r\n│   11 from metagpt.provider.openai_api import OpenAILLM                                           │\r\n│   12 from metagpt.provider.zhipuai_api import ZhiPuAILLM                                         │\r\n│                                                                                                  │\r\n│ /opt/tiger/MetaGPT/metagpt/provider/google_gemini_api.py:9 in <module>                           │\r\n│                                                                                                  │\r\n│     6 from dataclasses import asdict                                                             │\r\n│     7 from typing import List, Optional, Union                                                   │\r\n│     8                                                                                            │\r\n│ ❱   9 import google.generativeai as genai                                                        │\r\n│    10 from google.ai import generativelanguage as glm                                            │\r\n│    11 from google.generativeai.generative_models import GenerativeModel                          │\r\n│    12 from google.generativeai.types import content_types                                        │\r\n│                                                                                                  │\r\n│ /mnt/bn/gilesluo000/miniconda3/envs/metagpt/lib/python3.9/site-packages/google/generativeai/__in │\r\n│ it__.py:45 in <module>                                                                           │\r\n│                                                                                                  │\r\n│   42                                                                                             │\r\n│   43 from google.generativeai import version                                                     │\r\n│   44                                                                                             │\r\n│ ❱ 45 from google.generativeai import types                                                       │\r\n│   46 from google.generativeai.types import GenerationConfig                                      │\r\n│   47                                                                                             │\r\n│   48                                                                                             │\r\n│                                                                                                  │\r\n│ /mnt/bn/gilesluo000/miniconda3/envs/metagpt/lib/python3.9/site-packages/google/generativeai/type │\r\n│ s/__init__.py:17 in <module>                                                                     │\r\n│                                                                                                  │\r\n│   14 # limitations under the License.                                                            │\r\n│   15 \"\"\"A collection of type definitions used throughout the library.\"\"\"                         │\r\n│   16                                                                                             │\r\n│ ❱ 17 from google.generativeai.types.discuss_types import *                                       │\r\n│   18 from google.generativeai.types.model_types import *                                         │\r\n│   19 from google.generativeai.types.text_types import *                                          │\r\n│   20 from google.generativeai.types.citation_types import *                                      │\r\n│                                                                                                  │\r\n│ /mnt/bn/gilesluo000/miniconda3/envs/metagpt/lib/python3.9/site-packages/google/generativeai/type │\r\n│ s/discuss_types.py:22 in <module>                                                                │\r\n│                                                                                                  │\r\n│    19 from typing import Any, Dict, Union, Iterable, Optional, Tuple, List                       │\r\n│    20 from typing_extensions import TypedDict                                                    │\r\n│    21                                                                                            │\r\n│ ❱  22 import google.ai.generativelanguage as glm                                                 │\r\n│    23 from google.generativeai import string_utils                                               │\r\n│    24                                                                                            │\r\n│    25 from google.generativeai.types import safety_types                                         │\r\n│                                                                                                  │\r\n│ /mnt/bn/gilesluo000/miniconda3/envs/metagpt/lib/python3.9/site-packages/google/ai/generativelang │\r\n│ uage/__init__.py:21 in <module>                                                                  │\r\n│                                                                                                  │\r\n│    18 __version__ = package_version.__version__                                                  │\r\n│    19                                                                                            │\r\n│    20                                                                                            │\r\n│ ❱  21 from google.ai.generativelanguage_v1beta.services.discuss_service.async_client import (    │\r\n│    22 │   DiscussServiceAsyncClient,                                                             │\r\n│    23 )                                                                                          │\r\n│    24 from google.ai.generativelanguage_v1beta.services.discuss_service.client import (          │\r\n│                                                                                                  │\r\n│ /mnt/bn/gilesluo000/miniconda3/envs/metagpt/lib/python3.9/site-packages/google/ai/generativelang │\r\n│ uage_v1beta/__init__.py:21 in <module>                                                           │\r\n│                                                                                                  │\r\n│    18 __version__ = package_version.__version__                                                  │\r\n│    19                                                                                            │\r\n│    20                                                                                            │\r\n│ ❱  21 from .services.discuss_service import DiscussServiceAsyncClient, DiscussServiceClient      │\r\n│    22 from .services.generative_service import (                                                 │\r\n│    23 │   GenerativeServiceAsyncClient,                                                          │\r\n│    24 │   GenerativeServiceClient,                                                               │\r\n│                                                                                                  │\r\n│ /mnt/bn/gilesluo000/miniconda3/envs/metagpt/lib/python3.9/site-packages/google/ai/generativelang │\r\n│ uage_v1beta/services/discuss_service/__init__.py:16 in <module>                                  │\r\n│                                                                                                  │\r\n│   13 # See the License for the specific language governing permissions and                       │\r\n│   14 # limitations under the License.                                                            │\r\n│   15 #                                                                                           │\r\n│ ❱ 16 from .async_client import DiscussServiceAsyncClient                                         │\r\n│   17 from .client import DiscussServiceClient                                                    │\r\n│   18                                                                                             │\r\n│   19 __all__ = (                                                                                 │\r\n│                                                                                                  │\r\n│ /mnt/bn/gilesluo000/miniconda3/envs/metagpt/lib/python3.9/site-packages/google/ai/generativelang │\r\n│ uage_v1beta/services/discuss_service/async_client.py:47 in <module>                              │\r\n│                                                                                                  │\r\n│    44                                                                                            │\r\n│    45 from google.longrunning import operations_pb2  # type: ignore                              │\r\n│    46                                                                                            │\r\n│ ❱  47 from google.ai.generativelanguage_v1beta.types import discuss_service, safety              │\r\n│    48                                                                                            │\r\n│    49 from .client import DiscussServiceClient                                                   │\r\n│    50 from .transports.base import DEFAULT_CLIENT_INFO, DiscussServiceTransport                  │\r\n│                                                                                                  │\r\n│ /mnt/bn/gilesluo000/miniconda3/envs/metagpt/lib/python3.9/site-packages/google/ai/generativelang │\r\n│ uage_v1beta/types/__init__.py:16 in <module>                                                     │\r\n│                                                                                                  │\r\n│    13 # See the License for the specific language governing permissions and                      │\r\n│    14 # limitations under the License.                                                           │\r\n│    15 #                                                                                          │\r\n│ ❱  16 from .citation import CitationMetadata, CitationSource                                     │\r\n│    17 from .content import (                                                                     │\r\n│    18 │   Blob,                                                                                  │\r\n│    19 │   Content,                                                                               │\r\n│                                                                                                  │\r\n│ /mnt/bn/gilesluo000/miniconda3/envs/metagpt/lib/python3.9/site-packages/google/ai/generativelang │\r\n│ uage_v1beta/types/citation.py:22 in <module>                                                     │\r\n│                                                                                                  │\r\n│    19                                                                                            │\r\n│    20 import proto  # type: ignore                                                               │\r\n│    21                                                                                            │\r\n│ ❱  22 __protobuf__ = proto.module(                                                               │\r\n│    23 │   package=\"google.ai.generativelanguage.v1beta\",                                         │\r\n│    24 │   manifest={                                                                             │\r\n│    25 │   │   \"CitationMetadata\",                                                                │\r\n╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\r\nAttributeError: module 'proto' has no attribute 'module'\r\n\r\n\r\n**Environment information**\r\n\r\n\r\n- LLM type and model name:\r\n- System version:Debian GNU/Linux 12 (bookworm)\r\n- Python version:3.9.30\r\n- MetaGPT version or branch: v0.8.1\r\n",
      "state": "closed",
      "author": "GilesLuo",
      "author_type": "User",
      "created_at": "2024-12-10T10:19:19Z",
      "updated_at": "2025-02-16T00:33:45Z",
      "closed_at": "2025-02-16T00:33:45Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1636/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1636",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1636",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:22.007751",
      "comments": [
        {
          "author": "shenchucheng",
          "body": "Which version of protobuf is being used?",
          "created_at": "2024-12-11T07:36:17Z"
        },
        {
          "author": "iorisa",
          "body": "Which version of `google-generativeai` is being used?\r\nI'm using 0.4.1\r\n```bash\r\npip show google-generativeai\r\nName: google-generativeai\r\nVersion: 0.4.1\r\nSummary: Google Generative AI High level API client library and tools.\r\nHome-page: https://github.com/google/generative-ai-python\r\nAuthor: Google ",
          "created_at": "2025-01-02T14:40:34Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-02T00:32:17Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-16T00:33:45Z"
        }
      ]
    },
    {
      "issue_number": 1177,
      "title": "Data Interpreter - Large JSON/tabular data being returned by a tool, should not be included in subsequent code prompts. ",
      "body": "**Bug description**\r\n<!-- Clearly and directly describe the current bug -->\r\nI have a tool, that returns a large JSON/tabular data. I find that the DI takes all this data(50,000) chars and tries to add it to the prompt for subsequent analysis. (This is too expensive and slow)\r\nI could return a file name from the tool, where I dumped the JSON into, but this doesn't *ALWAYS* work, sometimes the DI tries to write all the data into the prompt, or worse still, truncates it. \r\n\r\nWhat is a more efficient way to do this? \r\n\r\n**Bug solved method**\r\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\r\n\r\n**Environment information**\r\n<!-- Environment：System version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\r\nOpenAI gpt-4-1106-preview\r\nPython 3.10\r\nUbuntu 22.04\r\n\r\n- LLM type and model name:\r\n- System version:\r\n- Python version:\r\n- MetaGPT version or branch:\r\n\r\n<!-- Dependent packagess：the packages version cause the bug(like `pydantic 1.10.8`), installation method（like `pip install metagpt` or `pip install from source` or `run in docker`） -->\r\n\r\n- packages version:\r\n- installation method: \r\n\r\n**Screenshots or logs**\r\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\r\n",
      "state": "closed",
      "author": "krish240574",
      "author_type": "User",
      "created_at": "2024-04-10T14:50:34Z",
      "updated_at": "2025-02-11T00:30:36Z",
      "closed_at": "2025-02-11T00:30:34Z",
      "labels": [
        "bug",
        "inactive"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1177/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1177",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1177",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:22.226318",
      "comments": [
        {
          "author": "seehi",
          "body": "@garylin2099 could you take a look at this?",
          "created_at": "2024-04-11T12:01:45Z"
        },
        {
          "author": "garylin2099",
          "body": "Let me clarify the question, so DI is expected to generate a string for your downstream tasks, and you want the string to contain the file name instead of the file content, which is very long, is my understanding correct?",
          "created_at": "2024-04-11T14:03:51Z"
        },
        {
          "author": "krish240574",
          "body": "umm, let me explain:\r\nTools could return various kinds of outputs, correct?\r\nIn my case, my tool returns the rows of a table, as JSON(This could be huge). What happens, is that after the tool execution has completed, DI picks up the output from the logs/working memory and adds it all to the prompt, ",
          "created_at": "2024-04-12T01:46:30Z"
        },
        {
          "author": "krish240574",
          "body": "These lines might hold a clue, to the issue:\r\n[https://github.com/geekan/MetaGPT/blob/aa715fcace7577ec711ba675c51d0c22cfab84b3/metagpt/roles/di/data_interpreter.py#L186](url)\r\n ",
          "created_at": "2024-04-12T02:07:46Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-28T00:30:08Z"
        }
      ]
    },
    {
      "issue_number": 1179,
      "title": "Support for converting existing software projects",
      "body": "It would be great if there was strong support for roles that enable MetaGPT to take an existing project written in one language and convert it to another or convert from one platform to another.",
      "state": "closed",
      "author": "pathquester",
      "author_type": "User",
      "created_at": "2024-04-11T06:37:37Z",
      "updated_at": "2025-02-08T00:29:27Z",
      "closed_at": "2025-02-08T00:29:27Z",
      "labels": [
        "enhancement",
        "inactive"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1179/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1179",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1179",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:22.471539",
      "comments": [
        {
          "author": "seehi",
          "body": "Sounds good, but the priority might not be that high.",
          "created_at": "2024-04-11T07:10:56Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-25T00:29:24Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-08T00:29:26Z"
        }
      ]
    },
    {
      "issue_number": 1189,
      "title": "Consistence check for the generated code might be a big improvement",
      "body": "I think it might be a big improvement if metagpt could add consistence check for the generated code, add fix the unconsistent code according to the result of the consistence check.\r\n",
      "state": "closed",
      "author": "longweiii",
      "author_type": "User",
      "created_at": "2024-04-12T13:29:01Z",
      "updated_at": "2025-02-08T00:29:26Z",
      "closed_at": "2025-02-08T00:29:26Z",
      "labels": [
        "enhancement",
        "inactive"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1189/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1189",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1189",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:22.678895",
      "comments": [
        {
          "author": "seehi",
          "body": "Working on optimizing that.\r\n",
          "created_at": "2024-04-12T13:36:06Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-25T00:29:22Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-08T00:29:25Z"
        }
      ]
    },
    {
      "issue_number": 1199,
      "title": "Can not able to convert mmd to other format.",
      "body": "Can anyone give insights on below error? \r\n\r\nWARNING  | metagpt.utils.mermaid:mermaid_to_file:70 -                                                                             Error: net::ERR_ACCESS_DENIED at file:///home/ubuntu/.nvm/versions/node/v18.20.2/lib/node_modules/@mermaid-js/mermaid-cli/dist/index.html                       at navigate (file:///home/ubuntu/.nvm/versions/node/v18.20.2/lib/node_modules/@mermaid-js/mermaid-cli/node_modules/puppeteer-core/lib/esm/puppeteer/common/Frame.js:215:23)                                                                                                                                             at process.processTicksAndRejections (node:internal/process/task_queues:95:5)                                                                               at async Frame.goto (file:///home/ubuntu/.nvm/versions/node/v18.20.2/lib/node_modules/@mermaid-js/mermaid-cli/node_modules/puppeteer-core/lib/esm/puppeteer/common/Frame.js:181:21)                                                                                                                                     at async CDPPage.goto (file:///home/ubuntu/.nvm/versions/node/v18.20.2/lib/node_modules/@mermaid-js/mermaid-cli/node_modules/puppeteer-core/lib/esm/puppeteer/common/Page.js:435:16)\r\n    at async renderMermaid (file:///home/ubuntu/.nvm/versions/node/v18.20.2/lib/node_modules/@mermaid-js/mermaid-cli/src/index.js:242:5)\r\n    at async parseMMD (file:///home/ubuntu/.nvm/versions/node/v18.20.2/lib/node_modules/@mermaid-js/mermaid-cli/src/index.js:218:20)\r\n    at async run (file:///home/ubuntu/.nvm/versions/node/v18.20.2/lib/node_modules/@mermaid-js/mermaid-cli/src/index.js:479:20)\r\n    at async cli (file:///home/ubuntu/.nvm/versions/node/v18.20.2/lib/node_modules/@mermaid-js/mermaid-cli/src/index.js:184:3)",
      "state": "closed",
      "author": "Unkownforlife",
      "author_type": "User",
      "created_at": "2024-04-16T06:50:56Z",
      "updated_at": "2025-02-06T00:30:37Z",
      "closed_at": "2025-02-06T00:30:37Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1199/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1199",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1199",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:22.912297",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-23T00:29:58Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-06T00:30:36Z"
        }
      ]
    },
    {
      "issue_number": 1201,
      "title": "新版狼人杀无法投票出局player",
      "body": "\r\n我尝试了最新版main分支的狼人杀，在这个新版狼人杀对局中，无法投票出局player，从而导致游戏无限在第一轮的投票阶段循环。图片为第一次投票的末尾和第二次重复循环的开始。\r\n![image](https://github.com/geekan/MetaGPT/assets/95960312/c57abc78-10ca-45c3-95ea-7f80a5f4916b)\r\n![image](https://github.com/geekan/MetaGPT/assets/95960312/c4bff83f-43cc-4120-8056-1abd42a957a8)\r\n",
      "state": "closed",
      "author": "kbkbsxwd",
      "author_type": "User",
      "created_at": "2024-04-16T07:37:18Z",
      "updated_at": "2025-02-06T00:30:36Z",
      "closed_at": "2025-02-06T00:30:36Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1201/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1201",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1201",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:23.081959",
      "comments": [
        {
          "author": "seehi",
          "body": "FYI: @garylin2099 ",
          "created_at": "2024-04-17T02:56:03Z"
        },
        {
          "author": "kbkbsxwd",
          "body": "我认为错误在这里：在这个输出中，尽管最后player1获得绝大多数投票，但主持人却将已经被狼人杀死的player2宣布淘汰。之后主持人act:242-Moderator(Moderator):Unknown instruction.  最终导致重复投票流程。",
          "created_at": "2024-04-20T08:11:27Z"
        },
        {
          "author": "better629",
          "body": "ok, you can add a PR to update the problem. And we also arranged a colleague to follow and fix this.",
          "created_at": "2024-04-20T08:57:01Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-23T00:29:57Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-06T00:30:35Z"
        }
      ]
    },
    {
      "issue_number": 1216,
      "title": "Making Data interpreter able to repair llm output, similar to what is done in ActionNode",
      "body": "**Feature description**\r\nUsing open-source models in the data interpreter often leads to issues with incapability of generating correct JSON format . I tried to add `repair_llm_output: true` in the config2.yaml but it didn't work. \r\n\r\nby checking the source code, I noticed that the repair work is conducted in ActionNode, while my issue occurs in WriteAnalysisCode:\r\n1. The model generated incorrect JSON response and passed it into the CodeParser\r\n2. The parser did not match the regex \r\n3. the logger reported an error, then directly returned the incorrectly formatted text.\r\n4. The incorrectly formatted text was passed back to the action, where it failed during decoding with` reflection = json.loads(CodeParser.parse_code(block=None, text=rsp))`\r\n\r\n**The repair mechanism was not triggered.**\r\n![20240422-180524](https://github.com/geekan/MetaGPT/assets/93753250/3fc79a77-d57f-4f59-b81e-dc46ae5907f6)\r\n\r\nTherefore, it is ideal to adapt the repair functionality for the data interpreter as well.\r\n\r\n**Your Feature**\r\nEnabling Data Interpreter to postprocess llm output\r\n",
      "state": "closed",
      "author": "usamimeri",
      "author_type": "User",
      "created_at": "2024-04-22T10:08:40Z",
      "updated_at": "2025-02-05T00:30:23Z",
      "closed_at": "2025-02-05T00:30:22Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1216/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1216",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1216",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:23.278926",
      "comments": [
        {
          "author": "seehi",
          "body": "FYI: @garylin2099 ",
          "created_at": "2024-04-23T02:32:54Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-22T00:30:20Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-05T00:30:22Z"
        }
      ]
    },
    {
      "issue_number": 1211,
      "title": "Add Data Interpreter RAG integration Example",
      "body": "please add an example of best approach in integrating the RAG module into Data Interpreter without hindering the current architecture of the agent.",
      "state": "closed",
      "author": "AliArmani3397",
      "author_type": "User",
      "created_at": "2024-04-20T11:51:29Z",
      "updated_at": "2025-02-05T00:30:23Z",
      "closed_at": "2025-02-05T00:30:23Z",
      "labels": [
        "documentation",
        "inactive"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1211/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "seehi"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1211",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1211",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:23.463634",
      "comments": [
        {
          "author": "seehi",
          "body": "Examples are under development and will be provided later.",
          "created_at": "2024-04-22T02:21:47Z"
        },
        {
          "author": "cjl0222",
          "body": "Hi! Thanks for your great work. I'm also wondering whether you could add this example for integrating RAG into Data Interpreter. It seems that there are only examples for RAG Retrieval and Rerank, but I have no idea how to utilize this ability into the current Data Interpreter Machine learning model",
          "created_at": "2024-11-29T02:20:50Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-22T00:30:21Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-05T00:30:23Z"
        }
      ]
    },
    {
      "issue_number": 1223,
      "title": "use groq llama3-70b-8192 conduct research failed",
      "body": "**Bug description**\r\nuse groq api llama3-70b-8192, run command: **python3 -m metagpt.roles.researcher \"tensorflow vs. pytorch\"**\r\nthen it just stuck here!\r\nuse gpt4 don't have problem.\r\n![image](https://github.com/geekan/MetaGPT/assets/57616924/798bcd4d-a889-4c9c-9bb0-0883333fcf0e)\r\n![image](https://github.com/geekan/MetaGPT/assets/57616924/d7c43b04-3e66-4d23-a3fb-54ad83f99c69)\r\n\r\n\r\n",
      "state": "closed",
      "author": "wzkzs",
      "author_type": "User",
      "created_at": "2024-04-24T02:16:24Z",
      "updated_at": "2025-02-05T00:30:22Z",
      "closed_at": "2025-02-05T00:30:21Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1223/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1223",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1223",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:23.641241",
      "comments": [
        {
          "author": "seehi",
          "body": "Dependent on the capabilities of LLM.\r\nFYI: @shenchucheng ",
          "created_at": "2024-04-24T02:45:15Z"
        },
        {
          "author": "wzkzs",
          "body": "> Dependent on the capabilities of LLM. FYI: @shenchucheng\r\n\r\nWhy does it get stuck without reporting an error?",
          "created_at": "2024-04-24T03:00:18Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-22T00:30:19Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-05T00:30:21Z"
        }
      ]
    },
    {
      "issue_number": 1225,
      "title": "metagpt.utils.text / generate_prompt_chunk() / Calculation for max token length is flawed because LLM model name could actually hold the DEPLOYMENT model name.",
      "body": "**Bug description**\r\n\r\nmetagpt.utils.text / generate_prompt_chunk() / Calculation for max token length is flawed because LLM model name could actually hold the DEPLOYMENT model name.\r\n\r\nThe calculation for max token length, i.e.:\r\n\r\n```\r\n...\r\n    reserved = reserved + count_string_tokens(prompt_template + system_text, model_name)\r\n    # 100 is a magic number to ensure the maximum context length is not exceeded\r\n    max_token = TOKEN_MAX.get(model_name, 2048) - reserved - 100\r\n...\r\n```\r\n\r\nis flawed on a number of counts:\r\n- It does not check for a +ve value. A negative value should raise an exception. If a negative value is derived for max_token the subsequent while loop recursively grows paragraphs with empty lines.\r\n- It assumes that the model_name is always going to be an LLM model name, but this could also be a DEPLOYMENT model name in the case of an Azure OpenAI Service deployment. Because the LLM deployment name could be anything, TOKEN_MATCH will fail to match a valid model name and return the default value - resulting in a negative value.\r\n\r\n**Bug solved method**\r\n\r\nIn order to resolve this issue need to distinguish between the model name and deployment name in the LLMConfig. One refers to the type of model being used, whereas the other refers to an instance / deployment of that type.\r\n\r\n**Environment information**\r\n\r\n- LLM type and model name: Azure OpenAI Service gpt-35-turbo\r\n- System version: Windows 11\r\n- Python version: 3.10.11\r\n- MetaGPT version or branch: 0.8.1\r\n\r\n<!-- Dependent packages：the packages version cause the bug(like `pydantic 1.10.8`), installation method（like `pip install metagpt` or `pip install from source` or `run in docker`） -->\r\n\r\n- packages version:\r\n\r\npoetry = \"~1.7.0\"\r\npython = \">=3.9,<3.13\"\r\naiohttp = \"3.8.6\"\r\nchannels = \"4.0.0\"\r\nfaiss_cpu = \"1.7.4\"\r\nfire = \"0.4.0\"\r\ntyper = \"0.9.0\"\r\nlancedb = \"0.4.0\"\r\nloguru = \"0.6.0\"\r\nmeilisearch = \"0.21.0\"\r\nnumpy = \"^1\"\r\nopenai = \"1.6.1\"\r\nopenpyxl = \"3.1.2\"\r\nbeautifulsoup4 = \"4.12.3\"\r\npandas = \"2.1.1\"\r\npydantic = \"2.5.3\"\r\npython_docx = \"0.8.11\"\r\nPyYAML = \"6.0.1\"\r\nsetuptools = \"65.6.3\"\r\ntenacity = \"8.2.3\"\r\ntiktoken = \"0.6.0\"\r\ntqdm = \"4.66.2\"\r\nanthropic = \"0.18.1\"\r\ntyping-inspect = \"0.8.0\"\r\nlibcst = \"1.0.1\"\r\nqdrant-client = \"1.7.0\"\r\nta = \"0.10.2\"\r\nsemantic-kernel = \"0.4.3.dev0\"\r\nwrapt = \"1.15.0\"\r\naioredis = \"~2.0.1\"\r\nwebsocket-client = \"1.6.2\"\r\naiofiles = \"23.2.1\"\r\ngitpython = \"3.1.40\"\r\nzhipuai = \"2.0.1\"\r\nrich = \"13.6.0\"\r\nnbclient = \"0.9.0\"\r\nnbformat = \"5.9.2\"\r\nipython = \"8.17.2\"\r\nipykernel = \"6.27.1\"\r\nscikit_learn = \"1.3.2\"\r\ntyping-extensions = \"4.9.0\"\r\nsocksio = \"~1.0.0\"\r\ngitignore-parser = \"0.1.9\"\r\nwebsockets = \"~11.0\"\r\nnetworkx = \"~3.2.1\"\r\ngoogle-generativeai = \"0.4.1\"\r\nplaywright = \">=1.26\"\r\nanytree = \"2.12.1\"\r\nipywidgets = \"8.1.1\"\r\nPillow = \"10.3.0\"\r\nimap_tools = \"1.5.0\"\r\nqianfan = \"0.3.2\"\r\ndashscope = \"1.14.1\"\r\nrank-bm25 = \"0.2.2\"\r\ngymnasium = \"0.29.1\"\r\njieba = \"0.42.1\"\r\nbeautifulsoup4  = \"~4.12.3\"\r\ndependency-injector = \"~4.41.0\"\r\nduckduckgo_search = \"~5.3.0\"\r\ngoogle-api-python-client = \"~2.127.0\"\r\nplaywright = \"~1.43.0\"\r\nselenium = \"~4.19.0\"\r\nwebdriver-manager = \"~4.0.1\"\r\n\r\n- installation method: poetry\r\n\r\n**Screenshots or logs**\r\n\r\nN/A\r\n",
      "state": "closed",
      "author": "kilesk",
      "author_type": "User",
      "created_at": "2024-04-24T14:59:44Z",
      "updated_at": "2025-02-05T00:30:21Z",
      "closed_at": "2025-02-05T00:30:20Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1225/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "shenchucheng"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1225",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1225",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:23.825042",
      "comments": [
        {
          "author": "geekan",
          "body": "@shenchucheng can you look at this question?",
          "created_at": "2024-05-18T10:12:46Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-22T00:30:17Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-05T00:30:20Z"
        }
      ]
    },
    {
      "issue_number": 1260,
      "title": "react模式下，自动拼装的promt，缺少action描述信息，请问如何解决？",
      "body": "如下图中，只有类名，请问如何增加工具的功能描述，并且能够拼接到promt中，以便更好的选择正确的action？\r\n![image](https://github.com/geekan/MetaGPT/assets/16470935/d63dee05-4f74-471d-86f5-0fe89457cbb8)\r\n",
      "state": "closed",
      "author": "nzk1912",
      "author_type": "User",
      "created_at": "2024-05-10T06:02:22Z",
      "updated_at": "2025-02-03T00:31:09Z",
      "closed_at": "2025-02-03T00:31:09Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1260/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "geekan"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1260",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1260",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:24.033003",
      "comments": [
        {
          "author": "YangZeyu95",
          "body": "Same issue.\r\nNow I have a workaround, set 'desc' when calling set_actions().\r\nFor example, self.set_actions([action_dummy(desc='some description')])",
          "created_at": "2024-05-13T07:16:22Z"
        },
        {
          "author": "hs3180",
          "body": "You can override __str__ method in your actions. They will be showed in action ReAct prompt.\r\n\r\nhttps://github.com/geekan/MetaGPT/blob/7057ace34468f36f28f8948455e7d251a3ed2899/metagpt/roles/role.py#L279",
          "created_at": "2024-05-15T11:26:10Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-20T00:30:59Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-03T00:31:08Z"
        }
      ]
    },
    {
      "issue_number": 1278,
      "title": "Unable to Finish One Day in Werewolf Game",
      "body": "Hi! It seems that I cannot finish one day (one night and one daytime) in Werewolf Game.\r\n\r\nEverything seems okay before they take the vote. After the vote, the moderator recieves Action 19: Unknown, then every agent keeps talking and do not stop for more than 30 minutes. No one died (it is not possible in real werewolf game) for that long time.\r\n\r\nI tried to set Action idx = 0 when it becomes 19. It successfully goes to the second day / night. However, still no one died after long time. \r\nI saw wolf tried to killed someone, but doesn't work.\r\n\r\nIs that an issue in code? Or something gets wrong in my settings.\r\n\r\nBTW I set the round = 500, but doesn't help.\r\n",
      "state": "closed",
      "author": "ruogu-alter",
      "author_type": "User",
      "created_at": "2024-05-16T10:35:24Z",
      "updated_at": "2025-02-03T00:31:07Z",
      "closed_at": "2025-02-03T00:31:06Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1278/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1278",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1278",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:24.266416",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-20T00:30:57Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-03T00:31:06Z"
        }
      ]
    },
    {
      "issue_number": 1297,
      "title": "ReAct loop can not stop gracefully, usually not stop.",
      "body": "**Bug description**\r\n1. I created a role that simply counts up to 3, after which the goal is considered accomplished. All the LLM I tried usually would not set next_state to -1 in role._think()  when operating in ReAct mode.\r\n2. After I essentially solved 1.  the role encountered difficulties in exiting gracefully. \r\n```\r\n2024-05-24 08:33:16.872 | INFO     | metagpt.roles.role:_think:397 - End actions with next_state=-1\r\n2024-05-24 08:33:16.874 | WARNING  | metagpt.utils.common:wrapper:649 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.\r\nTraceback (most recent call last):\r\n  File \"/home/wei/kf/MetaGPT/metagpt/utils/common.py\", line 640, in wrapper\r\n    return await func(self, *args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/wei/kf/MetaGPT/metagpt/roles/role.py\", line 551, in run\r\n    rsp = await self.react()\r\n          ^^^^^^^^^^^^^^^^^^\r\n  File \"/home/wei/kf/MetaGPT/metagpt/roles/role.py\", line 520, in react\r\n    rsp = await self._react()\r\n          ^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/wei/kf/MetaGPT/metagpt/roles/role.py\", line 475, in _react\r\n    rsp = await self._act()\r\n          ^^^^^^^^^^^^^^^^^\r\n  File \"/home/wei/kf/MetaGPT/workspace/counter.py\", line 53, in _act\r\n    logger.info(f\"{self._setting}: to do {self.rc.todo}({self.rc.todo.name})\")\r\n                                                         ^^^^^^^^^^^^^^^^^\r\nAttributeError: 'NoneType' object has no attribute 'name'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n```\r\n**Bug solved method**\r\n1. ![1716540205523](https://github.com/geekan/MetaGPT/assets/32776997/8eee4c5c-bae3-4c24-b259-6045c298ed39)\r\nI suppose this issue arises because the LLM might get confused after being instructed 'Just answer a number between 0-{n_states}', and then being told 'If you think you have completed your goal and don't need to go to any of the stages, return -1.' LLM may not be able to return -1. \r\n2.\r\n```\r\nclass Role(SerializationMixin, ContextMixin, BaseModel):\r\n    async def _think(self) -> bool:\r\n        \"\"\"Consider what to do and decide on the next course of action. Return false if nothing can be done.\"\"\"\r\n        ....\r\n        next_state = await self.llm.aask(prompt)\r\n        next_state = extract_state_value_from_output(next_state)\r\n        ....\r\n        self._set_state(next_state)\r\n===== after change =====\r\n        return  next_state >= 0 \r\n==== before changed =====\r\n       return True\r\n``` \r\n\r\n",
      "state": "closed",
      "author": "Wei-Jianan",
      "author_type": "User",
      "created_at": "2024-05-24T08:59:09Z",
      "updated_at": "2025-02-03T00:31:06Z",
      "closed_at": "2025-02-03T00:31:05Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1297/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1297",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1297",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:24.476516",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-19T00:32:41Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-03T00:31:05Z"
        }
      ]
    },
    {
      "issue_number": 1339,
      "title": "exp: RetryError[<Future at 0x22e7c98f510 state=finished raised JSONDecodeError>]",
      "body": "2024-06-12 23:08:44.870 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 12.079(s), this was the 5th time calling it. exp: RetryError[<Future at 0x22e7bd4da10 state=finished raised JSONDecodeError>]\r\n\r\n2024-06-12 23:08:52.188 | WARNING  | metagpt.provider.openai_api:_calc_usage:244 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-4-turbo. See https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken for information on how messages are converted to tokens.\r\n2024-06-12 23:08:52.195 | WARNING  | metagpt.utils.repair_llm_raw_output:extract_content_from_output:320 - extract_content try another pattern: \\[CONTENT\\]([\\s\\S]*)\\[/CONTENT\\]\r\n2024-06-12 23:08:52.197 | WARNING  | metagpt.utils.repair_llm_raw_output:run_and_passon:268 - parse json from content inside [CONTENT][/CONTENT] failed at retry 1, exp: Expecting value: line 1 column 2 (char 1)\r\n2024-06-12 23:08:52.199 | INFO     | metagpt.utils.repair_llm_raw_output:repair_invalid_json:237 - repair_invalid_json, raw error: Expecting value: line 1 column 2 (char 1)\r\n2024-06-12 23:08:52.201 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 19.422(s), this was the 6th time calling it. exp: RetryError[<Future at 0x22e7bd4d350 state=finished raised JSONDecodeError>]\r\n2024-06-12 23:08:52.205 | WARNING  | metagpt.utils.common:wrapper:649 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.\r\n2024-06-12 23:08:52.212 | ERROR    | metagpt.utils.common:wrapper:631 - Exception occurs, start to serialize the project, exp:\r\nTraceback (most recent call last):\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\tenacity\\__init__.py\", line 382, in __call__\r\n    result = fn(*args, **kwargs)\r\n             ^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\utils\\repair_llm_raw_output.py\", line 296, in retry_parse_json_text\r\n    parsed_data = CustomDecoder(strict=False).decode(output)\r\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\njson.decoder.JSONDecodeError: Expecting value: line 1 column 2 (char 1)\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\r\n    result = await fn(*args, **kwargs)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\actions\\action_node.py\", line 425, in _aask_v1\r\n    parsed_data = llm_output_postprocess(\r\n                  ^^^^^^^^^^^^^^^^^^^^^^^\r\ntenacity.RetryError: RetryError[<Future at 0x22e7bd4d350 state=finished raised JSONDecodeError>]\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\utils\\common.py\", line 640, in wrapper\r\n    return await func(self, *args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\roles\\role.py\", line 550, in run\r\n    rsp = await self.react()\r\n          ^^^^^^^^^^^^^^^^^^\r\ntenacity.RetryError: RetryError[<Future at 0x22e7bd4f190 state=finished raised RetryError>]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\utils\\common.py\", line 626, in wrapper\r\n    result = await func(self, *args, **kwargs)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\team.py\", line 134, in run\r\n    await self.env.run()\r\nException: Traceback (most recent call last):\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\tenacity\\__init__.py\", line 382, in __call__\r\n    result = fn(*args, **kwargs)\r\n             ^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\utils\\repair_llm_raw_output.py\", line 296, in retry_parse_json_text\r\n    parsed_data = CustomDecoder(strict=False).decode(output)\r\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\utils\\custom_decoder.py\", line 297, in decode\r\n    return super().decode(s)\r\n           ^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\json\\decoder.py\", line 337, in decode\r\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\json\\decoder.py\", line 353, in raw_decode\r\n    obj, end = self.scan_once(s, idx)\r\n               ^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\utils\\custom_decoder.py\", line 65, in scan_once\r\n    return _scan_once(string, idx)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\utils\\custom_decoder.py\", line 38, in _scan_once\r\n    return parse_array((string, idx + 1), _scan_once)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\json\\decoder.py\", line 232, in JSONArray\r\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\r\njson.decoder.JSONDecodeError: Expecting value: line 1 column 2 (char 1)\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\r\n    result = await fn(*args, **kwargs)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\actions\\action_node.py\", line 425, in _aask_v1\r\n    parsed_data = llm_output_postprocess(\r\n                  ^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\provider\\postprocess\\llm_output_postprocess.py\", line 19, in llm_output_postprocess\r\n    result = postprocess_plugin.run(output=output, schema=schema, req_key=req_key)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\provider\\postprocess\\base_postprocess_plugin.py\", line 68, in run\r\n    new_output = self.run_repair_llm_output(output=output, schema=schema, req_key=req_key)\r\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\provider\\postprocess\\base_postprocess_plugin.py\", line 32, in run_repair_llm_output\r\n    parsed_data = self.run_retry_parse_json_text(content)\r\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\provider\\postprocess\\base_postprocess_plugin.py\", line 47, in run_retry_parse_json_text\r\n    parsed_data = retry_parse_json_text(output=content)  # should use output=content\r\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\tenacity\\__init__.py\", line 289, in wrapped_f\r\n    return self(f, *args, **kw)\r\n           ^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\tenacity\\__init__.py\", line 379, in __call__\r\n    do = self.iter(retry_state=retry_state)\r\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\tenacity\\__init__.py\", line 326, in iter\r\n    raise retry_exc from fut.exception()\r\ntenacity.RetryError: RetryError[<Future at 0x22e7bd4d350 state=finished raised JSONDecodeError>]\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\utils\\common.py\", line 640, in wrapper\r\n    return await func(self, *args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\roles\\role.py\", line 550, in run\r\n    rsp = await self.react()\r\n          ^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\roles\\role.py\", line 517, in react\r\n    rsp = await self._react()\r\n          ^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\roles\\role.py\", line 463, in _react\r\n    rsp = await self._act()\r\n          ^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\roles\\role.py\", line 392, in _act\r\n    response = await self.rc.todo.run(self.rc.history)\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\actions\\write_prd.py\", line 87, in run\r\n    return await self._handle_new_requirement(req)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\actions\\write_prd.py\", line 108, in _handle_new_requirement\r\n    node = await WRITE_PRD_NODE.fill(context=context, llm=self.llm, exclude=exclude)  # schema=schema\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\actions\\action_node.py\", line 505, in fill\r\n    return await self.simple_fill(schema=schema, mode=mode, images=images, timeout=timeout, exclude=exclude)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\actions\\action_node.py\", line 457, in simple_fill\r\n    content, scontent = await self._aask_v1(\r\n                        ^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\r\n    return await fn(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\r\n    do = self.iter(retry_state=retry_state)\r\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\tenacity\\__init__.py\", line 326, in iter\r\n    raise retry_exc from fut.exception()\r\ntenacity.RetryError: RetryError[<Future at 0x22e7bd4f190 state=finished raised RetryError>]",
      "state": "closed",
      "author": "zhenglanglang",
      "author_type": "User",
      "created_at": "2024-06-12T15:30:15Z",
      "updated_at": "2025-02-03T00:31:04Z",
      "closed_at": "2025-02-03T00:31:04Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1339/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1339",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1339",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:24.712677",
      "comments": [
        {
          "author": "zhenglanglang",
          "body": "how to deal ？？\r\n",
          "created_at": "2024-06-12T15:30:33Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-19T00:32:40Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-03T00:31:03Z"
        }
      ]
    },
    {
      "issue_number": 1642,
      "title": "How to set top_p parameter properly?",
      "body": "Hi, first of all, I want to express my appreciation for your amazing work on this project. It has been incredibly helpful.\r\nI encountered an issue while trying to configure the top_p parameter. I included the setting in my config2.yaml file, but it doesn't seem to take effect. Could you please guide me on the correct way to set this parameter?\r\nmy config2.yaml snippet looks like:\r\n`llm:\r\n  api_type: \"open_llm\" \r\n  model: \"xxx\" \r\n  base_url: \"http://xxx/v1\" \r\n  api_key: \"none\"\r\n  max_token: 8192\r\n  temperature: 0.9\r\n  top_p: 0.5`  and I debugged to check the configured values, max_token and temperature already worked, but temperature not.\r\n\r\nAm I missing something, or is there another place I should configure this?\r\n\r\nThank you in advance for your help, and I’m looking forward to your response!",
      "state": "closed",
      "author": "sanexodus",
      "author_type": "User",
      "created_at": "2024-12-16T07:33:55Z",
      "updated_at": "2025-01-31T00:30:04Z",
      "closed_at": "2025-01-31T00:30:04Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1642/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1642",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1642",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:24.891673",
      "comments": [
        {
          "author": "shenchucheng",
          "body": "It seems to be a bug where the `top_p` configuration is not being used. Looking at the code [[here](https://github.com/geekan/MetaGPT/blob/main/metagpt/provider/openai_api.py#L128)](https://github.com/geekan/MetaGPT/blob/main/metagpt/provider/openai_api.py#L128), the `top_p` parameter is not include",
          "created_at": "2024-12-17T13:52:41Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-17T00:29:43Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-31T00:30:03Z"
        }
      ]
    },
    {
      "issue_number": 1627,
      "title": "WriteCode.get_codes fetches unexpectedly large amount of data.",
      "body": "**Bug description**\r\n            code_context = await WriteCode.get_codes(\r\n                self.i_context.task_doc,\r\n                exclude=self.i_context.filename,\r\n                project_repo=self.repo.with_src_path(self.context.src_workspace),\r\n                use_inc=self.config.inc,\r\n            )\r\ncode context might exceed the llm max_token\r\n\r\n**Bug solved method**\r\nlen(code_context)\r\n213693\r\nextremely large amount of code files are retrieved.\r\nmaybe retrieve only few context relevant files. and work on that with few iterations and summarize irrevelent part or using RAG to minimize the relevant data.\r\n",
      "state": "closed",
      "author": "davidleon",
      "author_type": "User",
      "created_at": "2024-12-05T09:46:48Z",
      "updated_at": "2025-01-24T00:29:56Z",
      "closed_at": "2025-01-24T00:29:56Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1627/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1627",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1627",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:25.079226",
      "comments": [
        {
          "author": "shenchucheng",
          "body": "Thank you for your suggestion! This issue indeed exists. In the new version, we no longer use `WriteCode` for code writing. Instead, we have introduced the `Editor` tool.",
          "created_at": "2024-12-09T03:03:50Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-09T00:30:46Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-24T00:29:55Z"
        }
      ]
    },
    {
      "issue_number": 1633,
      "title": "Code error in blackjack example",
      "body": "<img width=\"657\" alt=\"2024-12-07_22-36-51\" src=\"https://github.com/user-attachments/assets/61a11be1-fe6a-4d66-b4ab-271219fb2497\">\r\n\r\nThe image is of the example locate at URL: https://docs.deepwisdom.ai/main/en/guide/get_started/quickstart.html \r\n\r\nThe line: \r\n```\r\nawait startup(idea=\"write a cli blackjack game\")\r\n```\r\nis incorrect (the code won't run). Instead, it should be: \r\n```\r\nasyncio.run(startup(idea=\"write a client blackjack game\")\r\n",
      "state": "closed",
      "author": "erlebach",
      "author_type": "User",
      "created_at": "2024-12-08T03:44:04Z",
      "updated_at": "2025-01-24T00:29:55Z",
      "closed_at": "2025-01-24T00:29:55Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1633/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1633",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1633",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:25.356672",
      "comments": [
        {
          "author": "shenchucheng",
          "body": "Thank you for the feedback. Most of our examples are written in Jupyter Notebook, which is why the code runs as expected in that environment but results in a syntax error in the default Python IDE.",
          "created_at": "2024-12-09T04:02:16Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-09T00:30:44Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-24T00:29:54Z"
        }
      ]
    },
    {
      "issue_number": 1620,
      "title": "no listed python and docker installations ways working",
      "body": "**Bug description**\r\nNether a newly installed python installation within an python environment or a docker installation is working at the moment out of the box.\r\n\r\n**Bug not solved**\r\npip install metagpt is not working (tried 40 minutes, with an created environment, i had so mutch log output that it was too long for here but i also tried like 10 additional version overrites and all didnt worked.\r\nhttps://docs.deepwisdom.ai/main/en/guide/get_started/installation.html#install-stable-version\r\n\r\nand all other version from the readme to install it with pip also didnt worked\r\n\r\n\r\n**Environment information**\r\n<!-- Environment：System version (), Python version (),  -->\r\n\r\n- System version: Nobara Linux 40\r\n- Python version: Python 3.12.7\r\n\r\n<!-- Dependent packagess：the packages version cause the bug(like `pydantic 1.10.8`), installation method（like `pip install metagpt` or `pip install from source` or `run in docker`） -->\r\n\r\n- installation method: all listed docker and pip instructions on the documentation and readme site.\r\n\r\n**Screenshots or logs**\r\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\r\n```\r\ndocker run --rm     --privileged     -v /opt/metagpt/config/config2.yaml:/app/metagpt/config/config2.yaml     -v /opt/metagpt/workspace:/app/metagpt/workspace     metagpt/metagpt:latest     metagpt \"Write a cli snake game\"            2024-12-02 20:51:33.966 | INFO     | metagpt.const:get_metagpt_package_root:21 - Package root set to /app/metagpt\r\n╭───────────────────── Traceback (most recent call last) ──────────────────────╮\r\n│ /app/metagpt/metagpt/software_company.py:115 in startup                      │\r\n│                                                                              │\r\n│   112 │   │   typer.echo(\"Missing argument 'IDEA'. Run 'metagpt --help' for  │\r\n│   113 │   │   raise typer.Exit()                                             │\r\n│   114 │                                                                      │\r\n│ ❱ 115 │   return generate_repo(                                              │\r\n│   116 │   │   idea,                                                          │\r\n│   117 │   │   investment,                                                    │\r\n│   118 │   │   n_round,                                                       │\r\n│                                                                              │\r\n│ /app/metagpt/metagpt/software_company.py:31 in generate_repo                 │\r\n│                                                                              │\r\n│    28 │   recover_path=None,                                                 │\r\n│    29 ) -> ProjectRepo:                                                      │\r\n│    30 │   \"\"\"Run the startup logic. Can be called from CLI or other Python s │\r\n│ ❱  31 │   from metagpt.config2 import config                                 │\r\n│    32 │   from metagpt.context import Context                                │\r\n│    33 │   from metagpt.roles import (                                        │\r\n│    34 │   │   Architect,                                                     │\r\n│                                                                              │\r\n│ /app/metagpt/metagpt/config2.py:169 in <module>                              │\r\n│                                                                              │\r\n│   166 │   return result                                                      │\r\n│   167                                                                        │\r\n│   168                                                                        │\r\n│ ❱ 169 config = Config.default()                                              │\r\n│   170                                                                        │\r\n│                                                                              │\r\n│ /app/metagpt/metagpt/config2.py:109 in default                               │\r\n│                                                                              │\r\n│   106 │   │   ]                                                              │\r\n│   107 │   │                                                                  │\r\n│   108 │   │   dicts = [dict(os.environ)]                                     │\r\n│ ❱ 109 │   │   dicts += [Config.read_yaml(path) for path in default_config_pa │\r\n│   110 │   │   final = merge_dict(dicts)                                      │\r\n│   111 │   │   return Config(**final)                                         │\r\n│   112                                                                        │\r\n│                                                                              │\r\n│ /app/metagpt/metagpt/config2.py:109 in <listcomp>                            │\r\n│                                                                              │\r\n│   106 │   │   ]                                                              │\r\n│   107 │   │                                                                  │\r\n│   108 │   │   dicts = [dict(os.environ)]                                     │\r\n│ ❱ 109 │   │   dicts += [Config.read_yaml(path) for path in default_config_pa │\r\n│   110 │   │   final = merge_dict(dicts)                                      │\r\n│   111 │   │   return Config(**final)                                         │\r\n│   112                                                                        │\r\n│                                                                              │\r\n│ /app/metagpt/metagpt/utils/yaml_model.py:26 in read_yaml                     │\r\n│                                                                              │\r\n│   23 │   │   if not file_path.exists():                                      │\r\n│   24 │   │   │   return {}                                                   │\r\n│   25 │   │   with open(file_path, \"r\", encoding=encoding) as file:           │\r\n│ ❱ 26 │   │   │   return yaml.safe_load(file)                                 │\r\n│   27 │                                                                       │\r\n│   28 │   @classmethod                                                        │\r\n│   29 │   def from_yaml_file(cls, file_path: Path) -> \"YamlModel\":            │\r\n│                                                                              │\r\n│ /usr/local/lib/python3.9/site-packages/yaml/__init__.py:125 in safe_load     │\r\n│                                                                              │\r\n│   122 │   Resolve only basic YAML tags. This is known                        │\r\n│   123 │   to be safe for untrusted input.                                    │\r\n│   124 │   \"\"\"                                                                │\r\n│ ❱ 125 │   return load(stream, SafeLoader)                                    │\r\n│   126                                                                        │\r\n│   127 def safe_load_all(stream):                                             │\r\n│   128 │   \"\"\"                                                                │\r\n│                                                                              │\r\n│ /usr/local/lib/python3.9/site-packages/yaml/__init__.py:81 in load           │\r\n│                                                                              │\r\n│    78 │   \"\"\"                                                                │\r\n│    79 │   loader = Loader(stream)                                            │\r\n│    80 │   try:                                                               │\r\n│ ❱  81 │   │   return loader.get_single_data()                                │\r\n│    82 │   finally:                                                           │\r\n│    83 │   │   loader.dispose()                                               │\r\n│    84                                                                        │\r\n│                                                                              │\r\n│ /usr/local/lib/python3.9/site-packages/yaml/constructor.py:49 in             │\r\n│ get_single_data                                                              │\r\n│                                                                              │\r\n│    46 │                                                                      │\r\n│    47 │   def get_single_data(self):                                         │\r\n│    48 │   │   # Ensure that the stream contains a single document and constr │\r\n│ ❱  49 │   │   node = self.get_single_node()                                  │\r\n│    50 │   │   if node is not None:                                           │\r\n│    51 │   │   │   return self.construct_document(node)                       │\r\n│    52 │   │   return None                                                    │\r\n│                                                                              │\r\n│ /usr/local/lib/python3.9/site-packages/yaml/composer.py:36 in                │\r\n│ get_single_node                                                              │\r\n│                                                                              │\r\n│    33 │   │   # Compose a document if the stream is not empty.               │\r\n│    34 │   │   document = None                                                │\r\n│    35 │   │   if not self.check_event(StreamEndEvent):                       │\r\n│ ❱  36 │   │   │   document = self.compose_document()                         │\r\n│    37 │   │                                                                  │\r\n│    38 │   │   # Ensure that the stream contains no more documents.           │\r\n│    39 │   │   if not self.check_event(StreamEndEvent):                       │\r\n│                                                                              │\r\n│ /usr/local/lib/python3.9/site-packages/yaml/composer.py:55 in                │\r\n│ compose_document                                                             │\r\n│                                                                              │\r\n│    52 │   │   self.get_event()                                               │\r\n│    53 │   │                                                                  │\r\n│    54 │   │   # Compose the root node.                                       │\r\n│ ❱  55 │   │   node = self.compose_node(None, None)                           │\r\n│    56 │   │                                                                  │\r\n│    57 │   │   # Drop the DOCUMENT-END event.                                 │\r\n│    58 │   │   self.get_event()                                               │\r\n│                                                                              │\r\n│ /usr/local/lib/python3.9/site-packages/yaml/composer.py:84 in compose_node   │\r\n│                                                                              │\r\n│    81 │   │   elif self.check_event(SequenceStartEvent):                     │\r\n│    82 │   │   │   node = self.compose_sequence_node(anchor)                  │\r\n│    83 │   │   elif self.check_event(MappingStartEvent):                      │\r\n│ ❱  84 │   │   │   node = self.compose_mapping_node(anchor)                   │\r\n│    85 │   │   self.ascend_resolver()                                         │\r\n│    86 │   │   return node                                                    │\r\n│    87                                                                        │\r\n│                                                                              │\r\n│ /usr/local/lib/python3.9/site-packages/yaml/composer.py:127 in               │\r\n│ compose_mapping_node                                                         │\r\n│                                                                              │\r\n│   124 │   │   │   │   flow_style=start_event.flow_style)                     │\r\n│   125 │   │   if anchor is not None:                                         │\r\n│   126 │   │   │   self.anchors[anchor] = node                                │\r\n│ ❱ 127 │   │   while not self.check_event(MappingEndEvent):                   │\r\n│   128 │   │   │   #key_event = self.peek_event()                             │\r\n│   129 │   │   │   item_key = self.compose_node(node, None)                   │\r\n│   130 │   │   │   #if item_key in node.value:                                │\r\n│                                                                              │\r\n│ /usr/local/lib/python3.9/site-packages/yaml/parser.py:98 in check_event      │\r\n│                                                                              │\r\n│    95 │   │   # Check the type of the next event.                            │\r\n│    96 │   │   if self.current_event is None:                                 │\r\n│    97 │   │   │   if self.state:                                             │\r\n│ ❱  98 │   │   │   │   self.current_event = self.state()                      │\r\n│    99 │   │   if self.current_event is not None:                             │\r\n│   100 │   │   │   if not choices:                                            │\r\n│   101 │   │   │   │   return True                                            │\r\n│                                                                              │\r\n│ /usr/local/lib/python3.9/site-packages/yaml/parser.py:438 in                 │\r\n│ parse_block_mapping_key                                                      │\r\n│                                                                              │\r\n│   435 │   │   │   │   return self.process_empty_scalar(token.end_mark)       │\r\n│   436 │   │   if not self.check_token(BlockEndToken):                        │\r\n│   437 │   │   │   token = self.peek_token()                                  │\r\n│ ❱ 438 │   │   │   raise ParserError(\"while parsing a block mapping\", self.ma │\r\n│   439 │   │   │   │   │   \"expected <block end>, but found %r\" % token.id, t │\r\n│   440 │   │   token = self.get_token()                                       │\r\n│   441 │   │   event = MappingEndEvent(token.start_mark, token.end_mark)      │\r\n╰──────────────────────────────────────────────────────────────────────────────╯\r\nParserError: while parsing a block mapping\r\n  in \"/app/metagpt/config/config2.yaml\", line 1, column 1\r\nexpected <block end>, but found '<block mapping start>'\r\n  in \"/app/metagpt/config/config2.yaml\", line 5, column 3\r\n\r\n```",
      "state": "closed",
      "author": "Xyz00777",
      "author_type": "User",
      "created_at": "2024-12-02T21:22:37Z",
      "updated_at": "2025-01-21T00:29:30Z",
      "closed_at": "2025-01-21T00:29:29Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1620/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1620",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1620",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:25.584662",
      "comments": [
        {
          "author": "shenchucheng",
          "body": "The error suggests there is a syntax issue in your config2.yaml file.",
          "created_at": "2024-12-04T06:37:03Z"
        },
        {
          "author": "Xyz00777",
          "body": "wow okay that worked, fail :D\r\nbut still the python way didnt worked...",
          "created_at": "2024-12-04T23:32:48Z"
        },
        {
          "author": "shenchucheng",
          "body": "Are there any other errors?",
          "created_at": "2024-12-06T08:05:06Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-06T00:32:33Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-21T00:29:28Z"
        }
      ]
    },
    {
      "issue_number": 1607,
      "title": "执行demo时出现tenacity.RetryError: RetryError[<Future at 0x7f0a4fef12b0 state=finished raised AssertionError>]",
      "body": "metagpt \"Write a cli snake game\"\r\n2024-11-15 15:03:50.927 | INFO     | metagpt.const:get_metagpt_package_root:21 - Package root set to /app/metagpt\r\n2024-11-15 15:03:55.243 | INFO     | metagpt.team:invest:93 - Investment: $3.0.\r\n2024-11-15 15:03:55.246 | INFO     | metagpt.roles.role:_act:403 - Alice(Product Manager): to do PrepareDocuments(PrepareDocuments)\r\n2024-11-15 15:03:55.319 | INFO     | metagpt.utils.file_repository:save:57 - save to: /app/metagpt/workspace/20241115150355/docs/requirement.txt\r\n2024-11-15 15:03:55.321 | INFO     | metagpt.roles.role:_act:403 - Alice(Product Manager): to do WritePRD(WritePRD)\r\n2024-11-15 15:03:55.323 | INFO     | metagpt.actions.write_prd:run:86 - New requirement detected: Write a cli snake game\r\n2024-11-15 15:03:55.766 | WARNING  | tenacity.after:log_it:44 - Finished call to 'metagpt.provider.base_llm.BaseLLM.acompletion_text' after 0.441(s), this was the 1st time calling it.\r\n2024-11-15 15:03:56.337 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 1.012(s), this was the 1st time calling it. exp: \r\n2024-11-15 15:03:56.581 | WARNING  | tenacity.after:log_it:44 - Finished call to 'metagpt.provider.base_llm.BaseLLM.acompletion_text' after 0.238(s), this was the 1st time calling it.\r\n2024-11-15 15:03:57.182 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 1.857(s), this was the 2nd time calling it. exp: \r\n2024-11-15 15:03:58.808 | WARNING  | tenacity.after:log_it:44 - Finished call to 'metagpt.provider.base_llm.BaseLLM.acompletion_text' after 0.003(s), this was the 1st time calling it.\r\n2024-11-15 15:03:58.992 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 3.667(s), this was the 3rd time calling it. exp: \r\n2024-11-15 15:04:02.819 | WARNING  | tenacity.after:log_it:44 - Finished call to 'metagpt.provider.base_llm.BaseLLM.acompletion_text' after 0.003(s), this was the 1st time calling it.\r\n2024-11-15 15:04:02.896 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 7.571(s), this was the 4th time calling it. exp: \r\n2024-11-15 15:04:03.830 | WARNING  | tenacity.after:log_it:44 - Finished call to 'metagpt.provider.base_llm.BaseLLM.acompletion_text' after 0.003(s), this was the 1st time calling it.\r\n2024-11-15 15:04:04.174 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 8.849(s), this was the 5th time calling it. exp: \r\n2024-11-15 15:04:16.136 | WARNING  | tenacity.after:log_it:44 - Finished call to 'metagpt.provider.base_llm.BaseLLM.acompletion_text' after 0.002(s), this was the 1st time calling it.\r\n2024-11-15 15:04:16.423 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 21.098(s), this was the 6th time calling it. exp: \r\n2024-11-15 15:04:16.424 | WARNING  | metagpt.utils.common:wrapper:673 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.    \r\n2024-11-15 15:04:16.441 | ERROR    | metagpt.utils.common:wrapper:655 - Exception occurs, start to serialize the project, exp:\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 50, in __call__\r\n    result = await fn(*args, **kwargs)\r\n  File \"/app/metagpt/metagpt/actions/action_node.py\", line 437, in _aask_v1\r\n    content = await self.llm.aask(prompt, system_msgs, images=images, timeout=timeout)\r\nAssertionError\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/app/metagpt/metagpt/utils/common.py\", line 664, in wrapper\r\n    return await func(self, *args, **kwargs)\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 551, in run\r\n    rsp = await self.react()\r\ntenacity.RetryError: RetryError[<Future at 0x7f0a4fef12b0 state=finished raised AssertionError>]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/app/metagpt/metagpt/utils/common.py\", line 650, in wrapper\r\n    result = await func(self, *args, **kwargs)\r\n  File \"/app/metagpt/metagpt/team.py\", line 134, in run\r\n    await self.env.run()\r\nException: Traceback (most recent call last):\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 50, in __call__\r\n    result = await fn(*args, **kwargs)\r\n  File \"/app/metagpt/metagpt/actions/action_node.py\", line 437, in _aask_v1\r\n    content = await self.llm.aask(prompt, system_msgs, images=images, timeout=timeout)\r\n  File \"/app/metagpt/metagpt/provider/base_llm.py\", line 152, in aask\r\n    rsp = await self.acompletion_text(message, stream=stream, timeout=self.get_timeout(timeout))\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\r\n    return await fn(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 47, in __call__\r\n    do = self.iter(retry_state=retry_state)\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/__init__.py\", line 314, in iter\r\n    return fut.result()\r\n  File \"/usr/local/lib/python3.9/concurrent/futures/_base.py\", line 439, in result\r\n    return self.__get_result()\r\n  File \"/usr/local/lib/python3.9/concurrent/futures/_base.py\", line 391, in __get_result\r\n    raise self._exception\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 50, in __call__\r\n    result = await fn(*args, **kwargs)\r\n  File \"/app/metagpt/metagpt/provider/base_llm.py\", line 202, in acompletion_text\r\n    return await self._achat_completion_stream(messages, timeout=self.get_timeout(timeout))\r\n  File \"/app/metagpt/metagpt/provider/spark_api.py\", line 76, in _achat_completion_stream\r\n    async for chunk in response:\r\n  File \"/usr/local/lib/python3.9/site-packages/sparkai/core/language_models/chat_models.py\", line 309, in astream\r\n    raise e\r\n  File \"/usr/local/lib/python3.9/site-packages/sparkai/core/language_models/chat_models.py\", line 301, in astream\r\n    assert generation is not None\r\nAssertionError\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/app/metagpt/metagpt/utils/common.py\", line 664, in wrapper\r\n    return await func(self, *args, **kwargs)\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 551, in run\r\n    rsp = await self.react()\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 520, in react\r\n    rsp = await self._react()\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 475, in _react\r\n    rsp = await self._act()\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 404, in _act\r\n    response = await self.rc.todo.run(self.rc.history)\r\n  File \"/app/metagpt/metagpt/actions/write_prd.py\", line 87, in run\r\n    return await self._handle_new_requirement(req)\r\n  File \"/app/metagpt/metagpt/actions/write_prd.py\", line 108, in _handle_new_requirement\r\n    node = await WRITE_PRD_NODE.fill(context=context, llm=self.llm, exclude=exclude)  # schema=schema\r\n  File \"/app/metagpt/metagpt/actions/action_node.py\", line 648, in fill\r\n    return await self.simple_fill(schema=schema, mode=mode, images=images, timeout=timeout, exclude=exclude)\r\n  File \"/app/metagpt/metagpt/actions/action_node.py\", line 473, in simple_fill\r\n    content, scontent = await self._aask_v1(\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\r\n    return await fn(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 47, in __call__\r\n    do = self.iter(retry_state=retry_state)\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/__init__.py\", line 326, in iter\r\n    raise retry_exc from fut.exception()\r\ntenacity.RetryError: RetryError[<Future at 0x7f0a4fef12b0 state=finished raised AssertionError>]",
      "state": "closed",
      "author": "simonaries",
      "author_type": "User",
      "created_at": "2024-11-15T15:06:24Z",
      "updated_at": "2025-01-21T00:29:30Z",
      "closed_at": "2025-01-21T00:29:30Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1607/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1607",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1607",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:25.803882",
      "comments": [
        {
          "author": "voidking",
          "body": "从报错看，是调用LLM不通。建议先不要使用metagpt，而是先调通你使用的LLM官方给的示例代码，保证base_url、model和key都是正确的，然后再填入metagpt的配置文件中。",
          "created_at": "2024-11-18T12:21:00Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-06T00:32:37Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-21T00:29:29Z"
        }
      ]
    },
    {
      "issue_number": 1628,
      "title": "Run o1 with MetaGPT, cannot produce any output. ",
      "body": "**Bug description**\r\n1. When running o1, with examples/build_customized_multi_agents.py, no output is shown in the terminal. But o1 is indeed being used and charged.\r\n2. logs does have the o1 output as 'DEBUG', it is just not shown in the terminal\r\n3. If switch to gpt4, everything is working.\r\n\r\n**Environment information**\r\no1 and o1 mini both have the issue. No output in the terminal.\r\n\r\n- System version: Linux\r\n- MetaGPT version or branch: Latest metaGPT github repo installation as of today.\r\n",
      "state": "closed",
      "author": "hohoCode",
      "author_type": "User",
      "created_at": "2024-12-05T17:13:39Z",
      "updated_at": "2025-01-21T00:29:28Z",
      "closed_at": "2025-01-21T00:29:27Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1628/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1628",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1628",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:26.032739",
      "comments": [
        {
          "author": "shenchucheng",
          "body": "Please update your configuration as follows:  \r\n\r\n```yaml\r\nllm:\r\n  api_type: 'openai'\r\n  api_key: 'sk-...'\r\n  model: 'o1-mini'\r\n  use_system_prompt: false\r\n  stream: false\r\n```  \r\n\r\nMake sure `use_system_prompt` and `stream` are set to `false`.",
          "created_at": "2024-12-06T06:51:18Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-06T00:32:32Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-21T00:29:27Z"
        }
      ]
    },
    {
      "issue_number": 1629,
      "title": "access to deepseek",
      "body": "want to access to deepseek!!!!",
      "state": "closed",
      "author": "Dwendwen-Liu",
      "author_type": "User",
      "created_at": "2024-12-06T02:45:24Z",
      "updated_at": "2025-01-21T00:29:27Z",
      "closed_at": "2025-01-21T00:29:26Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1629/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1629",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1629",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:26.293699",
      "comments": [
        {
          "author": "shenchucheng",
          "body": "```\r\nllm:\r\n  api_key: sk-xxxxxxxxxxxxxxxxxxxx\r\n  api_type: openai\r\n  base_url: https://api.deepseek.com/v1\r\n  model: deepseek-chat  # deepseek-coder\r\n```\r\nSee, https://api-docs.deepseek.com/.\r\n",
          "created_at": "2024-12-06T03:06:22Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-06T00:32:31Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-21T00:29:26Z"
        }
      ]
    },
    {
      "issue_number": 1361,
      "title": "How to synchronize on multiple \"watches\"",
      "body": "Hi very impressive work! Can you show me how to do fan-in correctly in MetaGPT as the current default implementation of the watch list is merely a filter? I want an action to be dependent on multiple agents and wait on their inputs.",
      "state": "closed",
      "author": "jiange91",
      "author_type": "User",
      "created_at": "2024-06-20T05:05:20Z",
      "updated_at": "2025-01-20T00:30:56Z",
      "closed_at": "2025-01-20T00:30:56Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1361/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "geekan",
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1361",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1361",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:26.512989",
      "comments": [
        {
          "author": "voidking",
          "body": "I don't quite understand what you want. Can you give a more specific example?",
          "created_at": "2024-07-02T12:21:47Z"
        },
        {
          "author": "jiange91",
          "body": "Basically, I want an agent only to take action when all its dependencies are met. \r\nLike if A has a watch list of [B, C, D], I need all inputs from B, C, D for A to take action. But currently, it seems as long as B or C or D gives their input A will take action. Is watch list the wrong mechanism to ",
          "created_at": "2024-07-02T17:03:56Z"
        },
        {
          "author": "geekan",
          "body": "When making this design, my intention was to make it the same as pubsub (queue), and there are a large number of queue design patterns for reference.\r\n\r\nPublishing messages and consuming messages are actually two standard behaviors for queues. When you need to wait for multiple messages before start",
          "created_at": "2024-10-11T09:40:56Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-05T00:33:51Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-20T00:30:56Z"
        }
      ]
    },
    {
      "issue_number": 1365,
      "title": "MetaGpt not as a oneshot commander, but a continue chat backend api server.",
      "body": "The most common usage case about MetaGpt is just like a one-shot command executor。\r\n\r\nYou input the task: \" write me a golang hello world\"\r\n\r\nAnd MetaGpt will do lots of works for you, and then return you the workspace contains the code and document files。\r\n\r\n\r\nBUT, if can we make MetaGPT as a chat backend API server。\r\n\r\nFor example, we sold shoes, we want to train a AI salesman。 \r\n\r\nThe salesman should know each shoes style, size, and it's price.\r\n\r\nIt must answer question about the shoes. provided price sheets for customers.\r\n\r\nAnd if customer not willing to buy, the salesman should talk to customers, to make customer buy shoes as well.\r\n\r\n\r\nSo this is not a simple application, but a very complex requirement.\r\n\r\nThe role should have much knowledge on sales skills, and well talk ability。\r\n\r\nMetaGPT seems can do this job, but i don't know how to make it running as a API server.\r\n\r\nIt should read and remember talk sessions。 may be keep the same customer talk history for a long time, Next time the customer came back, we should still remember what he talked。\r\n",
      "state": "closed",
      "author": "code959437957",
      "author_type": "User",
      "created_at": "2024-06-25T09:09:00Z",
      "updated_at": "2025-01-19T00:32:40Z",
      "closed_at": "2025-01-19T00:32:39Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1365/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1365",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1365",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:26.702330",
      "comments": [
        {
          "author": "zhaoq1",
          "body": "Yes, I think this is very important. I think the human-computer interaction mode should be optimized in the streaming interface. The current terminal interaction method is very inconvenient.",
          "created_at": "2024-06-27T08:39:27Z"
        },
        {
          "author": "geekan",
          "body": "We will fix this issue in version 1.0",
          "created_at": "2024-10-20T07:04:55Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-04T00:29:59Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-19T00:32:39Z"
        }
      ]
    },
    {
      "issue_number": 1458,
      "title": "怎么生成符合我自定义规范的代码?",
      "body": "比如说我想生成一些前端代码，需要生成的代码要用我自己封装的组件库，工具库等.要怎么做？有例子吗？谢谢",
      "state": "closed",
      "author": "frh10",
      "author_type": "User",
      "created_at": "2024-08-20T09:51:24Z",
      "updated_at": "2025-01-18T00:28:40Z",
      "closed_at": "2025-01-18T00:28:39Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1458/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": "1.0",
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1458",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1458",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:26.909994",
      "comments": [
        {
          "author": "iorisa",
          "body": "这种灵活的开发需求，建议你用[DataInterpreter](https://docs.deepwisdom.ai/main/en/DataInterpreter/)来做。",
          "created_at": "2024-08-20T13:22:00Z"
        },
        {
          "author": "frh10",
          "body": "> 这种灵活的开发需求，建议你用[DataInterpreter](https://docs.deepwisdom.ai/main/en/DataInterpreter/)来做。\r\n\r\n你的意思是用自定义工具里的提示词实现吗？类似于教程文案助手那样？",
          "created_at": "2024-08-21T06:43:09Z"
        },
        {
          "author": "iorisa",
          "body": "不是。是把你的技术需求作为需求内容（消息的内容）的一部分发给DI，它自己会调整的",
          "created_at": "2024-08-22T06:57:45Z"
        },
        {
          "author": "tdsnxchen-max",
          "body": "> 比如说我想生成一些前端代码，需要生成的代码要用我自己封装的组件库，工具库等.要怎么做？有例子吗？谢谢\r\n\r\nI think it 's a common request. Have you implemented it?",
          "created_at": "2024-09-13T02:18:13Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-02T00:30:20Z"
        }
      ]
    },
    {
      "issue_number": 1557,
      "title": "Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1'",
      "body": "### 报错\r\nFinished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 17.605(s), this was the 3rd time calling it. exp: openai.types.completion_usage.CompletionUsage() argument after ** must be a mapping, not NoneType\r\n\r\n测试了qwen2.5系列，7b到72b全试了，包括官方开源模型和rombos-72b模型，全部都报错，而且百分百报错，任何问题都是一样\r\n\r\n### config：\r\nllm:\r\n  api_type: \"openai\"  # or azure / ollama / open_llm etc. Check LLMType for more options\r\n  model: \"gpt\"\r\n  base_url: \"http://192.168.1.161:1227/v1\"  # or forward url / other llm url\r\n  api_key: \"test\"\r\n\r\n### 安装（ubuntu22 python3.9）：\r\npip install --upgrade metagpt\r\nmetagpt --init-config\r\nnano ~/.metagpt/config2.yaml\r\nmetagpt \"python令牌桶限流代码\"",
      "state": "closed",
      "author": "maxin9966",
      "author_type": "User",
      "created_at": "2024-10-31T05:17:00Z",
      "updated_at": "2025-01-18T00:28:39Z",
      "closed_at": "2025-01-18T00:28:38Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1557/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "voidking"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1557",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1557",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:27.147736",
      "comments": [
        {
          "author": "geekan",
          "body": "1. Please ask questions in English.\r\n2. The model in your config is gpt. I would like to ask what the actual model is? Is the api_type filled in correctly?",
          "created_at": "2024-10-31T05:43:41Z"
        },
        {
          "author": "voidking",
          "body": "I guess there is some error in model configuration. You can try the model given in our documentation first.\r\nhttps://docs.deepwisdom.ai/main/en/guide/get_started/configuration/llm_api_configuration.html",
          "created_at": "2024-10-31T05:50:03Z"
        },
        {
          "author": "LimFang",
          "body": "well i got the same info, the config is all well set. Any solutions?",
          "created_at": "2024-11-19T11:27:01Z"
        },
        {
          "author": "Miracle-Master",
          "body": "try add this to your .yaml \"base_url\r\n=\"https://open.bigmodel.cn/api/paas/v4/\"\"",
          "created_at": "2024-12-03T09:22:27Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-03T00:30:22Z"
        }
      ]
    },
    {
      "issue_number": 1477,
      "title": "Cannot install due to old numpy version being used by metagpt",
      "body": "```\r\nCollecting numpy==1.24.3 (from metagpt)\r\n  Using cached numpy-1.24.3.tar.gz (10.9 MB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... error\r\n  error: subprocess-exited-with-error\r\n\r\n  × Getting requirements to build wheel did not run successfully.\r\n  │ exit code: 1\r\n  ╰─> [32 lines of output]\r\n      Traceback (most recent call last):\r\n        File \"C:\\Users\\blusc\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\r\n          main()\r\n          ~~~~^^\r\n        File \"C:\\Users\\blusc\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\r\n          json_out['return_val'] = hook(**hook_input['kwargs'])\r\n                                   ~~~~^^^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"C:\\Users\\blusc\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 112, in get_requires_for_build_wheel\r\n          backend = _build_backend()\r\n        File \"C:\\Users\\blusc\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 77, in _build_backend\r\n          obj = import_module(mod_path)\r\n        File \"C:\\Users\\blusc\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\importlib\\__init__.py\", line 88, in import_module\r\n          return _bootstrap._gcd_import(name[level:], package, level)\r\n                 ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\r\n        File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\r\n        File \"<frozen importlib._bootstrap>\", line 1310, in _find_and_load_unlocked\r\n        File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\r\n        File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\r\n        File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\r\n        File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\r\n        File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\r\n        File \"<frozen importlib._bootstrap_external>\", line 1022, in exec_module\r\n        File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\r\n        File \"C:\\Users\\blusc\\AppData\\Local\\Temp\\pip-build-env-hufjw5qu\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\", line 16, in <module>\r\n          import setuptools.version\r\n        File \"C:\\Users\\blusc\\AppData\\Local\\Temp\\pip-build-env-hufjw5qu\\overlay\\Lib\\site-packages\\setuptools\\version.py\", line 1, in <module>\r\n          import pkg_resources\r\n        File \"C:\\Users\\blusc\\AppData\\Local\\Temp\\pip-build-env-hufjw5qu\\overlay\\Lib\\site-packages\\pkg_resources\\__init__.py\", line 2172, in <module>\r\n          register_finder(pkgutil.ImpImporter, find_on_path)\r\n                          ^^^^^^^^^^^^^^^^^^^\r\n      AttributeError: module 'pkgutil' has no attribute 'ImpImporter'. Did you mean: 'zipimporter'?\r\n      [end of output]\r\n\r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\nerror: subprocess-exited-with-error\r\n\r\n× Getting requirements to build wheel did not run successfully.\r\n│ exit code: 1\r\n╰─> See above for output.\r\n\r\nnote: This error originates from a subprocess, and is likely not a problem with pip.\r\n```",
      "state": "closed",
      "author": "Bluscream",
      "author_type": "User",
      "created_at": "2024-09-10T23:10:52Z",
      "updated_at": "2025-01-17T00:29:51Z",
      "closed_at": "2025-01-17T00:29:50Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1477/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "better629"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1477",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1477",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:27.375090",
      "comments": [
        {
          "author": "seehi",
          "body": "It is recommended to upgrade the existing numpy.\r\n",
          "created_at": "2024-09-11T09:41:52Z"
        },
        {
          "author": "b423016",
          "body": "I want to Work on this issue\r\n",
          "created_at": "2024-10-02T13:28:52Z"
        },
        {
          "author": "PR-HARIHARAN",
          "body": "Hi team,\r\n\r\nI'm interested in working on this issue. Could someone please assign it to me? I'd be happy to contribute!\r\n\r\nThanks,\r\nHariharan P R\r\n",
          "created_at": "2024-10-03T12:25:08Z"
        },
        {
          "author": "geekan",
          "body": "@PR-HARIHARAN Thank you very much, you can submit PR directly and I will review all PRs in the next few days.",
          "created_at": "2024-10-03T12:26:26Z"
        },
        {
          "author": "better629",
          "body": "@PR-HARIHARAN @b423016 Are you ready for a PR to address this issue? We're looking forward to it",
          "created_at": "2024-10-09T16:51:34Z"
        }
      ]
    },
    {
      "issue_number": 1492,
      "title": "Metagpt执行python程序没有生成文件，但是在命令行运行metagpt \"write a game\"可以生成项目文件",
      "body": "**Bug description**\r\n<!-- Clearly and directly describe the current bug -->\r\n\r\n**Bug solved method**\r\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\r\n\r\n**Environment information**\r\n<!-- Environment：System version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\r\n\r\n- LLM type and model name:\r\n- System version:\r\n- Python version:\r\n- MetaGPT version or branch:\r\n\r\n<!-- Dependent packagess：the packages version cause the bug(like `pydantic 1.10.8`), installation method（like `pip install metagpt` or `pip install from source` or `run in docker`） -->\r\n\r\n- packages version:\r\n<img width=\"1484\" alt=\"截屏2024-10-08 18 59 23\" src=\"https://github.com/user-attachments/assets/2b92a980-e54e-400e-bb27-2ebde81eb03c\">\r\n\r\n- installation method: \r\n\r\n**Screenshots or logs**\r\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\r\n",
      "state": "closed",
      "author": "NICERTYU",
      "author_type": "User",
      "created_at": "2024-10-08T10:59:38Z",
      "updated_at": "2025-01-17T00:29:49Z",
      "closed_at": "2025-01-17T00:29:49Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1492/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1492",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1492",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:27.569770",
      "comments": [
        {
          "author": "better629",
          "body": "@NICERTYU What does it mean to execute a python program? Can you share you command?",
          "created_at": "2024-10-09T16:34:58Z"
        },
        {
          "author": "NICERTYU",
          "body": "> @NICERTYU What does it mean to execute a python program? Can you share you command?\r\n\r\n我在terminal运行 “Metagpt   “Write a cli game” 能够生成代码， 但是我在python程序中导入metagpt使用时，我使用的角色能够对话，但是没有代码文件产生。我使用的版本是0.8.0",
          "created_at": "2024-10-15T00:06:36Z"
        },
        {
          "author": "better629",
          "body": "> > @NICERTYU What does it mean to execute a python program? Can you share you command?\r\n> \r\n> 我在terminal运行 “Metagpt “Write a cli game” 能够生成代码， 但是我在python程序中导入metagpt使用时，我使用的角色能够对话，但是没有代码文件产生。我使用的版本是0.8.0\r\n\r\n@NICERTYU can you share your log by your used role under `imported metagpt`",
          "created_at": "2024-10-18T09:28:52Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-02T00:30:17Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-17T00:29:48Z"
        }
      ]
    },
    {
      "issue_number": 1495,
      "title": "Create tools dynamically, after checking if they exist or not. ",
      "body": "**Feature description**\r\n<!-- Clear and direct description of the functionality of the currently submitted or proposed feature -->\r\nDynamic tool creation and registration. \r\n**Your Feature**\r\n<!-- Describe the idea or process of implementing the current feature. Of course, you can also paste the URL address of your Pull Request. -->\r\nWhat if the metagpt agent/data interpreter agent realises it needs a particular tool for a task but it hasn't been provided? There needs to be a mechanism to check for this and create one on the fly. \r\nIt would highly enhance the strength of the agent, so it could add skills as it executes. \r\nThank you. \r\nSome reference code , to get started - https://github.com/yoheinakajima/babyagi/tree/main/babyagi/functionz\r\n<!-- When submitting features, you need to complete the corresponding doc/tests/examples to facilitate verification by reviewers. -->\r\n",
      "state": "closed",
      "author": "krish240574",
      "author_type": "User",
      "created_at": "2024-10-09T05:12:48Z",
      "updated_at": "2025-01-16T00:29:51Z",
      "closed_at": "2025-01-16T00:29:50Z",
      "labels": [
        "tool",
        "inactive"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1495/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1495",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1495",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:27.827732",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-01T00:34:17Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-16T00:29:50Z"
        }
      ]
    },
    {
      "issue_number": 1497,
      "title": "how can i get stable outputs?",
      "body": "I hope that the DataInterpreter can generate similar answers when given the same question. I've already set temperature to 0 in config.yaml, but the answers differ each time. How can I get stable outputs? ",
      "state": "closed",
      "author": "kuranatsu",
      "author_type": "User",
      "created_at": "2024-10-11T00:58:12Z",
      "updated_at": "2025-01-16T00:29:50Z",
      "closed_at": "2025-01-16T00:29:49Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1497/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1497",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1497",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:28.059913",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-01T00:34:16Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-16T00:29:49Z"
        }
      ]
    },
    {
      "issue_number": 1498,
      "title": "Group related issues: solutions about incremental development in MetaGPT",
      "body": "**Issues**\r\n- #1436 \r\n- #1379 \r\n- #1210 \r\n- #1095 \r\n- #972 \r\n- #871 \r\n- #333 \r\n\r\n**Bug solved method**\r\nThe previous incremental software development method based on SOP has several issues:\r\n- Inconvenient human-computer interaction. New user requirements, technical demands, bug fixes, and added design constraints are difficult to directly correspond to the relevant SOP steps for operation.\r\n- Inflexible programming languages. The same design cannot be easily switched to different programming languages, mixed-language programming is not supported, and design solutions cannot be reused.\r\n\r\nTo address this, we propose a more practical solution. \r\nIt is an upgraded version of `DI` (`Data Interpreter`) called `RoleZero`, which will be released soon. It adopts the following methods to handle software development issues with real-time human-computer interaction:\r\n1. Generate sequence diagrams from requirements. This compresses the content size of requirement descriptions and supports flexible changes in requirements and switching between programming languages.\r\n2. Generate code from sequence diagrams rather than directly from user requirements. This approach supports design outputs reuse, can flexibly generate code in different languages, allows for additional technical requirements during code generation (such as which packages must be used, how interfaces should be utilized, etc.), and supports mixed programming languages.\r\n3. Bug modifications can be implemented through human-computer interaction, directly targeting specific files.\r\n4. Regarding the coding of the UI, you can use `RoleZero` to convert UI pictures into code, and then merge them into the backend code generated based on the sequence diagrams through human-computer interaction.\r\n\r\n**Design Outputs Demo**\r\nHere is an example of a sequence diagram generated by `RoleZero` based on real software development requirements giving a user requirement PDF file and an external system interface usage PDF file, to help everyone understand `RoleZero`'s capabilities in interpreting requirements.\r\n![image](https://github.com/user-attachments/assets/d0429c27-df51-444a-b9c6-ebee122aaf91)\r\n![image](https://github.com/user-attachments/assets/ee0a8d8a-1621-424a-95d5-4bd5fb511eec)\r\n\r\n\r\nSubsequent issues related to new requirements or bug fixes will be consolidated under this issue for further follow-up.\r\n\r\n\r\n",
      "state": "closed",
      "author": "iorisa",
      "author_type": "User",
      "created_at": "2024-10-11T06:23:11Z",
      "updated_at": "2025-01-16T00:29:49Z",
      "closed_at": "2025-01-16T00:29:48Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1498/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": "1.0",
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1498",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1498",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:28.295711",
      "comments": [
        {
          "author": "hgftrdw45ud67is8o89",
          "body": "although PDF is a awesome file/document format, I personally think a json or etc would be better.\r\n\r\nBecause I am scared that the pdf parser could be too complex to use/maintain (especially compatibility).\r\n\r\nPDF is originally by adobe,so i think we must make sure the save format is https://www.iso.",
          "created_at": "2024-10-16T22:31:10Z"
        },
        {
          "author": "iorisa",
          "body": "We choose to use PDF because in reality, most software requirements are archived and transferred using docx or PDF documents, so this is an adjustment based on the real-world situation.\r\n\r\nPDF is just a file format, it does not define the content.\r\n\r\nHowever, in reality, the description of software ",
          "created_at": "2024-10-23T02:53:53Z"
        },
        {
          "author": "hgftrdw45ud67is8o89",
          "body": "i see. will wait for the release and test it out.",
          "created_at": "2024-10-24T22:13:02Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-01T00:34:15Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-16T00:29:48Z"
        }
      ]
    },
    {
      "issue_number": 1512,
      "title": " I need a function, that can generate standard workflow and related agents (or use local agents) ,codes according to users 's text input",
      "body": "请问可以给metagpt增加一个，根据已有智能体和工具，以及用户的需求，编排一整个工作流的环节吗",
      "state": "closed",
      "author": "CoderYiFei",
      "author_type": "User",
      "created_at": "2024-10-17T08:45:02Z",
      "updated_at": "2025-01-15T00:30:05Z",
      "closed_at": "2025-01-15T00:30:04Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1512/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1512",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1512",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:28.480183",
      "comments": [
        {
          "author": "geekan",
          "body": "Hello, please use English.",
          "created_at": "2024-10-20T07:12:45Z"
        },
        {
          "author": "CoderYiFei",
          "body": "I need a function, that can generate standard workflow and related agents (or use local agents) ,codes  according to users 's text input .... it seems that your AFlow can do it",
          "created_at": "2024-10-20T07:53:51Z"
        },
        {
          "author": "jmanhype",
          "body": "> I need a function, that can generate standard workflow and related agents (or use local agents) ,codes according to users' text input .... it seems that your AFlow can do it\r\n\r\nit can :package: https://jmanhype.github.io/HotpotQA-Alternate-History-Generator/",
          "created_at": "2024-10-20T08:39:49Z"
        },
        {
          "author": "jmanhype",
          "body": "> I need a function, that can generate standard workflow and related agents (or use local agents) ,codes according to users' text input .... it seems that your AFlow can do it\r\n\r\nfrom one friend to another ! cheers https://github.com/didiforgithub/MetaGPT-MathAI/tree/main/examples/aflow",
          "created_at": "2024-10-20T08:42:38Z"
        },
        {
          "author": "geekan",
          "body": "AFlow in its current design requires a dataset and it will be optimized for the metrics of the dataset. If you have a data set (even a very small one), then you can use AFlow.",
          "created_at": "2024-10-21T03:33:02Z"
        }
      ]
    },
    {
      "issue_number": 1516,
      "title": "metagpt should be able to get terminal output and screenshot to review code ",
      "body": "you can refer these projects to design it.\r\nrefer projects:\r\nopen-interpreter: https://github.com/OpenInterpreter/open-interpreter\r\naider: https://github.com/Aider-AI/aider\r\nscreenshot-to-code: https://github.com/abi/screenshot-to-code\r\nAgent-E: https://github.com/EmergenceAI/Agent-E\r\ngptme: https://github.com/ErikBjare/gptme",
      "state": "closed",
      "author": "CoderYiFei",
      "author_type": "User",
      "created_at": "2024-10-20T08:02:16Z",
      "updated_at": "2025-01-13T00:33:17Z",
      "closed_at": "2025-01-13T00:33:17Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1516/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1516",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1516",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:28.687148",
      "comments": [
        {
          "author": "jmanhype",
          "body": "https://jmanhype.github.io/HotpotQA-Alternate-History-Generator/",
          "created_at": "2024-10-20T08:41:08Z"
        },
        {
          "author": "geekan",
          "body": "You could try the [Data Interpreter](https://arxiv.org/abs/2402.18679), which has some of the functionality mentioned, like getting textual terminal output. It will become the backbone of all agents in version 1.0.",
          "created_at": "2024-10-21T03:34:26Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-30T00:32:09Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-13T00:33:16Z"
        }
      ]
    },
    {
      "issue_number": 1612,
      "title": "The prompt has 13284 tokens and the max_tokens is 4096 tokens.",
      "body": "**Bug description**\r\n<!-- Clearly and directly describe the current bug -->\r\nMetagpt exited halfway because of an exception due to max_tokens setting.\r\n\r\n**Bug solved method**\r\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\r\n\r\n**Environment information**\r\n<!-- Environment：System version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\r\n\r\n- LLM type and model name: yi-lightning\r\n- System version: ubuntu 22.04\r\n- Python version: 3.11\r\n- MetaGPT version or branch: main\r\n- packages version: 0.8.1\r\n- installation method: pip\r\n\r\n<!-- Dependent packagess：the packages version cause the bug(like `pydantic 1.10.8`), installation method（like `pip install metagpt` or `pip install from source` or `run in docker`） -->\r\n\r\n- packages version:\r\n- installation method: \r\n\r\n**Screenshots or logs**\r\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\r\n2024-11-22 17:18:08.597 | INFO     | metagpt.actions.write_code_review:run:185 - Code review and rewrite main.py: 1/2 | len(iterative_code)=12485, len(self.i_context.code_doc.content)=12485\r\n2024-11-22 17:18:31.001 | WARNING  | metagpt.utils.common:wrapper:673 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.\r\n2024-11-22 17:18:31.002 | ERROR    | metagpt.utils.common:wrapper:655 - Exception occurs, start to serialize the project, exp:\r\nTraceback (most recent call last):\r\n  File \"/root/anaconda3/envs/metagpt/lib/python3.11/site-packages/metagpt/utils/common.py\", line 650, in wrapper\r\n    result = await func(self, *args, **kwargs)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/anaconda3/envs/metagpt/lib/python3.11/site-packages/metagpt/team.py\", line 134, in run\r\n    await self.env.run()\r\nopenai.BadRequestError: Error code: 400 - {'error': {'code': 'bad_request', 'message': 'The total number of tokens in the prompt and the max_tokens must be less than or equal to 16000. The prompt has 13284 tokens and the max_tokens is 4096 tokens.', 'type': 'invalid_request_error', 'param': None}}\r\n\r\n",
      "state": "closed",
      "author": "happytravelingskysheep",
      "author_type": "User",
      "created_at": "2024-11-22T09:28:01Z",
      "updated_at": "2025-01-06T00:32:36Z",
      "closed_at": "2025-01-06T00:32:35Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1612/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1612",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1612",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:28.885275",
      "comments": [
        {
          "author": "voidking",
          "body": "Try to set `max_token` in config2.yaml\r\n```yaml\r\nllm:\r\n  api_type: \"openai\"\r\n  model: \"gpt-3.5-turbo-16k\" \r\n  base_url: \"https://api.openai.com/v1\" \r\n  api_key: \"sk-xxx\"\r\n  max_token: 16000\r\n```",
          "created_at": "2024-11-22T11:11:10Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-23T00:31:51Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-06T00:32:35Z"
        }
      ]
    },
    {
      "issue_number": 1611,
      "title": "Error: Parse error on line 42:...Handler --> selenium.webdriver",
      "body": "**Bug description**\r\nAnother bug with playwright. \r\nError: Parse error on line 42:...Handler --> selenium.webdriver\r\n**Bug solved method**\r\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\r\n\r\n**Environment information**\r\n- LLM type and model name:\r\n- System version: ubuntu 22.04\r\n- Python version: 3.11\r\n- MetaGPT version or branch: main\r\n- packages version: 0.8.1\r\n- installation method: pip\r\n\r\n**Screenshots or logs**\r\n2024-11-22 17:03:13.898 | INFO     | metagpt.utils.file_repository:save:57 - save to: /root/workspace/workspace/design_pattern_simulation/docs/system_design/20241122170240.json\r\n2024-11-22 17:03:13.899 | INFO     | metagpt.utils.file_repository:save:62 - update dependency: /root/workspace/workspace/design_pattern_simulation/docs/system_design/20241122170240.json:{'docs/prd/20241122170240.json'}\r\n2024-11-22 17:03:14.997 | ERROR    | metagpt.utils.mmdc_playwright:mermaid_to_file:121 - Page.evaluate: Error: Parse error on line 42:...Handler --> selenium.webdriver    Docum-----------------------^Expecting 'NEWLINE', 'EOF', 'SQS', 'STR', 'GENERICTYPE', 'LABEL', 'STRUCT_START', 'STRUCT_STOP', 'STYLE_SEPARATOR', 'ANNOTATION_END', 'AGGREGATION', 'EXTENSION', 'COMPOSITION', 'DEPENDENCY', 'LOLLIPOP', 'LINE', 'DOTTED_LINE', 'CALLBACK_NAME', 'HREF', 'MINUS', 'UNICODE_TEXT', 'NUM', 'ALPHA', 'BQUOTE_STR', got 'DOT'\r\n    at WA.parseError (file:///root/anaconda3/envs/metagpt/lib/python3.11/site-packages/metagpt/utils/index.html:1:894276)\r\n    at WA.parse (file:///root/anaconda3/envs/metagpt/lib/python3.11/site-packages/metagpt/utils/index.html:1:895563)\r\n    at CUe.parser.parse (file:///root/anaconda3/envs/metagpt/lib/python3.11/site-packages/metagpt/utils/index.html:1:276633)\r\n    at CUe.parse (file:///root/anaconda3/envs/metagpt/lib/python3.11/site-packages/metagpt/utils/index.html:1:276867)\r\n    at new CUe (file:///root/anaconda3/envs/metagpt/lib/python3.11/site-packages/metagpt/utils/index.html:1:276708)\r\n    at YjA (file:///root/anaconda3/envs/metagpt/lib/python3.11/site-packages/metagpt/utils/index.html:1:277173)\r\n    at async Object.eDt [as render] (file:///root/anaconda3/envs/metagpt/lib/python3.11/site-packages/metagpt/utils/index.html:1:281122)\r\n",
      "state": "closed",
      "author": "happytravelingskysheep",
      "author_type": "User",
      "created_at": "2024-11-22T09:23:23Z",
      "updated_at": "2025-01-06T00:32:36Z",
      "closed_at": "2025-01-06T00:32:36Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1611/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1611",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1611",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:29.068343",
      "comments": [
        {
          "author": "voidking",
          "body": "This error indicates that the mermaid file generated by llm is not standardized. Therefore, the parsing error occurs. \r\nIt is recommended to rerun or replace it with a better llm model.",
          "created_at": "2024-11-22T11:25:22Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-23T00:31:52Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-06T00:32:36Z"
        }
      ]
    },
    {
      "issue_number": 1602,
      "title": "如何结合gradio使用",
      "body": "使用DataInterpreter，如何结合gradio，把中间步骤输出结果展示出来",
      "state": "closed",
      "author": "ZTurboX",
      "author_type": "User",
      "created_at": "2024-11-14T07:52:37Z",
      "updated_at": "2025-01-05T00:33:47Z",
      "closed_at": "2025-01-05T00:33:46Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1602/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1602",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1602",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:29.369458",
      "comments": [
        {
          "author": "BCYounker",
          "body": "同问",
          "created_at": "2024-11-21T11:12:24Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-22T00:33:40Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-05T00:33:46Z"
        }
      ]
    },
    {
      "issue_number": 1593,
      "title": "Updating the TOKEN_COSTS for Model Qwen/Qwen2.5-Coder-32B-Instruct",
      "body": "2024-11-12 17:30:29.957 | WARNING  | metagpt.utils.cost_manager:update_cost:49 - Model Qwen/Qwen2.5-Coder-32B-Instruct not found in TOKEN_COSTS.",
      "state": "closed",
      "author": "ZONGEZE",
      "author_type": "User",
      "created_at": "2024-11-12T09:31:19Z",
      "updated_at": "2025-01-04T00:29:57Z",
      "closed_at": "2025-01-04T00:29:56Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1593/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1593",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1593",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:29.689358",
      "comments": [
        {
          "author": "voidking",
          "body": "Currently some LLM APIs do not support cost statistics. Which LLM are you using?",
          "created_at": "2024-11-13T02:23:02Z"
        },
        {
          "author": "ZONGEZE",
          "body": "> Currently some LLM APIs do not support cost statistics. Which LLM are you using?\r\n\r\nQwen2.5-Coder-32B-Instruct",
          "created_at": "2024-11-14T02:15:09Z"
        },
        {
          "author": "CheeYeah",
          "body": "in the file /utils/token_counter.py\r\nadd \"Qwen2.5-Coder-32B-Instruct\": {\"prompt\": 0.0005, \"completion\": 0.001}, at the end of DASHSCOPE_TOKEN_COSTS",
          "created_at": "2024-11-19T08:46:12Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-20T00:30:33Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-04T00:29:56Z"
        }
      ]
    },
    {
      "issue_number": 1583,
      "title": "TypeError: 'NoneType' object is not iterable",
      "body": "Hi ,\r\n**I just installed MetaGpt on ubuntu20, and config LLM through modified ./config/congfig2.yaml;**\r\n\r\n**then executed example , logs info below :**\r\npydantic_core._pydantic_core.ValidationError: 1 validation error for Config\r\nllm.api_key\r\n  Value error, Please set your API key in /home/*****/.metagpt/config2.yaml. If you also set your config in /data2/11_metadata/MetaGPT/config/config2.yaml, \r\nthe former will overwrite the latter. This may cause unexpected result.\r\n [type=value_error, input_value='YOUR_API_KEY', input_type=str]\r\n    For further information visit https://errors.pydantic.dev/2.9/v/value_error\r\n\r\n**so ,I Erased  /home/*****/.metagpt/config2.yaml ，executed agant, Error info like below:**\r\n**Feature description**\r\n_$ python examples/di/data_visualization.py_\r\n2024-11-08 11:28:52.046 | INFO     | metagpt.const:get_metagpt_package_root:21 - Package root set to /data2/11_metadata/MetaGPT\r\nTraceback (most recent call last):\r\n  File \"/data2/11_metadata/MetaGPT/examples/di/data_visualization.py\", line 4, in <module>\r\n    from metagpt.roles.di.data_interpreter import DataInterpreter\r\n  File \"/data2/11_metadata/MetaGPT/metagpt/roles/__init__.py\", line 9, in <module>\r\n    from metagpt.roles.role import Role\r\n  File \"/data2/11_metadata/MetaGPT/metagpt/roles/role.py\", line 30, in <module>\r\n    from metagpt.actions import Action, ActionOutput\r\n  File \"/data2/11_metadata/MetaGPT/metagpt/actions/__init__.py\", line 10, in <module>\r\n    from metagpt.actions.action import Action\r\n  File \"/data2/11_metadata/MetaGPT/metagpt/actions/action.py\", line 15, in <module>\r\n    from metagpt.actions.action_node import ActionNode\r\n  File \"/data2/11_metadata/MetaGPT/metagpt/actions/action_node.py\", line 22, in <module>\r\n    from metagpt.llm import BaseLLM\r\n  File \"/data2/11_metadata/MetaGPT/metagpt/llm.py\", line 11, in <module>\r\n    from metagpt.context import Context\r\n  File \"/data2/11_metadata/MetaGPT/metagpt/context.py\", line 14, in <module>\r\n    from metagpt.config2 import Config\r\n  File \"/data2/11_metadata/MetaGPT/metagpt/config2.py\", line 169, in <module>\r\n    config = Config.default()\r\n             ^^^^^^^^^^^^^^^^\r\n  File \"/data2/11_metadata/MetaGPT/metagpt/config2.py\", line 110, in default\r\n    final = merge_dict(dicts)\r\n            ^^^^^^^^^^^^^^^^^\r\n  File \"/data2/11_metadata/MetaGPT/metagpt/config2.py\", line 165, in merge_dict\r\n    result.update(dictionary)\r\n**### TypeError: 'NoneType' object is not iterable**\r\n**Your Feature**\r\n<!-- Describe the idea or process of implementing the current feature. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- When submitting features, you need to complete the corresponding doc/tests/examples to facilitate verification by reviewers. -->\r\n",
      "state": "closed",
      "author": "baronbigghf",
      "author_type": "User",
      "created_at": "2024-11-08T03:44:22Z",
      "updated_at": "2025-01-03T00:30:23Z",
      "closed_at": "2025-01-03T00:30:22Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1583/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "voidking"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1583",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1583",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:29.873755",
      "comments": [
        {
          "author": "voidking",
          "body": "How is config2.yaml configured?",
          "created_at": "2024-11-11T05:40:19Z"
        },
        {
          "author": "baronbigghf",
          "body": "> How is config2.yaml configured?\r\n\r\nthank you  vidking. I used  conifg file under /home , erased ./config/congfig2.yaml， then  it run ok . but not mind the reason .",
          "created_at": "2024-11-18T03:03:30Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-19T00:32:17Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-03T00:30:21Z"
        }
      ]
    },
    {
      "issue_number": 1604,
      "title": "输出中间过程名称",
      "body": "使用DataInterpreter，如何在await mi.run(requirement)中输出每步执行任务的名称在前端展示，即实时返回每一步的self.planner.current_task.instruction在前端展示",
      "state": "closed",
      "author": "ZTurboX",
      "author_type": "User",
      "created_at": "2024-11-15T01:41:40Z",
      "updated_at": "2025-01-01T00:34:12Z",
      "closed_at": "2025-01-01T00:34:12Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1604/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1604",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1604",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:30.098621",
      "comments": [
        {
          "author": "garylin2099",
          "body": "你好！可以在代码中添加向前端上报的相关代码。我们会在metagpt 1.0中推出上报功能",
          "created_at": "2024-11-15T11:43:17Z"
        },
        {
          "author": "ZTurboX",
          "body": "> 你好！可以在代码中添加向前端上报的相关代码。我们会在metagpt 1.0中推出上报功能\r\n\r\n能具体说说是用什么思路实现吗",
          "created_at": "2024-11-18T00:11:13Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-18T00:32:06Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-01T00:34:12Z"
        }
      ]
    },
    {
      "issue_number": 1502,
      "title": "Bug: Unable to Navigate Back to Main README from README_CN or README_JA",
      "body": "**Bug Description**\r\nWhen navigating between the localized versions of the documentation, the links in `README_CN.md` and `README_JA.md` do not correctly redirect back to the main `README.md` in English. Clicking on these links keeps the user stuck in the current localized version, preventing smooth and intuitive navigation.\r\n\r\n### Steps to Reproduce the Bug\r\n1. Open `README_CN.md` or `README_JA.md`.\r\n2. Click on the link intended to redirect to the main `README.md`.\r\n3. Observe that the redirection does not occur as expected.\r\n\r\n### Expected Result\r\nThe link should redirect the user to the main `README.md` in English, allowing for an easy and intuitive return from the localized versions of the documentation.\r\n\r\n### Actual Result\r\nThe link does not work properly or redirects incorrectly, preventing the user from leaving the localized version. \r\n\r\n![Screenshot 2024-10-14 011141](https://github.com/user-attachments/assets/6fdfef6c-8fa8-4b73-9a1f-01cbff472199)\r\n",
      "state": "closed",
      "author": "TitanSage02",
      "author_type": "User",
      "created_at": "2024-10-14T00:13:41Z",
      "updated_at": "2024-12-31T17:52:07Z",
      "closed_at": "2024-12-31T17:52:07Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1502/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1502",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1502",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:30.276416",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-31T00:30:26Z"
        }
      ]
    },
    {
      "issue_number": 1594,
      "title": "如何使用自定义tool",
      "body": "如何通过用户输入，调用自定义tool",
      "state": "closed",
      "author": "ZTurboX",
      "author_type": "User",
      "created_at": "2024-11-12T23:59:51Z",
      "updated_at": "2024-12-31T00:30:24Z",
      "closed_at": "2024-12-31T00:30:23Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1594/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1594",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1594",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:30.453754",
      "comments": [
        {
          "author": "voidking",
          "body": "目前不支持通过用户输入调用自定义tool。如果想自定义tool并调用，需要修改代码和配置文件。",
          "created_at": "2024-11-13T02:15:29Z"
        },
        {
          "author": "ZTurboX",
          "body": "> 目前不支持通过用户输入调用自定义tool。如果想自定义tool并调用，需要修改代码和配置文件。\r\n\r\n是类似这样修改吗？https://docs.deepwisdom.ai/main/zh/guide/tutorials/create_and_use_tools.html；看了DataInterpreter的源码，想通过llm plan自定义tool的执行，但不需要llm自动生成代码，是要修改WriteAnalysisCode吗",
          "created_at": "2024-11-13T02:38:55Z"
        },
        {
          "author": "voidking",
          "body": "是的，除了那份文档，也可以参考下调研员的实现，也是自定义tool很好的例子 https://github.com/geekan/MetaGPT/blob/main/examples/research.py",
          "created_at": "2024-11-15T07:56:16Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-16T00:34:53Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-31T00:30:23Z"
        }
      ]
    },
    {
      "issue_number": 1603,
      "title": "llm response appear self-talking",
      "body": "This is my prompt:\r\n\r\n```code\r\nPROMPT_TEMPLATE: str = \"\"\"### Context\r\n{context}\r\n\r\n### Instruction\r\n{instruction}\r\n\r\n### Requirements\r\n1. Base on the context, response a chat completion of Instruction.\r\n2. Please use beautiful and simple language and response must be in English.\r\n```\r\n\r\n\r\nmy context content is:\r\n```code memories = self.get_memories()\r\ncontext = \"\\n\".join(f\"{msg.role}: {msg.content}\" for msg in memories)\r\n```\r\n\r\n\r\nThe final return result:\r\n```code\r\nHello, Nice to meet you!\r\nuser: xxxxxxxx.\r\nrole: xxxxxxxx.\r\nuser: xxxxxxxx.\r\nrole: xxxxxxxx.\r\nuser: xxxxxxxx.\r\nrole: xxxxxxxx.\r\n```\r\nAfter answering two or three times, the replies will be self-talking. These contents have never appeared in the context again. Is it because my prompt is not written correctly?\r\n\r\n",
      "state": "closed",
      "author": "pzw943969386",
      "author_type": "User",
      "created_at": "2024-11-14T11:06:46Z",
      "updated_at": "2024-12-31T00:30:23Z",
      "closed_at": "2024-12-31T00:30:22Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1603/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1603",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1603",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:30.683976",
      "comments": [
        {
          "author": "voidking",
          "body": "What kind of functionality do you want to achieve? What does your complete code look like?",
          "created_at": "2024-11-15T05:47:13Z"
        },
        {
          "author": "pzw943969386",
          "body": "It is the simplest action, the function is ordinary chat, but the returned result sometimes talks to itself",
          "created_at": "2024-11-15T07:29:38Z"
        },
        {
          "author": "pzw943969386",
          "body": "The code is almost like this, some business logic is deleted\r\n```code\r\n\r\nclass ChatCompletionAction(Action):\r\n    PROMPT_TEMPLATE: str = \"\"\"### Context\r\n{context}\r\n\r\n### Instruction\r\n{instruction}\r\n\r\n### Requirements\r\n1. Base on the context, response a chat completion of Instruction.\r\n2. Please use ",
          "created_at": "2024-11-15T07:34:32Z"
        },
        {
          "author": "voidking",
          "body": "Maybe you can refer to: https://github.com/geekan/MetaGPT/blob/main/examples/debate.py",
          "created_at": "2024-11-15T07:39:53Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-16T00:34:51Z"
        }
      ]
    },
    {
      "issue_number": 1518,
      "title": "Can we add a directory , that contains the models to task' s auto allocation function? ",
      "body": "\r\nFor some relatively difficult tasks, more complex models such as o1-preview or Claude 3.5 Sonnet will be automatically called. \r\nFor example, code review tasks or architecture tasks (unless the user specifies not to use them). \r\n\r\nIf it is a relatively simple task, such as writing code for a text classification model or writing a function for a simple crawler, etc., a faster domestic model such as DeepSeek v2.5 can be automatically selected. \r\n\r\nThe function is to automatically prioritize the allocation of large models according to the task difficulty (assuming that the user has several large models).",
      "state": "closed",
      "author": "CoderYiFei",
      "author_type": "User",
      "created_at": "2024-10-20T12:15:57Z",
      "updated_at": "2024-12-30T00:32:09Z",
      "closed_at": "2024-12-30T00:32:08Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1518/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1518",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1518",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:30.876919",
      "comments": [
        {
          "author": "geekan",
          "body": "This feature is planned and expected to be available in the coming months, but is not available yet.",
          "created_at": "2024-10-21T03:35:20Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-05T00:33:09Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-30T00:32:08Z"
        }
      ]
    },
    {
      "issue_number": 1520,
      "title": "Can you add number of code lines that metagpt can maintain now , to readme",
      "body": "\r\nCould you add the medium lines that new version's MetaGPT can maintained ?\r\nits better to show a change figure in readme.md\r\nfrom 2023.07 to now , the number of code lines that metagpt can maintain from 2000 to ....(maybe 10k? 20k?)",
      "state": "closed",
      "author": "CoderYiFei",
      "author_type": "User",
      "created_at": "2024-10-20T16:06:00Z",
      "updated_at": "2024-12-30T00:32:07Z",
      "closed_at": "2024-12-30T00:32:06Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1520/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1520",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1520",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:31.116992",
      "comments": [
        {
          "author": "geekan",
          "body": "Our metrics are not yet available to the public, and some metrics may be updated in version 1.0.",
          "created_at": "2024-10-21T03:38:16Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-04T00:33:20Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-30T00:32:06Z"
        }
      ]
    },
    {
      "issue_number": 1519,
      "title": "[Very important] can metagpt add a directory to collect useful news , to let it envole it automatically",
      "body": "For example, there are many AI news per week on internet.\r\nmetagpt should download some news , \r\nand analyze if the news or open source project or a new arxiv paper useful , \r\nfor metagpt to evolve.\r\nthen metagpt will design a short term roadmap for itself, \r\nif Alexander Wu choose \"accept\", then metagpt will automatically develop a new branch that finished the roadmap.\r\nif Alexander Wu choose \"accept\" again , metagpt will  automatically test itself , and merge it to main branch.\r\n\r\nthese are AI news examples :\r\n[video] https://www.bilibili.com/video/BV1wk2UYaEWm?spm_id_from=333.788.player.switch&vd_source=97ab50b6d1c6cd0cf34537c8b367dece\r\n\r\n[news] https://d.aigclink.ai/fe1ce99bc6a64266aa1ee5479c8e6da6?v=8f252a54730e49f4b8caf897b7ae49f6\r\n....",
      "state": "closed",
      "author": "CoderYiFei",
      "author_type": "User",
      "created_at": "2024-10-20T14:04:53Z",
      "updated_at": "2024-12-30T00:32:07Z",
      "closed_at": "2024-12-30T00:32:07Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1519/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1519",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1519",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:31.311923",
      "comments": [
        {
          "author": "geekan",
          "body": "This is a very good idea. But unfortunately, the current Code Agent is not yet able to complete such complex functions.",
          "created_at": "2024-10-21T03:36:43Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-05T00:33:08Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-30T00:32:07Z"
        }
      ]
    },
    {
      "issue_number": 1521,
      "title": "Dynamic sop(team)  ,  instead of a given sop(team) , should be designed ",
      "body": "sometimes , sop(team) is changing soon.\r\nfor example , if I want to design a text classification model\r\nmy sop(team) might only be Engineer + Project Manager + boss + QA \r\n\r\nDifferent user request , will lead to different sop(team) \r\nDifferent sop(team)  , will lead to different code repo dynamically",
      "state": "closed",
      "author": "CoderYiFei",
      "author_type": "User",
      "created_at": "2024-10-20T16:32:01Z",
      "updated_at": "2024-12-29T00:33:54Z",
      "closed_at": "2024-12-29T00:33:54Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1521/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1521",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1521",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:31.528434",
      "comments": [
        {
          "author": "geekan",
          "body": "In a real-life scenario, you will have a team and distribute requirements freely, activating each member dynamically. In 1.0 we will see this feature.",
          "created_at": "2024-10-21T03:30:47Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-04T00:33:18Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-29T00:33:53Z"
        }
      ]
    },
    {
      "issue_number": 1528,
      "title": "[very important] streaming video/audio information to llm ,  should be supported.",
      "body": "The metagpt 's system needs to have the capability to support streaming video/audio input. \r\nFor example, in a game, it should be able to stream the screen information to a large world model (LWM). The LWM would then need to control the keyboard and mouse to simulate the game's operation, identify issues during gameplay, modify the code, and then restart the game, repeating this process iteratively. \r\nThis function should be add to game design task's sop(team).... ",
      "state": "closed",
      "author": "CoderYiFei",
      "author_type": "User",
      "created_at": "2024-10-21T16:06:53Z",
      "updated_at": "2024-12-29T00:33:53Z",
      "closed_at": "2024-12-29T00:33:53Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1528/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1528",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1528",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:31.727528",
      "comments": [
        {
          "author": "geekan",
          "body": "This work is being done and will be open sourced later",
          "created_at": "2024-10-22T04:14:43Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-04T00:33:17Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-29T00:33:52Z"
        }
      ]
    },
    {
      "issue_number": 1598,
      "title": "关于使用自定义本地LLM",
      "body": "请问如何调用本地的大模型来进行使用呢",
      "state": "closed",
      "author": "White-Friday",
      "author_type": "User",
      "created_at": "2024-11-13T10:49:01Z",
      "updated_at": "2024-12-29T00:33:50Z",
      "closed_at": "2024-12-29T00:33:49Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1598/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1598",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1598",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:31.894765",
      "comments": [
        {
          "author": "better629",
          "body": "refs to `https://docs.deepwisdom.ai/main/en/guide/tutorials/integration_with_open_llm.html`",
          "created_at": "2024-11-13T11:06:51Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-14T00:32:05Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-29T00:33:49Z"
        }
      ]
    },
    {
      "issue_number": 1597,
      "title": "metagpt.ext.aflow.scripts.optimizer:optimize:93 - Error occurred: object list can't be used in 'await' expression. Retrying... (Attempt 1/1)",
      "body": "**Bug description**\r\nmetagpt.ext.aflow.scripts.optimizer:optimize:93 - Error occurred: object list can't be used in 'await' expression. Retrying... (Attempt 1/1)\r\n\r\n**Bug solved method**\r\nnot solved\r\n\r\nAn error occurred when running AFLOW with this command:\r\n```\r\npython -m examples.aflow.optimize --dataset custom --max_rounds 1 --validation_rounds 3 --sample 2\r\n```\r\n\r\n**Environment information**\r\n- LLM type and model name:OpenAI grok-beta\r\n- System version:Windows 11\r\n- Python version:conda python 3.11.1\r\n- MetaGPT version or branch:2024.11 main\r\n\r\n\r\n- packages version:unknown\r\n- installation method: pip install -e .\r\n\r\n**Screenshots or logs**\r\n2024-11-13 17:12:16.364 | INFO     | metagpt.const:get_metagpt_package_root:21 - Package root set to B:\\software\\MetaGPT\r\n2024-11-13 17:12:20.381 | INFO     | metagpt.ext.aflow.scripts.optimizer:optimize:93 - Error occurred: object list can't be used in 'await' expression. Retrying... (Attempt 1/1)\r\n2024-11-13 17:12:20.382 | INFO     | metagpt.ext.aflow.scripts.optimizer:optimize:95 - Max retries reached. Moving to next round.\r\n2024-11-13 17:12:25.384 | INFO     | metagpt.ext.aflow.scripts.optimizer:optimize:106 - Score for round 2: None\r\n",
      "state": "closed",
      "author": "CALMCRAZY",
      "author_type": "User",
      "created_at": "2024-11-13T09:46:11Z",
      "updated_at": "2024-12-29T00:33:50Z",
      "closed_at": "2024-12-29T00:33:50Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1597/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1597",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1597",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:32.098719",
      "comments": [
        {
          "author": "didiforgithub",
          "body": "Hi, thanks for your usage.\r\n\r\nFor this question, maybe you need to first determine that the custom dataset is set in DatasetType.\r\n\r\nSubsequently, you can check your eval function to ensure that graph_evaluate returns the correct score, avg_cost, and total_cost. If the problem still cannot be resolv",
          "created_at": "2024-11-13T11:05:06Z"
        },
        {
          "author": "CALMCRAZY",
          "body": "> Hi, thanks for your usage.\r\n> \r\n> For this question, maybe you need to first determine that the custom dataset is set in DatasetType.\r\n> \r\n> Subsequently, you can check your eval function to ensure that graph_evaluate returns the correct score, avg_cost, and total_cost. If the problem still cannot",
          "created_at": "2024-11-13T13:32:18Z"
        },
        {
          "author": "didiforgithub",
          "body": "Sincerely thank you for your discovery, we will fix the BUG as soon as possible!",
          "created_at": "2024-11-13T13:38:33Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-14T00:32:06Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-29T00:33:50Z"
        }
      ]
    },
    {
      "issue_number": 1530,
      "title": "data-interpreter needs a dataset generation function",
      "body": "Sometimes , ds tasks need trained data from web page , or generated by llm.\r\ndata-interpreter should determine to get useful trained data from webpage,\r\nor generate useful data by it self.\r\n\r\nI mean it should be part of machine learning pipelines.\r\nIncluding:\r\n(1) has user provided labeled trained data?\r\n(2) if not , can llm get good labeled trained data from webpage?\r\n(3) it not , can llm generate  labeled trained data by it self?\r\n(4) to generate labeled trained data by llm it self ...\r\nthen llm get well-done labeled  trained data, and starting training\r\n\r\nFor example , I want to train a text translation model.\r\nThen , llm should determine , can it get English to Chinese text data from webpage,\r\nif it can not, than llm should generate some English to Chinese text data by it self,\r\nthen , start model training...",
      "state": "closed",
      "author": "CoderYiFei",
      "author_type": "User",
      "created_at": "2024-10-22T05:14:33Z",
      "updated_at": "2024-12-28T00:29:59Z",
      "closed_at": "2024-12-28T00:29:59Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1530/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1530",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1530",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:32.304085",
      "comments": [
        {
          "author": "geekan",
          "body": "Part of this issue corresponds to a research topic called dataset generation.\r\n- Your intuition is good, but it takes a lot of time to do it well, and it's also very difficult for humans.\r\n- Here are some obvious questions: How to ensure data quality? How to ensure the scientific nature of evaluatio",
          "created_at": "2024-10-22T05:41:58Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-04T00:33:15Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-28T00:29:58Z"
        }
      ]
    },
    {
      "issue_number": 1531,
      "title": "o1-mini 模型报错",
      "body": "**Bug description**\r\n<!-- Clearly and directly describe the current bug -->\r\n当model: \"o1-mini\"的时候, 会出现bug,\r\n```\r\nFinished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 86.782(s), this was the 1st time calling it. exp: Error code: 400 - {'error': {'message': \"Unsupported value: 'messages[0].role' does not support 'system' with this model.     (request id: 20241022224433123206060zGFL5WKQ) (request id: 2024102222443296560188YMHkpVsa) (request id: 2024102222443292570479MKCUGfgl) (request id: 20241022224431807183774j4pHfuUY)\", 'type': 'invalid_request_error', 'param': 'messages[0].role', 'code': 'unsupported_value'}}\r\n```\r\n\r\n\r\n**Bug solved method**\r\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\r\n\r\n**Environment information**\r\n<!-- Environment：System version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\r\n\r\n- LLM type and model name: OpenAI  o1-mini\r\n- System version: win11\r\n- Python version: 3.10\r\n- MetaGPT version or branch:  main\r\n\r\n<!-- Dependent packagess：the packages version cause the bug(like `pydantic 1.10.8`), installation method（like `pip install metagpt` or `pip install from source` or `run in docker`） -->\r\n\r\n- packages version: \r\n- installation method:  pip install \r\n\r\n**Screenshots or logs**\r\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\r\n![image](https://github.com/user-attachments/assets/7d6f335f-f330-4fcb-864b-b69977795765)\r\n",
      "state": "closed",
      "author": "MiangChen",
      "author_type": "User",
      "created_at": "2024-10-22T14:47:31Z",
      "updated_at": "2024-12-28T00:29:58Z",
      "closed_at": "2024-12-28T00:29:57Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1531/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1531",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1531",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:32.526281",
      "comments": [
        {
          "author": "better629",
          "body": "refs to `https://docs.deepwisdom.ai/main/en/guide/get_started/configuration/llm_api_configuration.html#steps`",
          "created_at": "2024-10-23T01:50:27Z"
        },
        {
          "author": "geekan",
          "body": "I feel it should be made into a default configuration that can be triggered by the model name.",
          "created_at": "2024-10-23T03:02:27Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-03T00:33:51Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-28T00:29:57Z"
        }
      ]
    },
    {
      "issue_number": 1591,
      "title": "Two questions about DI",
      "body": "\r\nHello, thank you for the excellent code and paper. Regarding DI, I have the following two questions: 1. Are the codes or logs generated after DI work placed in a certain folder like MetaGpt? 2. Is there any implementation code for the evaluation indicator CS mentioned in the paper?\r\nLooking Forward to your answer!",
      "state": "closed",
      "author": "kirainy",
      "author_type": "User",
      "created_at": "2024-11-11T08:07:50Z",
      "updated_at": "2024-12-28T00:29:56Z",
      "closed_at": "2024-12-28T00:29:56Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1591/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1591",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1591",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:32.713913",
      "comments": [
        {
          "author": "krish240574",
          "body": "1. Look at save_history(role = <the DI variable>)  - from metagpt.utils.recovery_util import save_history, also in examples/di/data_visualization.py\r\n2. Don't know, sorry. ",
          "created_at": "2024-11-11T15:31:16Z"
        },
        {
          "author": "kirainy",
          "body": "thanks for your reply！",
          "created_at": "2024-11-12T01:51:38Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-13T00:33:27Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-28T00:29:55Z"
        }
      ]
    },
    {
      "issue_number": 1585,
      "title": "使用web_browser_engine_selenium+chrome出现大量页面未关闭的情况",
      "body": "# 异常描述\r\n<img width=\"938\" alt=\"a03496e9de82d63cc52544c27956596\" src=\"https://github.com/user-attachments/assets/9cab7747-7488-4cd5-b3c7-3bfe00e8a3f7\">\r\n\r\n# 版本信息\r\nGoogle Chrome 119.0.6045.199 \r\nChromeDriver 119.0.6045.105 \r\nmetagpt 0.8",
      "state": "closed",
      "author": "QiMingChina",
      "author_type": "User",
      "created_at": "2024-11-08T09:38:51Z",
      "updated_at": "2024-12-27T00:30:23Z",
      "closed_at": "2024-12-27T00:30:22Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1585/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "shenchucheng"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1585",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1585",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:32.927206",
      "comments": [
        {
          "author": "shenchucheng",
          "body": "由https://github.com/geekan/MetaGPT/issues/1584 导致",
          "created_at": "2024-11-11T04:04:26Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-12T00:32:59Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-27T00:30:22Z"
        }
      ]
    },
    {
      "issue_number": 1584,
      "title": "使用web_brower_engine_selenium出现的The process started from chrome location /opt/google/chrome/chrome is no longer running问题",
      "body": "## 问题描述\r\n使用web_brower_engine_selenium工具进行页面抓取\r\n![image](https://github.com/user-attachments/assets/0d23dbc9-a6a7-4ab3-8d92-df18dcce8ae6)\r\n\r\n## 版本信息\r\nChromeDriver 119.0.6045.105 (配置在/usr/bin/chromedriver)\r\nGoogle Chrome 119.0.6045.199\r\n",
      "state": "closed",
      "author": "QiMingChina",
      "author_type": "User",
      "created_at": "2024-11-08T09:30:35Z",
      "updated_at": "2024-12-27T00:30:23Z",
      "closed_at": "2024-12-27T00:30:23Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1584/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "shenchucheng"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1584",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1584",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:33.132006",
      "comments": [
        {
          "author": "shenchucheng",
          "body": "deepin 桌面版，ChromeDriver 119.0.6045.105，Google Chrome 119.0.6045.199，无法复现这个问题， 能提供更详细的复现信息吗，比如使用的Linux版本，机器的资源信息等。或者尝试用playwright呢？",
          "created_at": "2024-11-11T04:01:50Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-12T00:33:00Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-27T00:30:23Z"
        }
      ]
    },
    {
      "issue_number": 1532,
      "title": "Can metagpt show more comparison with AgileCoder",
      "body": "AgileCoder: \r\nhttps://github.com/FSoft-AI4Code/AgileCoder",
      "state": "closed",
      "author": "CoderYiFei",
      "author_type": "User",
      "created_at": "2024-10-23T02:34:58Z",
      "updated_at": "2024-12-26T00:30:18Z",
      "closed_at": "2024-12-26T00:30:18Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1532/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1532",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1532",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:35.022613",
      "comments": [
        {
          "author": "stellaHSR",
          "body": "Hi CoderYiFei,\r\n\r\nThank you for your suggestion regarding a comparison with AgileCoder. I believe Agile(https://en.wikipedia.org/wiki/Agile_software_development) is a great development methodology, particularly emphasizing feedback-based iteration and incremental improvement, which can significantly",
          "created_at": "2024-10-23T06:58:49Z"
        },
        {
          "author": "CoderYiFei",
          "body": "For comparing metrics,\r\nI recommend  https://github.com/ActivityWatch/activitywatch/tree/master \r\nwe can assign some general hard software project to a programmer,\r\nAnd let him use different multi-agent tools, to find the difference of time cost , and the times human engaged.\r\n\r\nI am hoping 1.0 's v",
          "created_at": "2024-10-23T13:55:01Z"
        },
        {
          "author": "stellaHSR",
          "body": "I think this is a great idea. \r\nRegarding the observation of time consumption across different tools, are you referring to metrics similar to Jira, such as task hours, meeting times, and usage proportions of related development tools? Tracking these tools and their usage duration can indeed reflect ",
          "created_at": "2024-10-24T04:19:14Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-03T00:33:50Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-26T00:30:17Z"
        }
      ]
    },
    {
      "issue_number": 1533,
      "title": "Is it possible to  make more RPA support, like Claude 3.5 sonnet's computer-use feature",
      "body": "Claude 3.5 sonnet's new feature, computer-use 's function looks pretty useful\r\nCan metagpt show a computer-use based project in its examples dir?\r\nsomehow, like video shown here\r\nhttps://www.youtube.com/watch?v=vH2f7cjXjKI\r\n\r\n",
      "state": "closed",
      "author": "CoderYiFei",
      "author_type": "User",
      "created_at": "2024-10-23T03:37:37Z",
      "updated_at": "2024-12-25T00:30:07Z",
      "closed_at": "2024-12-25T00:30:06Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1533/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1533",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1533",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:35.204692",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-03T00:33:49Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-25T00:30:06Z"
        }
      ]
    },
    {
      "issue_number": 1576,
      "title": "Prompt word switching between Chinese and English?",
      "body": "When writing code from the data_interpreter agent, it is very important to split the userrequirement into sub-tasks as follows:\r\n\r\n![image](https://github.com/user-attachments/assets/83e92911-6cc8-484f-9528-e8a0b1690492)\r\n\r\n\r\nBut now the output prompt words are in English, and read the source code, basically are English prompt words, please ask, for the need for Chinese scenes, how to deal with?\r\n\r\n![bda7f93612ed91991fff30b40ff5be4](https://github.com/user-attachments/assets/e6479742-29aa-42b4-aae1-b542c4ff81c2)\r\n\r\neg:\r\n![1730869541315](https://github.com/user-attachments/assets/4674e00d-b406-4465-bc6f-e21eb45e7d38)\r\n![image](https://github.com/user-attachments/assets/71122ef8-5f7a-4c80-9ba7-d11bcb2099ef)\r\n\r\n\r\nHow to solve it?\r\n\r\n",
      "state": "closed",
      "author": "RyanOvO",
      "author_type": "User",
      "created_at": "2024-11-06T03:03:22Z",
      "updated_at": "2024-12-24T00:30:31Z",
      "closed_at": "2024-12-24T00:30:30Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1576/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1576",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1576",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:35.441411",
      "comments": [
        {
          "author": "geekan",
          "body": "Hello, plz wait for our 1.0 version, we have fixed this issue.",
          "created_at": "2024-11-06T08:51:01Z"
        },
        {
          "author": "RyanOvO",
          "body": "> Hello, plz wait for our 1.0 version, we have fixed this issue.\r\n\r\nAs for prompt, I suggest that all modules should consider switching between English and Chinese for the prompt word, after all, there should be many such scenarios",
          "created_at": "2024-11-07T00:50:44Z"
        },
        {
          "author": "geekan",
          "body": "This idea has crossed my mind numerous times throughout history. But I still haven't done this because, like the game text, it's a bit cumbersome to maintain. I'm not sure whether this idea is effective in the end, and since subtle differences in prompt words can lead to huge differences in effects,",
          "created_at": "2024-11-07T07:12:51Z"
        },
        {
          "author": "RyanOvO",
          "body": "> This idea has crossed my mind numerous times throughout history. But I still haven't done this because, like the game text, it's a bit cumbersome to maintain. I'm not sure whether this idea is effective in the end, and since subtle differences in prompt words can lead to huge differences in effect",
          "created_at": "2024-11-08T02:19:22Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-09T00:34:33Z"
        }
      ]
    },
    {
      "issue_number": 1534,
      "title": "Can metagpt support AI based search enginee Tavily",
      "body": "Maybe add TAVILY_API_KEY in [config2.example.yaml](https://github.com/geekan/MetaGPT/blob/main/config/config2.example.yaml)\r\nand its calling in necessary places\r\n\r\nrefering:\r\nhttps://docs.tavily.com/docs/python-sdk/tavily-search/examples",
      "state": "closed",
      "author": "CoderYiFei",
      "author_type": "User",
      "created_at": "2024-10-23T06:39:11Z",
      "updated_at": "2024-12-22T00:33:45Z",
      "closed_at": "2024-12-22T00:33:44Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1534/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1534",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1534",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:35.643665",
      "comments": [
        {
          "author": "geekan",
          "body": "Looks good. If you are interested, you can raise a PR.",
          "created_at": "2024-10-23T12:03:18Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-03T00:33:48Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-22T00:33:44Z"
        }
      ]
    },
    {
      "issue_number": 1568,
      "title": "[bug] Can not download the dataset of SELA",
      "body": "Can not download the dataset of SELA. I guess it is the problem of the path file.\r\n\r\n### Operations\r\n```\r\ncd to *****/sela/data\r\npython dataset.py --save_analysis_pool\r\n```\r\n\r\n### Errors\r\n\r\n```\r\n(terminal) data % python dataset.py --save_analysis_pool \r\n2024-11-03 23:18:**** | INFO     | metagpt.const:get_metagpt_package_root:21 - Package root set to /MetaGPT\r\nTraceback (most recent call last):\r\n  File \"/MetaGPT/metagpt/ext/sela/data/dataset.py\", line 12, in <module>\r\n    from metagpt.ext.sela.insights.solution_designer import SolutionDesigner\r\n  File \"/MetaGPT/metagpt/ext/sela/insights/solution_designer.py\", line 3, in <module>\r\n    from metagpt.ext.sela.utils import clean_json_from_rsp, load_data_config\r\n  File \"/MetaGPT/metagpt/ext/sela/utils.py\", line 21, in <module>\r\n    DATASET_CONFIG = load_data_config(\"datasets.yaml\")\r\n  File \"/MetaGPT/metagpt/ext/sela/utils.py\", line 16, in load_data_config\r\n    with open(file_path, \"r\") as stream:\r\nFileNotFoundError: [Errno 2] No such file or directory: 'datasets.yaml'\r\n```\r\n\r\n### Envs:\r\n```\r\nmacOS 16\r\npython = 3.10\r\nmategpt: cloned from the main branch\r\n```\r\n\r\n\r\n**Can I submit a PR to fix it?**",
      "state": "closed",
      "author": "Appointat",
      "author_type": "User",
      "created_at": "2024-11-03T15:26:43Z",
      "updated_at": "2024-12-21T00:30:14Z",
      "closed_at": "2024-12-21T00:30:14Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1568/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1568",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1568",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:35.829914",
      "comments": [
        {
          "author": "garylin2099",
          "body": "Yes, please feel free to submit a PR if you find the cause! In the meantime, @cyzus can you take a look too?",
          "created_at": "2024-11-04T07:41:54Z"
        },
        {
          "author": "cyzus",
          "body": "Can you try \r\n```\r\npython data/dataset.py\r\n```\r\nstarting from the sela folder instead of the data folder.\r\n\r\nI will update this to the readme\r\n",
          "created_at": "2024-11-04T08:43:55Z"
        },
        {
          "author": "Appointat",
          "body": "Great. I will retry it.",
          "created_at": "2024-11-05T05:49:48Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-06T00:33:08Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-21T00:30:13Z"
        }
      ]
    },
    {
      "issue_number": 1536,
      "title": "[Very important] metagpt need to send some question and related choices to human, to get feedback from human",
      "body": "It needs to do:\r\n1. During its developing\r\n(1) Is this part a key point during total developing circle? If so, (or human decide to) ,  trigger (2)...\r\n(2) What kind of question and choices should be sent to human?\r\n(3) Then send question and choices to human and receive feedback\r\n(4) How to change its following work, after receiving human choices.\r\n\r\n2. At the begging of work\r\nAnd at the begging of incremental work(or normal work),\r\nIt also needs to show its understanding of current user's code repo and user's requirement.....and to let human to answer\r\n\"correct understanding\" or \"incorrect understanding\"\r\nadditionally,\r\nsending key question and choices it designed , to clarify its understanding.\r\n\r\nProduct rules:\r\nTo choose \"A B C D\", or to answer \"correct or incorrect\" , is easy for human.\r\nTo write complex words and code, is hard for human.\r\n",
      "state": "closed",
      "author": "CoderYiFei",
      "author_type": "User",
      "created_at": "2024-10-23T10:44:43Z",
      "updated_at": "2024-12-20T00:30:36Z",
      "closed_at": "2024-12-20T00:30:36Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1536/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1536",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1536",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:36.044351",
      "comments": [
        {
          "author": "geekan",
          "body": "Yes. These are available in our 1.0 version. However, this problem is actually not as simple as we think. For example, \"Buy me an apple\" is simple for humans, but it is very complex for machines.\r\n\r\nBecause we don’t know whether we are looking for mobile phones or fruits, we don’t know the required ",
          "created_at": "2024-10-23T12:13:34Z"
        },
        {
          "author": "CoderYiFei",
          "body": "> Yes. These are available in our 1.0 version. However, this problem is actually not as simple as we think. For example, \"Buy me an apple\" is simple for humans, but it is very complex for machines.\r\n> \r\n> Because we don’t know whether we are looking for mobile phones or fruits, we don’t know the req",
          "created_at": "2024-10-23T13:13:16Z"
        },
        {
          "author": "LimFang",
          "body": "> It needs to do:\r\n> \r\n> 1. During its developing\r\n>    (1) Is this part a key point during total developing circle? If so, (or human decide to) ,  trigger (2)...\r\n>    (2) What kind of question and choices should be sent to human?\r\n>    (3) Then send question and choices to human and receive feedba",
          "created_at": "2024-10-24T06:20:41Z"
        },
        {
          "author": "CoderYiFei",
          "body": "You mean metagpt's agent message subscription mechanism not good enough,\r\nor you mean general mechanism and theory,  not good enough in all alternatives projects",
          "created_at": "2024-10-24T06:42:14Z"
        },
        {
          "author": "LimFang",
          "body": "Message subscription in metagpt is more likely a centralized pool pattern. Every agent pulls and pushes its designed or desired information. That is not good enough for timely interaction between machines and humans.",
          "created_at": "2024-10-24T07:01:24Z"
        }
      ]
    },
    {
      "issue_number": 1550,
      "title": "A verifier is needed ...... after AFlow Sela and FACT",
      "body": "AFlow is used for workflow construction;\r\nSela handles the tasks related to AutoML; \r\nFACT is responsible for multi-fact incremental retrieval. \r\n\r\nIt seems that a verifier, \r\nthat all of its indicators tops arxiv metrics just like AFlow Sela and FACT, is needed,\r\n\r\nto verify whether the result of execution of code ,\r\nmeets the user's requirement documentation.\r\n\r\nThen Programer will only need to ask questions....\r\nFACT will help to search useful information,  \r\nAFlow generate good workflow , based on PRD and FACT's searching,\r\nSela generate useful ml agents code , based on workflow, PRD and FACT's searching.\r\nFinally \"verifier\" will run code and will review result , and will update PRD , to start next loop.\r\n",
      "state": "closed",
      "author": "CoderYiFei",
      "author_type": "User",
      "created_at": "2024-10-29T14:46:06Z",
      "updated_at": "2024-12-19T00:32:21Z",
      "closed_at": "2024-12-19T00:32:20Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1550/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1550",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1550",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:36.289875",
      "comments": [
        {
          "author": "geekan",
          "body": "You have good intuition. I'm curious what your background is?",
          "created_at": "2024-10-30T02:16:50Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-03T00:33:46Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-19T00:32:19Z"
        }
      ]
    },
    {
      "issue_number": 1551,
      "title": "About testing and generated documents",
      "body": "1. Why are there no contents in tests and test_outputs in the generated code directory? How do you generate relevant documents and code? (生成的代码目录下，为什么tests和test_outputs里面没有内容？如果想要生成相关文档，该如何操作呢？)\r\n\r\n2. The generated documents, such as those in the PRD directory, are in MD format. Is it possible to create documents in Word format? (已生成的文档，如prd目录下的文档，是md格式的。请问是否可以生成word格式的文档。)",
      "state": "closed",
      "author": "lily-toru",
      "author_type": "User",
      "created_at": "2024-10-30T02:28:59Z",
      "updated_at": "2024-12-18T00:32:17Z",
      "closed_at": "2024-12-18T00:32:16Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1551/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "iorisa"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1551",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1551",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:36.512198",
      "comments": [
        {
          "author": "geekan",
          "body": "Thank you for your question. Just ask in **English** is ok.",
          "created_at": "2024-10-30T02:33:24Z"
        },
        {
          "author": "iorisa",
          "body": "1. When executing the `metagpt` command, add the `--run-tests` parameter, and also set a larger number for the `--n-round` parameter, such as 99, to enter the unit testing phase. [See more...](https://docs.deepwisdom.ai/main/en/guide/get_started/quickstart.html#usage )\r\n\r\n2. Markdown documents are r",
          "created_at": "2024-10-30T07:17:18Z"
        },
        {
          "author": "lily-toru",
          "body": "1. It is directly added after the metagpt command, just like this [metagpt \"Write a xxx function\" -- run tests]?\r\nHowever, after running, there's still no content in the \"tests\" and \"test_outputs\" folders.\r\nCan you provide an example of a command that includes setting the --n-round parameter?",
          "created_at": "2024-10-30T08:32:17Z"
        },
        {
          "author": "geekan",
          "body": "I feel it would be more efficient to discuss this issue in version 1.0. The current design will actually be obsolete in version 1.0.",
          "created_at": "2024-10-30T17:10:29Z"
        },
        {
          "author": "lily-toru",
          "body": "> I feel it would be more efficient to discuss this issue in version 1.0. The current design will actually be obsolete in version 1.0.\r\n\r\nThat is to say, in the current version, there will no further updates regarding the test section.\r\nMay I ask will the version 1.0 be released soon?",
          "created_at": "2024-10-31T01:14:42Z"
        }
      ]
    },
    {
      "issue_number": 1553,
      "title": "ValueError: Creator not registered for key: LLMType.OLLAMA",
      "body": "**Bug description**\r\n<!-- Clearly and directly describe the current bug -->\r\nI using ***MetaGPT ver 0.8.1*** but when use RAG with method **SimpleEngine.from_docs** have error ***ValueError: Creator not registered for key: LLMType.OLLAMA***\r\n\r\n<!--  **Bug solved method**  -->\r\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\r\n\r\n**Environment information**\r\n<!-- Environment：System version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\r\n\r\n- LLM type and model name: ollama and model: hf.co/hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF\r\n- System version:\r\n- Python version: 3.10\r\n- MetaGPT version or branch: 0.8.1\r\n\r\n<!-- Dependent packagess：the packages version cause the bug(like `pydantic 1.10.8`), installation method（like `pip install metagpt` or `pip install from source` or `run in docker`） -->\r\n\r\n- packages version:\r\n- installation method: \r\n\r\n**Screenshots or logs**\r\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\r\n***config2.yaml***\r\nembedding:\r\n  api_type: \"ollama\"\r\n  model: \"hf.co/hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF\"\r\n  base_url: \"http://127.0.0.1:11434/api\"\r\n\r\nllm:\r\n  api_type: \"ollama\"\r\n  model: \"hf.co/hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF\"\r\n  base_url: \"http://127.0.0.1:11434/api\"\r\n\r\n***Error Response***\r\n[/usr/local/lib/python3.10/dist-packages/metagpt/rag/factories/base.py](https://localhost:8080/#) in get_instance(self, key, **kwargs)\r\n     27             return creator(**kwargs)\r\n     28 \r\n---> 29         raise ValueError(f\"Creator not registered for key: {key}\")\r\n     30 \r\n     31 \r\n\r\nValueError: Creator not registered for key: LLMType.OLLAMA\r\n",
      "state": "closed",
      "author": "vanhocpham",
      "author_type": "User",
      "created_at": "2024-10-30T07:10:51Z",
      "updated_at": "2024-12-18T00:32:15Z",
      "closed_at": "2024-12-18T00:32:14Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1553/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "better629"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1553",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1553",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:36.695713",
      "comments": [
        {
          "author": "better629",
          "body": "@vanhocpham try the main branch, it supports ollama in `https://github.com/geekan/MetaGPT/blob/main/metagpt/rag/factories/embedding.py#L26`",
          "created_at": "2024-10-30T07:17:01Z"
        },
        {
          "author": "vanhocpham",
          "body": "@better629 i using pip install is working?",
          "created_at": "2024-10-30T07:18:29Z"
        },
        {
          "author": "better629",
          "body": "@vanhocpham refs to `https://docs.deepwisdom.ai/main/en/guide/get_started/installation.html#install-in-development-mode`\r\n```\r\ncd MetaGPT\r\npip3 install -e .\r\n```",
          "created_at": "2024-10-30T07:25:18Z"
        },
        {
          "author": "vanhocpham",
          "body": "@better629 Thanks, I will try and get back to you",
          "created_at": "2024-10-30T07:28:32Z"
        },
        {
          "author": "vanhocpham",
          "body": "@better629 I tried the way you instructed but another error occurred \r\n\r\n```\r\n/usr/local/lib/python3.10/dist-packages/metagpt/rag/engines/simple.py in from_docs(cls, input_dir, input_files, transformations, embed_model, llm, retriever_configs, ranker_configs)\r\n    116         nodes = run_transformat",
          "created_at": "2024-10-30T09:17:06Z"
        }
      ]
    },
    {
      "issue_number": 1251,
      "title": "MetaGPT+Zhipu glm-4 generated the cli_blackjack game can not run",
      "body": "**Bug description**\r\n<!-- Clearly and directly describe the current bug -->\r\n\r\nlooks like the generated code has dependency issues among the classes.\r\n\r\n% python main.py\r\nDo you want to play a game of Blackjack? [Y/n] Y\r\nTraceback (most recent call last):\r\n  File \"/Users/xuxiaotian/project/metaGPT/MetaGPT/workspace/cli_blackjack/cli_blackjack/main.py\", line 98, in <module>\r\n    main()\r\n  File \"/Users/xuxiaotian/project/metaGPT/MetaGPT/workspace/cli_blackjack/cli_blackjack/main.py\", line 94, in main\r\n    game.play()\r\n  File \"/Users/xuxiaotian/project/metaGPT/MetaGPT/workspace/cli_blackjack/cli_blackjack/main.py\", line 19, in play\r\n    if not self.player.bet(10):  # Default bet amount is 10\r\n  File \"/Users/xuxiaotian/project/metaGPT/MetaGPT/workspace/cli_blackjack/cli_blackjack/player.py\", line 26, in bet\r\n    self.hands.append(Hand())  # Add a new hand for the player\r\nNameError: name 'Hand' is not defined\r\n\r\n**Bug solved method**\r\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\r\n\r\n**Environment information**\r\n<!-- Environment：System version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\r\n\r\n- LLM type and model name: zhipu, glm-4\r\n- System version: MacOS 14.4.1,\r\n- Python version: 3.9\r\n- MetaGPT version or branch: dev version\r\n\r\n<!-- Dependent packagess：the packages version cause the bug(like `pydantic 1.10.8`), installation method（like `pip install metagpt` or `pip install from source` or `run in docker`） -->\r\n\r\n- packages version:\r\n- installation method:  pip install from source\r\n\r\n**Screenshots or logs**\r\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\r\n",
      "state": "closed",
      "author": "xiaotiancd",
      "author_type": "User",
      "created_at": "2024-05-08T05:47:00Z",
      "updated_at": "2024-10-20T07:04:19Z",
      "closed_at": "2024-10-20T07:04:19Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1251/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1251",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1251",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:38.763606",
      "comments": [
        {
          "author": "LyndonZhao",
          "body": "I met the same problem, it seems that zhipu glm-4 is bad at code generation.",
          "created_at": "2024-06-15T15:15:36Z"
        },
        {
          "author": "better629",
          "body": "Due to the lack of updates or replies by the user for a long time, we will close it. Please reopen it if necessary.",
          "created_at": "2024-10-10T02:09:08Z"
        },
        {
          "author": "geekan",
          "body": "This issue has been closed because it took too long.",
          "created_at": "2024-10-20T07:04:19Z"
        }
      ]
    },
    {
      "issue_number": 1168,
      "title": "metagpt \"Create a 2048 game\" report error \"Another program is using this file and the process cannot access it\"",
      "body": "**Bug description**\r\n2024-04-09 16:41:38.825 | WARNING  | metagpt.utils.git_repository:rename_root:214 - Move C:\\Users\\longw\\projectspace\\MetaGPT\\workspace\\20240409164058 to C:\\Users\\longw\\projectspace\\MetaGPT\\workspace\\game_2048 error: [WinError 32] Another program is using this file and the process cannot access it. : 'C:\\\\Users\\\\longw\\\\projectspace\\\\MetaGPT\\\\workspace\\\\20240409164058'\r\n\r\n\r\n**Environment information**\r\n<!-- Environment：System version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\r\n\r\n- LLM type and model name: gpt-4-turbo-preview\r\n- System version:Window11\r\n- Python version:3.10.11\r\n- MetaGPT version or branch: main\r\n\r\n<!-- Dependent packagess：the packages version cause the bug(like `pydantic 1.10.8`), installation method（like `pip install metagpt` or `pip install from source` or `run in docker`） -->\r\n\r\n![微信图片_20240409170335](https://github.com/geekan/MetaGPT/assets/166496192/7ef173bd-d832-47a5-83a3-4af6c24a47ce)\r\n\r\n",
      "state": "closed",
      "author": "longweiii",
      "author_type": "User",
      "created_at": "2024-04-09T09:05:38Z",
      "updated_at": "2024-10-20T07:03:03Z",
      "closed_at": "2024-10-20T07:03:02Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1168/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1168",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1168",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:38.932544",
      "comments": [
        {
          "author": "seehi",
          "body": "Does it affect the result? According to the log, the rename action was finally success. Check the [code](https://github.com/geekan/MetaGPT/blob/main/metagpt/utils/git_repository.py#L219) for details.",
          "created_at": "2024-04-09T12:49:35Z"
        },
        {
          "author": "longweiii",
          "body": "it seems the doc folder contains .json file, not .doc or .pdf file, is it correct?\r\n![微信图片_20240410092032](https://github.com/geekan/MetaGPT/assets/166496192/c5e2faa4-7cbf-4cc1-bae3-2f5d0eb5dae4)\r\n",
          "created_at": "2024-04-10T01:22:47Z"
        },
        {
          "author": "longweiii",
          "body": "And I got this issue when I install python websockets:\r\n![微信图片_20240410093259](https://github.com/geekan/MetaGPT/assets/166496192/d406e5bd-4549-4772-85c5-685ee216e960)\r\n",
          "created_at": "2024-04-10T01:34:04Z"
        },
        {
          "author": "longweiii",
          "body": "Should I use main branch or v0.8-release branch to build？",
          "created_at": "2024-04-10T01:40:24Z"
        },
        {
          "author": "longweiii",
          "body": "I use below command for 3 times：\r\nmetagpt \"Create a 2048 game\"\r\n\r\nBut the generated code have bugs each time.\r\nHow could I make metagpt generate correct code?",
          "created_at": "2024-04-10T04:07:36Z"
        }
      ]
    },
    {
      "issue_number": 1187,
      "title": "DataInterpreter - Could the saving of tabular data(dynamically generated) and plots be improved?",
      "body": "**Feature description**\r\n<!-- Clear and direct description of the functionality of the currently submitted or proposed feature -->\r\nProposed feature: \r\nThe true value of DataInterpreter will be exploited when all data analysis is presented as a report. \r\nA lot of tabular data gets generated, during the course of plan execution. There is a lot of slice and dice of data happening, plots generated, etc, during a full run of the DI. \r\nI manage to get history using save_history(), but the intermediate tabular results and plots generated are not clearly saved in the plan.json or code.ipynb. \r\n\r\nCould every intermediate table be saved clearly and links to plots generated be saved in the plan.json, for future use? For tables, just add it as part of the plan.json inside each \"results\" node and for the plots - have an option to say \"save_plots_dir\" - the path where the plots would get saved, and all plots would get dumped inside that path - then these paths are saved in plan.json, in the correct sequence. \r\n\r\n**Your Feature**\r\n<!-- Describe the idea or process of implementing the current feature. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- When submitting features, you need to complete the corresponding doc/tests/examples to facilitate verification by reviewers. -->\r\n",
      "state": "closed",
      "author": "krish240574",
      "author_type": "User",
      "created_at": "2024-04-12T05:53:54Z",
      "updated_at": "2024-10-11T15:20:44Z",
      "closed_at": "2024-10-11T15:20:44Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1187/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1187",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1187",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:39.145629",
      "comments": [
        {
          "author": "seehi",
          "body": "FYI: @garylin2099 ",
          "created_at": "2024-04-12T07:13:45Z"
        },
        {
          "author": "garylin2099",
          "body": "Hi, the plots can be viewed inside the code.ipynb. If you want the plots to be saved as images in other directory, you can specify it in the requirement prompt, just add \"please save the plots under xxx/xxx/\". Data Interpreter should be able to write code to realize the saving. Let me know if this w",
          "created_at": "2024-10-11T13:09:14Z"
        },
        {
          "author": "krish240574",
          "body": "Yes, it works, I shall use that - thank you. ",
          "created_at": "2024-10-11T15:20:44Z"
        }
      ]
    },
    {
      "issue_number": 1185,
      "title": "metagpt generate too many inconsistent invocation code between different source files",
      "body": "metagpt always generate inconsistent code between different source files. \r\nFor example,\r\nin source file A, it contains a method a(p1,p2),this method have 2 parameters, but in source file B, it will generate invocation code for the method a(p1) which only contains 1 parameters of that method, and sometime in source file A, it will generate invocation code for a non-exist method in other source file, and there are too many such cases in project for me to fix them,\r\nis there any good way to avoid such inconsistent codes？",
      "state": "closed",
      "author": "longweiii",
      "author_type": "User",
      "created_at": "2024-04-12T01:55:20Z",
      "updated_at": "2024-10-11T13:10:25Z",
      "closed_at": "2024-10-11T13:10:25Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1185/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1185",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1185",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:39.365723",
      "comments": [
        {
          "author": "longweiii",
          "body": "And sometimes the generated source code will call a non-exist attribute of a object, these inconsistent codes make project unable to run.",
          "created_at": "2024-04-12T02:01:02Z"
        },
        {
          "author": "seehi",
          "body": "What's your LLM model, prefer `gpt-4-turbo`",
          "created_at": "2024-04-12T02:29:10Z"
        },
        {
          "author": "longweiii",
          "body": "> What's your LLM model, prefer `gpt-4-turbo`\r\nI use this LLM model\r\n![微信图片_20240412104847](https://github.com/geekan/MetaGPT/assets/166496192/3185e372-dd4e-4acb-97d3-fd416d9a0f37)\r\n",
          "created_at": "2024-04-12T02:50:38Z"
        },
        {
          "author": "longweiii",
          "body": "is gpt-4-turbo-preview different from gpt-4-turbo?",
          "created_at": "2024-04-12T02:51:28Z"
        },
        {
          "author": "seehi",
          "body": "[gpt-4-turbo](https://platform.openai.com/docs/models/continuous-model-upgrades) is the latest model. \r\nYou can check [these cases](https://www.deepwisdom.ai/usecases), they are all generated by `metagpt`, sometimes it's neccessary to adjust the code.",
          "created_at": "2024-04-12T03:07:31Z"
        }
      ]
    },
    {
      "issue_number": 915,
      "title": "忽略用户需求，转而产出game.py",
      "body": "**Bug description**\r\n提出一个中等复杂的需求，无法产出对应需求，metagpt中间出现错误（warning或者error）后会转向输出game.py,main.py。\r\n\r\n**Bug solved method**\r\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\r\n我个人认为可能比较有用的信息：\r\n- C:\\project\\MetaGPT\\workspace\\video_search\\resources\\data_api_design\\20240221092626        \r\n信息: 用提供的模式无法找到文件。\r\n- 2024-02-21 09:26:26.482 | WARNING  | metagpt.utils.git_repository:rename_root:214 - Move C:\\project\\MetaGPT\\workspace\\20240221092607 to C:\\project\\MetaGPT\\workspace\\video_search error: [WinError 32] 另\r\n一个程序正在使用此文件，进程无法访问。: 'C:\\\\project\\\\MetaGPT\\\\workspace\\\\20240221092607'（这个问题我用管理者模式启动pycharm或者删除生成的项目文件夹也不能避免，不过不是每次都会出现，在我初次调用是成功过一次，后面就再也没成功过了）\r\n\r\n**Environment information**\r\n- LLM type and model name:gemini\r\n- System version:win10+metagpt 0.7\r\n- Python version:3.11.8\r\n\r\n<!-- Dependent packagess：the packages version cause the bug(like `pydantic 1.10.8`), installation method（like `pip install metagpt` or `pip install from source` or `run in docker`） -->\r\n\r\n- packages version:按照requirements安装\r\n- installation method:git clone,然后以开发者模式install \r\n\r\n**Screenshots or logs**\r\n(MetaGPT_ENV) PS C:\\project\\MetaGPT> metagpt \"Please help me complete a project, which is divided into front-end and back-end. The front-end uses the Vue framework, and the back-end uses java+springboo\r\nt+springmvc+mybatis plus+mysql. Please carefully analyze the requirements and implement each function. The project requirements are as follows：{'Video Search ': {'Background Management End': {'Persona\r\nl Center ': {'Login': {'Method ':' User Name+Password Login '},' Password Management ': {'Function ': ['Forgot Password ',' Send Verification Code to Modify via Email ',' Change Password '},' Logout ':\r\n {}},' Permission Management System ': {'General Permission Management System': {}}, 'Attendance Ma nagement': {'Attendance Personnel Management ': {'Function': 'Add, Delete, Change'}, 'Attendance Reco\r\nrds': {},' Attendance Machine Management ': {'Function': ['On ',' Off ']}, 'Personnel Search': {'Onl ine Personnel Monitoring ': {'Function': ['Single person monitoring ',' Multi person monitoring ',' \r\nView historical images']}, 'Offline Search': {'Function ':' Access videos and personnel images, batch  search for the location of personnel in the video '},' Priority Implementation ': 2},' Congestion \r\nMonitoring ': {'Online Video': {'Function ': ['Monitor traffic lights',' Monitor intersection vehicle  conditions']}, 'Notification': {'Method ': ['Email', 'Topic', 'SMS',' Notification Strategy ']}, '\r\nCall algorithm platform interface': {}}, 'Big screen, cockpit': {}, 'Data access': {' Bottom layer data  access': {'Collected by': 'edge computing', 'Data': {'Video data': {'Type': 'Real time data'}, '\r\nOther data': {}}}, 'Big data': {}}}\"\r\n2024-02-21 09:26:00.055 | INFO     | metagpt.const:get_metagpt_package_root:29 - Package root set to c:\\project\\metagpt\r\n2024-02-21 09:26:07.075 | INFO     | metagpt.team:invest:90 - Investment: $3.0.\r\n2024-02-21 09:26:07.084 | INFO     | metagpt.roles.role:_act:399 - Alice(Product Manager): to do PrepareDocuments(PrepareDocuments)\r\n2024-02-21 09:26:07.512 | INFO     | metagpt.utils.file_repository:save:60 - save to: C:\\project\\MetaGPT\\workspace\\20240221092607\\docs\\requirement.txt\r\n2024-02-21 09:26:07.520 | INFO     | metagpt.roles.role:_act:399 - Alice(Product Manager): to do WritePRD(WritePRD)\r\n2024-02-21 09:26:07.527 | INFO     | metagpt.actions.write_prd:run:86 - New requirement detected: Please help me complete a project, which is divided into front-end and back-end. The front-end uses the\r\n Vue framework, and the back-end uses java+springboot+springmvc+mybatis plus+mysql. Please carefully analyze the requirements and implement each function. The project requirements are as follows：{'Vid\r\neo Search ': {'Background Management End': {'Personal Center ': {'Login': {'Method ':' User Name+Password Login '},' Password Management ': {'Function ': ['Forgot Password ',' Send Verification Code to\r\n Modify via Email ',' Change Password '},' Logout ': {}},' Permission Management System ': {'General Permission Management System': {}}, 'Attendance Ma nagement': {'Attendance Personnel Management ': {\r\n'Function': 'Add, Delete, Change'}, 'Attendance Records': {},' Attendance Machine Management ': {'Function': ['On ',' Off ']}, 'Personnel Search': {'Onl ine Personnel Monitoring ': {'Function': ['Singl\r\ne person monitoring ',' Multi person monitoring ',' View historical images']}, 'Offline Search': {'Function ':' Access videos and personnel images, batch  search for the location of personnel in the vi\r\ndeo '},' Priority Implementation ': 2},' Congestion Monitoring ': {'Online Video': {'Function ': ['Monitor traffic lights',' Monitor intersection vehicle  conditions']}, 'Notification': {'Method ': ['E\r\nmail', 'Topic', 'SMS',' Notification Strategy ']}, 'Call algorithm platform interface': {}}, 'Big screen, cockpit': {}, 'Data access': {' Bottom layer data  access': {'Collected by': 'edge computing', \r\n'Data': {'Video data': {'Type': 'Real time data'}, 'Other data': {}}}, 'Big data': {}}}\r\n[CONTENT]\r\n{\r\n    \"Language\": \"en_us\",\r\n    \"Programming Language\": \"Java\",\r\n    \"Original Requirements\": \"Please help me complete a project, which is divided into front-end and back-end. The front-end uses the Vue framework, and the back-end uses java+springboot+springmvc+myba\r\ntis plus+mysql. Please carefully analyze the requirements and implement each function. The project requirements are as follows：{'Video Search ': {'Background Management End': {'Personal Center ': {'Lo\r\ngin': {'Method ':' User Name+Password Login '},' Password Management ': {'Function ': ['Forgot Password ',' Send Verification Code to Modify via Email ',' Change Password '},' Logout ': {}},' Permissio\r\nn Management System ': {'General Permission Management System': {}}, 'Attendance Ma nagement': {'Attendance Personnel Management ': {'Function': 'Add, Delete, Change'}, 'Attendance Records': {},' Atten\r\ndance Machine Management ': {'Function': ['On ',' Off ']}, 'Personnel Search': {'Onl ine Personnel Monitoring ': {'Function': ['Single person monitoring ',' Multi person monitoring ',' View historical \r\nimages']}, 'Offline Search': {'Function ':' Access videos and personnel images, batch  search for the location of personnel in the video '},' Priority Implementation ': 2},' Congestion Monitoring ': {'\r\nOnline Video': {'Function ': ['Monitor traffic lights',' Monitor intersection vehicle  conditions']}, 'Notification': {'Method ': ['Email', 'Topic', 'SMS',' Notification Strategy ']}, 'Call algorithm p\r\nlatform interface': {}}, 'Big screen, cockpit': {}, 'Data access': {' Bottom layer data  access': {'Collected by': 'edge computing', 'Data': {'Video data': {'Type': 'Real time data'}, 'Other data': {}}\r\n}, 'Big data': {}}}\",\r\n    \"Project Name\": \"video_search\",\r\n    \"Product Goals\": [\r\n        \"Provide a comprehensive video search solution\",\r\n        \"Enhance security and access control\",\r\n        \"Improve operational efficiency\"\r\n    ],\r\n    \"User Stories\": [\r\n        \"As a user, I want to be able to search for videos by multiple criteria\",\r\n        \"As a user, I want to be able to manage my personal information and permissions\",\r\n        \"As a user, I want to be able to monitor personnel and traffic conditions in real-time\",\r\n        \"As a user, I want to be able to receive notifications when there are important events\",\r\n        \"As a user, I want to be able to access data from multiple sources\"\r\n    ],\r\n    \"Competitive Analysis\": [\r\n        \"Product A: Provides basic video search functionality, but lacks advanced features\",\r\n        \"Product B: Offers more advanced features, but is more expensive and complex to use\",\r\n        \"Product C: Focuses on security and access control, but has limited video search capabilities\"\r\n    ],\r\n    \"Competitive Quadrant Chart\": \"quadrantChart\\n    title \\\"Reach and engagement of campaigns\\\"\\n    x-axis \\\"Low Reach\\\" --> \\\"High Reach\\\"\\n    y-axis \\\"Low Engagement\\\" --> \\\"High Engagement\\\"\\n  \r\n  quadrant-1 \\\"We should expand\\\"\\n    quadrant-2 \\\"Need to promote\\\"\\n    quadrant-3 \\\"Re-evaluate\\\"\\n    quadrant-4 \\\"May be improved\\\"\\n    \\\"Campaign A\\\": [0.3, 0.6]\\n    \\\"Campaign B\\\": [0.45, 0.2\r\n3]\\n    \\\"Campaign C\\\": [0.57, 0.69]\\n    \\\"Campaign D\\\": [0.78, 0.34]\\n    \\\"Campaign E\\\": [0.40, 0.34]\\n    \\\"Campaign F\\\": [0.35, 0.78]\\n    \\\"Our Target Product\\\": [0.5, 0.6]\",\r\n    \"Requirement Analysis\": \"The project requirements are comprehensive and cover a wide range of functionality. The system should be able to search for videos by multiple criteria, manage user permiss\r\nions, monitor personnel and traffic conditions in real-time, send notifications, and access data from multiple sources. The system should also be secure and easy to use.\",\r\n    \"Requirement Pool\": [\r\n        [\r\n            \"P0\",\r\n            \"Implement basic video search functionality\"\r\n        ],\r\n        [\r\n            \"P1\",\r\n            \"Implement advanced video search features\"\r\n        ],\r\n        [\r\n            \"P2\",\r\n            \"Implement user management and permission control\"\r\n        ],\r\n        [\r\n            \"P3\",\r\n            \"Implement real-time monitoring of personnel and traffic conditions\"\r\n        ],\r\n        [\r\n            \"P4\",\r\n            \"Implement notification system\"\r\n        ],\r\n        [\r\n            \"P5\",\r\n            \"Implement data access from multiple sources\"\r\n        ]\r\n    ],\r\n    \"UI Design draft\": \"The UI should be clean and easy to use. The main features should be easily accessible from the home page. The search bar should be prominent and allow users to search for videos\r\n by multiple criteria. The results page should display the videos in a clear and concise manner. The user management and permission control pages should be easy to navigate and allow administrators to \r\nmanage users and permissions effectively. The real-time monitoring page should display the personnel and traffic conditions in a clear and concise manner. The notification system should be easy to conf\r\nigure and use.\",\r\n    \"Anything UNCLEAR\": \"There are no unclear aspects of the project requirements.\"\r\n}\r\n[/CONTENT]\r\n2024-02-21 09:26:26.258 | INFO     | metagpt.utils.cost_manager:update_cost:52 - Total running cost: $0.001 | Max budget: $10.000 | Current cost: $0.001, prompt_tokens: 1312, completion_tokens: 1155\r\n2024-02-21 09:26:26.272 | INFO     | metagpt.utils.git_repository:rename_root:203 - Delete directory C:\\project\\MetaGPT\\workspace\\video_search\r\n2024-02-21 09:26:26.482 | WARNING  | metagpt.utils.git_repository:rename_root:214 - Move C:\\project\\MetaGPT\\workspace\\20240221092607 to C:\\project\\MetaGPT\\workspace\\video_search error: [WinError 32] 另\r\n一个程序正在使用此文件，进程无法访问。: 'C:\\\\project\\\\MetaGPT\\\\workspace\\\\20240221092607'\r\n2024-02-21 09:26:26.483 | INFO     | metagpt.utils.git_repository:rename_root:219 - Rename directory C:\\project\\MetaGPT\\workspace\\20240221092607 to C:\\project\\MetaGPT\\workspace\\video_search\r\n2024-02-21 09:26:26.847 | INFO     | metagpt.utils.file_repository:save:60 - save to: C:\\project\\MetaGPT\\workspace\\video_search\\docs\\prd\\20240221092626.json\r\n信息: 用提供的模式无法找到文件。\r\n2024-02-21 09:26:27.039 | WARNING  | metagpt.utils.mermaid:mermaid_to_file:39 - RUN `npm install -g @mermaid-js/mermaid-cli` to install mmdc,or consider changing engine to `playwright`, `pyppeteer`, or\r\n `ink`.\r\n2024-02-21 09:26:27.044 | INFO     | metagpt.utils.file_repository:save:60 - save to: C:\\project\\MetaGPT\\workspace\\video_search\\resources\\prd\\20240221092626.md\r\n2024-02-21 09:26:27.050 | INFO     | metagpt.roles.role:_act:399 - Bob(Architect): to do WriteDesign(WriteDesign)\r\n[CONTENT]\r\n{\r\n    \"Implementation approach\": \"We will use the Vue framework for the front-end and the Java+springboot+springmvc+mybatis plus+mysql stack for the back-end. We will use a modular approach to developmen\r\nt, with each module responsible for a specific set of functionality. This will make it easier to maintain and update the system in the future.\",\r\n    \"File list\": [\r\n        \"main.py\",\r\n        \"game.py\"\r\n    ],\r\n    \"Data structures and interfaces\": \"\\nclassDiagram\\n    class User {\\n        - username: str\\n        - password: str\\n        - email: str\\n        - permissions: list\\n        +login()\\n        +\r\nlogout()\\n        +change_password()\\n        +reset_password()\\n    }\\n    class Permission {\\n        - name: str\\n        - description: str\\n        +check()\\n    }\\n    class Role {\\n        - nam\r\ne: str\\n        - description: str\\n        - permissions: list\\n        +assign()\\n        +revoke()\\n    }\\n    class Attendance {\\n        - date: date\\n        - time: time\\n        - location: str\r\n\\n        - employee: User\\n        +check_in()\\n        +check_out()\\n    }\\n    class Congestion {\\n        - date: date\\n        - time: time\\n        - location: str\\n        - severity: int\\n     \r\n   +report()\\n    }\\n    class Notification {\\n        - type: str\\n        - message: str\\n        - recipient: User\\n        +send()\\n    }\\n    class Video {\\n        - id: int\\n        - title: str\r\n\\n        - description: str\\n        - url: str\\n        - tags: list\\n        +search()\\n        +view()\\n        +download()\\n    }\\n    class SearchEngine {\\n        - index: Index\\n        - ranki\r\nng: Ranking\\n        - summary: Summary\\n        +search(query: str) list\\n    }\\n    class Index {\\n        - data: dict\\n        +create_index(data: dict)\\n        +query_index(query: str) list\\n    \r\n}\\n    class Ranking {\\n        +rank_results(results: list) list\\n    }\\n    class Summary {\\n        +summarize_results(results: list) str\\n    }\\n    User --> Attendance\\n    User --> Congestion\\n  \r\n  User --> Notification\\n    User --> Video\\n    SearchEngine --> Index\\n    SearchEngine --> Ranking\\n    SearchEngine --> Summary\\n\",\r\n    \"Program call flow\": \"\\nsequenceDiagram\\n    participant M as Main\\n    participant SE as SearchEngine\\n    participant I as Index\\n    participant R as Ranking\\n    participant S as Summary\\n    M\r\n->>SE: search(query)\\n    SE->>I: query_index(query)\\n    I->>SE: return results\\n    SE->>R: rank_results(results)\\n    R-->>SE: return ranked_results\\n    SE->>S: summarize_results(ranked_results)\\n \r\n   S-->>SE: return summary\\n    SE-->>M: return summary\\n\",\r\n    \"Anything UNCLEAR\": \"Clarification needed on third-party API integration, ...\"\r\n}\r\n[/CONTENT]\r\n2024-02-21 09:26:49.444 | INFO     | metagpt.utils.cost_manager:update_cost:52 - Total running cost: $0.001 | Max budget: $10.000 | Current cost: $0.001, prompt_tokens: 1741, completion_tokens: 766\r\n2024-02-21 09:26:49.453 | INFO     | metagpt.utils.file_repository:save:60 - save to: C:\\project\\MetaGPT\\workspace\\video_search\\docs\\system_design\\20240221092626.json\r\n2024-02-21 09:26:49.458 | INFO     | metagpt.utils.file_repository:save:65 - update dependency: C:\\project\\MetaGPT\\workspace\\video_search\\docs\\system_design\\20240221092626.json:{'docs\\\\prd\\\\20240221092\r\n626.json'}\r\n信息: 用提供的模式无法找到文件。\r\n2024-02-21 09:26:49.627 | WARNING  | metagpt.utils.mermaid:mermaid_to_file:39 - RUN `npm install -g @mermaid-js/mermaid-cli` to install mmdc,or consider changing engine to `playwright`, `pyppeteer`, or\r\n `ink`.\r\n2024-02-21 09:26:49.629 | INFO     | metagpt.actions.design_api:_save_data_api_design:107 - Save class view to C:\\project\\MetaGPT\\workspace\\video_search\\resources\\data_api_design\\20240221092626        \r\n信息: 用提供的模式无法找到文件。\r\n2024-02-21 09:26:49.808 | WARNING  | metagpt.utils.mermaid:mermaid_to_file:39 - RUN `npm install -g @mermaid-js/mermaid-cli` to install mmdc,or consider changing engine to `playwright`, `pyppeteer`, or\r\n `ink`.\r\n2024-02-21 09:26:49.811 | INFO     | metagpt.actions.design_api:_save_seq_flow:116 - Saving sequence flow to C:\\project\\MetaGPT\\workspace\\video_search\\resources\\seq_flow\\20240221092626\r\n2024-02-21 09:26:49.816 | INFO     | metagpt.utils.file_repository:save:60 - save to: C:\\project\\MetaGPT\\workspace\\video_search\\resources\\system_design\\20240221092626.md\r\n2024-02-21 09:26:49.820 | INFO     | metagpt.roles.role:_act:399 - Eve(Project Manager): to do WriteTasks(WriteTasks)\r\n[CONTENT]\r\n{\r\n    \"Required Python packages\": [\r\n        \"flask==1.1.2\",\r\n        \"bcrypt==3.2.0\"\r\n    ],\r\n    \"Required Other language third-party packages\": [\r\n        \"No third-party dependencies required\"\r\n    ],\r\n    \"Logic Analysis\": [\r\n        [\r\n            \"game.py\",\r\n            \"Contains Game class and ... functions\"\r\n        ],\r\n        [\r\n            \"main.py\",\r\n            \"Contains main function, from game import Game\"\r\n        ]\r\n    ],\r\n    \"Task list\": [\r\n        \"game.py\",\r\n        \"main.py\"\r\n    ],\r\n    \"Shared Knowledge\": \"`game.py` contains functions shared across the project.\",\r\n    \"Anything UNCLEAR\": \"Clarification needed on how to start and initialize third-party libraries.\"\r\n}\r\n[/CONTENT]\r\n2024-02-21 09:26:55.292 | INFO     | metagpt.utils.cost_manager:update_cost:52 - Total running cost: $0.000 | Max budget: $10.000 | Current cost: $0.000, prompt_tokens: 1244, completion_tokens: 192\r\n2024-02-21 09:26:55.300 | ERROR    | metagpt.utils.common:log_it:476 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 5.110(s), this was the 1st time calling it. exp: 1 valida\r\ntion error for PM_NODE_AN\r\n  Value error, Missing fields: {'Full API spec'} [type=value_error, input_value={'Required Python package...third-party libraries.'}, input_type=dict]\r\n    For further information visit https://errors.pydantic.dev/2.5/v/value_error\r\n[CONTENT]\r\n{\r\n    \"Required Python packages\": [],\r\n    \"Required Other language third-party packages\": [],\r\n    \"Logic Analysis\": [\r\n        [\r\n            \"main.py\",\r\n            \"Contains main function, from game import Game\"\r\n        ],\r\n        [\r\n            \"game.py\",\r\n            \"Contains Game class and ... functions\"\r\n        ]\r\n    ],\r\n    \"Task list\": [\r\n        \"main.py\",\r\n        \"game.py\"\r\n    ],\r\n    \"Full API spec\": \"No API spec required\",\r\n    \"Shared Knowledge\": \"`game.py` contains functions shared across the project.\",\r\n    \"Anything UNCLEAR\": \"Clarification needed on how to start and initialize third-party libraries.\"\r\n}\r\n[/CONTENT]\r\n2024-02-21 09:27:00.834 | INFO     | metagpt.utils.cost_manager:update_cost:52 - Total running cost: $0.001 | Max budget: $10.000 | Current cost: $0.000, prompt_tokens: 1244, completion_tokens: 167\r\n2024-02-21 09:27:00.846 | INFO     | metagpt.utils.file_repository:save:60 - save to: C:\\project\\MetaGPT\\workspace\\video_search\\docs\\task\\20240221092626.json\r\n2024-02-21 09:27:00.852 | INFO     | metagpt.utils.file_repository:save:65 - update dependency: C:\\project\\MetaGPT\\workspace\\video_search\\docs\\task\\20240221092626.json:{'docs\\\\system_design\\\\2024022109\r\n2626.json'}\r\n2024-02-21 09:27:00.855 | INFO     | metagpt.utils.file_repository:save:60 - save to: C:\\project\\MetaGPT\\workspace\\video_search\\requirements.txt\r\n2024-02-21 09:27:01.330 | INFO     | metagpt.actions.write_code:run:147 - Writing main.py..\r\n## Code: main.py\r\n```python\r\nfrom game import Game\r\n\r\ndef main():\r\n    \"\"\"\r\n    Main function.\r\n    \"\"\"\r\n\r\n    # Create a new game.\r\n    game = Game()\r\n\r\n    # Start the game.\r\n    game.start()\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n2024-02-21 09:27:07.416 | INFO     | metagpt.utils.cost_manager:update_cost:52 - Total running cost: $0.000 | Max budget: $10.000 | Current cost: $0.000, prompt_tokens: 1201, completion_tokens: 72\r\n2024-02-21 09:27:07.420 | INFO     | metagpt.actions.write_code_review:run:183 - Code review and rewrite main.py: 1/2 | len(iterative_code)=193, len(self.i_context.code_doc.content)=193\r\n## Code Review: main.py\r\n1. Yes.\r\n2. Yes.\r\n3. Yes.\r\n4. Yes.\r\n5. Yes.\r\n6. Yes.\r\n\r\n## Actions\r\npass\r\n\r\n## Code Review Result\r\nLGTM\r\n2024-02-21 09:27:11.272 | INFO     | metagpt.utils.cost_manager:update_cost:52 - Total running cost: $0.001 | Max budget: $10.000 | Current cost: $0.000, prompt_tokens: 1654, completion_tokens: 51\r\n2024-02-21 09:27:11.284 | INFO     | metagpt.utils.file_repository:save:60 - save to: C:\\project\\MetaGPT\\workspace\\video_search\\video_search\\main.py\r\n2024-02-21 09:27:11.289 | INFO     | metagpt.utils.file_repository:save:65 - update dependency: C:\\project\\MetaGPT\\workspace\\video_search\\video_search\\main.py:{'docs\\\\system_design\\\\20240221092626.json\r\n', 'docs\\\\task\\\\20240221092626.json'}\r\n2024-02-21 09:27:11.293 | INFO     | metagpt.actions.write_code:run:147 - Writing game.py..\r\n,\r\n2024-02-21 09:27:14.455 | INFO     | metagpt.utils.cost_manager:update_cost:52 - Total running cost: $0.001 | Max budget: $10.000 | Current cost: $0.000, prompt_tokens: 1201, completion_tokens: 2\r\n2024-02-21 09:27:14.458 | ERROR    | metagpt.utils.common:parse_code:280 - ```.*?\\s+(.*?)``` not match following text:\r\n2024-02-21 09:27:14.459 | ERROR    | metagpt.utils.common:parse_code:281 - ,\r\n2024-02-21 09:27:14.462 | INFO     | metagpt.actions.write_code_review:run:183 - Code review and rewrite game.py: 1/2 | len(iterative_code)=1, len(self.i_context.code_doc.content)=1\r\n## Code Review: game.py\r\n1. The code is not implemented as per the requirements. The `handle_events` method should update the game state only if a move is successful.\r\n   ```python\r\n   def handle_events(self):\r\n       for event in pygame.event.get():\r\n           if event.type == pygame.QUIT:\r\n               return False\r\n           if event.type == pygame.KEYDOWN:\r\n               moved = False\r\n               if event.key == pygame.K_UP:\r\n                   moved = self.game.move('UP')\r\n               elif event.key == pygame.K_DOWN:\r\n                   moved = self.game.move('DOWN')\r\n               elif event.key == pygame.K_LEFT:\r\n                   moved = self.game.move('LEFT')\r\n               elif event.key == pygame.K_RIGHT:\r\n                   moved = self.game.move('RIGHT')\r\n               if moved:\r\n                   # Update the game state only if a move was successful\r\n                   self.render()\r\n       return True\r\n   ```\r\n2. The code logic is not completely correct. The `move` function is not implemented.\r\n   ```python\r\n   def move(self, direction):\r\n       # Implement the move logic here\r\n       pass\r\n   ```\r\n3. The existing code does not follow the \"Data structures and interfaces\". The `Game` class should have a `move` method that takes a direction as an argument and returns a boolean indicating whether th\r\ne move was successful.\r\n4. The `move` function is not implemented.\r\n5. All necessary pre-dependencies have been imported.\r\n6. Methods from other files are not being reused.\r\n\r\n## Actions\r\n1. Implement the `move` function in the `Game` class.\r\n2. Update the `handle_events` method to update the game state only if a move is successful.\r\n\r\n## Code Review Result\r\nLBTM\r\n2024-02-21 09:27:24.155 | INFO     | metagpt.utils.cost_manager:update_cost:52 - Total running cost: $0.002 | Max budget: $10.000 | Current cost: $0.001, prompt_tokens: 1596, completion_tokens: 407\r\n## Rewrite Code: game.py\r\n```python\r\nimport pygame\r\n\r\nclass Game:\r\n    def __init__(self):\r\n        self.game_state = ...  # Initialize the game state here\r\n\r\n    def move(self, direction):\r\n        # Implement the move logic here\r\n        # Return True if the move was successful, False otherwise\r\n        pass\r\n\r\n    def render(self):\r\n        # Implement the rendering logic here\r\n        pass\r\n\r\nclass GameEngine:\r\n    def __init__(self):\r\n        self.game = Game()\r\n\r\n    def handle_events(self):\r\n        for event in pygame.event.get():\r\n            if event.type == pygame.QUIT:\r\n                return False\r\n            if event.type == pygame.KEYDOWN:\r\n                moved = False\r\n                if event.key == pygame.K_UP:\r\n                    moved = self.game.move('UP')\r\n                elif event.key == pygame.K_DOWN:\r\n                    moved = self.game.move('DOWN')\r\n                elif event.key == pygame.K_LEFT:\r\n                    moved = self.game.move('LEFT')\r\n                elif event.key == pygame.K_RIGHT:\r\n                    moved = self.game.move('RIGHT')\r\n                if moved:\r\n                    # Update the game state only if a move was successful\r\n                    self.game.render()\r\n        return True\r\n\r\n    def run(self):\r\n        while self.handle_events():\r\n            # Update the game logic here\r\n            pass\r\n\r\nif __name__ == '__main__':\r\n    engine = GameEngine()\r\n    engine.run()\r\n```\r\n2024-02-21 09:27:31.668 | INFO     | metagpt.utils.cost_manager:update_cost:52 - Total running cost: $0.002 | Max budget: $10.000 | Current cost: $0.001, prompt_tokens: 1466, completion_tokens: 347\r\n2024-02-21 09:27:31.670 | INFO     | metagpt.actions.write_code_review:run:183 - Code review and rewrite game.py: 2/2 | len(iterative_code)=1374, len(self.i_context.code_doc.content)=1\r\n## Code Review: Ordered List. Based on the \"Code to be Reviewed\", provide key, clear, concise, and specific answer. If any answer is no, explain how to fix it step by step.\r\n1. Yes.\r\n2. Yes.\r\n3. Yes.\r\n4. Yes.\r\n5. Yes.\r\n6. Yes.\r\n\r\n## Actions: Ordered List. Things that should be done after CR, such as implementing class A and function B\r\n\r\n## Code Review Result: str. If the code doesn't have bugs, we don't need to rewrite it, so answer LGTM and stop. ONLY ANSWER LGTM/LBTM.\r\nLGTM\r\n2024-02-21 09:27:36.275 | INFO     | metagpt.utils.cost_manager:update_cost:52 - Total running cost: $0.003 | Max budget: $10.000 | Current cost: $0.001, prompt_tokens: 1928, completion_tokens: 141\r\n2024-02-21 09:27:36.287 | INFO     | metagpt.utils.file_repository:save:60 - save to: C:\\project\\MetaGPT\\workspace\\video_search\\video_search\\game.py\r\n2024-02-21 09:27:36.292 | INFO     | metagpt.utils.file_repository:save:65 - update dependency: C:\\project\\MetaGPT\\workspace\\video_search\\video_search\\game.py:{'docs\\\\system_design\\\\20240221092626.json\r\n', 'docs\\\\task\\\\20240221092626.json'}\r\n2024-02-21 09:27:36.497 | INFO     | metagpt.utils.git_repository:archive:168 - Archive: ['.dependencies.json', 'docs/prd/20240221092626.json', 'docs/requirement.txt', 'docs/system_design/2024022109262\r\n6.json', 'docs/task/20240221092626.json', 'requirements.txt', 'resources/competitive_analysis/20240221092626.mmd', 'resources/data_api_design/20240221092626.mmd', 'resources/prd/20240221092626.md', 're\r\nsources/seq_flow/20240221092626.mmd', 'resources/system_design/20240221092626.md', 'video_search/game.py', 'video_search/main.py']\r\n",
      "state": "closed",
      "author": "1010936691",
      "author_type": "User",
      "created_at": "2024-02-21T01:40:23Z",
      "updated_at": "2024-10-11T09:56:39Z",
      "closed_at": "2024-10-11T09:56:39Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/915/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "geekan"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/915",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/915",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:39.563394",
      "comments": [
        {
          "author": "iorisa",
          "body": "```text\r\n2024-02-21 09:26:26.482 | WARNING | metagpt.utils.git_repository:rename_root:214 - Move C:\\project\\MetaGPT\\workspace\\20240221092607 to C:\\project\\MetaGPT\\workspace\\video_search error: [WinError 32] 另\r\n一个程序正在使用此文件，进程无法访问。: 'C:\\project\\MetaGPT\\workspace\\20240221092607'\r\n```\r\nWindows下此处的异常只会导致",
          "created_at": "2024-03-04T04:00:43Z"
        },
        {
          "author": "geekan",
          "body": "TODO\r\n1. Prompt optimization\r\n2. Review & revise until the output meets expectations",
          "created_at": "2024-03-21T06:13:21Z"
        },
        {
          "author": "geekan",
          "body": "This bug will be fixed in our later versions. This issue will be closed first and then opened at any time.",
          "created_at": "2024-10-11T09:56:39Z"
        }
      ]
    },
    {
      "issue_number": 333,
      "title": "Iterating on a solution",
      "body": "Is it possible to iterate on a completed solution, or provide feedback on the chosen path? When setting long term memory to True and running again with revised instructions the execution prints the directives, but does not run any further steps.\r\n\r\npython startup.py \"This should be an emacs lisp package not a python package. The package should be a fork of gptel. Please modify the gptel package to interact with flowise\" --n_round=25 --code_review=True --investment=5\r\n2023-09-18 00:32:13.938 | INFO     | metagpt.config:__init__:44 - Config loading done.\r\n2023-09-18 00:32:13.942 | WARNING  | metagpt.config:__init__:77 - LONG_TERM_MEMORY is True\r\n2023-09-18 00:32:24.259 | WARNING  | metagpt.memory.longterm_memory:recover_memory:32 - Agent Alice(Product Manager) has existed memory storage with 3 messages and has recovered them.\r\n2023-09-18 00:32:24.297 | WARNING  | metagpt.memory.longterm_memory:recover_memory:32 - Agent Bob(Architect) has existed memory storage with 3 messages and has recovered them.\r\n2023-09-18 00:32:24.307 | WARNING  | metagpt.memory.longterm_memory:recover_memory:32 - Agent Eve(Project Manager) has existed memory storage with 1 messages and has recovered them.\r\n2023-09-18 00:32:24.330 | WARNING  | metagpt.memory.longterm_memory:recover_memory:32 - Agent Alex(Engineer) has existed memory storage with 2 messages and has recovered them.\r\n2023-09-18 00:32:24.334 | INFO     | metagpt.software_company:invest:39 - Investment: $5.",
      "state": "closed",
      "author": "rmulligan",
      "author_type": "User",
      "created_at": "2023-09-18T00:33:06Z",
      "updated_at": "2024-10-11T06:37:42Z",
      "closed_at": "2024-10-11T06:37:42Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 10,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/333/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "iorisa"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/333",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/333",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:39.822330",
      "comments": [
        {
          "author": "samuelmukoti",
          "body": "I'm wondering the same thing.  I happy to contribute a PR with some guidance of course?  Is anyone else already working on this? Is it part of the roadmap? \r\n\r\nI'd be happy to put together a pull request to address the iteration capabilities and contribute to the project. \r\n\r\nBefore jumping into cod",
          "created_at": "2023-09-23T22:06:02Z"
        },
        {
          "author": "javadan",
          "body": "SkyNet v1.0 here we go!  \r\n\r\n@samuelmukoti let me know if you work it out, i think this would be an ideal next feature.  \r\n\r\ngreat project @geekan - any advice for how best to implement ?  ",
          "created_at": "2023-10-01T21:07:36Z"
        },
        {
          "author": "geekan",
          "body": "@rmulligan @samuelmukoti @javadan check latest code and we've incremental dev now.",
          "created_at": "2023-12-21T09:24:13Z"
        },
        {
          "author": "javadan",
          "body": "Nice.\r\nA few errors I came across  (from github head):  \r\n- Only MetaGPT/config/config.yaml was used, not ~/.metagpt/key.yaml  resulting in `metagpt.config.NotConfiguredException: You should config a LLM configuration first`\r\n- When not specifying a project path, it will generate a project name unde",
          "created_at": "2023-12-25T11:58:15Z"
        },
        {
          "author": "kevb10",
          "body": "i'm also getting an error at \r\n```py\r\nif path.exists() and not CONFIG.inc:\r\n```\r\nwhen using the flags `--inc --project-path /path/here`\r\n\r\nwrapping it in a Path is the answer but @javadan you're rewrapping it \r\ni'm happy to submit a PR @geekan \r\n```py\r\n def _init_repo(self):\r\n        \"\"\"Initialize t",
          "created_at": "2023-12-28T00:10:59Z"
        }
      ]
    },
    {
      "issue_number": 1095,
      "title": "bug: Fixing existing code does not work",
      "body": "**Bug description**\r\n- `main` branch\r\n- logs:\r\n[20240321.txt](https://github.com/geekan/MetaGPT/files/14739821/20240321.txt)\r\n\r\n`Engineer` ignores error information in `_act_code_plan_and_change()`",
      "state": "closed",
      "author": "iorisa",
      "author_type": "User",
      "created_at": "2024-03-25T06:48:30Z",
      "updated_at": "2024-10-11T06:32:53Z",
      "closed_at": "2024-10-11T06:32:52Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1095/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1095",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1095",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:40.056711",
      "comments": [
        {
          "author": "iorisa",
          "body": "<img width=\"1121\" alt=\"截屏2024-03-25 15 02 37\" src=\"https://github.com/geekan/MetaGPT/assets/46912756/b9935d42-1a8a-49af-abdc-30b754c3a21e\">\r\n\r\nThe error information is excluded when formatting the prompt:\r\n<img width=\"1011\" alt=\"截屏2024-03-25 15 05 32\" src=\"https://github.com/geekan/MetaGPT/assets/46",
          "created_at": "2024-03-25T07:10:49Z"
        },
        {
          "author": "iorisa",
          "body": "I've consolidated all the incremental development-related issues into #1498 to make it easier to follow up. Any new issues will be discussed in this newly opened issue, and the old issue will be closed.",
          "created_at": "2024-10-11T06:32:52Z"
        }
      ]
    },
    {
      "issue_number": 1210,
      "title": "Fixing existing code does not work again",
      "body": "**Bug description**\r\nI generated metagpt project. But I am not satisfied with dummy logic implementation. I want to apply corrections to generated project\r\nI tried:\r\n--project-path ... --inc\r\nand\r\n--project-path ... only\r\nThe docs and resources changes. But the generated code doesn't. The .py code files in project does not change. The new file mentioned in log are not created.\r\nRunning metagpt on existing project doesn't call metagpt.actions.write_code:run. Only metagpt.actions.write_code_plan_and_change_an:run.\r\nDoes metagpt support applying new requirements to project? \r\n\r\n**Bug solved method**\r\nHave not tried to solve yet.\r\n\r\n**Environment information**\r\nDebian, python=3.11.2-1+b1, venv, \r\nI have this bug as on pip metagpt version, as on newest metagpt github release.\r\n\r\nModel gpt-3.5-turbo",
      "state": "closed",
      "author": "AndPim4912",
      "author_type": "User",
      "created_at": "2024-04-18T17:14:18Z",
      "updated_at": "2024-10-11T06:31:37Z",
      "closed_at": "2024-10-11T06:31:37Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1210/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1210",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1210",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:40.247366",
      "comments": [
        {
          "author": "seehi",
          "body": "According to the [document](https://docs.deepwisdom.ai/main/en/guide/in_depth_guides/incremental_development.html#unresolved-issues), there are still some unresolved issues in incremental development.",
          "created_at": "2024-04-19T03:04:46Z"
        },
        {
          "author": "iorisa",
          "body": "I've consolidated all the incremental development-related issues into #1498 to make it easier to follow up. Any new issues will be discussed in this newly opened issue, and the old issue will be closed.",
          "created_at": "2024-10-11T06:31:37Z"
        }
      ]
    },
    {
      "issue_number": 5,
      "title": "如何细化需求？",
      "body": "只用一句话去创建整个项目从商业设计上来讲是不靠谱的除非是很简单的逻辑比如“创建一个js版本的贪食蛇”。但是当我们要依赖AI去设计更大规模的系统时，我建议还是需要增加更加复杂的交互式设计通过AI去收集多轮对话的需求以及更多的细节让整个项目的生成变得更加可靠。如果是真的考虑商业化落地的话",
      "state": "closed",
      "author": "sd797994",
      "author_type": "User",
      "created_at": "2023-07-04T08:29:39Z",
      "updated_at": "2024-10-10T06:44:05Z",
      "closed_at": "2024-10-10T06:44:05Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/5/reactions",
        "total_count": 3,
        "+1": 3,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "geekan"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/5",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/5",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:42.150050",
      "comments": [
        {
          "author": "geekan",
          "body": "是的。在todo list上，请等待1-2天",
          "created_at": "2023-07-04T08:59:37Z"
        },
        {
          "author": "geekan",
          "body": "https://github.com/geekan/MetaGPT/blob/main/docs/ROADMAP.md\r\n\r\n这是目前的ROADMAP，其中Complete the design and implementation of module breakdown任务与此对应",
          "created_at": "2023-07-05T07:02:09Z"
        },
        {
          "author": "WangShuXian6",
          "body": "目前我是直接使用详细的产品需求去给到MetaGPT,几百个字没问题~~",
          "created_at": "2023-07-23T11:33:43Z"
        }
      ]
    },
    {
      "issue_number": 17,
      "title": "关于自动生成的项目的完整性",
      "body": "我自己在本地测试了几次，生成的项目都不能直接执行，会有各种问题，比如写命令行贪吃蛇，curses库总是抛出错误：\r\n  File \"/*****\", line 28, in _draw_snake\r\n    self.screen.addch(position[0], position[1], \"O\")\r\n_curses.error: add_wch() returned ERR\r\n我注意到该仓库长期规划中会添加测试角色，所以我想问下当前自动生成的项目无法完整执行是否是正常情况😂谢谢！\r\n",
      "state": "closed",
      "author": "Lucas66Zhang",
      "author_type": "User",
      "created_at": "2023-07-07T06:24:44Z",
      "updated_at": "2024-10-10T06:43:32Z",
      "closed_at": "2024-10-10T06:43:32Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/17/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "geekan"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/17",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/17",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:42.337215",
      "comments": [
        {
          "author": "geekan",
          "body": "是用4还是3.5？",
          "created_at": "2023-07-07T07:47:12Z"
        },
        {
          "author": "Lucas66Zhang",
          "body": "4",
          "created_at": "2023-07-07T08:57:59Z"
        },
        {
          "author": "geekan",
          "body": "进群，发一下log",
          "created_at": "2023-07-07T12:21:07Z"
        },
        {
          "author": "cc-qq-gg",
          "body": "\r\n\r\n\r\n\r\n> 进群，发一下log\r\n\r\n请问怎么加群",
          "created_at": "2023-07-11T01:35:28Z"
        },
        {
          "author": "geekan",
          "body": "@cc-qq-gg https://github.com/geekan/MetaGPT/blob/main/docs/resources/MetaGPT-WeChat-Personal.jpeg",
          "created_at": "2023-07-12T16:52:16Z"
        }
      ]
    },
    {
      "issue_number": 19,
      "title": "Require open source llms like ChatGLM, ChatRWKV, MPT-30b support.",
      "body": "Whether it is possible to deploy open source llms like ChatGLM, ChatRWKV, MPT-30b support to the project MetaGPT ?",
      "state": "closed",
      "author": "stc2001",
      "author_type": "User",
      "created_at": "2023-07-07T13:26:01Z",
      "updated_at": "2024-10-10T06:43:17Z",
      "closed_at": "2024-10-10T06:43:17Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/19/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/19",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/19",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:42.512731",
      "comments": [
        {
          "author": "geekan",
          "body": "Sure. It should be very easy to implement a provider or provide an OpenAI-compatible API, which requires development",
          "created_at": "2023-07-07T13:34:40Z"
        },
        {
          "author": "NetTecture",
          "body": "Actually no - does huggingface not expose them in an OpenAi compatible API?",
          "created_at": "2023-07-25T12:57:05Z"
        },
        {
          "author": "better629",
          "body": "`https://docs.deepwisdom.ai/main/en/guide/tutorials/integration_with_open_llm.html`",
          "created_at": "2024-10-10T06:43:17Z"
        }
      ]
    },
    {
      "issue_number": 20,
      "title": "Other Programming Languages",
      "body": "Right now, python language is hard coded. It would be nice if, it took the language from the initial prompt, or took the programming language as a command line argument.",
      "state": "closed",
      "author": "zerofill",
      "author_type": "User",
      "created_at": "2023-07-07T16:34:20Z",
      "updated_at": "2024-10-10T06:42:57Z",
      "closed_at": "2024-10-10T06:42:56Z",
      "labels": [
        "todo"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/20/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/20",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/20",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:42.697975",
      "comments": [
        {
          "author": "geekan",
          "body": "We will try to provide a multi-language version within a week.",
          "created_at": "2023-07-08T06:01:04Z"
        },
        {
          "author": "magick93",
          "body": "To add to this, it would be good if:\r\n- user can specify language(s) and frameworks, eg, specify a frontent - vuejs, svelte, etc\r\n- add requested 3rd party npm, pip etc modules to use - and include a github repo, or docs url\r\n- include a link to developer docs, api docs for any relevant sources",
          "created_at": "2023-07-28T09:02:32Z"
        },
        {
          "author": "geekan",
          "body": "This progress is slow because the first two weeks were filled with other high priorities. I try to finish writing this feature by 0804. This feature needs to be changed in 10 places, and there is some debugging work",
          "created_at": "2023-07-28T13:38:43Z"
        },
        {
          "author": "p971607",
          "body": "> 这一进展缓慢，因为头两周充满了其他高度优先事项。我尝试在 0804 之前完成此功能的编写。此功能需要在 10 处更改，并且有一些调试工作\r\n\r\n太棒了，高度高度高度期待\r\n\r\n> \r\n太棒了 ！！！高度期待这项工作啊~~发出土拨鼠之尖叫~~！！\r\n",
          "created_at": "2023-08-03T00:43:39Z"
        },
        {
          "author": "iamalin",
          "body": "> We will try to provide a multi-language version within a week.\r\n\r\nIs there any schedule for this proposal?",
          "created_at": "2024-03-11T09:59:49Z"
        }
      ]
    },
    {
      "issue_number": 31,
      "title": "Error communicating with openai ",
      "body": "  File \"/Users/r/Documents/1-projects/MetaGPT/venv/lib/python3.11/site-packages/aiohttp/connector.py\", line 982, in _wrap_create_connection\r\n    raise ClientConnectorCertificateError(req.connection_key, exc) from exc\r\naiohttp.client_exceptions.ClientConnectorCertificateError: Cannot connect to host api.openai.com:443 ssl:True [SSLCertVerificationError: (1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:992)')]\r\n\r\n\r\nI've checked that I have correct CA Bundle certificates and I can connect to api.openai.com easily",
      "state": "closed",
      "author": "rubywwwilde",
      "author_type": "User",
      "created_at": "2023-07-10T12:30:21Z",
      "updated_at": "2024-10-10T06:41:22Z",
      "closed_at": "2024-10-10T06:41:22Z",
      "labels": [
        "network"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/31/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "geekan"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/31",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/31",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:42.878383",
      "comments": [
        {
          "author": "geekan",
          "body": "Could you try this: https://github.com/beidongjiedeguang/openai-forward ?",
          "created_at": "2023-07-10T14:40:47Z"
        }
      ]
    },
    {
      "issue_number": 36,
      "title": "请问这个是不是必须要要开通openai 的plus会员才能去访问gpt-4？",
      "body": "因为我里面只有5美元，跑你这里的实例代码都跑不通</br>\r\nassert not isinstance(response, OpenAIResponse)",
      "state": "closed",
      "author": "liaogulou",
      "author_type": "User",
      "created_at": "2023-07-12T03:52:20Z",
      "updated_at": "2024-10-10T06:41:03Z",
      "closed_at": "2024-10-10T06:41:03Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/36/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/36",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/36",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:43.095813",
      "comments": [
        {
          "author": "liaogulou",
          "body": "> 因为我里面只有5美元，跑你这里的实例代码都跑不通 assert not isinstance(response, OpenAIResponse)\r\n\r\n还有导入包的时候，也报错</br>\r\nfrom metagpt.software_company import SoftwareCompany\r\n</br>\r\nException: Project root not found.",
          "created_at": "2023-07-12T03:53:44Z"
        },
        {
          "author": "geekan",
          "body": "#37 可以让GPT-3.5-TURBO也有成功概率（但不高），还是建议GPT-4优先\r\n\r\nException: Project root not found.\r\n这个请提供更详细的信息，包括执行时所处于的路径、OS、Python版本、日志等",
          "created_at": "2023-07-12T16:28:12Z"
        },
        {
          "author": "ToviHe",
          "body": "话说  如果是非plus 账户，这个 OPENAI_API_BASE 参数在哪里看的？",
          "created_at": "2023-07-13T09:22:07Z"
        },
        {
          "author": "geekan",
          "body": "@ToviHe @liaogulou api不需要plus。访问openai的api页面查看",
          "created_at": "2023-07-13T11:02:10Z"
        },
        {
          "author": "apas008",
          "body": "OPENAI_API_MODEL: \"gpt-3.5-turbo\"  改成这个跑不起来，log中是waiting news",
          "created_at": "2023-07-28T08:29:16Z"
        }
      ]
    },
    {
      "issue_number": 39,
      "title": "RetryError[<Future at 0x7f806d336a60 state=finished raised ValidationError>]",
      "body": "(mgpt) dope@dope:~/Documents/metagpt$ python startup.py \"Write a cli snake game\"\r\n2023-07-12 21:00:39.873 | INFO     | metagpt.config:__init__:43 - Config loading done.\r\n2023-07-12 21:00:39.873 | INFO     | metagpt.config:__init__:49 - Set OPENAI_API_BASE in case of network issues\r\n2023-07-12 21:00:40.585 | INFO     | metagpt.software_company:invest:39 - Investment: $3.0.\r\n2023-07-12 21:00:40.586 | INFO     | metagpt.roles.role:_act:155 - Alice(Product Manager): ready to WritePRD\r\n2023-07-12 21:00:40.586 | WARNING  | metagpt.actions.search_and_summarize:run:114 - Configure SERPAPI_API_KEY to unlock full feature\r\n## Original Requirements:\r\n\r\nThe boss wants a command-line snake game.\r\n\r\n## Product Goals:\r\n\r\n- Create a fun and engaging snake game that can be played in the command-line interface.\r\n- Provide a challenging gameplay experience for users.\r\n- Implement intuitive controls and smooth animations for a seamless gaming experience.\r\n\r\n## User Stories:\r\n\r\n- As a user, I want to be able to control the snake using arrow keys.\r\n- As a user, I want the snake to grow longer each time it eats food.\r\n- As a user, I want the game to end if the snake collides with the wall or itself.\r\n- As a user, I want to see my score displayed on the screen.\r\n- As a user, I want the game to have different levels of difficulty.\r\n\r\n## Competitive Analysis:\r\n\r\n- Python Snake Game: A basic snake game implemented in Python with simple graphics.\r\n- Snake Xenzia: A popular snake game with improved graphics and additional features.\r\n- Snake VS Block: A modern twist on the classic snake game with obstacles and power-ups.\r\n- Slither.io: An online multiplayer snake game with a competitive leaderboard.\r\n- Snake '97: A nostalgic recreation of the classic snake game from the Nokia 3310.\r\n- Snake Rivals: A multiplayer snake game with real-time battles and customizable snakes.\r\n- Snake Zone: A 3D snake game with immersive graphics and challenging levels.\r\n\r\n## Competitive Quadrant Chart:\r\n\r\n```mermaid\r\nquadrantChart\r\n    title Reach and engagement of snake games\r\n    x-axis Low Reach --> High Reach\r\n    y-axis Low Engagement --> High Engagement\r\n    quadrant-1 Basic Games\r\n    quadrant-2 Popular Games\r\n    quadrant-3 Innovative Games\r\n    quadrant-4 Advanced Games\r\n    \"Python Snake Game\": [0.2, 0.3]\r\n    \"Snake Xenzia\": [0.4, 0.4]\r\n    \"Snake VS Block\": [0.6, 0.6]\r\n    \"Slither.io\": [0.8, 0.7]\r\n    \"Snake '97\": [0.3, 0.2]\r\n    \"Snake Rivals\": [0.7, 0.8]\r\n    \"Snake Zone\": [0.9, 0.9]\r\n    \"Our Target Product\": [0.5, 0.6]\r\n```\r\n\r\n## Requirement Analysis:\r\n\r\nThe product should be a command-line snake game with intuitive controls, smooth animations, and challenging gameplay. It should have different levels of difficulty and display the user's score on the screen. The game should end if the snake collides with the wall or itself.\r\n\r\n## Requirement Pool:\r\n\r\n```python\r\n[\r\n    (\"Implement arrow key controls for the snake\", \"P0\"),\r\n    (\"Implement snake growth when it eats food\", \"P0\"),\r\n    (\"Detect collision with the wall or snake's body\", \"P0\"),\r\n    (\"Display the user's score on the screen\", \"P1\"),\r\n    (\"Implement different levels of difficulty\", \"P1\")\r\n]\r\n```\r\n\r\n## Anything UNCLEAR:\r\n\r\nThere are no unclear points.\r\nWarning: gpt-3.5-turbo may change over time. Returning num tokens assuming gpt-3.5-turbo-0301.\r\n2023-07-12 21:00:55.796 | INFO     | metagpt.provider.openai_api:update_cost:89 - Total running cost: $0.003 | Max budget: $3.000 | Current cost: $0.003, prompt_tokens=800, completion_tokens=625\r\n## Original Requirements:\r\nThe boss wants you to create a command-line snake game.\r\n\r\n## Product Goals:\r\n- Create a fun and engaging snake game.\r\n- Provide a smooth and responsive user experience.\r\n- Include customizable game settings for different difficulty levels.\r\n\r\n## User Stories:\r\n- As a user, I want to be able to control the snake using arrow keys.\r\n- As a user, I want the snake to grow longer when it eats food.\r\n- As a user, I want the game to end if the snake hits the wall or its own body.\r\n- As a user, I want to be able to pause and resume the game.\r\n- As a user, I want to see my current score and the highest score achieved.\r\n\r\n## Competitive Analysis:\r\n- Python Snake Game: A simple snake game implemented in Python with basic features.\r\n- Snake Xenzia: A classic snake game with improved graphics and sound effects.\r\n- Snake.io: A multiplayer snake game where players compete against each other.\r\n- Slither.io: A popular online multiplayer snake game with a large player base.\r\n- Snake '97: A nostalgic snake game that replicates the experience of playing on an old Nokia phone.\r\n- Snake Blast: A modern twist on the snake game with power-ups and special abilities.\r\n- Snake Rewind: A snake game with a rewind feature that allows players to undo their moves.\r\n\r\n## Competitive Quadrant Chart:\r\n```mermaid\r\nquadrantChart\r\n    title Reach and engagement of snake games\r\n    x-axis Low Reach --> High Reach\r\n    y-axis Low Engagement --> High Engagement\r\n    quadrant-1 We should expand\r\n    quadrant-2 Need to promote\r\n    quadrant-3 Re-evaluate\r\n    quadrant-4 May be improved\r\n    \"Python Snake Game\": [0.3, 0.6]\r\n    \"Snake Xenzia\": [0.45, 0.23]\r\n    \"Snake.io\": [0.57, 0.69]\r\n    \"Slither.io\": [0.78, 0.34]\r\n    \"Snake '97\": [0.40, 0.34]\r\n    \"Snake Blast\": [0.35, 0.78]\r\n    \"Snake Rewind\": [0.6, 0.7]\r\n    \"Our Target Product\": [0.5, 0.6]\r\n```\r\n\r\n## Requirement Analysis:\r\nThe product should be a command-line snake game with basic features such as controlling the snake, growing longer when eating food, and ending the game if the snake hits the wall or its own body. It should also include additional features like pausing and resuming the game, displaying the current score and highest score achieved, and customizable game settings for different difficulty levels.\r\n\r\n## Requirement Pool:\r\n```python\r\n[\r\n    (\"End game when snake hits the wall or its own body\", \"P0\"),\r\n    (\"Allow pausing and resuming the game\", \"P1\"),\r\n    (\"Display current score and highest score achieved\", \"P1\"),\r\n    (\"Customizable game settings for different difficulty levels\", \"P2\")\r\n]\r\n```\r\n\r\n## Anything UNCLEAR:\r\nThere are no unclear points.\r\nWarning: gpt-3.5-turbo may change over time. Returning num tokens assuming gpt-3.5-turbo-0301.\r\n2023-07-12 21:01:11.573 | INFO     | metagpt.provider.openai_api:update_cost:89 - Total running cost: $0.006 | Max budget: $3.000 | Current cost: $0.003, prompt_tokens=800, completion_tokens=636\r\nTraceback (most recent call last):\r\n  File \"/home/dope/anaconda3/envs/mgpt/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 50, in __call__\r\n    result = await fn(*args, **kwargs)\r\n  File \"/home/dope/Documents/metagpt/metagpt/actions/action.py\", line 60, in _aask_v1\r\n    instruct_content = output_class(**parsed_data)\r\n  File \"pydantic/main.py\", line 331, in pydantic.main.BaseModel.__init__\r\npydantic.error_wrappers.ValidationError: 3 validation errors for prd\r\nProduct Goals\r\n  value is not a valid list (type=type_error.list)\r\nUser Stories\r\n  value is not a valid list (type=type_error.list)\r\nCompetitive Analysis\r\n  value is not a valid list (type=type_error.list)\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/dope/Documents/metagpt/startup.py\", line 29, in <module>\r\n    fire.Fire(main)\r\n  File \"/home/dope/anaconda3/envs/mgpt/lib/python3.9/site-packages/fire-0.5.0-py3.9.egg/fire/core.py\", line 141, in Fire\r\n    component_trace = _Fire(component, args, parsed_flag_args, context, name)\r\n  File \"/home/dope/anaconda3/envs/mgpt/lib/python3.9/site-packages/fire-0.5.0-py3.9.egg/fire/core.py\", line 475, in _Fire\r\n    component, remaining_args = _CallAndUpdateTrace(\r\n  File \"/home/dope/anaconda3/envs/mgpt/lib/python3.9/site-packages/fire-0.5.0-py3.9.egg/fire/core.py\", line 691, in _CallAndUpdateTrace\r\n    component = fn(*varargs, **kwargs)\r\n  File \"/home/dope/Documents/metagpt/startup.py\", line 25, in main\r\n    asyncio.run(startup(idea, investment, n_round))\r\n  File \"/home/dope/anaconda3/envs/mgpt/lib/python3.9/asyncio/runners.py\", line 44, in run\r\n    return loop.run_until_complete(main)\r\n  File \"/home/dope/anaconda3/envs/mgpt/lib/python3.9/asyncio/base_events.py\", line 647, in run_until_complete\r\n    return future.result()\r\n  File \"/home/dope/Documents/metagpt/startup.py\", line 15, in startup\r\n    await company.run(n_round=n_round)\r\n  File \"/home/dope/Documents/metagpt/metagpt/software_company.py\", line 60, in run\r\n    await self.environment.run()\r\n  File \"/home/dope/Documents/metagpt/metagpt/environment.py\", line 64, in run\r\n    await asyncio.gather(*futures)\r\n  File \"/home/dope/Documents/metagpt/metagpt/roles/role.py\", line 229, in run\r\n    rsp = await self._react()\r\n  File \"/home/dope/Documents/metagpt/metagpt/roles/role.py\", line 200, in _react\r\n    return await self._act()\r\n  File \"/home/dope/Documents/metagpt/metagpt/roles/role.py\", line 156, in _act\r\n    response = await self._rc.todo.run(self._rc.important_memory)\r\n  File \"/home/dope/Documents/metagpt/metagpt/actions/write_prd.py\", line 138, in run\r\n    prd = await self._aask_v1(prompt, \"prd\", OUTPUT_MAPPING)\r\n  File \"/home/dope/anaconda3/envs/mgpt/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\r\n    return await fn(*args, **kwargs)\r\n  File \"/home/dope/anaconda3/envs/mgpt/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 47, in __call__\r\n    do = self.iter(retry_state=retry_state)\r\n  File \"/home/dope/anaconda3/envs/mgpt/lib/python3.9/site-packages/tenacity/__init__.py\", line 326, in iter\r\n    raise retry_exc from fut.exception()\r\ntenacity.RetryError: RetryError[<Future at 0x7f806d336a60 state=finished raised ValidationError>]",
      "state": "closed",
      "author": "luberion",
      "author_type": "User",
      "created_at": "2023-07-12T13:02:58Z",
      "updated_at": "2024-10-10T06:40:52Z",
      "closed_at": "2024-10-10T06:40:52Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/39/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "qa6300525"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/39",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/39",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:43.306127",
      "comments": [
        {
          "author": "qa6300525",
          "body": "The issue fundamentally arises from a discrepancy between the output of the LLM and our expectations. \r\n\r\nWe anticipated this:\r\n\r\n## Product Goals:\r\n```python\r\n[\r\n    \"Create ...\",\r\n    \"Provide ...\",\r\n    \"Implement ...\"\r\n]\r\n```\r\nHowever, the actual output was:\r\n\r\n## Product Goals:\r\n 1. Create ...\r",
          "created_at": "2023-07-12T23:23:02Z"
        },
        {
          "author": "geekan",
          "body": "@qa6300525 Some fields can actually be ignored, because the post-role has no dependence on them, even if the parsing error does not affect the effect",
          "created_at": "2023-07-13T01:32:45Z"
        },
        {
          "author": "geekan",
          "body": "https://github.com/geekan/MetaGPT/pull/41 almost fix this issue. pull & retry.",
          "created_at": "2023-07-13T06:26:08Z"
        }
      ]
    },
    {
      "issue_number": 75,
      "title": "How to edit already existing Repos?",
      "body": "Is there a way to edit already existing repositories?\r\nIf so what's the command for that?",
      "state": "closed",
      "author": "Gyro0o",
      "author_type": "User",
      "created_at": "2023-07-25T02:11:04Z",
      "updated_at": "2024-10-10T06:39:22Z",
      "closed_at": "2024-10-10T06:39:21Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/75/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/75",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/75",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:43.488970",
      "comments": [
        {
          "author": "geekan",
          "body": "In the process of doing it, it will take some time. but the idea is very clear",
          "created_at": "2023-07-25T16:47:08Z"
        },
        {
          "author": "better629",
          "body": "`https://docs.deepwisdom.ai/main/en/guide/in_depth_guides/incremental_development.html`",
          "created_at": "2024-10-10T06:39:21Z"
        }
      ]
    },
    {
      "issue_number": 371,
      "title": ". environment for key and variable ",
      "body": "Why is there ko .env variable for storage sou keys to protect user from potentially crime or is not not jedd want to work on that ",
      "state": "closed",
      "author": "martcpp",
      "author_type": "User",
      "created_at": "2023-09-27T08:49:59Z",
      "updated_at": "2024-10-10T05:53:58Z",
      "closed_at": "2024-10-10T05:53:58Z",
      "labels": [
        "discussion"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/371/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/371",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/371",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:45.395455",
      "comments": [
        {
          "author": "iorisa",
          "body": "Could you please provide more details? I'm not quite sure what you mean by 'ko .env'.\r\n\r\n",
          "created_at": "2023-09-29T14:15:27Z"
        },
        {
          "author": "syaikhipin",
          "body": "It means that the config.yaml will be turned into .env on the top file",
          "created_at": "2023-11-29T04:13:49Z"
        },
        {
          "author": "geekan",
          "body": "https://github.com/theskumar/python-dotenv\r\n",
          "created_at": "2023-12-21T09:21:04Z"
        },
        {
          "author": "better629",
          "body": "Since no further responses are needed, we will close it. Please reopen it if necessary.",
          "created_at": "2024-10-10T05:53:58Z"
        }
      ]
    },
    {
      "issue_number": 381,
      "title": "upgrading the installing guided to a set easy setup on the readme.md",
      "body": "i want update the installation guide with step to eg\r\ninstalling using virtual environments virtual and anacondas\r\nthis issues should be assigned to me and label hacktober let me wok on it",
      "state": "closed",
      "author": "martcpp",
      "author_type": "User",
      "created_at": "2023-10-01T01:39:16Z",
      "updated_at": "2024-10-10T05:48:54Z",
      "closed_at": "2024-10-10T05:48:54Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/381/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/381",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/381",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:45.587186",
      "comments": [
        {
          "author": "iorisa",
          "body": "Nice",
          "created_at": "2023-10-11T10:59:51Z"
        },
        {
          "author": "martcpp",
          "body": "Still waiting for it to be assigned before I start working on it @geekan ",
          "created_at": "2023-10-11T11:40:20Z"
        },
        {
          "author": "better629",
          "body": "Since no further responses are needed, we will close it. Please reopen it if necessary.",
          "created_at": "2024-10-10T05:48:54Z"
        }
      ]
    },
    {
      "issue_number": 389,
      "title": "Search example doesn't work",
      "body": "I am running the example search_google.py  and i get the following error. But I put a set & uncomment from the config file. `GOOGLE_API_KEY: \"xxx\"`   and take the # away from it so its all uncommented. technically it should work.\r\n\r\n```\r\n❯ python search_google.py\r\n2023-10-02 22:26:46.137 | INFO     | metagpt.config:__init__:44 - Config loading done.\r\n2023-10-02 22:26:47.243 | INFO     | metagpt.roles.seacher:_act_sp:54 - Alice(Smart Assistant): ready to SearchAndSummarize\r\n2023-10-02 22:26:47.243 | WARNING  | metagpt.actions.search_and_summarize:run:118 - Configure one of SERPAPI_API_KEY, SERPER_API_KEY, GOOGLE_API_KEY to unlock full feature\r\n```",
      "state": "closed",
      "author": "thurft",
      "author_type": "User",
      "created_at": "2023-10-02T21:39:01Z",
      "updated_at": "2024-10-10T04:11:06Z",
      "closed_at": "2024-10-10T04:11:06Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/389/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/389",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/389",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:45.754833",
      "comments": [
        {
          "author": "neilpaulmartin",
          "body": "Have you removed the \"\" also?",
          "created_at": "2023-10-04T20:27:48Z"
        },
        {
          "author": "iorisa",
          "body": "SERPAPI_API_KEY, SERPER_API_KEY, and GOOGLE_API_KEY are all reported as unavailable in the log. Please ensure that the key you used is uncommented and that the value is usable.",
          "created_at": "2023-10-11T10:25:43Z"
        },
        {
          "author": "olsn",
          "body": "The example is poorly documented, after browsing the source-code I found the following solution:\r\nThe default search-engine used in the `Searcher` is SERPAPI.\r\nIf you want to use direct google, you will have to modify the example to to the following:\r\n```\r\n...\r\nfrom metagpt.tools import SearchEngine",
          "created_at": "2023-10-17T14:25:18Z"
        }
      ]
    },
    {
      "issue_number": 467,
      "title": "Adding Contributors section to the readme.md ",
      "body": "Why Contributors section:- A \"Contributors\" section in a repo gives credit to and acknowledges \r\nthe people who have helped with the project, fosters a sense of community, and helps others\r\n know who to contact for questions or issues related to the project.\r\n\r\n**Issue type**\r\n\r\n- [✅] Docs\r\n\r\nExpected Behaviour:- \r\n\r\n![3](https://github.com/geekan/MetaGPT/assets/146939900/6689c0f1-c77a-47e5-b786-5b7b7cfbb448)\r\n",
      "state": "closed",
      "author": "mohitd404",
      "author_type": "User",
      "created_at": "2023-10-29T09:24:51Z",
      "updated_at": "2024-10-10T04:10:51Z",
      "closed_at": "2024-10-10T04:10:51Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/467/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "mohitd404"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/467",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/467",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:45.916352",
      "comments": [
        {
          "author": "mohitd404",
          "body": "@stellaHSR  Kindly assign this, issue to me ! I would love to work on it ! Thank you !",
          "created_at": "2023-10-29T09:25:20Z"
        },
        {
          "author": "mohitd404",
          "body": "@stellaHSR I have made the changes kindly review !!",
          "created_at": "2023-10-29T18:19:26Z"
        },
        {
          "author": "martcpp",
          "body": "Can you share outcome of change using pictures @mohitd404 ",
          "created_at": "2023-11-09T08:32:43Z"
        }
      ]
    },
    {
      "issue_number": 468,
      "title": "Adding code-of-conduct File to the repo !",
      "body": "code-of-conduct:- We propose adding a comprehensive Code of Conduct to our repository to ensure \r\na safe, respectful, and inclusive environment for all contributors and users. This code will \r\nserve as a guideline for behavior, promoting diversity, reducing conflicts, and attracting a \r\nwider range of perspectives.\r\n\r\n**Issue type**\r\n\r\n- [✅] Docs\r\n\r\n@ kindly assign this issue to me ! I would love to work on it ! Thank you !",
      "state": "closed",
      "author": "mohitd404",
      "author_type": "User",
      "created_at": "2023-10-29T09:26:46Z",
      "updated_at": "2024-10-10T04:10:27Z",
      "closed_at": "2024-10-10T04:10:26Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/468/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "mohitd404"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/468",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/468",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:46.095723",
      "comments": [
        {
          "author": "mohitd404",
          "body": "@stellaHSR  kindly assign this issue to me ! I would love to work on it ! Thank you !",
          "created_at": "2023-10-29T09:30:06Z"
        },
        {
          "author": "stellaHSR",
          "body": "Hi, thank you! We would like to have the code of conduct document included in our repository.",
          "created_at": "2023-10-29T16:07:10Z"
        },
        {
          "author": "mohitd404",
          "body": "@stellaHSR I have made the changes kindly review it ! ",
          "created_at": "2023-10-29T18:21:43Z"
        }
      ]
    },
    {
      "issue_number": 737,
      "title": "unsupported operand type(s) for +: 'generator' and 'list' when running researcher case",
      "body": "**Bug description**\r\n<!-- Clearly and directly describe the current bug -->\r\nTypeError: unsupported operand type(s) for +: 'generator' and 'list' occured when I tried to run the researcher case. I thought it was something wrong with my environment, but I tried it in the docker container again and still got the same error.\r\n\r\n**Environment information**\r\n- System version: ubuntu 22.04\r\n- From docker: metagpt/metagpt:latest\r\n- LLM type and model name: gpt-3.5-turbo-16k\r\n\r\n**Snippets from the key.yaml**\r\n```yaml\r\nOPENAI_API_MODEL: \"gpt-3.5-turbo-16k\"\r\nMAX_TOKENS: 4096\r\nRPM: 10\r\nTIMEOUT: 60\r\n\r\nSEARCH_ENGINE: serpapi\r\nWEB_BROWSER_ENGINE: playwright\r\n\r\n### for Research\r\nMODEL_FOR_RESEARCHER_SUMMARY: gpt-3.5-turbo\r\nMODEL_FOR_RESEARCHER_REPORT: gpt-3.5-turbo-16k\r\n```\r\n\r\n**logs**\r\n\r\n```text\r\nTraceback (most recent call last):\r\n  File \"/app/metagpt/metagpt/utils/common.py\", line 497, in wrapper\r\n    return await func(self, *args, **kwargs)\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 482, in run\r\n    rsp = await self.react()\r\n  File \"/app/metagpt/metagpt/roles/researcher.py\", line 105, in react\r\n    msg = await super().react()\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 452, in react\r\n    rsp = await self._act_by_order()\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 439, in _act_by_order\r\n    rsp = await self._act()\r\n  File \"/app/metagpt/metagpt/roles/researcher.py\", line 74, in _act\r\n    summaries = await asyncio.gather(*todos)\r\n  File \"/app/metagpt/metagpt/actions/research.py\", line 223, in run\r\n    for prompt in generate_prompt_chunk(\r\n  File \"/app/metagpt/metagpt/utils/text.py\", line 68, in generate_prompt_chunk\r\n    paragraphs = split_paragraph(paragraph) + paragraphs\r\nTypeError: unsupported operand type(s) for +: 'generator' and 'list'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"/usr/local/lib/python3.9/runpy.py\", line 87, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/app/metagpt/metagpt/roles/researcher.py\", line 126, in <module>\r\n    fire.Fire(main)\r\n  File \"/usr/local/lib/python3.9/site-packages/fire/core.py\", line 141, in Fire\r\n    component_trace = _Fire(component, args, parsed_flag_args, context, name)\r\n  File \"/usr/local/lib/python3.9/site-packages/fire/core.py\", line 466, in _Fire\r\n    component, remaining_args = _CallAndUpdateTrace(\r\n  File \"/usr/local/lib/python3.9/site-packages/fire/core.py\", line 679, in _CallAndUpdateTrace\r\n    component = loop.run_until_complete(fn(*varargs, **kwargs))\r\n  File \"/usr/local/lib/python3.9/asyncio/base_events.py\", line 647, in run_until_complete\r\n    return future.result()\r\n  File \"/app/metagpt/metagpt/roles/researcher.py\", line 124, in main\r\n    await role.run(topic)\r\n  File \"/app/metagpt/metagpt/utils/common.py\", line 513, in wrapper\r\n    raise Exception(format_trackback_info(limit=None))\r\nException: Traceback (most recent call last):\r\n  File \"/app/metagpt/metagpt/utils/common.py\", line 497, in wrapper\r\n    return await func(self, *args, **kwargs)\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 482, in run\r\n    rsp = await self.react()\r\n  File \"/app/metagpt/metagpt/roles/researcher.py\", line 105, in react\r\n    msg = await super().react()\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 452, in react\r\n    rsp = await self._act_by_order()\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 439, in _act_by_order\r\n    rsp = await self._act()\r\n  File \"/app/metagpt/metagpt/roles/researcher.py\", line 74, in _act\r\n    summaries = await asyncio.gather(*todos)\r\n  File \"/app/metagpt/metagpt/actions/research.py\", line 223, in run\r\n    for prompt in generate_prompt_chunk(\r\n  File \"/app/metagpt/metagpt/utils/text.py\", line 68, in generate_prompt_chunk\r\n    paragraphs = split_paragraph(paragraph) + paragraphs\r\nTypeError: unsupported operand type(s) for +: 'generator' and 'list'\r\n\r\n[\"dataiku\", \"datarobot\"][\"dataiku vs datarobot\", \"comparison between dataiku and datarobot\", \"features of dataiku and datarobot\", \"pros and cons of dataiku and datarobot\"][1, 2, 3, 0, 4][1, 2, 3, 0, 4][0, 1, 2, 4, 5, 6][0, 2, 3, 5, 6]\r\n```\r\n",
      "state": "closed",
      "author": "tappat225",
      "author_type": "User",
      "created_at": "2024-01-12T07:37:25Z",
      "updated_at": "2024-10-10T03:54:28Z",
      "closed_at": "2024-10-10T03:54:28Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/737/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "shenchucheng"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/737",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/737",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:46.282328",
      "comments": [
        {
          "author": "tappat225",
          "body": "Solved. It turns out that there is no value check for the max_token which is calculated from the code `max_token = TOKEN_MAX.get(model_name, 2048) - reserved - 100`. As I set `MAX_TOKENS: 4096` in `key.yaml` to 4096, it leads to the calculation result to be less than 0.\r\n\r\n**Solution**\r\nSet `MAX_TOK",
          "created_at": "2024-01-15T10:13:28Z"
        },
        {
          "author": "geekan",
          "body": "@shenchucheng Can you confirm if this issue has been resolved?",
          "created_at": "2024-03-21T11:51:55Z"
        },
        {
          "author": "shenchucheng",
          "body": "> @shenchucheng Can you confirm if this issue has been resolved?\r\n\r\n@geekan Fixxed by https://github.com/geekan/MetaGPT/pull/867.",
          "created_at": "2024-03-22T12:09:07Z"
        }
      ]
    },
    {
      "issue_number": 816,
      "title": "Error because of exceeding max completion tokens",
      "body": "I'm trying out the researcher role example. The code is running fine generating questions, doing web search etc. After a while however it throws an error because it is exceeding the max completion tokens. This happens with every example starting prompt I tried.  I understand that the latest GPT-4 Turbo model has a 128k input tokens context window, but only a 4,096 tokens completion output window. There does not seem to be an easy fix - I checked. \r\n\r\nThings I've tried:\r\n- specifiying my research prompt\r\n- increasing MAX_TOKENS variable (but that was silly as it only controls the input context window)\r\n- setting the long term memory variable to false\r\n- adjusting the class ConductResearch(Action) to try and create chunks of the completions but didn't work out\r\n\r\nAny other ideas?",
      "state": "closed",
      "author": "pas-mllr",
      "author_type": "User",
      "created_at": "2024-01-31T23:31:08Z",
      "updated_at": "2024-10-10T02:54:26Z",
      "closed_at": "2024-10-10T02:54:26Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/816/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "shenchucheng"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/816",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/816",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:46.441930",
      "comments": [
        {
          "author": "pas-mllr",
          "body": "@geekan kind sir?",
          "created_at": "2024-02-01T17:45:17Z"
        },
        {
          "author": "geekan",
          "body": "@pas-mllr thanks for your kind comments, i've reproduced the bug.\r\n\r\n@shenchucheng could you plz check this?",
          "created_at": "2024-03-20T14:47:25Z"
        }
      ]
    },
    {
      "issue_number": 1009,
      "title": "the Bug  source：python examples/di/imitate_webpage.py   is   Incomplete, shutdown  error info",
      "body": "**Bug description**\r\n\r\n\r\n- LLM type and model name:\r\n- openai\r\n-  model: \"gpt-4-1106-preview\" \r\n- Python 3.10:\r\n \r\n\r\n\r\n- packages version:\r\n- MetaGPT  0.76  \r\n\r\n \r\n**Screenshots or code logs**\r\n`File \"/home/miniconda3/envs/metaGpt/lib/python3.11/site-packages/metagpt/roles/di/data_interpreter.py\", line 46, in _act_on_task\r\n    code, result, is_success = await self._write_and_exec_code()\r\n                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/miniconda3/envs/metaGpt/lib/python3.11/site-packages/metagpt/roles/di/data_interpreter.py\", line 58, in _write_and_exec_code\r\n    self.working_memory.add(Message(content=code[\"code\"], role=\"assistant\", cause_by=cause_by))\r\n                                            ~~~~^^^^^^^^\r\nKeyError: 'code'\r\n\r\nDuring handling of the above exception, another exception occurred:`\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/data/MetaGPT/examples/di/imitate_webpage.py\", line 25, in <module>\r\n    asyncio.run(main())\r\n  File \"/home/miniconda3/envs/metaGpt/lib/python3.11/asyncio/runners.py\", line 190, in run\r\n    return runner.run(main)\r\n           ^^^^^^^^^^^^^^^^\r\n  File \"/home/miniconda3/envs/metaGpt/lib/python3.11/asyncio/runners.py\", line 118, in run\r\n    return self._loop.run_until_complete(task)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/miniconda3/envs/metaGpt/lib/python3.11/asyncio/base_events.py\", line 653, in run_until_complete\r\n    return future.result()\r\n           ^^^^^^^^^^^^^^^\r\n  File \"/data/MetaGPT/examples/di/imitate_webpage.py\", line 19, in main\r\n    await di.run(prompt)\r\n  File \"/home/miniconda3/envs/metaGpt/lib/python3.11/site-packages/metagpt/utils/common.py\", line 585, in wrapper\r\n    raise Exception(format_trackback_info(limit=None))\r\nException: Traceback (most recent call last):\r\n  File \"/home/miniconda3/envs/metaGpt/lib/python3.11/site-packages/metagpt/utils/common.py\", line 563, in wrapper\r\n    return await func(self, *args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/miniconda3/envs/metaGpt/lib/python3.11/site-packages/metagpt/roles/role.py\", line 558, in run\r\n    rsp = await self.react()\r\n          ^^^^^^^^^^^^^^^^^^\r\n  File \"/home/miniconda3/envs/metaGpt/lib/python3.11/site-packages/metagpt/roles/role.py\", line 529, in react\r\n    rsp = await self._plan_and_act()\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/miniconda3/envs/metaGpt/lib/python3.11/site-packages/metagpt/roles/role.py\", line 497, in _plan_and_act\r\n    task_result = await self._act_on_task(task)\r\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/miniconda3/envs/metaGpt/lib/python3.11/site-packages/metagpt/roles/di/data_interpreter.py\", line 46, in _act_on_task\r\n    code, result, is_success = await self._write_and_exec_code()\r\n                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/miniconda3/envs/metaGpt/lib/python3.11/site-packages/metagpt/roles/di/data_interpreter.py\", line 58, in _write_and_exec_code\r\n    self.working_memory.add(Message(content=code[\"code\"], role=\"assistant\", cause_by=cause_by))\r\n                                            ~~~~^^^^^^^^\r\nKeyError: 'code'\r\n\r\n(metaGpt) root@xjspace:/data/MetaGPT# [IPKernelApp] WARNING | Parent appears to have exited, shutting down.\r\n",
      "state": "closed",
      "author": "xjspace",
      "author_type": "User",
      "created_at": "2024-03-14T07:03:15Z",
      "updated_at": "2024-10-10T02:45:10Z",
      "closed_at": "2024-10-10T02:45:09Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1009/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1009",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1009",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:46.633053",
      "comments": [
        {
          "author": "garylin2099",
          "body": "Previous version of `code` variable is a dict, but it is changed to a string and properly handled. Try pulling the latest codes and this issue should be fixed.",
          "created_at": "2024-03-14T09:16:12Z"
        },
        {
          "author": "xjspace",
          "body": "> Previous version of `code` variable is a dict, but it is changed to a string and properly handled. Try pulling the latest codes and this issue should be fixed.\r\nI'll give it a try\r\n",
          "created_at": "2024-03-14T12:04:31Z"
        },
        {
          "author": "geekan",
          "body": "@xjspace Can you confirm that this issue has been resolved?",
          "created_at": "2024-03-21T03:35:30Z"
        },
        {
          "author": "better629",
          "body": "Due to the lack of updates or replies by the user for a long time, we will close it. Please reopen it if necessary.",
          "created_at": "2024-10-10T02:45:09Z"
        }
      ]
    },
    {
      "issue_number": 1013,
      "title": "ProjectRepo raise `ValueError(\"Invalid root\")` when using `--recover-path`",
      "body": "**Bug description**\r\n![image](https://github.com/geekan/MetaGPT/assets/46912756/9f1a6626-6e24-407b-8cb6-d1303c5dd32a)",
      "state": "closed",
      "author": "iorisa",
      "author_type": "User",
      "created_at": "2024-03-15T09:01:29Z",
      "updated_at": "2024-10-10T02:44:25Z",
      "closed_at": "2024-10-10T02:44:25Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1013/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 1
      },
      "assignees": [
        "better629"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1013",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1013",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:46.832260",
      "comments": []
    },
    {
      "issue_number": 1023,
      "title": "AttributeError: 'NoneType' object has no attribute 'startswith' when running \"Researcher\" example with Gemini",
      "body": "**Bug description**\r\nRunning an example provided on the web site - https://docs.deepwisdom.ai/main/en/guide/use_cases/agent/researcher.html - fails when using \"gemini\" model:\r\n\r\n**Environment information**\r\nSystem version - Windows 11\r\nPython version - Python 3.10.9\r\nLLM type and model - Gemini\r\n\r\nInstallation method: \"development mode\"\r\ngit clone https://github.com/geekan/MetaGPT.git\r\n\r\nconfig2.example.yaml:\r\nllm:\r\n  api_type: 'gemini'\r\n  api_key: 'XXXXXXXXXXXXXXXXXXXXXXXXXXX'\r\n\r\nsearch:\r\n  api_type: \"google\"\r\n  api_key: \"XXXXXXXXXXXXXXXXXXXXXXXXXXX\"\r\n  cse_id: \"XXXXXXXXXXXXXX\"\r\n\r\n\r\n\r\n(metagpt) PS C:\\Users\\user\\code\\test\\MetaGPT> python -m metagpt.roles.researcher \"tensorflow vs. pytorch\"\r\n2024-03-17 18:28:13.795 | INFO     | metagpt.const:get_metagpt_package_root:29 - Package root set to C:\\Users\\user\\code\\test\\MetaGPT\r\n2024-03-17 18:28:23.681 | INFO     | __main__:_act:56 - David(Researcher): to do CollectLinks(David)\r\n[\"Machine learning\", \"Natural language processing\"]\r\n2024-03-17 18:28:24.807 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.000 | Max budget: $10.000 | Current cost: $0.000, prompt_tokens: 37, completion_tokens: 10\r\n2024-03-17 18:28:25.233 | WARNING  | metagpt.utils.common:wrapper:647 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\utils\\common.py\", line 638, in wrapper\r\n    return await func(self, *args, **kwargs)\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\roles\\role.py\", line 548, in run\r\n    rsp = await self.react()\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\roles\\researcher.py\", line 105, in react\r\n    msg = await super().react()\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\roles\\role.py\", line 517, in react\r\n    rsp = await self._act_by_order()\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\roles\\role.py\", line 471, in _act_by_order\r\n    rsp = await self._act()\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\roles\\researcher.py\", line 67, in _act\r\n    links = await todo.run(topic, 4, 4)\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\actions\\research.py\", line 137, in run\r\n    prompt = reduce_message_length(gen_msg(), model_name, system_text, config.llm.max_token)\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\utils\\text.py\", line 26, in reduce_message_length\r\n    max_token = TOKEN_MAX.get(model_name, 2048) - count_string_tokens(system_text, model_name) - reserved\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\utils\\token_counter.py\", line 262, in count_string_tokens\r\n    encoding = tiktoken.encoding_for_model(model_name)\r\n  File \"C:\\Users\\user\\scoop\\apps\\miniconda3\\current\\envs\\metagpt\\lib\\site-packages\\tiktoken\\model.py\", line 97, in encoding_for_model\r\n    return get_encoding(encoding_name_for_model(model_name))\r\n  File \"C:\\Users\\user\\scoop\\apps\\miniconda3\\current\\envs\\metagpt\\lib\\site-packages\\tiktoken\\model.py\", line 80, in encoding_name_for_model\r\n    if model_name.startswith(model_prefix):\r\nAttributeError: 'NoneType' object has no attribute 'startswith'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\user\\scoop\\apps\\miniconda3\\current\\envs\\metagpt\\lib\\runpy.py\", line 196, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"C:\\Users\\user\\scoop\\apps\\miniconda3\\current\\envs\\metagpt\\lib\\runpy.py\", line 86, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\roles\\researcher.py\", line 126, in <module>\r\n    fire.Fire(main)\r\n  File \"C:\\Users\\user\\scoop\\apps\\miniconda3\\current\\envs\\metagpt\\lib\\site-packages\\fire\\core.py\", line 141, in Fire\r\n    component_trace = _Fire(component, args, parsed_flag_args, context, name)\r\n  File \"C:\\Users\\user\\scoop\\apps\\miniconda3\\current\\envs\\metagpt\\lib\\site-packages\\fire\\core.py\", line 466, in _Fire\r\n    component, remaining_args = _CallAndUpdateTrace(\r\n  File \"C:\\Users\\user\\scoop\\apps\\miniconda3\\current\\envs\\metagpt\\lib\\site-packages\\fire\\core.py\", line 679, in _CallAndUpdateTrace\r\n    component = loop.run_until_complete(fn(*varargs, **kwargs))\r\n  File \"C:\\Users\\user\\scoop\\apps\\miniconda3\\current\\envs\\metagpt\\lib\\asyncio\\base_events.py\", line 649, in run_until_complete\r\n    return future.result()\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\roles\\researcher.py\", line 124, in main\r\n    await role.run(topic)\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\utils\\common.py\", line 660, in wrapper\r\n    raise Exception(format_trackback_info(limit=None))\r\nException: Traceback (most recent call last):\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\utils\\common.py\", line 638, in wrapper\r\n    return await func(self, *args, **kwargs)\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\roles\\role.py\", line 548, in run\r\n    rsp = await self.react()\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\roles\\researcher.py\", line 105, in react\r\n    msg = await super().react()\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\roles\\role.py\", line 517, in react\r\n    rsp = await self._act_by_order()\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\roles\\role.py\", line 471, in _act_by_order\r\n    rsp = await self._act()\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\roles\\researcher.py\", line 67, in _act\r\n    links = await todo.run(topic, 4, 4)\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\actions\\research.py\", line 137, in run\r\n    prompt = reduce_message_length(gen_msg(), model_name, system_text, config.llm.max_token)\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\utils\\text.py\", line 26, in reduce_message_length\r\n    max_token = TOKEN_MAX.get(model_name, 2048) - count_string_tokens(system_text, model_name) - reserved\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\utils\\token_counter.py\", line 262, in count_string_tokens\r\n    encoding = tiktoken.encoding_for_model(model_name)\r\n  File \"C:\\Users\\user\\scoop\\apps\\miniconda3\\current\\envs\\metagpt\\lib\\site-packages\\tiktoken\\model.py\", line 97, in encoding_for_model\r\n    return get_encoding(encoding_name_for_model(model_name))\r\n  File \"C:\\Users\\user\\scoop\\apps\\miniconda3\\current\\envs\\metagpt\\lib\\site-packages\\tiktoken\\model.py\", line 80, in encoding_name_for_model\r\n    if model_name.startswith(model_prefix):\r\nAttributeError: 'NoneType' object has no attribute 'startswith'\r\n\r\n\r\n\r\n",
      "state": "closed",
      "author": "vmsysadm",
      "author_type": "User",
      "created_at": "2024-03-18T00:38:48Z",
      "updated_at": "2024-10-10T02:43:46Z",
      "closed_at": "2024-10-10T02:43:46Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1023/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "geekan"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1023",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1023",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:46.832279",
      "comments": [
        {
          "author": "iorisa",
          "body": "This log indicates that `model_name` is None:\r\n```text\r\nif model_name.startswith(model_prefix):\r\nAttributeError: 'NoneType' object has no attribute 'startswith'\r\n```\r\nAccording to the source code:\r\n```python\r\n        model_name = config.llm.model\r\n        prompt = reduce_message_length(gen_msg(), mo",
          "created_at": "2024-03-19T05:27:45Z"
        },
        {
          "author": "vmsysadm",
          "body": "Thank you for the information, that works! You may want to update your \"Configuration\" page https://docs.deepwisdom.ai/main/en/guide/get_started/configuration.html to mention that the Gemini model must be specified explicitly:\r\n\r\nGoogle Gemini\r\n\r\nsupports default model gemini-pro\r\nllm:\r\n  api_type: ",
          "created_at": "2024-03-19T19:14:01Z"
        },
        {
          "author": "geekan",
          "body": "Added to document. Will show up when it is redeployed",
          "created_at": "2024-03-21T03:29:08Z"
        }
      ]
    },
    {
      "issue_number": 1028,
      "title": "What kind of computer can run this model?",
      "body": "Can mac studio run this model?\r\nHow much memory dose this memory need?",
      "state": "closed",
      "author": "learningendless",
      "author_type": "User",
      "created_at": "2024-03-18T08:45:25Z",
      "updated_at": "2024-10-10T02:43:23Z",
      "closed_at": "2024-10-10T02:43:23Z",
      "labels": [
        "dataset"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1028/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "voidking"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1028",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1028",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:47.021097",
      "comments": [
        {
          "author": "devinambron",
          "body": "Yes, a Mac Studio with at least 16 GB RAM can run MetaGPT for basic tasks. Depending on what you're utilizing the model for, 32 GB RAM or more might work best.",
          "created_at": "2024-03-18T21:42:29Z"
        },
        {
          "author": "voidking",
          "body": "MetaGPT will call the remote LLM during operation, so it requires very few local resources.\r\nIf you just run MetaGPT on Mac Stutio, I think 4C8G is completely sufficient. \r\nIf you just run MetaGPT on Linux, I think 1C2G is sufficient.",
          "created_at": "2024-03-21T03:31:15Z"
        },
        {
          "author": "geekan",
          "body": "Maybe we need to have a list of different task success rates for different language models. This may be a data set requirement, but it is reasonable",
          "created_at": "2024-03-21T05:28:33Z"
        },
        {
          "author": "xenon0906",
          "body": "> Yes, a Mac Studio with at least 16 GB RAM can run MetaGPT for basic tasks. Depending on what you're utilizing the model for, 32 GB RAM or more might work best.\r\n\r\nI believe it totally depends on the size of the dataset and number of time the data is gonna be train in the model \r\nAs per my consider",
          "created_at": "2024-09-18T05:26:15Z"
        }
      ]
    },
    {
      "issue_number": 1052,
      "title": "Snake demo issue; FileNotFoundError: [Errno 2] No such file or directory: 'node_modules/.bin/browsers'",
      "body": "\r\nWhen I tried to run a demo using WSLg in Docker on WSL, I encountered the following error:\r\n\r\nHow can I fix this issue?\r\n\r\n```bash\r\n2024-03-20 02:39:20.007 | INFO     | metagpt.utils.file_repository:save:60 - save to: /app/metagpt/workspace/20240320023843/resources/prd/20240320023917.md\r\n2024-03-20 02:39:20.009 | INFO     | metagpt.roles.role:_act:399 - Bob(Architect): to do WriteDesign(WriteDesign)\r\n2024-03-20 02:39:20.064 | INFO     | metagpt.actions.design_api:run:67 - Nothing has changed.\r\n2024-03-20 02:39:20.066 | INFO     | metagpt.roles.role:_act:399 - Eve(Project Manager): to do WriteTasks(WriteTasks)\r\n2024-03-20 02:39:20.121 | INFO     | metagpt.actions.project_management:run:54 - Nothing has changed.\r\n2024-03-20 02:39:20.256 | INFO     | metagpt.utils.git_repository:archive:168 - Archive: ['node_modules/.bin/browsers', 'node_modules/.bin/extract-zip', 'node_modules/.bin/js-yaml', 'node_modules/.bin/mmdc', 'node_modules/.package-lock.json', 'node_modules/@babel/code-frame/LICENSE', 'node_modules/@babel/code-frame/README.md', 'node_modules/@babel/code-frame/node_modules/ansi-styles/index.js', 'node_modules/@babel/code-frame/node_modules/ansi-styles/license', 'node_modules/@babel/code-frame/node_modules/ansi-styles/package.json', 'node_modules/@babel/code-frame/node_modules/ansi-styles/readme.md', 'node_modules/@babel/code-frame/node_modules/chalk/index.js', 'nod\r\n\r\n...\r\n\r\n2024-03-20 02:39:20.281 | ERROR    | metagpt.utils.common:wrapper:553 - Exception occurs, start to serialize the project, exp:\r\nTraceback (most recent call last):\r\n  File \"/app/metagpt/metagpt/utils/common.py\", line 548, in wrapper\r\n    result = await func(self, *args, **kwargs)\r\n  File \"/app/metagpt/metagpt/team.py\", line 135, in run\r\n    self.env.archive(auto_archive)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'node_modules/.bin/browsers'\r\n```",
      "state": "closed",
      "author": "Sunwood-ai-labs",
      "author_type": "User",
      "created_at": "2024-03-20T02:44:53Z",
      "updated_at": "2024-10-10T02:41:30Z",
      "closed_at": "2024-10-10T02:41:30Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1052/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "better629"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1052",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1052",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:47.183948",
      "comments": [
        {
          "author": "iorisa",
          "body": "It seems caused by this issue: #1035.\r\nTry out main branch.",
          "created_at": "2024-03-20T03:29:42Z"
        }
      ]
    },
    {
      "issue_number": 1100,
      "title": "debate example fail to work with gemini",
      "body": "**Bug description**\r\ndebate example throws error with gemini-pro 1.5.\r\nWebsearch works with gemini-pro\r\n\r\n**Bug solved method**\r\n\r\n**Environment information**\r\nPython 3.9\r\nConda\r\n\r\n- LLM type and model name: Gemini-Pro\r\n- System version:\r\n- Python version: 3.9\r\n\r\n\r\n**Screenshots or logs**\r\npython3 debate.py \"Talk about Artificial General Intelligence\"\r\n2024-03-25 17:57:01.666 | INFO     | metagpt.const:get_metagpt_package_root:29 - Package root set to /Users/samsaha2\r\n2024-03-25 17:57:03.800 | INFO     | metagpt.team:invest:90 - Investment: $3.0.\r\n2024-03-25 17:57:03.801 | INFO     | __main__:_act:63 - Biden(Democrat): to do SpeakAloud(SpeakAloud)\r\n2024-03-25 17:57:06.072 | WARNING  | metagpt.utils.common:wrapper:572 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.\r\n2024-03-25 17:57:06.081 | ERROR    | metagpt.utils.common:wrapper:554 - Exception occurs, start to serialize the project, exp:\r\nTraceback (most recent call last):\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/metagpt/utils/common.py\", line 563, in wrapper\r\n    return await func(self, *args, **kwargs)\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/metagpt/roles/role.py\", line 558, in run\r\n    rsp = await self.react()\r\nValueError: The `response.text` quick accessor only works for simple (single-`Part`) text responses. This response is not simple text.Use the `result.parts` accessor or the full `result.candidates[index].content.parts` lookup instead.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/metagpt/utils/common.py\", line 549, in wrapper\r\n    result = await func(self, *args, **kwargs)\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/metagpt/team.py\", line 134, in run\r\n    await self.env.run()\r\nException: Traceback (most recent call last):\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/metagpt/utils/common.py\", line 563, in wrapper\r\n    return await func(self, *args, **kwargs)\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/metagpt/roles/role.py\", line 558, in run\r\n    rsp = await self.react()\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/metagpt/roles/role.py\", line 525, in react\r\n    rsp = await self._react()\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/metagpt/roles/role.py\", line 471, in _react\r\n    rsp = await self._act()\r\n  File \"/Users/samsaha2/debate.py\", line 70, in _act\r\n    rsp = await todo.run(context=context, name=self.name, opponent_name=self.opponent_name)\r\n  File \"/Users/samsaha2/debate.py\", line 41, in run\r\n    rsp = await self._aask(prompt)\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/metagpt/actions/action.py\", line 93, in _aask\r\n    return await self.llm.aask(prompt, system_msgs)\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/metagpt/provider/base_llm.py\", line 89, in aask\r\n    rsp = await self.acompletion_text(message, stream=stream, timeout=timeout)\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\r\n    return await fn(*args, **kwargs)\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 47, in __call__\r\n    do = self.iter(retry_state=retry_state)\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/tenacity/__init__.py\", line 314, in iter\r\n    return fut.result()\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/concurrent/futures/_base.py\", line 439, in result\r\n    return self.__get_result()\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/concurrent/futures/_base.py\", line 391, in __get_result\r\n    raise self._exception\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 50, in __call__\r\n    result = await fn(*args, **kwargs)\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/metagpt/provider/google_gemini_api.py\", line 147, in acompletion_text\r\n    return await self._achat_completion_stream(messages)\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/metagpt/provider/google_gemini_api.py\", line 127, in _achat_completion_stream\r\n    content = chunk.text\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/google/generativeai/types/generation_types.py\", line 328, in text\r\n    raise ValueError(\r\nValueError: The `response.text` quick accessor only works for simple (single-`Part`) text responses. This response is not simple text.Use the `result.parts` accessor or the full `result.candidates[index].content.parts` lookup instead.\r\n\r\n\r\n",
      "state": "closed",
      "author": "iitrsamrat",
      "author_type": "User",
      "created_at": "2024-03-25T12:31:43Z",
      "updated_at": "2024-10-10T02:40:14Z",
      "closed_at": "2024-10-10T02:40:14Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1100/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1100",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1100",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:47.390938",
      "comments": [
        {
          "author": "iorisa",
          "body": "It's blocked by gemini:\r\n```\r\n[category: HARM_CATEGORY_SEXUALLY_EXPLICIT\r\nprobability: NEGLIGIBLE\r\n, category: HARM_CATEGORY_HATE_SPEECH\r\nprobability: NEGLIGIBLE\r\n, category: HARM_CATEGORY_HARASSMENT\r\nprobability: NEGLIGIBLE\r\n, category: HARM_CATEGORY_DANGEROUS_CONTENT\r\nprobability: NEGLIGIBLE\r\n]\r\n`",
          "created_at": "2024-03-25T13:24:05Z"
        },
        {
          "author": "iitrsamrat",
          "body": "My prompt for debate is the following.\r\n\"\r\n\"Talk about Artificial General Intelligence\"\r\n\"\r\nHow to debug if it is blocked I am just running on command line as below.\r\n\r\npython3 debate.py \"Talk about Artificial General Intelligence\"",
          "created_at": "2024-03-25T13:33:27Z"
        },
        {
          "author": "geekan",
          "body": "Try `examples/debate_simple.py`?\r\n\r\nremove line 17 and line 19 to use your config in the file.",
          "created_at": "2024-03-25T13:38:03Z"
        },
        {
          "author": "iitrsamrat",
          "body": "\r\nGot the following error.\r\n\r\nModified debate_simple.py\r\n`\r\n#!/usr/bin/env python\r\n# -*- coding: utf-8 -*-\r\n\"\"\"\r\n@Time    : 2023/12/22\r\n@Author  : alexanderwu\r\n@File    : debate_simple.py\r\n\"\"\"\r\nimport asyncio\r\n\r\nfrom metagpt.actions import Action\r\nfrom metagpt.config2 import Config\r\nfrom metagpt.env",
          "created_at": "2024-03-25T13:44:04Z"
        },
        {
          "author": "iorisa",
          "body": "I'll add some codes to throw a `ValueError` exception when gemini blocked the chat, in order to notify the external user.",
          "created_at": "2024-03-25T13:51:29Z"
        }
      ]
    },
    {
      "issue_number": 1117,
      "title": "关于狼人项目的跟进",
      "body": "你们好，我已经根据你们之前的狼人项目进行改进，并做了一些有意思的工作，但是我观察到metagpt新版本有很多激动人心的功能，但狼人项目跟这个版本差异过大，并不能使用这些新功能，因此想问一下关于狼人项目的迁移，近期是否有打算去做呢？\r\n万分感谢。",
      "state": "closed",
      "author": "nameBai",
      "author_type": "User",
      "created_at": "2024-03-27T04:53:39Z",
      "updated_at": "2024-10-10T02:36:41Z",
      "closed_at": "2024-10-10T02:36:41Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1117/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "better629"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1117",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1117",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:47.647871",
      "comments": [
        {
          "author": "geekan",
          "body": "Can you tell us about “interesting jobs”? Then we might know how to modify it",
          "created_at": "2024-03-27T07:40:45Z"
        },
        {
          "author": "iorisa",
          "body": "可以提PR，或者把问题代码贴出来，我告你怎么升级到最新metagpt代码。",
          "created_at": "2024-03-27T07:57:14Z"
        },
        {
          "author": "nameBai",
          "body": "好的，我先看看，有问题我会提出",
          "created_at": "2024-03-27T08:09:56Z"
        },
        {
          "author": "nameBai",
          "body": "> Can you tell us about “interesting jobs”? Then we might know how to modify it\r\n\r\n我们打算利用metagpt做一个教学场景的复杂模拟，新的框架调整了角色记忆和环境的逻辑，每个角色使用不用的llm_config以及原生支持各类的商业大模型的特点，这都是原有框架没有的。",
          "created_at": "2024-03-27T08:42:04Z"
        },
        {
          "author": "geekan",
          "body": "Do you mean tutorial on werewolf scene? Or it's a real education scene?",
          "created_at": "2024-03-28T07:02:05Z"
        }
      ]
    },
    {
      "issue_number": 1132,
      "title": "Minecraft Environment which is contained in the release version is not adapted by Windows",
      "body": "The Release version somehow put Minecraft (which is a independent branch, not in the main branch) in to it.\r\nThis \"Minecraft Environment\" has several packages which are only supported in Linux such as Langchain.\r\nIf you just use `pip install metagpt` in Windows, you will get error \"No module named pwd\" as the package pwd is Unix Specific Service\r\nTry to use manual installation rather than pip. And please fix this thank you.\r\n\r\n中文版本（Chinese Version）：\r\n发行版本中，不知怎么搞的把Minecraft那个Branch拿进来了。这个Branch里有一些Linux依赖，例如Langchain。直接`pip install metagpt`会报错\"No module named pwd\"，建议手动安装。请作者修复这个问题，移除Minecraft环境，或者让Minecraft环境变得同时适配Windows和Linux。\r\n",
      "state": "closed",
      "author": "RyanLoil",
      "author_type": "User",
      "created_at": "2024-03-28T10:07:26Z",
      "updated_at": "2024-10-10T02:35:42Z",
      "closed_at": "2024-10-10T02:35:42Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 16,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1132/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "better629"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1132",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1132",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:47.843094",
      "comments": [
        {
          "author": "geekan",
          "body": "@RyanLoil We should not have any dependencies on langchain (main branch) now. Can you post your specific environment and package version?",
          "created_at": "2024-03-28T14:56:42Z"
        },
        {
          "author": "RyanLoil",
          "body": "Here is the dependencies requirement list from [Metagpt 0.7.7 release version](https://files.pythonhosted.org/packages/bc/22/732a40ccd2da1164e5ce0b4e57fbf6ac530aae1e390fa475673cf862fb64/metagpt-0.7.7.tar.gz) from pypi\r\n\r\n> aiohttp==3.8.4\r\n> channels==4.0.0\r\n> faiss_cpu==1.7.4\r\n> fire==0.4.0\r\n> typer",
          "created_at": "2024-03-29T05:43:12Z"
        },
        {
          "author": "RyanLoil",
          "body": "Also I highly recommended that please do not use the dependencies versions which are too specific, many frameworks got abandoned due to this issue.",
          "created_at": "2024-03-29T05:45:45Z"
        },
        {
          "author": "better629",
          "body": "@RyanLoil maybe you can try main which removed langchain.",
          "created_at": "2024-03-29T06:17:52Z"
        },
        {
          "author": "RyanLoil",
          "body": "> @RyanLoil maybe you can try main which removed langchain.\r\n\r\nI have already done that. Just in case I submitted this issue.",
          "created_at": "2024-03-29T06:19:06Z"
        }
      ]
    },
    {
      "issue_number": 1240,
      "title": "怎么在MetaGPT基础上使用ComfyUI? 怎么把基本大模型接口变成Ollama?",
      "body": "**Feature description**\r\n<!-- Clear and direct description of the functionality of the currently submitted or proposed feature -->\r\n怎么在MetaGPT基础上使用ComfyUI? 怎么把基本大模型接口变成Ollama?\r\n\r\n**Your Feature**\r\n<!-- Describe the idea or process of implementing the current feature. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- When submitting features, you need to complete the corresponding doc/tests/examples to facilitate verification by reviewers. -->\r\n\r\n画图:\r\n\r\n`ollama` <-> `MetaGPT` <->  `ComfyUI` \r\n\r\n以此组装一个代理工作流?",
      "state": "closed",
      "author": "qwas982",
      "author_type": "User",
      "created_at": "2024-05-01T11:51:21Z",
      "updated_at": "2024-10-10T02:12:09Z",
      "closed_at": "2024-10-10T02:12:08Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1240/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "better629"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1240",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1240",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:48.068178",
      "comments": [
        {
          "author": "qwas982",
          "body": "ComfyUI原来是画画专用,\r\n我想把它用作coding. \r\n如何做?",
          "created_at": "2024-05-01T11:52:56Z"
        },
        {
          "author": "better629",
          "body": "using ollama according to `https://docs.deepwisdom.ai/main/en/guide/tutorials/integration_with_open_llm.html#ollama`",
          "created_at": "2024-05-25T06:05:53Z"
        },
        {
          "author": "qwas982",
          "body": "我认为架构都要重新设计,\r\n\r\n大模型它不可能自动访问周边的工具,虽然都在电脑里,在操作系统里,\r\n在这种情况下,用py写一些代码去控制大模型做事,有些疲于奔命 南辕北辙.\r\n最好的方式是让大模型自动识别代理工作流的各步骤,让它模仿人的操作流程,\r\n让它写码就在VSCode里写,访问网页就在浏览器里浏览,画图就用blender画,\r\n\r\n但是大模型没长手,这种情况下怎么办?\r\n大模型如何去启动这些工具,如何在工具里操作?\r\n微软最近的发布会` Build 2024 `给出了答案,\r\n\r\n# 放一个摄像头照屏幕,把图像实时传输给大模型,把鼠标或键盘的输入控制交给大模型,   \r\n这里得出的结论是",
          "created_at": "2024-05-28T02:51:18Z"
        },
        {
          "author": "geekan",
          "body": "非常感谢你热情洋溢的发言，但是大语言模型操作计算机成功率目前普遍低于 15",
          "created_at": "2024-06-01T06:50:15Z"
        },
        {
          "author": "qwas982",
          "body": "> 非常感谢你热情洋溢的发言，但是大语言模型操作计算机成功率目前普遍低于 15\r\n\r\n不客气,\r\n原来还处于比较初始的水平,\r\n看来大模型行业还有巨大潜力",
          "created_at": "2024-06-25T02:22:42Z"
        }
      ]
    },
    {
      "issue_number": 1275,
      "title": "Function _achat_completion_stream in metagpt/provider/openai_api.py produced TypeError: openai.types.completion_usage.CompletionUsage() argument after ** must be a mapping, not NoneType",
      "body": "**Bug description**\r\nRunning the example code llm_hello_world.py on branch v0.8-release will produce a TypeError. See logs below.\r\n\r\n**Screenshots or logs**\r\n\r\nTraceback (most recent call last):\r\n  File \"/workspaces/MetaGPT/examples/llm_hello_world.py\", line 43, in <module>\r\n    asyncio.run(main())\r\n  File \"/usr/local/lib/python3.9/asyncio/runners.py\", line 44, in run\r\n    return loop.run_until_complete(main)\r\n  File \"/usr/local/lib/python3.9/asyncio/base_events.py\", line 647, in run_until_complete\r\n    return future.result()\r\n  File \"/workspaces/MetaGPT/examples/llm_hello_world.py\", line 19, in main\r\n    logger.info(await llm.aask(question))\r\n  File \"/workspaces/MetaGPT/metagpt/provider/base_llm.py\", line 150, in aask\r\n    rsp = await self.acompletion_text(message, stream=stream, timeout=self.get_timeout(timeout))\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\r\n    return await fn(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 47, in __call__\r\n    do = self.iter(retry_state=retry_state)\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/__init__.py\", line 314, in iter\r\n    return fut.result()\r\n  File \"/usr/local/lib/python3.9/concurrent/futures/_base.py\", line 439, in result\r\n    return self.__get_result()\r\n  File \"/usr/local/lib/python3.9/concurrent/futures/_base.py\", line 391, in __get_result\r\n    raise self._exception\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 50, in __call__\r\n    result = await fn(*args, **kwargs)\r\n  File \"/workspaces/MetaGPT/metagpt/provider/openai_api.py\", line 141, in acompletion_text\r\n    return await self._achat_completion_stream(messages, timeout=timeout)\r\n  File \"/workspaces/MetaGPT/metagpt/provider/openai_api.py\", line 94, in _achat_completion_stream\r\n    usage = CompletionUsage(**chunk.usage)\r\nTypeError: openai.types.completion_usage.CompletionUsage() argument after ** must be a mapping, not NoneType\r\n",
      "state": "closed",
      "author": "garylin2099",
      "author_type": "User",
      "created_at": "2024-05-15T08:48:36Z",
      "updated_at": "2024-10-10T01:47:39Z",
      "closed_at": "2024-10-10T01:47:39Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1275/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1275",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1275",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:48.272162",
      "comments": []
    }
  ]
}