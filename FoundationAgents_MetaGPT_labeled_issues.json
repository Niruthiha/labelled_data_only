{
  "repository": "FoundationAgents/MetaGPT",
  "repository_info": {
    "repo": "FoundationAgents/MetaGPT",
    "stars": 56571,
    "language": "Python",
    "description": "ğŸŒŸ The Multi-Agent Framework: First AI Software Company, Towards Natural Language Programming",
    "url": "https://github.com/FoundationAgents/MetaGPT",
    "topics": [
      "agent",
      "gpt",
      "llm",
      "metagpt",
      "multi-agent"
    ],
    "created_at": "2023-06-30T09:04:55Z",
    "updated_at": "2025-06-21T22:59:20Z",
    "search_query": "ai agent language:python stars:>3 -framework",
    "total_issues_estimate": 124,
    "labeled_issues_estimate": 97,
    "labeling_rate": 78.9,
    "sample_labeled": 30,
    "sample_total": 38,
    "has_issues": true,
    "repo_id": 660551251,
    "default_branch": "main",
    "size": 184017
  },
  "extraction_date": "2025-06-21T22:47:50.016125",
  "extraction_type": "LABELED_ISSUES_ONLY",
  "total_labeled_issues": 212,
  "issues": [
    {
      "issue_number": 1836,
      "title": "openai.types.completion_usage.CompletionUsage() argument after ** must be a mapping, not NoneType",
      "body": "[/CONTENT]2025-05-22 15:39:19.772 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 28.469(s), this was the 1st time calling it. exp: openai.types.completion_usage.CompletionUsage() argument after ** must be a mapping, not NoneType\n\nè§£å†³:\nåªèƒ½ä½¿ç”¨å®˜æ–¹deepseekçš„apiï¼Œä½¿ç”¨éå®˜æ–¹çš„deepseek apiä¼šå‡ºç°ä¸Šè¿°é—®é¢˜(æˆ‘ä½¿ç”¨ç™¾ç‚¼å¹³å°å’Œè¶…ç®—ä¸­å¿ƒæä¾›å…è´¹apiï¼Œä¸€ç›´ä¼šå‡ºç°ä¸Šè¿°é—®é¢˜)ã€‚",
      "state": "open",
      "author": "HappyVing",
      "author_type": "User",
      "created_at": "2025-05-22T07:56:58Z",
      "updated_at": "2025-06-22T00:40:41Z",
      "closed_at": null,
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1836/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1836",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1836",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:46.994241",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-22T00:40:10Z"
        },
        {
          "author": "HappyVing",
          "body": "å·²ç»æ”¶åˆ°ä½ çš„é‚®ä»¶å•¦~~~~~~",
          "created_at": "2025-06-22T00:40:41Z"
        }
      ]
    },
    {
      "issue_number": 1816,
      "title": "æ€æ ·è®©Alexå·¥ä½œï¼Ÿ",
      "body": "**Feature description**\næˆ‘è®©MGä¸ºæˆ‘å¼€å‘ä¸€ä¸ªå·¥å…·ï¼Œé¦–å…ˆAliceå®Œæˆäº†PRDï¼Œç„¶åBobè®¾è®¡äº†ç³»ç»Ÿæ¶æ„ï¼Œä½†Alixeæ²¡æœ‰å¼€å‘å°±ç»“æŸäº†\n\n![Image](https://github.com/user-attachments/assets/269245c1-5ffa-4440-b7b2-64beac41f301)",
      "state": "closed",
      "author": "pulj26pulj26",
      "author_type": "User",
      "created_at": "2025-04-24T03:22:01Z",
      "updated_at": "2025-06-22T00:40:14Z",
      "closed_at": "2025-06-22T00:40:14Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1816/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1816",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1816",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:47.186578",
      "comments": [
        {
          "author": "muchengxuev587",
          "body": "æˆ‘ä¹Ÿæ˜¯ã€‚ã€‚ã€‚å¾ˆä¹…ä»¥å‰çš„ç‰ˆæœ¬è²Œä¼¼ä¸ä¼šè¿™æ ·",
          "created_at": "2025-04-29T06:48:04Z"
        },
        {
          "author": "leason-lyx",
          "body": "æˆ‘ç”¨æœ€æ–°çš„be6921cç‰ˆæœ¬ï¼Œé‡åˆ°åŒæ ·çš„é—®é¢˜",
          "created_at": "2025-05-08T12:30:31Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-08T00:39:57Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-06-22T00:40:14Z"
        }
      ]
    },
    {
      "issue_number": 1831,
      "title": "mgx_envç¯å¢ƒä¸teamleaderè®¾ç½®çš„é—®é¢˜bug",
      "body": "æŠ¥é”™å†…å®¹ï¼š\n\nAttributeError: 'NoneType' object has no attribute 'profile'\n\nè¿è¡Œdebate.pyç­‰ç¤ºä¾‹æ—¶ï¼Œéƒ½ä¼šæŠ¥é”™ã€‚æ·»åŠ äº†`TeamLeader()`åï¼Œæœ€ç»ˆçš„`SimpleCoder(Role)`ï¼Œä¸ä¼šæ‰§è¡Œ_actç­‰æ–¹æ³•ï¼Œå¯¼è‡´æ•ˆæœæœ‰é—®é¢˜ã€‚\n\nåŸå› åˆ†æï¼š\né¦–å…ˆä¸åŠ  `TeamLeader()` ç±»æŠ¥é”™çš„åŸå› æ˜¯å› ä¸ºåœ¨mgx_env.pyçš„æ–‡ä»¶ä¸­ï¼Œè°ƒç”¨publish_messageæ–¹æ³•ï¼Œå…¶ä¸­è·å–åˆ°æ‰€æœ‰çš„roleï¼Œå¦‚ä¸‹ï¼š\n```\ndef publish_message(self, message: Message, user_defined_recipient: str = \"\", publicer: str = \"\") -> bool:\n    \"\"\"let the team leader take over message publishing\"\"\"\n    print(\"MDXEnv.....  publish_message .....\")\n    message = self.attach_images(message)  # for multi-modal message\n\n    tl = self.get_role(TEAMLEADER_NAME)  # TeamLeader's name is Mike\n```\nå¦‚æœä¸è®¾ç½®æ·»åŠ äº†`TeamLeader()`ï¼Œåˆ™tlè¿”å›æ˜¯ä¸ªNoneï¼Œå¯¼è‡´åç»­å°±ä¼šæŠ›é”™ï¼Œå› ä¸ºä¼šè·å–`profile`å±æ€§ï¼Œå¦‚ä¸‹ï¼š\n` elif publicer == tl.profile:`ï¼›è€Œæ·»åŠ äº†`TeamLeader()`ï¼Œ`self.get_role`å°±èƒ½è¿”å›æ•°æ®ï¼Œç›¸å½“äºæ˜¯æŠŠteamleaderæ³¨å†Œè¿›å»äº†ï¼Œä½†åé¢ä¼šå¯¼è‡´å¤šæ™ºèƒ½ä½“è¿è¡Œæ—¶ï¼Œæ•ˆæœæœ‰é—®é¢˜ã€‚\n\nåœ¨ä¹‹å‰çš„ç‰ˆæœ¬ä¸­ï¼Œæ˜¯ä¸éœ€è¦æ·»åŠ è¿™ä¸ª`TeamLeader()`ï¼Œè€Œä¸”envç¯å¢ƒå¥½åƒä¹Ÿä¸æ˜¯mgxï¼Œç›´æ¥å°±èƒ½è¿è¡Œï¼Œä¼°è®¡æ˜¯å“ªé‡Œæ”¹é”™äº†ï¼Œå¸Œæœ›å¯ä»¥æ£€æŸ¥ä¸‹ã€‚\n\nè§£å†³æ–¹æ¡ˆï¼š\nè·Ÿäº†æºç ï¼Œæœ€åå‘ç°ï¼Œå‹æ ¹å°±æ²¡æœ‰è°ƒç”¨åˆ°`self.set_actions([xxxx])`ä¸­çš„actionsï¼›å› ä¸ºåœ¨`_observe`ä¸­çš„åˆ¤æ–­æœ‰é—®é¢˜ï¼Œå¦‚ä¸‹ï¼š\n\n`self.rc.news = [msg for msg in self.rc.news if msg.send_to == {self.name} ]`\n\nmsgçš„å†…å®¹æ˜¯ï¼š{'ç¨‹åºå‘˜Ryan', '\\<all\\>'}ï¼Œç¬¬ä¸€ä¸ªæ˜¯æ·»åŠ çš„teamleaderï¼Œç¬¬äºŒä¸ªä¸€ä¸ªå¸¸æ•°æ ‡è®°ï¼Œå…·ä½“ä¸šåŠ¡æ„ä¹‰æˆ‘ä¸æ¸…æ¥šï¼ŒæŒ‰æˆ‘ç†è§£æ¥çœ‹ï¼Œåº”è¯¥æ˜¯å…¨ä½“çš„roles/actionsã€‚å› æ­¤æˆ‘æ”¹äº†ä¸‹ä»£ç å¦‚ä¸‹ï¼š\n`self.rc.news = [msg for msg in self.rc.news if (msg.send_to == {self.name} or MESSAGE_ROUTE_TO_ALL in msg.send_to)]`\næœ€åæ˜¯okäº†ã€‚\n\nè¿˜æœ‰ä¸€ä¸ªæ”¹æ³•ï¼Œå®˜æ–¹çš„run_projectæºç ä¸­æœ‰é—®é¢˜ï¼Œå¦‚ä¸‹ï¼š\n\n```\n    def run_project(self, idea, send_to: str = \"\"):\n        \"\"\"Run a project from publishing user requirement.\"\"\"\n        self.idea = idea\n\n        # Human requirement.\n        self.env.publish_message(Message(content=idea))\n```\n\nè¿™é‡Œæ²¡æœ‰ç”¨ä¸Š`send_to`å‚æ•°ï¼Œåœ¨debate.pyç¤ºä¾‹ä¸­ï¼Œç”¨æˆ·åœ¨åˆå§‹åŒ–çš„æ—¶å€™ï¼Œæ˜¯éœ€è¦ä¼ å‚æŒ‡å®šæ¥æ”¶äººsend_toçš„ï¼Œè€Œä¸”ä»ä»£ç é€»è¾‘æ¥çœ‹æœ¬å°±æ˜¯åº”è¯¥åœ¨Messageä¸­å¢åŠ å‚æ•°send_toï¼Œæ”¹ä¸ºå¦‚ä¸‹ï¼š\n```\n\n    def run_project(self, idea, send_to: str = \"\"):\n        \"\"\"Run a project from publishing user requirement.\"\"\"\n        self.idea = idea\n        # Human requirement.\n        self.env.publish_message(Message(content=idea, send_to = send_to))\n```\n\ndebate.pyä¸­ä¹Ÿéœ€è¦ä¿®æ”¹ï¼š\n```\n\n    async def _observe(self) -> int:\n        await super()._observe()\n        # accept messages sent (from opponent) to self, disregard own messages from the last round\n        # åº”è¯¥ç”¨ in æ¥åˆ¤æ–­ï¼Œå› ä¸ºmsg.send_toæ˜¯ä¸€ä¸ªseté›†åˆå¯¹è±¡\n        self.rc.news = [msg for msg in self.rc.news if self.name in msg.send_to]\n        return len(self.rc.news)\n```\n\n\næœŸæœ›ï¼š\nå¸Œæœ›å®˜æ–¹å‡ºä¸ªå®˜æ–¹è§£å†³æ–¹æ¡ˆï¼Œæ„Ÿè°¢ã€‚\n",
      "state": "open",
      "author": "RyanOvO",
      "author_type": "User",
      "created_at": "2025-05-17T03:15:52Z",
      "updated_at": "2025-06-22T00:40:13Z",
      "closed_at": null,
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1831/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1831",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1831",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:47.456522",
      "comments": [
        {
          "author": "cranyy",
          "body": "Hi, i had the same issue as you -- I used translate to follow your solution, which was much better than mine, because I have no need for a leader, and this new env is completely redundant for me -- so my solution was in team.py:\n```\nclass Team(BaseModel):\n    '''\n    Team: Possesses one or more role",
          "created_at": "2025-05-21T16:03:11Z"
        },
        {
          "author": "RyanOvO",
          "body": "> Hi, i had the same issue as you -- I used translate to follow your solution, which was much better than mine, because I have no need for a leader, and this new env is completely redundant for me -- so my solution was in team.py:\n> \n> ```\n> class Team(BaseModel):\n>     '''\n>     Team: Possesses one",
          "created_at": "2025-05-22T05:32:12Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-22T00:40:12Z"
        }
      ]
    },
    {
      "issue_number": 1835,
      "title": "Do you have any plan about supporting Python 3.12 ?",
      "body": "As I said in Title",
      "state": "open",
      "author": "william8188",
      "author_type": "User",
      "created_at": "2025-05-21T08:16:45Z",
      "updated_at": "2025-06-21T00:35:39Z",
      "closed_at": null,
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1835/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1835",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1835",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:47.675019",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-21T00:35:38Z"
        }
      ]
    },
    {
      "issue_number": 1740,
      "title": "debugæ‰§è¡ŒDIçš„æ—¶å€™æŠ¥é”™",
      "body": "/Users/majin/PycharmProjects/metagpt-tesst/.venv/lib/python3.9/site-packages/debugpy/_vendored/force_pydevd.py:18: UserWarning: incompatible copy of pydevd already imported:\n /Users/majin/Applications/PyCharm Professional Edition.app/Contents/plugins/python-ce/helpers/pydev/_pydev_bundle/__init__.py\nä½ å¥½ï¼Œdebugè¿è¡ŒDataInterpreterçš„æ—¶å€™æŠ¥é”™ã€‚å¸®å¿™çœ‹ä¸‹å¦‚ä½•è§£å†³",
      "state": "open",
      "author": "WuJingLearn",
      "author_type": "User",
      "created_at": "2025-03-05T04:00:06Z",
      "updated_at": "2025-06-20T00:36:15Z",
      "closed_at": null,
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1740/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1740",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1740",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:47.871392",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-05T00:32:13Z"
        },
        {
          "author": "stellaHSR",
          "body": "èƒ½å¦æä¾›æ›´å¤šæŠ¥é”™æˆªå›¾ï¼Ÿçœ‹ç€æ˜¯è°ƒè¯•å™¨æœ¬èº«é…ç½®",
          "created_at": "2025-05-18T09:26:33Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-20T00:36:14Z"
        }
      ]
    },
    {
      "issue_number": 1833,
      "title": "The output content of llm is confused with that of the log, and it seems as if it has been truncated",
      "body": "The output content of llm is confused with that of the log, and it seems as if it has been truncatedï¼š\n\n![Image](https://github.com/user-attachments/assets/afdea662-fd25-416c-a50d-3043f41887f8)\n\nHow can the source code within metagpt not output the content returned by the LLM, and even if it is output, it should not be mixed with the log",
      "state": "open",
      "author": "RyanOvO",
      "author_type": "User",
      "created_at": "2025-05-20T01:17:02Z",
      "updated_at": "2025-06-20T00:36:11Z",
      "closed_at": null,
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1833/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1833",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1833",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:48.103531",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-20T00:36:10Z"
        }
      ]
    },
    {
      "issue_number": 1834,
      "title": "class SimpleEngine has duplication _from_nodes methods",
      "body": "\n![Image](https://github.com/user-attachments/assets/ba523147-4253-4fe6-87c7-4ec9ce662b16)\n\n```\n\n @classmethod\n    def _from_nodes(\n        cls,\n        nodes: list[BaseNode],\n        transformations: Optional[list[TransformComponent]] = None,\n        embed_model: BaseEmbedding = None,\n        llm: LLM = None,\n        retriever_configs: list[BaseRetrieverConfig] = None,\n        ranker_configs: list[BaseRankerConfig] = None,\n    ) -> \"SimpleEngine\":\n        embed_model = cls._resolve_embed_model(embed_model, retriever_configs)\n        llm = llm or get_rag_llm()\n\n        retriever = get_retriever(configs=retriever_configs, nodes=nodes, embed_model=embed_model)\n        rankers = get_rankers(configs=ranker_configs, llm=llm)  # Default []\n\n        return cls(\n            retriever=retriever,\n            node_postprocessors=rankers,\n            response_synthesizer=get_response_synthesizer(llm=llm),\n            transformations=transformations,\n        )\n\n    @classmethod\n    def _from_nodes(\n        cls,\n        nodes: list[BaseNode],\n        transformations: Optional[list[TransformComponent]] = None,\n        embed_model: BaseEmbedding = None,\n        llm: LLM = None,\n        retriever_configs: list[BaseRetrieverConfig] = None,\n        ranker_configs: list[BaseRankerConfig] = None,\n    ) -> \"SimpleEngine\":\n        embed_model = cls._resolve_embed_model(embed_model, retriever_configs)\n        llm = llm or get_rag_llm()\n\n        retriever = get_retriever(configs=retriever_configs, nodes=nodes, embed_model=embed_model)\n        rankers = get_rankers(configs=ranker_configs, llm=llm)  # Default []\n\n        return cls(\n            retriever=retriever,\n            node_postprocessors=rankers,\n            response_synthesizer=get_response_synthesizer(llm=llm),\n            transformations=transformations,\n        )\n```\n\n\nthe `_from_nodes  `method is repeated. \n",
      "state": "open",
      "author": "RyanOvO",
      "author_type": "User",
      "created_at": "2025-05-20T05:45:49Z",
      "updated_at": "2025-06-20T00:36:09Z",
      "closed_at": null,
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1834/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1834",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1834",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:48.290388",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-20T00:36:09Z"
        }
      ]
    },
    {
      "issue_number": 1706,
      "title": "Aflow è¿è¡ŒæŠ¥é”™",
      "body": "\nè¿è¡ŒAflow å‘½ä»¤ï¼Œåªè¿è¡Œå®Œæˆround1çš„æ‰§è¡Œã€‚ç„¶åå°±éƒ½æŠ¥é”™ï¼Œæ˜¯å¦ä¸æ”¯æŒqwen å’Œ deepseekæ¨¡å‹æ¥å®ç°ï¼Ÿ\n\n### å‘½ä»¤ï¼š\n\npython -m examples.aflow.optimize  --dataset MATH --opt_model_name deepseek-v3  --exec_model_name qwen2.5\n --if_first_optimize=false\n\n### æ¨¡å‹é…ç½®ï¼š\nmodels:\n    \"qwen2.5\": \n        api_type: \"dashscope\" \n        model: \"qwen2.5-72b-instruct\"\n        base_url: \"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n        api_key: \"sk-xxxx\"\n        temperature: 0.5\n    \"deepseek-v3\": \n        api_type: \"dashscope\" \n        model: \"deepseek-v3\"\n        base_url: \"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n        api_key: \"sk-xxxx\"\n        temperature: 0.5\n\n\næŠ¥é”™ä¿¡æ¯ï¼š\n\n**Bug description**\n<!-- Clearly and directly describe the current bug -->\n2025-02-20 16:25:18.965 | INFO     | metagpt.ext.aflow.scripts.optimizer:optimize:93 - Error occurred: Unable to serialize unknown type: <class 'numpy.int64'>. Retrying... (Attempt 1/1)\n2025-02-20 16:25:18.968 | INFO     | metagpt.ext.aflow.scripts.optimizer:optimize:95 - Max retries reached. Moving to next round.\n2025-02-20 16:25:23.971 | INFO     | metagpt.ext.aflow.scripts.optimizer:optimize:106 - Score for round 2: None\nTraceback (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"C:\\work\\spaces\\MetaGPT\\examples\\aflow\\optimize.py\", line 133, in <module>\n    optimizer.optimize(\"Graph\")\n  File \"C:\\work\\spaces\\MetaGPT\\metagpt\\ext\\aflow\\scripts\\optimizer.py\", line 108, in optimize\n    converged, convergence_round, final_round = self.convergence_utils.check_convergence(top_k=3)\n                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\work\\spaces\\MetaGPT\\metagpt\\ext\\aflow\\scripts\\optimizer_utils\\convergence_utils.py\", line 74, in check_convergence\n    self.avg_scores, self.stds = self.calculate_avg_and_std()\n                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\work\\spaces\\MetaGPT\\metagpt\\ext\\aflow\\scripts\\optimizer_utils\\convergence_utils.py\", line 58, in calculate_avg_and_std\n    self.rounds = self.process_rounds()\n                  ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\work\\spaces\\MetaGPT\\metagpt\\ext\\aflow\\scripts\\optimizer_utils\\convergence_utils.py\", line 44, in process_rounds\n    self.data = self.load_data(root_path=self.root_path)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\work\\spaces\\MetaGPT\\metagpt\\ext\\aflow\\scripts\\optimizer_utils\\convergence_utils.py\", line 38, in load_data\n    return json.load(file)\n           ^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ThinkPad\\.conda\\envs\\metagpt\\Lib\\json\\__init__.py\", line 293, in load\n    return loads(fp.read(),\n           ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ThinkPad\\.conda\\envs\\metagpt\\Lib\\json\\__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ThinkPad\\.conda\\envs\\metagpt\\Lib\\json\\decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ThinkPad\\.conda\\envs\\metagpt\\Lib\\json\\decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 6 column 23 (char 112)\n",
      "state": "open",
      "author": "qjs2000",
      "author_type": "User",
      "created_at": "2025-02-20T10:10:06Z",
      "updated_at": "2025-06-19T00:36:16Z",
      "closed_at": null,
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1706/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1706",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1706",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:48.470363",
      "comments": [
        {
          "author": "Clairegggg",
          "body": "Did you solve it?",
          "created_at": "2025-03-10T13:34:48Z"
        },
        {
          "author": "Guo-Jintao",
          "body": "è¯·é—®ä¸€ä¸‹ç”¨çš„æ˜¯å“ªä¸ªç‰ˆæœ¬çš„metagptï¼Œç”¨Version: 0.8.1ä¼¼ä¹äºaflowä»£ç ä¸å¤ªå…¼å®¹ï¼Œ\n2025-03-14 15:51:04.570 | INFO     | metagpt.ext.aflow.benchmark.gsm8k:evaluate_problem:53 - Maximum retries reached. Skipping this sample. Error: ActionNode.fill() got an unexpected keyword argument 'context'ï¼Œ\næœ€æ–°ç‰ˆæœ¬çš„metagptï¼ŒActionNode.fill()å˜æˆäº†reqï¼Œå°†",
          "created_at": "2025-03-17T08:50:46Z"
        },
        {
          "author": "helloword1",
          "body": "é—®é¢˜+1\n",
          "created_at": "2025-03-17T08:56:06Z"
        },
        {
          "author": "Guo-Jintao",
          "body": "è§£å†³äº†ï¼Œå°†action_nodeæ¢æˆè¿™ä¸ªé“¾æ¥çš„å°±è¡Œäº†https://github.com/geekan/MetaGPT/pull/1510/files?short_path=66cde96",
          "created_at": "2025-03-18T02:46:30Z"
        },
        {
          "author": "Guo-Jintao",
          "body": "åäº†ï¼Œé‡åˆ°ä¸€æ¥¼è€å“¥çš„é”™è¯¯äº†ï¼Œ@qjs2000 å“¥ï¼Œé—®é¢˜è§£å†³äº†å—",
          "created_at": "2025-03-18T03:22:46Z"
        }
      ]
    },
    {
      "issue_number": 1768,
      "title": "user_requirement missed in plan_and_act mode",
      "body": "**Bug description**\nThe LLM generated code in plan_and_act mode does not contain data path info. Found that self.user_requirement (containing the data info) is empty. So the prompt does not contain data info for LLM to write the correct code. \n\n**Bug solved method**\nAdd ` self.user_requirement = self.get_memories()[-1].content `\nto DataInterpreter's plan_and_act method may solve the issue. However, I'm not sure if it affects other functionalities.   \n\n**Environment information**\nSystem version (mac os), Python version (conda python 3.9), LLM type and model (Zhipu glm-4-plus)",
      "state": "open",
      "author": "AdaChambers",
      "author_type": "User",
      "created_at": "2025-03-17T05:24:33Z",
      "updated_at": "2025-06-19T00:36:14Z",
      "closed_at": null,
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1768/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1768",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1768",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:48.679256",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-18T00:38:06Z"
        },
        {
          "author": "stellaHSR",
          "body": "yes, thank you for report the bug. We will add ` user_requirement = self.get_memories()[0].content` here: https://github.com/FoundationAgents/MetaGPT/blob/ba2868974b2ecc3fe4218ad29dd334867c07f678/metagpt/roles/di/data_interpreter.py#L159",
          "created_at": "2025-05-18T09:42:26Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-19T00:36:14Z"
        }
      ]
    },
    {
      "issue_number": 1828,
      "title": "é»˜è®¤embbeddingæ¨¡å‹å‡ºç°é—®é¢˜ ï¼šTypeError: 'NoneType' object is not iterable",
      "body": "æˆ‘åœ¨æŒ‡å®šäº†äº†æœ¬åœ°çš„å¤§æ¨¡å‹è·¯å¾„ä¹‹åï¼Œä½¿ç”¨MetaGPTçš„é»˜è®¤åµŒå…¥æ¨¡å‹ä¼šæŠ¥é”™ï¼š\nTraceback (most recent call last):\n  File \"/mnt/d/MetaGPT-main/MetaGPT-main/examples/mytest.py\", line 28, in <module>\n    asyncio.run(main())\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/asyncio/runners.py\", line 190, in run\n    return runner.run(main)\n           ^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/asyncio/runners.py\", line 118, in run\n    return self._loop.run_until_complete(task)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n    return future.result()\n           ^^^^^^^^^^^^^^^\n  File \"/mnt/d/MetaGPT-main/MetaGPT-main/examples/mytest.py\", line 23, in main\n    engine = SimpleEngine.from_docs(input_files=[DOC_PATH])\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/d/MetaGPT-main/MetaGPT-main/metagpt/rag/engines/simple.py\", line 128, in from_docs\n    return cls._from_nodes(\n           ^^^^^^^^^^^^^^^^\n  File \"/mnt/d/MetaGPT-main/MetaGPT-main/metagpt/rag/engines/simple.py\", line 301, in _from_nodes\n    retriever = get_retriever(configs=retriever_configs, nodes=nodes, embed_model=embed_model)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/d/MetaGPT-main/MetaGPT-main/metagpt/rag/factories/retriever.py\", line 69, in get_retriever\n    return self._create_default(**kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/d/MetaGPT-main/MetaGPT-main/metagpt/rag/factories/retriever.py\", line 76, in _create_default\n    index = self._extract_index(None, **kwargs) or self._build_default_index(**kwargs)\n                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/d/MetaGPT-main/MetaGPT-main/metagpt/rag/factories/retriever.py\", line 117, in _build_default_index\n    index = VectorStoreIndex(\n            ^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/llama_index/core/indices/vector_store/base.py\", line 74, in __init__\n    super().__init__(\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/llama_index/core/indices/base.py\", line 91, in __init__\n    index_struct = self.build_index_from_nodes(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/llama_index/core/indices/vector_store/base.py\", line 307, in build_index_from_nodes\n    return self._build_index_from_nodes(nodes, **insert_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/llama_index/core/indices/vector_store/base.py\", line 279, in _build_index_from_nodes\n    self._add_nodes_to_index(\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/llama_index/core/indices/vector_store/base.py\", line 232, in _add_nodes_to_index\n    nodes_batch = self._get_node_with_embedding(nodes_batch, show_progress)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/llama_index/core/indices/vector_store/base.py\", line 140, in _get_node_with_embedding\n    id_to_embed_map = embed_nodes(\n                      ^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/llama_index/core/indices/utils.py\", line 138, in embed_nodes\n    new_embeddings = embed_model.get_text_embedding_batch(\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/llama_index/core/base/embeddings/base.py\", line 255, in get_text_embedding_batch\n    embeddings = self._get_text_embeddings(cur_batch)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/llama_index/embeddings/openai/base.py\", line 419, in _get_text_embeddings\n    return get_embeddings(\n           ^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/tenacity/__init__.py\", line 289, in wrapped_f\n    return self(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/tenacity/__init__.py\", line 379, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/tenacity/__init__.py\", line 314, in iter\n    return fut.result()\n           ^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/tenacity/__init__.py\", line 382, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/llama_index/embeddings/openai/base.py\", line 180, in get_embeddings\n    data = client.embeddings.create(input=list_of_text, model=engine, **kwargs).data\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/openai/resources/embeddings.py\", line 114, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/openai/_base_client.py\", line 1271, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/openai/_base_client.py\", line 942, in request\n    return self._request(\n           ^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/openai/_base_client.py\", line 1048, in _request\n    return self._process_response(\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/openai/_base_client.py\", line 1147, in _process_response\n    return api_response.parse()\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/openai/_response.py\", line 318, in parse\n    parsed = self._options.post_parser(parsed)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lcj1069/anaconda3/envs/MetaGPT4/lib/python3.11/site-packages/openai/resources/embeddings.py\", line 102, in parser\n    for embedding in obj.data:\nTypeError: 'NoneType' object is not iterable\nERROR conda.cli.main_run:execute(124): `conda run python /mnt/d/MetaGPT-main/MetaGPT-main/examples/mytest.py` failed. (See above for error)\n\næˆ‘è‡ªå·±è®¤ä¸ºæ˜¯å› ä¸ºç½‘ç»œåŸå› æ— æ³•è®¿é—®openaiçš„embeddingæ¨¡å‹ï¼Œä½†æ˜¯æˆ‘æŸ¥é˜…äº†MetaGPTæ–‡æ¡£ä¸­æ”¯æŒçš„å…¶ä»–embeddingæ¨¡å‹ï¼Œå‘ç°å¤§å¤šæ•°embeddingæ¨¡å‹ä¸MetaGPTçš„è¿è¡Œç¯å¢ƒä¸ç›¸é€‚é…ï¼Œè¯·é—®ä½ ä»¬æœ‰æ›´å¥½çš„è®¿é—®openaiçš„æ–¹æ³•æˆ–è€…æœ‰å…¶ä»–æ”¯æŒMetaGPTå¯æœ¬åœ°éƒ¨ç½²çš„embeddingæ¨¡å‹å—ï¼Ÿ",
      "state": "closed",
      "author": "lcj1069864078",
      "author_type": "User",
      "created_at": "2025-05-15T00:34:04Z",
      "updated_at": "2025-06-18T00:38:43Z",
      "closed_at": "2025-06-18T00:38:43Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1828/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1828",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1828",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:48.892923",
      "comments": [
        {
          "author": "seehi",
          "body": "1. å¯ä»¥ç”¨ä¸‹é¢ä»£ç éªŒè¯embeddingæœåŠ¡æ˜¯å¦æ­£å¸¸ï¼š\n```python\nfrom llama_index.embeddings.openai import OpenAIEmbedding\n\n\nembedding = OpenAIEmbedding(api_base=\"YOUR_API_BASE\", api_key=\"YOUR_API_KEY\")\nprint(embedding.get_text_embedding(\"hello world\"))\n```\n2. å½“å‰å¯é€šè¿‡é…ç½®è®¾ç½®çš„embeddingæ¨¡å‹ï¼Œå¯æŸ¥çœ‹ï¼š[é…ç½®embedding](https://docs.deepwisdom.a",
          "created_at": "2025-05-18T11:30:41Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-18T00:35:47Z"
        }
      ]
    },
    {
      "issue_number": 1748,
      "title": "AttributeError: 'NoneType' object has no attribute 'name'",
      "body": "æˆ‘åœ¨ä½¿ç”¨ç¤ºä¾‹demoç”Ÿæˆä»£ç çš„æ—¶å€™é‡åˆ°äº†`AttributeError: 'NoneType' object has no attribute 'name'`è¿™ä¸ªæŠ¥é”™ï¼ŒæŸ¥çœ‹ä»£ç åå‘ç°nameæ˜¯self.rcä¸Šé¢çš„ä¸€ä¸ªå±æ€§ï¼Œè¯·é—®è¯¥å±æ€§æœ‰ä»€ä¹ˆä½œç”¨ï¼Œæˆ‘è¯¥å¦‚ä½•ä¿®å¤è¿™ä¸ªbug\n",
      "state": "open",
      "author": "2645283289",
      "author_type": "User",
      "created_at": "2025-03-09T10:02:02Z",
      "updated_at": "2025-06-18T00:35:55Z",
      "closed_at": null,
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1748/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1748",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1748",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:49.081279",
      "comments": [
        {
          "author": "YiFraternity",
          "body": "æˆ‘ä¹Ÿé‡åˆ°è¿™ä¸ªé—®é¢˜ï¼Œæ­£åœ¨debug",
          "created_at": "2025-04-04T09:55:44Z"
        },
        {
          "author": "limboys",
          "body": "Can you provide more context, such as the\nPython version\nmachine architecture\ndemo example",
          "created_at": "2025-05-18T13:27:42Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-18T00:35:55Z"
        }
      ]
    },
    {
      "issue_number": 1761,
      "title": "å¦‚ä½•å°†å“åº”ä¿å­˜åˆ°å·¥ä½œç©ºé—´ï¼Œæˆ‘è°ƒç”¨ç›¸åº”çš„apié”™è¯¯ä¿¡æ¯ä¹Ÿä¸æ˜¯å¾ˆæ˜ç¡®",
      "body": "**Bug description**\næˆ‘æƒ³åœ¨Actionå“åº”çš„æ—¶å€™ï¼Œå°†ç›¸åº”ç»“æœä¿å­˜ä¸ºä¸€ä¸ªæ–‡ä»¶ï¼Œæˆ‘è°ƒç”¨äº†è¿™è¡Œä»£ç \n`await self.repo.resources.code_summary.save(filename=\"prd.md\", content=response)`ï¼Œæˆ‘å´å¾—åˆ°ä¸€ä¸ªé”™è¯¯\n`2025-03-13 20:21:05.436 | ERROR    | metagpt.utils.common:wrapper:631 - Exception occurs, start to serialize the project, exp:\nTraceback (most recent call last):\n  File \"/Users/huanhu/PycharmProjects/hello_metagpt/.venv/lib/python3.11/site-packages/metagpt/utils/common.py\", line 640, in wrapper\n    return await func(self, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/huanhu/PycharmProjects/hello_metagpt/.venv/lib/python3.11/site-packages/metagpt/roles/role.py\", line 550, in run\n    rsp = await self.react()\n          ^^^^^^^^^^^^^^^^^^\nValueError: Invalid root\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/huanhu/PycharmProjects/hello_metagpt/.venv/lib/python3.11/site-packages/metagpt/utils/common.py\", line 626, in wrapper\n    result = await func(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/huanhu/PycharmProjects/hello_metagpt/.venv/lib/python3.11/site-packages/metagpt/team.py\", line 134, in run\n    await self.env.run()\nException: Traceback (most recent call last):\n  File \"/Users/huanhu/PycharmProjects/hello_metagpt/.venv/lib/python3.11/site-packages/metagpt/utils/common.py\", line 640, in wrapper\n    return await func(self, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/huanhu/PycharmProjects/hello_metagpt/.venv/lib/python3.11/site-packages/metagpt/roles/role.py\", line 550, in run\n    rsp = await self.react()\n          ^^^^^^^^^^^^^^^^^^\n  File \"/Users/huanhu/PycharmProjects/hello_metagpt/.venv/lib/python3.11/site-packages/metagpt/roles/role.py\", line 517, in react\n    rsp = await self._react()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"/Users/huanhu/PycharmProjects/hello_metagpt/.venv/lib/python3.11/site-packages/metagpt/roles/role.py\", line 463, in _react\n    rsp = await self._act()\n          ^^^^^^^^^^^^^^^^^\n  File \"/Users/huanhu/PycharmProjects/hello_metagpt/huhuan_soft_company.py\", line 41, in _act\n    response = await todo.run(msg.content)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/huanhu/PycharmProjects/hello_metagpt/huhuan_soft_company.py\", line 24, in run\n    await self.repo.resources.code_summary.save(filename=\"prd.md\", content=response)\n          ^^^^^^^^^\n  File \"/Users/huanhu/PycharmProjects/hello_metagpt/.venv/lib/python3.11/site-packages/metagpt/actions/action.py\", line 42, in repo\n    self.context.repo = ProjectRepo(self.context.git_repo)\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/huanhu/PycharmProjects/hello_metagpt/.venv/lib/python3.11/site-packages/metagpt/utils/project_repo.py\", line 97, in __init__\n    raise ValueError(\"Invalid root\")\nValueError: Invalid root\n`\n\n**code**\n`from metagpt.actions import Action\nfrom metagpt.roles import Role\nfrom metagpt.schema import Message\nfrom metagpt.logs import logger\nimport asyncio\n\nfrom metagpt.team import Team\n\n\nclass WritePrd(Action):\n    PROMPT_TEMPLATE: str = \"{instruction}\"\n\n    name: str = \"ç¼–å†™é¡¹ç›®éœ€æ±‚æ–‡æ¡£\"\n\n    async def run(self, instruction: str):\n        prompt = self.PROMPT_TEMPLATE.format(instruction=instruction)\n        response = await self._aask(prompt)\n        await self.repo.resources.code_summary.save(filename=\"prd.md\", content=response)\n        return response\n\n\nclass ProductManage(Role):\n    name: str = \"huhuan\"\n\n    profile: str = \"ProductManage\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([WritePrd])\n\n    async def _act(self) -> Message:\n        logger.info(f\"{self._setting}: to do {self.rc.todo}({self.rc.todo.name})\")\n        todo = self.todo\n        msg = self.get_memories(k=1)[0]\n        response = await todo.run(msg.content)\n        msg = Message(content=response, role=self.profile, cause_by=type(todo))\n\n        return msg\n\n\nasync def main():\n    company = Team()\n    company.hire([\n        ProductManage()\n    ])\n    company.invest(investment=3)\n\n    idea = \"ä½ å¥½\"\n    company.run_project(idea)\n    await company.run(n_round=5)\n\n\nif __name__ == '__main__':\n    asyncio.run(main())\n`",
      "state": "open",
      "author": "youbiaokachi123",
      "author_type": "User",
      "created_at": "2025-03-13T12:22:00Z",
      "updated_at": "2025-06-18T00:35:54Z",
      "closed_at": null,
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1761/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1761",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1761",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:49.300139",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-13T00:59:25Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-18T00:35:53Z"
        }
      ]
    },
    {
      "issue_number": 1772,
      "title": "ragåŠŸèƒ½ä¸èƒ½æ­£å¸¸ä½¿ç”¨",
      "body": "å®‰è£…ç¨³å®šç‰ˆï¼ˆæˆªæ­¢2025-3-19ï¼‰æ— æ³•ä½¿ç”¨ragåŠŸèƒ½ï¼Œæ— æ³•è¿è¡Œç¤ºä¾‹ä»£ç ï¼Œä¼šæ˜¾ç¤ºä»¥ä¸‹é”™è¯¯ï¼š\nRetrying llama_index.embeddings.openai.base.get_embeddings in 1.7915908865025045 seconds as it raised NotFoundError: Error code: 404 - {'event_id': '30-inst-228-20250319170241-4fed467a', 'error_msg': 'Not Found. Please check the configuration.'}.\n....\nFile \"E:\\Anaconda\\envs\\metagpt_stable\\lib\\site-packages\\openai\\_base_client.py\", line 930, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.NotFoundError: Error code: 404 - {'event_id': '30-inst-5-20250319170244-9280c94d', 'error_msg': 'Not Found. Please check the configuration.'}\n\n**å®‰è£…æœ€æ–°çš„ç¨³å®šç‰ˆmetagpt==0.8.2ä¼šæœ‰ä¾èµ–å†²çªï¼Œè¯•è¿‡git cloneæ–¹æ³•å’Œpip install --upgrade metagptï¼ˆpip install --upgrade git+https://github.com/geekan/MetaGPT.gitï¼‰åä¼šå‡ºç°ç¼ºå¤±åŒ…çš„æƒ…å†µï¼š**\n\nTraceback (most recent call last):\n  File \"D:\\Metagpt\\MetaGPT81\\test.py\", line 3, in <module>\n    from metagpt.rag.engines import SimpleEngine\n  File \"E:\\Anaconda\\envs\\metagpt_stable\\lib\\site-packages\\metagpt\\rag\\engines\\__init__.py\", line 3, in <module>\n    from metagpt.rag.engines.simple import SimpleEngine\n  File \"E:\\Anaconda\\envs\\metagpt_stable\\lib\\site-packages\\metagpt\\rag\\engines\\simple.py\", line 35, in <module>\n    from metagpt.rag.factories import (\n  File \"E:\\Anaconda\\envs\\metagpt_stable\\lib\\site-packages\\metagpt\\rag\\factories\\__init__.py\", line 3, in <module>\n    from metagpt.rag.factories.retriever import get_retriever\n  File \"E:\\Anaconda\\envs\\metagpt_stable\\lib\\site-packages\\metagpt\\rag\\factories\\retriever.py\", line 16, in <module>\n    from llama_index.vector_stores.milvus import MilvusVectorStore\nModuleNotFoundError: No module named 'llama_index.vector_stores.milvus'ï¼›\nå®‰è£…'llama_index.vector_stores.milvuså°±ä¼šæœ‰å†²çªï¼Œæ— æ³•è§£å†³ï¼ï¼ï¼\nå…·ä½“æ˜¯metagpt==1.0.0ä¾èµ–setuptools==65.6.3ï¼Œä½†æ˜¯pymilvus 2.5.5 requires setuptools>69ç­‰ç­‰ï¼Œæœ‰å¾ˆå¤šå†²çªæ— æ³•è§£å†³ï¼ï¼\n\n\n\n\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nllama-index-embeddings-azure-openai 0.1.6 requires llama-index-core<0.11.0,>=0.10.11.post1, but you have llama-index-core 0.12.25 which is incompatible.\nllama-index-embeddings-openai 0.1.5 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.25 which is incompatible.\nllama-index-llms-azure-openai 0.1.4 requires llama-index-core<0.11.0,>=0.10.11.post1, but you have llama-index-core 0.12.25 which is incompatible.\nllama-index-llms-openai 0.1.8 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.25 which is incompatible.\nllama-index-readers-file 0.1.4 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.25 which is incompatible.\nllama-index-retrievers-bm25 0.1.3 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.25 which is incompatible.\nllama-index-vector-stores-chroma 0.1.6 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.25 which is incompatible.\nllama-index-vector-stores-elasticsearch 0.1.6 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.25 which is incompatible.\nllama-index-vector-stores-faiss 0.1.1 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.25 which is incompatible.\nmetagpt 1.0.0 requires setuptools==65.6.3, but you have setuptools 76.1.0 which is incompatible.\nmetagpt 1.0.0 requires typing-extensions==4.11.0, but you have typing-extensions 4.12.2 which is incompatible.\nsemantic-kernel 0.4.3.dev0 requires python-dotenv==1.0.0, but you have python-dotenv 1.0.1 which is incompatible.",
      "state": "open",
      "author": "zing-else",
      "author_type": "User",
      "created_at": "2025-03-19T09:40:12Z",
      "updated_at": "2025-06-18T00:35:52Z",
      "closed_at": null,
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1772/reactions",
        "total_count": 4,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 4
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1772",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1772",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:49.522932",
      "comments": [
        {
          "author": "YyKMfight",
          "body": "ç¡®å®ï¼Œå°è¯•è§£å†³äº†ä¸€ä¸Šåˆä¸€ç›´å¤±è´¥",
          "created_at": "2025-03-30T04:40:52Z"
        },
        {
          "author": "seehi",
          "body": "ç”±äºä¾èµ–å†²çªï¼Œä¸´æ—¶å»æ‰RAGçš„milvusï¼Œå¯ç”¨mainåˆ†æ”¯å†è¯•çœ‹çœ‹ï¼Œ[ç›¸å…³PR](https://github.com/geekan/MetaGPT/pull/1794)",
          "created_at": "2025-03-31T08:04:36Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-02T00:34:13Z"
        },
        {
          "author": "lcj1069864078",
          "body": "æˆ‘ä¹Ÿé‡åˆ°è¿‡ragç¯å¢ƒçš„é—®é¢˜ï¼Œæˆ‘æŒ‰ç…§å®˜æ–¹æ‰‹å†Œçš„å‘½ä»¤ï¼š pip install metagpt[rag]   ä¸€æ¬¡æ€§å°†metagptç¯å¢ƒå’Œragè£…å¥½ è¿™æ ·å®‰è£…çš„ragæ˜¯æ­£å¸¸çš„ï¼Œä¸è¿‡embeddingå‡ºç°äº†æŠ¥é”™ï¼Œä½ å¯ä»¥è¯•è¯•ï¼ˆæˆ‘çš„pythonç‰ˆæœ¬æ˜¯3.11ï¼‰",
          "created_at": "2025-05-15T12:22:25Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-18T00:35:52Z"
        }
      ]
    },
    {
      "issue_number": 1819,
      "title": "Issue when running baseline set-up",
      "body": "**Bug description**\nI am unable to completely generate a workspace.\n\n**Environment information**\n\n- LLM type and model name:\n- System version: macOS 15.4.1\n- Python version: Python 3.10.16\n- MetaGPT version or branch: main\n\nSet-up from: `git clone https://github.com/geekan/MetaGPT && cd MetaGPT && pip install --upgrade -e .`\n\n**Instructions**\n- metagpt --init-config\n- modify `/Users/cmodi/.metagpt/config2.yaml` to use openrouter (via this example: https://github.com/FoundationAgents/MetaGPT/blob/main/config/examples/openrouter-llama3-70b-instruct.yaml)\n- `metagpt \"write a cli blackjack game\"`\n\n**Screenshots or logs**\n```\n(metagpt) cmodi@cmodi-mbp MetaGPT % metagpt \"write a cli blackjack game\"\n2025-04-30 13:59:38.982 | INFO     | metagpt.const:get_metagpt_package_root:15 - Package root set to /Users/cmodi/Documents/ai/llama-api/MetaGPT\n2025-04-30 13:59:38.982 | INFO     | metagpt.const:get_metagpt_package_root:15 - Package root set to /Users/cmodi/Documents/ai/llama-api/MetaGPT\n/opt/anaconda3/envs/metagpt/lib/python3.10/site-packages/pydantic/main.py:214: UserWarning: A custom validator is returning a value other than `self`.\nReturning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\nSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\n  warnings.warn(\n2025-04-30 14:00:32.188 | INFO     | metagpt.team:invest:96 - Investment: $3.0.\nThought: This is a detailed software development task that requires multiple steps, including designing and implementing a command-line interface for a blackjack game.\nResponse Category: TASK\n2025-04-30 14:00:33.267 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.009 | Max budget: $3.000 | Current cost: $0.009, prompt_tokens: 1073, completion_tokens: 32\nEnglish\n2025-04-30 14:00:34.162 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.010 | Max budget: $3.000 | Current cost: $0.002, prompt_tokens: 196, completion_tokens: 2\nBased on the user requirement to write a CLI blackjack game, I will create a plan to assign tasks to team members. Since this is a software development requirement, I will decompose it into multiple tasks and assign them to different team members based on their expertise.\n\nHere is my plan:\n\n```json\n[\n    {\n        \"command_name\": \"Plan.append_task\",\n        \"args\": {\n            \"task_id\": \"1\",\n            \"dependent_task_ids\": [],\n            \"instruction\": \"Create a product requirement document (PRD) for the CLI blackjack game.\",\n            \"assignee\": \"Alice\"\n        }\n    },\n    {\n        \"command_name\": \"Plan.append_task\",\n        \"args\": {\n            \"task_id\": \"2\",\n            \"dependent_task_ids\": [\"1\"],\n            \"instruction\": \"Design a concise, usable, complete software system for the CLI blackjack game based on the PRD.\",\n            \"assignee\": \"Bob\"\n        }\n    },\n    {\n        \"command_name\": \"Plan.append_task\",\n        \"args\": {\n            \"task_id\": \"3\",\n            \"dependent_task_ids\": [\"2\"],\n            \"instruction\": \"Implement the CLI blackjack game using Vite, React, MUI, Tailwind CSS, and deploy the web app.\",\n            \"assignee\": \"Alex\"\n        }\n    },\n    {\n        \"command_name\": \"TeamLeader.publish_message\",\n        \"args\": {\n            \"content\": \"Write a cli blackjack game.\",\n            \"send_to\": \"Alice\"\n        }\n    },\n    {\n        \"command_name\": \"RoleZero.reply_to_human\",\n        \"args\": {\n            \"content\": \"I have assigned the tasks to the team members. Alice will create the PRD, Bob will design the software architecture, and Alex will implement the CLI blackjack game.\"\n        }\n    }\n]\n```\n2025-04-30 14:00:55.774 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.046 | Max budget: $3.000 | Current cost: $0.035, prompt_tokens: 4048, completion_tokens: 375\n2025-04-30 14:00:55.776 | INFO     | metagpt.roles.di.role_zero:_act:322 - Commands: \n[{'command_name': 'Plan.append_task', 'args': {'task_id': '1', 'dependent_task_ids': [], 'instruction': 'Create a product requirement document (PRD) for the CLI blackjack game.', 'assignee': 'Alice'}}, {'command_name': 'Plan.append_task', 'args': {'task_id': '2', 'dependent_task_ids': ['1'], 'instruction': 'Design a concise, usable, complete software system for the CLI blackjack game based on the PRD.', 'assignee': 'Bob'}}, {'command_name': 'Plan.append_task', 'args': {'task_id': '3', 'dependent_task_ids': ['2'], 'instruction': 'Implement the CLI blackjack game using Vite, React, MUI, Tailwind CSS, and deploy the web app.', 'assignee': 'Alex'}}, {'command_name': 'TeamLeader.publish_message', 'args': {'content': 'Write a cli blackjack game.', 'send_to': 'Alice'}}, {'command_name': 'RoleZero.reply_to_human', 'args': {'content': 'I have assigned the tasks to the team members. Alice will create the PRD, Bob will design the software architecture, and Alex will implement the CLI blackjack game.'}}]\n2025-04-30 14:00:55.777 | INFO     | metagpt.roles.di.role_zero:_act:324 - Commands outputs: \nCommand Plan.append_task executed\n\nCommand Plan.append_task executed\n\nCommand Plan.append_task executed\n\nCommand TeamLeader.publish_message executed\n\nCommand RoleZero.reply_to_human executed: SUCCESS, human has received your reply. Refrain from resending duplicate messages.  If you no longer need to take action, use the command â€˜endâ€™ to stop.\nEnglish\n2025-04-30 14:00:57.313 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.047 | Max budget: $3.000 | Current cost: $0.001, prompt_tokens: 106, completion_tokens: 2\nI understand that I need to create a CLI Blackjack game. To start, I will create a new task to design the game's architecture and then implement the game logic.\n\nHere is my plan:\n\n```json\n[\n    {\n        \"command_name\": \"Task.create\",\n        \"args\": {\"task_id\": \"Design Game Architecture\", \"instruction\": \"Design the architecture of the CLI Blackjack game\", \"task_type\": \"Design\", \"assignee\": \"Alice\"}\n    },\n    {\n        \"command_name\": \"Task.create\",\n        \"args\": {\"task_id\": \"Implement Game Logic\", \"instruction\": \"Implement the game logic for the CLI Blackjack game\", \"task_type\": \"Implementation\", \"assignee\": \"Alice\"}\n    }\n]\n```\n2025-04-30 14:00:58.395 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.062 | Max budget: $3.000 | Current cost: $0.016, prompt_tokens: 1818, completion_tokens: 153\n2025-04-30 14:00:58.395 | INFO     | metagpt.roles.di.role_zero:_act:322 - Commands: \n[{'command_name': 'Task.create', 'args': {'task_id': 'Design Game Architecture', 'instruction': 'Design the architecture of the CLI Blackjack game', 'task_type': 'Design', 'assignee': 'Alice'}}, {'command_name': 'Task.create', 'args': {'task_id': 'Implement Game Logic', 'instruction': 'Implement the game logic for the CLI Blackjack game', 'task_type': 'Implementation', 'assignee': 'Alice'}}]\n2025-04-30 14:00:58.396 | INFO     | metagpt.roles.di.role_zero:_act:324 - Commands outputs: \nCommand Task.create not found.\nI understand that I need to create a CLI Blackjack game. To start, I will create a new task to design the game's architecture and then implement the game logic.\n\nHere is my plan:\n\n```json\n[\n    {\n        \"command_name\": \"Task.create\",\n        \"args\": {\"task_id\": \"Design Game Architecture\", \"instruction\": \"Design the architecture of the CLI Blackjack game\", \"task_type\": \"Design\", \"assignee\": \"Alice\"}\n    },\n    {\n        \"command_name\": \"Task.create\",\n        \"args\": {\"task_id\": \"Implement Game Logic\", \"instruction\": \"Implement the game logic for the CLI Blackjack game\", \"task_type\": \"Implementation\", \"assignee\": \"Alice\"}\n    }\n]\n```\n2025-04-30 14:01:08.609 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.092 | Max budget: $3.000 | Current cost: $0.030, prompt_tokens: 3584, completion_tokens: 152\n2025-04-30 14:01:08.610 | WARNING  | metagpt.roles.di.role_zero:_check_duplicates:436 - Duplicate response detected: I understand that I need to create a CLI Blackjack game. To start, I will create a new task to design the game's architecture and then implement the game logic.\n\nHere is my plan:\n\n```json\n[\n    {\n        \"command_name\": \"Task.create\",\n        \"args\": {\"task_id\": \"Design Game Architecture\", \"instruction\": \"Design the architecture of the CLI Blackjack game\", \"task_type\": \"Design\", \"assignee\": \"Alice\"}\n    },\n    {\n        \"command_name\": \"Task.create\",\n        \"args\": {\"task_id\": \"Implement Game Logic\", \"instruction\": \"Implement the game logic for the CLI Blackjack game\", \"task_type\": \"Implementation\", \"assignee\": \"Alice\"}\n    }\n]\n```\nUpon reviewing the history, I realize that I need to create a plan to write a CLI Blackjack game. Since there is no existing plan, I will create a new plan with the required tasks.\n\nHere are the commands to create a plan:\n\n```json\n[\n    {\n        \"command_name\": \"Plan.create\",\n        \"args\": {\"plan_id\": \"Write CLI Blackjack Game\", \"description\": \"Create a CLI Blackjack game\"}\n    },\n    {\n        \"command_name\": \"Task.create\",\n        \"args\": {\"task_id\": \"Define Game Requirements\", \"instruction\": \"Define the requirements for the CLI Blackjack game\", \"task_type\": \"Research\", \"assignee\": \"Alice\"}\n    }\n]\n```\n2025-04-30 14:01:10.601 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.100 | Max budget: $3.000 | Current cost: $0.007, prompt_tokens: 762, completion_tokens: 145\n2025-04-30 14:01:10.601 | INFO     | metagpt.roles.di.role_zero:_act:322 - Commands: \n[{'command_name': 'Plan.create', 'args': {'plan_id': 'Write CLI Blackjack Game', 'description': 'Create a CLI Blackjack game'}}, {'command_name': 'Task.create', 'args': {'task_id': 'Define Game Requirements', 'instruction': 'Define the requirements for the CLI Blackjack game', 'task_type': 'Research', 'assignee': 'Alice'}}]\n2025-04-30 14:01:10.601 | INFO     | metagpt.roles.di.role_zero:_act:324 - Commands outputs: \nCommand Plan.create not found.\nBased on the goal to write a CLI Blackjack game, I will create a plan to achieve this goal. Since there is no existing plan, I will start by defining the game requirements.\n\nHere are my thoughts:\nI need to define the game requirements, design the game architecture, implement the game logic, and test the game. \n\nHere are the commands to create a plan:\n\n```json\n[\n    {\n        \"command_name\": \"Task.create\",\n        \"args\": {\"task_id\": \"Define Game Requirements\", \"instruction\": \"Define the requirements for the CLI Blackjack game\", \"task_type\": \"Research\", \"assignee\": \"Alice\"}\n    },\n    {\n        \"command_name\": \"Task.create\",\n        \"args\": {\"task_id\": \"Design Game Architecture\", \"instruction\": \"Design the architecture of the CLI Blackjack game\", \"task_type\": \"Design\", \"assignee\": \"Alice\", \"dependent_task_ids\": [\"Define Game Requirements\"]}\n    },\n    {\n        \"command_name\": \"Task.create\",\n        \"args\": {\"task_id\": \"Implement Game Logic\", \"instruction\": \"Implement the game logic for the CLI Blackjack game\", \"task_type\": \"Implementation\", \"assignee\": \"Alice\", \"dependent_task_ids\": [\"Design Game Architecture\"]}\n    },\n    {\n        \"command_name\": \"Task.create\",\n        \"args\": {\"task_id\": \"Test Game\", \"instruction\": \"Test the CLI Blackjack game\", \"task_type\": \"Testing\", \"assignee\": \"Alice\", \"dependent_task_ids\": [\"Implement Game Logic\"]}\n    }\n]\n```\n2025-04-30 14:01:29.290 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.117 | Max budget: $3.000 | Current cost: $0.018, prompt_tokens: 1881, completion_tokens: 321\n2025-04-30 14:01:29.291 | INFO     | metagpt.roles.di.role_zero:_act:322 - Commands: \n[{'command_name': 'Task.create', 'args': {'task_id': 'Define Game Requirements', 'instruction': 'Define the requirements for the CLI Blackjack game', 'task_type': 'Research', 'assignee': 'Alice'}}, {'command_name': 'Task.create', 'args': {'task_id': 'Design Game Architecture', 'instruction': 'Design the architecture of the CLI Blackjack game', 'task_type': 'Design', 'assignee': 'Alice', 'dependent_task_ids': ['Define Game Requirements']}}, {'command_name': 'Task.create', 'args': {'task_id': 'Implement Game Logic', 'instruction': 'Implement the game logic for the CLI Blackjack game', 'task_type': 'Implementation', 'assignee': 'Alice', 'dependent_task_ids': ['Design Game Architecture']}}, {'command_name': 'Task.create', 'args': {'task_id': 'Test Game', 'instruction': 'Test the CLI Blackjack game', 'task_type': 'Testing', 'assignee': 'Alice', 'dependent_task_ids': ['Implement Game Logic']}}]\n2025-04-30 14:01:29.291 | INFO     | metagpt.roles.di.role_zero:_act:324 - Commands outputs: \nCommand Task.create not found.\nBased on the goal to write a CLI Blackjack game, I will create a plan to achieve this goal. Since there is no existing plan, I will start by defining the game requirements.\n\nHere are my thoughts:\nI need to define the game requirements, design the game architecture, implement the game logic, and test the game.\n\nHere are the commands to create a plan:\n\n```json\n[\n    {\"command_name\": \"RoleZero.ask_human\", \"args\": {\"question\": \"Can you provide more details about the CLI Blackjack game, such as the rules and features required?\"}},\n    {\"command_name\": \"Task.create\", \"args\": {\"task_id\": \"Define Game Requirements\", \"instruction\": \"Define the requirements for the CLI Blackjack game\", \"task_type\": \"Research\", \"assignee\": \"Alice\"}}\n]\n```\n2025-04-30 14:01:30.224 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.134 | Max budget: $3.000 | Current cost: $0.017, prompt_tokens: 1986, completion_tokens: 167\n2025-04-30 14:01:30.225 | INFO     | metagpt.roles.di.role_zero:_act:322 - Commands: \n[{'command_name': 'RoleZero.ask_human', 'args': {'question': 'Can you provide more details about the CLI Blackjack game, such as the rules and features required?'}}, {'command_name': 'Task.create', 'args': {'task_id': 'Define Game Requirements', 'instruction': 'Define the requirements for the CLI Blackjack game', 'task_type': 'Research', 'assignee': 'Alice'}}]\nCan you provide more details about the CLI Blackjack game, such as the rules and features required?each card is worth the value indicated in the number. Jack, Queen, and King cards are worth 10. Aces are worth 11 or 1. The objective is to achieve 21 points or the closest to 21. If you beat the dealer then you win.\n2025-04-30 14:02:43.895 | INFO     | metagpt.roles.di.role_zero:_act:324 - Commands outputs: \nCommand RoleZero.ask_human executed:Human response: each card is worth the value indicated in the number. Jack, Queen, and King cards are worth 10. Aces are worth 11 or 1. The objective is to achieve 21 points or the closest to 21. If you beat the dealer then you win.\n\nCommand Task.create not found.\nBased on the goal to write a CLI Blackjack game, I will create a plan to achieve this goal. Since there is no existing plan, I will start by defining the game requirements.\n\nHere are my thoughts:\nI have received the game requirements from the human user, which include the card values and the objective of the game. Next, I will create a task to design the game architecture.\n\nHere are the commands to create a plan:\n\n```json\n[\n    {\"command_name\": \"Task.create\", \"args\": {\"task_id\": \"Define Game Requirements\", \"instruction\": \"Define the requirements for the CLI Blackjack game\", \"task_type\": \"Research\", \"assignee\": \"Alice\", \"status\": \"Completed\"}},\n    {\"command_name\": \"Task.create\", \"args\": {\"task_id\": \"Design Game Architecture\", \"instruction\": \"Design the architecture of the CLI Blackjack game\", \"task_type\": \"Design\", \"assignee\": \"Alice\"}}\n]\n```\n2025-04-30 14:02:47.588 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.152 | Max budget: $3.000 | Current cost: $0.018, prompt_tokens: 2045, completion_tokens: 196\n2025-04-30 14:02:47.589 | INFO     | metagpt.roles.di.role_zero:_act:322 - Commands: \n[{'command_name': 'Task.create', 'args': {'task_id': 'Define Game Requirements', 'instruction': 'Define the requirements for the CLI Blackjack game', 'task_type': 'Research', 'assignee': 'Alice', 'status': 'Completed'}}, {'command_name': 'Task.create', 'args': {'task_id': 'Design Game Architecture', 'instruction': 'Design the architecture of the CLI Blackjack game', 'task_type': 'Design', 'assignee': 'Alice'}}]\n2025-04-30 14:02:47.590 | INFO     | metagpt.roles.di.role_zero:_act:324 - Commands outputs: \nCommand Task.create not found.\nBased on the goal to write a CLI Blackjack game, I will create a plan to achieve this goal. Since there is no existing plan, I will start by defining the game requirements and designing the game architecture.\n\nHere are my thoughts:\nI have received the game requirements from the human user, which include the card values and the objective of the game. Next, I will create a task to design the game architecture.\n\n```json\n[\n    {\"command_name\": \"RoleZero.reply_to_human\", \"args\": {\"content\": \"I have received the game requirements. Next, I will design the game architecture.\"}},\n    {\"command_name\": \"RoleZero.ask_human\", \"args\": {\"question\": \"Can you provide more details about the game architecture, such as the classes and methods required?\"}}\n]\n```\n2025-04-30 14:02:48.619 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.171 | Max budget: $3.000 | Current cost: $0.018, prompt_tokens: 2125, completion_tokens: 163\n2025-04-30 14:02:48.620 | INFO     | metagpt.roles.di.role_zero:_act:322 - Commands: \n[{'command_name': 'RoleZero.reply_to_human', 'args': {'content': 'I have received the game requirements. Next, I will design the game architecture.'}}, {'command_name': 'RoleZero.ask_human', 'args': {'question': 'Can you provide more details about the game architecture, such as the classes and methods required?'}}]\nCan you provide more details about the game architecture, such as the classes and methods required?we want to get the hand value, points per card value, and other general utility functions.\n2025-04-30 14:03:37.899 | INFO     | metagpt.roles.di.role_zero:_act:324 - Commands outputs: \nCommand RoleZero.reply_to_human executed: SUCCESS, human has received your reply. Refrain from resending duplicate messages.  If you no longer need to take action, use the command â€˜endâ€™ to stop.\n\nCommand RoleZero.ask_human executed:Human response: we want to get the hand value, points per card value, and other general utility functions.\nBased on the goal to write a CLI Blackjack game, I will create a plan to achieve this goal. Since there is no existing plan, I will start by defining the game requirements and designing the game architecture.\n\nI have received the game requirements from the human user, which include the card values and the objective of the game. I have also received the details about the game architecture, which include getting the hand value, points per card value, and other general utility functions.\n\nNext, I will create tasks to implement the game logic and test the game.\n\n```json\n[\n    {\"command_name\": \"Task.create\", \"args\": {\"task_id\": \"Design Game Architecture\", \"instruction\": \"Design the architecture of the CLI Blackjack game\", \"task_type\": \"Design\", \"assignee\": \"Alice\", \"status\": \"Completed\"}},\n    {\"command_name\": \"Task.create\", \"args\": {\"task_id\": \"Implement Game Logic\", \"instruction\": \"Implement the game logic for the CLI Blackjack game\", \"task_type\": \"Implementation\", \"assignee\": \"Alice\"}},\n    {\"command_name\": \"Task.create\", \"args\": {\"task_id\": \"Test Game\", \"instruction\": \"Test the CLI Blackjack game\", \"task_type\": \"Testing\", \"assignee\": \"Alice\", \"dependent_task_ids\": [\"Implement Game Logic\"]}}\n]\n```\n2025-04-30 14:03:42.564 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.190 | Max budget: $3.000 | Current cost: $0.019, prompt_tokens: 2161, completion_tokens: 275\n2025-04-30 14:03:42.565 | INFO     | metagpt.roles.di.role_zero:_act:322 - Commands: \n[{'command_name': 'Task.create', 'args': {'task_id': 'Design Game Architecture', 'instruction': 'Design the architecture of the CLI Blackjack game', 'task_type': 'Design', 'assignee': 'Alice', 'status': 'Completed'}}, {'command_name': 'Task.create', 'args': {'task_id': 'Implement Game Logic', 'instruction': 'Implement the game logic for the CLI Blackjack game', 'task_type': 'Implementation', 'assignee': 'Alice'}}, {'command_name': 'Task.create', 'args': {'task_id': 'Test Game', 'instruction': 'Test the CLI Blackjack game', 'task_type': 'Testing', 'assignee': 'Alice', 'dependent_task_ids': ['Implement Game Logic']}}]\n2025-04-30 14:03:42.565 | INFO     | metagpt.roles.di.role_zero:_act:324 - Commands outputs: \nCommand Task.create not found.\nBased on the goal to write a CLI Blackjack game, I will create a plan to achieve this goal. Since there is no existing plan, I will start by defining the game requirements and designing the game architecture.\n\nI have received the game requirements from the human user, which include the card values and the objective of the game. I have also received the details about the game architecture, which include getting the hand value, points per card value, and other general utility functions.\n\nNext, I will create tasks to implement the game logic and test the game.\n\n```json\n[\n    {\"command_name\": \"Editor.create_file\", \"args\": {\"filename\": \"blackjack_game.py\"}},\n    {\"command_name\": \"Editor.append_file\", \"args\": {\"file_name\": \"blackjack_game.py\", \"content\": \"class Card:\\n    def __init__(self, value, suit):\\n        self.value = value\\n        self.suit = suit\\n\\n    def __repr__(self):\\n        return f'{self.value} of {self.suit}'}\"},\n    {\"command_name\": \"Editor.append_file\", \"args\": {\"file_name\": \"blackjack_game.py\", \"content\": \"\\n\\ndef calculate_hand_value(hand):\\n    # implement hand value calculation logic\\n    pass\"}}\n]\n```\n2025-04-30 14:03:57.308 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.221 | Max budget: $3.000 | Current cost: $0.031, prompt_tokens: 3563, completion_tokens: 265\n2025-04-30 14:03:57.309 | WARNING  | metagpt.roles.di.role_zero:_parse_commands:459 - Failed to parse JSON for: Based on the goal to write a CLI Blackjack game, I will create a plan to achieve this goal. Since there is no existing plan, I will start by defining the game requirements and designing the game architecture.\n\nI have received the game requirements from the human user, which include the card values and the objective of the game. I have also received the details about the game architecture, which include getting the hand value, points per card value, and other general utility functions.\n\nNext, I will create tasks to implement the game logic and test the game.\n\n```json\n[\n    {\"command_name\": \"Editor.create_file\", \"args\": {\"filename\": \"blackjack_game.py\"}},\n    {\"command_name\": \"Editor.append_file\", \"args\": {\"file_name\": \"blackjack_game.py\", \"content\": \"class Card:\\n    def __init__(self, value, suit):\\n        self.value = value\\n        self.suit = suit\\n\\n    def __repr__(self):\\n        return f'{self.value} of {self.suit}'}\"},\n    {\"command_name\": \"Editor.append_file\", \"args\": {\"file_name\": \"blackjack_game.py\", \"content\": \"\\n\\ndef calculate_hand_value(hand):\\n    # implement hand value calculation logic\\n    pass\"}}\n]\n```. Trying to repair...\nI'd be happy to help you with that.\n\nAfter reviewing the JSON data, I noticed that there are some formatting issues. Here is the corrected JSON data:\n\n```json\n[\n    {\"command_name\": \"Editor.create_file\", \"args\": {\"filename\": \"blackjack_game.py\"}},\n    {\"command_name\": \"Editor.append_file\", \"args\": {\"file_name\": \"blackjack_game.py\", \"content\": \"class Card:\\n    def __init__(self, value, suit):\\n        self.value = value\\n        self.suit = suit\\n\\n    def __repr__(self):\\n        return f'{self.value} of {self.suit}'}},\n    {\"command_name\": \"Editor.append_file\", \"args\": {\"file_name\": \"blackjack_game.py\", \"content\": \"\\ndef calculate_hand_value(hand):\\n    # implement hand value calculation logic\\n    pass\"}}\n]\n```\n\nThe issues were:\n\n1. The JSON data was not properly formatted, with inconsistent indentation and missing commas.\n2. The file paths were not enclosed in double quotes, which is required in JSON.\n\nI've corrected these issues, and the JSON data should now be loadable by the `json.loads()` function.\n2025-04-30 14:04:11.195 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.226 | Max budget: $3.000 | Current cost: $0.006, prompt_tokens: 453, completion_tokens: 249\n2025-04-30 14:04:11.246 | ERROR    | metagpt.utils.common:wrapper:683 - Exception occurs, start to serialize the project, exp:\nTraceback (most recent call last):\n  File \"/Users/cmodi/Documents/ai/llama-api/MetaGPT/metagpt/roles/di/role_zero.py\", line 457, in _parse_commands\n    commands = json.loads(repair_llm_raw_output(output=commands, req_keys=[None], repair_type=RepairType.JSON))\n  File \"/opt/anaconda3/envs/metagpt/lib/python3.10/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\njson.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 4 column 5 (char 373)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/cmodi/Documents/ai/llama-api/MetaGPT/metagpt/roles/di/role_zero.py\", line 464, in _parse_commands\n    commands = json.loads(CodeParser.parse_code(block=None, lang=\"json\", text=commands))\n  File \"/opt/anaconda3/envs/metagpt/lib/python3.10/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\njson.decoder.JSONDecodeError: Invalid control character at: line 3 column 279 (char 367)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/cmodi/Documents/ai/llama-api/MetaGPT/metagpt/utils/common.py\", line 692, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"/Users/cmodi/Documents/ai/llama-api/MetaGPT/metagpt/roles/role.py\", line 548, in run\n    rsp = await self.react()\njson.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 4 column 5 (char 373)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/cmodi/Documents/ai/llama-api/MetaGPT/metagpt/utils/common.py\", line 678, in wrapper\n    result = await func(self, *args, **kwargs)\n  File \"/Users/cmodi/Documents/ai/llama-api/MetaGPT/metagpt/team.py\", line 134, in run\n    await self.env.run()\nException: Traceback (most recent call last):\n  File \"/Users/cmodi/Documents/ai/llama-api/MetaGPT/metagpt/roles/di/role_zero.py\", line 457, in _parse_commands\n    commands = json.loads(repair_llm_raw_output(output=commands, req_keys=[None], repair_type=RepairType.JSON))\n  File \"/opt/anaconda3/envs/metagpt/lib/python3.10/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n  File \"/opt/anaconda3/envs/metagpt/lib/python3.10/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File \"/opt/anaconda3/envs/metagpt/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n    obj, end = self.scan_once(s, idx)\njson.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 4 column 5 (char 373)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/cmodi/Documents/ai/llama-api/MetaGPT/metagpt/roles/di/role_zero.py\", line 464, in _parse_commands\n    commands = json.loads(CodeParser.parse_code(block=None, lang=\"json\", text=commands))\n  File \"/opt/anaconda3/envs/metagpt/lib/python3.10/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n  File \"/opt/anaconda3/envs/metagpt/lib/python3.10/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File \"/opt/anaconda3/envs/metagpt/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n    obj, end = self.scan_once(s, idx)\njson.decoder.JSONDecodeError: Invalid control character at: line 3 column 279 (char 367)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/cmodi/Documents/ai/llama-api/MetaGPT/metagpt/utils/common.py\", line 692, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"/Users/cmodi/Documents/ai/llama-api/MetaGPT/metagpt/roles/role.py\", line 548, in run\n    rsp = await self.react()\n  File \"/Users/cmodi/Documents/ai/llama-api/MetaGPT/metagpt/roles/role.py\", line 515, in react\n    rsp = await self._react()\n  File \"/Users/cmodi/Documents/ai/llama-api/MetaGPT/metagpt/roles/di/role_zero.py\", line 354, in _react\n    rsp = await self._act()\n  File \"/Users/cmodi/Documents/ai/llama-api/MetaGPT/metagpt/roles/di/role_zero.py\", line 316, in _act\n    commands, ok, self.command_rsp = await self._parse_commands(self.command_rsp)\n  File \"/Users/cmodi/Documents/ai/llama-api/MetaGPT/metagpt/roles/di/role_zero.py\", line 469, in _parse_commands\n    commands = json.loads(\n  File \"/opt/anaconda3/envs/metagpt/lib/python3.10/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n  File \"/opt/anaconda3/envs/metagpt/lib/python3.10/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File \"/opt/anaconda3/envs/metagpt/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n    obj, end = self.scan_once(s, idx)\njson.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 4 column 5 (char 373)\n\n\n/opt/anaconda3/envs/metagpt/lib/python3.10/site-packages/pydantic/_internal/_std_types_schema.py:319: UserWarning: Pydantic serializer warnings:\n  Expected `enum` but got `str` with value `'react'` - serialized value may not be as expected\n  return handler(v)\n/Users/cmodi/Documents/ai/llama-api/MetaGPT/metagpt/base/base_serialization.py:26: UserWarning: Pydantic serializer warnings:\n  Expected `enum` but got `str` with value `'react'` - serialized value may not be as expected\n  ret = default_serializer(self)\n```",
      "state": "open",
      "author": "cmodi-meta",
      "author_type": "User",
      "created_at": "2025-04-30T21:39:09Z",
      "updated_at": "2025-06-18T00:35:50Z",
      "closed_at": null,
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1819/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1819",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1819",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:49.716217",
      "comments": [
        {
          "author": "better629",
          "body": "@cmodi-meta the output of the llm \n\n```\n[\n    {\"command_name\": \"Editor.create_file\", \"args\": {\"filename\": \"blackjack_game.py\"}},\n    {\"command_name\": \"Editor.append_file\", \"args\": {\"file_name\": \"blackjack_game.py\", \"content\": \"class Card:\\n    def __init__(self, value, suit):\\n        self.value = v",
          "created_at": "2025-05-14T05:53:03Z"
        },
        {
          "author": "cmodi-meta",
          "body": "Thank you for the reply @better629 . I've tried using other models like from OpenAI as well and I run into the same issue. I suspect there may be an issue with env set-up? Would you be able to provide a step by step with a openrouter provider (or any other provider) model to help get started?\n\nI'd l",
          "created_at": "2025-05-15T01:15:20Z"
        },
        {
          "author": "cmodi-meta",
          "body": "@better629 or rather is there a set of instructions you can provide to work with the [openrouter-llama3-70b-instruct.yaml](https://github.com/FoundationAgents/MetaGPT/blob/main/config/examples/openrouter-llama3-70b-instruct.yaml)) since that's a pre-config'd yaml file that we can use out of the box.",
          "created_at": "2025-05-15T08:22:03Z"
        },
        {
          "author": "limboys",
          "body": "llmapi configration doc here:https://docs.deepwisdom.ai/main/en/guide/get_started/configuration/llm_api_configuration.html",
          "created_at": "2025-05-18T09:35:39Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-18T00:35:49Z"
        }
      ]
    },
    {
      "issue_number": 1821,
      "title": "Gemini Models -  504 Deadline Exceeded and BlockedPromptException",
      "body": "**Bug description**\n<!-- Clearly and directly describe the current bug -->\nHi, when I use Gemini models, I keep running into 504 Deadline exceeded and BlockedPromptException errors. \nGuess the Gemini_Api code inside the /provider needs to be tweaked with better timeout and safety settings. \n\n\n**Environment information**\n<!-- Environmentï¼šSystem version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\nUbuntu 24.04\nGemini 2.5 pro\nPython 3.11.7\nMetagpt 0.0.8\n",
      "state": "closed",
      "author": "krish240574",
      "author_type": "User",
      "created_at": "2025-05-02T01:08:15Z",
      "updated_at": "2025-06-18T00:35:49Z",
      "closed_at": "2025-06-18T00:35:49Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1821/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1821",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1821",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:49.903985",
      "comments": [
        {
          "author": "krish240574",
          "body": "errors: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\nresponse:\nGenerateContentResponse(\n    done=True,\n    iterator=None,\n    result=glm.GenerateContentResponse",
          "created_at": "2025-05-03T11:54:18Z"
        },
        {
          "author": "krish240574",
          "body": "this makes the Gemini models pretty much unusable with MetaGPT - context of 1 million tokens ! ",
          "created_at": "2025-05-03T11:54:36Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-03T00:36:23Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-06-18T00:35:48Z"
        }
      ]
    },
    {
      "issue_number": 1773,
      "title": "AttributeError: 'NoneType' object has no attribute 'profile'",
      "body": "åœ¨è¿è¡Œâ€œè¾©è®ºï¼šæ™ºèƒ½ä½“å¯¹æŠ—â€çš„ä»£ç æ—¶ï¼Œ[MetaGPT](https://github.com/geekan/MetaGPT/tree/main)/[examples](https://github.com/geekan/MetaGPT/tree/main/examples)\n/debate.py\næŠ¥é”™ï¼š\nAttributeError: 'NoneType' object has no attribute 'profile'\n\n\næ·»åŠ teamleaderèƒ½è¿è¡Œï¼Œä½†è¾“å‡ºä¸æ˜¯è¾©è®ºå†…å®¹ï¼Œè€Œåªæœ‰ä¸€æ®µè¯ã€‚",
      "state": "open",
      "author": "xukaizhao",
      "author_type": "User",
      "created_at": "2025-03-19T14:27:38Z",
      "updated_at": "2025-06-17T00:35:53Z",
      "closed_at": null,
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1773/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1773",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1773",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:50.119063",
      "comments": [
        {
          "author": "RatexMak",
          "body": "ä¸€æ ·çš„æ•…éšœï¼Œè¯·é—®è§£å†³äº†å—ï¼Ÿ",
          "created_at": "2025-04-16T02:30:30Z"
        },
        {
          "author": "stayfoo",
          "body": "ä¿®æ”¹é…ç½®ï¼šMetaGPT/metagpt/const.py  ä¸­çš„ TEAMLEADER_NAME ä¸ºè‡ªå·±å®šä¹‰çš„\n\n```\n# TEAMLEADER_NAME = \"Mike\"\nTEAMLEADER_NAME = \"ç¨‹åºå‘˜Alice\"\n```",
          "created_at": "2025-04-26T09:32:02Z"
        },
        {
          "author": "Xinyuz26",
          "body": "> ä¿®æ”¹é…ç½®ï¼šMetaGPT/metagpt/const.py ä¸­çš„ TEAMLEADER_NAME ä¸ºè‡ªå·±å®šä¹‰çš„\n> \n> ```\n> # TEAMLEADER_NAME = \"Mike\"\n> TEAMLEADER_NAME = \"ç¨‹åºå‘˜Alice\"\n> ```\n\nè¯·é—®teamleaderåœ¨è¿™é‡Œçš„ä½œç”¨æ˜¯ä»€ä¹ˆå‘¢\n",
          "created_at": "2025-04-29T03:26:52Z"
        },
        {
          "author": "qianweijiujiu",
          "body": "Have you ever fixed it. I tried to modify the const TEAMLEADER_NAME but it didn't work.",
          "created_at": "2025-04-29T11:12:36Z"
        },
        {
          "author": "Zha-Miku",
          "body": "> > ä¿®æ”¹é…ç½®ï¼šMetaGPT/metagpt/const.py ä¸­çš„ TEAMLEADER_NAME ä¸ºè‡ªå·±å®šä¹‰çš„\n> > ```\n> > # TEAMLEADER_NAME = \"Mike\"\n> > TEAMLEADER_NAME = \"ç¨‹åºå‘˜Alice\"\n> > ```\n> \n> è¯·é—®teamleaderåœ¨è¿™é‡Œçš„ä½œç”¨æ˜¯ä»€ä¹ˆå‘¢\n\nnot work",
          "created_at": "2025-05-01T08:04:50Z"
        }
      ]
    },
    {
      "issue_number": 1832,
      "title": "Is this project being abondoned?",
      "body": "I see very few updates and bug fixes, things have slowed down here drastically - is this project dying? \nIt will be very sad to see it go, it is a brilliant piece of work. ",
      "state": "open",
      "author": "krish240574",
      "author_type": "User",
      "created_at": "2025-05-17T12:27:52Z",
      "updated_at": "2025-06-17T00:35:51Z",
      "closed_at": null,
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1832/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 1,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1832",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1832",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:50.463606",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-17T00:35:51Z"
        }
      ]
    },
    {
      "issue_number": 1778,
      "title": "ImportError: cannot import name 'model_validator' from 'pydantic'",
      "body": "**Bug description**\nå½“é‡‡ç”¨python 3.10çš„æ—¶å€™ï¼Œæ‰§è¡Œï¼š\n```sh\npython -m examples.spo.optimize\n```\næœ‰ File \"N:\\Python-virtual-envir\\MetaGPT_programs\\lib\\site-packages\\semantic_kernel\\connectors\\ai\\function_choice_behavior.py\", line 12, in <module>\n    from semantic_kernel.kernel_pydantic import KernelBaseModel\n  File \"N:\\Python-virtual-envir\\MetaGPT_programs\\lib\\site-packages\\semantic_kernel\\kernel_pydantic.py\", line 7, in <module>        \n    from pydantic.networks import Url\nImportError: cannot import name 'Url' from 'pydantic.networks' (N:\\Python-virtual-envir\\MetaGPT_programs\\lib\\site-packages\\pydantic\\networks.py) è¿™ä¸ªé—®é¢˜ï¼›\nç„¶è€ŒGPT çš„åˆ†æç»“æœä¸ºï¼š\né—®é¢˜åŸå› ï¼š\n\næ ¹æ® [Pydantic å®˜æ–¹è¿ç§»æŒ‡å—](https://pydantic.com.cn/migration/)ï¼Œåœ¨ Pydantic V2 ä¸­ï¼Œpydantic.networks ä¸­çš„ Url ç±»å‹å·²è¢«ç§»é™¤æˆ–é‡æ„ã€‚è¿™æ„å‘³ç€ï¼Œå¦‚æœæ‚¨çš„é¡¹ç›®æˆ–å…¶ä¾èµ–é¡¹ï¼ˆå¦‚ semantic-kernelï¼‰ä»åœ¨å°è¯•ä» pydantic.networks å¯¼å…¥ Urlï¼Œä¸”æ‚¨ä½¿ç”¨çš„æ˜¯ Pydantic V2ï¼Œåˆ™ä¼šå‡ºç°æ­¤å¯¼å…¥é”™è¯¯ã€‚\nå› æ­¤æˆ‘é‡‡ç”¨äº†\n```sh\npip install pydantic==1.10.*\n```\nå†æ¬¡æ‰§è¡Œï¼š\n```sh\npython -m examples.spo.optimize\n```\nå‡ºç°äº†å¦‚ä¸‹é”™è¯¯ï¼š\n  File \"N:\\Python-virtual-envir\\MetaGPT_programs\\lib\\site-packages\\semantic_kernel\\connectors\\ai\\prompt_execution_settings.py\", line 6, in <module>\n    from pydantic import Field, model_validator\nImportError: cannot import name 'model_validator' from 'pydantic' (N:\\Python-virtual-envir\\MetaGPT_programs\\lib\\site-packages\\pydantic\\__init__.cp310-win_amd64.pyd)\nåˆ†æå¾—åˆ° ï¼š\nè¿™é€šå¸¸æ˜¯ç”±äº pydantic ç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜å¼•èµ·çš„ã€‚æ ¹æ® [Pydantic å®˜æ–¹æ–‡æ¡£](https://docs.pydantic.dev/2.0/usage/validators/)ï¼Œmodel_validator æ˜¯åœ¨ Pydantic V2 ä¸­å¼•å…¥çš„ã€‚å¦‚æœæ‚¨çš„ä»£ç æˆ–å…¶ä¾èµ–é¡¹å°è¯•å¯¼å…¥ model_validatorï¼Œä½†å½“å‰ç¯å¢ƒä¸­å®‰è£…çš„æ˜¯ Pydantic V1ï¼Œåˆ™ä¼šå‡ºç°æ­¤é”™è¯¯ã€‚\nå› æ­¤è¿™ä¸ªé—®é¢˜æ€»çš„æ¥è¯´æ˜¯ï¼Œpydantic å°äº2.0å’Œå¤§äºç­‰äº2.0 ä¹Ÿå°±æ˜¯æ•´ä¸ªé¡¹ç›®ä¸­å­˜åœ¨å¼•ç”¨pydanticè¿™ä¸ªåº“æ—¶å€™å‡ºç°ä¾èµ–å†²çªé”™è¯¯ï¼›\n\n**Environment information**\n<!-- Environmentï¼šSystem version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\n\n- LLM type and model name:\n- System version:\n- Python version:\n- MetaGPT version or branch:\n\n<!-- Dependent packagessï¼šthe packages version cause the bug(like `pydantic 1.10.8`), installation methodï¼ˆlike `pip install metagpt` or `pip install from source` or `run in docker`ï¼‰ -->\n\n- packages version:\n- installation method: \n\n**Screenshots or logs**\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->",
      "state": "open",
      "author": "lijiandao",
      "author_type": "User",
      "created_at": "2025-03-21T07:08:53Z",
      "updated_at": "2025-06-16T00:37:52Z",
      "closed_at": null,
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1778/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1778",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1778",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:50.662268",
      "comments": [
        {
          "author": "Lluvia-Tang",
          "body": "æ€ä¹ˆè§£å†³å‘¢ï¼Ÿ\n",
          "created_at": "2025-04-21T11:10:42Z"
        },
        {
          "author": "better629",
          "body": "use `pydantic 2.x` and remove `semantic_kernel`",
          "created_at": "2025-05-16T12:58:41Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-16T00:37:51Z"
        }
      ]
    },
    {
      "issue_number": 1417,
      "title": "humaneval",
      "body": "è¯·é—®å¯ä»¥æä¾›æµ‹è¯•humanevalçš„ç›¸å…³æ–¹æ³•å—ï¼Œç°åœ¨æƒ³è¦è¿›è¡Œæµ‹è¯•ä½†æ˜¯å®Œå…¨ä¸çŸ¥é“è¯¥å¦‚ä½•ä¸‹æ‰‹ï¼Œgenerate_repoè¿”å›çš„æ˜¯ä¸€ä¸ªProjectrepoç±»å‹ä¸èƒ½è¢«è½¬æ¢æˆjsonlï¼Œå¸Œæœ›ä½œè€…èƒ½åŠ ä¸Šå»ï¼Œè°¢è°¢ã€‚\r\n",
      "state": "closed",
      "author": "codeAlwaysPass",
      "author_type": "User",
      "created_at": "2024-07-27T09:28:01Z",
      "updated_at": "2025-06-11T16:16:43Z",
      "closed_at": "2025-02-01T00:32:41Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1417/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "stellaHSR"
      ],
      "milestone": "1.0",
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1417",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1417",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:50.864930",
      "comments": [
        {
          "author": "iorisa",
          "body": "ProjectRepoå¯¹åº”çš„æ˜¯ä¸€ä¸ªæ–‡ä»¶å¤¹è·¯å¾„ã€‚å¦‚æœè¦è½¬JSONï¼Œæœ¬è´¨ä¸Šæ˜¯å°†ä¸€ä¸ªæ–‡ä»¶å¤¹è½¬JSONã€‚\r\nä½ å¸Œæœ›è½¬æˆä»€ä¹ˆæ ·çš„JSONï¼Ÿ\r\n@codeAlwaysPass ",
          "created_at": "2024-07-29T07:41:05Z"
        },
        {
          "author": "codeAlwaysPass",
          "body": "æˆ‘å¸Œæœ›è½¬æˆä¸€ä¸ªå¯ä»¥è®©humanevalè¯„ä¼°çš„jsonlæ–‡ä»¶ï¼Œç›®å‰æˆ‘æ˜¯è‡ªå·±å†™pythonè„šæœ¬æŠŠæ–‡ä»¶å¤¹é‡Œé¢çš„ä»£ç å†™å…¥jsonlï¼Œä½†å¯èƒ½æ˜¯ç”±äºæˆ‘çš„ä»£ç é—®é¢˜è¿™æ ·å¾—åˆ°çš„jsonlè·å¾—çš„å‡†ç¡®ç‡åªæœ‰0.27ã€‚",
          "created_at": "2024-07-29T08:14:13Z"
        },
        {
          "author": "stellaHSR",
          "body": "ç”±äºç‰ˆæœ¬è¿­ä»£æ–°å¢åŠŸèƒ½ä¸”è¿­ä»£è¾ƒå¿«ï¼Œengineer ä¸­å¢åŠ äº†ä¸å°‘ repo çº§åˆ«çš„å¤„ç†å’Œè®¾è®¡ã€‚é’ˆå¯¹ HumanEvalï¼Œæˆ‘å»ºè®®ä½ å…ˆç†Ÿæ‚‰å¹¶ä½¿ç”¨ v0.4-release æˆ–è€…ä¹‹å‰çš„ç‰ˆæœ¬ã€‚åœ¨è¿™ä¸ªç‰ˆæœ¬ä¸­ï¼Œä½ å¯ä»¥è·å– engineer çš„æ‰§è¡Œç»“æœï¼ˆ`msg = Message(content=code, role=self.profile, cause_by=WriteCode)`ï¼‰ã€‚ä½ å¯ä»¥é€‰æ‹©åœ¨ msg ç”Ÿæˆä¹‹å‰ç›´æ¥å°†codeä¿å­˜åˆ°JSONLæ–‡ä»¶ï¼Œæˆ–è€…åœ¨ engineer æ‰§è¡Œç»“æŸåï¼Œé€šè¿‡ memory çš„ `get_by_action`s å‡½æ•°æ¥è·å–ä»£ç ï¼Œå†å°†å…¶å†™å…¥ JSONL æ–‡ä»¶ã€‚:)",
          "created_at": "2024-10-11T06:35:21Z"
        },
        {
          "author": "geekan",
          "body": "There will be some scripts related to humaneval in version 1.0",
          "created_at": "2024-10-20T07:05:45Z"
        },
        {
          "author": "wkwk-ai",
          "body": "è¯·é—®ç°åœ¨æœ‰å¯ä»¥æµ‹è¯•humanevalçš„scriptäº†å—ï¼Ÿ",
          "created_at": "2024-12-17T06:47:49Z"
        }
      ]
    },
    {
      "issue_number": 1811,
      "title": "ui_with_chainlit ç•Œé¢æ— å“åº”",
      "body": "![Image](https://github.com/user-attachments/assets/03b1c325-9ade-4d3d-9309-a21a94b51da7)",
      "state": "closed",
      "author": "liang-tian-tian",
      "author_type": "User",
      "created_at": "2025-04-15T11:18:38Z",
      "updated_at": "2025-06-11T00:35:56Z",
      "closed_at": "2025-06-11T00:35:56Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1811/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1811",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1811",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:51.103899",
      "comments": [
        {
          "author": "HuntZhaozq",
          "body": "é‡åˆ°äº†åŒæ ·çš„é—®é¢˜ï¼Œè¯·é—®ä½ è§£å†³äº†å—",
          "created_at": "2025-04-27T06:49:28Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-28T00:35:18Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-06-11T00:35:56Z"
        }
      ]
    },
    {
      "issue_number": 1817,
      "title": "manual_example.png missing in android_assistant",
      "body": "https://github.com/geekan/MetaGPT/blob/be6921cae61471bf1ffaf9cb9fe7375a6cfd00c5/metagpt/ext/android_assistant/README.md?plain=1#L32\n\n`./resources` is not exist. And I try find in repo but get nothing. `manual_example.png` not exist in examples/android_assistant, docs/resources. README_CN.md has same issue.",
      "state": "closed",
      "author": "BackMountainDevil",
      "author_type": "User",
      "created_at": "2025-04-26T02:52:16Z",
      "updated_at": "2025-06-10T00:35:47Z",
      "closed_at": "2025-06-10T00:35:47Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1817/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1817",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1817",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:51.293114",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-27T00:34:35Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-06-10T00:35:46Z"
        }
      ]
    },
    {
      "issue_number": 1823,
      "title": "the for-loop didn't really carry out in the check of backpropagation",
      "body": "**Bug description**\n<!-- Clearly and directly describe the current bug -->\n  https://github.com/FoundationAgents/MetaGPT/blob/be6921cae61471bf1ffaf9cb9fe7375a6cfd00c5/metagpt/ext/sela/experimenter.py#L87\nHere `i` didn't really be placed in the index\n\n**Bug solved method**\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\n\n**Environment information**\n<!-- Environmentï¼šSystem version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\n\n- LLM type and model name:\n- System version:\n- Python version:\n- MetaGPT version or branch:\n\n<!-- Dependent packagessï¼šthe packages version cause the bug(like `pydantic 1.10.8`), installation methodï¼ˆlike `pip install metagpt` or `pip install from source` or `run in docker`ï¼‰ -->\n\n- packages version:\n- installation method: \n\n**Screenshots or logs**\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->",
      "state": "closed",
      "author": "zuxfoucault",
      "author_type": "User",
      "created_at": "2025-05-05T03:14:49Z",
      "updated_at": "2025-06-06T01:01:37Z",
      "closed_at": "2025-06-06T01:01:37Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1823/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1823",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1823",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:51.453925",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-06-05T00:35:51Z"
        }
      ]
    },
    {
      "issue_number": 1814,
      "title": "agent è·‘åˆ°ä¸€åŠå¡ä½äº†ï¼Œä¸ä¼šå†è¿è¡Œäº†ï¼Œ 2025-04-22 17:36:21.365 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.000 | Max budget: $1000.000 | Current cost: $0.000, prompt_tokens: 2048, completion_tokens: 381",
      "body": "2025-04-22 17:36:21.365 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.000 | Max budget: $1000.000 | Current cost: $0.000, prompt_tokens: 2048, completion_tokens: 381\n\nè¿™æ˜¯é‚£ä¸ªå—é™åˆ¶äº†å—",
      "state": "closed",
      "author": "wangxiaohangxdu",
      "author_type": "User",
      "created_at": "2025-04-22T09:43:04Z",
      "updated_at": "2025-06-06T00:35:27Z",
      "closed_at": "2025-06-06T00:35:27Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1814/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1814",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1814",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:51.627130",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-23T00:35:22Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-06-06T00:35:27Z"
        }
      ]
    },
    {
      "issue_number": 1813,
      "title": "0.8.2ç‰ˆæœ¬æ— æ³•è¯†åˆ«æç¤ºè¯ä¸­çš„æ–‡ä»¶åœ°å€ï¼Œ0.8.1ç‰ˆæœ¬å¯ä»¥ï¼Œæç¤ºè¯è¦æ±‚æ˜¯å¦æœ‰å˜åŒ–ï¼Ÿ",
      "body": "é—®é¢˜ï¼šåœ¨åˆ©ç”¨machine_learning.pyåˆ†ææ•°æ®æ–‡ä»¶æ—¶ï¼Œæç¤ºè¯ä¸­æœ‰æŒ‡å®šçš„æ–‡ä»¶ï¼Œä½†ä»»åŠ¡æ— æ³•è¯†åˆ«\n\nç‰ˆæœ¬ï¼š0.8.2\n\næç¤ºè¯ï¼šå°†æ‰€æœ‰æ–‡ä»¶çš„[å·¥ä½œè¡¨1]ä¸­å¤§åŒºä¸º\"å¤§åŒºK\"çš„æ•°æ®åˆå¹¶ä¸ºä¸€ä¸ªæ–°çš„æ–‡ä»¶ è¾“å…¥æ–‡ä»¶ä¿å­˜åœ¨/home/admin/ai-metagpt-task/2025-04-07/d20783dc-5a86-48f4-9eb5-4ec817b87664/å›½æ°‘é¥®æ°´å®ˆæŠ¤è®¡åˆ’0118.xlsx è¾“å…¥æ–‡ä»¶ä¿å­˜åœ¨/home/admin/ai-metagpt-task/2025-04-07/d20783dc-5a86-48f4-9eb5-4ec817b87664/å›½æ°‘é¥®æ°´å®ˆæŠ¤è®¡åˆ’0119.xlsx è¾“å…¥æ–‡ä»¶ä¿å­˜åœ¨home/admin/ai-metagpt-task/2025-04-07/d20783dc-5a86-48f4-9eb5-4ec817b87664/å›½æ°‘é¥®æ°´å®ˆæŠ¤è®¡åˆ’0120.xlsx è¾“å‡ºæ–‡ä»¶ä¿å­˜åœ¨/home/admin/ai-metagpt-task/2025-04-20/1e1ceb76-e1c4-47cf-8886-d1605966f00a/res_æ—¶é—´æˆ³.xlsx\n\n<img width=\"602\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/6900c933-6b70-493f-a0ba-754d1d1d6956\" />",
      "state": "closed",
      "author": "dingdangmaozj",
      "author_type": "User",
      "created_at": "2025-04-20T10:41:05Z",
      "updated_at": "2025-06-04T00:36:09Z",
      "closed_at": "2025-06-04T00:36:08Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1813/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1813",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1813",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:51.814844",
      "comments": [
        {
          "author": "dingdangmaozj",
          "body": "ä¸Šè¿°æ¥å…¥çš„æ¨¡å‹ä¸ºgpt-4o",
          "created_at": "2025-04-20T10:45:05Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-21T00:35:34Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-06-04T00:36:07Z"
        }
      ]
    },
    {
      "issue_number": 1783,
      "title": "Crash after running for a period of time",
      "body": "### Bug Description\n\nI followed the steps in the README and ran the command to create a simple NestJS module. However, after running for a while, it crashed.\n\n### Bug solved method\n\n- None\n\n### Environment information\n\n- System version: Linux\n- Python version: 3.10\n- OpenManus version or branch: main\n- Installation method:\n```bash\ngit clone https://github.com/geekan/MetaGPT && cd MetaGPT && pip install --upgrade -e .\nmetagpt --init-config\n```\n- ollama version is 0.6.2\n#### config\n```\nllm:\napi_type: ollama\nmodel: \"phi4\"\nbase_url: \"http://localhost:11434/api\"\ntimeout: 9000\n\nbrowser:\nengine: \"playwright\" # playwright/selenium\nbrowser_type: \"firefox\"\n```\n\n\n### Extra information\n\n![Image](https://github.com/user-attachments/assets/c8e7e79c-0d9a-4873-9c81-bc66a9805217)\n\n#### logs\n\n```\nTo fix it, ensure all keys are in double quotes:\n\njson\n{\n  \"name\": \"John Doe\",\n  \"age\": 30,\n  \"courses\": [\"Math\", \"Science\"]\n}\n\n\n### Conclusion\n\nIf you provide the JSON data that is causing issues, I can help identify specific problems. Otherwise, follow the above guidelines to ensure your JSON is correctly formatted for `json.loads()` to process without errors. If no issues are detected in your input, it should be returned unchanged.\n2025-03-22 11:09:35.662 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.000 | Max budget: $3.000 | Current cost: $0.000, prompt_tokens: 1541, completion_tokens: 640\n2025-03-22 11:09:35.663 | ERROR    | metagpt.utils.common:wrapper:683 - Exception occurs, start to serialize the project, exp:\nTraceback (most recent call last):\n  File \"/mnt/ForAI/workspaces/MetaGPT/metagpt/utils/common.py\", line 692, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"/mnt/ForAI/workspaces/MetaGPT/metagpt/roles/role.py\", line 548, in run\n    rsp = await self.react()\nKeyError: 'command_name'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/mnt/ForAI/workspaces/MetaGPT/metagpt/utils/common.py\", line 678, in wrapper\n    result = await func(self, *args, **kwargs)\n  File \"/mnt/ForAI/workspaces/MetaGPT/metagpt/team.py\", line 134, in run\n    await self.env.run()\nException: Traceback (most recent call last):\n  File \"/mnt/ForAI/workspaces/MetaGPT/metagpt/utils/common.py\", line 692, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"/mnt/ForAI/workspaces/MetaGPT/metagpt/roles/role.py\", line 548, in run\n    rsp = await self.react()\n  File \"/mnt/ForAI/workspaces/MetaGPT/metagpt/roles/role.py\", line 515, in react\n    rsp = await self._react()\n  File \"/mnt/ForAI/workspaces/MetaGPT/metagpt/roles/di/role_zero.py\", line 354, in _react\n    rsp = await self._act()\n  File \"/mnt/ForAI/workspaces/MetaGPT/metagpt/roles/di/role_zero.py\", line 316, in _act\n    commands, ok, self.command_rsp = await self._parse_commands(self.command_rsp)\n  File \"/mnt/ForAI/workspaces/MetaGPT/metagpt/roles/di/role_zero.py\", line 483, in _parse_commands\n    command_flag = [command[\"command_name\"] not in self.exclusive_tool_commands for command in commands]\n  File \"/mnt/ForAI/workspaces/MetaGPT/metagpt/roles/di/role_zero.py\", line 483, in <listcomp>\n    command_flag = [command[\"command_name\"] not in self.exclusive_tool_commands for command in commands]\nKeyError: 'command_name'\n\n\n/home/xdien/.venv/lib/python3.10/site-packages/pydantic/_internal/_std_types_schema.py:319: UserWarning: Pydantic serializer warnings:\n  Expected `enum` but got `str` with value `'react'` - serialized value may not be as expected\n  return handler(v)\n/mnt/ForAI/workspaces/MetaGPT/metagpt/base/base_serialization.py:26: UserWarning: Pydantic serializer warnings:\n  Expected `enum` but got `str` with value `'react'` - serialized value may not be as expected\n  ret = default_serializer(self)\n```",
      "state": "closed",
      "author": "xdien",
      "author_type": "User",
      "created_at": "2025-03-22T05:07:28Z",
      "updated_at": "2025-06-03T00:36:29Z",
      "closed_at": "2025-06-03T00:36:26Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1783/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1783",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1783",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:52.043175",
      "comments": [
        {
          "author": "nileshkokane01",
          "body": "this error occurs for most of the examples. For instance : write_design.py , write_game_code.py etc.  Can anyone let us know the fix?",
          "created_at": "2025-04-19T11:38:44Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-20T00:35:57Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-06-03T00:36:26Z"
        }
      ]
    },
    {
      "issue_number": 1770,
      "title": "openai apié…ç½®-æç¤ºé”™è¯¯ï¼Œå·²ç»åœ¨é¡¹ç›®æ–‡ä»¶ä¸‹é…ç½®å¥½config2.yaml",
      "body": "è¯¦ç»†æ“ä½œä¸­çš„â€œåœ¨å½“å‰å·¥ä½œç›®å½•ä¸­åˆ›å»ºä¸€ä¸ªåä¸ºconfigçš„æ–‡ä»¶å¤¹â€ï¼Œ  å½“å‰å·¥ä½œç›®å½•æŒ‡çš„æ˜¯å“ªé‡Œï¼Œæœ‰æ²¡æœ‰è¯¦ç»†é…ç½®openai apiçš„æ­¥éª¤ï¼Ÿ",
      "state": "closed",
      "author": "hold-zt",
      "author_type": "User",
      "created_at": "2025-03-18T10:43:05Z",
      "updated_at": "2025-06-02T00:37:47Z",
      "closed_at": "2025-06-02T00:37:47Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1770/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1770",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1770",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:52.237503",
      "comments": [
        {
          "author": "xukaizhao",
          "body": "å¯ä»¥åœ¨ç»ˆç«¯è¾“å…¥ï¼šmetagpt --init-config \nä¼šè‡ªåŠ¨åˆ›å»ºconfig2.yamlï¼Œç„¶åä¼šæ˜¾ç¤ºè·¯å¾„ï¼Œæ¯”å¦‚æˆ‘çš„æ˜¯Configuration file initialized at C:\\Users\\THUNDEROBOT\\.metagpt\\config2.yaml\néœ€è¦åœ¨è¿™ä¸ªæ–‡ä»¶é‡Œæ”¹é…ç½®",
          "created_at": "2025-03-19T14:29:42Z"
        },
        {
          "author": "hold-zt",
          "body": "> å¯ä»¥åœ¨ç»ˆç«¯è¾“å…¥ï¼šmetagpt --init-config ä¼šè‡ªåŠ¨åˆ›å»ºconfig2.yamlï¼Œç„¶åä¼šæ˜¾ç¤ºè·¯å¾„ï¼Œæ¯”å¦‚æˆ‘çš„æ˜¯Configuration file initialized at C:\\Users\\THUNDEROBOT.metagpt\\config2.yaml éœ€è¦åœ¨è¿™ä¸ªæ–‡ä»¶é‡Œæ”¹é…ç½®\n\nå·²ç»åˆ›å»ºå¥½å¹¶é…ç½®å®Œæˆï¼Œè¿˜æ˜¯ç›¸åŒçš„æŠ¥é”™ã€‚\n2025-03-20 10:19:23.396 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode.",
          "created_at": "2025-03-20T02:23:25Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-19T00:37:36Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-06-02T00:37:46Z"
        }
      ]
    },
    {
      "issue_number": 1810,
      "title": "è¿è¡ŒæŠ¥é”™ validation errors for CompletionUsage",
      "body": "**Bug description**\næ— è®ºæ˜¯pipå®‰è£…metagptï¼Œè¿˜æ˜¯git cloneï¼Œå‡æŠ¥é”™å¦‚ä¸‹ 3 validation errors for CompletionUsageã€‚\næµ‹è¯•å¤šç»„ç”Ÿæˆï¼š metagpt \"write a snake game\"ã€metagpt \"Create a 2048 game\"ã€ metagpt \"write a cli blackjack game\" \n\n**Bug solved method**\næ— \n\n**Environment information**\n- LLM type and model name: \n-   api_type: 'openai' \n    model: 'gpt-4o' # gpt-3.5-turboç°è±¡åŒ\n    base_url: 'https://zzzzapi.com/v1' \n- System version: mac osx (15.3.2 (24D81))\n- Python version: 3.9.20\n- MetaGPT version or branch: main\n\n<!-- Dependent packagessï¼šthe packages version cause the bug(like `pydantic 1.10.8`), installation methodï¼ˆlike `pip install metagpt` or `pip install from source` or `run in docker`ï¼‰ -->\n\n- packages version:\n- installation method:  pip install metagptå’Œgit cloneç°è±¡ç›¸åŒ\n\n**Screenshots or logs**\n2025-04-14 10:40:01.384 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 78.980(s), this was the 6th time calling it. exp: 3 validation errors for CompletionUsage\ncompletion_tokens\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\nprompt_tokens\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\ntotal_tokens\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\n2025-04-14 10:40:01.385 | WARNING  | metagpt.utils.common:wrapper:649 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.\n2025-04-14 10:40:01.398 | ERROR    | metagpt.utils.common:wrapper:631 - Exception occurs, start to serialize the project, exp:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 50, in __call__\n    result = await fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/actions/action_node.py\", line 420, in _aask_v1\n    content = await self.llm.aask(prompt, system_msgs, images=images, timeout=timeout)\npydantic_core._pydantic_core.ValidationError: 3 validation errors for CompletionUsage\ncompletion_tokens\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\nprompt_tokens\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\ntotal_tokens\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/utils/common.py\", line 640, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/roles/role.py\", line 550, in run\n    rsp = await self.react()\ntenacity.RetryError: RetryError[<Future at 0x14591ddf0 state=finished raised ValidationError>]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/utils/common.py\", line 626, in wrapper\n    result = await func(self, *args, **kwargs)\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/team.py\", line 134, in run\n    await self.env.run()\nException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 50, in __call__\n    result = await fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/actions/action_node.py\", line 420, in _aask_v1\n    content = await self.llm.aask(prompt, system_msgs, images=images, timeout=timeout)\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/provider/base_llm.py\", line 150, in aask\n    rsp = await self.acompletion_text(message, stream=stream, timeout=self.get_timeout(timeout))\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\n    return await fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 47, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/__init__.py\", line 314, in iter\n    return fut.result()\n  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py\", line 439, in result\n    return self.__get_result()\n  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py\", line 391, in __get_result\n    raise self._exception\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 50, in __call__\n    result = await fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/provider/openai_api.py\", line 141, in acompletion_text\n    return await self._achat_completion_stream(messages, timeout=timeout)\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/provider/openai_api.py\", line 94, in _achat_completion_stream\n    usage = CompletionUsage(**chunk.usage)\n  File \"/usr/local/lib/python3.9/site-packages/pydantic/main.py\", line 171, in __init__\n    self.__pydantic_validator__.validate_python(data, self_instance=self)\npydantic_core._pydantic_core.ValidationError: 3 validation errors for CompletionUsage\ncompletion_tokens\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\nprompt_tokens\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\ntotal_tokens\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/utils/common.py\", line 640, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/roles/role.py\", line 550, in run\n    rsp = await self.react()\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/roles/role.py\", line 517, in react\n    rsp = await self._react()\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/roles/role.py\", line 463, in _react\n    rsp = await self._act()\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/roles/role.py\", line 392, in _act\n    response = await self.rc.todo.run(self.rc.history)\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/actions/write_prd.py\", line 87, in run\n    return await self._handle_new_requirement(req)\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/actions/write_prd.py\", line 108, in _handle_new_requirement\n    node = await WRITE_PRD_NODE.fill(context=context, llm=self.llm, exclude=exclude)  # schema=schema\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/actions/action_node.py\", line 505, in fill\n    return await self.simple_fill(schema=schema, mode=mode, images=images, timeout=timeout, exclude=exclude)\n  File \"/usr/local/lib/python3.9/site-packages/metagpt/actions/action_node.py\", line 457, in simple_fill\n    content, scontent = await self._aask_v1(\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\n    return await fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 47, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/__init__.py\", line 326, in iter\n    raise retry_exc from fut.exception()\ntenacity.RetryError: RetryError[<Future at 0x14591ddf0 state=finished raised ValidationError>]\n\n![Image](https://github.com/user-attachments/assets/c26a513e-2b42-433d-8aaf-8b3d71c08333)",
      "state": "closed",
      "author": "wang498505194",
      "author_type": "User",
      "created_at": "2025-04-14T02:50:23Z",
      "updated_at": "2025-06-02T00:37:46Z",
      "closed_at": "2025-06-02T00:37:46Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1810/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1810",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1810",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:52.429837",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-19T00:37:31Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-06-02T00:37:45Z"
        }
      ]
    },
    {
      "issue_number": 1789,
      "title": "agentå¹²åˆ°ä¸€åŠè‡ªå·±åœæ­¢äº†ï¼Œä¹Ÿæ²¡æœ‰ä»»ä½•æŠ¥é”™",
      "body": "![Image](https://github.com/user-attachments/assets/203664cc-5be6-4c9f-ae19-2d101fbea23d)\næˆ‘æµ‹è¯•äº†ä¸¤æ¬¡ï¼Œå®‰è£…æ–¹å¼ä¸ºpip install git+https://github.com/geekan/MetaGPT\næ¨¡å‹ä½¿ç”¨çš„æ˜¯deepseek-chatï¼Œä½™é¢å……è¶³\nå¯åŠ¨å‘½ä»¤ä¸ºmetagpt \"åˆ›å»ºä¸€ä¸ªè¯­éŸ³å…‹éš†çš„ç½‘ç«™ï¼Œè¦æ±‚é¡µé¢å¥½çœ‹ï¼Œæ¨¡å—æ¸…æ™°ï¼Œçœ‹ç€éå¸¸æœ‰é€¼æ ¼\"",
      "state": "closed",
      "author": "TheHonestBob",
      "author_type": "User",
      "created_at": "2025-03-27T09:03:42Z",
      "updated_at": "2025-05-31T00:34:24Z",
      "closed_at": "2025-05-31T00:34:24Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 10,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1789/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1789",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1789",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:52.608713",
      "comments": [
        {
          "author": "userInner",
          "body": "è¯·é—®ä½ æ˜¯å¦‚ä½•ä½¿ç”¨çš„ï¼Œæˆ‘ä½¿ç”¨pip install metaGPTï¼Œæ— æ³•ä½¿ç”¨deepseek",
          "created_at": "2025-03-30T08:16:21Z"
        },
        {
          "author": "TheHonestBob",
          "body": "> è¯·é—®ä½ æ˜¯å¦‚ä½•ä½¿ç”¨çš„ï¼Œæˆ‘ä½¿ç”¨pip install metaGPTï¼Œæ— æ³•ä½¿ç”¨deepseek\n\npip install git+https://github.com/geekan/MetaGPT  è¿™æ ·å®‰è£…1.0.0ç‰ˆæœ¬\n",
          "created_at": "2025-03-31T02:33:08Z"
        },
        {
          "author": "userInner",
          "body": "è°¢è°¢ï¼Œæˆ‘å°è¯•äº†è¿™ä¸ªï¼Œä½†æ˜¯å‘ç°æ€»æ˜¯åœç•™åœ¨alexå®ç°ä»£ç è¿™ä¸€æ­¥å°±ä¸å†æ‰§è¡Œäº†\r\n\r\n\r\n\r\n---åŸå§‹é‚®ä»¶---\r\nå‘ä»¶äºº: ***@***.***&gt;\r\nå‘é€æ—¶é—´: 2025å¹´3æœˆ31æ—¥(å‘¨ä¸€) ä¸Šåˆ10:33\r\næ”¶ä»¶äºº: ***@***.***&gt;;\r\næŠ„é€: ***@***.******@***.***&gt;;\r\nä¸»é¢˜: Re: [geekan/MetaGPT] agentå¹²åˆ°ä¸€åŠè‡ªå·±åœæ­¢äº†ï¼Œä¹Ÿæ²¡æœ‰ä»»ä½•æŠ¥é”™ (Issue #1789)\r\n\r\n\r\n    \r\nè¯·é—®ä½ æ˜¯å¦‚ä½•ä½¿ç”¨çš„ï¼Œæˆ‘ä½¿ç”¨pip install metaGPTï¼Œæ— æ³•ä½¿ç”¨deepseek\r\n  \r\npip install ",
          "created_at": "2025-03-31T02:37:28Z"
        },
        {
          "author": "TheHonestBob",
          "body": "> è°¢è°¢ï¼Œæˆ‘å°è¯•äº†è¿™ä¸ªï¼Œä½†æ˜¯å‘ç°æ€»æ˜¯åœç•™åœ¨alexå®ç°ä»£ç è¿™ä¸€æ­¥å°±ä¸å†æ‰§è¡Œäº†\n> [â€¦](#)\n\næ˜¯çš„ï¼Œè¿™ä¸ªé—®é¢˜ä¸ä»…ä»…åœ¨1.0.0ç‰ˆæœ¬ï¼Œæ˜¯ç”Ÿæˆä»»åŠ¡æµç¨‹é‚£æ­¥å°±å‡ºé”™äº†ï¼Œå¯¼è‡´ä»»åŠ¡æå‰ç»“æŸï¼Œæˆ‘è¯•äº†openaiçš„æ¨¡å‹ï¼Œä¸€æ ·å„ç§é—®é¢˜ï¼ŒæˆåŠŸç‡ç›¸å½“ä½ï¼Œæˆ‘å·²æ”¾å¼ƒè¿™ä¸ªé¡¹ç›®ï¼Œå°è¯•ä½¿ç”¨å…¶ä»–æ­å»ºagentæ–¹ä¾¿çš„æ¡†æ¶ï¼Œä½ çš„æµ‹è¯•æ•ˆæœå’‹æ ·",
          "created_at": "2025-03-31T02:40:37Z"
        },
        {
          "author": "userInner",
          "body": "ä»–åœ¨æ„å»ºblackjack gameï¼ŒæˆåŠŸæ„å»ºå‡ºäº†ä»£ç ï¼Œä½†æ˜¯æˆ‘è®©ä»–ç¼–å†™å…¶ä»–å·¥ç¨‹ï¼Œä¾‹å¦‚ç®¡ç†ç³»ç»Ÿ | ç½‘é¡µå¼€å‘ï¼Œéƒ½å§‹ç»ˆåœåœ¨alexè¿™ä¸€æ­¥\r\n\r\n\r\n\r\n---åŸå§‹é‚®ä»¶---\r\nå‘ä»¶äºº: ***@***.***&gt;\r\nå‘é€æ—¶é—´: 2025å¹´3æœˆ31æ—¥(å‘¨ä¸€) ä¸Šåˆ10:41\r\næ”¶ä»¶äºº: ***@***.***&gt;;\r\næŠ„é€: ***@***.******@***.***&gt;;\r\nä¸»é¢˜: Re: [geekan/MetaGPT] agentå¹²åˆ°ä¸€åŠè‡ªå·±åœæ­¢äº†ï¼Œä¹Ÿæ²¡æœ‰ä»»ä½•æŠ¥é”™ (Issue #1789)\r\n\r\n\r\n    \r\nè°¢è°¢ï¼Œæˆ‘å°è¯•äº†è¿™ä¸ªï¼Œä½†æ˜¯å‘ç°æ€»æ˜¯åœç•™åœ¨alexå®ç°ä»£ç è¿™ä¸€æ­¥å°±ä¸å†",
          "created_at": "2025-03-31T02:59:43Z"
        }
      ]
    },
    {
      "issue_number": 1806,
      "title": "å¸Œæœ›æä¾›ä¸€ä¸ªå®Œæ•´ä¸€ç‚¹çš„â€œä¸ºè§’è‰²æˆ–åŠ¨ä½œé…ç½®ä¸åŒLLMâ€ ç¤ºä¾‹",
      "body": "å¸Œæœ›æä¾›ä¸€ä¸ªå®Œæ•´ä¸€ç‚¹çš„â€œä¸ºè§’è‰²æˆ–åŠ¨ä½œé…ç½®ä¸åŒLLMâ€\n\næˆ‘æŒ‰ç…§å®˜æ–¹çš„æ–‡æ¡£æ¥ä¸èƒ½å®ç°è¿™ä¸ª åŠŸèƒ½",
      "state": "closed",
      "author": "Minhat-GitHub",
      "author_type": "User",
      "created_at": "2025-04-10T04:02:05Z",
      "updated_at": "2025-05-29T00:35:22Z",
      "closed_at": "2025-05-29T00:35:22Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 13,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1806/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1806",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1806",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:52.827454",
      "comments": [
        {
          "author": "lwjin-1112",
          "body": "æˆ‘è¿™é‡Œæ˜¯ä¸ºactioné…ç½®ä¸åŒLLM\n![Image](https://github.com/user-attachments/assets/cfdf6677-9731-4570-b576-565822544d4f)",
          "created_at": "2025-04-11T04:44:05Z"
        },
        {
          "author": "Minhat-GitHub",
          "body": "> æˆ‘è¿™é‡Œæ˜¯ä¸ºactioné…ç½®ä¸åŒLLM ![Image](https://github.com/user-attachments/assets/cfdf6677-9731-4570-b576-565822544d4f)\n\nè¿˜æ˜¯çœ‹ä¸æ‡‚å•Š",
          "created_at": "2025-04-11T05:51:40Z"
        },
        {
          "author": "lwjin-1112",
          "body": "> > æˆ‘è¿™é‡Œæ˜¯ä¸ºactioné…ç½®ä¸åŒLLM![Image](https://github.com/user-attachments/assets/cfdf6677-9731-4570-b576-565822544d4f)\n> \n> è¿˜æ˜¯çœ‹ä¸æ‡‚å•Š\n\né¦–å…ˆå¯¼å…¥æ¨¡å—è¯»å–é»˜è®¤çš„é…ç½®\nfrom metagpt.config2 import Config\nç„¶åä¿®æ”¹modelçš„å€¼ï¼Œåœ¨ä¸ºactionç±»é…ç½®æ—¶ï¼Œå› ä¸ºæ˜¯åœ¨roleä¸­æ·»åŠ åŠ¨ä½œï¼Œæ·»åŠ æ—¶æŒ‡å®šconfigå³å¯ï¼ˆç¬¬ä¸€ä¸ªæ¡†é‚£æ ·ï¼‰ï¼›è‹¥æ˜¯ä¸ºroleé…ç½®æ—¶ï¼Œåœ¨envæ·»åŠ roleæ—¶ï¼ŒæŒ‡å®šconfigå³å¯ï¼ˆåƒç¬¬ä¸€ä¸ªæ¡†ï¼‰ï¼Œç®€è€Œè¨€ä¹‹ï¼Œåœ¨å“ªé‡Œæ·»åŠ actionæˆ–roleï¼Œå°±åœ¨",
          "created_at": "2025-04-11T06:21:15Z"
        },
        {
          "author": "Minhat-GitHub",
          "body": "> > > æˆ‘è¿™é‡Œæ˜¯ä¸ºactioné…ç½®ä¸åŒLLM![Image](https://github.com/user-attachments/assets/cfdf6677-9731-4570-b576-565822544d4f)\n> > \n> > \n> > è¿˜æ˜¯çœ‹ä¸æ‡‚å•Š\n> \n> é¦–å…ˆå¯¼å…¥æ¨¡å—è¯»å–é»˜è®¤çš„é…ç½® from metagpt.config2 import Config ç„¶åä¿®æ”¹modelçš„å€¼ï¼Œåœ¨ä¸ºactionç±»é…ç½®æ—¶ï¼Œå› ä¸ºæ˜¯åœ¨roleä¸­æ·»åŠ åŠ¨ä½œï¼Œæ·»åŠ æ—¶æŒ‡å®šconfigå³å¯ï¼ˆç¬¬ä¸€ä¸ªæ¡†é‚£æ ·ï¼‰ï¼›è‹¥æ˜¯ä¸ºroleé…ç½®æ—¶ï¼Œåœ¨envæ·»åŠ roleæ—¶ï¼ŒæŒ‡å®šconfigå³å¯ï¼ˆåƒç¬¬ä¸€ä¸ªæ¡†ï¼‰ï¼Œç®€è€Œè¨€ä¹‹ï¼Œåœ¨å“ªé‡Œæ·»",
          "created_at": "2025-04-11T06:34:29Z"
        },
        {
          "author": "lwjin-1112",
          "body": "> > > > æˆ‘è¿™é‡Œæ˜¯ä¸ºactioné…ç½®ä¸åŒLLM![Image](https://github.com/user-attachments/assets/cfdf6677-9731-4570-b576-565822544d4f)\n> > > \n> > > \n> > > è¿˜æ˜¯çœ‹ä¸æ‡‚å•Š\n> > \n> > \n> > é¦–å…ˆå¯¼å…¥æ¨¡å—è¯»å–é»˜è®¤çš„é…ç½® from metagpt.config2 import Config ç„¶åä¿®æ”¹modelçš„å€¼ï¼Œåœ¨ä¸ºactionç±»é…ç½®æ—¶ï¼Œå› ä¸ºæ˜¯åœ¨roleä¸­æ·»åŠ åŠ¨ä½œï¼Œæ·»åŠ æ—¶æŒ‡å®šconfigå³å¯ï¼ˆç¬¬ä¸€ä¸ªæ¡†é‚£æ ·ï¼‰ï¼›è‹¥æ˜¯ä¸ºroleé…ç½®æ—¶ï¼Œåœ¨envæ·»åŠ roleæ—¶ï¼ŒæŒ‡å®šconfigå³å¯",
          "created_at": "2025-04-11T07:04:54Z"
        }
      ]
    },
    {
      "issue_number": 1809,
      "title": "å¦‚ä½•è·å–MetaGPTè¿è¡Œæ—¶æ‰€æœ‰roleæŒ‰ç…§é¡ºåºå¯¹è¯çš„è½¨è¿¹ï¼ˆtrajectoryï¼‰? åŒæ—¶æ˜¯å¦æœ‰åŠŸèƒ½å¯ä»¥è‡ªå®šä¹‰ä»“åº“è·¯å¾„ï¼Ÿ",
      "body": "**Feature description**\n<!-- Clear and direct description of the functionality of the currently submitted or proposed feature -->\nFeature 1\næˆ‘æƒ³å°è¯•å°†æ‰€æœ‰roleä¹‹é—´çš„å¯¹è¯ï¼Œä¿å­˜ä¸ºjsonæ–‡ä»¶ï¼Œå¯ä»¥ä¾¿äºå¤„ç†textç±»å‹çš„ç»“æœï¼Œä¾¿äºåˆ†æï¼Œç›®å‰çš„åŠŸèƒ½å¥½åƒæ— æ³•åšåˆ°ï¼Ÿ\nFeature 2\nåŒæ—¶ï¼Œæˆ‘æƒ³è‡ªå®šä¹‰ä¸€ä¸ªproject pathï¼Œæˆ‘å°è¯•ä½¿ç”¨--project-nameä¸--project-path,éƒ½ä¸å¥æ•ˆã€‚\n\n**Your Feature**\n<!-- Describe the idea or process of implementing the current feature. Of course, you can also paste the URL address of your Pull Request. -->\n<!-- When submitting features, you need to complete the corresponding doc/tests/examples to facilitate verification by reviewers. -->\næˆ‘ç›®å‰çš„æ€è·¯æ˜¯åœ¨æ¯ä¸€ä¸ªroleé‚£è¾¹é…ç½®ä¸€ä¸ªå…¨å±€å˜é‡ï¼Œä¿å­˜msgä¿¡æ¯ï¼Œä½†æ˜¯ç”±äºä»£ç èƒ½åŠ›æ¯”è¾ƒå¼±ï¼Œmetagptå°è£…å®Œå–„ï¼Œæœ‰ç‚¹éš¾ä»¥æ“ä½œï¼Œæ²¡æœ‰æ”¹å¯¹ã€‚",
      "state": "closed",
      "author": "YuanDaoze",
      "author_type": "User",
      "created_at": "2025-04-12T12:35:03Z",
      "updated_at": "2025-05-28T00:35:21Z",
      "closed_at": "2025-05-28T00:35:20Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1809/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1809",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1809",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:53.056677",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-13T00:35:08Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-28T00:35:19Z"
        }
      ]
    },
    {
      "issue_number": 1807,
      "title": "Is there any plan for MetaGPT to support the MCP tool?",
      "body": "**Feature description**\nAs MCP becomes an industry trend, does MetaGPT have any plans to support the integration of a wide variety of MCP tools?\n",
      "state": "closed",
      "author": "zhouxiao999",
      "author_type": "User",
      "created_at": "2025-04-11T00:44:47Z",
      "updated_at": "2025-05-27T00:34:38Z",
      "closed_at": "2025-05-27T00:34:37Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1807/reactions",
        "total_count": 2,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 2,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1807",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1807",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:53.282704",
      "comments": [
        {
          "author": "lwjin-1112",
          "body": "éƒ½å¿«æœ‰1å¹´æ²¡æ›´æ–°è¿­ä»£äº†ï¼Œå¯èƒ½éœ€è¦è‡ªå·±å¼€å‘äº†",
          "created_at": "2025-04-11T04:41:49Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-12T00:37:13Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-27T00:34:37Z"
        }
      ]
    },
    {
      "issue_number": 1705,
      "title": "How to configure colab to use Azure OpenAI API",
      "body": "I am trying to run the [colab](https://colab.research.google.com/drive/1xlReN7EIpKzgZO1If29-zsw7QNUUfEbx?usp=sharing) found on the documentation. \nHow to set the env variables to use Azure OpenAI API?\nI can't find  the \n\n> ~/.metagpt/config2.yaml\n\n to update with Azure OpenAI API env variables.",
      "state": "closed",
      "author": "quartermaine",
      "author_type": "User",
      "created_at": "2025-02-20T08:27:59Z",
      "updated_at": "2025-05-26T05:55:44Z",
      "closed_at": "2025-05-26T05:55:44Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1705/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1705",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1705",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:53.528271",
      "comments": [
        {
          "author": "seehi",
          "body": "å¯å‚è€ƒï¼š#1690 ",
          "created_at": "2025-02-20T08:35:00Z"
        },
        {
          "author": "quartermaine",
          "body": "Hello @seehi, \n\nThanks for the quick response. I used the following to set the env variables \n\n```\nmetagpt.const.API_KEY = userdata.get('OPENAI_API_KEY')\nmetagpt.const.MODEL = userdata.get('MODEL_NAME')\nmetagpt.const.API_TYPE = userdata.get('OPENAI_API_TYPE')\nmetagpt.const.API_VERSION = userdata.get",
          "created_at": "2025-02-20T08:53:10Z"
        },
        {
          "author": "seehi",
          "body": "Such as:\n```\nfrom pathlib import Path\n\nimport metagpt.const\n\n# 1. Change CONFIG_ROOT\nmetagpt.const.CONFIG_ROOT = Path.cwd()\n\n# 2. Create config2.yaml\ncontent = '''llm:\n  api_type: \"openai\"  # or azure / ollama / open_llm etc. Check LLMType for more options\n  model: \"gpt-4-turbo-preview\"  # or gpt-3.",
          "created_at": "2025-02-20T09:17:36Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-23T00:35:22Z"
        },
        {
          "author": "quartermaine",
          "body": "I will check the proposed solution and let you know.\n\nThanks",
          "created_at": "2025-03-28T07:41:37Z"
        }
      ]
    },
    {
      "issue_number": 1677,
      "title": "ERROR: Failed building wheel for volcengine-python-sdk   Running setup.py clean for volcengine-python-sdk Failed to build volcengine-python-sdk ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects",
      "body": "      copying volcenginesdktransitrouter\\models\\transit_router_forward_policy_entry_for_describe_transit_router_forward_policy_entries_output.py -> build\\lib\\volcenginesdktransitrouter\\models\n      copying volcenginesdktransitrouter\\models\\transit_router_forward_policy_table_for_describe_transit_router_forward_policy_tables_output.py -> build\\lib\\volcenginesdktransitrouter\\models\n      copying volcenginesdktransitrouter\\models\\transit_router_for_describe_transit_routers_output.py -> build\\lib\\volcenginesdktransitrouter\\models\n      copying volcenginesdktransitrouter\\models\\transit_router_grant_rule_for_describe_transit_router_grant_rules_output.py -> build\\lib\\volcenginesdktransitrouter\\models\n      copying volcenginesdktransitrouter\\models\\transit_router_route_entry_for_describe_transit_router_route_entries_output.py -> build\\lib\\volcenginesdktransitrouter\\models\n      copying volcenginesdktransitrouter\\models\\transit_router_route_policy_entry_for_describe_transit_router_route_policy_entries_output.py -> build\\lib\\volcenginesdktransitrouter\\models\n      copying volcenginesdktransitrouter\\models\\transit_router_route_policy_table_for_describe_transit_router_route_policy_tables_output.py -> build\\lib\\volcenginesdktransitrouter\\models\n      copying volcenginesdktransitrouter\\models\\transit_router_route_table_association_for_describe_transit_router_route_table_associations_output.py -> build\\lib\\volcenginesdktransitrouter\\models\n      copying volcenginesdktransitrouter\\models\\transit_router_route_table_for_describe_transit_router_route_tables_output.py -> build\\lib\\volcenginesdktransitrouter\\models\n      copying volcenginesdktransitrouter\\models\\transit_router_route_table_propagation_for_describe_transit_router_route_table_propagations_output.py -> build\\lib\\volcenginesdktransitrouter\\models\n      copying volcenginesdktransitrouter\\models\\transit_router_traffic_qos_marking_entry_for_describe_transit_router_traffic_qos_marking_entries_output.py -> build\\lib\\volcenginesdktransitrouter\\models\n      error: could not create 'build\\lib\\volcenginesdktransitrouter\\models\\transit_router_traffic_qos_marking_entry_for_describe_transit_router_traffic_qos_marking_entries_output.py': No such file or directory\n      [end of output]\n\n  note: This error originates from a subprocess, and is likely not a problem with pip.\n  ERROR: Failed building wheel for volcengine-python-sdk\n  Running setup.py clean for volcengine-python-sdk\nFailed to build volcengine-python-sdk\nERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (volcengine-python-sdk)",
      "state": "closed",
      "author": "gokulcoder7",
      "author_type": "User",
      "created_at": "2025-01-22T16:00:12Z",
      "updated_at": "2025-05-24T00:33:47Z",
      "closed_at": "2025-05-24T00:33:47Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1677/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1677",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1677",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:53.740861",
      "comments": [
        {
          "author": "iorisa",
          "body": "**1. Check Python Version**\n\nEnsure that the Python version you are using is compatible with `volcengine-python-sdk`. According to the official documentation, Python 3.7 or higher is recommended. If you are using a higher version (e.g., Python 3.11), there might be compatibility issues. You can try ",
          "created_at": "2025-01-23T02:39:12Z"
        },
        {
          "author": "chen2438",
          "body": "+1\n\nI use macOS 15.4\n\n```bash\nCollecting volcengine-python-sdk~=1.0.94 (from volcengine-python-sdk[ark]~=1.0.94->-r requirements.txt (line 78))\n  Downloading volcengine-python-sdk-1.0.123.tar.gz (3.2 MB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.2/3.2 MB 5.7 MB/s eta 0:00:00\n  Preparing metadata (setu",
          "created_at": "2025-02-12T08:33:54Z"
        },
        {
          "author": "chen2438",
          "body": "> +1\n> \n> Collecting volcengine-python-sdk~=1.0.94 (from volcengine-python-sdk[ark]~=1.0.94->-r requirements.txt (line 78))\n>   Downloading volcengine-python-sdk-1.0.123.tar.gz (3.2 MB)\n>      â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.2/3.2 MB 5.7 MB/s eta 0:00:00\n>   Preparing metadata (setup.py) ... erro",
          "created_at": "2025-02-12T08:49:54Z"
        },
        {
          "author": "Miiiikasa",
          "body": "take a look at this: https://blog.csdn.net/steamedobun/article/details/142848303?ops_request_misc=%257B%2522request%255Fid%2522%253A%252219acde4f6ba6277a6c10be80ea91ed17%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=19acde4f6ba6277a6c10be80ea91ed17&biz_id=0&utm_medium=dis",
          "created_at": "2025-03-09T08:41:54Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-11T00:33:35Z"
        }
      ]
    },
    {
      "issue_number": 1682,
      "title": "openai new models dont work",
      "body": "The new models give max_temperature unknown error and cannot be used.",
      "state": "closed",
      "author": "cranyy",
      "author_type": "User",
      "created_at": "2025-02-03T00:17:40Z",
      "updated_at": "2025-05-24T00:33:46Z",
      "closed_at": "2025-05-24T00:33:45Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1682/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1682",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1682",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:53.938827",
      "comments": [
        {
          "author": "seehi",
          "body": "temperature?",
          "created_at": "2025-02-12T09:08:18Z"
        },
        {
          "author": "cranyy",
          "body": "my bad, i meant tokens --            ^^^^^^^^^^^^^^^^^^^^\n ```\n File \"E:\\MetaStocky\\env\\Lib\\site-packages\\openai\\_base_client.py\", line 1625, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Unsupport",
          "created_at": "2025-02-12T14:20:51Z"
        },
        {
          "author": "seehi",
          "body": "https://github.com/geekan/MetaGPT/pull/1710",
          "created_at": "2025-02-25T08:00:07Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-01T00:38:08Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-24T00:33:45Z"
        }
      ]
    },
    {
      "issue_number": 1734,
      "title": "FileNotFoundError: [Errno 2] No such file or directory: 'my_env/bin/Activate.ps1'",
      "body": "/mnt/d/.github/MetaGPT/my_env/bin/Activate.ps1\nin my root this file already here\n\n2025-03-03 15:50:01.275 | ERROR    | metagpt.utils.common:wrapper:631 - Exception occurs, start to serialize the project, exp:\nTraceback (most recent call last):\n  File \"/mnt/d/.github/MetaGPT/my_env/lib/python3.9/site-packages/metagpt/utils/common.py\", line 626, in wrapper\n    result = await func(self, *args, **kwargs)\n  File \"/mnt/d/.github/MetaGPT/my_env/lib/python3.9/site-packages/metagpt/team.py\", line 135, in run\n    self.env.archive(auto_archive)\nFileNotFoundError: [Errno 2] No such file or directory: 'my_env/bin/Activate.ps1'",
      "state": "closed",
      "author": "yuuuuuuan",
      "author_type": "User",
      "created_at": "2025-03-03T08:04:27Z",
      "updated_at": "2025-05-22T00:34:56Z",
      "closed_at": "2025-05-22T00:34:56Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1734/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1734",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1734",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:54.166912",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-03T00:32:40Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-22T00:34:55Z"
        }
      ]
    },
    {
      "issue_number": 1738,
      "title": "metagpt/provider/openai_api.py 94è¡Œå­˜åœ¨bug",
      "body": "```\nif hasattr(chunk, \"usage\"):\n# Some services have usage as an attribute of the chunk, such as Fireworks\n    usage = CompletionUsage(**chunk.usage)\nusageä¼šå‡ºç°Noneçš„æƒ…å†µ\næœ€å¥½åŠ ä¸Š\nif chunk.usage:\n   usage = CompletionUsage(**chunk.usage)\n\n```\n\næ—¥å¿—\nChatCompletionChunk(id='chatcmpl-B7OpXSFxuj3RCEYCnFslLUchlZDiJ', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=None), finish_reason='stop', index=0, logprobs=None)], created=1741103443, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None)\n",
      "state": "closed",
      "author": "moseshu",
      "author_type": "User",
      "created_at": "2025-03-04T15:50:06Z",
      "updated_at": "2025-05-22T00:34:55Z",
      "closed_at": "2025-05-22T00:34:55Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1738/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1738",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1738",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:54.395740",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-04T00:32:42Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-22T00:34:54Z"
        }
      ]
    },
    {
      "issue_number": 1739,
      "title": "è®¡ç®—tokensçš„è´¹ç”¨çš„æ—¶å€™å­˜åœ¨bug",
      "body": "```python\n_calc_usage åœ¨è®¡ç®—ä¸åŒçš„gptçš„ä»·æ ¼çš„æ—¶å€™æ˜ å°„ä¸€ä¸‹ï¼Œgpt-4oæœ‰å¾ˆå¤šç‰ˆæœ¬ï¼Œä»·æ ¼éƒ½æ˜¯æŒ‰ç…§gpt-4oç®—çš„ï¼Œä¸ç„¶æ— æ³•æ‰¾åˆ°å…·ä½“çš„4o ç‰ˆæœ¬\n\n\n metagpt.provider.openai_api:_calc_usage:246 - usage calculation failed: num_tokens_from_messages() is not implemented for model chatgpt-4o-latest. See https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken for information on how messages are converted to tokens.\n 15\n```",
      "state": "closed",
      "author": "moseshu",
      "author_type": "User",
      "created_at": "2025-03-05T01:49:11Z",
      "updated_at": "2025-05-21T00:35:42Z",
      "closed_at": "2025-05-21T00:35:42Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1739/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1739",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1739",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:54.704104",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-05T00:32:14Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-21T00:35:41Z"
        }
      ]
    },
    {
      "issue_number": 1769,
      "title": "Several issues persist - prevents using metagpt for anything serious.",
      "body": "After extensive testing running metagpt for ~100 hours using openrouter:anthropic/claude-3.7-sonnet:thinking, I've concluded the following:\n\n1. json parsing fails when documents/code grow larger than it can handle.  Sometimes I was successful in instructing it to work in smaller chunks and it would actually do it, however, most times it would not and continue to fail and exit/crashes.  \n2. Context limit being exceeded and it does not appear that the \"middle-out\" / compression features of openrouter are implemented to prevent this.\n3. No easily observable way to just resume when it crashes. Instead, it will try sometimes and rebuild the docs it has already built, even when I specify that the docs are there for it to review.   \n4. Token usage is very high per api requests making using metagpt for any sizable project not optimal. \n\nThe project shows promise, but there are many other projects that seem to have managed to address these simple issues well.  It appears that the activity around this project is limited and reduced as compared to the past.  Are there any plans to get things up to speed?  Do you need help?",
      "state": "closed",
      "author": "myevolve",
      "author_type": "User",
      "created_at": "2025-03-17T20:45:24Z",
      "updated_at": "2025-05-21T00:35:40Z",
      "closed_at": "2025-05-21T00:35:39Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1769/reactions",
        "total_count": 3,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 1
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1769",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1769",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:54.884694",
      "comments": [
        {
          "author": "ODAncona",
          "body": "> there are many other projects that seem to have managed to address these simple issues well \n\nSuch as ?",
          "created_at": "2025-03-19T02:00:51Z"
        },
        {
          "author": "myevolve",
          "body": "I have been working extensively with both open source and closed source projects:\n\nCLI/Web: aider, openhands (similar to devin) -- This project has come a long way and does a pretty good job.\n\nIDE: Roo Code, Cline, Windsurf, Cursor  -- My testing for these has been mainly around configuring autonomo",
          "created_at": "2025-03-21T08:03:45Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-07T00:34:50Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-21T00:35:39Z"
        }
      ]
    },
    {
      "issue_number": 1744,
      "title": "æœ¬åœ°éƒ¨ç½²å¦‚ä½•é…ç½®åœ¨ç»ˆç«¯å’Œæµè§ˆå™¨ä¸­è¿›è¡Œç”Ÿæˆä»£ç çš„æµ‹è¯•",
      "body": "å¦‚ä½•åƒmgx.devä¸­åœ¨Terminalä¸­è¿›è¡Œæµ‹è¯•ä»¥åŠä¼šè‡ªåŠ¨éƒ¨ç½²webæœåŠ¡åœ¨æµè§ˆå™¨ä¸­çœ‹åˆ°å®æ—¶æ•ˆæœ",
      "state": "closed",
      "author": "yuuuuuuan",
      "author_type": "User",
      "created_at": "2025-03-07T06:17:26Z",
      "updated_at": "2025-05-20T00:36:03Z",
      "closed_at": "2025-05-20T00:36:02Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1744/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1744",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1744",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:55.085257",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-07T00:34:30Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-20T00:36:02Z"
        }
      ]
    },
    {
      "issue_number": 1745,
      "title": "FileNotFoundError with Log file",
      "body": "**Bug description**\n<!-- Clearly and directly describe the current bug -->\n\nWhen trying to create any application, such as the 2048 game, I encounter this exception:\n\n![Image](https://github.com/user-attachments/assets/feaf91ad-dfef-459f-ac2f-d339d7833017)\n\n```\n2025-03-07 22:00:05.878 | ERROR    | metagpt.utils.common:wrapper:631 - Exception occurs, start to serialize the project, exp:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/site-packages/metagpt/utils/common.py\", line 626, in wrapper\n    result = await func(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/site-packages/metagpt/team.py\", line 135, in run\n    self.env.archive(auto_archive)\nFileNotFoundError: [Errno 2] No such file or directory: 'logs/20250307.txt'\n```\n\nThis is running inside a Docker container \n```bash\npython --version\nPython 3.11.11\n```\n\n**Bug solved method**\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\n\n**Environment information**\n<!-- Environmentï¼šSystem version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\n\n- LLM type and model name: Claude\n- System version: `Docker: python:3.11.11-bullseye`\n- Python version: `3.11.11`\n- MetaGPT version or branch: Whatever comes with `pip install --upgrade metagpt`\n\n<!-- Dependent packagessï¼šthe packages version cause the bug(like `pydantic 1.10.8`), installation methodï¼ˆlike `pip install metagpt` or `pip install from source` or `run in docker`ï¼‰ -->\n\n- packages version:\n- installation method: \n\n**Screenshots or logs**\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\nThe `logs` folder, as well as the logfile itself do exist:\n![Image](https://github.com/user-attachments/assets/89826544-b5cd-47d6-8b0d-f539110efb77)\n\n<details><summary>Logs preceeding the exception</summary>\n\n```\n2025-03-07 22:00:05.149 | DEBUG    | metagpt.roles.role:run:547 - Bob(Architect): no news. waiting.\n2025-03-07 22:00:05.150 | DEBUG    | metagpt.roles.role:run:547 - Eve(Project Manager): no news. waiting.\n2025-03-07 22:00:05.150 | DEBUG    | metagpt.roles.role:run:547 - Alex(Engineer): no news. waiting.\n2025-03-07 22:00:05.150 | DEBUG    | metagpt.environment.base_env:run:168 - is idle: True\n2025-03-07 22:00:05.515 | INFO     | metagpt.utils.git_repository:archive:168 - Archive: ['logs/20250307.txt', 'metagpt/tools/schemas/CatCount.yml', 'metagpt/tools/schemas/CatCross.yml', 'metagpt/tools/schemas/FillMissingValue.yml', 'metagpt/tools/schemas/GPTvGenerator.yml', 'metagpt/tools/schemas/GeneralSelection.yml', 'metagpt/tools/schemas/GroupStat.yml', 'metagpt/tools/schemas/KFoldTargetMeanEncoder.yml', 'metagpt/tools/schemas/LabelEncode.yml', 'metagpt/tools/schemas/MaxAbsScale.yml', 'metagpt/tools/schemas/MinMaxScale.yml', 'metagpt/tools/schemas/OneHotEncode.yml', 'metagpt/tools/schemas/OrdinalEncode.yml', 'metagpt/tools/schemas/PolynomialExpansion.yml', 'metagpt/tools/schemas/RobustScale.yml', 'metagpt/tools/schemas/SDEngine.yml', 'metagpt/tools/schemas/SplitBins.yml', 'metagpt/tools/schemas/StandardScale.yml', 'metagpt/tools/schemas/TargetMeanEncoder.yml', 'metagpt/tools/schemas/VarianceBasedSelection.yml', 'metagpt/tools/schemas/email_login_imap.yml', 'metagpt/tools/schemas/scrape_web_playwright.yml', 'prompt.md', 'workspace/20250307215742/docs/prd/20250307215811.json', 'workspace/20250307215742/resources/competitive_analysis/20250307215811.mmd', 'workspace/20250307215742/resources/prd/20250307215811.md', 'workspace/20250307215930/docs/prd/20250307220002.json', 'workspace/20250307215930/resources/competitive_analysis/20250307220002.mmd', 'workspace/20250307215930/resources/prd/20250307220002.md', 'workspace/ecs_jira_integration/', 'workspace/jira_ecs_api/docs/prd/20250307220002.json', 'workspace/jira_ecs_api/resources/competitive_analysis/20250307220002.mmd', 'workspace/jira_ecs_api/resources/prd/20250307220002.md', 'workspace/storage/team/team.json']\n2025-03-07 22:00:05.878 | ERROR    | metagpt.utils.common:wrapper:631 - Exception occurs, start to serialize the project, exp:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/site-packages/metagpt/utils/common.py\", line 626, in wrapper\n    result = await func(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/site-packages/metagpt/team.py\", line 135, in run\n    self.env.archive(auto_archive)\nFileNotFoundError: [Errno 2] No such file or directory: 'logs/20250307.txt'\n```\n</details> ",
      "state": "closed",
      "author": "shmolf",
      "author_type": "User",
      "created_at": "2025-03-07T22:28:19Z",
      "updated_at": "2025-05-20T00:36:02Z",
      "closed_at": "2025-05-20T00:36:01Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1745/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1745",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1745",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:55.286853",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-07T00:34:29Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-20T00:36:01Z"
        }
      ]
    },
    {
      "issue_number": 1747,
      "title": "metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 18.375(s), this was the 5th time calling it. exp: 'async for' requires an object with __aiter__ method, got bytes",
      "body": "2025-03-09 15:35:23.233 | INFO     | metagpt.const:get_metagpt_package_root:29 - Package root set to D:\\work\\AI\\MetaGPT\n2025-03-09 15:35:26.399 | INFO     | metagpt.team:invest:90 - Investment: $3.0.\n2025-03-09 15:35:26.402 | INFO     | metagpt.roles.role:_act:391 - Alice(Product Manager): to do PrepareDocuments(PrepareDocuments)\n2025-03-09 15:35:26.660 | INFO     | metagpt.utils.file_repository:save:57 - save to: D:\\work\\AI\\MetaGPT\\workspace\\20250309153526\\docs\\requirement.txt\n2025-03-09 15:35:26.662 | INFO     | metagpt.roles.role:_act:391 - Alice(Product Manager): to do WritePRD(WritePRD)\n2025-03-09 15:35:26.664 | INFO     | metagpt.actions.write_prd:run:86 - New requirement detected: Create a 2048 game\n2025-03-09 15:35:28.723 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 2.063(s), this was the 1st time calling it. exp: 'async for' requires an object with __aiter__ method, got bytes2025-03-09 15:35:30.981 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 4.313(s), this was the 2nd time calling it. exp: 'async for' requires an object with __aiter__ method, got bytes2025-03-09 15:35:34.583 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 7.922(s), this was the 3rd time calling it. exp: 'async for' requires an object with __aiter__ method, got bytes2025-03-09 15:35:37.469 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 10.797(s), this was the 4th time calling it. exp: 'async for' requires an object with __aiter__ method, got bytes\n2025-03-09 15:35:45.041 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 18.375(s), this was the 5th time calling it. exp: 'async for' requires an object with __aiter__ method, got bytes\n2025-03-09 15:35:51.742 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 25.078(s), this was the 6th time calling it. exp: 'async for' requires an object with __aiter__ method, got bytes\n2025-03-09 15:35:51.743 | WARNING  | metagpt.utils.common:wrapper:649 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.\n2025-03-09 15:35:51.746 | ERROR    | metagpt.utils.common:wrapper:631 - Exception occurs, start to serialize the project, exp:\nTraceback (most recent call last):\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n    result = await fn(*args, **kwargs)\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\actions\\action_node.py\", line 420, in _aask_v1\n    content = await self.llm.aask(prompt, system_msgs, images=images, timeout=timeout)\nTypeError: 'async for' requires an object with __aiter__ method, got bytes\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\utils\\common.py\", line 640, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\roles\\role.py\", line 550, in run\n    rsp = await self.react()\ntenacity.RetryError: RetryError[<Future at 0x1e838289f40 state=finished raised TypeError>]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\utils\\common.py\", line 626, in wrapper\n    result = await func(self, *args, **kwargs)\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\team.py\", line 134, in run\n    await self.env.run()\nException: Traceback (most recent call last):\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n    result = await fn(*args, **kwargs)\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\actions\\action_node.py\", line 420, in _aask_v1\n    content = await self.llm.aask(prompt, system_msgs, images=images, timeout=timeout)\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\provider\\base_llm.py\", line 150, in aask\n    rsp = await self.acompletion_text(message, stream=stream, timeout=self.get_timeout(timeout))\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n    return await fn(*args, **kwargs)\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n    return fut.result()\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\concurrent\\futures\\_base.py\", line 439, in result\n    return self.__get_result()\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\concurrent\\futures\\_base.py\", line 391, in __get_result\n    raise self._exception\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n    result = await fn(*args, **kwargs)\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\provider\\base_llm.py\", line 200, in acompletion_text\n    return await self._achat_completion_stream(messages, timeout=self.get_timeout(timeout))\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\provider\\ollama_api.py\", line 79, in _achat_completion_stream\n    async for raw_chunk in stream_resp:\nTypeError: 'async for' requires an object with __aiter__ method, got bytes\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\utils\\common.py\", line 640, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\roles\\role.py\", line 550, in run\n    rsp = await self.react()\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\roles\\role.py\", line 517, in react\n    rsp = await self._react()\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\roles\\role.py\", line 463, in _react\n    rsp = await self._act()\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\roles\\role.py\", line 392, in _act\n    response = await self.rc.todo.run(self.rc.history)\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\actions\\write_prd.py\", line 87, in run\n    return await self._handle_new_requirement(req)\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\actions\\write_prd.py\", line 108, in _handle_new_requirement\n    node = await WRITE_PRD_NODE.fill(context=context, llm=self.llm, exclude=exclude)  # schema=schema\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\actions\\action_node.py\", line 505, in fill\n    return await self.simple_fill(schema=schema, mode=mode, images=images, timeout=timeout, exclude=exclude)\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\actions\\action_node.py\", line 457, in simple_fill\n    content, scontent = await self._aask_v1(\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n    return await fn(*args, **kwargs)\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"C:\\software\\miniconda3\\envs\\metagpt\\lib\\site-packages\\tenacity\\__init__.py\", line 326, in iter\n    raise retry_exc from fut.exception()\ntenacity.RetryError: RetryError[<Future at 0x1e838289f40 state=finished raised TypeError>]",
      "state": "closed",
      "author": "459936800",
      "author_type": "User",
      "created_at": "2025-03-09T07:36:56Z",
      "updated_at": "2025-05-20T00:36:00Z",
      "closed_at": "2025-05-20T00:36:00Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1747/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 1
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1747",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1747",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:55.475115",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-09T00:33:07Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-20T00:35:59Z"
        }
      ]
    },
    {
      "issue_number": 1758,
      "title": "Tools should be in which directory to tool registry?",
      "body": "[tutorials](https://docs.deepwisdom.ai/main/en/guide/tutorials/create_and_use_tools.html):\nCraft functions or classes tailored to enable specific interactions with the external environment and place them in the metagpt/tools/libs directory.\n\nBut the directory should be in `metagpt/tools/libs` or `miniconda3\\envs\\metagpt\\Lib\\site-packages\\metagpt\\tools\\libs`?\n\nIf it is placed in `metagpt/tools/libs`, importErr will appear. \nPutting it in `miniconda3\\envs\\metagpt\\Lib\\site-packages\\metagpt\\tools\\libs` is obviously unreasonable in a production environment.",
      "state": "closed",
      "author": "AstridRylan",
      "author_type": "User",
      "created_at": "2025-03-12T07:54:22Z",
      "updated_at": "2025-05-19T00:37:40Z",
      "closed_at": "2025-05-19T00:37:39Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1758/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1758",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1758",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:55.668678",
      "comments": [
        {
          "author": "AstridRylan",
          "body": "Same as #1622 ",
          "created_at": "2025-03-12T07:56:39Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-12T00:32:28Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-19T00:37:39Z"
        }
      ]
    },
    {
      "issue_number": 1804,
      "title": "Unused send_to parameter in run_project method in metagpt/team.py",
      "body": "In the Team class's run_project method ( `team.py` ), there's an unused parameter send_to :\n\n```python\ndef run_project(self, idea, send_to: str = \"\"):\n    \"\"\"Run a project from publishing user requirement.\"\"\"\n    self.idea = idea\n    # Human requirement.\n    self.env.publish_message(Message(content=idea))\n ```\n\nThe parameter send_to is defined with a default value but never used within the method body. This could lead to confusion about its purpose and potential misuse.\n",
      "state": "closed",
      "author": "li-aolong",
      "author_type": "User",
      "created_at": "2025-04-03T16:15:46Z",
      "updated_at": "2025-05-19T00:37:36Z",
      "closed_at": "2025-05-19T00:37:35Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1804/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1804",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1804",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:55.901002",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-04T00:38:22Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-19T00:37:34Z"
        }
      ]
    },
    {
      "issue_number": 1785,
      "title": "install error PEP 668",
      "body": "pip install --upgrade metagpt\n\n\nerror: externally-managed-environment\n\nÃ— This environment is externally managed\nâ•°â”€> To install Python packages system-wide, try apt install\n    python3-xyz, where xyz is the package you are trying to\n    install.\n    \n    If you wish to install a non-Debian-packaged Python package,\n    create a virtual environment using python3 -m venv path/to/venv.\n    Then use path/to/venv/bin/python and path/to/venv/bin/pip. Make\n    sure you have python3-full installed.\n    \n    If you wish to install a non-Debian packaged Python application,\n    it may be easiest to use pipx install xyz, which will manage a\n    virtual environment for you. Make sure you have pipx installed.\n    \n    See /usr/share/doc/python3.12/README.venv for more information.\n\nnote: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\nhint: See PEP 668 for the detailed specification.\n",
      "state": "closed",
      "author": "athuljayaram",
      "author_type": "User",
      "created_at": "2025-03-23T15:06:28Z",
      "updated_at": "2025-05-18T13:12:17Z",
      "closed_at": "2025-05-17T00:34:19Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1785/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1785",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1785",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:56.102405",
      "comments": [
        {
          "author": "athuljayaram",
          "body": "pip install --upgrade metagpt  --break-system-packages\nDefaulting to user installation because normal site-packages is not writeable\nCollecting metagpt\n  Using cached metagpt-0.8.1-py3-none-any.whl.metadata (15 kB)\nCollecting aiohttp==3.8.6 (from metagpt)\n  Using cached aiohttp-3.8.6.tar.gz (7.4 MB)",
          "created_at": "2025-03-23T15:07:12Z"
        },
        {
          "author": "athuljayaram",
          "body": "python3 --version\nPython 3.12.3\n",
          "created_at": "2025-03-23T15:08:47Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-01T00:38:39Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-17T00:34:19Z"
        },
        {
          "author": "limboys",
          "body": "you can try pip install numpy==1.26.0 or Use Python 3.11 instead of 3.12",
          "created_at": "2025-05-18T13:12:16Z"
        }
      ]
    },
    {
      "issue_number": 1771,
      "title": "Unused argument",
      "body": "https://github.com/geekan/MetaGPT/blob/main/metagpt/ext/sela/search/tree_search.py#L334\nit seems the `node` argument is not used",
      "state": "closed",
      "author": "zuxfoucault",
      "author_type": "User",
      "created_at": "2025-03-19T06:15:14Z",
      "updated_at": "2025-05-18T00:38:05Z",
      "closed_at": "2025-05-18T00:38:05Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1771/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1771",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1771",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:56.325424",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-03T00:33:29Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-18T00:38:05Z"
        }
      ]
    },
    {
      "issue_number": 1776,
      "title": "can metagpt support TPM setting?",
      "body": "2025-03-21 13:36:02.044 | ERROR    | metagpt.utils.common:wrapper:683 - Exception occurs, start to serialize the project, exp:\nTraceback (most recent call last):\n  File \"/mnt/d/.github/MetaGPT/metagpt/utils/common.py\", line 692, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"/mnt/d/.github/MetaGPT/metagpt/roles/role.py\", line 548, in run\n    rsp = await self.react()\nopenai.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `llama3-70b-8192` in organization `org_01jjvzqkd4frf9g3awzsx7d5vx` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 6042, please reduce your message size and try again. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/mnt/d/.github/MetaGPT/metagpt/utils/common.py\", line 678, in wrapper\n    result = await func(self, *args, **kwargs)\n  File \"/mnt/d/.github/MetaGPT/metagpt/team.py\", line 134, in run\n    await self.env.run()\nException: Traceback (most recent call last):\n  File \"/mnt/d/.github/MetaGPT/metagpt/utils/common.py\", line 692, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"/mnt/d/.github/MetaGPT/metagpt/roles/role.py\", line 548, in run\n    rsp = await self.react()\n  File \"/mnt/d/.github/MetaGPT/metagpt/roles/role.py\", line 515, in react\n    rsp = await self._react()\n  File \"/mnt/d/.github/MetaGPT/metagpt/roles/di/role_zero.py\", line 349, in _react\n    has_todo = await self._think()\n  File \"/mnt/d/.github/MetaGPT/metagpt/roles/product_manager.py\", line 56, in _think\n    return await super()._think()\n  File \"/mnt/d/.github/MetaGPT/metagpt/roles/di/role_zero.py\", line 257, in _think\n    self.command_rsp = await self.llm_cached_aask(req=req, system_msgs=[system_prompt], state_data=state_data)\n  File \"/mnt/d/.github/MetaGPT/metagpt/exp_pool/decorator.py\", line 187, in async_wrapper\n    return await wrapped_func(args, kwargs)\n  File \"/mnt/d/.github/MetaGPT/metagpt/exp_pool/decorator.py\", line 65, in get_or_create\n    return await rsp if asyncio.iscoroutine(rsp) else rsp\n  File \"/mnt/d/.github/MetaGPT/metagpt/roles/di/role_zero.py\", line 268, in llm_cached_aask\n    return await self.llm.aask(req, system_msgs=system_msgs)\n  File \"/mnt/d/.github/MetaGPT/metagpt/provider/base_llm.py\", line 206, in aask\n    rsp = await self.acompletion_text(compressed_message, stream=stream, timeout=self.get_timeout(timeout))\n  File \"/mnt/d/.github/MetaGPT/myenv/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\n    return await fn(*args, **kwargs)\n  File \"/mnt/d/.github/MetaGPT/myenv/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 47, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"/mnt/d/.github/MetaGPT/myenv/lib/python3.9/site-packages/tenacity/__init__.py\", line 314, in iter\n    return fut.result()\n  File \"/root/.pyenv/versions/3.9.21/lib/python3.9/concurrent/futures/_base.py\", line 439, in result\n    return self.__get_result()\n  File \"/root/.pyenv/versions/3.9.21/lib/python3.9/concurrent/futures/_base.py\", line 391, in __get_result\n    raise self._exception\n  File \"/mnt/d/.github/MetaGPT/myenv/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 50, in __call__\n    result = await fn(*args, **kwargs)\n  File \"/mnt/d/.github/MetaGPT/metagpt/provider/openai_api.py\", line 174, in acompletion_text\n    return await self._achat_completion_stream(messages, timeout=timeout)\n  File \"/mnt/d/.github/MetaGPT/metagpt/provider/openai_api.py\", line 92, in _achat_completion_stream\n    response: AsyncStream[ChatCompletionChunk] = await self.aclient.chat.completions.create(\n  File \"/mnt/d/.github/MetaGPT/myenv/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n  File \"/mnt/d/.github/MetaGPT/myenv/lib/python3.9/site-packages/openai/_base_client.py\", line 1856, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/mnt/d/.github/MetaGPT/myenv/lib/python3.9/site-packages/openai/_base_client.py\", line 1550, in request\n    return await self._request(\n  File \"/mnt/d/.github/MetaGPT/myenv/lib/python3.9/site-packages/openai/_base_client.py\", line 1651, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `llama3-70b-8192` in organization `org_01jjvzqkd4frf9g3awzsx7d5vx` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 6042, please reduce your message size and try again. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
      "state": "closed",
      "author": "yuuuuuuan",
      "author_type": "User",
      "created_at": "2025-03-21T05:43:25Z",
      "updated_at": "2025-05-17T00:34:24Z",
      "closed_at": "2025-05-17T00:34:23Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1776/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1776",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1776",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:56.545435",
      "comments": [
        {
          "author": "Terrdi",
          "body": "I implemented the feature.You can tried it. [feature/rate-limit](https://github.com/Terrdi/MetaGPT/tree/feature/rate_limit)",
          "created_at": "2025-03-21T18:42:27Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-02T00:34:12Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-17T00:34:23Z"
        }
      ]
    },
    {
      "issue_number": 1777,
      "title": "è¯·é—®Messageåœ¨ä»€ä¹ˆæƒ…å†µä¸‹ä¼šè¢«ä½¿ç”¨åˆ°ï¼Ÿ",
      "body": "MetaGPTä¸­åªä¼šåœ¨LLMè¾“å…¥å’Œè¾“å‡ºçš„æ—¶å€™ç”¨`Message`ä¼ é€’å—ï¼Ÿ\nè°ƒç”¨å·¥å…·ã€å·¥å…·è¿”å›ç»“æœã€Agentä¸Agenté—´é€šä¿¡ä¼šä½¿ç”¨`Message`ä¼ é€’æ¶ˆæ¯å—ï¼Ÿ",
      "state": "closed",
      "author": "GoldenFishes",
      "author_type": "User",
      "created_at": "2025-03-21T06:59:56Z",
      "updated_at": "2025-05-17T00:34:23Z",
      "closed_at": "2025-05-17T00:34:22Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1777/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1777",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1777",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:56.788960",
      "comments": [
        {
          "author": "Clairegggg",
          "body": "åŒé—®\n",
          "created_at": "2025-03-23T02:59:53Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-01T00:38:45Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-17T00:34:22Z"
        }
      ]
    },
    {
      "issue_number": 1779,
      "title": "Roleé‡Œé¢çš„working_memoryå’Œmemoryæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ",
      "body": "æˆ‘åªçŸ¥é“Plannerè§„åˆ’å™¨ä½¿ç”¨çš„æ˜¯working_memoryï¼Œæƒ³é—®working_memoryå’Œmemoryæœ‰ä»€ä¹ˆåŒºåˆ†ï¼Ÿ",
      "state": "closed",
      "author": "GoldenFishes",
      "author_type": "User",
      "created_at": "2025-03-21T08:30:39Z",
      "updated_at": "2025-05-17T00:34:22Z",
      "closed_at": "2025-05-17T00:34:21Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1779/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1779",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1779",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:57.018857",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-01T00:38:44Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-17T00:34:21Z"
        }
      ]
    },
    {
      "issue_number": 1784,
      "title": "The TreeofThought.solve method can trigger an RCE vulnerability",
      "body": "### Summary\nWhile using the latest version (<=v0.8.1) of MetaGPT's `TreeofThought.solve` method, we discovered that users can guide the large language model through dialogue to generate malicious code. This code can then be executed by triggering the `eval` method within the `ThoughtSolverBase.generate_thoughts` function, enabling the execution of arbitrary commands. The risky code is shown in the figure below.\n\n<img width=\"335\" alt=\"image\" src=\"https://github.com/user-attachments/assets/33585033-dc79-4bc4-9c9e-6259952c160e\">\n\n### Details\nWe used the template provided in [creative_writing.py](https://github.com/geekan/MetaGPT/blob/main/tests/metagpt/strategy/prompt_templates/creative_writing.py) and the test code in [test_creative_writing.py](https://github.com/geekan/MetaGPT/blob/main/tests/metagpt/strategy/examples/test_creative_writing.py) to validate that a malicious user can pass malicious code to the eval method in ThoughtSolverBase.generate_thoughts. By utilizing the jailbreak technique provided in the PoC, we bypassed the restrictions imposed by the creative_writing template on malicious user inputs. This allowed us to embed malicious code within the conversation, guide the large language model to return the malicious code, and subsequently trigger the RCE vulnerability.\n\n### PoC\nPlease review the file tot_demo.py.\n\n### Impact\nThe following diagram illustrates the process of executing the aforementioned code sample, which triggers the execution of malicious code. This code then reads relevant files from the server's local system (other actions, such as deleting files, can also be performed).\n\n<img width=\"316\" alt=\"image\" src=\"https://github.com/user-attachments/assets/a8a24ccf-e521-4351-9604-38a668cbfbbb\">\n\n### Weaknesses\nImproper Neutralization of Directives in Dynamically Evaluated Code ('Eval Injection') (CWE-95)\n\n### Environment information\nLLM type and model name: OpenAI gpt-3.5-turbo\n\nSystem version: ubuntu18.04\n\nPython version: python3.11\n\nMetaGPT version or branch: 68b7dc6\n",
      "state": "closed",
      "author": "BACMiao",
      "author_type": "User",
      "created_at": "2025-03-23T06:59:53Z",
      "updated_at": "2025-05-17T00:34:21Z",
      "closed_at": "2025-05-17T00:34:20Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1784/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1784",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1784",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:57.219611",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-01T00:38:41Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-17T00:34:20Z"
        }
      ]
    },
    {
      "issue_number": 1671,
      "title": "Value error, Please set your API key in config2.yaml [type=value_error, input_value='YOUR_API_KEY', input_type=str]",
      "body": "**Bug description**\n<!-- Clearly and directly describe the current bug -->\n\n**Bug solved method**\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\n\n**Environment information**\n<!-- Environmentï¼šSystem version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\n\n- LLM type and model name: ollama qwen 2.5 coder 14b\n- System version: windows 11\n- Python version:Python 3.9.21\n- MetaGPT version or branch:\n\n<!-- Dependent packagessï¼šthe packages version cause the bug(like `pydantic 1.10.8`), installation methodï¼ˆlike `pip install metagpt` or `pip install from source` or `run in docker`ï¼‰ -->\n\n- packages version:\n- installation method: \n\n\n\n\n\n\n\nllm:\n  api_type: \"ollama\"  # or azure / ollama / open_llm etc. Check LLMType for more options\n  model: \"qwen2.5-coder:14b\"  # or gpt-3.5-turbo-1106 / gpt-4-1106-preview\n  base_url: \"http://localhost:11434\"  # or forward url / other llm url\n  api_key: \"YOUR_API_KEY\"\n\n\n\n\n**Screenshots or logs**\n\n![Image](https://github.com/user-attachments/assets/6988573b-1bbb-47f6-aae7-3c57f76913a7)\n\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\n",
      "state": "closed",
      "author": "gokulcoder7",
      "author_type": "User",
      "created_at": "2025-01-17T15:49:03Z",
      "updated_at": "2025-05-16T13:12:10Z",
      "closed_at": "2025-05-16T13:12:10Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1671/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1671",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1671",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:57.411399",
      "comments": [
        {
          "author": "gokulcoder7",
          "body": "how to find api key for ollama models ?",
          "created_at": "2025-01-17T15:49:29Z"
        },
        {
          "author": "iorisa",
          "body": "For the configuration of ollama's config2.yaml, you can refer to this document: [ollama-api](https://docs.deepwisdom.ai/main/en/guide/get_started/configuration/llm_api_configuration.html#ollama-api)\nIf it is a local ollama model, you can fill in any string, but it cannot be an empty string, left unf",
          "created_at": "2025-01-18T03:22:30Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-18T00:30:22Z"
        },
        {
          "author": "gokulcoder7",
          "body": "Tried this but I got new errror",
          "created_at": "2025-02-22T02:49:24Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-02T00:33:37Z"
        }
      ]
    },
    {
      "issue_number": 1717,
      "title": "å…¼å®¹ç«å±±æ–¹èˆŸçš„ä»£ç åˆ äº†ï¼Ÿï¼Ÿï¼Ÿ",
      "body": "**Feature description**\n<!-- Clear and direct description of the functionality of the currently submitted or proposed feature -->\n\n**Your Feature**\n<!-- Describe the idea or process of implementing the current feature. Of course, you can also paste the URL address of your Pull Request. -->\n<!-- When submitting features, you need to complete the corresponding doc/tests/examples to facilitate verification by reviewers. -->\n\n\n![Image](https://github.com/user-attachments/assets/b9734680-eafe-47a6-aac3-b2e412a07472)",
      "state": "closed",
      "author": "RoeGross",
      "author_type": "User",
      "created_at": "2025-02-24T07:29:48Z",
      "updated_at": "2025-05-16T13:09:23Z",
      "closed_at": "2025-05-16T13:09:23Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1717/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1717",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1717",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:46:57.654439",
      "comments": [
        {
          "author": "RoeGross",
          "body": "![Image](https://github.com/user-attachments/assets/42182178-a543-40b5-8895-f35fbf4916df)\n\n  è¿™æ ·ä½¿ç”¨èµ·æ¥äº†ç«å±±æ–¹èˆŸçš„ deepSeel R1   ä½†æ˜¯è§£æå¥½åƒè¦æŠ¥é”™    \n\n![Image](https://github.com/user-attachments/assets/03ab5ffe-47a1-4383-ba7a-e5af3701ae8b)",
          "created_at": "2025-02-24T07:49:42Z"
        },
        {
          "author": "seehi",
          "body": "[é…ç½®ç«å±±æ–¹èˆŸçš„API](https://docs.deepwisdom.ai/main/zh/guide/get_started/configuration/llm_api_configuration.html#%E7%81%AB%E5%B1%B1%E6%96%B9%E8%88%9F%E7%9A%84api)",
          "created_at": "2025-02-24T12:05:58Z"
        },
        {
          "author": "diesers",
          "body": "å…ˆåœ¨ç«å±±äº‘é‚£è¾¹åˆ›å»ºåœ¨çº¿æ¥å…¥ç‚¹ï¼Œæ¥å…¥ç‚¹é€‰æ‹©æŒ‡å®šçš„æ¨¡å‹ã€‚ç„¶å model å¡«å†™ ep-xxxx ï¼ˆæ¥å…¥ç‚¹ idï¼‰å°±è¡Œ",
          "created_at": "2025-03-12T10:26:40Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-12T00:32:32Z"
        }
      ]
    },
    {
      "issue_number": 1721,
      "title": "Unable to configure ollama via 3rd party url",
      "body": "**Bug description**\n\nI am trying to use MetaGPT via a third party url wrapper. It works for me with openai and claude:\n\n```\nllm:\n  api_type: \"openai\"  # or azure / ollama / groq etc.\n  model: \"gpt-4-turbo\"  # or gpt-3.5-turbo\n  base_url: \"http://localhost:8989/openai\"\n  api_key: \"xxxx\"\n```\n\nBut when i configure ollama, i have a problem:\n\n```\nllm:\n  api_type: \"ollama\"  # or azure / ollama / groq etc.\n  model: \"llama2\"  # or gpt-3.5-turbo\n  base_url: \"http://localhost:8989/ollama\"\n```\n\nBut it fails with a 404 not found, because the base URL needs to be:\n/api/chat and it just gets /chat\n\n```\n    @property\n    def api_suffix(self) -> str:\n        return \"/chat\"\n```\n\nI also tried to setup a proxy:\n\n```\nllm:\n  api_type: \"ollama\"  # or azure / ollama / groq etc.\n  model: \"llama2\"  # or gpt-3.5-turbo\n  base_url: \"http://localhost:11434/api\"  # or forward url / other llm url\n  proxy: \"http://localhost:8989\"\n```\n\nBut it doesn't seem to be even picked. How can i configure ollama via this wrapper url?\n\n\n**Environment information**\nmac os m2\nllm type -> ollama\n\n",
      "state": "closed",
      "author": "yrobla",
      "author_type": "User",
      "created_at": "2025-02-26T09:46:17Z",
      "updated_at": "2025-05-16T13:08:56Z",
      "closed_at": "2025-05-16T13:08:56Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1721/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1721",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1721",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:02.847305",
      "comments": [
        {
          "author": "iorisa",
          "body": "```yaml\nllm:\n  api_type: \"ollama\" \n  model: \"llama3.2\"  # or gpt-3.5-turbo\n  base_url: \"http://localhost:11434/api\" \n  api_key: \"any string will be ok\"\n```\nSovled by: #1710 ",
          "created_at": "2025-03-04T10:40:06Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-04T00:32:44Z"
        }
      ]
    },
    {
      "issue_number": 1741,
      "title": "Title",
      "body": "**Bug description**\n<!-- Clearly and directly describe the current bug -->\n\n**Bug solved method**\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\n\n**Environment information**\n<!-- Environmentï¼šSystem version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\n\n- LLM type and model name:\n- System version:\n- Python version:\n- MetaGPT version or branch:\n\n<!-- Dependent packagessï¼šthe packages version cause the bug(like `pydantic 1.10.8`), installation methodï¼ˆlike `pip install metagpt` or `pip install from source` or `run in docker`ï¼‰ -->\n\n- packages version:\n- installation method: \n\n**Screenshots or logs**\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->",
      "state": "closed",
      "author": "zainabalzawjalfaisal",
      "author_type": "User",
      "created_at": "2025-03-06T05:49:28Z",
      "updated_at": "2025-05-16T13:06:58Z",
      "closed_at": "2025-05-16T13:06:58Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1741/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1741",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1741",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:03.069862",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-06T00:35:37Z"
        }
      ]
    },
    {
      "issue_number": 1742,
      "title": "Is Web interface in SaaS version only?",
      "body": "So a web interface, presumably MetaGPT X, is shown on website, but while reading the doc,  I only see that there are CLI interactions. So is this different product? ",
      "state": "closed",
      "author": "MaximFworks",
      "author_type": "User",
      "created_at": "2025-03-06T08:34:37Z",
      "updated_at": "2025-05-16T13:06:45Z",
      "closed_at": "2025-05-16T13:06:45Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1742/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 1
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1742",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1742",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:03.243997",
      "comments": [
        {
          "author": "gitgo1994",
          "body": "yeah i think its different im not sure if they provide a web interface for the opensource version. ",
          "created_at": "2025-03-10T18:31:20Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-04-10T00:32:51Z"
        },
        {
          "author": "better629",
          "body": "The open source version is the open source version of most functions of the product (mgx.dev)",
          "created_at": "2025-05-16T13:06:43Z"
        }
      ]
    },
    {
      "issue_number": 1801,
      "title": "250+ repos analyzed: MetaGPT is fast, efficient, and refreshingly human",
      "body": "Hi @geekan, @better629, @garylin2099, and @seehi, \n\nWe analyzed how teams handle pull request workflows across 250+ open source projects â€” and MetaGPT stood out to us with 0s wait times and 100% human participation (rather than bots), which is exceptionally rare. \n\nCould we get your thoughts on how well the analysis matches your process? ğŸ‘‰ https://collab.dev/geekan/MetaGPT \n\nThanks for setting a great example! \nâ€” Alissa\n",
      "state": "closed",
      "author": "alissav0",
      "author_type": "User",
      "created_at": "2025-04-02T20:44:33Z",
      "updated_at": "2025-05-16T12:55:31Z",
      "closed_at": "2025-05-16T12:55:31Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1801/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1801",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1801",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:03.459923",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-03T00:33:23Z"
        }
      ]
    },
    {
      "issue_number": 1790,
      "title": "Is there a way to use meta gpt with already existing project that is not been created with it?",
      "body": "**Feature description**\nUsing it with the old projects.",
      "state": "closed",
      "author": "Canahmetozguven",
      "author_type": "User",
      "created_at": "2025-03-28T02:16:31Z",
      "updated_at": "2025-05-16T00:35:28Z",
      "closed_at": "2025-05-16T00:35:27Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1790/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1790",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1790",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:03.646257",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-01T00:38:38Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-16T00:35:27Z"
        }
      ]
    },
    {
      "issue_number": 1791,
      "title": "ä»£ç ç¼ºå°‘å¿…å¡«å­—æ®µ",
      "body": "Exception occurs, start to serialize the project, exp:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 50, in __call__\n    result = await fn(*args, **kwargs)\n  File \"/app/metagpt/metagpt/actions/action_node.py\", line 449, in _aask_v1\n    instruct_content = output_class(**parsed_data)\npydantic_core._pydantic_core.ValidationError: 1 validation error for WritePRD_AN\n  Value error, Missing fields: {'UI Design draft', 'Requirement Analysis', 'Anything UNCLEAR', 'Requirement Pool', 'Competitive Quadrant Chart'} [type=value_error, input_value={'Language': 'zh_cn', 'Pr...è·³è·ƒã€åƒé‡‘å¸ç­‰'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.5/v/value_error\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/app/metagpt/metagpt/utils/common.py\", line 664, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"/app/metagpt/metagpt/roles/role.py\", line 551, in run\n    rsp = await self.react()\ntenacity.RetryError: RetryError[<Future at 0x7f7f82e462e0 state=finished raised ValidationError>]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/app/metagpt/metagpt/utils/common.py\", line 650, in wrapper\n    result = await func(self, *args, **kwargs)\n  File \"/app/metagpt/metagpt/team.py\", line 134, in run\n    await self.env.run()\nException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 50, in __call__\n    result = await fn(*args, **kwargs)\n  File \"/app/metagpt/metagpt/actions/action_node.py\", line 449, in _aask_v1\n    instruct_content = output_class(**parsed_data)\n  File \"/usr/local/lib/python3.9/site-packages/pydantic/main.py\", line 164, in __init__\n    __pydantic_self__.__pydantic_validator__.validate_python(data, self_instance=__pydantic_self__)\npydantic_core._pydantic_core.ValidationError: 1 validation error for WritePRD_AN\n  Value error, Missing fields: {'UI Design draft', 'Requirement Analysis', 'Anything UNCLEAR', 'Requirement Pool', 'Competitive Quadrant Chart'} [type=value_error, input_value={'Language': 'zh_cn', 'Pr...è·³è·ƒã€åƒé‡‘å¸ç­‰'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.5/v/value_error\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/app/metagpt/metagpt/utils/common.py\", line 664, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"/app/metagpt/metagpt/roles/role.py\", line 551, in run\n    rsp = await self.react()\n  File \"/app/metagpt/metagpt/roles/role.py\", line 520, in react\n    rsp = await self._react()\n  File \"/app/metagpt/metagpt/roles/role.py\", line 475, in _react\n    rsp = await self._act()\n  File \"/app/metagpt/metagpt/roles/role.py\", line 404, in _act\n    response = await self.rc.todo.run(self.rc.history)\n  File \"/app/metagpt/metagpt/actions/write_prd.py\", line 87, in run\n    return await self._handle_new_requirement(req)\n  File \"/app/metagpt/metagpt/actions/write_prd.py\", line 108, in _handle_new_requirement\n    node = await WRITE_PRD_NODE.fill(context=context, llm=self.llm, exclude=exclude)  # schema=schema\n  File \"/app/metagpt/metagpt/actions/action_node.py\", line 648, in fill\n    return await self.simple_fill(schema=schema, mode=mode, images=images, timeout=timeout, exclude=exclude)\n  File \"/app/metagpt/metagpt/actions/action_node.py\", line 473, in simple_fill\n    content, scontent = await self._aask_v1(\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\n    return await fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 47, in __call__\n\n\nç¼ºå°‘å­—æ®µï¼š\n\nç³»ç»Ÿè¦æ±‚ WritePRD_ANï¼ˆå†™PRDçš„Action Nodeï¼‰å¿…é¡»åŒ…å«ä»¥ä¸‹å­—æ®µï¼š\n\nUI Design draftï¼ˆUIè®¾è®¡ç¨¿ï¼‰\n\nRequirement Analysisï¼ˆéœ€æ±‚åˆ†æï¼‰\n\nCompetitive Quadrant Chartï¼ˆç«äº‰è±¡é™å›¾ï¼‰\n\nRequirement Poolï¼ˆéœ€æ±‚æ± ï¼‰\n\nAnything UNCLEARï¼ˆä¸æ˜ç¡®çš„å†…å®¹ï¼‰\n\nä½†ä½ ä¼ å…¥çš„æ•°æ®ï¼ˆinput_valueï¼‰ç¼ºå°‘è¿™äº›å­—æ®µ",
      "state": "closed",
      "author": "ruan121212",
      "author_type": "User",
      "created_at": "2025-03-28T02:27:04Z",
      "updated_at": "2025-05-16T00:35:27Z",
      "closed_at": "2025-05-16T00:35:26Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1791/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1791",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1791",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:03.857835",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-01T00:38:36Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-16T00:35:26Z"
        }
      ]
    },
    {
      "issue_number": 1793,
      "title": "Every time I generate code, it gets stuck at this point. Why?",
      "body": "![Image](https://github.com/user-attachments/assets/9488395c-6778-4381-8f98-51fd21669f0d)",
      "state": "closed",
      "author": "liang-tian-tian",
      "author_type": "User",
      "created_at": "2025-03-30T09:24:42Z",
      "updated_at": "2025-05-16T00:35:26Z",
      "closed_at": "2025-05-16T00:35:25Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1793/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1793",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1793",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:04.045806",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-01T00:38:35Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-16T00:35:25Z"
        }
      ]
    },
    {
      "issue_number": 1795,
      "title": "[Dependency] Incompatibility with numpy>=2.0",
      "body": "**Bug description**\nWhen attempting to install both metagpt (>=0.8.0) and langchain-ark (>=0.1.5) using uv/pip, dependency resolution fails due to incompatible numpy version requirements.\n\n**Environment information**\n- System version: Ubuntu 24.04.1 LTS (WSL)\n- Python version: 3.11.11\n- uv version: 0.6.11\n- LLM Model: volcengine\n\n**Bug reproduction method**\n```bash\nuv add metagpt>=0.8.0 langchain_ark>=0.1.5\n```\n\n**Error Message**\n```text\nÃ— No solution found when resolving dependencies for split (python_full_version == '3.11.*'):\n  â•°â”€â–¶ Because only the following versions of metagpt are available:\n          .........\n          .........\n          metagpt==0.8.0\n          metagpt==0.8.1\n          metagpt==0.8.2\n      and all of:\n          metagpt<=0.6.4\n          metagpt>=0.8.0,<=0.8.1\n      depend on numpy==1.24.3, we can conclude that all of:\n          metagpt<0.6.5\n          metagpt>0.7.7,<0.8.2\n      depend on numpy==1.24.3.\n      And because all versions of langchain-ark depend on numpy>=2.1.3, we can conclude that all versions of langchain-ark and all of:\n          metagpt<0.6.5\n          metagpt>0.7.7,<0.8.2\n       are incompatible. (1)\n```\n\nIt seems that the error report says that `metagpt` does not support `numpy` versions above 2.0. \n\nIn fact, although it requires numpy>=2.1.3, `langchain-ark` currently can works with numpy==1.24.3, and I can solve my problem with some not-so-elegant methods. \n\nHowever, Numpy is a extremely important fundamental library in the field of scientific computing, and it's a pity that a project like metagpt with considerable influence does not support its latest version. Do we have plans to support latest Numpy in the future?",
      "state": "closed",
      "author": "zzkluck",
      "author_type": "User",
      "created_at": "2025-04-01T02:36:27Z",
      "updated_at": "2025-05-16T00:35:24Z",
      "closed_at": "2025-05-16T00:35:24Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1795/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1795",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1795",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:04.228607",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-02T00:34:09Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-16T00:35:23Z"
        }
      ]
    },
    {
      "issue_number": 1796,
      "title": "Aflowæ–‡ä»¶ç¼ºå¤±",
      "body": "aflowæ¨¡å—ä¸­çš„readmeä¸­æœ‰optimized_path/template/operator.pyå’Œoptimized_path/template/operator.jsonï¼Œä½†æ˜¯åœ¨ä»£ç ä¸­å¹¶æ²¡æœ‰æ‰¾åˆ°è¿™ä¸¤ä¸ªæ–‡ä»¶ï¼Œä¹Ÿæ²¡æœ‰æä¾›è¿™ä¸¤ä¸ªæ–‡ä»¶çš„é…ç½®æ–¹æ³•ï¼Œå¯ä»¥ä»‹ç»ä¸€ä¸‹å—",
      "state": "closed",
      "author": "aajing",
      "author_type": "User",
      "created_at": "2025-04-01T09:41:21Z",
      "updated_at": "2025-05-16T00:35:23Z",
      "closed_at": "2025-05-16T00:35:23Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1796/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1796",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1796",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:04.479733",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-02T00:34:08Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-05-16T00:35:22Z"
        }
      ]
    },
    {
      "issue_number": 1780,
      "title": "to run the example app of hello_world.py with the llm config of ollama encounter the exception when json.loads the response",
      "body": "**Bug description**\n<!-- Clearly and directly describe the current bug -->\nto run the example app of hello_world.py with the llm config of ollama encounter the exception when json.loads the response\n\n**Bug solved method**\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\n\n**Environment information**\n<!-- Environmentï¼šSystem version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\nPRETTY_NAME=\"Ubuntu 22.10\"\nNAME=\"Ubuntu\"\nVERSION_ID=\"22.10\"\nVERSION=\"22.10 (Kinetic Kudu)\"\n\nPython 3.9.21\n\nLLM config:\nllm:\n  api_type: \"ollama\"  # or azure / ollama / groq etc.\n  model: \"llama2:7b\"  # or gpt-3.5-turbo  llama2:7b  gemma3:1b\n  base_url: \"http://localhost:11435/v1/\"  # or forward url / other llm url\n  api_key: \"\"\n\n- LLM type and model name: llama2:7b\n- System version: ollama 0.6.0\n- Python version: Python 3.9.21\n- MetaGPT version or branch:- latest code of main branch\n\n<!-- Dependent packagessï¼šthe packages version cause the bug(like `pydantic 1.10.8`), installation methodï¼ˆlike `pip install metagpt` or `pip install from source` or `run in docker`ï¼‰ -->\nconda create -n metagpt python=3.9 && conda activate metagpt\ngit clone https://github.com/geekan/MetaGPT && cd MetaGPT && pip install --upgrade -e .\n\n- packages version:\n- latest code of main branch\n- \n- installation method: \nconda create -n metagpt python=3.9 && conda activate metagpt\ngit clone https://github.com/geekan/MetaGPT && cd MetaGPT && pip install --upgrade -e .\n\n**Screenshots or logs**\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\nException has occurred: JSONDecodeError\nExtra data: line 1 column 5 (char 4)\n  File \"/home/cienet/ollama_model/MetaGPT/metagpt/provider/ollama_api.py\", line 41, in decode\n    return json.loads(response.data.decode(\"utf-8\"))\n  File \"/home/cienet/ollama_model/MetaGPT/metagpt/provider/ollama_api.py\", line 257, in _processing_openai_response\n    resp = self.ollama_message.decode(openai_resp)\n  File \"/home/cienet/ollama_model/MetaGPT/metagpt/provider/ollama_api.py\", line 252, in _achat_completion_stream\n    return self._processing_openai_response(resp)\n  File \"/home/cienet/ollama_model/MetaGPT/metagpt/provider/base_llm.py\", line 259, in acompletion_text\n    return await self._achat_completion_stream(messages, timeout=self.get_timeout(timeout))\n  File \"/home/cienet/ollama_model/MetaGPT/metagpt/provider/base_llm.py\", line 206, in aask\n    rsp = await self.acompletion_text(compressed_message, stream=stream, timeout=self.get_timeout(timeout))\n  File \"/home/cienet/ollama_model/MetaGPT/examples/hello_world.py\", line 16, in ask_and_print\n    rsp = await llm.aask(question, system_msgs=[system_prompt], stream=True)\n  File \"/home/cienet/ollama_model/MetaGPT/examples/hello_world.py\", line 41, in main\n    await ask_and_print(\"what's your name?\", llm, \"I'm a helpful AI assistant.\")\n  File \"/home/cienet/ollama_model/MetaGPT/examples/hello_world.py\", line 47, in <module>",
      "state": "closed",
      "author": "Leif-Liu",
      "author_type": "User",
      "created_at": "2025-03-21T08:56:39Z",
      "updated_at": "2025-05-06T00:43:45Z",
      "closed_at": "2025-05-06T00:43:45Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1780/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1780",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1780",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:04.693568",
      "comments": [
        {
          "author": "Leif-Liu",
          "body": "base_url: \"http://127.0.0.1:11435/api\"\n\ncould connect the cli with the local ollama llm. but encounter another issue:\n\ndef role_raise_decorator(func):\n    async def wrapper(self, *args, **kwargs):\n        try:\n            return await func(self, *args, **kwargs)\n        except KeyboardInterrupt as k",
          "created_at": "2025-03-24T08:24:04Z"
        },
        {
          "author": "Leif-Liu",
          "body": "Exception has occurred: Exception\nTraceback (most recent call last):\n  File \"/home/liufeng/MetaGPT/metagpt/utils/common.py\", line 692, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"/home/liufeng/MetaGPT/metagpt/roles/role.py\", line 548, in run\n    rsp = await self.react()\n  File \"/",
          "created_at": "2025-03-24T08:24:32Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-05-01T00:38:42Z"
        }
      ]
    },
    {
      "issue_number": 1716,
      "title": "mac python3.13. can not install",
      "body": "**Bug description**\nduring install:\n      FAILED: pandas/_libs/tslibs/base.cpython-313-darwin.so.p/meson-generated_pandas__libs_tslibs_base.pyx.c.o\n      cc -Ipandas/_libs/tslibs/base.cpython-313-darwin.so.p -Ipandas/_libs/tslibs -I../../pandas/_libs/tslibs -I../../../../pip-build-env-g78rnw_k/overlay/lib/python3.13/site-packages/numpy/_core/include -I../../pandas/_libs/include -I/Library/Frameworks/Python.framework/Versions/3.13/include/python3.13 -fvisibility=hidden -fcolor-diagnostics -DNDEBUG -w -std=c99 -O3 -DNPY_NO_DEPRECATED_API=0 -DNPY_TARGET_VERSION=NPY_1_21_API_VERSION -MD -MQ pandas/_libs/tslibs/base.cpython-313-darwin.so.p/meson-generated_pandas__libs_tslibs_base.pyx.c.o -MF pandas/_libs/tslibs/base.cpython-313-darwin.so.p/meson-generated_pandas__libs_tslibs_base.pyx.c.o.d -o pandas/_libs/tslibs/base.cpython-313-darwin.so.p/meson-generated_pandas__libs_tslibs_base.pyx.c.o -c pandas/_libs/tslibs/base.cpython-313-darwin.so.p/pandas/_libs/tslibs/base.pyx.c\n      pandas/_libs/tslibs/base.cpython-313-darwin.so.p/pandas/_libs/tslibs/base.pyx.c:5399:70: error: too few arguments to function call, expected 6, have 5\n       5397 |                 int ret = _PyLong_AsByteArray((PyLongObject *)v,\n            |                           ~~~~~~~~~~~~~~~~~~~\n\n\n\n**Environment information**\nMac OS Sequoia 15.3\nPython 3.13\n\n",
      "state": "closed",
      "author": "leogong99",
      "author_type": "User",
      "created_at": "2025-02-23T18:06:27Z",
      "updated_at": "2025-04-10T00:32:55Z",
      "closed_at": "2025-04-10T00:32:54Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1716/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1716",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1716",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:06.567326",
      "comments": [
        {
          "author": "seehi",
          "body": "Try python3.9/3.10/3.11",
          "created_at": "2025-02-24T03:03:22Z"
        },
        {
          "author": "TheGreatCorrine",
          "body": "I guess you need to use **python3.9** or **python3.10**.\nThis is because Python 3.12+ has compatibility issues: `pkgutil.ImpImporter` was removed in Python 3.12, but `setuptools` still depends on it, causing the `numpy` build to fail.\n`metagpt` requires numpy==1.24.3, which may not be fully compatib",
          "created_at": "2025-02-24T16:44:16Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-27T00:32:31Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-04-10T00:32:53Z"
        }
      ]
    },
    {
      "issue_number": 1711,
      "title": "TypeError: __init__() got an unexpected keyword argument 'proxies'",
      "body": "æˆ‘çš„config\n`llm:`\n`  api_key: 'sk-...' `\n`  model: 'xdeepseekr1' `\n`  base_url: 'https://maas-api.cn-huabei-1.xf-yun.com/v1' `",
      "state": "closed",
      "author": "Kattentions",
      "author_type": "User",
      "created_at": "2025-02-21T10:38:52Z",
      "updated_at": "2025-04-09T00:33:13Z",
      "closed_at": "2025-04-09T00:33:13Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1711/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1711",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1711",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:06.803762",
      "comments": [
        {
          "author": "jackymaxzzz",
          "body": "same",
          "created_at": "2025-02-22T19:08:05Z"
        },
        {
          "author": "destiny0326",
          "body": "httpxçš„ç‰ˆæœ¬å¤ªé«˜äº†\nhttpxåŒ…åœ¨11.28è¿›è¡Œæ›´æ–°ï¼Œå®‰è£…äº†httpx 0.28.0 ç‰ˆæœ¬çš„åŒ…å¯¼è‡´æŠ¥é”™\n\nè§£å†³åŠæ³•\npip install httpx==0.27.2",
          "created_at": "2025-02-23T02:47:49Z"
        },
        {
          "author": "jackymaxzzz",
          "body": "> httpxçš„ç‰ˆæœ¬å¤ªé«˜äº† httpxåŒ…åœ¨11.28æ›´æ–°ï¼Œå®‰è£…äº†httpx 0.28.0ç‰ˆæœ¬çš„åŒ…å¯¼è‡´æŠ¥é”™\n> \n> è§£å†³æ–¹æ³• pip install httpx==0.27.2\n\néå¸¸æ„Ÿè°¢ï¼Œé—®é¢˜è§£å†³",
          "created_at": "2025-02-23T03:14:16Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-26T00:32:22Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-04-09T00:33:12Z"
        }
      ]
    },
    {
      "issue_number": 1709,
      "title": "openai o1 raise BadRequestError: Unsupported parameter: 'max_tokens' is not supported with this model",
      "body": "**Bug description**\n```\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.\", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}}\n```\n\nllm config:\n```yaml\nllm:\n  api_type: \"openai\"  # or azure / ollama / groq etc.\n  model: \"o1\"  # or gpt-3.5-turbo\n  base_url: \"https://api.openai.com/v1\"  # or forward url / other llm url\n  api_key:\n```\n",
      "state": "closed",
      "author": "iorisa",
      "author_type": "User",
      "created_at": "2025-02-21T07:23:04Z",
      "updated_at": "2025-04-07T00:34:33Z",
      "closed_at": "2025-04-07T00:34:33Z",
      "labels": [
        "bug",
        "inactive"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1709/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1709",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1709",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:07.045709",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-24T00:34:03Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-04-07T00:34:33Z"
        }
      ]
    },
    {
      "issue_number": 1703,
      "title": "Researcherä¸€ç›´é‡å¤ | INFO     | metagpt.utils.token_counter:count_output_tokens:486 - Warning: model GLM-4 not found in tiktoken. Using cl100k_base encoding.",
      "body": "ç°æœ‰çš„ç½‘é¡µæœç´¢åŠŸèƒ½åªèƒ½ç”¨ChatGPTåšå—ï¼Œç”¨è´¨è°±è¿›å…¥WebBrowseAndSummarizeæ—¶ä¸€ç›´é‡å¤Warning: model GLM-4 not found in tiktoken. Using cl100k_base encoding.çš„è­¦å‘Šï¼Œç­‰äº†å¤§æ¦‚7,8åˆ†é’Ÿä¹Ÿä¸å‡ºç»“æœï¼Œæ˜¯ä¸æ˜¯åªèƒ½é‡å†™ä»£ç ï¼Œè¿˜æ˜¯å…¶ä»–æ¨¡å‹æ€§èƒ½é—®é¢˜ï¼Ÿ",
      "state": "closed",
      "author": "1729256800",
      "author_type": "User",
      "created_at": "2025-02-19T12:57:21Z",
      "updated_at": "2025-04-06T00:35:41Z",
      "closed_at": "2025-04-06T00:35:41Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1703/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1703",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1703",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:07.240869",
      "comments": [
        {
          "author": "seehi",
          "body": "è¿™ä¸ªwarningæ˜¯å› ä¸ºæ‰¾ä¸åˆ°æ¨¡å‹å¯¹åº”çš„token encodingï¼Œè€Œä½¿ç”¨é»˜è®¤å€¼cl100k_baseã€‚\næ²¡æœ‰ç»“æœï¼Œåº”è¯¥æ˜¯è·Ÿæ¨¡å‹èƒ½åŠ›æœ‰å…³ï¼Œå¯ä»¥çœ‹ä¸‹logsæˆ–è€…è¾“å‡ºæ›´å¤šæ—¥å¿—ã€‚",
          "created_at": "2025-02-20T08:33:58Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-23T00:35:23Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-04-06T00:35:40Z"
        }
      ]
    },
    {
      "issue_number": 1689,
      "title": "Team serialization may fail when the program exits abnormally",
      "body": "**Bug description**\nWhen I tried to run the Werewolf example, the model call failed due to platform flow restrictions. At this time, the program failed to serialize when it tried to write the current state to the storage/team.json file.\nAfter debugging, I found that the attribute special_actions in BasePlayer contained Action classes such as Speak, which caused the serialization failure\n\n**Bug solved method**\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\nI tried to add a custom serializer to Team so that it can be customized by users\nhttps://github.com/geekan/MetaGPT/pull/1688\n\n**Environment information**\n<!-- Environmentï¼šSystem version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\n\n- LLM type and model name: deepseek-r1\n- System version: MacOS\n- Python version: python3.9\n- MetaGPT version or branch: main\n\n<!-- Dependent packagessï¼šthe packages version cause the bug(like `pydantic 1.10.8`), installation methodï¼ˆlike `pip install metagpt` or `pip install from source` or `run in docker`ï¼‰ -->\n\n- packages version:\n- installation method: pip install -e \".[rag,test,dev]\"\n\n",
      "state": "closed",
      "author": "Terrdi",
      "author_type": "User",
      "created_at": "2025-02-11T04:07:24Z",
      "updated_at": "2025-04-05T00:32:22Z",
      "closed_at": "2025-04-05T00:32:21Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1689/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1689",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1689",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:07.454990",
      "comments": [
        {
          "author": "seehi",
          "body": "The PR is large.",
          "created_at": "2025-02-13T06:34:52Z"
        },
        {
          "author": "Terrdi",
          "body": "OK, I changed the target branch and submitted some new changes. \nThe aflow example also uses json serialization to save the results. The total_cost field is numpy.int64, which cannot be serialized directly. Then I fixed this problem.",
          "created_at": "2025-02-19T07:11:15Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-22T00:31:42Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-04-05T00:32:21Z"
        }
      ]
    },
    {
      "issue_number": 1698,
      "title": "keyä¸­ç”¨çš„æ˜¯serpapiï¼Œä½†è¿è¡Œresearcheræ—¶æŠ¥é”™ä¿¡æ¯æ˜¾ç¤ºç”¨çš„æ˜¯ddgæ˜¯ä»€ä¹ˆé—®é¢˜å¯¼è‡´çš„ï¼Ÿ",
      "body": "search:\n  api_type: 'serpapi' # serpapi/google/serper/ddg\n  api_key: ''\n  # cse_id: 'YOUR_CSE_ID' # only for google\n  params:\n    engine: google # google/bing/yahoo/baidu/yandex, check https://serpapi.com/bing-search-api for more details\n    google_domain: 'google.com'\n    gl: us\n    hl: en\n\n2025-02-18 15:28:19.229 | INFO     | metagpt.const:get_metagpt_package_root:21 - Package root set to D:\\Code\\python\\pycharm\\MetaGPT\n2025-02-18 15:28:26.195 | INFO     | __main__:_act:44 - David(Researcher): to do CollectLinks(CollectLinks)\n[\"2025 Spring Fashion Trends\", \"Women's Fashion\"]\n2025-02-18 15:28:33.048 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.001 | Max budget: $10.000 | Current cost: $0.001, prompt_tokens: 74, completion_tokens: 16\n2025-02-18 15:28:43.059 | ERROR    | metagpt.tools.search_engine:run:142 - fail to search 2025 Spring Fashion Trends for _get_url() https://duckduckgo.com Timeout: Failed to perform, curl: (28) Connection timed out after 10006 milliseconds. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.",
      "state": "closed",
      "author": "1729256800",
      "author_type": "User",
      "created_at": "2025-02-18T07:44:30Z",
      "updated_at": "2025-04-05T00:32:20Z",
      "closed_at": "2025-04-05T00:32:20Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1698/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1698",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1698",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:07.657686",
      "comments": [
        {
          "author": "seehi",
          "body": "é»˜è®¤å€¼æ˜¯[ddg](https://github.com/geekan/MetaGPT/blob/main/metagpt/configs/search_config.py#L19)ï¼Œçœ‹ç€åƒé…ç½®æ²¡æ­£ç¡®è§£æï¼Œå¯ä»¥æŠŠconfigçš„å€¼æ‰“å°å‡ºæ¥çœ‹ä¸‹",
          "created_at": "2025-02-19T06:08:56Z"
        },
        {
          "author": "1729256800",
          "body": "ç¡®å®æ²¡æ­£å¸¸è§£æï¼Œä¸çŸ¥é“ä»€ä¹ˆåŸå› ï¼Œåªèƒ½æ‰‹åŠ¨æŠŠé»˜è®¤å€¼æ”¹äº†",
          "created_at": "2025-02-19T12:44:46Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-22T00:31:40Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-04-05T00:32:19Z"
        }
      ]
    },
    {
      "issue_number": 1697,
      "title": "When testing researcher.py, there is a BUG ModuleNotFoundError: No module named 'sparkai', hoping to have a big boss to solve the confusion",
      "body": "I have tried pip install sparkai, but this only results in missing sparkai.core\nThat seems to be the main problem spark_api.py,but I use the moonshot\n\nTraceback (most recent call last):\n  File \"D:\\Code\\python\\pycharm\\MetaGPT\\metagpt\\roles\\researcher.py\", line 13, in <module>\n    from metagpt.actions import Action, CollectLinks, ConductResearch, WebBrowseAndSummarize\n  File \"D:\\Code\\python\\pycharm\\MetaGPT\\metagpt\\actions\\__init__.py\", line 10, in <module>\n    from metagpt.actions.action import Action\n  File \"D:\\Code\\python\\pycharm\\MetaGPT\\metagpt\\actions\\action.py\", line 15, in <module>\n    from metagpt.actions.action_node import ActionNode\n  File \"D:\\Code\\python\\pycharm\\MetaGPT\\metagpt\\actions\\action_node.py\", line 22, in <module>\n    from metagpt.llm import BaseLLM\n  File \"D:\\Code\\python\\pycharm\\MetaGPT\\metagpt\\llm.py\", line 11, in <module>\n    from metagpt.context import Context\n  File \"D:\\Code\\python\\pycharm\\MetaGPT\\metagpt\\context.py\", line 16, in <module>\n    from metagpt.provider.base_llm import BaseLLM\n  File \"D:\\Code\\python\\pycharm\\MetaGPT\\metagpt\\provider\\__init__.py\", line 16, in <module>\n    from metagpt.provider.spark_api import SparkLLM\n  File \"D:\\Code\\python\\pycharm\\MetaGPT\\metagpt\\provider\\spark_api.py\", line 4, in <module>\n    from sparkai.core.messages import _convert_to_message, convert_to_messages\nModuleNotFoundError: No module named 'sparkai'\n\n",
      "state": "closed",
      "author": "1729256800",
      "author_type": "User",
      "created_at": "2025-02-17T13:33:53Z",
      "updated_at": "2025-04-04T00:32:49Z",
      "closed_at": "2025-04-04T00:32:48Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1697/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1697",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1697",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:07.881634",
      "comments": [
        {
          "author": "1729256800",
          "body": "æ‰¾åˆ°é—®é¢˜äº†æ˜¯åŒ…æ²¡å®‰è£…å¯¹ï¼Œå¯ä»¥å‚è€ƒrequirement.txtæ–‡ä»¶ï¼Œè¿˜å¾—æ›´æ”¹ä¸€ä¸‹å®‰è£…è·¯å¾„å­—æ•°ä¸Šé™",
          "created_at": "2025-02-18T07:47:09Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-21T00:32:25Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-04-04T00:32:48Z"
        }
      ]
    },
    {
      "issue_number": 1700,
      "title": "Feature Request: Enable default authentication method with Amazon EC2 Instance Profile for Amazon Bedrock LLM provider",
      "body": "**Feature description**\n\nBy default, all of the AWS SDKs (including `boto3`) attempt to dynamically retrieve temporary credentials using a \"metadata endpoint\" on EC2 instances, Lambda Functions, and AWS Fargate tasks. This authentication mechanism avoids the requirement of providing static credentials from an AWS IAM User account, in favor of creating an IAM **Role** identity.\n\nAccording to the documentation for MetaGPT, the only supported authentication mechanism for Amazon Bedrock is to create an IAM User, with a static access key and secret key.\n\nCould you please support using the default IAM Instance Profile, which requires no additional configuration, provided that MetaGPT is running on AWS Fargate or EC2 instances?\n\n<img width=\"567\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/964fc1ae-5fb6-4b83-b734-4bee6c9450cc\" />\n\nIn AWS Fargate, it's called a \"Task Role\": https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html\n\nFor EC2 instances it's called the \"IAM Instance Profile\": https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2_instance-profiles.html\n\nHere's the `boto3` documentation that describes the process that the AWS SDK uses to \"find\" credentials: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html\n\nBoto3 will look in several locations when searching for credentials. The mechanism in which Boto3 looks for credentials is to search through a list of possible locations and stop as soon as it finds credentials. The order in which Boto3 searches for credentials is:\n\n- Passing credentials as parameters in the boto3.client() method\n- Passing credentials as parameters when creating a Session object\n- Environment variables\n- Assume role provider\n- Assume role with web identity provider\n- AWS IAM Identity Center credential provider\n- Shared credential file (~/.aws/credentials)\n- AWS config file (~/.aws/config)\n- Boto2 config file (/etc/boto.cfg and ~/.boto)\n- Container credential provider\n- Instance metadata service on an Amazon EC2 instance that has an IAM role configured.\n\n<img width=\"791\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/a64b803c-69e4-40d5-b69d-ba2f33e4d4ef\" />\n\nI'm referring to 10 and 11 in the above screenshot, rather than specifying static credentials.\n\nHonestly, it's quite possible that MetaGPT already supports this authentication mechanism for Bedrock, but I don't see documentation (for MetaGPT) on how to configure it to use the default credential chain.",
      "state": "closed",
      "author": "trevorstr",
      "author_type": "User",
      "created_at": "2025-02-18T21:59:51Z",
      "updated_at": "2025-04-04T00:32:47Z",
      "closed_at": "2025-04-04T00:32:47Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1700/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1700",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1700",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:08.075806",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-21T00:32:24Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-04-04T00:32:47Z"
        }
      ]
    },
    {
      "issue_number": 1708,
      "title": "é…ç½®deepseekçš„apiä¹‹åï¼Œmetagpté‡å¤åœ¨thinkï¼Œä½†æ— æ³•æ‰§è¡ŒactionåŠ¨ä½œ",
      "body": "2025-02-21 10:06:54.840 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 231.734(s), this was the 6th time calling it. exp: 1 validation error for WritePRD_AN\n  Value error, Missing fields: {'UI Design draft', 'Anything UNCLEAR'} [type=value_error, input_value={'Language': 'zh_cn', 'Pr...ç¤º': 'å±å¹•åº•éƒ¨'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.5/v/value_error\n2025-02-21 10:06:54.842 | WARNING  | metagpt.utils.common:wrapper:673 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.\n2025-02-21 10:06:54.855 | ERROR    | metagpt.utils.common:wrapper:655 - Exception occurs, start to serialize the project, exp:\nTraceback (most recent call last):\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n    result = await fn(*args, **kwargs)\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\metagpt\\actions\\action_node.py\", line 449, in _aask_v1\n    instruct_content = output_class(**parsed_data)\npydantic_core._pydantic_core.ValidationError: 1 validation error for WritePRD_AN\n  Value error, Missing fields: {'UI Design draft', 'Anything UNCLEAR'} [type=value_error, input_value={'Language': 'zh_cn', 'Pr...ç¤º': 'å±å¹•åº•éƒ¨'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.5/v/value_error\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\metagpt\\utils\\common.py\", line 664, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\metagpt\\roles\\role.py\", line 551, in run\n    rsp = await self.react()\ntenacity.RetryError: RetryError[<Future at 0x1b156176a60 state=finished raised ValidationError>]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\metagpt\\utils\\common.py\", line 650, in wrapper\n    result = await func(self, *args, **kwargs)\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\metagpt\\team.py\", line 134, in run\n    await self.env.run()\nException: Traceback (most recent call last):\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n    result = await fn(*args, **kwargs)\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\metagpt\\actions\\action_node.py\", line 449, in _aask_v1\n    instruct_content = output_class(**parsed_data)\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\pydantic\\main.py\", line 164, in __init__\n    __pydantic_self__.__pydantic_validator__.validate_python(data, self_instance=__pydantic_self__)\npydantic_core._pydantic_core.ValidationError: 1 validation error for WritePRD_AN\n  Value error, Missing fields: {'UI Design draft', 'Anything UNCLEAR'} [type=value_error, input_value={'Language': 'zh_cn', 'Pr...ç¤º': 'å±å¹•åº•éƒ¨'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.5/v/value_error\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\metagpt\\utils\\common.py\", line 664, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\metagpt\\roles\\role.py\", line 551, in run\n    rsp = await self.react()\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\metagpt\\roles\\role.py\", line 520, in react\n    rsp = await self._react()\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\metagpt\\roles\\role.py\", line 475, in _react\n    rsp = await self._act()\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\metagpt\\roles\\role.py\", line 404, in _act\n    response = await self.rc.todo.run(self.rc.history)\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\metagpt\\actions\\write_prd.py\", line 87, in run\n    return await self._handle_new_requirement(req)\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\metagpt\\actions\\write_prd.py\", line 108, in _handle_new_requirement\n    node = await WRITE_PRD_NODE.fill(context=context, llm=self.llm, exclude=exclude)  # schema=schema\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\metagpt\\actions\\action_node.py\", line 648, in fill\n    return await self.simple_fill(schema=schema, mode=mode, images=images, timeout=timeout, exclude=exclude)\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\metagpt\\actions\\action_node.py\", line 473, in simple_fill\n    content, scontent = await self._aask_v1(\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n    return await fn(*args, **kwargs)\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"C:\\Users\\USERl\\.conda\\envs\\metagpt\\lib\\site-packages\\tenacity\\__init__.py\", line 326, in iter\n    raise retry_exc from fut.exception()\ntenacity.RetryError: RetryError[<Future at 0x1b156176a60 state=finished raised ValidationError>]",
      "state": "closed",
      "author": "zhulf11",
      "author_type": "User",
      "created_at": "2025-02-21T02:15:09Z",
      "updated_at": "2025-04-03T07:09:40Z",
      "closed_at": "2025-04-03T07:09:40Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1708/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1708",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1708",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:08.284066",
      "comments": [
        {
          "author": "seehi",
          "body": "deepseek-chatè¿˜æ˜¯deepseek-reasoner",
          "created_at": "2025-02-24T03:01:38Z"
        },
        {
          "author": "annian101",
          "body": "> 2025-02-21 10:06:54.840 | é”™è¯¯ | metagpt.utils.common:log_it:554 - åœ¨ 231.734(s) ä¹‹åå®Œæˆå¯¹â€œmetagpt.actions.action_node.ActionNode._aask_v1â€çš„è°ƒç”¨ï¼Œè¿™æ˜¯ç¬¬ 6 æ¬¡è°ƒç”¨å®ƒã€‚ exp: WritePRD_AN çš„ 1 ä¸ªéªŒè¯é”™è¯¯ å€¼é”™è¯¯ï¼Œç¼ºå°‘å­—æ®µï¼š{'UI è®¾è®¡è‰ç¨¿'ï¼Œ'ä»»ä½•ä¸æ¸…æ¥šçš„å†…å®¹'} [type=value_error, input_value={'Language': 'zh_cn', 'Pr...ç¤º': 'å±å¹•åº•éƒ¨'}}, input_type=dict] æœ‰",
          "created_at": "2025-02-24T05:46:13Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-27T00:32:34Z"
        },
        {
          "author": "mei-Tom",
          "body": "æˆ‘ä¹Ÿé‡åˆ°äº†è¿™ä¸ªé—®é¢˜ï¼ŒDeepSeek-R1ä¸€ç›´åœ¨æ€è€ƒï¼Œæœ€åè¿”å›çš„ç»“æœæ˜¯ç©ºå­—ç¬¦ä¸²ï¼Œç›®å‰åªèƒ½ç”¨V3æˆ–å…¶ä»–LLMæ¥ä»£æ›¿ï¼Œè¯·é—®åç»­æ˜¯å¦‚ä½•è§£å†³çš„ï¼Ÿ",
          "created_at": "2025-04-03T02:38:30Z"
        },
        {
          "author": "zhulf11",
          "body": "æˆ‘åé¢å†æ¬¡æ¢äº†ä¸€ä¸ªæ—¶é—´è°ƒç”¨äº†R1æ¥å£ï¼Œdeepseekç»™å‡ºäº†actionã€‚ä½†å®é™…æˆ‘å¹¶æ²¡æœ‰åšä»»ä½•æ”¹åŠ¨ã€‚\næ®æˆ‘çš„æ¨æµ‹ï¼Œæ— æ³•è¿”å›actionæ˜¯å› ä¸ºæˆ‘ä½¿ç”¨çš„gpuå¡ä½¿ç”¨ç‡è¿‡é«˜å¯¼è‡´ï¼Œå„ä½é‡åˆ°è¿™ä¸ªé—®é¢˜å¯ä»¥æŸ¥çœ‹ä¸€ä¸‹gpuä½¿ç”¨ç‡ï¼Œé¿å¼€é«˜ä½¿ç”¨ç‡çš„æƒ…å†µä¸‹çœ‹æ˜¯å¦è¿˜æœ‰è¿™ä¸ªé—®é¢˜ã€‚",
          "created_at": "2025-04-03T07:09:28Z"
        }
      ]
    },
    {
      "issue_number": 1696,
      "title": "æˆ‘æ€ä¹ˆæŠŠDataInterpreteråŠ å…¥åˆ°æˆ‘çš„Teamä¸­å‘¢",
      "body": "ä¾‹å¦‚æˆ‘å¸Œæœ›æˆ‘çš„Teamä¸­æœ‰Researcherå’ŒDataInterpreterä¸¤ä¸ªè§’è‰²ï¼Œå…¶ä¸­Researcherè¾“å‡ºæ–‡ä»¶åœ°å€ï¼ŒDataInterpreterè®¿é—®æ–‡ä»¶è¿›è¡Œå¯è§†åŒ–ï¼Œæˆ‘å¸Œæœ›ç”¨å¦‚ä¸‹ä»£ç \n    team.hire(\n        [\n            Researcher(),\n            DataInterpreter(),\n        ]\nè¿™å¯ä»¥å®ç°å—",
      "state": "closed",
      "author": "chaos-max",
      "author_type": "User",
      "created_at": "2025-02-16T07:04:09Z",
      "updated_at": "2025-04-03T00:32:46Z",
      "closed_at": "2025-04-03T00:32:45Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1696/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1696",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1696",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:08.541707",
      "comments": [
        {
          "author": "seehi",
          "body": "å½“å‰ç‰ˆæœ¬è¦å®ç°çš„è¯ï¼Œè§’è‰²DataInterpreterè¦watchè§’è‰²Researcherçš„actionã€‚å¯å…³æ³¨åç»­çš„ç‰ˆæœ¬æ›´æ–°ã€‚",
          "created_at": "2025-02-17T04:01:45Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-20T00:31:45Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-04-03T00:32:44Z"
        }
      ]
    },
    {
      "issue_number": 1690,
      "title": "MetaGPT åœ¨ modelscope ç¯å¢ƒä¸­å‡ºç°è¿™æ ·çš„é—®é¢˜ï¼Œè¯»å– config è¯»å–ä¸åˆ°",
      "body": "<img width=\"2002\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/5e41a8c1-9a54-47d8-a670-0354f7a34d85\" />\n\n<img width=\"937\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/3e4d46b8-21e7-429d-a467-74aa86a1b91c\" />",
      "state": "closed",
      "author": "WangLaoShi",
      "author_type": "User",
      "created_at": "2025-02-12T09:34:51Z",
      "updated_at": "2025-04-03T00:32:46Z",
      "closed_at": "2025-04-03T00:32:46Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1690/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1690",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1690",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:08.772034",
      "comments": [
        {
          "author": "WangLaoShi",
          "body": "åœ¨ Google Colab ä¸Šï¼Œä¹Ÿä¼šå­˜åœ¨ä½¿ç”¨çš„é—®é¢˜\n\n<img width=\"1519\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/708a42de-830d-48b8-93d1-1ad521ded9bc\" />\n\næ²¡æœ‰åŠæ³•ç¼–è¾‘ `config2.yml`ï¼Œæ‰€ä»¥ï¼Œæ˜¯ä¸æ˜¯æœ‰åŠæ³•è‡ªå·±å®šä¹‰è¿™ä¸ªæ–‡ä»¶çš„ä½ç½®å‘¢ã€‚",
          "created_at": "2025-02-12T09:50:07Z"
        },
        {
          "author": "seehi",
          "body": "ä¸€ç§æ–¹æ³•æ˜¯ä¿®æ”¹å…¨å±€å˜é‡CONFIG_ROOT\n```python\nimport metagpt.const\n\nmetagpt.const.CONFIG_ROOT = \"config2.ymlæ–‡ä»¶çš„ç›®å½•\"\n```",
          "created_at": "2025-02-13T06:26:02Z"
        },
        {
          "author": "LiangMiSan",
          "body": "è¿™ä¸ªé—®é¢˜æˆ‘ä¹Ÿé‡åˆ°äº†ï¼Œæ˜¯å› ä¸ºæŠŠåç¼€å†™é”™äº†ï¼Œå°†â€.ymlâ€œæ”¹æˆ\".yaml\"å°±å¯ä»¥äº†",
          "created_at": "2025-02-17T06:39:48Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-20T00:31:47Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-04-03T00:32:46Z"
        }
      ]
    },
    {
      "issue_number": 1685,
      "title": "How to Use Third-Party Proxy with MetaGPT?",
      "body": "I have configured my parameters as follows:\n\n```yaml\napi_type: 'open_llm'  # or azure / ollama / open_llm etc. Check LLMType for more options\nmodel: \"gpt-4o-mini\"  # or gpt-3.5-turbo-1106 / gpt-4-1106-preview\napi_key: \"sk-xxx\"\nbase_url: \"https://xiaoai.plus/v1\"\n```\nOf course, I have also tried setting api_type to openai, but I keep encountering the following error:\n\n`metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 92.768(s), this was the 6th time calling it. exp: openai.types.completion_usage.CompletionUsage() argument after ** must be a mapping, not NoneType`\n\nIs it possible that the issue arises from the use of a third-party proxy?",
      "state": "closed",
      "author": "jingyaolliu",
      "author_type": "User",
      "created_at": "2025-02-08T10:24:46Z",
      "updated_at": "2025-04-01T00:38:08Z",
      "closed_at": "2025-04-01T00:38:08Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1685/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1685",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1685",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:09.047505",
      "comments": [
        {
          "author": "seehi",
          "body": "[Supported LLMs](https://docs.deepwisdom.ai/main/en/guide/get_started/configuration/llm_api_configuration.html)",
          "created_at": "2025-02-12T09:12:07Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-15T00:31:35Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-04-01T00:38:07Z"
        }
      ]
    },
    {
      "issue_number": 1693,
      "title": "When running metagpt with Ollama Mistral, I face errors TypeError: 'async for' requires an object with __aiter__ method, got bytes",
      "body": "I used conda to metagpt and so I dont know how to find the source code and edit it. \n2025-02-13 20:37:01.345 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 29.328(s), this was the 6th time calling it. exp: 'async for' requires an object with __aiter__ method, got bytes\n2025-02-13 20:37:01.347 | WARNING  | metagpt.utils.common:wrapper:649 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.\n2025-02-13 20:37:01.379 | ERROR    | metagpt.utils.common:wrapper:631 - Exception occurs, start to serialize the project, exp:\nTraceback (most recent call last):\n  File \"C:\\Users\\Naveen Raam V\\anaconda3\\envs\\metagpt\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n    result = await fn(*args, **kwargs)\n  File \"C:\\Users\\Naveen Raam V\\anaconda3\\envs\\metagpt\\lib\\site-packages\\metagpt\\actions\\action_node.py\", line 420, in _aask_v1\n    content = await self.llm.aask(prompt, system_msgs, images=images, timeout=timeout)\nTypeError: 'async for' requires an object with __aiter__ method, got bytes\n\nThis is the detailed error message I have received. ",
      "state": "closed",
      "author": "naveen-raam",
      "author_type": "User",
      "created_at": "2025-02-13T15:46:12Z",
      "updated_at": "2025-03-31T00:35:26Z",
      "closed_at": "2025-03-31T00:35:25Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1693/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1693",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1693",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:09.238005",
      "comments": [
        {
          "author": "naveen-raam",
          "body": "Please provide me solutions on how to handle the issues in latest version. I used conda, so please point out how to change the source code if the solution needs it. ",
          "created_at": "2025-02-13T15:48:42Z"
        },
        {
          "author": "seehi",
          "body": "#1218 ",
          "created_at": "2025-02-14T09:10:27Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-17T00:33:54Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-31T00:35:24Z"
        }
      ]
    },
    {
      "issue_number": 1691,
      "title": "è¿è¡Œç‹¼äººæ€å<class 'pydantic._internal._model_construction.ModelMetaclass'>",
      "body": "**windowsç¯å¢ƒè¿è¡Œç‹¼äººæ€åä¸€æ®µå¯¹è¯æŠ¥é”™**\n```2025-02-13 20:11:20.007 | ERROR    | metagpt.utils.common:wrapper:631 - Exception occurs, start to serialize the project, exp:\nTraceback (most recent call last):\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n    result = await fn(*args, **kwargs)\n  File \"E:\\Project_python\\llm_related\\knowledge_distillation_llm\\Agent\\werewolf\\actions\\common_actions.py\", line 237, in run\n    rsp = await self._aask(prompt)\nTypeError: openai.types.completion_usage.CompletionUsage() argument after ** must be a mapping, not CompletionUsage\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\metagpt\\utils\\common.py\", line 640, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\metagpt\\roles\\role.py\", line 550, in run\n    rsp = await self.react()\ntenacity.RetryError: RetryError[<Future at 0x1e8ddda8b80 state=finished raised TypeError>]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\metagpt\\utils\\common.py\", line 626, in wrapper\n    result = await func(self, *args, **kwargs)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\metagpt\\team.py\", line 134, in run\n    await self.env.run()\nException: Traceback (most recent call last):\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n    result = await fn(*args, **kwargs)\n  File \"E:\\Project_python\\llm_related\\knowledge_distillation_llm\\Agent\\werewolf\\actions\\common_actions.py\", line 237, in run\n    rsp = await self._aask(prompt)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\metagpt\\actions\\action.py\", line 93, in _aask\n    return await self.llm.aask(prompt, system_msgs)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\metagpt\\provider\\base_llm.py\", line 150, in aask\n    rsp = await self.acompletion_text(message, stream=stream, timeout=self.get_timeout(timeout))\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n    return await fn(*args, **kwargs)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n    return fut.result()\n  File \"D:\\ProgramData\\envs\\agent\\lib\\concurrent\\futures\\_base.py\", line 439, in result\n    return self.__get_result()\n  File \"D:\\ProgramData\\envs\\agent\\lib\\concurrent\\futures\\_base.py\", line 391, in __get_result\n    raise self._exception\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n    result = await fn(*args, **kwargs)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\metagpt\\provider\\openai_api.py\", line 141, in acompletion_text\n    return await self._achat_completion_stream(messages, timeout=timeout)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\metagpt\\provider\\openai_api.py\", line 94, in _achat_completion_stream\n    usage = CompletionUsage(**chunk.usage)\nTypeError: openai.types.completion_usage.CompletionUsage() argument after ** must be a mapping, not CompletionUsage\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\metagpt\\utils\\common.py\", line 640, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\metagpt\\roles\\role.py\", line 550, in run\n    rsp = await self.react()\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\metagpt\\roles\\role.py\", line 517, in react\n    rsp = await self._react()\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\metagpt\\roles\\role.py\", line 463, in _react\n    rsp = await self._act()\n  File \"E:\\Project_python\\llm_related\\knowledge_distillation_llm\\Agent\\werewolf\\roles\\base_player.py\", line 101, in _act\n    await Reflect().run(\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n    return await fn(*args, **kwargs)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\tenacity\\__init__.py\", line 326, in iter\n    raise retry_exc from fut.exception()\ntenacity.RetryError: RetryError[<Future at 0x1e8ddda8b80 state=finished raised TypeError>]\n\n\nTraceback (most recent call last):\n  File \"E:\\Project_python\\llm_related\\knowledge_distillation_llm\\Agent\\werewolf\\start_game.py\", line 68, in <module>\n    fire.Fire(main)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\fire\\core.py\", line 141, in Fire\n    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\fire\\core.py\", line 466, in _Fire\n    component, remaining_args = _CallAndUpdateTrace(\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\fire\\core.py\", line 681, in _CallAndUpdateTrace\n    component = fn(*varargs, **kwargs)\n  File \"E:\\Project_python\\llm_related\\knowledge_distillation_llm\\Agent\\werewolf\\start_game.py\", line 53, in main\n    asyncio.run(\n  File \"D:\\ProgramData\\envs\\agent\\lib\\asyncio\\runners.py\", line 44, in run\n    return loop.run_until_complete(main)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\asyncio\\base_events.py\", line 647, in run_until_complete\n    return future.result()\n  File \"E:\\Project_python\\llm_related\\knowledge_distillation_llm\\Agent\\werewolf\\start_game.py\", line 40, in start_game\n    await game.run(n_round=n_round)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\metagpt\\utils\\common.py\", line 632, in wrapper\n    self.serialize()  # Team.serialize\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\metagpt\\team.py\", line 60, in serialize\n    write_json_file(team_info_path, self.model_dump())\n  File \"D:\\ProgramData\\envs\\agent\\lib\\site-packages\\metagpt\\utils\\common.py\", line 581, in write_json_file\n    json.dump(data, fout, ensure_ascii=False, indent=indent, default=to_jsonable_python)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\json\\__init__.py\", line 179, in dump\n    for chunk in iterable:\n  File \"D:\\ProgramData\\envs\\agent\\lib\\json\\encoder.py\", line 431, in _iterencode\n    yield from _iterencode_dict(o, _current_indent_level)\n  File \"D:\\ProgramData\\envs\\agent\\lib\\json\\encoder.py\", line 405, in _iterencode_dict\n    yield from chunks\n  File \"D:\\ProgramData\\envs\\agent\\lib\\json\\encoder.py\", line 405, in _iterencode_dict\n    yield from chunks\n  File \"D:\\ProgramData\\envs\\agent\\lib\\json\\encoder.py\", line 405, in _iterencode_dict\n    yield from chunks\n  [Previous line repeated 1 more time]\n  File \"D:\\ProgramData\\envs\\agent\\lib\\json\\encoder.py\", line 325, in _iterencode_list\n    yield from chunks\n  File \"D:\\ProgramData\\envs\\agent\\lib\\json\\encoder.py\", line 438, in _iterencode\n    o = _default(o)\npydantic_core._pydantic_core.PydanticSerializationError: Unable to serialize unknown type: <class 'pydantic._internal._model_construction.ModelMetaclass'>\n\n**Screenshots or logs**\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\n",
      "state": "closed",
      "author": "QiXingRan",
      "author_type": "User",
      "created_at": "2025-02-13T12:12:21Z",
      "updated_at": "2025-03-31T00:35:26Z",
      "closed_at": "2025-03-31T00:35:26Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1691/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1691",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1691",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:09.440461",
      "comments": [
        {
          "author": "Terrdi",
          "body": "æˆ‘ä¿®å¤äº†è¿™ä¸ªbug,ä½†æ˜¯è¿˜æ²¡æœ‰merge\nhttps://github.com/Terrdi/MetaGPT/tree/fix-serialize-error\nä½ è¯•è¯•è¿™ä¸ªåˆ†æ”¯å‘¢",
          "created_at": "2025-02-14T11:00:13Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-17T00:33:55Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-31T00:35:25Z"
        }
      ]
    },
    {
      "issue_number": 1687,
      "title": "è‡ªç ”æ¨ç†å¼•æ“æ€§èƒ½é—®é¢˜",
      "body": "æˆ‘ä»¬è‡ªç ”çš„æ¨ç†å¼•æ“æ˜¯åŸºäºvllmåšäº†æ·±åº¦ä¼˜åŒ–çš„ï¼Œä½†æ˜¯ç”¨metagptè·‘2048æ¸¸æˆæ¯”vllmæ…¢äº†ä¸ƒå…«åˆ†é’Ÿï¼Œè¿™æ˜¯å“ªçš„é—®é¢˜å‘¢ï¼Œç†è®ºä¸Šè®²æ˜¯åº”è¯¥æ¯”vllmæ›´å¿«çš„",
      "state": "closed",
      "author": "zainlau",
      "author_type": "User",
      "created_at": "2025-02-10T11:45:18Z",
      "updated_at": "2025-03-30T00:36:14Z",
      "closed_at": "2025-03-30T00:36:14Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1687/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1687",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1687",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:09.664137",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-13T00:32:22Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-30T00:36:13Z"
        }
      ]
    },
    {
      "issue_number": 1722,
      "title": "Release artifacts (models, dataset) on Hugging Face",
      "body": "Hi @better629 ğŸ¤—\n\nNiels here from the open-source team at Hugging Face. I discovered your work through Hugging Face's daily papers as yours got featured: https://huggingface.co/papers/2410.10762.\nThe paper page lets people discuss about your paper and lets them find artifacts about it (your models, datasets or demo for instance), you can also claim\nthe paper as yours which will show up on your public profile at HF.\n\nIt'd be great to make the model and any relevant datasets available on the ğŸ¤— hub, to improve their discoverability/visibility.\nWe can add tags so that people find them when filtering https://huggingface.co/models and https://huggingface.co/datasets.\n\n## Uploading models\n\nSee here for a guide: https://huggingface.co/docs/hub/models-uploading. \n\nIn this case, we could leverage the [PyTorchModelHubMixin](https://huggingface.co/docs/huggingface_hub/package_reference/mixins#huggingface_hub.PyTorchModelHubMixin) class which adds `from_pretrained` and `push_to_hub` to any custom `nn.Module`. Alternatively, one can leverages the [hf_hub_download](https://huggingface.co/docs/huggingface_hub/en/guides/download#download-a-single-file) one-liner to download a checkpoint from the hub. \n\nWe encourage researchers to push each model checkpoint to a separate model repository, so that things like download stats also work. We can then also link the checkpoints to the paper page.\n\n## Uploading dataset\n\nWould be awesome to make the dataset available on ğŸ¤— , so that people can do:\n\n```python\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"your-hf-org-or-username/your-dataset\")\n```\nSee here for a guide: https://huggingface.co/docs/datasets/loading.\n\nBesides that, there's the [dataset viewer](https://huggingface.co/docs/hub/en/datasets-viewer) which allows people to quickly explore the first few rows of the data in the browser.\n\nLet me know if you're interested/need any help regarding this!\n\nCheers,\n\nNiels\nML Engineer @ HF ğŸ¤—",
      "state": "closed",
      "author": "NielsRogge",
      "author_type": "User",
      "created_at": "2025-02-26T10:21:39Z",
      "updated_at": "2025-03-29T12:39:46Z",
      "closed_at": "2025-03-29T12:39:46Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1722/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 1,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1722",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1722",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:10.941027",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-29T00:32:24Z"
        }
      ]
    },
    {
      "issue_number": 1681,
      "title": "Baidu_Qianfan needs base_url in Config",
      "body": "**Bug description**\nI have read document of Config,[https://docs.deepwisdom.ai/main/zh/guide/get_started/configuration/llm_api_configuration.html]\n\nwhich said:\n\n![Image](https://github.com/user-attachments/assets/496ae28d-c12d-4de1-91a8-86da3e3e9b06)\n\n\nIf I set these config parameters as same as above, request or url will use default base url:\n\n![Image](https://github.com/user-attachments/assets/dc25cc1d-9e8d-4407-8824-985810a4eccb)\n\n**Bug solved method**\n1. \n![Image](https://github.com/user-attachments/assets/4457335f-40f3-48a9-9f2d-7dd827f9799f)\n\nMay be extract to a abstract function or other way.\n\n2. If I add base_url in Config2.yaml, that will be right. But add the description into document.\n\n**Environment information**\n<!-- Environmentï¼šSystem version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\n\n- LLM type and model name:\n- System version: Ubuntu 24.04\n- Python version: 3.11\n- MetaGPT version or branch: git main branch\n\n<!-- Dependent packagessï¼šthe packages version cause the bug(like `pydantic 1.10.8`), installation methodï¼ˆlike `pip install metagpt` or `pip install from source` or `run in docker`ï¼‰ -->\n\n- packages version:\n- installation method: \n\n**Screenshots or logs**\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\n",
      "state": "closed",
      "author": "peterxia-chn",
      "author_type": "User",
      "created_at": "2025-01-31T03:24:07Z",
      "updated_at": "2025-03-23T00:35:27Z",
      "closed_at": "2025-03-23T00:35:26Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1681/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1681",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1681",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:11.196826",
      "comments": [
        {
          "author": "Terrdi",
          "body": "I configured base_url such as \n\n base_url: \"https://qianfan.baidubce.com/v2\"\n\nthen it works.",
          "created_at": "2025-02-06T07:51:14Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-09T00:28:39Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-23T00:35:26Z"
        }
      ]
    },
    {
      "issue_number": 1701,
      "title": "ModuleNotFoundError: No module named 'semantic_kernel.orchestration'",
      "body": "I encountered a ModuleNotFoundError when trying to use Semantic Kernel. The error message is as follows:\n![Image](https://github.com/user-attachments/assets/9429eb34-7609-4f57-b233-ada7480566be)\nMy Enviroment:\nOS: Windows 11\nPython Version: 3.12\nSemantic Kernel Version: 1.21.1\n![Image](https://github.com/user-attachments/assets/aa9b33d1-4350-475e-881c-168c8285e627)\n",
      "state": "closed",
      "author": "yuhua88",
      "author_type": "User",
      "created_at": "2025-02-19T00:52:54Z",
      "updated_at": "2025-03-22T01:17:24Z",
      "closed_at": "2025-03-22T01:17:24Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1701/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1701",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1701",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:11.416807",
      "comments": [
        {
          "author": "seehi",
          "body": "\"semantic-kernel==0.4.3.dev0\" in the [requirements.txt](https://github.com/geekan/MetaGPT/blob/main/requirements.txt#L44), try python3.9/3.10/3.11",
          "created_at": "2025-02-19T08:21:16Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-22T00:31:39Z"
        }
      ]
    },
    {
      "issue_number": 1684,
      "title": "about memory",
      "body": "When will it be updated: \n[doc](https://docs.deepwisdom.ai/main/en/guide/in_depth_guides/memory.html)",
      "state": "closed",
      "author": "philogos",
      "author_type": "User",
      "created_at": "2025-02-05T13:03:32Z",
      "updated_at": "2025-03-22T00:31:44Z",
      "closed_at": "2025-03-22T00:31:44Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1684/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1684",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1684",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:11.651379",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-08T00:25:40Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-22T00:31:43Z"
        }
      ]
    },
    {
      "issue_number": 1666,
      "title": "Can MetaGPT still running on colab?",
      "body": "**Bug description**\r\n\r\nRun the example Colab on Quickstart and install it using `!pip install --upgrade metagpt.`\r\nBut got some error.\r\n\r\n**Bug solved method**\r\n\r\nhttps://colab.research.google.com/drive/1xlReN7EIpKzgZO1If29-zsw7QNUUfEbx?usp=sharing\r\n\r\n**Environment information**\r\n<!-- Environmentï¼šSystem version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\r\n\r\n- LLM type and model name: `gpt-4-1106-preview`\r\n- System version: `colab`\r\n- Python version:  `3.10.12`\r\n- MetaGPT version or branch: `newest`\r\n\r\n<!-- Dependent packagessï¼šthe packages version cause the bug(like `pydantic 1.10.8`), installation methodï¼ˆlike `pip install metagpt` or `pip install from source` or `run in docker`ï¼‰ -->\r\n\r\n- packages version:\r\n- installation method:  `!pip install --upgrade metagpt`\r\n\r\n**Screenshots or logs**\r\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\r\n\r\n> 2025-01-13 13:21:18.135 | INFO     | metagpt.team:invest:90 - Investment: $3.0.\r\n> 2025-01-13 13:21:18.142 | INFO     | metagpt.roles.role:_act:391 - Alice(Product Manager): to do PrepareDocuments(PrepareDocuments)\r\n> 2025-01-13 13:21:18.176 | INFO     | metagpt.utils.file_repository:save:57 - save to: /usr/local/lib/python3.10/dist-packages/workspace/20250113132118/docs/requirement.txt\r\n> 2025-01-13 13:21:18.182 | INFO     | metagpt.roles.role:_act:391 - Alice(Product Manager): to do WritePRD(WritePRD)\r\n> 2025-01-13 13:21:18.187 | INFO     | metagpt.actions.write_prd:run:86 - New requirement detected: write a 2048 game\r\n> 2025-01-13 13:21:26.995 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 8.805(s), this was the 1st time calling it. exp: 400 Unknown error trying to retrieve streaming response. Please retry with `stream=False` for more details.\r\n> 2025-01-13 13:21:35.140 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 16.950(s), this was the 2nd time calling it. exp: 400 Unknown error trying to retrieve streaming response. Please retry with `stream=False` for more details.\r\n> 2025-01-13 13:21:44.283 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 26.093(s), this was the 3rd time calling it. exp: 400 Unknown error trying to retrieve streaming response. Please retry with `stream=False` for more details.\r\n> 2025-01-13 13:21:49.758 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 31.568(s), this was the 4th time calling it. exp: 400 Unknown error trying to retrieve streaming response. Please retry with `stream=False` for more details.\r\n> 2025-01-13 13:22:01.147 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 42.957(s), this was the 5th time calling it. exp: 400 Unknown error trying to retrieve streaming response. Please retry with `stream=False` for more details.\r\n> 2025-01-13 13:22:19.540 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 61.350(s), this was the 6th time calling it. exp: 400 Unknown error trying to retrieve streaming response. Please retry with `stream=False` for more details.\r\n> 2025-01-13 13:22:19.541 | WARNING  | metagpt.utils.common:wrapper:649 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.\r\n> 2025-01-13 13:22:19.554 | ERROR    | metagpt.utils.common:wrapper:631 - Exception occurs, start to serialize the project, exp:\r\n> Traceback (most recent call last):\r\n>   File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/types/generation_types.py\", line 385, in rewrite_stream_error\r\n>     yield\r\n>   File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 263, in generate_content_async\r\n>     iterator = await self._async_client.stream_generate_content(\r\n> AttributeError: 'ResponseIterator' object has no attribute '__await__'. Did you mean: '__init__'?\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"/usr/local/lib/python3.10/dist-packages/tenacity/_asyncio.py\", line 50, in __call__\r\n>     result = await fn(*args, **kwargs)\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/actions/action_node.py\", line 420, in _aask_v1\r\n>     content = await self.llm.aask(prompt, system_msgs, images=images, timeout=timeout)\r\n> google.api_core.exceptions.BadRequest: 400 Unknown error trying to retrieve streaming response. Please retry with `stream=False` for more details.\r\n> \r\n> The above exception was the direct cause of the following exception:\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/utils/common.py\", line 640, in wrapper\r\n>     return await func(self, *args, **kwargs)\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/roles/role.py\", line 550, in run\r\n>     rsp = await self.react()\r\n> tenacity.RetryError: RetryError[<Future at 0x7848cbac7820 state=finished raised BadRequest>]\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/utils/common.py\", line 626, in wrapper\r\n>     result = await func(self, *args, **kwargs)\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/team.py\", line 134, in run\r\n>     await self.env.run()\r\n> Exception: Traceback (most recent call last):\r\n>   File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/types/generation_types.py\", line 385, in rewrite_stream_error\r\n>     yield\r\n>   File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 263, in generate_content_async\r\n>     iterator = await self._async_client.stream_generate_content(\r\n>   File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary_async.py\", line 230, in retry_wrapped_func\r\n>     return await retry_target(\r\n>   File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary_async.py\", line 160, in retry_target\r\n>     _retry_error_helper(\r\n>   File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\r\n>     raise final_exc from source_exc\r\n>   File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary_async.py\", line 155, in retry_target\r\n>     return await target()\r\n>   File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers_async.py\", line 85, in __await__\r\n>     response = yield from self._call.__await__()\r\n> AttributeError: 'ResponseIterator' object has no attribute '__await__'. Did you mean: '__init__'?\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"/usr/local/lib/python3.10/dist-packages/tenacity/_asyncio.py\", line 50, in __call__\r\n>     result = await fn(*args, **kwargs)\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/actions/action_node.py\", line 420, in _aask_v1\r\n>     content = await self.llm.aask(prompt, system_msgs, images=images, timeout=timeout)\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/provider/base_llm.py\", line 150, in aask\r\n>     rsp = await self.acompletion_text(message, stream=stream, timeout=self.get_timeout(timeout))\r\n>   File \"/usr/local/lib/python3.10/dist-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\r\n>     return await fn(*args, **kwargs)\r\n>   File \"/usr/local/lib/python3.10/dist-packages/tenacity/_asyncio.py\", line 47, in __call__\r\n>     do = self.iter(retry_state=retry_state)\r\n>   File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 314, in iter\r\n>     return fut.result()\r\n>   File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\r\n>     return self.__get_result()\r\n>   File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\r\n>     raise self._exception\r\n>   File \"/usr/local/lib/python3.10/dist-packages/tenacity/_asyncio.py\", line 50, in __call__\r\n>     result = await fn(*args, **kwargs)\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/provider/base_llm.py\", line 200, in acompletion_text\r\n>     return await self._achat_completion_stream(messages, timeout=self.get_timeout(timeout))\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/provider/google_gemini_api.py\", line 141, in _achat_completion_stream\r\n>     resp: AsyncGenerateContentResponse = await self.llm.generate_content_async(\r\n>   File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 262, in generate_content_async\r\n>     with generation_types.rewrite_stream_error():\r\n>   File \"/usr/lib/python3.10/contextlib.py\", line 153, in __exit__\r\n>     self.gen.throw(typ, value, traceback)\r\n>   File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/types/generation_types.py\", line 387, in rewrite_stream_error\r\n>     raise google.api_core.exceptions.BadRequest(\r\n> google.api_core.exceptions.BadRequest: 400 Unknown error trying to retrieve streaming response. Please retry with `stream=False` for more details.\r\n> \r\n> The above exception was the direct cause of the following exception:\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/utils/common.py\", line 640, in wrapper\r\n>     return await func(self, *args, **kwargs)\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/roles/role.py\", line 550, in run\r\n>     rsp = await self.react()\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/roles/role.py\", line 517, in react\r\n>     rsp = await self._react()\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/roles/role.py\", line 463, in _react\r\n>     rsp = await self._act()\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/roles/role.py\", line 392, in _act\r\n>     response = await self.rc.todo.run(self.rc.history)\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/actions/write_prd.py\", line 87, in run\r\n>     return await self._handle_new_requirement(req)\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/actions/write_prd.py\", line 108, in _handle_new_requirement\r\n>     node = await WRITE_PRD_NODE.fill(context=context, llm=self.llm, exclude=exclude)  # schema=schema\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/actions/action_node.py\", line 505, in fill\r\n>     return await self.simple_fill(schema=schema, mode=mode, images=images, timeout=timeout, exclude=exclude)\r\n>   File \"/usr/local/lib/python3.10/dist-packages/metagpt/actions/action_node.py\", line 457, in simple_fill\r\n>     content, scontent = await self._aask_v1(\r\n>   File \"/usr/local/lib/python3.10/dist-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\r\n>     return await fn(*args, **kwargs)\r\n>   File \"/usr/local/lib/python3.10/dist-packages/tenacity/_asyncio.py\", line 47, in __call__\r\n>     do = self.iter(retry_state=retry_state)\r\n>   File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 326, in iter\r\n>     raise retry_exc from fut.exception()\r\n> tenacity.RetryError: RetryError[<Future at 0x7848cbac7820 state=finished raised BadRequest>]",
      "state": "closed",
      "author": "HiHelloTW",
      "author_type": "User",
      "created_at": "2025-01-13T14:06:46Z",
      "updated_at": "2025-03-21T00:32:28Z",
      "closed_at": "2025-03-21T00:32:28Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1666/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1666",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1666",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:11.861511",
      "comments": [
        {
          "author": "iorisa",
          "body": "Based on the log `/usr/local/lib/python3.10/dist-packages/metagpt/provider/google_gemini_api.py`, I infer that you are probably using the Gemini model instead of `gpt-4-1106-preview`. \nCould you please post your `config2.yaml` configuration?",
          "created_at": "2025-01-16T13:53:48Z"
        },
        {
          "author": "HiHelloTW",
          "body": "Oh! Thanks, it worked after I adjusted my `config2.yaml`.",
          "created_at": "2025-02-03T14:51:53Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-06T00:31:50Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-21T00:32:28Z"
        }
      ]
    },
    {
      "issue_number": 1674,
      "title": "Pip install error",
      "body": "**Bug description**\nI am facing the following issue when I try to do pip install on my \n\nPS C:\\Users\\jawwa\\Downloads\\AI Agents> pip install metagpt\nCollecting metagpt\n  Using cached metagpt-0.8.1-py3-none-any.whl.metadata (15 kB)\nCollecting aiohttp==3.8.6 (from metagpt)\n  Using cached aiohttp-3.8.6.tar.gz (7.4 MB)\n  Installing build dependencies ... done\n  Getting requirements to build wheel ... done\n  Preparing metadata (pyproject.toml) ... done\nCollecting channels==4.0.0 (from metagpt)\n  Using cached channels-4.0.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting faiss-cpu==1.7.4 (from metagpt)\n  Using cached faiss-cpu-1.7.4.tar.gz (57 kB)\n  Installing build dependencies ... done\n  Getting requirements to build wheel ... done\n  Preparing metadata (pyproject.toml) ... done\nCollecting fire==0.4.0 (from metagpt)\n  Using cached fire-0.4.0.tar.gz (87 kB)\n  Preparing metadata (setup.py) ... done\nCollecting typer==0.9.0 (from metagpt)\n  Using cached typer-0.9.0-py3-none-any.whl.metadata (14 kB)\nCollecting lancedb==0.4.0 (from metagpt)\n  Using cached lancedb-0.4.0-py3-none-any.whl.metadata (16 kB)\nCollecting loguru==0.6.0 (from metagpt)\n  Using cached loguru-0.6.0-py3-none-any.whl.metadata (21 kB)\nCollecting meilisearch==0.21.0 (from metagpt)\n  Using cached meilisearch-0.21.0-py3-none-any.whl.metadata (8.8 kB)\nCollecting numpy==1.24.3 (from metagpt)\n  Using cached numpy-1.24.3.tar.gz (10.9 MB)\n  Installing build dependencies ... done\n  Getting requirements to build wheel ... error\n  error: subprocess-exited-with-error\n\n  Ã— Getting requirements to build wheel did not run successfully.\n  â”‚ exit code: 1\n  â•°â”€> [33 lines of output]\n      Traceback (most recent call last):\n        File \"C:\\Users\\jawwa\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n          main()\n        File \"C:\\Users\\jawwa\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n          json_out['return_val'] = hook(**hook_input['kwargs'])\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        File \"C:\\Users\\jawwa\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 112, in get_requires_for_build_wheel\n          backend = _build_backend()\n                    ^^^^^^^^^^^^^^^^\n        File \"C:\\Users\\jawwa\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 77, in _build_backend\n          obj = import_module(mod_path)\n                ^^^^^^^^^^^^^^^^^^^^^^^\n        File \"C:\\Users\\jawwa\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n          return _bootstrap._gcd_import(name[level:], package, level)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n        File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n        File \"<frozen importlib._bootstrap>\", line 1310, in _find_and_load_unlocked\n        File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n        File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n        File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n        File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n        File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n        File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n        File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n        File \"C:\\Users\\jawwa\\AppData\\Local\\Temp\\pip-build-env-kdnmwm9n\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\", line 16, in <module>\n          import setuptools.version\n        File \"C:\\Users\\jawwa\\AppData\\Local\\Temp\\pip-build-env-kdnmwm9n\\overlay\\Lib\\site-packages\\setuptools\\version.py\", line 1, in <module>\n          import pkg_resources\n        File \"C:\\Users\\jawwa\\AppData\\Local\\Temp\\pip-build-env-kdnmwm9n\\overlay\\Lib\\site-packages\\pkg_resources\\__init__.py\", line 2172, in <module>\n          register_finder(pkgutil.ImpImporter, find_on_path)\n                          ^^^^^^^^^^^^^^^^^^^\n      AttributeError: module 'pkgutil' has no attribute 'ImpImporter'. Did you mean: 'zipimporter'?\n      [end of output]\n\n  note: This error originates from a subprocess, and is likely not a problem with pip.\nerror: subprocess-exited-with-error\n\nÃ— Getting requirements to build wheel did not run successfully.\nâ”‚ exit code: 1\nâ•°â”€> See above for output.\n\nnote: This error originates from a subprocess, and is likely not a problem with pip.\n\nPS C:\\Users\\jawwa\\Downloads\\AI Agents> pip show metagpt\n\nWARNING: Package(s) not found: metagpt\n\nWhat do  I do to install it properly?\n",
      "state": "closed",
      "author": "jawwad-ahmed2809",
      "author_type": "User",
      "created_at": "2025-01-21T02:06:42Z",
      "updated_at": "2025-03-20T00:31:50Z",
      "closed_at": "2025-03-20T00:31:49Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1674/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1674",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1674",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:12.070720",
      "comments": [
        {
          "author": "iorisa",
          "body": "You need to first install a Linux OS simulator, such as MinGW or Cygwin, and then install MetaGPT.",
          "created_at": "2025-01-21T02:11:44Z"
        },
        {
          "author": "peterxia-chn",
          "body": "The version of Python should be >=3.9 and <=3.11, I have used 3.12 , faced the same question.",
          "created_at": "2025-02-03T01:19:50Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-06T00:31:47Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-20T00:31:49Z"
        }
      ]
    },
    {
      "issue_number": 149,
      "title": "MetaGPT and possible enhancements",
      "body": "I have used your interesting software and it produces very nice output.\r\nI propose these possible ehancements.\r\n1) To provide the possibility, in an iterative fashion, to enhance the software product itself and update all it's architectural views and implementation details until the user stop this iteration.\r\n2) To save checkpoints of such iteration with some versioning control\r\n3) To provide the possibility to restart the iteration from the last checkpoint saved\r\n4) To analyze the code produced and identify any possible manual modification as a part of the produced software lifecycle itself\r\n\r\nFirstly point 1.\r\n\r\nOther points are more complex.",
      "state": "closed",
      "author": "gnovelli",
      "author_type": "User",
      "created_at": "2023-08-08T07:28:04Z",
      "updated_at": "2025-03-19T00:32:23Z",
      "closed_at": "2025-03-19T00:32:23Z",
      "labels": [
        "enhancement",
        "inactive"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/149/reactions",
        "total_count": 5,
        "+1": 5,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/149",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/149",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:12.248109",
      "comments": [
        {
          "author": "voidking",
          "body": "Good suggestion, thanks a lot. We will take it into consideration. Some of your suggestions are in the roadmap.",
          "created_at": "2023-08-09T02:16:33Z"
        },
        {
          "author": "gnovelli",
          "body": "To make the software development cycle iterative and integrate agents that examine and modify the code, you can adopt an approach similar to the Agile development model. Here's a possible solution:\r\n\r\n1. **Phase Definition**:\r\n\r\n    a. **Requirements**: Receive the description of the requirements fr",
          "created_at": "2023-08-12T10:54:14Z"
        },
        {
          "author": "geekan",
          "body": "Great idea, this is what we most want to do",
          "created_at": "2023-09-09T03:28:37Z"
        },
        {
          "author": "kripper",
          "body": "Any update on enhancing existing software products?",
          "created_at": "2024-03-04T03:55:05Z"
        },
        {
          "author": "iorisa",
          "body": "Well, the functionality to incrementally add requirements was already supported in version 0.6, and this feature was further enhanced in version 0.7. \r\nHowever, the incremental development mode indeed encountered some issues:\r\n1. Larger models tend to gradually lose track during the accumulation of ",
          "created_at": "2024-03-08T06:12:04Z"
        }
      ]
    },
    {
      "issue_number": 164,
      "title": "Limit error when running program",
      "body": "When running the program, I get the following error. Is there a way to resolve the limitations?\r\n\r\nopenai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4264 tokens (1264 in the messages, 3000 in the completion). Please reduce the length of the messages or completion.",
      "state": "closed",
      "author": "mandarin77",
      "author_type": "User",
      "created_at": "2023-08-08T17:41:09Z",
      "updated_at": "2025-03-19T00:32:22Z",
      "closed_at": "2025-03-19T00:32:22Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/164/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/164",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/164",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:12.449244",
      "comments": [
        {
          "author": "voidking",
          "body": "Modify the config in `config/key.yaml`.\r\n1. `OPENAI_API_MODEL` change to `gpt-3.5-turbo-16k` or `gpt-4`.\r\n2. `MAX_TOKENS` change to `5000`.",
          "created_at": "2023-08-09T03:14:23Z"
        },
        {
          "author": "mandarin77",
          "body": "Thank you for your response. I tried setting to turbo as you stated, and 5000 MAX_TOKENS, but I now get this error. Please advise and thanks for your help.\r\n\r\n    result = await fn(*args, **kwargs)\r\n  File \"C:\\MetaGPT\\metagpt\\actions\\action.py\", line 62, in _aask_v1\r\n    instruct_content = output_cl",
          "created_at": "2023-08-09T11:55:47Z"
        },
        {
          "author": "geekan",
          "body": "This problem actually comes from the poor Instruction Following of gpt-3.5-turbo. gpt-4 basically does not have this problem",
          "created_at": "2023-09-09T03:21:59Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-05T00:31:45Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-19T00:32:21Z"
        }
      ]
    },
    {
      "issue_number": 195,
      "title": "Doesn't produce anything close to working code for example \"cli snake game\" given in readme",
      "body": "Cool idea. Thanks for creating it. Interesting to try it out. However the example given in the readme doesn't lead to working code. Unfortunately it tries to instantiate classes without providing necessary properties.\r\n\r\nUsing chatgpt4 and code review. Unfortunately it doesn't seem suitable for any task.\r\n\r\nNote I don't think it is necessarily your fault. ChatGPT4 I think has gotten much worse.",
      "state": "closed",
      "author": "Benzidrine",
      "author_type": "User",
      "created_at": "2023-08-11T08:53:28Z",
      "updated_at": "2025-03-19T00:32:21Z",
      "closed_at": "2025-03-19T00:32:20Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/195/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/195",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/195",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:12.746974",
      "comments": [
        {
          "author": "voidking",
          "body": "Yes, we cannot guarantee that the generated code will work, it relies heavily on gpt. There is some work in the roadmap that may improve the success rate of the first run.",
          "created_at": "2023-08-12T08:38:19Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-05T00:31:43Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-19T00:32:20Z"
        }
      ]
    },
    {
      "issue_number": 249,
      "title": "create an HR role that can create roles as needed ",
      "body": "When a need arises for a specific skill or role that doesn't currently exist in the company (such as API Integration), a higher authority like the Project Manager or CEO could request the HR role to create that position, recruit an agent for it, and integrate it back into the project. Here's how you could implement this:\r\n\r\nStep 1: Define a Mechanism for Role Requests\r\nCreate a mechanism where roles like the Project Manager or CEO can request a new position. This could be a method in the HR role or a separate communication channel within the system.\r\n\r\npython\r\nCopy code\r\nclass HumanResources(Role):\r\n    # ...\r\n\r\n    def request_new_role(self, role_name, description, requester):\r\n        \"\"\"\r\n        Request a new role based on the company's needs.\r\n        \"\"\"\r\n        # Logic to handle the request for a new role\r\n        self.recruit_agent(role_name, description)\r\n        # Notify the requester (e.g., Project Manager, CEO) about the recruitment\r\nStep 2: Implement Recruitment and Integration\r\nIn the HR role, define methods to recruit a new agent for the requested role and integrate it into the existing project.\r\n\r\npython\r\nCopy code\r\n    def recruit_agent(self, role_name, description):\r\n        \"\"\"\r\n        Recruit a new agent and create the specified role.\r\n        \"\"\"\r\n        # Create a new role class if it doesn't exist\r\n        new_role = self.create_role(role_name, description)\r\n        # Create a new agent and assign the new role\r\n        new_agent = self.assign_role(new_role)\r\n        # Integrate the new agent into the project\r\n        self.integrate_agent(new_agent, role_name)\r\n\r\n    def integrate_agent(self, agent, role_name):\r\n        \"\"\"\r\n        Integrate the new agent into the existing project.\r\n        \"\"\"\r\n        # Logic to integrate the new agent into the project\r\nStep 3: Define New Roles Dynamically\r\nDepending on the design of the system, you may need a way to define new roles dynamically based on the request. This could involve creating new classes, configurations, or behaviors for the role.\r\n\r\npython\r\nCopy code\r\n    def create_role(self, role_name, description):\r\n        \"\"\"\r\n        Create a new role based on the given name and description.\r\n        \"\"\"\r\n        # Logic to define a new role dynamically\r\nStep 4: Coordinate with Existing Roles\r\nEnsure that existing roles like Project Manager, Architect, and Engineers can communicate with the HR role and that the new agent integrates smoothly into the existing workflow.\r\n\r\nConclusion\r\nThis approach adds a dynamic and responsive dimension to the MetaGPT project, allowing it to adapt to changing needs and requirements. It simulates how real-world companies identify needs, create new roles, recruit talents, and integrate them into ongoing projects.\r\n\r\nThe complexity of implementing this feature would depend on the existing architecture of the MetaGPT project and the level of realism and flexibility desired. It would likely involve careful design, integration, and testing to ensure that the new roles and agents behave as expected and enhance the overall functionality of the system.",
      "state": "closed",
      "author": "Aaronminer1",
      "author_type": "User",
      "created_at": "2023-08-18T16:40:56Z",
      "updated_at": "2025-03-18T00:32:05Z",
      "closed_at": "2025-03-18T00:32:04Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/249/reactions",
        "total_count": 6,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 3,
        "eyes": 1
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/249",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/249",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:12.965130",
      "comments": [
        {
          "author": "voidking",
          "body": "Good idea! We will think about it. Our current plan is to expand the capabilities of metagpt by accessing third-party roles.",
          "created_at": "2023-08-20T02:54:58Z"
        },
        {
          "author": "geekan",
          "body": "CEO -> raise JD -> HR -> generate role -> evaluate?",
          "created_at": "2023-09-09T03:05:51Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-04T00:31:38Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-18T00:32:04Z"
        }
      ]
    },
    {
      "issue_number": 260,
      "title": "M1 and metaGPT malfunction",
      "body": "It seems some issues occur when a computer with an M1 or M2 apple chip tries to set up metaGpt on their computer. Both my boss and I tried and ran into a lot of errors. Have you heard anything about this issue. Could you please help me figure out how to set it up? I need to test it and analyze it.",
      "state": "closed",
      "author": "mklimov24",
      "author_type": "User",
      "created_at": "2023-08-23T17:43:23Z",
      "updated_at": "2025-03-17T00:34:00Z",
      "closed_at": "2025-03-17T00:33:58Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/260/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/260",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/260",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:13.151456",
      "comments": [
        {
          "author": "voidking",
          "body": "Can you describe the details? For example, what command was executed and what error was reported.",
          "created_at": "2023-08-24T11:38:48Z"
        },
        {
          "author": "mklimov24",
          "body": "mirraklimov@Mirras-MacBook-Pro metagpt % python3 setup.py install\r\nrunning install\r\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-ba",
          "created_at": "2023-08-24T17:25:58Z"
        },
        {
          "author": "anmol098",
          "body": "+1",
          "created_at": "2023-08-30T09:56:11Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-03T00:33:10Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-17T00:33:58Z"
        }
      ]
    },
    {
      "issue_number": 300,
      "title": "Add support for Vertex AI",
      "body": "**_If you are looking for a powerful and affordable platform for text generation, I highly recommend Vertex AI._**\r\n\r\nVertex AI offers a variety of generative models, such as Text Bison, Chat Bison, Code Generation, Code Chat, and Code Completion. These models are fine-tuned for code generation, code chat, and code completion.\r\n\r\nThe pricing for Vertex AI generative models is very reasonable compared to OpenAI. You only pay for the input and output characters that you use, and the price per 1,000 characters is $0.0005 for most models.[Vertex AI Pricing](https://cloud.google.com/vertex-ai/pricing)\r\n\r\n[Vertex AI Code Models](https://cloud.google.com/vertex-ai/docs/generative-ai/code/code-models-overview)\r\n",
      "state": "closed",
      "author": "haseeb-heaven",
      "author_type": "User",
      "created_at": "2023-09-09T03:55:19Z",
      "updated_at": "2025-03-17T00:33:58Z",
      "closed_at": "2025-03-17T00:33:57Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/300/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/300",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/300",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:13.376158",
      "comments": [
        {
          "author": "geekan",
          "body": "Is there any paper or complete comparison document with OpenAI?",
          "created_at": "2023-09-09T07:06:41Z"
        },
        {
          "author": "haseeb-heaven",
          "body": "This [Medium Article](https://medium.com/google-cloud/generative-ai-pricing-openai-vs-google-cloud-8fe708a5636a) is only one i can find for reference now.",
          "created_at": "2023-09-09T10:12:48Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-03-03T00:33:09Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-17T00:33:57Z"
        }
      ]
    },
    {
      "issue_number": 1567,
      "title": "[Bug]: Rate Limit Exceeded in DDGAPIWrapper Search Function",
      "body": "## Describe the Bug\r\n\r\nThe original `DDGAPIWrapper` raises a `DuckDuckGoSearchException` due to exceeding DuckDuckGo API's rate limits. This prevents the application from retrieving search results effectively.\r\n\r\n### **Error Message**\r\n\r\n```python\r\nduckduckgo_search.exceptions.DuckDuckGoSearchException: _get_url() https://duckduckgo.com/ DuckDuckGoSearchException: Ratelimit\r\n```\r\n\r\n### **Steps to Reproduce**\r\n\r\n- Integrate the original `DDGAPIWrapper` class into your project.\r\n\r\n- Invoke the `run` method multiple times rapidly, for example:\r\n```python\r\npython -m metagpt.roles.researcher \"tensorflow vs. pytorch\r\n```\r\n\r\n- The application raises a `DuckDuckGoSearchException` with the message `Ratelimit`.\r\n\r\n**Sample Code of the original `DDGAPIWrapper`:**\r\n\r\n```python\r\nimport asyncio, json\r\nfrom concurrent import futures\r\nfrom typing import Literal, Optional, overload\r\nfrom pydantic import BaseModel, ConfigDict\r\nfrom duckduckgo_search import DDGS\r\n\r\nclass DDGAPIWrapper(BaseModel):\r\n    model_config = ConfigDict(arbitrary_types_allowed=True)\r\n    loop: Optional[asyncio.AbstractEventLoop] = None\r\n    executor: Optional[futures.Executor] = None\r\n    proxy: Optional[str] = None\r\n\r\n    @property\r\n    def ddgs(self):\r\n        return DDGS(proxies=self.proxy)\r\n\r\n    @overload\r\n    def run(self, query: str, max_results: int = 8, as_string: Literal[True] = True, focus: list[str] | None = None) -> str:\r\n        ...\r\n\r\n    @overload\r\n    def run(self, query: str, max_results: int = 8, as_string: Literal[False] = False, focus: list[str] | None = None) -> list[dict[str, str]]:\r\n        ...\r\n\r\n    async def run(self, query: str, max_results: int = 8, as_string: bool = True) -> str | list[dict]:\r\n        loop = self.loop or asyncio.get_event_loop()\r\n        future = loop.run_in_executor(self.executor, self._search_from_ddgs, query, max_results)\r\n        search_results = await future\r\n\r\n        if as_string:\r\n            return json.dumps(search_results, ensure_ascii=False)\r\n        return search_results\r\n\r\n    def _search_from_ddgs(self, query: str, max_results: int):\r\n        return [\r\n            {\"link\": i[\"href\"], \"snippet\": i[\"body\"], \"title\": i[\"title\"]}\r\n            for (_, i) in zip(range(max_results), self.ddgs.text(query))\r\n        ]\r\n\r\nif __name__ == \"__main__\":\r\n    import fire\r\n    fire.Fire(DDGAPIWrapper().run)\r\n```\r\n\r\n### **Expected Behavior**\r\n\r\nThe `DDGAPIWrapper.run` method should perform DuckDuckGo searches and return the specified number of results without triggering rate limit errors, even under multiple concurrent requests.\r\n\r\n### **Actual Behavior**\r\n\r\nThe method intermittently raises a `DuckDuckGoSearchException` with the message `Ratelimit`, indicating that the application is sending too many requests to the DuckDuckGo API in a short period.\r\n\r\n### **Analysis**\r\n\r\n**Cause:**\r\nThe original script lacks mechanisms to control the frequency of API requests. Rapid or concurrent calls to the `run` method exceed DuckDuckGo's rate limits, resulting in exceptions.\r\n\r\n**Impact:**\r\nFailed search operations disrupt the application's functionality, leading to an inability to retrieve necessary search results.\r\n\r\n### **Proposed Solution**\r\n\r\nEnhance the `DDGAPIWrapper` by implementing rate limiting, retry mechanisms, and caching to prevent exceeding DuckDuckGo's API rate limits.\r\n\r\n**Modifications in `DDGAPIWrapper` (Script 2):**\r\n\r\n- Introduced libraries for rate limiting (`aiolimiter`), caching (`aiocache`), and retries (`tenacity`).\r\n\r\n - Defined `DuckDuckGoSearchException` to handle specific search-related errors.\r\n\r\n - Implemented `AsyncLimiter` to restrict to 1 request per second.\r\n\r\n - Utilized `tenacity` to retry failed requests with exponential backoff upon encountering rate limit exceptions.\r\n\r\n - Added caching to store search results for 5 minutes, reducing redundant API calls.\r\n\r\n - Improved exception handling to differentiate between rate limit errors and other issues.\r\n\r\n- Changed the main execution to use the `cached_run` method, leveraging caching and enhanced functionalities.\r\n\r\n**Modified `DDGAPIWrapper`:**\r\n\r\n```python\r\nimport asyncio, json\r\nfrom concurrent import futures\r\nfrom typing import Literal, Optional, overload\r\nfrom pydantic import BaseModel, ConfigDict\r\nfrom aiolimiter import AsyncLimiter\r\nfrom aiocache import cached, Cache\r\nfrom aiocache.serializers import JsonSerializer\r\nfrom tenacity import retry, wait_exponential, stop_after_attempt, retry_if_exception_type\r\nfrom duckduckgo_search import DDGS\r\n\r\n# Custom exception for DuckDuckGo search errors\r\nclass DuckDuckGoSearchException(Exception):\r\n    pass\r\n\r\nclass DDGAPIWrapper(BaseModel):\r\n    model_config = ConfigDict(arbitrary_types_allowed=True)\r\n    loop: Optional[asyncio.AbstractEventLoop] = None\r\n    executor: Optional[futures.Executor] = None\r\n    proxy: Optional[str] = None\r\n    rate_limiter: AsyncLimiter = AsyncLimiter(max_rate=1, time_period=1)\r\n\r\n    @property\r\n    def ddgs(self):\r\n        return DDGS(proxies=self.proxy)\r\n\r\n    @overload\r\n    def run(self, query: str, max_results: int = 8, as_string: Literal[True] = True, focus: list[str] | None = None) -> str:\r\n        ...\r\n\r\n    @overload\r\n    def run(self, query: str, max_results: int = 8, as_string: Literal[False] = False, focus: list[str] | None = None) -> list[dict[str, str]]:\r\n        ...\r\n\r\n    @retry(\r\n        retry=retry_if_exception_type(DuckDuckGoSearchException),\r\n        wait=wait_exponential(multiplier=1, min=4, max=10),\r\n        stop=stop_after_attempt(5),\r\n        reraise=True\r\n    )\r\n    async def run(self, query: str, max_results: int = 8, as_string: bool = True) -> str | list[dict]:\r\n        loop = self.loop or asyncio.get_event_loop()\r\n\r\n        async with self.rate_limiter:\r\n            try:\r\n                future = loop.run_in_executor(self.executor, self._search_from_ddgs, query, max_results)\r\n                search_results = await future\r\n            except Exception as e:\r\n                if 'Ratelimit' in str(e):\r\n                    print(f\"Rate limit hit for query: {query}. Retrying...\")\r\n                    raise DuckDuckGoSearchException(\"Rate limit exceeded\") from e\r\n                else:\r\n                    print(f\"An error occurred: {e}\")\r\n                    raise DuckDuckGoSearchException(\"An error occurred during search\") from e\r\n\r\n        if as_string:\r\n            return json.dumps(search_results, ensure_ascii=False)\r\n        return search_results\r\n\r\n    def _search_from_ddgs(self, query: str, max_results: int):\r\n        return [\r\n            {\"link\": i[\"href\"], \"snippet\": i[\"body\"], \"title\": i[\"title\"]}\r\n            for (_, i) in zip(range(max_results), self.ddgs.text(query))\r\n        ]\r\n\r\n    @cached(ttl=300, cache=Cache.MEMORY, serializer=JsonSerializer())\r\n    async def cached_run(self, query: str, max_results: int = 8, as_string: bool = True) -> str | list[dict]:\r\n        \"\"\"Cached version of the run method.\"\"\"\r\n        return await self.run(query, max_results, as_string)\r\n\r\nif __name__ == \"__main__\":\r\n    import fire\r\n    api_wrapper = DDGAPIWrapper()\r\n    fire.Fire(api_wrapper.cached_run)\r\n```\r\n\r\n### **Outcome**\r\n\r\nThe application seems to have successfully mitigated rate limit issues. \r\n\r\nI am saying this because I am using models inferred by ollama API endpoints, such that I have encountered issues with respect to token counting, which ollama community is still [tackling](https://github.com/ollama/ollama/issues/3582). \r\n\r\nSo, it would be grateful for anyone who is able to test this proposed solution and see whether it does solve problems relating to DDG while not introducing other errors.\r\n\r\nBut overall, some comments on the proposed fix: \r\n\r\n - The `AsyncLimiter` ensures that search requests do not exceed 1 request per second, adhering to DuckDuckGo's rate limits.\r\n\r\n - The retry mechanism automatically handles transient rate limit errors by retrying failed requests with exponential backoff.\r\n\r\n - Caching reduces redundant API calls for identical queries, optimizing performance and further preventing rate limit breaches.\r\n\r\n- Boiler-plate for custom exceptions for future debugging and maintenance.\r\n",
      "state": "closed",
      "author": "cnm13ryan",
      "author_type": "User",
      "created_at": "2024-11-01T19:22:06Z",
      "updated_at": "2025-03-14T23:54:45Z",
      "closed_at": "2024-12-21T00:30:15Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1567/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "shenchucheng"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1567",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1567",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:13.571974",
      "comments": [
        {
          "author": "shenchucheng",
          "body": "@cnm13ryan  Thank you very much for your advice. Using tenacity is indeed an effective approach. However, I suggest defining a separate DDGSearchRatelimitException, and only retry when a DDGSearchRatelimitException is triggered, rather than retrying on any exception.\r\n\r\n",
          "created_at": "2024-11-05T04:02:20Z"
        },
        {
          "author": "shenchucheng",
          "body": "@cnm13ryan  And, feel free to raise a PR :)\r\n\r\n",
          "created_at": "2024-11-05T04:04:43Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-06T00:33:09Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-21T00:30:15Z"
        },
        {
          "author": "zuxfoucault",
          "body": "> ## Describe the Bug\n> The original `DDGAPIWrapper` raises a `DuckDuckGoSearchException` due to exceeding DuckDuckGo API's rate limits. This prevents the application from retrieving search results effectively.\n> \n> ### **Error Message**\n> duckduckgo_search.exceptions.DuckDuckGoSearchException: _get",
          "created_at": "2025-03-06T20:02:17Z"
        }
      ]
    },
    {
      "issue_number": 558,
      "title": "KeyError: 'Could not automatically map chatglm_turbo to a tokeniser. Please use `tiktok.get_encoding` to explicitly get the tokeniser you expect.'",
      "body": "è¿è¡Œ examples/research.py æ—¶å‡ºç°é”™è¯¯ï¼Œ\r\n\r\n```python\r\nimport asyncio\r\n\r\nfrom metagpt.roles.researcher import RESEARCH_PATH, Researcher\r\n\r\n\r\nasync def main():\r\n    topic = (\"XXX\")\r\n    role = Researcher(language=\"zh-cn\")\r\n    await role.run(topic)\r\n\r\n    print(f\"save report to {RESEARCH_PATH / f'{topic}.md'}.\")\r\n\r\n\r\nif __name__ == '__main__':\r\n    asyncio.run(main())\r\n```\r\n\r\n```bash\r\n2023-12-14 15:27:28.767 | INFO     | metagpt.const:get_project_root:21 - PROJECT_ROOT set to D:\\_GitHubProjects\\Clones\\MetaGPT\r\n2023-12-14 15:27:28.848 | INFO     | metagpt.config:__init__:44 - Config loading done.\r\n2023-12-14 15:27:30.221 | INFO     | metagpt.roles.researcher:_act:40 - David(Researcher): ready to CollectLinks\r\n [\"artificial intelligence\", \"machine learning\"]2023-12-14 15:27:31.683 | INFO     | metagpt.provider.openai_api:update_cost:91 - Total running cost: $0.000 | Max budget: $10.000 | Current cost: $0.000, prompt_tokens: 36, completion_tokens: 11\r\nTraceback (most recent call last):\r\n  File \"D:\\_GitHubProjects\\Clones\\MetaGPT\\examples\\research.py\", line 24, in <module>\r\n    asyncio.run(main())\r\n  File \"D:\\_firefly\\Python310\\lib\\asyncio\\runners.py\", line 44, in run\r\n    return loop.run_until_complete(main)\r\n  File \"D:\\_firefly\\Python310\\lib\\asyncio\\base_events.py\", line 649, in run_until_complete\r\n    return future.result()\r\n  File \"D:\\_GitHubProjects\\Clones\\MetaGPT\\examples\\research.py\", line 18, in main\r\n    await role.run(topic)\r\n  File \"D:\\_GitHubProjects\\Clones\\MetaGPT\\metagpt\\roles\\role.py\", line 330, in run\r\n    rsp = await self.react()\r\n  File \"D:\\_GitHubProjects\\Clones\\MetaGPT\\metagpt\\roles\\researcher.py\", line 68, in react\r\n    msg = await super().react()\r\n  File \"D:\\_GitHubProjects\\Clones\\MetaGPT\\metagpt\\roles\\role.py\", line 291, in react\r\n    rsp = await self._act_by_order()\r\n  File \"D:\\_GitHubProjects\\Clones\\MetaGPT\\metagpt\\roles\\role.py\", line 278, in _act_by_order\r\n    rsp = await self._act()\r\n  File \"D:\\_GitHubProjects\\Clones\\MetaGPT\\metagpt\\roles\\researcher.py\", line 51, in _act\r\n    links = await todo.run(topic, 4, 4)\r\n  File \"D:\\_GitHubProjects\\Clones\\MetaGPT\\metagpt\\actions\\research.py\", line 130, in run\r\n    prompt = reduce_message_length(gen_msg(), self.llm.model, system_text, CONFIG.max_tokens_rsp)\r\n  File \"D:\\_GitHubProjects\\Clones\\MetaGPT\\metagpt\\utils\\text.py\", line 21, in reduce_message_length\r\n    max_token = TOKEN_MAX.get(model_name, 2048) - count_string_tokens(system_text, model_name) - reserved\r\n  File \"D:\\_GitHubProjects\\Clones\\MetaGPT\\metagpt\\utils\\token_counter.py\", line 105, in count_string_tokens\r\n    encoding = tiktoken.encoding_for_model(model_name)\r\n  File \"D:\\_GitHubProjects\\Clones\\MetaGPT\\.venv\\lib\\site-packages\\tiktoken\\model.py\", line 70, in encoding_for_model\r\n    raise KeyError(\r\nKeyError: 'Could not automatically map chatglm_turbo to a tokeniser. Please use `tiktok.get_encoding` to explicitly get the tokeniser you expect.'\r\n\r\n```",
      "state": "closed",
      "author": "QIN2DIM",
      "author_type": "User",
      "created_at": "2023-12-14T07:30:01Z",
      "updated_at": "2025-03-14T00:31:37Z",
      "closed_at": "2025-03-14T00:31:36Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/558/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/558",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/558",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:13.840116",
      "comments": [
        {
          "author": "shenchucheng",
          "body": "ç›®å‰ä»…åœ¨openaiä¸‹åšäº†æµ‹è¯•ï¼Œå…¶ä»–æ¨¡å‹éœ€è¦è¿›ä¸€æ­¥é€‚é…",
          "created_at": "2023-12-21T08:10:53Z"
        },
        {
          "author": "redlion99",
          "body": "chatglm_turbo ä½¿ç”¨çš„encodingæ˜¯å“ªä¸ªå‘¢ï¼Ÿ",
          "created_at": "2023-12-29T02:46:13Z"
        },
        {
          "author": "HuntZhaozq",
          "body": "@shenchucheng è¯·é—®ç°åœ¨researcherè¿˜æ˜¯åªèƒ½åœ¨openaiä¸Šä½¿ç”¨å—ï¼Ÿ",
          "created_at": "2024-01-26T02:54:25Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-28T00:31:29Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-14T00:31:36Z"
        }
      ]
    },
    {
      "issue_number": 532,
      "title": "[Suggestion]Gradio Web intefrace",
      "body": "As stated in the title, simple gradio interface that could manage the MetaGPT and its settings (Number of agents, instruction for each agent, OpenAI API key or Local machine hosted Model... etc.)",
      "state": "closed",
      "author": "NightFuryPrime",
      "author_type": "User",
      "created_at": "2023-12-05T13:50:54Z",
      "updated_at": "2025-03-13T00:32:27Z",
      "closed_at": "2025-03-13T00:32:26Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/532/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "voidking"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/532",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/532",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:14.044453",
      "comments": [
        {
          "author": "stellaHSR",
          "body": "You can use https://huggingface.co/spaces/deepwisdom/MetaGPT",
          "created_at": "2023-12-20T09:49:22Z"
        },
        {
          "author": "yvrjsharma",
          "body": "Hi, this space is not accessible, maybe because it is set up as 'private'. Would you be able to check? ",
          "created_at": "2024-11-04T10:45:49Z"
        },
        {
          "author": "geekan",
          "body": "@voidking could you plz help us to check this?",
          "created_at": "2024-11-04T10:48:55Z"
        },
        {
          "author": "voidking",
          "body": "@yvrjsharma Try this: https://huggingface.co/spaces/deepwisdom/MetaGPT-SoftwareCompany",
          "created_at": "2024-11-04T12:24:26Z"
        },
        {
          "author": "yvrjsharma",
          "body": "> @yvrjsharma Try this: https://huggingface.co/spaces/deepwisdom/MetaGPT-SoftwareCompany\r\n\r\nThanks! Yes, this one is Public, however, is in an error state atm. I've restarted the app to see if that helps put it back up.",
          "created_at": "2024-11-04T15:30:48Z"
        }
      ]
    },
    {
      "issue_number": 656,
      "title": "Add Security Engineer role",
      "body": "## User Story\r\nAs a user of MetaGPT, I want to have the option to include a Security Engineer role in my software development process. \r\n\r\n## Feature Description\r\nThe Security Engineer role would be responsible for:\r\n\r\n- Reviewing system architecture diagrams and interface definitions from an application security perspective\r\n- Performing threat modeling to identify potential security vulnerabilities in the design\r\n- Developing and executing security test cases (e.g. input validation, authentication, access control etc.)\r\n- Providing recommendations to mitigate identified security risks\r\n- Ensuring secure coding practices are followed in the implemented code\r\n- Performing security auditing on the final product\r\n\r\n## Benefits\r\nAdding a Security Engineer role would enhance the security posture and trustworthiness of solutions built using MetaGPT. It would act as an additional quality gate to catch security issues early in the development lifecycle. This is especially important for solutions dealing with sensitive data or deployed in security-critical environments.\r\n\r\nHaving security as a first-class concern via a dedicated role would encourage more secure software development practices overall.\r\n\r\n## Acceptance Criteria \r\n- Ability to initialize a Security Engineer agent with specialized skills and knowledge\r\n- Security Engineer can interoperate with other agents via existing message passing mechanisms \r\n- Security test cases are generated and executed\r\n- Recommendations provided to mitigate identified issues\r\n- Metrics capture the number of vulnerabilities detected and remediation rate\r\n\r\nLet me know if any clarification or additional detail is required!",
      "state": "closed",
      "author": "ei-grad",
      "author_type": "User",
      "created_at": "2023-12-29T13:48:57Z",
      "updated_at": "2025-03-13T00:32:25Z",
      "closed_at": "2025-03-13T00:32:25Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/656/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/656",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/656",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:14.260927",
      "comments": [
        {
          "author": "Rchenyu",
          "body": "@ei-grad  It sounds like a very good suggestionï¼If Metagpt is to create deployable applications, adding a security control module is necessary. You can try developing and submitting a pull request (PR), and if you need any assistance, please let me know. Additionally, we have a developer group. If y",
          "created_at": "2024-02-14T05:46:32Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-27T00:31:20Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-13T00:32:24Z"
        }
      ]
    },
    {
      "issue_number": 731,
      "title": "[Vulnerability] Arbitrary code execution when use QaEngineer role",
      "body": "**Vulnerability description**\r\nWhen we use QaEngineer role, arbitrary code execution could happen because QaEngineer adopt a dangerous action `RunCode` to test codes generated by Engineer. `RunCode.run_script()` method invokes `subprocess.Popen` without any check. Evil guys can manipulate prompts to execute some sensitive operations.\r\n\r\n**Proof of concept**\r\nMy PoC code was designed with slight modifications in your [tutorial example](https://docs.deepwisdom.ai/main/en/guide/get_started/quickstart.html)\r\n```python\r\nimport os\r\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\r\n\r\nimport asyncio\r\nfrom metagpt.roles import (\r\n    ProductManager,\r\n    Architect,\r\n    ProjectManager,\r\n    Engineer,\r\n    QaEngineer\r\n)\r\nfrom metagpt.team import Team\r\n\r\nasync def startup(idea: str):\r\n    company = Team()\r\n    company.hire(\r\n        [\r\n            ProductManager(),\r\n            Architect(),\r\n            ProjectManager(),\r\n            Engineer(),\r\n            QaEngineer()\r\n        ]\r\n    )\r\n    company.invest(investment=1.0)\r\n    company.run_project(idea=idea)\r\n\r\n    await company.run(n_round=16)\r\n\r\nasync def app(user_prompt):\r\n    await startup(idea=user_prompt)\r\n\r\nif __name__ == \"__main__\":\r\n    user_input = \"I want to execute shell command `ls -l`. Please help me write a piece of code and test this code.\"\r\n    asyncio.run(app(user_input))\r\n```\r\nAnd in the path `MetaGPT/workspace/.../test_outputs/`, we can notice the output of `ls -l` in a json file. It means that `ls -l` executes successfully.\r\n![rce](https://github.com/geekan/MetaGPT/assets/17444844/cd0c6905-8971-4b0f-a6da-d7a5327fbb2c)\r\n\r\nNote that in this PoC I only execute `ls -l`, but in real sceanario, attacker could execute dangerous operations such as file deletions, backdoor opening.\r\n\r\n**Vulnerability solved suggestion**\r\nUsing docker to execute python is a good choice. Restricting some sensitive codes via whitelist or blacklist could also be considered.\r\n",
      "state": "closed",
      "author": "fubuki8087",
      "author_type": "User",
      "created_at": "2024-01-10T02:21:24Z",
      "updated_at": "2025-03-12T00:31:49Z",
      "closed_at": "2025-03-12T00:31:48Z",
      "labels": [
        "enhancement",
        "inactive"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/731/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/731",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/731",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:14.539932",
      "comments": [
        {
          "author": "voidking",
          "body": "Good advice. We will take this into consideration.\r\nMaybe you can also contribute a PR? ğŸ˜",
          "created_at": "2024-01-17T12:14:23Z"
        },
        {
          "author": "fubuki8087",
          "body": "> Good advice. We will take this into consideration. Maybe you can also contribute a PR? ğŸ˜\r\n\r\nThank you, but I am usually quite busy with work. However, I can offer some suggestions here.\r\n\r\n1. **Using docker**. Docker offers an isolated environment. Even if attackers gain remote command execution p",
          "created_at": "2024-01-22T02:17:37Z"
        },
        {
          "author": "geekan",
          "body": "sandbox requirements. I think it is reasonable in a certain sense, but there is always a tradeoff between security and functionality.",
          "created_at": "2024-03-21T13:12:21Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-26T00:31:18Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-12T00:31:47Z"
        }
      ]
    },
    {
      "issue_number": 1178,
      "title": "Wishlist.",
      "body": "(Love the project, awesome work).\r\n\r\nI see Devin/this project doing demos like \"do this simple video game from scratch\", or \"do a to-do list web app\", starting from zero and using whatever libraries/technologies it prefers.\r\n\r\nThose are neat, but I don't think they are the most useful, at least for some people.\r\n\r\nHere's what *I* would want/need these projects to do, in case that would be useful to know, in the form of the prompts as I'd ask them of the agents:\r\n\r\n1. (Coming into my *existing* project/database), tell it: Â« in src/lib/Editor.ts, there's a function to resize images according to the specs it finds in the database, I'd like that function (and the other sub-functions it calls) to be put into a new library named Resizer.ts in src/lib/utils/, and change Editor.ts to use that library Â»\r\n\r\n2. Â« Once that's done, find other places in the code where we resize images, and for each, change them to use the new Resizer library. Â»\r\n\r\n3. Â« In src/test, using the same format and testing library as I am already using in my tools, write a series of tests for the Resizer library. You can find \"sample\" images to resize inside of data/samples/resized-images/ Â»\r\n\r\n4. Â« My project is made of two parts, the scripts (run with Node) in src/, and the ui (written in Vuejs, run in the browser) in ui/src/. Each part has its own \"Page\" class/abstraction with different functions/properties. I'd like you to join both of these into a single file/class that both the scripts and the UI can call/use. This is tricky because a few of the libraries the \"scripts\"-side class uses will not work in the browser. You must find a solution that allows us to have only one class everything imports, but to not have errors in the browser despite this. Propose and explain in detail a possible solution to this problem for me to review, then if I like the solution I'll ask you to implement it. Â»\r\n\r\nIf your project was able to do this, it would completely change my life.\r\n\r\nJust a wishlist :) \r\n\r\nAwesome work by the way.\r\n\r\n",
      "state": "closed",
      "author": "arthurwolf",
      "author_type": "User",
      "created_at": "2024-04-10T17:24:29Z",
      "updated_at": "2025-03-12T00:31:47Z",
      "closed_at": "2025-03-12T00:31:47Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1178/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1178",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1178",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:14.751765",
      "comments": [
        {
          "author": "krish240574",
          "body": "I second that, brilliant work !\r\nOne feature I would find really useful - \r\nCache requests and outputs that work, so they could be re-used during future executions. \r\nThanks. \r\n",
          "created_at": "2024-04-11T03:04:39Z"
        },
        {
          "author": "geekan",
          "body": "Sorry, we are currently at a high intensity of work, so the response is very slow. We are solving the scenario you mentioned, please wait for a while.",
          "created_at": "2024-05-18T11:02:30Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-26T00:30:59Z"
        },
        {
          "author": "arthurwolf",
          "body": "I still wish this :)",
          "created_at": "2025-01-26T01:57:22Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-26T00:31:17Z"
        }
      ]
    },
    {
      "issue_number": 1639,
      "title": "é›†æˆDesignReviewæ—¶æŠ¥é”™",
      "body": "**Bug description**\r\næˆ‘çš„ç¨‹åºåœ¨é›†æˆDesignReviewæ—¶ï¼ŒæŠ¥é”™å¦‚ä¸‹ï¼šTypeError: DesignReview.run() missing 1 required positional argument: 'api_design'ï¼ŒæŸ¥äº†ä¸‹æ˜¯ role.pyä¸­çš„ä»£ç  async def _act(self) -> Message:\r\n    logger.info(f\"{self._setting}: to do {self.rc.todo}({self.rc.todo.name})\")\r\n    response = await self.rc.todo.run(self.rc.history)åªä¼ äº†ä¸€ä¸‹å‚æ•°ï¼Œä½†DesignReview.runä¸­æœ‰ä¸¤ä¸ªå‚æ•°å¯¼è‡´çš„\r\nå…·ä½“æŠ¥é”™ä¿¡æ¯åŠä»£ç ä½ç½®æˆªå›¾æ˜¾ç¤º\r\n\r\n**Bug solved method**\r\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\r\n\r\n**Environment information**\r\n- LLM type and model name:\r\n- System version: windows 11\r\n- Python version: python 3.11\r\n- MetaGPT version or branch: master\r\n\r\n<!-- Dependent packagessï¼šthe packages version cause the bug(like `pydantic 1.10.8`), installation methodï¼ˆlike `pip install metagpt` or `pip install from source` or `run in docker`ï¼‰ -->\r\n\r\n- packages version:\r\n- installation method: \r\n\r\n**Screenshots or logs**\r\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\r\n![image](https://github.com/user-attachments/assets/cc5dbcad-ff33-42ee-b801-0af74ce39368)\r\n![image](https://github.com/user-attachments/assets/c1cb7663-eb7f-41f6-831f-90ba5eef34be)",
      "state": "closed",
      "author": "deger2012",
      "author_type": "User",
      "created_at": "2024-12-14T07:09:53Z",
      "updated_at": "2025-03-07T00:32:08Z",
      "closed_at": "2025-03-07T00:32:07Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1639/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1639",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1639",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:14.983705",
      "comments": [
        {
          "author": "deger2012",
          "body": "![image](https://github.com/user-attachments/assets/5f662ba0-d915-49ab-87bb-2da7640397bf)\r\n",
          "created_at": "2024-12-14T07:10:49Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-14T00:29:21Z"
        },
        {
          "author": "iorisa",
          "body": "ä½ åº”è¯¥ä¼ `prompt`ï¼Œè€Œä¸æ˜¯é‚£ä¸¤ä¸ªå‚æ•°ã€‚\næ•´ä¸ªMetaGPTæ¡†æ¶ï¼Œagentä¹‹é—´ã€actionä¹‹é—´éƒ½æ˜¯ä¼ messageã€‚",
          "created_at": "2025-01-16T14:47:05Z"
        },
        {
          "author": "deger2012",
          "body": "å—¯ å¥½çš„ è°¢è°¢\r\n\r\n________________________________\r\nå‘ä»¶äºº: Guess ***@***.***>\r\nå‘é€æ—¶é—´: 2025å¹´1æœˆ16æ—¥ 22:47\r\næ”¶ä»¶äºº: geekan/MetaGPT ***@***.***>\r\næŠ„é€: Luo Min ***@***.***>; Author ***@***.***>\r\nä¸»é¢˜: Re: [geekan/MetaGPT] é›†æˆDesignReviewæ—¶æŠ¥é”™ (Issue #1639)\r\n\r\n\r\nä½ åº”è¯¥ä¼ promptï¼Œè€Œä¸æ˜¯é‚£ä¸¤ä¸ªå‚æ•°\r\n\r\nâ€•\r\nReply to this email directly, view it",
          "created_at": "2025-01-21T07:52:23Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-21T00:31:02Z"
        }
      ]
    },
    {
      "issue_number": 1672,
      "title": "MetaGPT response: ValueError: Detected source code \"docs/prd/20250119145241.json\" from an unknown origin.",
      "body": "ValueError: Detected source code \"docs/prd/20250119145241.json\" from an unknown origin.\n<!-- Clearly and directly describe the current bug -->\n\n**Environment information**\nUsing Windows 11, installed using docker.\n- LLM type and model name: ollama llama3\n- System version: Windows 11\n- Python version:3.12.4\n- MetaGPT version or branch:latest\n\n<!-- Dependent packagessï¼šthe packages version cause the bug(like `pydantic 1.10.8`), installation methodï¼ˆlike `pip install metagpt` or `pip install from source` or `run in docker`ï¼‰ -->\n\nCONFIGURATION FILE: \n(config2.yml)\nllm:\n  api_type: \"ollama\"  # Change this to 'ollama'\n  model: \"llama3\"     # Use the name of the model you pulled\n  base_url: \"http://192.168.1.102:11434/api\"  # Default URL for the Ollama API\n  api_key: \"dummy_api_key_123456\"         # Leave this empty for Ollama, no API key needed\n  repair_llm_output: true\n\n\nmermaid:\n  engine: \"nodejs\"\n  path: \"mmdc\"\n  puppeteer_config: \"/app/metagpt/config/puppeteer-config.json\"\n  pyppeteer_path: \"/usr/bin/chromium\"\n\n\n\n\nMy input in powershell:\ndocker run --rm -v D:\\metagpt\\config\\config2.yaml:/app/metagpt/config/config2.yaml -v D:\\metagpt\\workspace:/app/metagpt/workspace metagpt/metagpt:latest metagpt \"Write a cli snake game\"\n\n\nOutput in powershell:-\nPS D:\\metagpt> docker run --rm -v D:\\metagpt\\config\\config2.yaml:/app/metagpt/config/config2.yaml -v D:\\metagpt\\workspace:/app/metagpt/workspace metagpt/metagpt:latest metagpt \"Write a cli snake game\"\n2025-01-19 14:58:54.539 | INFO     | metagpt.const:get_metagpt_package_root:21 - Package root set to /app/metagpt\n2025-01-19 14:58:56.983 | INFO     | metagpt.team:invest:93 - Investment: $3.0.\n2025-01-19 14:58:56.984 | INFO     | metagpt.roles.role:_act:403 - Alice(Product Manager): to do PrepareDocuments(PrepareDocuments)\n2025-01-19 14:58:57.739 | INFO     | metagpt.utils.file_repository:save:57 - save to: /app/metagpt/workspace/20250119145856/docs/requirement.txt\n2025-01-19 14:58:57.740 | INFO     | metagpt.roles.role:_act:403 - Alice(Product Manager): to do WritePRD(WritePRD)\n2025-01-19 14:58:57.745 | INFO     | metagpt.actions.write_prd:run:86 - New requirement detected: Write a cli snake game\n2025-01-19 15:00:06.783 | WARNING  | metagpt.utils.cost_manager:update_cost:49 - Model llama3 not found in TOKEN_COSTS.\n2025-01-19 15:00:06.802 | INFO     | metagpt.utils.git_repository:rename_root:203 - Delete directory /app/metagpt/workspace/game_snake_cli\n2025-01-19 15:00:07.111 | WARNING  | metagpt.utils.git_repository:rename_root:217 - Failed to move /app/metagpt/workspace/20250119145856 to /app/metagpt/workspace/game_snake_cli\n2025-01-19 15:00:07.156 | INFO     | metagpt.utils.file_repository:save:57 - save to: /app/metagpt/workspace/20250119145856/docs/prd/20250119150007.json\n2025-01-19 15:00:07.196 | INFO     | metagpt.utils.file_repository:save:57 - save to: /app/metagpt/workspace/20250119145856/resources/prd/20250119150007.md\n2025-01-19 15:00:07.199 | INFO     | metagpt.roles.role:_act:403 - Bob(Architect): to do WriteDesign(WriteDesign)\n2025-01-19 15:00:07.727 | INFO     | metagpt.actions.design_api:run:67 - Nothing has changed.\n2025-01-19 15:00:07.729 | INFO     | metagpt.roles.role:_act:403 - Eve(Project Manager): to do WriteTasks(WriteTasks)\n2025-01-19 15:00:08.068 | INFO     | metagpt.actions.project_management:run:54 - Nothing has changed.\n2025-01-19 15:00:09.325 | ERROR    | metagpt.roles.engineer:_new_coding_context:280 - Detected source code \"docs/prd/20250119150007.json\" from an unknown origin.\n2025-01-19 15:00:09.326 | WARNING  | metagpt.utils.common:wrapper:673 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.\n2025-01-19 15:00:09.327 | ERROR    | metagpt.utils.common:wrapper:655 - Exception occurs, start to serialize the project, exp:\nTraceback (most recent call last):\n  File \"/app/metagpt/metagpt/utils/common.py\", line 664, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"/app/metagpt/metagpt/roles/role.py\", line 551, in run\n    rsp = await self.react()\nValueError: Detected source code \"docs/prd/20250119150007.json\" from an unknown origin.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/app/metagpt/metagpt/utils/common.py\", line 650, in wrapper\n    result = await func(self, *args, **kwargs)\n  File \"/app/metagpt/metagpt/team.py\", line 134, in run\n    await self.env.run()\nException: Traceback (most recent call last):\n  File \"/app/metagpt/metagpt/utils/common.py\", line 664, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"/app/metagpt/metagpt/roles/role.py\", line 551, in run\n    rsp = await self.react()\n  File \"/app/metagpt/metagpt/roles/role.py\", line 520, in react\n    rsp = await self._react()\n  File \"/app/metagpt/metagpt/roles/role.py\", line 470, in _react\n    todo = await self._think()\n  File \"/app/metagpt/metagpt/roles/engineer.py\", line 256, in _think\n    await self._new_code_actions()\n  File \"/app/metagpt/metagpt/roles/engineer.py\", line 347, in _new_code_actions\n    coding_doc = await self._new_coding_doc(filename=filename, dependency=dependency)\n  File \"/app/metagpt/metagpt/roles/engineer.py\", line 292, in _new_coding_doc\n    context = await self._new_coding_context(filename, dependency)\n  File \"/app/metagpt/metagpt/roles/engineer.py\", line 281, in _new_coding_context\n    raise ValueError(f'Detected source code \"{filename}\" from an unknown origin.')\nValueError: Detected source code \"docs/prd/20250119150007.json\" from an unknown origin.\n\n\n[CONTENT]\n{\n    \"Language\": \"en_us\",\n    \"Programming Language\": \"Python\",\n    \"Original Requirements\": \"Create a CLI snake game\",\n    \"Project Name\": \"game_snake_cli\",\n    \"Product Goals\": [\n        \"Create an engaging user experience\",\n        \"Improve accessibility, be responsive\",\n        \"More beautiful UI\"\n    ],\n    \"User Stories\": [\n        \"As a player, I want to be able to choose difficulty levels\",\n        \"As a player, I want to see my score after each game\",\n        \"As a player, I want to get restart button when I lose\",\n        \"As a player, I want to see beautiful UI that make me feel good\",\n        \"As a player, I want to play game via command line interface\"\n    ],\n    \"Competitive Analysis\": [\n        \"Snake Game A: Simple interface, lacks responsive features\",\n        \"play2048.co: Beautiful and responsive UI with my best score shown\",\n        \"snakegame.com: Responsive UI with my best score shown, but many ads\"\n    ],\n    \"Competitive Quadrant Chart\": \"\",\n    \"Requirement Analysis\": \"\",\n    \"Requirement Pool\": [\n        [\n            \"P0\",\n            \"The main code for snake game logic...\"\n        ]\n    ],\n    \"UI Design draft\": \"Basic function description with a simple style and layout.\",\n    \"Anything UNCLEAR\": \"\"\n}\n[/CONTENT]",
      "state": "closed",
      "author": "IshpreetSingh8264",
      "author_type": "User",
      "created_at": "2025-01-19T15:00:41Z",
      "updated_at": "2025-03-06T00:31:51Z",
      "closed_at": "2025-03-06T00:31:50Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1672/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1672",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1672",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:15.237540",
      "comments": [
        {
          "author": "iorisa",
          "body": "According to the logs you provided, the LLaMA3 model you used did not successfully complete the design work for the PRD, which subsequently triggered the following issues. I suggest you try other llm.\n\nMy log from the design phase of the GPT-4O-Mini model is as follows:\n```\n2025-01-20 02:40:53.434 |",
          "created_at": "2025-01-20T02:59:11Z"
        },
        {
          "author": "IshpreetSingh8264",
          "body": "```\nC:\\Users\\acer>docker run --rm -v D:\\metagpt\\config\\config2.yaml:/app/metagpt/config/config2.yaml -v D:\\metagpt\\workspace:/app/metagpt/workspace metagpt/metagpt:latest metagpt \"Write a cli snake game\"\n2025-01-20 07:05:29.623 | INFO     | metagpt.const:get_metagpt_package_root:21 - Package root se",
          "created_at": "2025-01-20T07:11:24Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-20T00:30:58Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-06T00:31:49Z"
        }
      ]
    },
    {
      "issue_number": 1660,
      "title": "SoftwareDev dataset",
      "body": "Hello Developer,\r\nMay I ask where I can obtain the contents of the SoftwareDev dataset? Or is this dataset a closed-source dataset?",
      "state": "closed",
      "author": "yuanhao2023",
      "author_type": "User",
      "created_at": "2025-01-10T03:23:38Z",
      "updated_at": "2025-03-04T00:31:37Z",
      "closed_at": "2025-03-04T00:31:36Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1660/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1660",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1660",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:15.546842",
      "comments": [
        {
          "author": "iorisa",
          "body": "Sorry, I don't quite understand what the `SoftwareDev dataset` is used for. To avoid any misunderstanding, could you please describe it in detail?\r\n",
          "created_at": "2025-01-11T07:37:56Z"
        },
        {
          "author": "yuanhao2023",
          "body": "> æŠ±æ­‰ï¼Œæˆ‘ä¸å¤ªæ˜ç™½ this æ˜¯åšä»€ä¹ˆç”¨çš„ã€‚ä¸ºé¿å…ä»»ä½•è¯¯è§£ï¼Œæ‚¨èƒ½è¯¦ç»†æè¿°ä¸€ä¸‹å—ï¼Ÿ`SoftwareDev dataset`\r\n\r\nThanks for your reply. According to the MetaGPT paper, the performance comparison between MetaGPT and ChatDev is based on the SoftwareDev dataset. I am currently working on a research project based on MetaGPT and would like to evaluat",
          "created_at": "2025-01-11T08:17:24Z"
        },
        {
          "author": "iorisa",
          "body": "The SoftwareDev related to the MetaGPT paper is not open to the public. After the release of MetaGPT 1.0 and MGX, we will open an open-source version similar to SoftwareDev.",
          "created_at": "2025-01-18T03:45:18Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-18T00:30:25Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-04T00:31:36Z"
        }
      ]
    },
    {
      "issue_number": 1663,
      "title": "é‡åˆ°ä¸ªbug  tenacity.RetryError: RetryError[<Future at 0x7f0b05a80c40 state=finished raised RetryError>]",
      "body": "**Bug description**\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/__init__.py\", line 382, in __call__\r\n    result = fn(*args, **kwargs)\r\n  File \"/app/metagpt/metagpt/utils/repair_llm_raw_output.py\", line 296, in retry_parse_json_text\r\n    parsed_data = CustomDecoder(strict=False).decode(output)\r\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 50, in __call__\r\n    result = await fn(*args, **kwargs)\r\n  File \"/app/metagpt/metagpt/actions/action_node.py\", line 442, in _aask_v1\r\n    parsed_data = llm_output_postprocess(\r\ntenacity.RetryError: RetryError[<Future at 0x7f0b05a80cd0 state=finished raised JSONDecodeError>]\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/app/metagpt/metagpt/utils/common.py\", line 664, in wrapper\r\n    return await func(self, *args, **kwargs)\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 551, in run\r\n    rsp = await self.react()\r\ntenacity.RetryError: RetryError[<Future at 0x7f0b05a80c40 state=finished raised RetryError>]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/app/metagpt/metagpt/utils/common.py\", line 650, in wrapper\r\n    result = await func(self, *args, **kwargs)\r\n  File \"/app/metagpt/metagpt/team.py\", line 134, in run\r\n    await self.env.run()\r\nException: Traceback (most recent call last):\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/__init__.py\", line 382, in __call__\r\n    result = fn(*args, **kwargs)\r\n  File \"/app/metagpt/metagpt/utils/repair_llm_raw_output.py\", line 296, in retry_parse_json_text\r\n    parsed_data = CustomDecoder(strict=False).decode(output)\r\n  File \"/app/metagpt/metagpt/utils/custom_decoder.py\", line 297, in decode\r\n    return super().decode(s)\r\n  File \"/usr/local/lib/python3.9/json/decoder.py\", line 337, in decode\r\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\r\n  File \"/usr/local/lib/python3.9/json/decoder.py\", line 355, in raw_decode\r\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\r\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 50, in __call__\r\n    result = await fn(*args, **kwargs)\r\n  File \"/app/metagpt/metagpt/actions/action_node.py\", line 442, in _aask_v1\r\n    parsed_data = llm_output_postprocess(\r\n  File \"/app/metagpt/metagpt/provider/postprocess/llm_output_postprocess.py\", line 19, in llm_output_postprocess\r\n    result = postprocess_plugin.run(output=output, schema=schema, req_key=req_key)\r\n  File \"/app/metagpt/metagpt/provider/postprocess/base_postprocess_plugin.py\", line 68, in run\r\n    new_output = self.run_repair_llm_output(output=output, schema=schema, req_key=req_key)\r\n  File \"/app/metagpt/metagpt/provider/postprocess/base_postprocess_plugin.py\", line 32, in run_repair_llm_output\r\n    parsed_data = self.run_retry_parse_json_text(content)\r\n  File \"/app/metagpt/metagpt/provider/postprocess/base_postprocess_plugin.py\", line 47, in run_retry_parse_json_text\r\n    parsed_data = retry_parse_json_text(output=content)  # should use output=content\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/__init__.py\", line 289, in wrapped_f\r\n    return self(f, *args, **kw)\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/__init__.py\", line 379, in __call__\r\n    do = self.iter(retry_state=retry_state)\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/__init__.py\", line 326, in iter\r\n    raise retry_exc from fut.exception()\r\ntenacity.RetryError: RetryError[<Future at 0x7f0b05a80cd0 state=finished raised JSONDecodeError>]\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/app/metagpt/metagpt/utils/common.py\", line 664, in wrapper\r\n    return await func(self, *args, **kwargs)\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 551, in run\r\n    rsp = await self.react()\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 520, in react\r\n    rsp = await self._react()\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 475, in _react\r\n    rsp = await self._act()\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 404, in _act\r\n    response = await self.rc.todo.run(self.rc.history)\r\n  File \"/app/metagpt/metagpt/actions/write_prd.py\", line 87, in run\r\n    return await self._handle_new_requirement(req)\r\n  File \"/app/metagpt/metagpt/actions/write_prd.py\", line 108, in _handle_new_requirement\r\n    node = await WRITE_PRD_NODE.fill(context=context, llm=self.llm, exclude=exclude)  # schema=schema\r\n  File \"/app/metagpt/metagpt/actions/action_node.py\", line 648, in fill\r\n    return await self.simple_fill(schema=schema, mode=mode, images=images, timeout=timeout, exclude=exclude)\r\n  File \"/app/metagpt/metagpt/actions/action_node.py\", line 473, in simple_fill\r\n    content, scontent = await self._aask_v1(\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\r\n    return await fn(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 47, in __call__\r\n    do = self.iter(retry_state=retry_state)\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/__init__.py\", line 326, in iter\r\n    raise retry_exc from fut.exception()\r\ntenacity.RetryError: RetryError[<Future at 0x7f0b05a80c40 state=finished raised RetryError>]\r\n\r\n**Environment information**\r\nlmstudio  éƒ¨ç½²çš„ qwen1.5-0.5b-chatã€‚\r\nåœ¨ä½ ä»¬æä¾›çš„dockerå®¹å™¨è¿è¡Œã€‚\r\n\r\n\r\nèƒ½å¤Ÿè¾“å‡ºcodeä»£ç ã€‚ä¸çŸ¥é“ä»€ä¹ˆåŸå› é€ æˆçš„ã€‚\r\n",
      "state": "closed",
      "author": "Salary-only-17k",
      "author_type": "User",
      "created_at": "2025-01-12T13:45:31Z",
      "updated_at": "2025-03-04T00:31:36Z",
      "closed_at": "2025-03-04T00:31:35Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1663/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1663",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1663",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:15.844384",
      "comments": [
        {
          "author": "Salary-only-17k",
          "body": "\r\n random\r\nfrom random import randint\r\n\r\nclass Game:\r\n    def __init__(self):\r\n        self.score = 0\r\n        self difficulty = 1\r\n        self.user_stories = []\r\n\r\n    def play(self, player_id):\r\n        # Generate random number between 0 and 2047\r\n        player_number = randint(0, 2048)\r\n       ",
          "created_at": "2025-01-12T13:46:13Z"
        },
        {
          "author": "Salary-only-17k",
          "body": "ç”Ÿæˆçš„ä»£ç è¿è¡Œä¸èµ·æ¥",
          "created_at": "2025-01-12T13:48:12Z"
        },
        {
          "author": "iorisa",
          "body": "ä½ å¯ä»¥è¯•è¯•ç”¨[å¢é‡å¼€å‘åŠŸèƒ½](https://docs.deepwisdom.ai/main/en/guide/in_depth_guides/incremental_development.html)æ¥ä¿®è¿™ä¸ªbugã€‚\nä¸è¿‡æˆ‘æ›´æ¨èä½ ä½¿ç”¨[Data Interpreteræ¨¡å¼](https://docs.deepwisdom.ai/main/en/guide/use_cases/agent/interpreter/intro.html)æ¥è§£å†³è¿™ç§éSOPåœºæ™¯ã€‚è½¯ä»¶å…¬å¸SOPæ˜¯ä¸€ä¸ªç”¨æ¥å±•ç¤ºMetaGPTæ¡†æ¶èƒ½åŠ›çš„ç¤ºä¾‹ï¼Œä½†å®é™…ä¸Šè½¯ä»¶å¼€å‘æµç¨‹å¹¶ä¸æ˜¯ä¸€ä¸ªSOPåœºæ™¯ã€‚",
          "created_at": "2025-01-18T03:35:02Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-18T00:30:24Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-04T00:31:35Z"
        }
      ]
    },
    {
      "issue_number": 1668,
      "title": "å…³äºè°ƒç”¨åƒå¸†api",
      "body": "è¯·é—®å¦‚ä½•æ›´æ–°modelåˆ—è¡¨ï¼Ÿåƒä¸€äº›æ¯”è¾ƒæ–°çš„æ¨¡å‹å¦‚ERNIE 4.0\\3.5 éƒ½ä¸åœ¨qianfanæ”¯æŒçš„æ¨¡å‹åˆ—è¡¨å†…ã€‚",
      "state": "closed",
      "author": "Akihiiii",
      "author_type": "User",
      "created_at": "2025-01-16T14:01:47Z",
      "updated_at": "2025-03-03T00:33:08Z",
      "closed_at": "2025-03-03T00:33:07Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1668/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1668",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1668",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:16.051564",
      "comments": [
        {
          "author": "iorisa",
          "body": "qianfanæ¨¡å‹ä»£ç æ˜¯è¿™ä¸ª`metagpt/provider/qianfan_api.py`ã€‚\næ˜¯æ¨¡å‹è°ƒä¸é€šè¿˜æ˜¯è¯´æ‰£è´¹ç»“ç®—é—®é¢˜ï¼Ÿ\nå¦‚æœæ˜¯æ‰£è´¹ç»“ç®—é—®é¢˜ï¼Œå¯ä»¥åœ¨`metagpt/utils/token_counter.py`ä¸­æ·»åŠ ï¼š\n```python\n\"\"\"\nQianFan Token Price https://cloud.baidu.com/doc/WENXINWORKSHOP/s/hlrk4akp7#tokens%E5%90%8E%E4%BB%98%E8%B4%B9\nDue to QianFan has multi price strategies, we unify `Tokens p",
          "created_at": "2025-01-16T14:24:56Z"
        },
        {
          "author": "Akihiiii",
          "body": "æ„Ÿè°¢æ‚¨ç™¾å¿™ä¹‹ä¸­çš„å›å¤ï¼\n`2025-01-17 17:16:03.811 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 0.000(s), this was the 1st time calling it. exp: The provided model `ERNIE-4.0-8K` is not in the list of supported models. If this is a recentl",
          "created_at": "2025-01-17T09:22:06Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-17T00:32:35Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-03T00:33:07Z"
        }
      ]
    },
    {
      "issue_number": 1630,
      "title": " The package installation behavior in the code is unrestricted",
      "body": "**Bug description**\r\nIn the process of using MetaGPT's QaEngine, users can easily make the `RunCode._install_requirements` method download any dependency package through conversation. This could potentially allow malicious users to have the MetaGPT-deployed server download malicious dependency packages or change the versions of the dependencies required for the runtime environment.\r\n\r\n**Bug solved method**\r\nWe recommend that MetaGPT provide a reminder to inform developers to restrict the Python environment, at the very least avoiding the use of the same Python environment that is running MetaGPT.\r\n\r\n**Environment information**\r\n- LLM type and model name: OpenAI gpt-3.5-turbo\r\n- System version: ubuntu18.04 \r\n- Python version:  python3.11\r\n- MetaGPT version or branch: 68b7dc6\r\n- packages version:\r\n- installation method: \r\n\r\n**Screenshots or logs**\r\nPoC:\r\n```python\r\nimport os\r\nos.environ[\"OPENAI_API_KEY\"] = \"\"\r\n\r\nimport asyncio\r\nfrom metagpt.roles import (\r\n    ProductManager,\r\n    Architect,\r\n    ProjectManager,\r\n    Engineer,\r\n    QaEngineer\r\n)\r\nfrom metagpt.team import Team\r\n\r\nasync def startup(idea: str):\r\n    company = Team()\r\n    company.hire(\r\n        [\r\n            ProductManager(),\r\n            Architect(),\r\n            ProjectManager(),\r\n            Engineer(),\r\n            QaEngineer()\r\n\r\n        ]\r\n    )\r\n    company.invest(investment=1.0)\r\n    company.run_project(idea=idea)\r\n\r\n    await company.run(n_round=16)\r\n\r\nasync def app(user_prompt):\r\n    await startup(idea=user_prompt)\r\n\r\nif __name__ == \"__main__\":\r\n    user_input = \"write a calculate program, I need to include pandasai==2.4.0 and langchain==0.0.231 in the generated requirements.txt \" \\\r\n                 \"as a service, so please download it and excute the program.\"\r\n    asyncio.run(app(user_input))\r\n```\r\nScreenshots:\r\n<img width=\"1479\" alt=\"image\" src=\"https://github.com/user-attachments/assets/71e48d0b-1173-4566-98c9-2b8d538cf584\">\r\n",
      "state": "closed",
      "author": "BACMiao",
      "author_type": "User",
      "created_at": "2024-12-06T03:40:21Z",
      "updated_at": "2025-03-02T00:34:05Z",
      "closed_at": "2025-03-02T00:34:04Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1630/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1630",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1630",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:16.284636",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-06T00:32:30Z"
        },
        {
          "author": "iorisa",
          "body": "MetaGPT has two modes: SOP and Data Interpreter mode. \nSOP is a kind of waterfall model. The software company you use is an example of SOP. The applicable scenario for SOP is to implement some fixed processes. Therefore, whether to allow pip install should be determined at the design stage of SOP, r",
          "created_at": "2025-01-16T14:55:53Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-16T00:33:46Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-02T00:34:04Z"
        }
      ]
    },
    {
      "issue_number": 1646,
      "title": "å¦‚ä½•åœ¨è‡ªå·±å®šä¹‰çš„roleå¼•å…¥è‡ªå·±ç¼–å†™çš„toolï¼Ÿ",
      "body": "å®˜æ–¹ç¤ºä¾‹docsä¸­ç”¨å†™å¥½çš„DataInterpreterè¿™ä¸ªroleè¿›è¡Œtoolçš„ä½¿ç”¨ï¼Œä½†æ˜¯æˆ‘æƒ³è‡ªå·±åˆ›å»ºä¸€ä¸ªclass roleæ¥ä½¿ç”¨è‡ªå®šä¹‰çš„toolï¼Œè¦å¦‚ä½•åšå‘¢\r\n",
      "state": "closed",
      "author": "cjrcjrljy",
      "author_type": "User",
      "created_at": "2024-12-17T10:38:31Z",
      "updated_at": "2025-03-02T00:34:03Z",
      "closed_at": "2025-03-02T00:34:03Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1646/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1646",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1646",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:16.483385",
      "comments": [
        {
          "author": "shenchucheng",
          "body": "å¯ä»¥ç»§æ‰¿DataInterpreterï¼Œç„¶åtoolsä¼ å…¥ä½ çš„å·¥å…·",
          "created_at": "2024-12-17T14:07:03Z"
        },
        {
          "author": "cjrcjrljy",
          "body": "> \r\n\r\nä½†æ˜¯DataInterpreterçš„ä¸€äº›åŠŸèƒ½æˆ‘ä¸éœ€è¦ï¼Œå¹¶ä¸”å†™äº†æ–°çš„æç¤ºè¯åè¿˜æ˜¯ä¼šæ‰§è¡Œä¸€äº›æˆ‘ä¸éœ€è¦çš„æ­¥éª¤ï¼Œæ‰€ä»¥æ€æ ·è‡ªå·±åˆ›å»ºä¸€ä¸ªæ–°çš„roleç„¶åå¯ä»¥ä½¿ç”¨tools",
          "created_at": "2025-01-10T01:45:16Z"
        },
        {
          "author": "iorisa",
          "body": "DIçš„ç”¨æ³•æœ‰ç¤ºä¾‹ï¼šhttps://github.com/geekan/MetaGPT/blob/main/examples/di/crawl_webpage.py\nä¸»è¦æ˜¯2éƒ¨åˆ†ï¼š\n1. åˆ›å»ºå¯¹è±¡çš„æ—¶å€™ï¼ŒæŠŠä½ è¦ä½¿ç”¨çš„å·¥å…·æ³¨å†Œè¿›å»ï¼Œåƒè¿™æ ·(æ³¨æ„è¦ç¡®ä¿`import scrape_web_playwright`æˆåŠŸ)ï¼š\n```python\ndi = DataInterpreter(tools=[\"scrape_web_playwright\"])\n```\n2. åˆ›å»ºå·¥å…·çš„æ—¶å€™è¦ä½¿ç”¨`@register_tool`è£…é¥°å™¨ï¼Œè¿˜è¦æ·»åŠ google docstringæ ¼å¼çš„æ³¨é‡Šï¼ŒDIæ ¹æ®è¿™äº›æ³¨é‡Šæ¥ç†è§£å·¥å…·çš„ç”¨",
          "created_at": "2025-01-16T14:35:44Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-16T00:33:43Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-02T00:34:02Z"
        }
      ]
    },
    {
      "issue_number": 1667,
      "title": "Can you release some examples about how to use RoleReactMode",
      "body": "**Feature description**\r\n<!-- Clear and direct description of the functionality of the currently submitted or proposed feature -->\r\nAll examples is `react_mode = BY_ORDER`. \r\nI know MetaGPT   supporting `REACT or PLAN_AND_ACT` model, so could you release more example how to use `REACT or PLAN_AND_ACT`.\r\n",
      "state": "closed",
      "author": "GitEasonXu",
      "author_type": "User",
      "created_at": "2025-01-15T06:10:21Z",
      "updated_at": "2025-03-02T00:34:02Z",
      "closed_at": "2025-03-02T00:34:01Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1667/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1667",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1667",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:16.707731",
      "comments": [
        {
          "author": "iorisa",
          "body": "The `Data Interpreter` utilizes the `PLAN_AND_ACT` mode. \nYou can find the detailed code in `metagpt/roles/di/data_interpreter.py`. \nYou can also find relevant demos at [Data Interpreter (DI) | MetaGPT](https://docs.deepwisdom.ai/main/en/guide/use_cases/agent/interpreter/intro.html).\n\nRegarding `REA",
          "created_at": "2025-01-16T14:11:43Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-16T00:33:42Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-02T00:34:01Z"
        }
      ]
    },
    {
      "issue_number": 1664,
      "title": "Frustration in Environment Setup",
      "body": "**Bug description**\r\nI have followed the environement setup guide in github listed below:\r\n1) conda create -n metagpt python=3.9 && conda activate metagpt\r\n2) pull the git repo\r\n3) pip install -r requirement.txt\r\n4) pip install --upgrade metagpt\r\n5) initilize the llm configuration\r\n6) now I try to run my code that is fine with importing statements like from metagpt.actions import Action, and from metagpt.team import Team, however, the importing statement from metagpt.rag.engines import SimpleEngine really gives me a headache.\r\nFirst, I encountered an error \r\ncannot import name 'Url' from 'pydantic.networks', which I found the reason was that the pydantic version is too new on my side, which is pydantic-2.10.5 that replaces Url with AnyUrl or HttpUrl\r\nSo, I downgrade my pydantic verison to 2.6.4 and install the corresponding llama-index version 0.10.0, however, I found that it now gives me another error \r\nmodule not Found Error, no module named 'llama_index.vector_stores\" which is because my llama index version is too old, the version 0.12.10 has vector stores\r\nBut when I update my llama_index version I found that llama_index 0.12.10 depends on pydantic version 2.10.5 so it is a cicular dependency now. I do not know how to solve it \r\n\r\n**Bug solved method**\r\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\r\nI do not know how to solve it with the conflict on pydantic and llama_inndex, even if I disable the import statement, the system seems to import the SimpleEngine automatically \r\n\r\n**Environment information**\r\n<!-- Environmentï¼šSystem version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\r\n\r\n- LLM type and model name: api_type: \"ollama\", model: \"llama3.2\",base_url: \"http://localhost:11434\", api_key: \"dummy\"\r\n- System version: MacOS\r\n- Python version: conda 3.9 \r\n- MetaGPT version or branch: 0.8.1\r\n\r\n<!-- Dependent packagessï¼šthe packages version cause the bug(like `pydantic 1.10.8`), installation methodï¼ˆlike `pip install metagpt` or `pip install from source` or `run in docker`ï¼‰ -->\r\n\r\n- packages version: pydantic 2.6.4/2.10.5, llama_index 0.10.0/0.12.10\r\n- installation method:  pip install\r\n\r\n**Screenshots or logs**\r\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\r\n",
      "state": "closed",
      "author": "JustinGao20",
      "author_type": "User",
      "created_at": "2025-01-12T15:30:51Z",
      "updated_at": "2025-03-01T00:34:27Z",
      "closed_at": "2025-03-01T00:34:26Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1664/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1664",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1664",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:16.971090",
      "comments": [
        {
          "author": "iorisa",
          "body": "Recommended package version list: #1653 ",
          "created_at": "2025-01-15T02:26:00Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-15T00:30:02Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-03-01T00:34:25Z"
        }
      ]
    },
    {
      "issue_number": 1661,
      "title": "ä¸ºä»€ä¹ˆä¸æ”¯æŒqwen-coder?",
      "body": "æ”¯æŒåˆ—è¡¨æ²¡çœ‹åˆ°è¿™ä¸€api",
      "state": "closed",
      "author": "daviddavid97",
      "author_type": "User",
      "created_at": "2025-01-12T06:30:10Z",
      "updated_at": "2025-02-26T00:31:16Z",
      "closed_at": "2025-02-26T00:31:15Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1661/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1661",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1661",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:18.925710",
      "comments": [
        {
          "author": "iorisa",
          "body": "åƒé—®å¤§æ¨¡å‹å·²ç»æ”¯æŒopenaiæ¥å£äº†ï¼Œå¯ä»¥å‚è€ƒissue #1650 çš„è§£å†³æ–¹æ³•ï¼Œæ¢ä¸€ä¸‹æ¨¡å‹åå­—å°±è¡Œäº†\r\n\r\n",
          "created_at": "2025-01-12T09:49:15Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-12T00:30:21Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-26T00:31:15Z"
        }
      ]
    },
    {
      "issue_number": 763,
      "title": "ActionNode æ˜¯å¦å¯ä»¥æ”¯æŒåˆ—è¡¨å¼çš„childrenï¼Ÿ",
      "body": "**Feature description**\r\n<!-- Clear and direct description of the functionality of the currently submitted or proposed feature -->\r\n\r\n**Your Feature**\r\n<!-- Describe the idea or process of implementing the current feature. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- When submitting features, you need to complete the corresponding doc/tests/examples to facilitate verification by reviewers. -->\r\næˆ‘çš„ä»£ç å¦‚ä¸‹ï¼š\r\n```python\r\nfrom typing import Dict, List\r\nfrom metagpt.actions.action_node import ActionNode\r\nNAME = ActionNode(\r\n    key=\"name\",\r\n    expected_type=str,\r\n    instruction=\"\"\"name of the objective\"\"\",\r\n    example=\"color\"\r\n)\r\n\r\nVARIABLE_TYPE = ActionNode(\r\n    key=\"type\",\r\n    expected_type=str,\r\n    instruction=\"\"\"type of the varialbe. can be String, Int, Float etc, or a self defined type\"\"\",\r\n    example=\"AgentPopulation\")\r\nDESC = ActionNode(\r\n    key=\"desc\",\r\n    expected_type=str,\r\n    instruction=\"\"\"description\"\"\",\r\n    example=\"im a description\"\r\n)\r\nVariable_Type = ActionNode.from_children(\r\n    \"variable\", [NAME, VARIABLE_TYPE, DESC])\r\nVARIABLE_LIST = ActionNode(\r\n    key=\"variables\",\r\n    expected_type=List[Variable_Type],\r\n    instruction=\"\"\"list of variables\"\"\",\r\n    # example=[{\r\n    #     \"name\": \"current_patch\",\r\n    #     \"type\": \"Discrete2DPatch\",\r\n    #     \"desc\": \"å½“å‰ç½‘æ ¼\"\r\n    # }]\r\n    example=[]\r\n)\r\nInput_Type = ActionNode.from_children(\"input\", [NAME, VARIABLE_TYPE, DESC])\r\nINPUTS = ActionNode(\r\n    key=\"inputs\",\r\n    expected_type=List[Input_Type],\r\n    instruction=\"\"\"list of inputs\"\"\",\r\n    example=[]\r\n)\r\n```\r\næˆ‘æƒ³åˆ›å»ºä¸€ä¸ªINPUTSç±»å‹ï¼Œç”¨æ¥ç”Ÿæˆä¸€ç³»åˆ—å˜é‡ã€‚ç”±äºéœ€è¦çš„å˜é‡æ•°é‡ä¸èƒ½æå‰ç¡®å®šï¼Œæˆ‘éœ€è¦å°†ä»–ä»¬æ”¾åˆ°ä¸€ä¸ªlistä¸­ï¼Œä½†æ˜¯ç›®å‰å¥½åƒä¸æ”¯æŒ      expected_type=List[Variable_Type] è¿™ç§æ–¹å¼ã€‚\r\næŠ¥é”™çš„ä¿¡æ¯ï¼š\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/jovyan/LLM_agent/MetaGen/action_node.py\", line 29, in <module>\r\n    expected_type=List[Variable_Type],\r\n  File \"/home/jovyan/.conda/envs/metagpt/lib/python3.10/typing.py\", line 312, in inner\r\n    return func(*args, **kwds)\r\n  File \"/home/jovyan/.conda/envs/metagpt/lib/python3.10/typing.py\", line 1143, in __getitem__\r\n    params = tuple(_type_check(p, msg) for p in params)\r\n  File \"/home/jovyan/.conda/envs/metagpt/lib/python3.10/typing.py\", line 1143, in <genexpr>\r\n    params = tuple(_type_check(p, msg) for p in params)\r\n  File \"/home/jovyan/.conda/envs/metagpt/lib/python3.10/typing.py\", line 176, in _type_check\r\n    raise TypeError(f\"{msg} Got {arg!r:.100}.\")\r\nTypeError: Parameters to generic types must be types. Got variable, <class 'str'>, , , , {'name': name, <class 'str'>, name of the objective, color, , {}, 'ty.\r\n```\r\nè¯·é—®æ˜¯å¦æœ‰å…¶ä»–æ–¹å¼èƒ½å¤Ÿå®ç°è®©ä»–åŠ¨æ€çš„ç”Ÿæˆä¸€ç»„ä¸å®šæ•°é‡çš„Variable_Typeç±»å‹çš„æ•°æ®ï¼Ÿ",
      "state": "closed",
      "author": "wujiren",
      "author_type": "User",
      "created_at": "2024-01-16T09:33:13Z",
      "updated_at": "2025-02-25T00:31:39Z",
      "closed_at": "2025-02-25T00:31:39Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/763/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "geekan"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/763",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/763",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:19.142659",
      "comments": [
        {
          "author": "geekan",
          "body": "It's still in the design stage, and further design is needed to complete and stabilize the output, so if you're interested, you can participate in this part together",
          "created_at": "2024-01-17T12:49:10Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-10T00:31:49Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-25T00:31:38Z"
        }
      ]
    },
    {
      "issue_number": 774,
      "title": "Encountered a bug where unable to generate and save report while trying examples/research.py.",
      "body": "**Bug description**\r\nWhen trying the examples/research.py, encountered a bug where unable to generate and save report. The process stops at the step to do ConductResearch, with prompt_tokens: 1874, completion_tokens: 0, and the content is empty ('').\r\n\r\n**Environment information**\r\n- LLM type and model name: gpt-4-1106-preview\r\n- System version: ubuntu 22.04\r\n- Python version: 3.10.12\r\n- packages version: 0.6.0, 0.6.4, 0.6.5\r\n- installation method: pip install metagpt\r\n\r\n**Screenshots or logs**\r\n2024-01-18 15:29:10.095 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.545 | Max budget: $10.000 | Current cost: $0.037, prompt_tokens: 2735, completion_tokens: 321\r\n2024-01-18 15:29:21.722 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.572 | Max budget: $10.000 | Current cost: $0.027, prompt_tokens: 2290, completion_tokens: 122\r\n2024-01-18 15:29:21.722 | INFO     | metagpt.roles.researcher:_act:56 - David(Researcher): to do ConductResearch(David)\r\n2024-01-18 15:29:23.129 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.590 | Max budget: $10.000 | Current cost: $0.019, prompt_tokens: 1874, completion_tokens: 0\r\n",
      "state": "closed",
      "author": "zbwxp",
      "author_type": "User",
      "created_at": "2024-01-18T15:37:41Z",
      "updated_at": "2025-02-25T00:31:38Z",
      "closed_at": "2025-02-25T00:31:37Z",
      "labels": [
        "bug",
        "inactive"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/774/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "shenchucheng"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/774",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/774",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:19.379633",
      "comments": [
        {
          "author": "voidking",
          "body": "If you installed metagpt by `pip install metagpt`, there should be no examples/research.py\r\nWhat commands did you execute? And what is the order of these commands?",
          "created_at": "2024-01-19T05:40:09Z"
        },
        {
          "author": "zbwxp",
          "body": "> If you installed metagpt by `pip install metagpt`, there should be no examples/research.py What commands did you execute? And what is the order of these commands?\r\n\r\n\r\n```python\r\nimport asyncio\r\nfrom metagpt.roles.researcher import Researcher\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    async def main(top",
          "created_at": "2024-01-19T06:18:17Z"
        },
        {
          "author": "zbwxp",
          "body": "> If you installed metagpt by `pip install metagpt`, there should be no examples/research.py What commands did you execute? And what is the order of these commands?\r\n\r\nFound the cause of the error.\r\n\r\nopenai.BadRequestError: Error code: 400 - {'error': {'message': 'max_tokens is too large: 10964. Th",
          "created_at": "2024-01-19T06:47:11Z"
        },
        {
          "author": "geekan",
          "body": "@shenchucheng could you plz take a look at this?",
          "created_at": "2024-03-21T07:14:26Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-08T00:29:29Z"
        }
      ]
    },
    {
      "issue_number": 1022,
      "title": "Generated Python code for Game of 2048 largely inconsistent",
      "body": "**Bug description**\r\nI tried to create the Game of 2048 as instructed in the Intro section and I used the OpenAI model \"gpt-4-turbo-preview\". I set up MetaGPT using conda on my macOS system, using Python 3.9. I initialized the config to use OpenAI with a valid API-KEY and the best model available (see above).\r\n\r\nUnfortunately, the generated code is not self-consistent. MetaGPT created multiple Python files and the generated code looked superficiously good. But when trying to run the main.py code, many errors were raised. Most errors are the result of code references to either Python constants, methods, or constructors of generated Python code that did not exist or were referenced with an incorrect name.\r\n\r\nThe errors are too numerous to fix. I have attached the generated Python code for further details. I renamed all Python files to use the filename extension '.txt', since an upload of Python files seems to be prohibited by Github.\r\n[main.txt](https://github.com/geekan/MetaGPT/files/14628057/main.txt)\r\n[game.txt](https://github.com/geekan/MetaGPT/files/14628058/game.txt)\r\n[ui.txt](https://github.com/geekan/MetaGPT/files/14628059/ui.txt)\r\n[logic.txt](https://github.com/geekan/MetaGPT/files/14628060/logic.txt)\r\n[constants.txt](https://github.com/geekan/MetaGPT/files/14628061/constants.txt)",
      "state": "closed",
      "author": "crjaensch",
      "author_type": "User",
      "created_at": "2024-03-17T16:19:07Z",
      "updated_at": "2025-02-25T00:31:36Z",
      "closed_at": "2025-02-25T00:31:36Z",
      "labels": [
        "todo",
        "inactive"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1022/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "geekan"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1022",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1022",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:19.622039",
      "comments": [
        {
          "author": "crjaensch",
          "body": "Let me add that I tried the --code-review as well as the -no-code-review option. Moreover, the --run-tests option does not seem to work. Here I would have expected that MetaGPT recognizes that there are errors and tries to incrementally fix the errors through revised code generation trials.",
          "created_at": "2024-03-17T20:59:45Z"
        },
        {
          "author": "iorisa",
          "body": "1. About `the generated code is not self-consistent`: LLM does not always produce good design and then write good code. I suggest you retry if it failed. \r\n\r\n2. About `--run-tests option does not work`: The value of `--n-round` is  too small. `--n-round` is a safety valve that will terminate the inf",
          "created_at": "2024-03-19T05:53:14Z"
        },
        {
          "author": "crjaensch",
          "body": "Thanks for the specific suggestions on how to get better results with MetaGPT. I will certainly try the suggestions.",
          "created_at": "2024-03-20T07:34:15Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-07T00:30:32Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-25T00:31:36Z"
        }
      ]
    },
    {
      "issue_number": 1050,
      "title": "Running \"researcher\" example fails when using gemini-pro model. ",
      "body": "**Bug description**\r\nRunning \"researcher\" example fails when using gemini-pro model. It appears that the first step where David(Researcher) is passing the user query to CollectLinks(David) is not passing correct data. I'm not sure how to provide additional move verbose logging but will be happy to if someone would let me know.\r\n\r\n**Environment information**\r\nSystem version - Windows 11\r\nPython version - Python 3.10.9\r\nLLM type and model - Gemini\r\n\r\nInstallation method: \"development mode\"\r\ngit clone https://github.com/geekan/MetaGPT.git\r\n\r\nconfig2.example.yaml:\r\nllm:\r\napi_type: 'gemini'\r\napi_key: 'XXXXXXXXXXXXXXXXXXXXXXXXXXX'\r\nmodel: 'gemini-pro'\r\n\r\nsearch:\r\napi_type: \"google\"\r\napi_key: \"XXXXXXXXXXXXXXXXXXXXXXXXXXX\"\r\ncse_id: \"XXXXXXXXXXXXXX\"\r\n\r\n(metagpt) PS C:\\Users\\user\\code\\MetaGPT>  python -m metagpt.roles.researcher \"meat vs icecream\"\r\n2024-03-19 13:08:32.406 | INFO     | metagpt.const:get_metagpt_package_root:29 - Package root set to C:\\Users\\user\\code\\MetaGPT\r\n2024-03-19 13:08:37.393 | INFO     | __main__:_act:56 - David(Researcher): to do CollectLinks(David)\r\n[\"Computer Vision\", \"Object Detection\"]\r\n2024-03-19 13:08:38.442 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.000 | Max budget: $10.000 | Current cost: $0.000, prompt_tokens: 37, completion_tokens: 9\r\nWarning: model not found. Using cl100k_base encoding.\r\nWarning: model not found. Using cl100k_base encoding.\r\n[\"What are the applications of computer vision in the healthcare industry?\", \"How can object detection be used to improve safety in autonomous vehicles?\", \"What are the challenges and limitations of computer vision in real-world applications?\", \"How is computer vision being used to advance scientific research?\"]\r\n2024-03-19 13:08:42.291 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.000 | Max budget: $10.000 | Current cost: $0.000, prompt_tokens: 1251, completion_tokens: 57\r\n[ ...snip...]\r\n\r\n\r\nPS C:\\Users\\user\\code\\MetaGPT\\logs> less .\\20240319.txt\r\n2024-03-19 13:08:37.393 | DEBUG    | metagpt.roles.role:_observe:431 - David(Researcher) observed: ['user: meat vs icecream...']\r\n2024-03-19 13:08:37.393 | DEBUG    | metagpt.roles.role:_set_state:325 - actions=[CollectLinks, WebBrowseAndSummarize, ConductResearch], state=0\r\n2024-03-19 13:08:37.393 | INFO     | __main__:_act:56 - David(Researcher): to do CollectLinks(David)\r\n2024-03-19 13:08:37.393 | DEBUG    | metagpt.provider.base_llm:aask:126 - [{'role': 'user', 'parts': ['Please provide up to 2 necessary keywords related to\r\n your research topic for Google search. Your response must be in JSON format, for example: [\"keyword1\", \"keyword2\"].']}]\r\n2024-03-19 13:08:38.442 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.000 | Max budget: $10.000 | Current cost: $0.000, p\r\nrompt_tokens: 37, completion_tokens: 9\r\n2024-03-19 13:08:40.106 | DEBUG    | metagpt.actions.research:run:138 - ### Requirements\r\n1. The keywords related to your research topic and the search results are shown in the \"Search Result Information\" section.\r\n2. Provide up to 4 queries related to your research topic base on the search results.\r\n3. Please respond in the following JSON format: [\"query1\", \"query2\", \"query3\", ...].\r\n\r\n### Search Result Information\r\n#### Keyword: Computer Vision\r\n Search Result: [{'title': 'Computer vision - Wikipedia', 'link': 'https://en.wikipedia.org/wiki/Computer_vision', 'snippet': 'Computer vision covers the core technology of automated image analysis which is used in many fields. Machine vision usually refers to a process of combining\\xa0...'}, {'title': 'What is Computer Vision? | IBM', 'link': 'https://www.ibm.com/topics/computer-vision', 'snippet': 'Computer vision is a field of artificial intelligence (AI) enabling computers to derive information from images, videos and other inputs.'}, {'title': 'What Is Computer Vision? | Microsoft Azure', 'link': 'https://azure.microsoft.com/en-us/resources/cloud-computing-dictionary/what-is-computer-vision', 'snippet': 'Computer vision. Computer vision is a field of computer science that focuses on enabling computers to identify and understand objects and people in images and\\xa0...'}, {'title': 'Computer Vision: What it is and why it matters | SAS', 'link': 'https://www.sas.com/en_us/insights/analytics/computer-vision.html', 'snippet': 'Computer vision can help agencies perform\r\npredictive maintenance by analyzing equipment and infrastructure images to make better decisions on which of these\\xa0...'}, {'title': 'Azure AI Vision with OCR and AI | Microsoft Azure', 'link': 'https://azure.microsoft.com/en-us/products/ai-services/ai-vision', 'snippet': 'Accelerate computer vision development with Microsoft Azure. Unlock insights from image and video content using OCR, object detection, and image analysis.'}, {'title': 'Everything You Ever Wanted To Know About Computer Vision. | by ...', 'link': 'https://towardsdatascience.com/everything-you-ever-wanted-to-know-about-computer-vision-heres-a-look-why-it-s-so-awesome-e8a58dfb641e', 'snippet': \"Computer vision also plays an important role in facial recognition applications, the technology that enables computers to match images of people's faces to\\xa0...\"}, {'title': 'Azure AI Vision documentation - Quickstarts, Tutorials, API Reference', 'link': 'https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/', 'snippet': 'The cloud-based Azure AI Vision API provides developers with access to advanced algorithms for processing images and returning information.'}, {'title': 'What is Computer Vision? - Image recognition AI/ML Explained - AWS', 'link': 'https://aws.amazon.com/what-is/computer-vision/', 'snippet': 'Computer vision applications use artificial intelligence and machine learning (AI/ML) to process this data accurately for object identification and facial\\xa0...'}]\r\n\r\n#### Keyword: Object Detection\r\n Search Result: [{'title': 'Object detection - Wikipedia', 'link': 'https://en.wikipedia.org/wiki/Object_detection', 'snippet': 'Object detection ... Object detection is a computer technology related to computer vision and image processing that deals with detecting instances of semantic\\xa0...'}, {'title': 'Object Detection | Papers With Code', 'link': 'https://paperswithcode.com/task/object-detection', 'snippet': 'Object Detection is a computer vision task in which the goal is to detect and locate objects of interest in an image or video. The task involves identifying\\xa0...'}, {'title': 'What Is Object Detection? - MATLAB & Simulink', 'link': 'https://www.mathworks.com/discovery/object-detection.html', 'snippet': 'Object detection algorithms typically leverage machine learning or deep learning to produce meaningful results. When humans look at images or video, we can\\xa0...'}, {'title': 'https://github.com/tensorflow/models/tree/master/r...', 'link': 'https://github.com/tensorflow/models/tree/master/research/object_detection'}, {'title': 'What is Object Detection? The Ultimate Guide.', 'link': 'https://blog.roboflow.com/object-detection/', 'snippet': 'Aug 22, 2023 ... Object detection can be used for any problem where\r\n[...snip...]\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "state": "closed",
      "author": "vmsysadm",
      "author_type": "User",
      "created_at": "2024-03-19T19:41:59Z",
      "updated_at": "2025-02-24T00:32:24Z",
      "closed_at": "2025-02-24T00:32:23Z",
      "labels": [
        "bug",
        "inactive"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1050/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "shenchucheng"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1050",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1050",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:19.848815",
      "comments": [
        {
          "author": "iorisa",
          "body": "It seems still running, since 'save report to ...' does not present in the log.\r\n```python\r\nasync def main():\r\n    topic = \"dataiku vs. datarobot\"\r\n    role = Researcher(language=\"en-us\")\r\n    await role.run(topic)\r\n    print(f\"save report to {RESEARCH_PATH / f'{topic}.md'}.\")\r\n```",
          "created_at": "2024-03-20T12:33:02Z"
        },
        {
          "author": "vmsysadm",
          "body": "The log that's provided is truncated - in the command line I'm attempting to ask to research \"meat vs icecream\" question, but the output indicates that the research topic is [\"Computer Vision\", \"Object Detection\"] or something equally irrelevant.\r\n\r\n\r\n(metagpt) PS C:\\Users\\user\\code\\MetaGPT> python ",
          "created_at": "2024-03-20T13:09:37Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-07T00:30:30Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-24T00:32:22Z"
        }
      ]
    },
    {
      "issue_number": 1106,
      "title": "Enhancing Code Refactoring Capability for Advanced Code Generation",
      "body": "**Feature description**\r\nRefactoring code is an essential aspect of software development, aiding in improving code readability, maintainability, and performance. However, the process of identifying which methods or functions need refactoring, along with understanding their dependencies and potential impact on the overall software, can be challenging.\r\n\r\n**Your Feature**\r\nThe goal of this issue is to enhance code generation agent's ability to perform advanced code refactoring. By improving its capability to analyze code, identify refactor opportunities, and understand the implications of those changes, we can significantly improve the efficiency and effectiveness of our code generation process.\r\n\r\nWhat strategies or methodologies can we employ to further enhance code generation agent's capability to intelligently identify refactor opportunities and predict their impact on the software system?\r\n\r\n",
      "state": "closed",
      "author": "moamen270",
      "author_type": "User",
      "created_at": "2024-03-25T20:31:10Z",
      "updated_at": "2025-02-24T00:32:22Z",
      "closed_at": "2025-02-24T00:32:22Z",
      "labels": [
        "discussion",
        "inactive"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1106/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1106",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1106",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:20.107659",
      "comments": [
        {
          "author": "geekan",
          "body": "Very good demand! Do you have any specific implementation suggestions?",
          "created_at": "2024-03-26T07:32:26Z"
        },
        {
          "author": "moamen270",
          "body": "I started this issue to discuss about how to implement this thing ğŸ˜„ ",
          "created_at": "2024-03-26T08:23:34Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-07T00:30:29Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-24T00:32:21Z"
        }
      ]
    },
    {
      "issue_number": 1635,
      "title": "How to add RAG into Data Interpreter",
      "body": "Hi! Thanks for your great work. I'm wondering whether you could add an example or documentation for integrating RAG into Data Interpreter. It seems that there are only examples for RAG Retrieval and Rerank, but I have no idea how to utilize this ability into the current Data Interpreter Machine learning modeling procedure. Thanks!",
      "state": "closed",
      "author": "cjl0222",
      "author_type": "User",
      "created_at": "2024-12-09T01:21:06Z",
      "updated_at": "2025-02-24T00:32:21Z",
      "closed_at": "2025-02-24T00:32:20Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1635/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1635",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1635",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:20.339024",
      "comments": [
        {
          "author": "iorisa",
          "body": "When the `Data Interpreter` object's `rc.memory` content is too large, you can use the RAG approach to retrieve this memory, which reduces the cost of a single interaction and avoids exceeding the maximum token limit of the LLM.\r\n\r\nFor example, using RAG to override the `self.get_memories()` functio",
          "created_at": "2025-01-09T03:39:30Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-09T00:32:54Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-24T00:32:20Z"
        }
      ]
    },
    {
      "issue_number": 1641,
      "title": "can we use customize tools in role or action?",
      "body": "i just now saw the docs ,finding \" role = DataInterpreter(tools=[\"calculate_factorial\"])\" by this way using customize  tools ,however, i want \r\nto use my tools in defining 'role' or 'action',how can to that\r\n",
      "state": "closed",
      "author": "cjrcjrljy",
      "author_type": "User",
      "created_at": "2024-12-16T07:16:31Z",
      "updated_at": "2025-02-23T00:33:36Z",
      "closed_at": "2025-02-23T00:33:34Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1641/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1641",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1641",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:20.603606",
      "comments": [
        {
          "author": "shenchucheng",
          "body": "Would you mind providing an example to help clarify your requirement?",
          "created_at": "2024-12-17T14:10:58Z"
        },
        {
          "author": "iorisa",
          "body": "In MetaGPT, `action` and `tool` are equivalent concepts, and `role` can be represented using either `action` or `tool`.\r\n",
          "created_at": "2025-01-09T03:28:41Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-09T00:32:52Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-23T00:33:34Z"
        }
      ]
    },
    {
      "issue_number": 1657,
      "title": "Exception in role's execution, deletion of newest role communication message throws another exception and exits application process",
      "body": "**Bug description**\r\n<!-- Clearly and directly describe the current bug -->\r\nWhile executing and preparing files, the following logs show initializing failed for one of the roles and in order to fix it, entire metagpt process crashed and exited out. Attached logs below from the project specifying stacktrace as is from console:\r\n`2025-01-07 01:28:33.166 | WARNING  | metagpt.utils.common:wrapper:649 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.\r\n2025-01-07 01:28:33.275 | ERROR    | metagpt.utils.common:wrapper:631 - Exception occurs, start to serialize the project, exp:\r\nTraceback (most recent call last):\r\n  File \"<PATH>\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\r\n    result = await fn(*args, **kwargs)\r\n  File \"<PATH>/venv\\lib\\site-packages\\metagpt\\actions\\action_node.py\", line 432, in _aask_v1\r\n    instruct_content = output_class(**parsed_data)`\r\n\r\n**Bug solved method**\r\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\r\n\r\n**Environment information**\r\n<!-- Environmentï¼šSystem version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\r\n\r\n- LLM type and model name: qwen-2.5-coder 32b\r\n- System version: Windows 11\r\n- Python version: 3.9.11 (VirtualEnv)\r\n- MetaGPT version or branch: master cli\r\n\r\n<!-- Dependent packagessï¼šthe packages version cause the bug(like `pydantic 1.10.8`), installation methodï¼ˆlike `pip install metagpt` or `pip install from source` or `run in docker`ï¼‰ -->\r\n\r\n- packages version: used venv to initialize and write wrapper to create crud application in Java\r\n- installation method: pip install --upgrade metagpt\r\n\r\n**Screenshots or logs**\r\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\r\n\r\n> 2025-01-07 01:28:33.162 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 343.484(s), this was the 6th time calling it. exp: 1 validation error for PM_NODE_AN\r\n\r\n>   Value error, Missing fields: {'Required Python packages'} [type=value_error, input_value={'Required Java packages'...or terminal operators.'}, input_type=dict]\r\n>     For further information visit https://errors.pydantic.dev/2.6/v/value_error\r\n> 2025-01-07 01:28:33.166 | WARNING  | metagpt.utils.common:wrapper:649 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.\r\n> 2025-01-07 01:28:33.275 | ERROR    | metagpt.utils.common:wrapper:631 - Exception occurs, start to serialize the project, exp:\r\n> Traceback (most recent call last):\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\r\n>     result = await fn(*args, **kwargs)\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\actions\\action_node.py\", line 432, in _aask_v1\r\n>     instruct_content = output_class(**parsed_data)\r\n> pydantic_core._pydantic_core.ValidationError: 1 validation error for PM_NODE_AN\r\n>   Value error, Missing fields: {'Required Python packages'} [type=value_error, input_value={'Required Java packages'...or terminal operators.'}, input_type=dict]\r\n\r\n   \r\n\r\n>  For further information visit https://errors.pydantic.dev/2.6/v/value_error\r\n> \r\n> The above exception was the direct cause of the following exception:\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\utils\\common.py\", line 640, in wrapper\r\n>     return await func(self, *args, **kwargs)\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\roles\\role.py\", line 550, in run\r\n>     rsp = await self.react()\r\n> tenacity.RetryError: RetryError[<Future at 0x224aceb39d0 state=finished raised ValidationError>]\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\utils\\common.py\", line 626, in wrapper\r\n>     result = await func(self, *args, **kwargs)\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\team.py\", line 134, in run\r\n>     await self.env.run()\r\n> Exception: Traceback (most recent call last):\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\r\n>     result = await fn(*args, **kwargs)\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\actions\\action_node.py\", line 432, in _aask_v1\r\n>     instruct_content = output_class(**parsed_data)\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\pydantic\\main.py\", line 171, in __init__\r\n>     self.__pydantic_validator__.validate_python(data, self_instance=self)\r\n> pydantic_core._pydantic_core.ValidationError: 1 validation error for PM_NODE_AN\r\n>   Value error, Missing fields: {'Required Python packages'} [type=value_error, input_value={'Required Java packages'...or terminal operators.'}, input_type=dict]\r\n>     For further information visit https://errors.pydantic.dev/2.6/v/value_error\r\n\r\n> The above exception was the direct cause of the following exception:\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\utils\\common.py\", line 640, in wrapper\r\n>     return await func(self, *args, **kwargs)\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\roles\\role.py\", line 550, in run\r\n>     rsp = await self.react()\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\roles\\role.py\", line 517, in react\r\n>     rsp = await self._react()\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\roles\\role.py\", line 463, in _react\r\n>     rsp = await self._act()\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\roles\\role.py\", line 392, in _act\r\n>     response = await self.rc.todo.run(self.rc.history)\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\actions\\project_management.py\", line 43, in run\r\n>     task_doc = await self._update_tasks(filename=filename)\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\actions\\project_management.py\", line 66, in _update_tasks\r\n>     rsp = await self._run_new_tasks(context=system_design_doc.content)\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\actions\\project_management.py\", line 76, in _run_new_tasks\r\n>     node = await PM_NODE.fill(context, self.llm, schema=self.prompt_schema)\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\actions\\action_node.py\", line 505, in fill\r\n>     return await self.simple_fill(schema=schema, mode=mode, images=images, timeout=timeout, exclude=exclude)\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\metagpt\\actions\\action_node.py\", line 457, in simple_fill\r\n>     content, scontent = await self._aask_v1(\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\r\n>     return await fn(*args, **kwargs)\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\r\n>     do = self.iter(retry_state=retry_state)\r\n>   File \"C:\\Projects\\projmgpt\\venv\\lib\\site-packages\\tenacity\\__init__.py\", line 326, in iter\r\n>     raise retry_exc from fut.exception()\r\n> tenacity.RetryError: RetryError[<Future at 0x224aceb39d0 state=finished raised ValidationError>]\r\n",
      "state": "closed",
      "author": "katemamba",
      "author_type": "User",
      "created_at": "2025-01-06T20:15:39Z",
      "updated_at": "2025-02-23T00:33:34Z",
      "closed_at": "2025-02-23T00:33:33Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1657/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1657",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1657",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:20.803172",
      "comments": [
        {
          "author": "iorisa",
          "body": "> 2025-01-07 01:28:33.162 | ERROR | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 343.484(s), this was the 6th time calling it. exp: 1 validation error for PM_NODE_AN\r\n> \r\n> Value error, Missing fields: {'Required Python packages'} [type=v",
          "created_at": "2025-01-09T02:03:19Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-09T00:32:51Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-23T00:33:33Z"
        }
      ]
    },
    {
      "issue_number": 1149,
      "title": "Build Action for DB operation such as connection and analysis",
      "body": "**Feature description**\r\n<!-- Clear and direct description of the functionality of the currently submitted or proposed feature -->\r\n\r\nSuggest to build a Action (and Role) for DB operation such as DB connection and make data visualization from DB basic on LLM.\r\n\r\nThe Aciton/Role can be:\r\n1. connect to DB with user conf.\r\n2. data analysis and visualization (such as LLM-based BI).\r\n\r\n**Your Feature**\r\n<!-- Describe the idea or process of implementing the current feature. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- When submitting features, you need to complete the corresponding doc/tests/examples to facilitate verification by reviewers. -->\r\n\r\n",
      "state": "closed",
      "author": "jinchihe",
      "author_type": "User",
      "created_at": "2024-04-01T12:46:16Z",
      "updated_at": "2025-02-22T00:29:47Z",
      "closed_at": "2025-02-22T00:29:46Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1149/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "iorisa"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1149",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1149",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:20.995837",
      "comments": [
        {
          "author": "geekan",
          "body": "Outstanding concept! Can you write more about this idea?",
          "created_at": "2024-04-02T02:47:08Z"
        },
        {
          "author": "krish240574",
          "body": "1. Connect to a dB with creds., or to a BI system. \r\n2. Get data based on query\r\n3. Plot, train models based on data\r\n\r\nThis could simply become a tool, that returns data to the DI, which is then consumed by the DI for analysis   ",
          "created_at": "2024-04-09T08:26:30Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-06T00:30:39Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-22T00:29:46Z"
        }
      ]
    },
    {
      "issue_number": 1160,
      "title": "save_role for the data interpreter would be great if it saved individual files instead of a jupyter notebook",
      "body": "**Feature description**\r\nBasically the title. If you add save_role to any of the di files it saves the plan and then it saves the code as a jupyter notebook. would be incredibly usefull after everything has been completed successfully for it to save the final working copies of the files it has created into individual/single script. Because the current jupyter notebook includes everything - the broken code, the outputs, the new code with fixes, so its not very useful. \r\n\r\nmuch love to this project",
      "state": "closed",
      "author": "cranyy",
      "author_type": "User",
      "created_at": "2024-04-05T01:17:51Z",
      "updated_at": "2025-02-20T00:31:06Z",
      "closed_at": "2025-02-20T00:31:05Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1160/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1160",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1160",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:21.186138",
      "comments": [
        {
          "author": "geekan",
          "body": "I think this feature will be very useful indeed @garylin2099",
          "created_at": "2024-04-05T14:10:59Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-06T00:30:38Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-20T00:31:05Z"
        }
      ]
    },
    {
      "issue_number": 1167,
      "title": "Datainterpreter Message history, available for usage like chat?",
      "body": "**Feature description**\r\n<!-- Clear and direct description of the functionality of the currently submitted or proposed feature -->\r\nIs the message history for DI available , like a chat feature? I need to use it in a web app, so the user is updated frequently. \r\nThe history is dumped to data/<timestamp>/plan.json, I see that, but that happens only after the run completes.\r\nAre running messages available? \r\n\r\nI see inside metagpt/roles/role.py, the following :\r\ndef get_memories(self, k=0) -> list[Message]:\r\n        \"\"\"A wrapper to return the most recent k memories of this role, return all when k=0\"\"\"\r\n        return self.rc.memory.get(k=k)\r\nand a variable called working_memory\r\n\r\nCan they be useful somehow?\r\n        \r\n\r\n**Your Feature**\r\n<!-- Describe the idea or process of implementing the current feature. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- When submitting features, you need to complete the corresponding doc/tests/examples to facilitate verification by reviewers. -->\r\n",
      "state": "closed",
      "author": "krish240574",
      "author_type": "User",
      "created_at": "2024-04-09T05:37:35Z",
      "updated_at": "2025-02-19T00:30:51Z",
      "closed_at": "2025-02-19T00:30:50Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1167/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1167",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1167",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:21.415623",
      "comments": [
        {
          "author": "geekan",
          "body": "There are some codes that have not yet been merged, perhaps u'll need to wait for serveral weeks.",
          "created_at": "2024-05-18T11:06:00Z"
        },
        {
          "author": "krish240574",
          "body": "Any updates on this, please ? I'd love to be able to echo messages to the user, as the DI executes. For now, the user has to wait till all execution completes, then I can retrieve the dumped history from save_history and send to user. It would be great if I could access regular updates. \r\n",
          "created_at": "2024-11-09T17:22:20Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-04T00:29:56Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-19T00:30:50Z"
        }
      ]
    },
    {
      "issue_number": 1170,
      "title": "When will it be made a plugin for VSCode and IDEA",
      "body": "**Feature description**\r\nI hope it could be used as a plugin with VSCode or IDEA, and could work with an exist software project. Because this is the real daily job actually.\r\n\r\n**Your Feature**\r\n<!-- Describe the idea or process of implementing the current feature. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- When submitting features, you need to complete the corresponding doc/tests/examples to facilitate verification by reviewers. -->\r\n",
      "state": "closed",
      "author": "azlanxun",
      "author_type": "User",
      "created_at": "2024-04-09T09:31:58Z",
      "updated_at": "2025-02-19T00:30:50Z",
      "closed_at": "2025-02-19T00:30:49Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1170/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1170",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1170",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:21.603361",
      "comments": [
        {
          "author": "seehi",
          "body": "Can you provide a corresponding scenario combined with your current use of metagpt?",
          "created_at": "2024-04-11T07:25:31Z"
        },
        {
          "author": "azlanxun",
          "body": "As a software engineer in company, there is few opportunities to start a project from scratch, most job is programming on an existing project, which was started some years ago. \r\nFor example, there is an project about 100K lines, and I make some new modules on it daily.\r\nAnd usually we write a new f",
          "created_at": "2024-04-29T07:01:35Z"
        },
        {
          "author": "geekan",
          "body": "Sorry, we are currently at a high intensity of work, so the response is very slow. We are solving the scenario you mentioned, please wait for a while.",
          "created_at": "2024-05-18T11:04:30Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-04T00:29:55Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-19T00:30:48Z"
        }
      ]
    },
    {
      "issue_number": 1650,
      "title": "can not use qwen-vl-max",
      "body": "**Bug description**\r\n<!-- Clearly and directly describe the current bug -->\r\ncan not use the qwen-vl-max API\r\n**Bug solved method**\r\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\r\n\r\n**Environment information**\r\n<!-- Environmentï¼šSystem version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\r\n\r\n- LLM type and model name: dashscope, qwen-vl-max-latest\r\n- System version: ubuntu22.04\r\n- Python version: 3.10\r\n- MetaGPT version or branch: 0.8.1\r\n\r\n<!-- Dependent packagessï¼šthe packages version cause the bug(like `pydantic 1.10.8`), installation methodï¼ˆlike `pip install metagpt` or `pip install from source` or `run in docker`ï¼‰ -->\r\n\r\n- packages version:\r\n- installation method: pip\r\n\r\n**Screenshots or logs**\r\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\r\nException: Traceback (most recent call last):\r\n  File \"/cpfs01/user/conda/envs/agent/lib/python3.10/site-packages/metagpt/utils/common.py\", line 640, in wrapper\r\n    return await func(self, *args, **kwargs)\r\n  File \"/cpfs01/user/conda/envs/agent/lib/python3.10/site-packages/metagpt/roles/role.py\", line 550, in run\r\n    rsp = await self.react()\r\n  File \"/cpfs01/user/conda/envs/agent/lib/python3.10/site-packages/metagpt/roles/role.py\", line 519, in react\r\n    rsp = await self._act_by_order()\r\n  File \"/cpfs01/user/conda/envs/agent/lib/python3.10/site-packages/metagpt/roles/role.py\", line 473, in _act_by_order\r\n    rsp = await self._act()\r\n  File \"/nas/shared/landmark_3dgen/yangyuhang/Agent/test.py\", line 147, in _act\r\n    result = await todo.run(msg.content)\r\n  File \"/nas/shared/landmark_3dgen/yangyuhang/Agent/test.py\", line 36, in run\r\n    rsp = await self._aask(prompt)\r\n  File \"/cpfs01/user/conda/envs/agent/lib/python3.10/site-packages/metagpt/actions/action.py\", line 93, in _aask\r\n    return await self.llm.aask(prompt, system_msgs)\r\n  File \"/cpfs01/user/conda/envs/agent/lib/python3.10/site-packages/metagpt/provider/base_llm.py\", line 150, in aask\r\n    rsp = await self.acompletion_text(message, stream=stream, timeout=self.get_timeout(timeout))\r\n  File \"/cpfs01/user/conda/envs/agent/lib/python3.10/site-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\r\n    return await fn(*args, **kwargs)\r\n  File \"/cpfs01/user/conda/envs/agent/lib/python3.10/site-packages/tenacity/_asyncio.py\", line 47, in __call__\r\n    do = self.iter(retry_state=retry_state)\r\n  File \"/cpfs01/user/conda/envs/agent/lib/python3.10/site-packages/tenacity/__init__.py\", line 314, in iter\r\n    return fut.result()\r\n  File \"/cpfs01/user/conda/envs/agent/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\r\n    return self.__get_result()\r\n  File \"/cpfs01/user/conda/envs/agent/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\r\n    raise self._exception\r\n  File \"/cpfs01/user/conda/envs/agent/lib/python3.10/site-packages/tenacity/_asyncio.py\", line 50, in __call__\r\n    result = await fn(*args, **kwargs)\r\n  File \"/cpfs01/user/conda/envs/agent/lib/python3.10/site-packages/metagpt/provider/base_llm.py\", line 200, in acompletion_text\r\n    return await self._achat_completion_stream(messages, timeout=self.get_timeout(timeout))\r\n  File \"/cpfs01/user/conda/envs/agent/lib/python3.10/site-packages/metagpt/provider/dashscope_api.py\", line 220, in _achat_completion_stream\r\n    self._check_response(chunk)\r\n  File \"/cpfs01/user/conda/envs/agent/lib/python3.10/site-packages/metagpt/provider/dashscope_api.py\", line 194, in _check_response\r\n    raise RuntimeError(f\"code: {resp.code}, request_id: {resp.request_id}, message: {resp.message}\")\r\nRuntimeError: code: InvalidParameter, request_id: bd2b84b8-7989-93d3-b942-5f1af2ff129a, message: url error, please check urlï¼",
      "state": "closed",
      "author": "yyvhang",
      "author_type": "User",
      "created_at": "2024-12-27T13:35:27Z",
      "updated_at": "2025-02-17T00:32:39Z",
      "closed_at": "2025-02-17T00:32:38Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1650/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1650",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1650",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:21.820211",
      "comments": [
        {
          "author": "iorisa",
          "body": "Ok, I'll follow up on this issue.",
          "created_at": "2025-01-02T14:28:47Z"
        },
        {
          "author": "iorisa",
          "body": "The follow `config/config2.yaml` configuration is working:\r\n```yaml\r\nllm:\r\n  api_type: \"openai\"\r\n  model: \"qwen-vl-max\"\r\n  base_url: \"https://dashscope.aliyuncs.com/compatible-mode/v1\"\r\n  api_key: \"sk-3b9e***\"\r\n  max_token: 1500\r\n  temperature: 0.5\r\n```",
          "created_at": "2025-01-03T11:36:19Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-03T00:31:01Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-17T00:32:38Z"
        }
      ]
    },
    {
      "issue_number": 1636,
      "title": "Fail to run demo: module 'proto' has no attribute 'module'",
      "body": "**Bug description**\r\nFirst, thank you for making this fantastic project! I'm not able to run the demo after installation.\r\n\r\nI tried several means to install metagpt but all of them raised the \"module 'proto' has no attribute 'module'\" error. Is that because I'm using Debian?\r\n\r\n\r\n$ metagpt \"write a cli blackjack game\"\r\n2024-12-10 18:01:10.074 | INFO     | metagpt.const:get_metagpt_package_root:21 - Package root set to /opt/tiger/MetaGPT\r\nâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Traceback (most recent call last) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\r\nâ”‚ /opt/tiger/MetaGPT/metagpt/software_company.py:117 in startup                                    â”‚\r\nâ”‚                                                                                                  â”‚\r\nâ”‚   114 â”‚   â”‚   typer.echo(\"Missing argument 'IDEA'. Run 'metagpt --help' for more information.\"   â”‚\r\nâ”‚   115 â”‚   â”‚   raise typer.Exit()                                                                 â”‚\r\nâ”‚   116 â”‚                                                                                          â”‚\r\nâ”‚ â± 117 â”‚   return generate_repo(                                                                  â”‚\r\nâ”‚   118 â”‚   â”‚   idea,                                                                              â”‚\r\nâ”‚   119 â”‚   â”‚   investment,                                                                        â”‚\r\nâ”‚   120 â”‚   â”‚   n_round,                                                                           â”‚\r\nâ”‚                                                                                                  â”‚\r\nâ”‚ /opt/tiger/MetaGPT/metagpt/software_company.py:32 in generate_repo                               â”‚\r\nâ”‚                                                                                                  â”‚\r\nâ”‚    29 ) -> ProjectRepo:                                                                          â”‚\r\nâ”‚    30 â”‚   \"\"\"Run the startup logic. Can be called from CLI or other Python scripts.\"\"\"           â”‚\r\nâ”‚    31 â”‚   from metagpt.config2 import config                                                     â”‚\r\nâ”‚ â±  32 â”‚   from metagpt.context import Context                                                    â”‚\r\nâ”‚    33 â”‚   from metagpt.roles import (                                                            â”‚\r\nâ”‚    34 â”‚   â”‚   Architect,                                                                         â”‚\r\nâ”‚    35 â”‚   â”‚   Engineer,                                                                          â”‚\r\nâ”‚                                                                                                  â”‚\r\nâ”‚ /opt/tiger/MetaGPT/metagpt/context.py:16 in <module>                                             â”‚\r\nâ”‚                                                                                                  â”‚\r\nâ”‚    13                                                                                            â”‚\r\nâ”‚    14 from metagpt.config2 import Config                                                         â”‚\r\nâ”‚    15 from metagpt.configs.llm_config import LLMConfig, LLMType                                  â”‚\r\nâ”‚ â±  16 from metagpt.provider.base_llm import BaseLLM                                              â”‚\r\nâ”‚    17 from metagpt.provider.llm_provider_registry import create_llm_instance                     â”‚\r\nâ”‚    18 from metagpt.utils.cost_manager import (                                                   â”‚\r\nâ”‚    19 â”‚   CostManager,                                                                           â”‚\r\nâ”‚                                                                                                  â”‚\r\nâ”‚ /opt/tiger/MetaGPT/metagpt/provider/__init__.py:9 in <module>                                    â”‚\r\nâ”‚                                                                                                  â”‚\r\nâ”‚    6 @File    : __init__.py                                                                      â”‚\r\nâ”‚    7 \"\"\"                                                                                         â”‚\r\nâ”‚    8                                                                                             â”‚\r\nâ”‚ â±  9 from metagpt.provider.google_gemini_api import GeminiLLM                                    â”‚\r\nâ”‚   10 from metagpt.provider.ollama_api import OllamaLLM                                           â”‚\r\nâ”‚   11 from metagpt.provider.openai_api import OpenAILLM                                           â”‚\r\nâ”‚   12 from metagpt.provider.zhipuai_api import ZhiPuAILLM                                         â”‚\r\nâ”‚                                                                                                  â”‚\r\nâ”‚ /opt/tiger/MetaGPT/metagpt/provider/google_gemini_api.py:9 in <module>                           â”‚\r\nâ”‚                                                                                                  â”‚\r\nâ”‚     6 from dataclasses import asdict                                                             â”‚\r\nâ”‚     7 from typing import List, Optional, Union                                                   â”‚\r\nâ”‚     8                                                                                            â”‚\r\nâ”‚ â±   9 import google.generativeai as genai                                                        â”‚\r\nâ”‚    10 from google.ai import generativelanguage as glm                                            â”‚\r\nâ”‚    11 from google.generativeai.generative_models import GenerativeModel                          â”‚\r\nâ”‚    12 from google.generativeai.types import content_types                                        â”‚\r\nâ”‚                                                                                                  â”‚\r\nâ”‚ /mnt/bn/gilesluo000/miniconda3/envs/metagpt/lib/python3.9/site-packages/google/generativeai/__in â”‚\r\nâ”‚ it__.py:45 in <module>                                                                           â”‚\r\nâ”‚                                                                                                  â”‚\r\nâ”‚   42                                                                                             â”‚\r\nâ”‚   43 from google.generativeai import version                                                     â”‚\r\nâ”‚   44                                                                                             â”‚\r\nâ”‚ â± 45 from google.generativeai import types                                                       â”‚\r\nâ”‚   46 from google.generativeai.types import GenerationConfig                                      â”‚\r\nâ”‚   47                                                                                             â”‚\r\nâ”‚   48                                                                                             â”‚\r\nâ”‚                                                                                                  â”‚\r\nâ”‚ /mnt/bn/gilesluo000/miniconda3/envs/metagpt/lib/python3.9/site-packages/google/generativeai/type â”‚\r\nâ”‚ s/__init__.py:17 in <module>                                                                     â”‚\r\nâ”‚                                                                                                  â”‚\r\nâ”‚   14 # limitations under the License.                                                            â”‚\r\nâ”‚   15 \"\"\"A collection of type definitions used throughout the library.\"\"\"                         â”‚\r\nâ”‚   16                                                                                             â”‚\r\nâ”‚ â± 17 from google.generativeai.types.discuss_types import *                                       â”‚\r\nâ”‚   18 from google.generativeai.types.model_types import *                                         â”‚\r\nâ”‚   19 from google.generativeai.types.text_types import *                                          â”‚\r\nâ”‚   20 from google.generativeai.types.citation_types import *                                      â”‚\r\nâ”‚                                                                                                  â”‚\r\nâ”‚ /mnt/bn/gilesluo000/miniconda3/envs/metagpt/lib/python3.9/site-packages/google/generativeai/type â”‚\r\nâ”‚ s/discuss_types.py:22 in <module>                                                                â”‚\r\nâ”‚                                                                                                  â”‚\r\nâ”‚    19 from typing import Any, Dict, Union, Iterable, Optional, Tuple, List                       â”‚\r\nâ”‚    20 from typing_extensions import TypedDict                                                    â”‚\r\nâ”‚    21                                                                                            â”‚\r\nâ”‚ â±  22 import google.ai.generativelanguage as glm                                                 â”‚\r\nâ”‚    23 from google.generativeai import string_utils                                               â”‚\r\nâ”‚    24                                                                                            â”‚\r\nâ”‚    25 from google.generativeai.types import safety_types                                         â”‚\r\nâ”‚                                                                                                  â”‚\r\nâ”‚ /mnt/bn/gilesluo000/miniconda3/envs/metagpt/lib/python3.9/site-packages/google/ai/generativelang â”‚\r\nâ”‚ uage/__init__.py:21 in <module>                                                                  â”‚\r\nâ”‚                                                                                                  â”‚\r\nâ”‚    18 __version__ = package_version.__version__                                                  â”‚\r\nâ”‚    19                                                                                            â”‚\r\nâ”‚    20                                                                                            â”‚\r\nâ”‚ â±  21 from google.ai.generativelanguage_v1beta.services.discuss_service.async_client import (    â”‚\r\nâ”‚    22 â”‚   DiscussServiceAsyncClient,                                                             â”‚\r\nâ”‚    23 )                                                                                          â”‚\r\nâ”‚    24 from google.ai.generativelanguage_v1beta.services.discuss_service.client import (          â”‚\r\nâ”‚                                                                                                  â”‚\r\nâ”‚ /mnt/bn/gilesluo000/miniconda3/envs/metagpt/lib/python3.9/site-packages/google/ai/generativelang â”‚\r\nâ”‚ uage_v1beta/__init__.py:21 in <module>                                                           â”‚\r\nâ”‚                                                                                                  â”‚\r\nâ”‚    18 __version__ = package_version.__version__                                                  â”‚\r\nâ”‚    19                                                                                            â”‚\r\nâ”‚    20                                                                                            â”‚\r\nâ”‚ â±  21 from .services.discuss_service import DiscussServiceAsyncClient, DiscussServiceClient      â”‚\r\nâ”‚    22 from .services.generative_service import (                                                 â”‚\r\nâ”‚    23 â”‚   GenerativeServiceAsyncClient,                                                          â”‚\r\nâ”‚    24 â”‚   GenerativeServiceClient,                                                               â”‚\r\nâ”‚                                                                                                  â”‚\r\nâ”‚ /mnt/bn/gilesluo000/miniconda3/envs/metagpt/lib/python3.9/site-packages/google/ai/generativelang â”‚\r\nâ”‚ uage_v1beta/services/discuss_service/__init__.py:16 in <module>                                  â”‚\r\nâ”‚                                                                                                  â”‚\r\nâ”‚   13 # See the License for the specific language governing permissions and                       â”‚\r\nâ”‚   14 # limitations under the License.                                                            â”‚\r\nâ”‚   15 #                                                                                           â”‚\r\nâ”‚ â± 16 from .async_client import DiscussServiceAsyncClient                                         â”‚\r\nâ”‚   17 from .client import DiscussServiceClient                                                    â”‚\r\nâ”‚   18                                                                                             â”‚\r\nâ”‚   19 __all__ = (                                                                                 â”‚\r\nâ”‚                                                                                                  â”‚\r\nâ”‚ /mnt/bn/gilesluo000/miniconda3/envs/metagpt/lib/python3.9/site-packages/google/ai/generativelang â”‚\r\nâ”‚ uage_v1beta/services/discuss_service/async_client.py:47 in <module>                              â”‚\r\nâ”‚                                                                                                  â”‚\r\nâ”‚    44                                                                                            â”‚\r\nâ”‚    45 from google.longrunning import operations_pb2  # type: ignore                              â”‚\r\nâ”‚    46                                                                                            â”‚\r\nâ”‚ â±  47 from google.ai.generativelanguage_v1beta.types import discuss_service, safety              â”‚\r\nâ”‚    48                                                                                            â”‚\r\nâ”‚    49 from .client import DiscussServiceClient                                                   â”‚\r\nâ”‚    50 from .transports.base import DEFAULT_CLIENT_INFO, DiscussServiceTransport                  â”‚\r\nâ”‚                                                                                                  â”‚\r\nâ”‚ /mnt/bn/gilesluo000/miniconda3/envs/metagpt/lib/python3.9/site-packages/google/ai/generativelang â”‚\r\nâ”‚ uage_v1beta/types/__init__.py:16 in <module>                                                     â”‚\r\nâ”‚                                                                                                  â”‚\r\nâ”‚    13 # See the License for the specific language governing permissions and                      â”‚\r\nâ”‚    14 # limitations under the License.                                                           â”‚\r\nâ”‚    15 #                                                                                          â”‚\r\nâ”‚ â±  16 from .citation import CitationMetadata, CitationSource                                     â”‚\r\nâ”‚    17 from .content import (                                                                     â”‚\r\nâ”‚    18 â”‚   Blob,                                                                                  â”‚\r\nâ”‚    19 â”‚   Content,                                                                               â”‚\r\nâ”‚                                                                                                  â”‚\r\nâ”‚ /mnt/bn/gilesluo000/miniconda3/envs/metagpt/lib/python3.9/site-packages/google/ai/generativelang â”‚\r\nâ”‚ uage_v1beta/types/citation.py:22 in <module>                                                     â”‚\r\nâ”‚                                                                                                  â”‚\r\nâ”‚    19                                                                                            â”‚\r\nâ”‚    20 import proto  # type: ignore                                                               â”‚\r\nâ”‚    21                                                                                            â”‚\r\nâ”‚ â±  22 __protobuf__ = proto.module(                                                               â”‚\r\nâ”‚    23 â”‚   package=\"google.ai.generativelanguage.v1beta\",                                         â”‚\r\nâ”‚    24 â”‚   manifest={                                                                             â”‚\r\nâ”‚    25 â”‚   â”‚   \"CitationMetadata\",                                                                â”‚\r\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\r\nAttributeError: module 'proto' has no attribute 'module'\r\n\r\n\r\n**Environment information**\r\n\r\n\r\n- LLM type and model name:\r\n- System version:Debian GNU/Linux 12 (bookworm)\r\n- Python version:3.9.30\r\n- MetaGPT version or branch: v0.8.1\r\n",
      "state": "closed",
      "author": "GilesLuo",
      "author_type": "User",
      "created_at": "2024-12-10T10:19:19Z",
      "updated_at": "2025-02-16T00:33:45Z",
      "closed_at": "2025-02-16T00:33:45Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1636/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1636",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1636",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:22.007751",
      "comments": [
        {
          "author": "shenchucheng",
          "body": "Which version of protobuf is being used?",
          "created_at": "2024-12-11T07:36:17Z"
        },
        {
          "author": "iorisa",
          "body": "Which version of `google-generativeai` is being used?\r\nI'm using 0.4.1\r\n```bash\r\npip show google-generativeai\r\nName: google-generativeai\r\nVersion: 0.4.1\r\nSummary: Google Generative AI High level API client library and tools.\r\nHome-page: https://github.com/google/generative-ai-python\r\nAuthor: Google ",
          "created_at": "2025-01-02T14:40:34Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-02-02T00:32:17Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-16T00:33:45Z"
        }
      ]
    },
    {
      "issue_number": 1177,
      "title": "Data Interpreter - Large JSON/tabular data being returned by a tool, should not be included in subsequent code prompts. ",
      "body": "**Bug description**\r\n<!-- Clearly and directly describe the current bug -->\r\nI have a tool, that returns a large JSON/tabular data. I find that the DI takes all this data(50,000) chars and tries to add it to the prompt for subsequent analysis. (This is too expensive and slow)\r\nI could return a file name from the tool, where I dumped the JSON into, but this doesn't *ALWAYS* work, sometimes the DI tries to write all the data into the prompt, or worse still, truncates it. \r\n\r\nWhat is a more efficient way to do this? \r\n\r\n**Bug solved method**\r\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\r\n\r\n**Environment information**\r\n<!-- Environmentï¼šSystem version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\r\nOpenAI gpt-4-1106-preview\r\nPython 3.10\r\nUbuntu 22.04\r\n\r\n- LLM type and model name:\r\n- System version:\r\n- Python version:\r\n- MetaGPT version or branch:\r\n\r\n<!-- Dependent packagessï¼šthe packages version cause the bug(like `pydantic 1.10.8`), installation methodï¼ˆlike `pip install metagpt` or `pip install from source` or `run in docker`ï¼‰ -->\r\n\r\n- packages version:\r\n- installation method: \r\n\r\n**Screenshots or logs**\r\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\r\n",
      "state": "closed",
      "author": "krish240574",
      "author_type": "User",
      "created_at": "2024-04-10T14:50:34Z",
      "updated_at": "2025-02-11T00:30:36Z",
      "closed_at": "2025-02-11T00:30:34Z",
      "labels": [
        "bug",
        "inactive"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1177/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1177",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1177",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:22.226318",
      "comments": [
        {
          "author": "seehi",
          "body": "@garylin2099 could you take a look at this?",
          "created_at": "2024-04-11T12:01:45Z"
        },
        {
          "author": "garylin2099",
          "body": "Let me clarify the question, so DI is expected to generate a string for your downstream tasks, and you want the string to contain the file name instead of the file content, which is very long, is my understanding correct?",
          "created_at": "2024-04-11T14:03:51Z"
        },
        {
          "author": "krish240574",
          "body": "umm, let me explain:\r\nTools could return various kinds of outputs, correct?\r\nIn my case, my tool returns the rows of a table, as JSON(This could be huge). What happens, is that after the tool execution has completed, DI picks up the output from the logs/working memory and adds it all to the prompt, ",
          "created_at": "2024-04-12T01:46:30Z"
        },
        {
          "author": "krish240574",
          "body": "These lines might hold a clue, to the issue:\r\n[https://github.com/geekan/MetaGPT/blob/aa715fcace7577ec711ba675c51d0c22cfab84b3/metagpt/roles/di/data_interpreter.py#L186](url)\r\n ",
          "created_at": "2024-04-12T02:07:46Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-28T00:30:08Z"
        }
      ]
    },
    {
      "issue_number": 1179,
      "title": "Support for converting existing software projects",
      "body": "It would be great if there was strong support for roles that enable MetaGPT to take an existing project written in one language and convert it to another or convert from one platform to another.",
      "state": "closed",
      "author": "pathquester",
      "author_type": "User",
      "created_at": "2024-04-11T06:37:37Z",
      "updated_at": "2025-02-08T00:29:27Z",
      "closed_at": "2025-02-08T00:29:27Z",
      "labels": [
        "enhancement",
        "inactive"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1179/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1179",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1179",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:22.471539",
      "comments": [
        {
          "author": "seehi",
          "body": "Sounds good, but the priority might not be that high.",
          "created_at": "2024-04-11T07:10:56Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-25T00:29:24Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-08T00:29:26Z"
        }
      ]
    },
    {
      "issue_number": 1189,
      "title": "Consistence check for the generated code might be a big improvement",
      "body": "I think it might be a big improvement if metagpt could add consistence check for the generated code, add fix the unconsistent code according to the result of the consistence check.\r\n",
      "state": "closed",
      "author": "longweiii",
      "author_type": "User",
      "created_at": "2024-04-12T13:29:01Z",
      "updated_at": "2025-02-08T00:29:26Z",
      "closed_at": "2025-02-08T00:29:26Z",
      "labels": [
        "enhancement",
        "inactive"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1189/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1189",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1189",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:22.678895",
      "comments": [
        {
          "author": "seehi",
          "body": "Working on optimizing that.\r\n",
          "created_at": "2024-04-12T13:36:06Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-25T00:29:22Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-08T00:29:25Z"
        }
      ]
    },
    {
      "issue_number": 1199,
      "title": "Can not able to convert mmd to other format.",
      "body": "Can anyone give insights on below error? \r\n\r\nWARNING  | metagpt.utils.mermaid:mermaid_to_file:70 -                                                                             Error: net::ERR_ACCESS_DENIED at file:///home/ubuntu/.nvm/versions/node/v18.20.2/lib/node_modules/@mermaid-js/mermaid-cli/dist/index.html                       at navigate (file:///home/ubuntu/.nvm/versions/node/v18.20.2/lib/node_modules/@mermaid-js/mermaid-cli/node_modules/puppeteer-core/lib/esm/puppeteer/common/Frame.js:215:23)                                                                                                                                             at process.processTicksAndRejections (node:internal/process/task_queues:95:5)                                                                               at async Frame.goto (file:///home/ubuntu/.nvm/versions/node/v18.20.2/lib/node_modules/@mermaid-js/mermaid-cli/node_modules/puppeteer-core/lib/esm/puppeteer/common/Frame.js:181:21)                                                                                                                                     at async CDPPage.goto (file:///home/ubuntu/.nvm/versions/node/v18.20.2/lib/node_modules/@mermaid-js/mermaid-cli/node_modules/puppeteer-core/lib/esm/puppeteer/common/Page.js:435:16)\r\n    at async renderMermaid (file:///home/ubuntu/.nvm/versions/node/v18.20.2/lib/node_modules/@mermaid-js/mermaid-cli/src/index.js:242:5)\r\n    at async parseMMD (file:///home/ubuntu/.nvm/versions/node/v18.20.2/lib/node_modules/@mermaid-js/mermaid-cli/src/index.js:218:20)\r\n    at async run (file:///home/ubuntu/.nvm/versions/node/v18.20.2/lib/node_modules/@mermaid-js/mermaid-cli/src/index.js:479:20)\r\n    at async cli (file:///home/ubuntu/.nvm/versions/node/v18.20.2/lib/node_modules/@mermaid-js/mermaid-cli/src/index.js:184:3)",
      "state": "closed",
      "author": "Unkownforlife",
      "author_type": "User",
      "created_at": "2024-04-16T06:50:56Z",
      "updated_at": "2025-02-06T00:30:37Z",
      "closed_at": "2025-02-06T00:30:37Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1199/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1199",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1199",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:22.912297",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-23T00:29:58Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-06T00:30:36Z"
        }
      ]
    },
    {
      "issue_number": 1201,
      "title": "æ–°ç‰ˆç‹¼äººæ€æ— æ³•æŠ•ç¥¨å‡ºå±€player",
      "body": "\r\næˆ‘å°è¯•äº†æœ€æ–°ç‰ˆmainåˆ†æ”¯çš„ç‹¼äººæ€ï¼Œåœ¨è¿™ä¸ªæ–°ç‰ˆç‹¼äººæ€å¯¹å±€ä¸­ï¼Œæ— æ³•æŠ•ç¥¨å‡ºå±€playerï¼Œä»è€Œå¯¼è‡´æ¸¸æˆæ— é™åœ¨ç¬¬ä¸€è½®çš„æŠ•ç¥¨é˜¶æ®µå¾ªç¯ã€‚å›¾ç‰‡ä¸ºç¬¬ä¸€æ¬¡æŠ•ç¥¨çš„æœ«å°¾å’Œç¬¬äºŒæ¬¡é‡å¤å¾ªç¯çš„å¼€å§‹ã€‚\r\n![image](https://github.com/geekan/MetaGPT/assets/95960312/c57abc78-10ca-45c3-95ea-7f80a5f4916b)\r\n![image](https://github.com/geekan/MetaGPT/assets/95960312/c4bff83f-43cc-4120-8056-1abd42a957a8)\r\n",
      "state": "closed",
      "author": "kbkbsxwd",
      "author_type": "User",
      "created_at": "2024-04-16T07:37:18Z",
      "updated_at": "2025-02-06T00:30:36Z",
      "closed_at": "2025-02-06T00:30:36Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1201/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1201",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1201",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:23.081959",
      "comments": [
        {
          "author": "seehi",
          "body": "FYI: @garylin2099 ",
          "created_at": "2024-04-17T02:56:03Z"
        },
        {
          "author": "kbkbsxwd",
          "body": "æˆ‘è®¤ä¸ºé”™è¯¯åœ¨è¿™é‡Œï¼šåœ¨è¿™ä¸ªè¾“å‡ºä¸­ï¼Œå°½ç®¡æœ€åplayer1è·å¾—ç»å¤§å¤šæ•°æŠ•ç¥¨ï¼Œä½†ä¸»æŒäººå´å°†å·²ç»è¢«ç‹¼äººæ€æ­»çš„player2å®£å¸ƒæ·˜æ±°ã€‚ä¹‹åä¸»æŒäººact:242-Moderator(Moderator):Unknown instruction.  æœ€ç»ˆå¯¼è‡´é‡å¤æŠ•ç¥¨æµç¨‹ã€‚",
          "created_at": "2024-04-20T08:11:27Z"
        },
        {
          "author": "better629",
          "body": "ok, you can add a PR to update the problem. And we also arranged a colleague to follow and fix this.",
          "created_at": "2024-04-20T08:57:01Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-23T00:29:57Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-06T00:30:35Z"
        }
      ]
    },
    {
      "issue_number": 1216,
      "title": "Making Data interpreter able to repair llm output, similar to what is done in ActionNode",
      "body": "**Feature description**\r\nUsing open-source models in the data interpreter often leads to issues with incapability of generating correct JSON format . I tried to add `repair_llm_output: true` in the config2.yaml but it didn't work. \r\n\r\nby checking the source code, I noticed that the repair work is conducted in ActionNode, while my issue occurs in WriteAnalysisCode:\r\n1. The model generated incorrect JSON response and passed it into the CodeParser\r\n2. The parser did not match the regex \r\n3. the logger reported an error, then directly returned the incorrectly formatted text.\r\n4. The incorrectly formatted text was passed back to the action, where it failed during decoding with` reflection = json.loads(CodeParser.parse_code(block=None, text=rsp))`\r\n\r\n**The repair mechanism was not triggered.**\r\n![20240422-180524](https://github.com/geekan/MetaGPT/assets/93753250/3fc79a77-d57f-4f59-b81e-dc46ae5907f6)\r\n\r\nTherefore, it is ideal to adapt the repair functionality for the data interpreter as well.\r\n\r\n**Your Feature**\r\nEnabling Data Interpreter to postprocess llm output\r\n",
      "state": "closed",
      "author": "usamimeri",
      "author_type": "User",
      "created_at": "2024-04-22T10:08:40Z",
      "updated_at": "2025-02-05T00:30:23Z",
      "closed_at": "2025-02-05T00:30:22Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1216/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1216",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1216",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:23.278926",
      "comments": [
        {
          "author": "seehi",
          "body": "FYI: @garylin2099 ",
          "created_at": "2024-04-23T02:32:54Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-22T00:30:20Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-05T00:30:22Z"
        }
      ]
    },
    {
      "issue_number": 1211,
      "title": "Add Data Interpreter RAG integration Example",
      "body": "please add an example of best approach in integrating the RAG module into Data Interpreter without hindering the current architecture of the agent.",
      "state": "closed",
      "author": "AliArmani3397",
      "author_type": "User",
      "created_at": "2024-04-20T11:51:29Z",
      "updated_at": "2025-02-05T00:30:23Z",
      "closed_at": "2025-02-05T00:30:23Z",
      "labels": [
        "documentation",
        "inactive"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1211/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "seehi"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1211",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1211",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:23.463634",
      "comments": [
        {
          "author": "seehi",
          "body": "Examples are under development and will be provided later.",
          "created_at": "2024-04-22T02:21:47Z"
        },
        {
          "author": "cjl0222",
          "body": "Hi! Thanks for your great work. I'm also wondering whether you could add this example for integrating RAG into Data Interpreter. It seems that there are only examples for RAG Retrieval and Rerank, but I have no idea how to utilize this ability into the current Data Interpreter Machine learning model",
          "created_at": "2024-11-29T02:20:50Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-22T00:30:21Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-05T00:30:23Z"
        }
      ]
    },
    {
      "issue_number": 1223,
      "title": "use groq llama3-70b-8192 conduct research failed",
      "body": "**Bug description**\r\nuse groq api llama3-70b-8192, run command: **python3 -m metagpt.roles.researcher \"tensorflow vs. pytorch\"**\r\nthen it just stuck here!\r\nuse gpt4 don't have problem.\r\n![image](https://github.com/geekan/MetaGPT/assets/57616924/798bcd4d-a889-4c9c-9bb0-0883333fcf0e)\r\n![image](https://github.com/geekan/MetaGPT/assets/57616924/d7c43b04-3e66-4d23-a3fb-54ad83f99c69)\r\n\r\n\r\n",
      "state": "closed",
      "author": "wzkzs",
      "author_type": "User",
      "created_at": "2024-04-24T02:16:24Z",
      "updated_at": "2025-02-05T00:30:22Z",
      "closed_at": "2025-02-05T00:30:21Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1223/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1223",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1223",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:23.641241",
      "comments": [
        {
          "author": "seehi",
          "body": "Dependent on the capabilities of LLM.\r\nFYI: @shenchucheng ",
          "created_at": "2024-04-24T02:45:15Z"
        },
        {
          "author": "wzkzs",
          "body": "> Dependent on the capabilities of LLM. FYI: @shenchucheng\r\n\r\nWhy does it get stuck without reporting an error?",
          "created_at": "2024-04-24T03:00:18Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-22T00:30:19Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-05T00:30:21Z"
        }
      ]
    },
    {
      "issue_number": 1225,
      "title": "metagpt.utils.text / generate_prompt_chunk() / Calculation for max token length is flawed because LLM model name could actually hold the DEPLOYMENT model name.",
      "body": "**Bug description**\r\n\r\nmetagpt.utils.text / generate_prompt_chunk() / Calculation for max token length is flawed because LLM model name could actually hold the DEPLOYMENT model name.\r\n\r\nThe calculation for max token length, i.e.:\r\n\r\n```\r\n...\r\n    reserved = reserved + count_string_tokens(prompt_template + system_text, model_name)\r\n    # 100 is a magic number to ensure the maximum context length is not exceeded\r\n    max_token = TOKEN_MAX.get(model_name, 2048) - reserved - 100\r\n...\r\n```\r\n\r\nis flawed on a number of counts:\r\n- It does not check for a +ve value. A negative value should raise an exception. If a negative value is derived for max_token the subsequent while loop recursively grows paragraphs with empty lines.\r\n- It assumes that the model_name is always going to be an LLM model name, but this could also be a DEPLOYMENT model name in the case of an Azure OpenAI Service deployment. Because the LLM deployment name could be anything, TOKEN_MATCH will fail to match a valid model name and return the default value - resulting in a negative value.\r\n\r\n**Bug solved method**\r\n\r\nIn order to resolve this issue need to distinguish between the model name and deployment name in the LLMConfig. One refers to the type of model being used, whereas the other refers to an instance / deployment of that type.\r\n\r\n**Environment information**\r\n\r\n- LLM type and model name: Azure OpenAI Service gpt-35-turbo\r\n- System version: Windows 11\r\n- Python version: 3.10.11\r\n- MetaGPT version or branch: 0.8.1\r\n\r\n<!-- Dependent packagesï¼šthe packages version cause the bug(like `pydantic 1.10.8`), installation methodï¼ˆlike `pip install metagpt` or `pip install from source` or `run in docker`ï¼‰ -->\r\n\r\n- packages version:\r\n\r\npoetry = \"~1.7.0\"\r\npython = \">=3.9,<3.13\"\r\naiohttp = \"3.8.6\"\r\nchannels = \"4.0.0\"\r\nfaiss_cpu = \"1.7.4\"\r\nfire = \"0.4.0\"\r\ntyper = \"0.9.0\"\r\nlancedb = \"0.4.0\"\r\nloguru = \"0.6.0\"\r\nmeilisearch = \"0.21.0\"\r\nnumpy = \"^1\"\r\nopenai = \"1.6.1\"\r\nopenpyxl = \"3.1.2\"\r\nbeautifulsoup4 = \"4.12.3\"\r\npandas = \"2.1.1\"\r\npydantic = \"2.5.3\"\r\npython_docx = \"0.8.11\"\r\nPyYAML = \"6.0.1\"\r\nsetuptools = \"65.6.3\"\r\ntenacity = \"8.2.3\"\r\ntiktoken = \"0.6.0\"\r\ntqdm = \"4.66.2\"\r\nanthropic = \"0.18.1\"\r\ntyping-inspect = \"0.8.0\"\r\nlibcst = \"1.0.1\"\r\nqdrant-client = \"1.7.0\"\r\nta = \"0.10.2\"\r\nsemantic-kernel = \"0.4.3.dev0\"\r\nwrapt = \"1.15.0\"\r\naioredis = \"~2.0.1\"\r\nwebsocket-client = \"1.6.2\"\r\naiofiles = \"23.2.1\"\r\ngitpython = \"3.1.40\"\r\nzhipuai = \"2.0.1\"\r\nrich = \"13.6.0\"\r\nnbclient = \"0.9.0\"\r\nnbformat = \"5.9.2\"\r\nipython = \"8.17.2\"\r\nipykernel = \"6.27.1\"\r\nscikit_learn = \"1.3.2\"\r\ntyping-extensions = \"4.9.0\"\r\nsocksio = \"~1.0.0\"\r\ngitignore-parser = \"0.1.9\"\r\nwebsockets = \"~11.0\"\r\nnetworkx = \"~3.2.1\"\r\ngoogle-generativeai = \"0.4.1\"\r\nplaywright = \">=1.26\"\r\nanytree = \"2.12.1\"\r\nipywidgets = \"8.1.1\"\r\nPillow = \"10.3.0\"\r\nimap_tools = \"1.5.0\"\r\nqianfan = \"0.3.2\"\r\ndashscope = \"1.14.1\"\r\nrank-bm25 = \"0.2.2\"\r\ngymnasium = \"0.29.1\"\r\njieba = \"0.42.1\"\r\nbeautifulsoup4  = \"~4.12.3\"\r\ndependency-injector = \"~4.41.0\"\r\nduckduckgo_search = \"~5.3.0\"\r\ngoogle-api-python-client = \"~2.127.0\"\r\nplaywright = \"~1.43.0\"\r\nselenium = \"~4.19.0\"\r\nwebdriver-manager = \"~4.0.1\"\r\n\r\n- installation method: poetry\r\n\r\n**Screenshots or logs**\r\n\r\nN/A\r\n",
      "state": "closed",
      "author": "kilesk",
      "author_type": "User",
      "created_at": "2024-04-24T14:59:44Z",
      "updated_at": "2025-02-05T00:30:21Z",
      "closed_at": "2025-02-05T00:30:20Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1225/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "shenchucheng"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1225",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1225",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:23.825042",
      "comments": [
        {
          "author": "geekan",
          "body": "@shenchucheng can you look at this question?",
          "created_at": "2024-05-18T10:12:46Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-22T00:30:17Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-05T00:30:20Z"
        }
      ]
    },
    {
      "issue_number": 1260,
      "title": "reactæ¨¡å¼ä¸‹ï¼Œè‡ªåŠ¨æ‹¼è£…çš„promtï¼Œç¼ºå°‘actionæè¿°ä¿¡æ¯ï¼Œè¯·é—®å¦‚ä½•è§£å†³ï¼Ÿ",
      "body": "å¦‚ä¸‹å›¾ä¸­ï¼Œåªæœ‰ç±»åï¼Œè¯·é—®å¦‚ä½•å¢åŠ å·¥å…·çš„åŠŸèƒ½æè¿°ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ‹¼æ¥åˆ°promtä¸­ï¼Œä»¥ä¾¿æ›´å¥½çš„é€‰æ‹©æ­£ç¡®çš„actionï¼Ÿ\r\n![image](https://github.com/geekan/MetaGPT/assets/16470935/d63dee05-4f74-471d-86f5-0fe89457cbb8)\r\n",
      "state": "closed",
      "author": "nzk1912",
      "author_type": "User",
      "created_at": "2024-05-10T06:02:22Z",
      "updated_at": "2025-02-03T00:31:09Z",
      "closed_at": "2025-02-03T00:31:09Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1260/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "geekan"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1260",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1260",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:24.033003",
      "comments": [
        {
          "author": "YangZeyu95",
          "body": "Same issue.\r\nNow I have a workaround, set 'desc' when calling set_actions().\r\nFor example, self.set_actions([action_dummy(desc='some description')])",
          "created_at": "2024-05-13T07:16:22Z"
        },
        {
          "author": "hs3180",
          "body": "You can override __str__ method in your actions. They will be showed in action ReAct prompt.\r\n\r\nhttps://github.com/geekan/MetaGPT/blob/7057ace34468f36f28f8948455e7d251a3ed2899/metagpt/roles/role.py#L279",
          "created_at": "2024-05-15T11:26:10Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-20T00:30:59Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-03T00:31:08Z"
        }
      ]
    },
    {
      "issue_number": 1278,
      "title": "Unable to Finish One Day in Werewolf Game",
      "body": "Hi! It seems that I cannot finish one day (one night and one daytime) in Werewolf Game.\r\n\r\nEverything seems okay before they take the vote. After the vote, the moderator recieves Action 19: Unknown, then every agent keeps talking and do not stop for more than 30 minutes. No one died (it is not possible in real werewolf game) for that long time.\r\n\r\nI tried to set Action idx = 0 when it becomes 19. It successfully goes to the second day / night. However, still no one died after long time. \r\nI saw wolf tried to killed someone, but doesn't work.\r\n\r\nIs that an issue in code? Or something gets wrong in my settings.\r\n\r\nBTW I set the round = 500, but doesn't help.\r\n",
      "state": "closed",
      "author": "ruogu-alter",
      "author_type": "User",
      "created_at": "2024-05-16T10:35:24Z",
      "updated_at": "2025-02-03T00:31:07Z",
      "closed_at": "2025-02-03T00:31:06Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1278/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1278",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1278",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:24.266416",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-20T00:30:57Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-03T00:31:06Z"
        }
      ]
    },
    {
      "issue_number": 1297,
      "title": "ReAct loop can not stop gracefully, usually not stop.",
      "body": "**Bug description**\r\n1. I created a role that simply counts up to 3, after which the goal is considered accomplished. All the LLM I tried usually would not set next_state to -1 in role._think()  when operating in ReAct mode.\r\n2. After I essentially solved 1.  the role encountered difficulties in exiting gracefully. \r\n```\r\n2024-05-24 08:33:16.872 | INFO     | metagpt.roles.role:_think:397 - End actions with next_state=-1\r\n2024-05-24 08:33:16.874 | WARNING  | metagpt.utils.common:wrapper:649 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.\r\nTraceback (most recent call last):\r\n  File \"/home/wei/kf/MetaGPT/metagpt/utils/common.py\", line 640, in wrapper\r\n    return await func(self, *args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/wei/kf/MetaGPT/metagpt/roles/role.py\", line 551, in run\r\n    rsp = await self.react()\r\n          ^^^^^^^^^^^^^^^^^^\r\n  File \"/home/wei/kf/MetaGPT/metagpt/roles/role.py\", line 520, in react\r\n    rsp = await self._react()\r\n          ^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/wei/kf/MetaGPT/metagpt/roles/role.py\", line 475, in _react\r\n    rsp = await self._act()\r\n          ^^^^^^^^^^^^^^^^^\r\n  File \"/home/wei/kf/MetaGPT/workspace/counter.py\", line 53, in _act\r\n    logger.info(f\"{self._setting}: to do {self.rc.todo}({self.rc.todo.name})\")\r\n                                                         ^^^^^^^^^^^^^^^^^\r\nAttributeError: 'NoneType' object has no attribute 'name'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n```\r\n**Bug solved method**\r\n1. ![1716540205523](https://github.com/geekan/MetaGPT/assets/32776997/8eee4c5c-bae3-4c24-b259-6045c298ed39)\r\nI suppose this issue arises because the LLM might get confused after being instructed 'Just answer a number between 0-{n_states}', and then being told 'If you think you have completed your goal and don't need to go to any of the stages, return -1.' LLM may not be able to return -1. \r\n2.\r\n```\r\nclass Role(SerializationMixin, ContextMixin, BaseModel):\r\n    async def _think(self) -> bool:\r\n        \"\"\"Consider what to do and decide on the next course of action. Return false if nothing can be done.\"\"\"\r\n        ....\r\n        next_state = await self.llm.aask(prompt)\r\n        next_state = extract_state_value_from_output(next_state)\r\n        ....\r\n        self._set_state(next_state)\r\n===== after change =====\r\n        return  next_state >= 0 \r\n==== before changed =====\r\n       return True\r\n``` \r\n\r\n",
      "state": "closed",
      "author": "Wei-Jianan",
      "author_type": "User",
      "created_at": "2024-05-24T08:59:09Z",
      "updated_at": "2025-02-03T00:31:06Z",
      "closed_at": "2025-02-03T00:31:05Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1297/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1297",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1297",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:24.476516",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-19T00:32:41Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-03T00:31:05Z"
        }
      ]
    },
    {
      "issue_number": 1339,
      "title": "exp: RetryError[<Future at 0x22e7c98f510 state=finished raised JSONDecodeError>]",
      "body": "2024-06-12 23:08:44.870 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 12.079(s), this was the 5th time calling it. exp: RetryError[<Future at 0x22e7bd4da10 state=finished raised JSONDecodeError>]\r\n\r\n2024-06-12 23:08:52.188 | WARNING  | metagpt.provider.openai_api:_calc_usage:244 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-4-turbo. See https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken for information on how messages are converted to tokens.\r\n2024-06-12 23:08:52.195 | WARNING  | metagpt.utils.repair_llm_raw_output:extract_content_from_output:320 - extract_content try another pattern: \\[CONTENT\\]([\\s\\S]*)\\[/CONTENT\\]\r\n2024-06-12 23:08:52.197 | WARNING  | metagpt.utils.repair_llm_raw_output:run_and_passon:268 - parse json from content inside [CONTENT][/CONTENT] failed at retry 1, exp: Expecting value: line 1 column 2 (char 1)\r\n2024-06-12 23:08:52.199 | INFO     | metagpt.utils.repair_llm_raw_output:repair_invalid_json:237 - repair_invalid_json, raw error: Expecting value: line 1 column 2 (char 1)\r\n2024-06-12 23:08:52.201 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 19.422(s), this was the 6th time calling it. exp: RetryError[<Future at 0x22e7bd4d350 state=finished raised JSONDecodeError>]\r\n2024-06-12 23:08:52.205 | WARNING  | metagpt.utils.common:wrapper:649 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.\r\n2024-06-12 23:08:52.212 | ERROR    | metagpt.utils.common:wrapper:631 - Exception occurs, start to serialize the project, exp:\r\nTraceback (most recent call last):\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\tenacity\\__init__.py\", line 382, in __call__\r\n    result = fn(*args, **kwargs)\r\n             ^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\utils\\repair_llm_raw_output.py\", line 296, in retry_parse_json_text\r\n    parsed_data = CustomDecoder(strict=False).decode(output)\r\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\njson.decoder.JSONDecodeError: Expecting value: line 1 column 2 (char 1)\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\r\n    result = await fn(*args, **kwargs)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\actions\\action_node.py\", line 425, in _aask_v1\r\n    parsed_data = llm_output_postprocess(\r\n                  ^^^^^^^^^^^^^^^^^^^^^^^\r\ntenacity.RetryError: RetryError[<Future at 0x22e7bd4d350 state=finished raised JSONDecodeError>]\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\utils\\common.py\", line 640, in wrapper\r\n    return await func(self, *args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\roles\\role.py\", line 550, in run\r\n    rsp = await self.react()\r\n          ^^^^^^^^^^^^^^^^^^\r\ntenacity.RetryError: RetryError[<Future at 0x22e7bd4f190 state=finished raised RetryError>]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\utils\\common.py\", line 626, in wrapper\r\n    result = await func(self, *args, **kwargs)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\team.py\", line 134, in run\r\n    await self.env.run()\r\nException: Traceback (most recent call last):\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\tenacity\\__init__.py\", line 382, in __call__\r\n    result = fn(*args, **kwargs)\r\n             ^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\utils\\repair_llm_raw_output.py\", line 296, in retry_parse_json_text\r\n    parsed_data = CustomDecoder(strict=False).decode(output)\r\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\utils\\custom_decoder.py\", line 297, in decode\r\n    return super().decode(s)\r\n           ^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\json\\decoder.py\", line 337, in decode\r\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\json\\decoder.py\", line 353, in raw_decode\r\n    obj, end = self.scan_once(s, idx)\r\n               ^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\utils\\custom_decoder.py\", line 65, in scan_once\r\n    return _scan_once(string, idx)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\utils\\custom_decoder.py\", line 38, in _scan_once\r\n    return parse_array((string, idx + 1), _scan_once)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\json\\decoder.py\", line 232, in JSONArray\r\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\r\njson.decoder.JSONDecodeError: Expecting value: line 1 column 2 (char 1)\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\r\n    result = await fn(*args, **kwargs)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\actions\\action_node.py\", line 425, in _aask_v1\r\n    parsed_data = llm_output_postprocess(\r\n                  ^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\provider\\postprocess\\llm_output_postprocess.py\", line 19, in llm_output_postprocess\r\n    result = postprocess_plugin.run(output=output, schema=schema, req_key=req_key)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\provider\\postprocess\\base_postprocess_plugin.py\", line 68, in run\r\n    new_output = self.run_repair_llm_output(output=output, schema=schema, req_key=req_key)\r\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\provider\\postprocess\\base_postprocess_plugin.py\", line 32, in run_repair_llm_output\r\n    parsed_data = self.run_retry_parse_json_text(content)\r\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\provider\\postprocess\\base_postprocess_plugin.py\", line 47, in run_retry_parse_json_text\r\n    parsed_data = retry_parse_json_text(output=content)  # should use output=content\r\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\tenacity\\__init__.py\", line 289, in wrapped_f\r\n    return self(f, *args, **kw)\r\n           ^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\tenacity\\__init__.py\", line 379, in __call__\r\n    do = self.iter(retry_state=retry_state)\r\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\tenacity\\__init__.py\", line 326, in iter\r\n    raise retry_exc from fut.exception()\r\ntenacity.RetryError: RetryError[<Future at 0x22e7bd4d350 state=finished raised JSONDecodeError>]\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\utils\\common.py\", line 640, in wrapper\r\n    return await func(self, *args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\roles\\role.py\", line 550, in run\r\n    rsp = await self.react()\r\n          ^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\roles\\role.py\", line 517, in react\r\n    rsp = await self._react()\r\n          ^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\roles\\role.py\", line 463, in _react\r\n    rsp = await self._act()\r\n          ^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\roles\\role.py\", line 392, in _act\r\n    response = await self.rc.todo.run(self.rc.history)\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\actions\\write_prd.py\", line 87, in run\r\n    return await self._handle_new_requirement(req)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\actions\\write_prd.py\", line 108, in _handle_new_requirement\r\n    node = await WRITE_PRD_NODE.fill(context=context, llm=self.llm, exclude=exclude)  # schema=schema\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\actions\\action_node.py\", line 505, in fill\r\n    return await self.simple_fill(schema=schema, mode=mode, images=images, timeout=timeout, exclude=exclude)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\metagpt\\actions\\action_node.py\", line 457, in simple_fill\r\n    content, scontent = await self._aask_v1(\r\n                        ^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\r\n    return await fn(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\r\n    do = self.iter(retry_state=retry_state)\r\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Users\\anaconda3\\envs\\yolome\\Lib\\site-packages\\tenacity\\__init__.py\", line 326, in iter\r\n    raise retry_exc from fut.exception()\r\ntenacity.RetryError: RetryError[<Future at 0x22e7bd4f190 state=finished raised RetryError>]",
      "state": "closed",
      "author": "zhenglanglang",
      "author_type": "User",
      "created_at": "2024-06-12T15:30:15Z",
      "updated_at": "2025-02-03T00:31:04Z",
      "closed_at": "2025-02-03T00:31:04Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1339/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1339",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1339",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:24.712677",
      "comments": [
        {
          "author": "zhenglanglang",
          "body": "how to deal ï¼Ÿï¼Ÿ\r\n",
          "created_at": "2024-06-12T15:30:33Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-19T00:32:40Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-02-03T00:31:03Z"
        }
      ]
    },
    {
      "issue_number": 1642,
      "title": "How to set top_p parameter properly?",
      "body": "Hi, first of all, I want to express my appreciation for your amazing work on this project. It has been incredibly helpful.\r\nI encountered an issue while trying to configure the top_p parameter. I included the setting in my config2.yaml file, but it doesn't seem to take effect. Could you please guide me on the correct way to set this parameter?\r\nmy config2.yaml snippet looks like:\r\n`llm:\r\n  api_type: \"open_llm\" \r\n  model: \"xxx\" \r\n  base_url: \"http://xxx/v1\" \r\n  api_key: \"none\"\r\n  max_token: 8192\r\n  temperature: 0.9\r\n  top_p: 0.5`  and I debugged to check the configured values, max_token and temperature already worked, but temperature not.\r\n\r\nAm I missing something, or is there another place I should configure this?\r\n\r\nThank you in advance for your help, and Iâ€™m looking forward to your response!",
      "state": "closed",
      "author": "sanexodus",
      "author_type": "User",
      "created_at": "2024-12-16T07:33:55Z",
      "updated_at": "2025-01-31T00:30:04Z",
      "closed_at": "2025-01-31T00:30:04Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1642/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1642",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1642",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:24.891673",
      "comments": [
        {
          "author": "shenchucheng",
          "body": "It seems to be a bug where the `top_p` configuration is not being used. Looking at the code [[here](https://github.com/geekan/MetaGPT/blob/main/metagpt/provider/openai_api.py#L128)](https://github.com/geekan/MetaGPT/blob/main/metagpt/provider/openai_api.py#L128), the `top_p` parameter is not include",
          "created_at": "2024-12-17T13:52:41Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-17T00:29:43Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-31T00:30:03Z"
        }
      ]
    },
    {
      "issue_number": 1627,
      "title": "WriteCode.get_codes fetches unexpectedly large amount of data.",
      "body": "**Bug description**\r\n            code_context = await WriteCode.get_codes(\r\n                self.i_context.task_doc,\r\n                exclude=self.i_context.filename,\r\n                project_repo=self.repo.with_src_path(self.context.src_workspace),\r\n                use_inc=self.config.inc,\r\n            )\r\ncode context might exceed the llm max_token\r\n\r\n**Bug solved method**\r\nlen(code_context)\r\n213693\r\nextremely large amount of code files are retrieved.\r\nmaybe retrieve only few context relevant files. and work on that with few iterations and summarize irrevelent part or using RAG to minimize the relevant data.\r\n",
      "state": "closed",
      "author": "davidleon",
      "author_type": "User",
      "created_at": "2024-12-05T09:46:48Z",
      "updated_at": "2025-01-24T00:29:56Z",
      "closed_at": "2025-01-24T00:29:56Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1627/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1627",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1627",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:25.079226",
      "comments": [
        {
          "author": "shenchucheng",
          "body": "Thank you for your suggestion! This issue indeed exists. In the new version, we no longer use `WriteCode` for code writing. Instead, we have introduced the `Editor` tool.",
          "created_at": "2024-12-09T03:03:50Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-09T00:30:46Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-24T00:29:55Z"
        }
      ]
    },
    {
      "issue_number": 1633,
      "title": "Code error in blackjack example",
      "body": "<img width=\"657\" alt=\"2024-12-07_22-36-51\" src=\"https://github.com/user-attachments/assets/61a11be1-fe6a-4d66-b4ab-271219fb2497\">\r\n\r\nThe image is of the example locate at URL: https://docs.deepwisdom.ai/main/en/guide/get_started/quickstart.html \r\n\r\nThe line: \r\n```\r\nawait startup(idea=\"write a cli blackjack game\")\r\n```\r\nis incorrect (the code won't run). Instead, it should be: \r\n```\r\nasyncio.run(startup(idea=\"write a client blackjack game\")\r\n",
      "state": "closed",
      "author": "erlebach",
      "author_type": "User",
      "created_at": "2024-12-08T03:44:04Z",
      "updated_at": "2025-01-24T00:29:55Z",
      "closed_at": "2025-01-24T00:29:55Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1633/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1633",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1633",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:25.356672",
      "comments": [
        {
          "author": "shenchucheng",
          "body": "Thank you for the feedback. Most of our examples are written in Jupyter Notebook, which is why the code runs as expected in that environment but results in a syntax error in the default Python IDE.",
          "created_at": "2024-12-09T04:02:16Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-09T00:30:44Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-24T00:29:54Z"
        }
      ]
    },
    {
      "issue_number": 1620,
      "title": "no listed python and docker installations ways working",
      "body": "**Bug description**\r\nNether a newly installed python installation within an python environment or a docker installation is working at the moment out of the box.\r\n\r\n**Bug not solved**\r\npip install metagpt is not working (tried 40 minutes, with an created environment, i had so mutch log output that it was too long for here but i also tried like 10 additional version overrites and all didnt worked.\r\nhttps://docs.deepwisdom.ai/main/en/guide/get_started/installation.html#install-stable-version\r\n\r\nand all other version from the readme to install it with pip also didnt worked\r\n\r\n\r\n**Environment information**\r\n<!-- Environmentï¼šSystem version (), Python version (),  -->\r\n\r\n- System version: Nobara Linux 40\r\n- Python version: Python 3.12.7\r\n\r\n<!-- Dependent packagessï¼šthe packages version cause the bug(like `pydantic 1.10.8`), installation methodï¼ˆlike `pip install metagpt` or `pip install from source` or `run in docker`ï¼‰ -->\r\n\r\n- installation method: all listed docker and pip instructions on the documentation and readme site.\r\n\r\n**Screenshots or logs**\r\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\r\n```\r\ndocker run --rm     --privileged     -v /opt/metagpt/config/config2.yaml:/app/metagpt/config/config2.yaml     -v /opt/metagpt/workspace:/app/metagpt/workspace     metagpt/metagpt:latest     metagpt \"Write a cli snake game\"            2024-12-02 20:51:33.966 | INFO     | metagpt.const:get_metagpt_package_root:21 - Package root set to /app/metagpt\r\nâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Traceback (most recent call last) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\r\nâ”‚ /app/metagpt/metagpt/software_company.py:115 in startup                      â”‚\r\nâ”‚                                                                              â”‚\r\nâ”‚   112 â”‚   â”‚   typer.echo(\"Missing argument 'IDEA'. Run 'metagpt --help' for  â”‚\r\nâ”‚   113 â”‚   â”‚   raise typer.Exit()                                             â”‚\r\nâ”‚   114 â”‚                                                                      â”‚\r\nâ”‚ â± 115 â”‚   return generate_repo(                                              â”‚\r\nâ”‚   116 â”‚   â”‚   idea,                                                          â”‚\r\nâ”‚   117 â”‚   â”‚   investment,                                                    â”‚\r\nâ”‚   118 â”‚   â”‚   n_round,                                                       â”‚\r\nâ”‚                                                                              â”‚\r\nâ”‚ /app/metagpt/metagpt/software_company.py:31 in generate_repo                 â”‚\r\nâ”‚                                                                              â”‚\r\nâ”‚    28 â”‚   recover_path=None,                                                 â”‚\r\nâ”‚    29 ) -> ProjectRepo:                                                      â”‚\r\nâ”‚    30 â”‚   \"\"\"Run the startup logic. Can be called from CLI or other Python s â”‚\r\nâ”‚ â±  31 â”‚   from metagpt.config2 import config                                 â”‚\r\nâ”‚    32 â”‚   from metagpt.context import Context                                â”‚\r\nâ”‚    33 â”‚   from metagpt.roles import (                                        â”‚\r\nâ”‚    34 â”‚   â”‚   Architect,                                                     â”‚\r\nâ”‚                                                                              â”‚\r\nâ”‚ /app/metagpt/metagpt/config2.py:169 in <module>                              â”‚\r\nâ”‚                                                                              â”‚\r\nâ”‚   166 â”‚   return result                                                      â”‚\r\nâ”‚   167                                                                        â”‚\r\nâ”‚   168                                                                        â”‚\r\nâ”‚ â± 169 config = Config.default()                                              â”‚\r\nâ”‚   170                                                                        â”‚\r\nâ”‚                                                                              â”‚\r\nâ”‚ /app/metagpt/metagpt/config2.py:109 in default                               â”‚\r\nâ”‚                                                                              â”‚\r\nâ”‚   106 â”‚   â”‚   ]                                                              â”‚\r\nâ”‚   107 â”‚   â”‚                                                                  â”‚\r\nâ”‚   108 â”‚   â”‚   dicts = [dict(os.environ)]                                     â”‚\r\nâ”‚ â± 109 â”‚   â”‚   dicts += [Config.read_yaml(path) for path in default_config_pa â”‚\r\nâ”‚   110 â”‚   â”‚   final = merge_dict(dicts)                                      â”‚\r\nâ”‚   111 â”‚   â”‚   return Config(**final)                                         â”‚\r\nâ”‚   112                                                                        â”‚\r\nâ”‚                                                                              â”‚\r\nâ”‚ /app/metagpt/metagpt/config2.py:109 in <listcomp>                            â”‚\r\nâ”‚                                                                              â”‚\r\nâ”‚   106 â”‚   â”‚   ]                                                              â”‚\r\nâ”‚   107 â”‚   â”‚                                                                  â”‚\r\nâ”‚   108 â”‚   â”‚   dicts = [dict(os.environ)]                                     â”‚\r\nâ”‚ â± 109 â”‚   â”‚   dicts += [Config.read_yaml(path) for path in default_config_pa â”‚\r\nâ”‚   110 â”‚   â”‚   final = merge_dict(dicts)                                      â”‚\r\nâ”‚   111 â”‚   â”‚   return Config(**final)                                         â”‚\r\nâ”‚   112                                                                        â”‚\r\nâ”‚                                                                              â”‚\r\nâ”‚ /app/metagpt/metagpt/utils/yaml_model.py:26 in read_yaml                     â”‚\r\nâ”‚                                                                              â”‚\r\nâ”‚   23 â”‚   â”‚   if not file_path.exists():                                      â”‚\r\nâ”‚   24 â”‚   â”‚   â”‚   return {}                                                   â”‚\r\nâ”‚   25 â”‚   â”‚   with open(file_path, \"r\", encoding=encoding) as file:           â”‚\r\nâ”‚ â± 26 â”‚   â”‚   â”‚   return yaml.safe_load(file)                                 â”‚\r\nâ”‚   27 â”‚                                                                       â”‚\r\nâ”‚   28 â”‚   @classmethod                                                        â”‚\r\nâ”‚   29 â”‚   def from_yaml_file(cls, file_path: Path) -> \"YamlModel\":            â”‚\r\nâ”‚                                                                              â”‚\r\nâ”‚ /usr/local/lib/python3.9/site-packages/yaml/__init__.py:125 in safe_load     â”‚\r\nâ”‚                                                                              â”‚\r\nâ”‚   122 â”‚   Resolve only basic YAML tags. This is known                        â”‚\r\nâ”‚   123 â”‚   to be safe for untrusted input.                                    â”‚\r\nâ”‚   124 â”‚   \"\"\"                                                                â”‚\r\nâ”‚ â± 125 â”‚   return load(stream, SafeLoader)                                    â”‚\r\nâ”‚   126                                                                        â”‚\r\nâ”‚   127 def safe_load_all(stream):                                             â”‚\r\nâ”‚   128 â”‚   \"\"\"                                                                â”‚\r\nâ”‚                                                                              â”‚\r\nâ”‚ /usr/local/lib/python3.9/site-packages/yaml/__init__.py:81 in load           â”‚\r\nâ”‚                                                                              â”‚\r\nâ”‚    78 â”‚   \"\"\"                                                                â”‚\r\nâ”‚    79 â”‚   loader = Loader(stream)                                            â”‚\r\nâ”‚    80 â”‚   try:                                                               â”‚\r\nâ”‚ â±  81 â”‚   â”‚   return loader.get_single_data()                                â”‚\r\nâ”‚    82 â”‚   finally:                                                           â”‚\r\nâ”‚    83 â”‚   â”‚   loader.dispose()                                               â”‚\r\nâ”‚    84                                                                        â”‚\r\nâ”‚                                                                              â”‚\r\nâ”‚ /usr/local/lib/python3.9/site-packages/yaml/constructor.py:49 in             â”‚\r\nâ”‚ get_single_data                                                              â”‚\r\nâ”‚                                                                              â”‚\r\nâ”‚    46 â”‚                                                                      â”‚\r\nâ”‚    47 â”‚   def get_single_data(self):                                         â”‚\r\nâ”‚    48 â”‚   â”‚   # Ensure that the stream contains a single document and constr â”‚\r\nâ”‚ â±  49 â”‚   â”‚   node = self.get_single_node()                                  â”‚\r\nâ”‚    50 â”‚   â”‚   if node is not None:                                           â”‚\r\nâ”‚    51 â”‚   â”‚   â”‚   return self.construct_document(node)                       â”‚\r\nâ”‚    52 â”‚   â”‚   return None                                                    â”‚\r\nâ”‚                                                                              â”‚\r\nâ”‚ /usr/local/lib/python3.9/site-packages/yaml/composer.py:36 in                â”‚\r\nâ”‚ get_single_node                                                              â”‚\r\nâ”‚                                                                              â”‚\r\nâ”‚    33 â”‚   â”‚   # Compose a document if the stream is not empty.               â”‚\r\nâ”‚    34 â”‚   â”‚   document = None                                                â”‚\r\nâ”‚    35 â”‚   â”‚   if not self.check_event(StreamEndEvent):                       â”‚\r\nâ”‚ â±  36 â”‚   â”‚   â”‚   document = self.compose_document()                         â”‚\r\nâ”‚    37 â”‚   â”‚                                                                  â”‚\r\nâ”‚    38 â”‚   â”‚   # Ensure that the stream contains no more documents.           â”‚\r\nâ”‚    39 â”‚   â”‚   if not self.check_event(StreamEndEvent):                       â”‚\r\nâ”‚                                                                              â”‚\r\nâ”‚ /usr/local/lib/python3.9/site-packages/yaml/composer.py:55 in                â”‚\r\nâ”‚ compose_document                                                             â”‚\r\nâ”‚                                                                              â”‚\r\nâ”‚    52 â”‚   â”‚   self.get_event()                                               â”‚\r\nâ”‚    53 â”‚   â”‚                                                                  â”‚\r\nâ”‚    54 â”‚   â”‚   # Compose the root node.                                       â”‚\r\nâ”‚ â±  55 â”‚   â”‚   node = self.compose_node(None, None)                           â”‚\r\nâ”‚    56 â”‚   â”‚                                                                  â”‚\r\nâ”‚    57 â”‚   â”‚   # Drop the DOCUMENT-END event.                                 â”‚\r\nâ”‚    58 â”‚   â”‚   self.get_event()                                               â”‚\r\nâ”‚                                                                              â”‚\r\nâ”‚ /usr/local/lib/python3.9/site-packages/yaml/composer.py:84 in compose_node   â”‚\r\nâ”‚                                                                              â”‚\r\nâ”‚    81 â”‚   â”‚   elif self.check_event(SequenceStartEvent):                     â”‚\r\nâ”‚    82 â”‚   â”‚   â”‚   node = self.compose_sequence_node(anchor)                  â”‚\r\nâ”‚    83 â”‚   â”‚   elif self.check_event(MappingStartEvent):                      â”‚\r\nâ”‚ â±  84 â”‚   â”‚   â”‚   node = self.compose_mapping_node(anchor)                   â”‚\r\nâ”‚    85 â”‚   â”‚   self.ascend_resolver()                                         â”‚\r\nâ”‚    86 â”‚   â”‚   return node                                                    â”‚\r\nâ”‚    87                                                                        â”‚\r\nâ”‚                                                                              â”‚\r\nâ”‚ /usr/local/lib/python3.9/site-packages/yaml/composer.py:127 in               â”‚\r\nâ”‚ compose_mapping_node                                                         â”‚\r\nâ”‚                                                                              â”‚\r\nâ”‚   124 â”‚   â”‚   â”‚   â”‚   flow_style=start_event.flow_style)                     â”‚\r\nâ”‚   125 â”‚   â”‚   if anchor is not None:                                         â”‚\r\nâ”‚   126 â”‚   â”‚   â”‚   self.anchors[anchor] = node                                â”‚\r\nâ”‚ â± 127 â”‚   â”‚   while not self.check_event(MappingEndEvent):                   â”‚\r\nâ”‚   128 â”‚   â”‚   â”‚   #key_event = self.peek_event()                             â”‚\r\nâ”‚   129 â”‚   â”‚   â”‚   item_key = self.compose_node(node, None)                   â”‚\r\nâ”‚   130 â”‚   â”‚   â”‚   #if item_key in node.value:                                â”‚\r\nâ”‚                                                                              â”‚\r\nâ”‚ /usr/local/lib/python3.9/site-packages/yaml/parser.py:98 in check_event      â”‚\r\nâ”‚                                                                              â”‚\r\nâ”‚    95 â”‚   â”‚   # Check the type of the next event.                            â”‚\r\nâ”‚    96 â”‚   â”‚   if self.current_event is None:                                 â”‚\r\nâ”‚    97 â”‚   â”‚   â”‚   if self.state:                                             â”‚\r\nâ”‚ â±  98 â”‚   â”‚   â”‚   â”‚   self.current_event = self.state()                      â”‚\r\nâ”‚    99 â”‚   â”‚   if self.current_event is not None:                             â”‚\r\nâ”‚   100 â”‚   â”‚   â”‚   if not choices:                                            â”‚\r\nâ”‚   101 â”‚   â”‚   â”‚   â”‚   return True                                            â”‚\r\nâ”‚                                                                              â”‚\r\nâ”‚ /usr/local/lib/python3.9/site-packages/yaml/parser.py:438 in                 â”‚\r\nâ”‚ parse_block_mapping_key                                                      â”‚\r\nâ”‚                                                                              â”‚\r\nâ”‚   435 â”‚   â”‚   â”‚   â”‚   return self.process_empty_scalar(token.end_mark)       â”‚\r\nâ”‚   436 â”‚   â”‚   if not self.check_token(BlockEndToken):                        â”‚\r\nâ”‚   437 â”‚   â”‚   â”‚   token = self.peek_token()                                  â”‚\r\nâ”‚ â± 438 â”‚   â”‚   â”‚   raise ParserError(\"while parsing a block mapping\", self.ma â”‚\r\nâ”‚   439 â”‚   â”‚   â”‚   â”‚   â”‚   \"expected <block end>, but found %r\" % token.id, t â”‚\r\nâ”‚   440 â”‚   â”‚   token = self.get_token()                                       â”‚\r\nâ”‚   441 â”‚   â”‚   event = MappingEndEvent(token.start_mark, token.end_mark)      â”‚\r\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\r\nParserError: while parsing a block mapping\r\n  in \"/app/metagpt/config/config2.yaml\", line 1, column 1\r\nexpected <block end>, but found '<block mapping start>'\r\n  in \"/app/metagpt/config/config2.yaml\", line 5, column 3\r\n\r\n```",
      "state": "closed",
      "author": "Xyz00777",
      "author_type": "User",
      "created_at": "2024-12-02T21:22:37Z",
      "updated_at": "2025-01-21T00:29:30Z",
      "closed_at": "2025-01-21T00:29:29Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1620/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1620",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1620",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:25.584662",
      "comments": [
        {
          "author": "shenchucheng",
          "body": "The error suggests there is a syntax issue in your config2.yaml file.",
          "created_at": "2024-12-04T06:37:03Z"
        },
        {
          "author": "Xyz00777",
          "body": "wow okay that worked, fail :D\r\nbut still the python way didnt worked...",
          "created_at": "2024-12-04T23:32:48Z"
        },
        {
          "author": "shenchucheng",
          "body": "Are there any other errors?",
          "created_at": "2024-12-06T08:05:06Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-06T00:32:33Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-21T00:29:28Z"
        }
      ]
    },
    {
      "issue_number": 1607,
      "title": "æ‰§è¡Œdemoæ—¶å‡ºç°tenacity.RetryError: RetryError[<Future at 0x7f0a4fef12b0 state=finished raised AssertionError>]",
      "body": "metagpt \"Write a cli snake game\"\r\n2024-11-15 15:03:50.927 | INFO     | metagpt.const:get_metagpt_package_root:21 - Package root set to /app/metagpt\r\n2024-11-15 15:03:55.243 | INFO     | metagpt.team:invest:93 - Investment: $3.0.\r\n2024-11-15 15:03:55.246 | INFO     | metagpt.roles.role:_act:403 - Alice(Product Manager): to do PrepareDocuments(PrepareDocuments)\r\n2024-11-15 15:03:55.319 | INFO     | metagpt.utils.file_repository:save:57 - save to: /app/metagpt/workspace/20241115150355/docs/requirement.txt\r\n2024-11-15 15:03:55.321 | INFO     | metagpt.roles.role:_act:403 - Alice(Product Manager): to do WritePRD(WritePRD)\r\n2024-11-15 15:03:55.323 | INFO     | metagpt.actions.write_prd:run:86 - New requirement detected: Write a cli snake game\r\n2024-11-15 15:03:55.766 | WARNING  | tenacity.after:log_it:44 - Finished call to 'metagpt.provider.base_llm.BaseLLM.acompletion_text' after 0.441(s), this was the 1st time calling it.\r\n2024-11-15 15:03:56.337 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 1.012(s), this was the 1st time calling it. exp: \r\n2024-11-15 15:03:56.581 | WARNING  | tenacity.after:log_it:44 - Finished call to 'metagpt.provider.base_llm.BaseLLM.acompletion_text' after 0.238(s), this was the 1st time calling it.\r\n2024-11-15 15:03:57.182 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 1.857(s), this was the 2nd time calling it. exp: \r\n2024-11-15 15:03:58.808 | WARNING  | tenacity.after:log_it:44 - Finished call to 'metagpt.provider.base_llm.BaseLLM.acompletion_text' after 0.003(s), this was the 1st time calling it.\r\n2024-11-15 15:03:58.992 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 3.667(s), this was the 3rd time calling it. exp: \r\n2024-11-15 15:04:02.819 | WARNING  | tenacity.after:log_it:44 - Finished call to 'metagpt.provider.base_llm.BaseLLM.acompletion_text' after 0.003(s), this was the 1st time calling it.\r\n2024-11-15 15:04:02.896 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 7.571(s), this was the 4th time calling it. exp: \r\n2024-11-15 15:04:03.830 | WARNING  | tenacity.after:log_it:44 - Finished call to 'metagpt.provider.base_llm.BaseLLM.acompletion_text' after 0.003(s), this was the 1st time calling it.\r\n2024-11-15 15:04:04.174 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 8.849(s), this was the 5th time calling it. exp: \r\n2024-11-15 15:04:16.136 | WARNING  | tenacity.after:log_it:44 - Finished call to 'metagpt.provider.base_llm.BaseLLM.acompletion_text' after 0.002(s), this was the 1st time calling it.\r\n2024-11-15 15:04:16.423 | ERROR    | metagpt.utils.common:log_it:554 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 21.098(s), this was the 6th time calling it. exp: \r\n2024-11-15 15:04:16.424 | WARNING  | metagpt.utils.common:wrapper:673 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.    \r\n2024-11-15 15:04:16.441 | ERROR    | metagpt.utils.common:wrapper:655 - Exception occurs, start to serialize the project, exp:\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 50, in __call__\r\n    result = await fn(*args, **kwargs)\r\n  File \"/app/metagpt/metagpt/actions/action_node.py\", line 437, in _aask_v1\r\n    content = await self.llm.aask(prompt, system_msgs, images=images, timeout=timeout)\r\nAssertionError\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/app/metagpt/metagpt/utils/common.py\", line 664, in wrapper\r\n    return await func(self, *args, **kwargs)\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 551, in run\r\n    rsp = await self.react()\r\ntenacity.RetryError: RetryError[<Future at 0x7f0a4fef12b0 state=finished raised AssertionError>]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/app/metagpt/metagpt/utils/common.py\", line 650, in wrapper\r\n    result = await func(self, *args, **kwargs)\r\n  File \"/app/metagpt/metagpt/team.py\", line 134, in run\r\n    await self.env.run()\r\nException: Traceback (most recent call last):\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 50, in __call__\r\n    result = await fn(*args, **kwargs)\r\n  File \"/app/metagpt/metagpt/actions/action_node.py\", line 437, in _aask_v1\r\n    content = await self.llm.aask(prompt, system_msgs, images=images, timeout=timeout)\r\n  File \"/app/metagpt/metagpt/provider/base_llm.py\", line 152, in aask\r\n    rsp = await self.acompletion_text(message, stream=stream, timeout=self.get_timeout(timeout))\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\r\n    return await fn(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 47, in __call__\r\n    do = self.iter(retry_state=retry_state)\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/__init__.py\", line 314, in iter\r\n    return fut.result()\r\n  File \"/usr/local/lib/python3.9/concurrent/futures/_base.py\", line 439, in result\r\n    return self.__get_result()\r\n  File \"/usr/local/lib/python3.9/concurrent/futures/_base.py\", line 391, in __get_result\r\n    raise self._exception\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 50, in __call__\r\n    result = await fn(*args, **kwargs)\r\n  File \"/app/metagpt/metagpt/provider/base_llm.py\", line 202, in acompletion_text\r\n    return await self._achat_completion_stream(messages, timeout=self.get_timeout(timeout))\r\n  File \"/app/metagpt/metagpt/provider/spark_api.py\", line 76, in _achat_completion_stream\r\n    async for chunk in response:\r\n  File \"/usr/local/lib/python3.9/site-packages/sparkai/core/language_models/chat_models.py\", line 309, in astream\r\n    raise e\r\n  File \"/usr/local/lib/python3.9/site-packages/sparkai/core/language_models/chat_models.py\", line 301, in astream\r\n    assert generation is not None\r\nAssertionError\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/app/metagpt/metagpt/utils/common.py\", line 664, in wrapper\r\n    return await func(self, *args, **kwargs)\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 551, in run\r\n    rsp = await self.react()\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 520, in react\r\n    rsp = await self._react()\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 475, in _react\r\n    rsp = await self._act()\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 404, in _act\r\n    response = await self.rc.todo.run(self.rc.history)\r\n  File \"/app/metagpt/metagpt/actions/write_prd.py\", line 87, in run\r\n    return await self._handle_new_requirement(req)\r\n  File \"/app/metagpt/metagpt/actions/write_prd.py\", line 108, in _handle_new_requirement\r\n    node = await WRITE_PRD_NODE.fill(context=context, llm=self.llm, exclude=exclude)  # schema=schema\r\n  File \"/app/metagpt/metagpt/actions/action_node.py\", line 648, in fill\r\n    return await self.simple_fill(schema=schema, mode=mode, images=images, timeout=timeout, exclude=exclude)\r\n  File \"/app/metagpt/metagpt/actions/action_node.py\", line 473, in simple_fill\r\n    content, scontent = await self._aask_v1(\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\r\n    return await fn(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 47, in __call__\r\n    do = self.iter(retry_state=retry_state)\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/__init__.py\", line 326, in iter\r\n    raise retry_exc from fut.exception()\r\ntenacity.RetryError: RetryError[<Future at 0x7f0a4fef12b0 state=finished raised AssertionError>]",
      "state": "closed",
      "author": "simonaries",
      "author_type": "User",
      "created_at": "2024-11-15T15:06:24Z",
      "updated_at": "2025-01-21T00:29:30Z",
      "closed_at": "2025-01-21T00:29:30Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1607/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1607",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1607",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:25.803882",
      "comments": [
        {
          "author": "voidking",
          "body": "ä»æŠ¥é”™çœ‹ï¼Œæ˜¯è°ƒç”¨LLMä¸é€šã€‚å»ºè®®å…ˆä¸è¦ä½¿ç”¨metagptï¼Œè€Œæ˜¯å…ˆè°ƒé€šä½ ä½¿ç”¨çš„LLMå®˜æ–¹ç»™çš„ç¤ºä¾‹ä»£ç ï¼Œä¿è¯base_urlã€modelå’Œkeyéƒ½æ˜¯æ­£ç¡®çš„ï¼Œç„¶åå†å¡«å…¥metagptçš„é…ç½®æ–‡ä»¶ä¸­ã€‚",
          "created_at": "2024-11-18T12:21:00Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-06T00:32:37Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-21T00:29:29Z"
        }
      ]
    },
    {
      "issue_number": 1628,
      "title": "Run o1 with MetaGPT, cannot produce any output. ",
      "body": "**Bug description**\r\n1. When running o1, with examples/build_customized_multi_agents.py, no output is shown in the terminal. But o1 is indeed being used and charged.\r\n2. logs does have the o1 output as 'DEBUG', it is just not shown in the terminal\r\n3. If switch to gpt4, everything is working.\r\n\r\n**Environment information**\r\no1 and o1 mini both have the issue. No output in the terminal.\r\n\r\n- System version: Linux\r\n- MetaGPT version or branch: Latest metaGPT github repo installation as of today.\r\n",
      "state": "closed",
      "author": "hohoCode",
      "author_type": "User",
      "created_at": "2024-12-05T17:13:39Z",
      "updated_at": "2025-01-21T00:29:28Z",
      "closed_at": "2025-01-21T00:29:27Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1628/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1628",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1628",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:26.032739",
      "comments": [
        {
          "author": "shenchucheng",
          "body": "Please update your configuration as follows:  \r\n\r\n```yaml\r\nllm:\r\n  api_type: 'openai'\r\n  api_key: 'sk-...'\r\n  model: 'o1-mini'\r\n  use_system_prompt: false\r\n  stream: false\r\n```  \r\n\r\nMake sure `use_system_prompt` and `stream` are set to `false`.",
          "created_at": "2024-12-06T06:51:18Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-06T00:32:32Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-21T00:29:27Z"
        }
      ]
    },
    {
      "issue_number": 1629,
      "title": "access to deepseek",
      "body": "want to access to deepseek!!!!",
      "state": "closed",
      "author": "Dwendwen-Liu",
      "author_type": "User",
      "created_at": "2024-12-06T02:45:24Z",
      "updated_at": "2025-01-21T00:29:27Z",
      "closed_at": "2025-01-21T00:29:26Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1629/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1629",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1629",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:26.293699",
      "comments": [
        {
          "author": "shenchucheng",
          "body": "```\r\nllm:\r\n  api_key: sk-xxxxxxxxxxxxxxxxxxxx\r\n  api_type: openai\r\n  base_url: https://api.deepseek.com/v1\r\n  model: deepseek-chat  # deepseek-coder\r\n```\r\nSee, https://api-docs.deepseek.com/.\r\n",
          "created_at": "2024-12-06T03:06:22Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-06T00:32:31Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-21T00:29:26Z"
        }
      ]
    },
    {
      "issue_number": 1361,
      "title": "How to synchronize on multiple \"watches\"",
      "body": "Hi very impressive work! Can you show me how to do fan-in correctly in MetaGPT as the current default implementation of the watch list is merely a filter? I want an action to be dependent on multiple agents and wait on their inputs.",
      "state": "closed",
      "author": "jiange91",
      "author_type": "User",
      "created_at": "2024-06-20T05:05:20Z",
      "updated_at": "2025-01-20T00:30:56Z",
      "closed_at": "2025-01-20T00:30:56Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1361/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "geekan",
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1361",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1361",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:26.512989",
      "comments": [
        {
          "author": "voidking",
          "body": "I don't quite understand what you want. Can you give a more specific example?",
          "created_at": "2024-07-02T12:21:47Z"
        },
        {
          "author": "jiange91",
          "body": "Basically, I want an agent only to take action when all its dependencies are met. \r\nLike if A has a watch list of [B, C, D], I need all inputs from B, C, D for A to take action. But currently, it seems as long as B or C or D gives their input A will take action. Is watch list the wrong mechanism to ",
          "created_at": "2024-07-02T17:03:56Z"
        },
        {
          "author": "geekan",
          "body": "When making this design, my intention was to make it the same as pubsub (queue), and there are a large number of queue design patterns for reference.\r\n\r\nPublishing messages and consuming messages are actually two standard behaviors for queues. When you need to wait for multiple messages before start",
          "created_at": "2024-10-11T09:40:56Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-05T00:33:51Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-20T00:30:56Z"
        }
      ]
    },
    {
      "issue_number": 1365,
      "title": "MetaGpt not as a oneshot commander, but a continue chat backend api server.",
      "body": "The most common usage case about MetaGpt is just like a one-shot command executorã€‚\r\n\r\nYou input the task: \" write me a golang hello world\"\r\n\r\nAnd MetaGpt will do lots of works for you, and then return you the workspace contains the code and document filesã€‚\r\n\r\n\r\nBUT, if can we make MetaGPT as a chat backend API serverã€‚\r\n\r\nFor example, we sold shoes, we want to train a AI salesmanã€‚ \r\n\r\nThe salesman should know each shoes style, size, and it's price.\r\n\r\nIt must answer question about the shoes. provided price sheets for customers.\r\n\r\nAnd if customer not willing to buy, the salesman should talk to customers, to make customer buy shoes as well.\r\n\r\n\r\nSo this is not a simple application, but a very complex requirement.\r\n\r\nThe role should have much knowledge on sales skills, and well talk abilityã€‚\r\n\r\nMetaGPT seems can do this job, but i don't know how to make it running as a API server.\r\n\r\nIt should read and remember talk sessionsã€‚ may be keep the same customer talk history for a long time, Next time the customer came back, we should still remember what he talkedã€‚\r\n",
      "state": "closed",
      "author": "code959437957",
      "author_type": "User",
      "created_at": "2024-06-25T09:09:00Z",
      "updated_at": "2025-01-19T00:32:40Z",
      "closed_at": "2025-01-19T00:32:39Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1365/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1365",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1365",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:26.702330",
      "comments": [
        {
          "author": "zhaoq1",
          "body": "Yes, I think this is very important. I think the human-computer interaction mode should be optimized in the streaming interface. The current terminal interaction method is very inconvenient.",
          "created_at": "2024-06-27T08:39:27Z"
        },
        {
          "author": "geekan",
          "body": "We will fix this issue in version 1.0",
          "created_at": "2024-10-20T07:04:55Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-04T00:29:59Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-19T00:32:39Z"
        }
      ]
    },
    {
      "issue_number": 1458,
      "title": "æ€ä¹ˆç”Ÿæˆç¬¦åˆæˆ‘è‡ªå®šä¹‰è§„èŒƒçš„ä»£ç ?",
      "body": "æ¯”å¦‚è¯´æˆ‘æƒ³ç”Ÿæˆä¸€äº›å‰ç«¯ä»£ç ï¼Œéœ€è¦ç”Ÿæˆçš„ä»£ç è¦ç”¨æˆ‘è‡ªå·±å°è£…çš„ç»„ä»¶åº“ï¼Œå·¥å…·åº“ç­‰.è¦æ€ä¹ˆåšï¼Ÿæœ‰ä¾‹å­å—ï¼Ÿè°¢è°¢",
      "state": "closed",
      "author": "frh10",
      "author_type": "User",
      "created_at": "2024-08-20T09:51:24Z",
      "updated_at": "2025-01-18T00:28:40Z",
      "closed_at": "2025-01-18T00:28:39Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1458/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": "1.0",
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1458",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1458",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:26.909994",
      "comments": [
        {
          "author": "iorisa",
          "body": "è¿™ç§çµæ´»çš„å¼€å‘éœ€æ±‚ï¼Œå»ºè®®ä½ ç”¨[DataInterpreter](https://docs.deepwisdom.ai/main/en/DataInterpreter/)æ¥åšã€‚",
          "created_at": "2024-08-20T13:22:00Z"
        },
        {
          "author": "frh10",
          "body": "> è¿™ç§çµæ´»çš„å¼€å‘éœ€æ±‚ï¼Œå»ºè®®ä½ ç”¨[DataInterpreter](https://docs.deepwisdom.ai/main/en/DataInterpreter/)æ¥åšã€‚\r\n\r\nä½ çš„æ„æ€æ˜¯ç”¨è‡ªå®šä¹‰å·¥å…·é‡Œçš„æç¤ºè¯å®ç°å—ï¼Ÿç±»ä¼¼äºæ•™ç¨‹æ–‡æ¡ˆåŠ©æ‰‹é‚£æ ·ï¼Ÿ",
          "created_at": "2024-08-21T06:43:09Z"
        },
        {
          "author": "iorisa",
          "body": "ä¸æ˜¯ã€‚æ˜¯æŠŠä½ çš„æŠ€æœ¯éœ€æ±‚ä½œä¸ºéœ€æ±‚å†…å®¹ï¼ˆæ¶ˆæ¯çš„å†…å®¹ï¼‰çš„ä¸€éƒ¨åˆ†å‘ç»™DIï¼Œå®ƒè‡ªå·±ä¼šè°ƒæ•´çš„",
          "created_at": "2024-08-22T06:57:45Z"
        },
        {
          "author": "tdsnxchen-max",
          "body": "> æ¯”å¦‚è¯´æˆ‘æƒ³ç”Ÿæˆä¸€äº›å‰ç«¯ä»£ç ï¼Œéœ€è¦ç”Ÿæˆçš„ä»£ç è¦ç”¨æˆ‘è‡ªå·±å°è£…çš„ç»„ä»¶åº“ï¼Œå·¥å…·åº“ç­‰.è¦æ€ä¹ˆåšï¼Ÿæœ‰ä¾‹å­å—ï¼Ÿè°¢è°¢\r\n\r\nI think it 's a common request. Have you implemented it?",
          "created_at": "2024-09-13T02:18:13Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-02T00:30:20Z"
        }
      ]
    },
    {
      "issue_number": 1557,
      "title": "Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1'",
      "body": "### æŠ¥é”™\r\nFinished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 17.605(s), this was the 3rd time calling it. exp: openai.types.completion_usage.CompletionUsage() argument after ** must be a mapping, not NoneType\r\n\r\næµ‹è¯•äº†qwen2.5ç³»åˆ—ï¼Œ7båˆ°72bå…¨è¯•äº†ï¼ŒåŒ…æ‹¬å®˜æ–¹å¼€æºæ¨¡å‹å’Œrombos-72bæ¨¡å‹ï¼Œå…¨éƒ¨éƒ½æŠ¥é”™ï¼Œè€Œä¸”ç™¾åˆ†ç™¾æŠ¥é”™ï¼Œä»»ä½•é—®é¢˜éƒ½æ˜¯ä¸€æ ·\r\n\r\n### configï¼š\r\nllm:\r\n  api_type: \"openai\"  # or azure / ollama / open_llm etc. Check LLMType for more options\r\n  model: \"gpt\"\r\n  base_url: \"http://192.168.1.161:1227/v1\"  # or forward url / other llm url\r\n  api_key: \"test\"\r\n\r\n### å®‰è£…ï¼ˆubuntu22 python3.9ï¼‰ï¼š\r\npip install --upgrade metagpt\r\nmetagpt --init-config\r\nnano ~/.metagpt/config2.yaml\r\nmetagpt \"pythonä»¤ç‰Œæ¡¶é™æµä»£ç \"",
      "state": "closed",
      "author": "maxin9966",
      "author_type": "User",
      "created_at": "2024-10-31T05:17:00Z",
      "updated_at": "2025-01-18T00:28:39Z",
      "closed_at": "2025-01-18T00:28:38Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1557/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "voidking"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1557",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1557",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:27.147736",
      "comments": [
        {
          "author": "geekan",
          "body": "1. Please ask questions in English.\r\n2. The model in your config is gpt. I would like to ask what the actual model is? Is the api_type filled in correctly?",
          "created_at": "2024-10-31T05:43:41Z"
        },
        {
          "author": "voidking",
          "body": "I guess there is some error in model configuration. You can try the model given in our documentation first.\r\nhttps://docs.deepwisdom.ai/main/en/guide/get_started/configuration/llm_api_configuration.html",
          "created_at": "2024-10-31T05:50:03Z"
        },
        {
          "author": "LimFang",
          "body": "well i got the same info, the config is all well set. Any solutions?",
          "created_at": "2024-11-19T11:27:01Z"
        },
        {
          "author": "Miracle-Master",
          "body": "try add this to your .yaml \"base_url\r\n=\"https://open.bigmodel.cn/api/paas/v4/\"\"",
          "created_at": "2024-12-03T09:22:27Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-03T00:30:22Z"
        }
      ]
    },
    {
      "issue_number": 1477,
      "title": "Cannot install due to old numpy version being used by metagpt",
      "body": "```\r\nCollecting numpy==1.24.3 (from metagpt)\r\n  Using cached numpy-1.24.3.tar.gz (10.9 MB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... error\r\n  error: subprocess-exited-with-error\r\n\r\n  Ã— Getting requirements to build wheel did not run successfully.\r\n  â”‚ exit code: 1\r\n  â•°â”€> [32 lines of output]\r\n      Traceback (most recent call last):\r\n        File \"C:\\Users\\blusc\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\r\n          main()\r\n          ~~~~^^\r\n        File \"C:\\Users\\blusc\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\r\n          json_out['return_val'] = hook(**hook_input['kwargs'])\r\n                                   ~~~~^^^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"C:\\Users\\blusc\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 112, in get_requires_for_build_wheel\r\n          backend = _build_backend()\r\n        File \"C:\\Users\\blusc\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 77, in _build_backend\r\n          obj = import_module(mod_path)\r\n        File \"C:\\Users\\blusc\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\importlib\\__init__.py\", line 88, in import_module\r\n          return _bootstrap._gcd_import(name[level:], package, level)\r\n                 ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\r\n        File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\r\n        File \"<frozen importlib._bootstrap>\", line 1310, in _find_and_load_unlocked\r\n        File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\r\n        File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\r\n        File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\r\n        File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\r\n        File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\r\n        File \"<frozen importlib._bootstrap_external>\", line 1022, in exec_module\r\n        File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\r\n        File \"C:\\Users\\blusc\\AppData\\Local\\Temp\\pip-build-env-hufjw5qu\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\", line 16, in <module>\r\n          import setuptools.version\r\n        File \"C:\\Users\\blusc\\AppData\\Local\\Temp\\pip-build-env-hufjw5qu\\overlay\\Lib\\site-packages\\setuptools\\version.py\", line 1, in <module>\r\n          import pkg_resources\r\n        File \"C:\\Users\\blusc\\AppData\\Local\\Temp\\pip-build-env-hufjw5qu\\overlay\\Lib\\site-packages\\pkg_resources\\__init__.py\", line 2172, in <module>\r\n          register_finder(pkgutil.ImpImporter, find_on_path)\r\n                          ^^^^^^^^^^^^^^^^^^^\r\n      AttributeError: module 'pkgutil' has no attribute 'ImpImporter'. Did you mean: 'zipimporter'?\r\n      [end of output]\r\n\r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\nerror: subprocess-exited-with-error\r\n\r\nÃ— Getting requirements to build wheel did not run successfully.\r\nâ”‚ exit code: 1\r\nâ•°â”€> See above for output.\r\n\r\nnote: This error originates from a subprocess, and is likely not a problem with pip.\r\n```",
      "state": "closed",
      "author": "Bluscream",
      "author_type": "User",
      "created_at": "2024-09-10T23:10:52Z",
      "updated_at": "2025-01-17T00:29:51Z",
      "closed_at": "2025-01-17T00:29:50Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1477/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "better629"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1477",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1477",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:27.375090",
      "comments": [
        {
          "author": "seehi",
          "body": "It is recommended to upgrade the existing numpy.\r\n",
          "created_at": "2024-09-11T09:41:52Z"
        },
        {
          "author": "b423016",
          "body": "I want to Work on this issue\r\n",
          "created_at": "2024-10-02T13:28:52Z"
        },
        {
          "author": "PR-HARIHARAN",
          "body": "Hi team,\r\n\r\nI'm interested in working on this issue. Could someone please assign it to me? I'd be happy to contribute!\r\n\r\nThanks,\r\nHariharan P R\r\n",
          "created_at": "2024-10-03T12:25:08Z"
        },
        {
          "author": "geekan",
          "body": "@PR-HARIHARAN Thank you very much, you can submit PR directly and I will review all PRs in the next few days.",
          "created_at": "2024-10-03T12:26:26Z"
        },
        {
          "author": "better629",
          "body": "@PR-HARIHARAN @b423016 Are you ready for a PR to address this issue? We're looking forward to it",
          "created_at": "2024-10-09T16:51:34Z"
        }
      ]
    },
    {
      "issue_number": 1492,
      "title": "Metagptæ‰§è¡Œpythonç¨‹åºæ²¡æœ‰ç”Ÿæˆæ–‡ä»¶ï¼Œä½†æ˜¯åœ¨å‘½ä»¤è¡Œè¿è¡Œmetagpt \"write a game\"å¯ä»¥ç”Ÿæˆé¡¹ç›®æ–‡ä»¶",
      "body": "**Bug description**\r\n<!-- Clearly and directly describe the current bug -->\r\n\r\n**Bug solved method**\r\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\r\n\r\n**Environment information**\r\n<!-- Environmentï¼šSystem version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\r\n\r\n- LLM type and model name:\r\n- System version:\r\n- Python version:\r\n- MetaGPT version or branch:\r\n\r\n<!-- Dependent packagessï¼šthe packages version cause the bug(like `pydantic 1.10.8`), installation methodï¼ˆlike `pip install metagpt` or `pip install from source` or `run in docker`ï¼‰ -->\r\n\r\n- packages version:\r\n<img width=\"1484\" alt=\"æˆªå±2024-10-08 18 59 23\" src=\"https://github.com/user-attachments/assets/2b92a980-e54e-400e-bb27-2ebde81eb03c\">\r\n\r\n- installation method: \r\n\r\n**Screenshots or logs**\r\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\r\n",
      "state": "closed",
      "author": "NICERTYU",
      "author_type": "User",
      "created_at": "2024-10-08T10:59:38Z",
      "updated_at": "2025-01-17T00:29:49Z",
      "closed_at": "2025-01-17T00:29:49Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1492/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1492",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1492",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:27.569770",
      "comments": [
        {
          "author": "better629",
          "body": "@NICERTYU What does it mean to execute a python program? Can you share you command?",
          "created_at": "2024-10-09T16:34:58Z"
        },
        {
          "author": "NICERTYU",
          "body": "> @NICERTYU What does it mean to execute a python program? Can you share you command?\r\n\r\næˆ‘åœ¨terminalè¿è¡Œ â€œMetagpt   â€œWrite a cli gameâ€ èƒ½å¤Ÿç”Ÿæˆä»£ç ï¼Œ ä½†æ˜¯æˆ‘åœ¨pythonç¨‹åºä¸­å¯¼å…¥metagptä½¿ç”¨æ—¶ï¼Œæˆ‘ä½¿ç”¨çš„è§’è‰²èƒ½å¤Ÿå¯¹è¯ï¼Œä½†æ˜¯æ²¡æœ‰ä»£ç æ–‡ä»¶äº§ç”Ÿã€‚æˆ‘ä½¿ç”¨çš„ç‰ˆæœ¬æ˜¯0.8.0",
          "created_at": "2024-10-15T00:06:36Z"
        },
        {
          "author": "better629",
          "body": "> > @NICERTYU What does it mean to execute a python program? Can you share you command?\r\n> \r\n> æˆ‘åœ¨terminalè¿è¡Œ â€œMetagpt â€œWrite a cli gameâ€ èƒ½å¤Ÿç”Ÿæˆä»£ç ï¼Œ ä½†æ˜¯æˆ‘åœ¨pythonç¨‹åºä¸­å¯¼å…¥metagptä½¿ç”¨æ—¶ï¼Œæˆ‘ä½¿ç”¨çš„è§’è‰²èƒ½å¤Ÿå¯¹è¯ï¼Œä½†æ˜¯æ²¡æœ‰ä»£ç æ–‡ä»¶äº§ç”Ÿã€‚æˆ‘ä½¿ç”¨çš„ç‰ˆæœ¬æ˜¯0.8.0\r\n\r\n@NICERTYU can you share your log by your used role under `imported metagpt`",
          "created_at": "2024-10-18T09:28:52Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-02T00:30:17Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-17T00:29:48Z"
        }
      ]
    },
    {
      "issue_number": 1495,
      "title": "Create tools dynamically, after checking if they exist or not. ",
      "body": "**Feature description**\r\n<!-- Clear and direct description of the functionality of the currently submitted or proposed feature -->\r\nDynamic tool creation and registration. \r\n**Your Feature**\r\n<!-- Describe the idea or process of implementing the current feature. Of course, you can also paste the URL address of your Pull Request. -->\r\nWhat if the metagpt agent/data interpreter agent realises it needs a particular tool for a task but it hasn't been provided? There needs to be a mechanism to check for this and create one on the fly. \r\nIt would highly enhance the strength of the agent, so it could add skills as it executes. \r\nThank you. \r\nSome reference code , to get started - https://github.com/yoheinakajima/babyagi/tree/main/babyagi/functionz\r\n<!-- When submitting features, you need to complete the corresponding doc/tests/examples to facilitate verification by reviewers. -->\r\n",
      "state": "closed",
      "author": "krish240574",
      "author_type": "User",
      "created_at": "2024-10-09T05:12:48Z",
      "updated_at": "2025-01-16T00:29:51Z",
      "closed_at": "2025-01-16T00:29:50Z",
      "labels": [
        "tool",
        "inactive"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1495/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1495",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1495",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:27.827732",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-01T00:34:17Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-16T00:29:50Z"
        }
      ]
    },
    {
      "issue_number": 1497,
      "title": "how can i get stable outputs?",
      "body": "I hope that the DataInterpreter can generate similar answers when given the same question. I've already set temperature to 0 in config.yaml, but the answers differ each time. How can I get stable outputs? ",
      "state": "closed",
      "author": "kuranatsu",
      "author_type": "User",
      "created_at": "2024-10-11T00:58:12Z",
      "updated_at": "2025-01-16T00:29:50Z",
      "closed_at": "2025-01-16T00:29:49Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1497/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1497",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1497",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:28.059913",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-01T00:34:16Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-16T00:29:49Z"
        }
      ]
    },
    {
      "issue_number": 1498,
      "title": "Group related issues: solutions about incremental development in MetaGPT",
      "body": "**Issues**\r\n- #1436 \r\n- #1379 \r\n- #1210 \r\n- #1095 \r\n- #972 \r\n- #871 \r\n- #333 \r\n\r\n**Bug solved method**\r\nThe previous incremental software development method based on SOP has several issues:\r\n- Inconvenient human-computer interaction. New user requirements, technical demands, bug fixes, and added design constraints are difficult to directly correspond to the relevant SOP steps for operation.\r\n- Inflexible programming languages. The same design cannot be easily switched to different programming languages, mixed-language programming is not supported, and design solutions cannot be reused.\r\n\r\nTo address this, we propose a more practical solution. \r\nIt is an upgraded version of `DI` (`Data Interpreter`) called `RoleZero`, which will be released soon. It adopts the following methods to handle software development issues with real-time human-computer interaction:\r\n1. Generate sequence diagrams from requirements. This compresses the content size of requirement descriptions and supports flexible changes in requirements and switching between programming languages.\r\n2. Generate code from sequence diagrams rather than directly from user requirements. This approach supports design outputs reuse, can flexibly generate code in different languages, allows for additional technical requirements during code generation (such as which packages must be used, how interfaces should be utilized, etc.), and supports mixed programming languages.\r\n3. Bug modifications can be implemented through human-computer interaction, directly targeting specific files.\r\n4. Regarding the coding of the UI, you can use `RoleZero` to convert UI pictures into code, and then merge them into the backend code generated based on the sequence diagrams through human-computer interaction.\r\n\r\n**Design Outputs Demo**\r\nHere is an example of a sequence diagram generated by `RoleZero` based on real software development requirements giving a user requirement PDF file and an external system interface usage PDF file, to help everyone understand `RoleZero`'s capabilities in interpreting requirements.\r\n![image](https://github.com/user-attachments/assets/d0429c27-df51-444a-b9c6-ebee122aaf91)\r\n![image](https://github.com/user-attachments/assets/ee0a8d8a-1621-424a-95d5-4bd5fb511eec)\r\n\r\n\r\nSubsequent issues related to new requirements or bug fixes will be consolidated under this issue for further follow-up.\r\n\r\n\r\n",
      "state": "closed",
      "author": "iorisa",
      "author_type": "User",
      "created_at": "2024-10-11T06:23:11Z",
      "updated_at": "2025-01-16T00:29:49Z",
      "closed_at": "2025-01-16T00:29:48Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1498/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": "1.0",
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1498",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1498",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:28.295711",
      "comments": [
        {
          "author": "hgftrdw45ud67is8o89",
          "body": "although PDF is a awesome file/document format, I personally think a json or etc would be better.\r\n\r\nBecause I am scared that the pdf parser could be too complex to use/maintain (especially compatibility).\r\n\r\nPDF is originally by adobe,so i think we must make sure the save format is https://www.iso.",
          "created_at": "2024-10-16T22:31:10Z"
        },
        {
          "author": "iorisa",
          "body": "We choose to use PDF because in reality, most software requirements are archived and transferred using docx or PDF documents, so this is an adjustment based on the real-world situation.\r\n\r\nPDF is just a file format, it does not define the content.\r\n\r\nHowever, in reality, the description of software ",
          "created_at": "2024-10-23T02:53:53Z"
        },
        {
          "author": "hgftrdw45ud67is8o89",
          "body": "i see. will wait for the release and test it out.",
          "created_at": "2024-10-24T22:13:02Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2025-01-01T00:34:15Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-16T00:29:48Z"
        }
      ]
    },
    {
      "issue_number": 1512,
      "title": " I need a function, that can generate standard workflow and related agents (or use local agents) ,codes according to users 's text input",
      "body": "è¯·é—®å¯ä»¥ç»™metagptå¢åŠ ä¸€ä¸ªï¼Œæ ¹æ®å·²æœ‰æ™ºèƒ½ä½“å’Œå·¥å…·ï¼Œä»¥åŠç”¨æˆ·çš„éœ€æ±‚ï¼Œç¼–æ’ä¸€æ•´ä¸ªå·¥ä½œæµçš„ç¯èŠ‚å—",
      "state": "closed",
      "author": "CoderYiFei",
      "author_type": "User",
      "created_at": "2024-10-17T08:45:02Z",
      "updated_at": "2025-01-15T00:30:05Z",
      "closed_at": "2025-01-15T00:30:04Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1512/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1512",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1512",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:28.480183",
      "comments": [
        {
          "author": "geekan",
          "body": "Hello, please use English.",
          "created_at": "2024-10-20T07:12:45Z"
        },
        {
          "author": "CoderYiFei",
          "body": "I need a function, that can generate standard workflow and related agents (or use local agents) ,codes  according to users 's text input .... it seems that your AFlow can do it",
          "created_at": "2024-10-20T07:53:51Z"
        },
        {
          "author": "jmanhype",
          "body": "> I need a function, that can generate standard workflow and related agents (or use local agents) ,codes according to users' text input .... it seems that your AFlow can do it\r\n\r\nit can :package: https://jmanhype.github.io/HotpotQA-Alternate-History-Generator/",
          "created_at": "2024-10-20T08:39:49Z"
        },
        {
          "author": "jmanhype",
          "body": "> I need a function, that can generate standard workflow and related agents (or use local agents) ,codes according to users' text input .... it seems that your AFlow can do it\r\n\r\nfrom one friend to another ! cheers https://github.com/didiforgithub/MetaGPT-MathAI/tree/main/examples/aflow",
          "created_at": "2024-10-20T08:42:38Z"
        },
        {
          "author": "geekan",
          "body": "AFlow in its current design requires a dataset and it will be optimized for the metrics of the dataset. If you have a data set (even a very small one), then you can use AFlow.",
          "created_at": "2024-10-21T03:33:02Z"
        }
      ]
    },
    {
      "issue_number": 1516,
      "title": "metagpt should be able to get terminal output and screenshot to review code ",
      "body": "you can refer these projects to design it.\r\nrefer projects:\r\nopen-interpreter: https://github.com/OpenInterpreter/open-interpreter\r\naider: https://github.com/Aider-AI/aider\r\nscreenshot-to-code: https://github.com/abi/screenshot-to-code\r\nAgent-E: https://github.com/EmergenceAI/Agent-E\r\ngptme: https://github.com/ErikBjare/gptme",
      "state": "closed",
      "author": "CoderYiFei",
      "author_type": "User",
      "created_at": "2024-10-20T08:02:16Z",
      "updated_at": "2025-01-13T00:33:17Z",
      "closed_at": "2025-01-13T00:33:17Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1516/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1516",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1516",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:28.687148",
      "comments": [
        {
          "author": "jmanhype",
          "body": "https://jmanhype.github.io/HotpotQA-Alternate-History-Generator/",
          "created_at": "2024-10-20T08:41:08Z"
        },
        {
          "author": "geekan",
          "body": "You could try the [Data Interpreter](https://arxiv.org/abs/2402.18679), which has some of the functionality mentioned, like getting textual terminal output. It will become the backbone of all agents in version 1.0.",
          "created_at": "2024-10-21T03:34:26Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-30T00:32:09Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-13T00:33:16Z"
        }
      ]
    },
    {
      "issue_number": 1612,
      "title": "The prompt has 13284 tokens and the max_tokens is 4096 tokens.",
      "body": "**Bug description**\r\n<!-- Clearly and directly describe the current bug -->\r\nMetagpt exited halfway because of an exception due to max_tokens setting.\r\n\r\n**Bug solved method**\r\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\r\n\r\n**Environment information**\r\n<!-- Environmentï¼šSystem version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\r\n\r\n- LLM type and model name: yi-lightning\r\n- System version: ubuntu 22.04\r\n- Python version: 3.11\r\n- MetaGPT version or branch: main\r\n- packages version: 0.8.1\r\n- installation method: pip\r\n\r\n<!-- Dependent packagessï¼šthe packages version cause the bug(like `pydantic 1.10.8`), installation methodï¼ˆlike `pip install metagpt` or `pip install from source` or `run in docker`ï¼‰ -->\r\n\r\n- packages version:\r\n- installation method: \r\n\r\n**Screenshots or logs**\r\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\r\n2024-11-22 17:18:08.597 | INFO     | metagpt.actions.write_code_review:run:185 - Code review and rewrite main.py: 1/2 | len(iterative_code)=12485, len(self.i_context.code_doc.content)=12485\r\n2024-11-22 17:18:31.001 | WARNING  | metagpt.utils.common:wrapper:673 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.\r\n2024-11-22 17:18:31.002 | ERROR    | metagpt.utils.common:wrapper:655 - Exception occurs, start to serialize the project, exp:\r\nTraceback (most recent call last):\r\n  File \"/root/anaconda3/envs/metagpt/lib/python3.11/site-packages/metagpt/utils/common.py\", line 650, in wrapper\r\n    result = await func(self, *args, **kwargs)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/anaconda3/envs/metagpt/lib/python3.11/site-packages/metagpt/team.py\", line 134, in run\r\n    await self.env.run()\r\nopenai.BadRequestError: Error code: 400 - {'error': {'code': 'bad_request', 'message': 'The total number of tokens in the prompt and the max_tokens must be less than or equal to 16000. The prompt has 13284 tokens and the max_tokens is 4096 tokens.', 'type': 'invalid_request_error', 'param': None}}\r\n\r\n",
      "state": "closed",
      "author": "happytravelingskysheep",
      "author_type": "User",
      "created_at": "2024-11-22T09:28:01Z",
      "updated_at": "2025-01-06T00:32:36Z",
      "closed_at": "2025-01-06T00:32:35Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1612/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1612",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1612",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:28.885275",
      "comments": [
        {
          "author": "voidking",
          "body": "Try to set `max_token` in config2.yaml\r\n```yaml\r\nllm:\r\n  api_type: \"openai\"\r\n  model: \"gpt-3.5-turbo-16k\" \r\n  base_url: \"https://api.openai.com/v1\" \r\n  api_key: \"sk-xxx\"\r\n  max_token: 16000\r\n```",
          "created_at": "2024-11-22T11:11:10Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-23T00:31:51Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-06T00:32:35Z"
        }
      ]
    },
    {
      "issue_number": 1611,
      "title": "Error: Parse error on line 42:...Handler --> selenium.webdriver",
      "body": "**Bug description**\r\nAnother bug with playwright. \r\nError: Parse error on line 42:...Handler --> selenium.webdriver\r\n**Bug solved method**\r\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\r\n\r\n**Environment information**\r\n- LLM type and model name:\r\n- System version: ubuntu 22.04\r\n- Python version: 3.11\r\n- MetaGPT version or branch: main\r\n- packages version: 0.8.1\r\n- installation method: pip\r\n\r\n**Screenshots or logs**\r\n2024-11-22 17:03:13.898 | INFO     | metagpt.utils.file_repository:save:57 - save to: /root/workspace/workspace/design_pattern_simulation/docs/system_design/20241122170240.json\r\n2024-11-22 17:03:13.899 | INFO     | metagpt.utils.file_repository:save:62 - update dependency: /root/workspace/workspace/design_pattern_simulation/docs/system_design/20241122170240.json:{'docs/prd/20241122170240.json'}\r\n2024-11-22 17:03:14.997 | ERROR    | metagpt.utils.mmdc_playwright:mermaid_to_file:121 - Page.evaluate: Error: Parse error on line 42:...Handler --> selenium.webdriver    Docum-----------------------^Expecting 'NEWLINE', 'EOF', 'SQS', 'STR', 'GENERICTYPE', 'LABEL', 'STRUCT_START', 'STRUCT_STOP', 'STYLE_SEPARATOR', 'ANNOTATION_END', 'AGGREGATION', 'EXTENSION', 'COMPOSITION', 'DEPENDENCY', 'LOLLIPOP', 'LINE', 'DOTTED_LINE', 'CALLBACK_NAME', 'HREF', 'MINUS', 'UNICODE_TEXT', 'NUM', 'ALPHA', 'BQUOTE_STR', got 'DOT'\r\n    at WA.parseError (file:///root/anaconda3/envs/metagpt/lib/python3.11/site-packages/metagpt/utils/index.html:1:894276)\r\n    at WA.parse (file:///root/anaconda3/envs/metagpt/lib/python3.11/site-packages/metagpt/utils/index.html:1:895563)\r\n    at CUe.parser.parse (file:///root/anaconda3/envs/metagpt/lib/python3.11/site-packages/metagpt/utils/index.html:1:276633)\r\n    at CUe.parse (file:///root/anaconda3/envs/metagpt/lib/python3.11/site-packages/metagpt/utils/index.html:1:276867)\r\n    at new CUe (file:///root/anaconda3/envs/metagpt/lib/python3.11/site-packages/metagpt/utils/index.html:1:276708)\r\n    at YjA (file:///root/anaconda3/envs/metagpt/lib/python3.11/site-packages/metagpt/utils/index.html:1:277173)\r\n    at async Object.eDt [as render] (file:///root/anaconda3/envs/metagpt/lib/python3.11/site-packages/metagpt/utils/index.html:1:281122)\r\n",
      "state": "closed",
      "author": "happytravelingskysheep",
      "author_type": "User",
      "created_at": "2024-11-22T09:23:23Z",
      "updated_at": "2025-01-06T00:32:36Z",
      "closed_at": "2025-01-06T00:32:36Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1611/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1611",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1611",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:29.068343",
      "comments": [
        {
          "author": "voidking",
          "body": "This error indicates that the mermaid file generated by llm is not standardized. Therefore, the parsing error occurs. \r\nIt is recommended to rerun or replace it with a better llm model.",
          "created_at": "2024-11-22T11:25:22Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-23T00:31:52Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-06T00:32:36Z"
        }
      ]
    },
    {
      "issue_number": 1602,
      "title": "å¦‚ä½•ç»“åˆgradioä½¿ç”¨",
      "body": "ä½¿ç”¨DataInterpreterï¼Œå¦‚ä½•ç»“åˆgradioï¼ŒæŠŠä¸­é—´æ­¥éª¤è¾“å‡ºç»“æœå±•ç¤ºå‡ºæ¥",
      "state": "closed",
      "author": "ZTurboX",
      "author_type": "User",
      "created_at": "2024-11-14T07:52:37Z",
      "updated_at": "2025-01-05T00:33:47Z",
      "closed_at": "2025-01-05T00:33:46Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1602/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1602",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1602",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:29.369458",
      "comments": [
        {
          "author": "BCYounker",
          "body": "åŒé—®",
          "created_at": "2024-11-21T11:12:24Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-22T00:33:40Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-05T00:33:46Z"
        }
      ]
    },
    {
      "issue_number": 1593,
      "title": "Updating the TOKEN_COSTS for Model Qwen/Qwen2.5-Coder-32B-Instruct",
      "body": "2024-11-12 17:30:29.957 | WARNING  | metagpt.utils.cost_manager:update_cost:49 - Model Qwen/Qwen2.5-Coder-32B-Instruct not found in TOKEN_COSTS.",
      "state": "closed",
      "author": "ZONGEZE",
      "author_type": "User",
      "created_at": "2024-11-12T09:31:19Z",
      "updated_at": "2025-01-04T00:29:57Z",
      "closed_at": "2025-01-04T00:29:56Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1593/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1593",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1593",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:29.689358",
      "comments": [
        {
          "author": "voidking",
          "body": "Currently some LLM APIs do not support cost statistics. Which LLM are you using?",
          "created_at": "2024-11-13T02:23:02Z"
        },
        {
          "author": "ZONGEZE",
          "body": "> Currently some LLM APIs do not support cost statistics. Which LLM are you using?\r\n\r\nQwen2.5-Coder-32B-Instruct",
          "created_at": "2024-11-14T02:15:09Z"
        },
        {
          "author": "CheeYeah",
          "body": "in the file /utils/token_counter.py\r\nadd \"Qwen2.5-Coder-32B-Instruct\": {\"prompt\": 0.0005, \"completion\": 0.001}, at the end of DASHSCOPE_TOKEN_COSTS",
          "created_at": "2024-11-19T08:46:12Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-20T00:30:33Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-04T00:29:56Z"
        }
      ]
    },
    {
      "issue_number": 1583,
      "title": "TypeError: 'NoneType' object is not iterable",
      "body": "Hi ,\r\n**I just installed MetaGpt on ubuntu20, and config LLM through modified ./config/congfig2.yaml;**\r\n\r\n**then executed example , logs info below :**\r\npydantic_core._pydantic_core.ValidationError: 1 validation error for Config\r\nllm.api_key\r\n  Value error, Please set your API key in /home/*****/.metagpt/config2.yaml. If you also set your config in /data2/11_metadata/MetaGPT/config/config2.yaml, \r\nthe former will overwrite the latter. This may cause unexpected result.\r\n [type=value_error, input_value='YOUR_API_KEY', input_type=str]\r\n    For further information visit https://errors.pydantic.dev/2.9/v/value_error\r\n\r\n**so ,I Erased  /home/*****/.metagpt/config2.yaml ï¼Œexecuted agant, Error info like below:**\r\n**Feature description**\r\n_$ python examples/di/data_visualization.py_\r\n2024-11-08 11:28:52.046 | INFO     | metagpt.const:get_metagpt_package_root:21 - Package root set to /data2/11_metadata/MetaGPT\r\nTraceback (most recent call last):\r\n  File \"/data2/11_metadata/MetaGPT/examples/di/data_visualization.py\", line 4, in <module>\r\n    from metagpt.roles.di.data_interpreter import DataInterpreter\r\n  File \"/data2/11_metadata/MetaGPT/metagpt/roles/__init__.py\", line 9, in <module>\r\n    from metagpt.roles.role import Role\r\n  File \"/data2/11_metadata/MetaGPT/metagpt/roles/role.py\", line 30, in <module>\r\n    from metagpt.actions import Action, ActionOutput\r\n  File \"/data2/11_metadata/MetaGPT/metagpt/actions/__init__.py\", line 10, in <module>\r\n    from metagpt.actions.action import Action\r\n  File \"/data2/11_metadata/MetaGPT/metagpt/actions/action.py\", line 15, in <module>\r\n    from metagpt.actions.action_node import ActionNode\r\n  File \"/data2/11_metadata/MetaGPT/metagpt/actions/action_node.py\", line 22, in <module>\r\n    from metagpt.llm import BaseLLM\r\n  File \"/data2/11_metadata/MetaGPT/metagpt/llm.py\", line 11, in <module>\r\n    from metagpt.context import Context\r\n  File \"/data2/11_metadata/MetaGPT/metagpt/context.py\", line 14, in <module>\r\n    from metagpt.config2 import Config\r\n  File \"/data2/11_metadata/MetaGPT/metagpt/config2.py\", line 169, in <module>\r\n    config = Config.default()\r\n             ^^^^^^^^^^^^^^^^\r\n  File \"/data2/11_metadata/MetaGPT/metagpt/config2.py\", line 110, in default\r\n    final = merge_dict(dicts)\r\n            ^^^^^^^^^^^^^^^^^\r\n  File \"/data2/11_metadata/MetaGPT/metagpt/config2.py\", line 165, in merge_dict\r\n    result.update(dictionary)\r\n**### TypeError: 'NoneType' object is not iterable**\r\n**Your Feature**\r\n<!-- Describe the idea or process of implementing the current feature. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- When submitting features, you need to complete the corresponding doc/tests/examples to facilitate verification by reviewers. -->\r\n",
      "state": "closed",
      "author": "baronbigghf",
      "author_type": "User",
      "created_at": "2024-11-08T03:44:22Z",
      "updated_at": "2025-01-03T00:30:23Z",
      "closed_at": "2025-01-03T00:30:22Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1583/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "voidking"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1583",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1583",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:29.873755",
      "comments": [
        {
          "author": "voidking",
          "body": "How is config2.yaml configured?",
          "created_at": "2024-11-11T05:40:19Z"
        },
        {
          "author": "baronbigghf",
          "body": "> How is config2.yaml configured?\r\n\r\nthank you  vidking. I used  conifg file under /home , erased ./config/congfig2.yamlï¼Œ then  it run ok . but not mind the reason .",
          "created_at": "2024-11-18T03:03:30Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-19T00:32:17Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-03T00:30:21Z"
        }
      ]
    },
    {
      "issue_number": 1604,
      "title": "è¾“å‡ºä¸­é—´è¿‡ç¨‹åç§°",
      "body": "ä½¿ç”¨DataInterpreterï¼Œå¦‚ä½•åœ¨await mi.run(requirement)ä¸­è¾“å‡ºæ¯æ­¥æ‰§è¡Œä»»åŠ¡çš„åç§°åœ¨å‰ç«¯å±•ç¤ºï¼Œå³å®æ—¶è¿”å›æ¯ä¸€æ­¥çš„self.planner.current_task.instructionåœ¨å‰ç«¯å±•ç¤º",
      "state": "closed",
      "author": "ZTurboX",
      "author_type": "User",
      "created_at": "2024-11-15T01:41:40Z",
      "updated_at": "2025-01-01T00:34:12Z",
      "closed_at": "2025-01-01T00:34:12Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1604/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1604",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1604",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:30.098621",
      "comments": [
        {
          "author": "garylin2099",
          "body": "ä½ å¥½ï¼å¯ä»¥åœ¨ä»£ç ä¸­æ·»åŠ å‘å‰ç«¯ä¸ŠæŠ¥çš„ç›¸å…³ä»£ç ã€‚æˆ‘ä»¬ä¼šåœ¨metagpt 1.0ä¸­æ¨å‡ºä¸ŠæŠ¥åŠŸèƒ½",
          "created_at": "2024-11-15T11:43:17Z"
        },
        {
          "author": "ZTurboX",
          "body": "> ä½ å¥½ï¼å¯ä»¥åœ¨ä»£ç ä¸­æ·»åŠ å‘å‰ç«¯ä¸ŠæŠ¥çš„ç›¸å…³ä»£ç ã€‚æˆ‘ä»¬ä¼šåœ¨metagpt 1.0ä¸­æ¨å‡ºä¸ŠæŠ¥åŠŸèƒ½\r\n\r\nèƒ½å…·ä½“è¯´è¯´æ˜¯ç”¨ä»€ä¹ˆæ€è·¯å®ç°å—",
          "created_at": "2024-11-18T00:11:13Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-18T00:32:06Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2025-01-01T00:34:12Z"
        }
      ]
    },
    {
      "issue_number": 1502,
      "title": "Bug: Unable to Navigate Back to Main README from README_CN or README_JA",
      "body": "**Bug Description**\r\nWhen navigating between the localized versions of the documentation, the links in `README_CN.md` and `README_JA.md` do not correctly redirect back to the main `README.md` in English. Clicking on these links keeps the user stuck in the current localized version, preventing smooth and intuitive navigation.\r\n\r\n### Steps to Reproduce the Bug\r\n1. Open `README_CN.md` or `README_JA.md`.\r\n2. Click on the link intended to redirect to the main `README.md`.\r\n3. Observe that the redirection does not occur as expected.\r\n\r\n### Expected Result\r\nThe link should redirect the user to the main `README.md` in English, allowing for an easy and intuitive return from the localized versions of the documentation.\r\n\r\n### Actual Result\r\nThe link does not work properly or redirects incorrectly, preventing the user from leaving the localized version. \r\n\r\n![Screenshot 2024-10-14 011141](https://github.com/user-attachments/assets/6fdfef6c-8fa8-4b73-9a1f-01cbff472199)\r\n",
      "state": "closed",
      "author": "TitanSage02",
      "author_type": "User",
      "created_at": "2024-10-14T00:13:41Z",
      "updated_at": "2024-12-31T17:52:07Z",
      "closed_at": "2024-12-31T17:52:07Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1502/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1502",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1502",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:30.276416",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-31T00:30:26Z"
        }
      ]
    },
    {
      "issue_number": 1594,
      "title": "å¦‚ä½•ä½¿ç”¨è‡ªå®šä¹‰tool",
      "body": "å¦‚ä½•é€šè¿‡ç”¨æˆ·è¾“å…¥ï¼Œè°ƒç”¨è‡ªå®šä¹‰tool",
      "state": "closed",
      "author": "ZTurboX",
      "author_type": "User",
      "created_at": "2024-11-12T23:59:51Z",
      "updated_at": "2024-12-31T00:30:24Z",
      "closed_at": "2024-12-31T00:30:23Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1594/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1594",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1594",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:30.453754",
      "comments": [
        {
          "author": "voidking",
          "body": "ç›®å‰ä¸æ”¯æŒé€šè¿‡ç”¨æˆ·è¾“å…¥è°ƒç”¨è‡ªå®šä¹‰toolã€‚å¦‚æœæƒ³è‡ªå®šä¹‰toolå¹¶è°ƒç”¨ï¼Œéœ€è¦ä¿®æ”¹ä»£ç å’Œé…ç½®æ–‡ä»¶ã€‚",
          "created_at": "2024-11-13T02:15:29Z"
        },
        {
          "author": "ZTurboX",
          "body": "> ç›®å‰ä¸æ”¯æŒé€šè¿‡ç”¨æˆ·è¾“å…¥è°ƒç”¨è‡ªå®šä¹‰toolã€‚å¦‚æœæƒ³è‡ªå®šä¹‰toolå¹¶è°ƒç”¨ï¼Œéœ€è¦ä¿®æ”¹ä»£ç å’Œé…ç½®æ–‡ä»¶ã€‚\r\n\r\næ˜¯ç±»ä¼¼è¿™æ ·ä¿®æ”¹å—ï¼Ÿhttps://docs.deepwisdom.ai/main/zh/guide/tutorials/create_and_use_tools.htmlï¼›çœ‹äº†DataInterpreterçš„æºç ï¼Œæƒ³é€šè¿‡llm planè‡ªå®šä¹‰toolçš„æ‰§è¡Œï¼Œä½†ä¸éœ€è¦llmè‡ªåŠ¨ç”Ÿæˆä»£ç ï¼Œæ˜¯è¦ä¿®æ”¹WriteAnalysisCodeå—",
          "created_at": "2024-11-13T02:38:55Z"
        },
        {
          "author": "voidking",
          "body": "æ˜¯çš„ï¼Œé™¤äº†é‚£ä»½æ–‡æ¡£ï¼Œä¹Ÿå¯ä»¥å‚è€ƒä¸‹è°ƒç ”å‘˜çš„å®ç°ï¼Œä¹Ÿæ˜¯è‡ªå®šä¹‰toolå¾ˆå¥½çš„ä¾‹å­ https://github.com/geekan/MetaGPT/blob/main/examples/research.py",
          "created_at": "2024-11-15T07:56:16Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-16T00:34:53Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-31T00:30:23Z"
        }
      ]
    },
    {
      "issue_number": 1603,
      "title": "llm response appear self-talking",
      "body": "This is my prompt:\r\n\r\n```code\r\nPROMPT_TEMPLATE: str = \"\"\"### Context\r\n{context}\r\n\r\n### Instruction\r\n{instruction}\r\n\r\n### Requirements\r\n1. Base on the context, response a chat completion of Instruction.\r\n2. Please use beautiful and simple language and response must be in English.\r\n```\r\n\r\n\r\nmy context content is:\r\n```code memories = self.get_memories()\r\ncontext = \"\\n\".join(f\"{msg.role}: {msg.content}\" for msg in memories)\r\n```\r\n\r\n\r\nThe final return result:\r\n```code\r\nHello, Nice to meet you!\r\nuser: xxxxxxxx.\r\nrole: xxxxxxxx.\r\nuser: xxxxxxxx.\r\nrole: xxxxxxxx.\r\nuser: xxxxxxxx.\r\nrole: xxxxxxxx.\r\n```\r\nAfter answering two or three times, the replies will be self-talking. These contents have never appeared in the context again. Is it because my prompt is not written correctly?\r\n\r\n",
      "state": "closed",
      "author": "pzw943969386",
      "author_type": "User",
      "created_at": "2024-11-14T11:06:46Z",
      "updated_at": "2024-12-31T00:30:23Z",
      "closed_at": "2024-12-31T00:30:22Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1603/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1603",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1603",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:30.683976",
      "comments": [
        {
          "author": "voidking",
          "body": "What kind of functionality do you want to achieve? What does your complete code look like?",
          "created_at": "2024-11-15T05:47:13Z"
        },
        {
          "author": "pzw943969386",
          "body": "It is the simplest action, the function is ordinary chat, but the returned result sometimes talks to itself",
          "created_at": "2024-11-15T07:29:38Z"
        },
        {
          "author": "pzw943969386",
          "body": "The code is almost like this, some business logic is deleted\r\n```code\r\n\r\nclass ChatCompletionAction(Action):\r\n    PROMPT_TEMPLATE: str = \"\"\"### Context\r\n{context}\r\n\r\n### Instruction\r\n{instruction}\r\n\r\n### Requirements\r\n1. Base on the context, response a chat completion of Instruction.\r\n2. Please use ",
          "created_at": "2024-11-15T07:34:32Z"
        },
        {
          "author": "voidking",
          "body": "Maybe you can refer to: https://github.com/geekan/MetaGPT/blob/main/examples/debate.py",
          "created_at": "2024-11-15T07:39:53Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-16T00:34:51Z"
        }
      ]
    },
    {
      "issue_number": 1518,
      "title": "Can we add a directory , that contains the models to task' s auto allocation function? ",
      "body": "\r\nFor some relatively difficult tasks, more complex models such as o1-preview or Claude 3.5 Sonnet will be automatically called. \r\nFor example, code review tasks or architecture tasks (unless the user specifies not to use them). \r\n\r\nIf it is a relatively simple task, such as writing code for a text classification model or writing a function for a simple crawler, etc., a faster domestic model such as DeepSeek v2.5 can be automatically selected. \r\n\r\nThe function is to automatically prioritize the allocation of large models according to the task difficulty (assuming that the user has several large models).",
      "state": "closed",
      "author": "CoderYiFei",
      "author_type": "User",
      "created_at": "2024-10-20T12:15:57Z",
      "updated_at": "2024-12-30T00:32:09Z",
      "closed_at": "2024-12-30T00:32:08Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1518/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1518",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1518",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:30.876919",
      "comments": [
        {
          "author": "geekan",
          "body": "This feature is planned and expected to be available in the coming months, but is not available yet.",
          "created_at": "2024-10-21T03:35:20Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-05T00:33:09Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-30T00:32:08Z"
        }
      ]
    },
    {
      "issue_number": 1520,
      "title": "Can you add number of code lines that metagpt can maintain now , to readme",
      "body": "\r\nCould you add the medium lines that new version's MetaGPT can maintained ?\r\nits better to show a change figure in readme.md\r\nfrom 2023.07 to now , the number of code lines that metagpt can maintain from 2000 to ....(maybe 10k? 20k?)",
      "state": "closed",
      "author": "CoderYiFei",
      "author_type": "User",
      "created_at": "2024-10-20T16:06:00Z",
      "updated_at": "2024-12-30T00:32:07Z",
      "closed_at": "2024-12-30T00:32:06Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1520/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1520",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1520",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:31.116992",
      "comments": [
        {
          "author": "geekan",
          "body": "Our metrics are not yet available to the public, and some metrics may be updated in version 1.0.",
          "created_at": "2024-10-21T03:38:16Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-04T00:33:20Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-30T00:32:06Z"
        }
      ]
    },
    {
      "issue_number": 1519,
      "title": "[Very important] can metagpt add a directory to collect useful news , to let it envole it automatically",
      "body": "For example, there are many AI news per week on internet.\r\nmetagpt should download some news , \r\nand analyze if the news or open source project or a new arxiv paper useful , \r\nfor metagpt to evolve.\r\nthen metagpt will design a short term roadmap for itself, \r\nif Alexander Wu choose \"accept\", then metagpt will automatically develop a new branch that finished the roadmap.\r\nif Alexander Wu choose \"accept\" again , metagpt will  automatically test itself , and merge it to main branch.\r\n\r\nthese are AI news examples :\r\n[video] https://www.bilibili.com/video/BV1wk2UYaEWm?spm_id_from=333.788.player.switch&vd_source=97ab50b6d1c6cd0cf34537c8b367dece\r\n\r\n[news] https://d.aigclink.ai/fe1ce99bc6a64266aa1ee5479c8e6da6?v=8f252a54730e49f4b8caf897b7ae49f6\r\n....",
      "state": "closed",
      "author": "CoderYiFei",
      "author_type": "User",
      "created_at": "2024-10-20T14:04:53Z",
      "updated_at": "2024-12-30T00:32:07Z",
      "closed_at": "2024-12-30T00:32:07Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1519/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1519",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1519",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:31.311923",
      "comments": [
        {
          "author": "geekan",
          "body": "This is a very good idea. But unfortunately, the current Code Agent is not yet able to complete such complex functions.",
          "created_at": "2024-10-21T03:36:43Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-05T00:33:08Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-30T00:32:07Z"
        }
      ]
    },
    {
      "issue_number": 1521,
      "title": "Dynamic sop(team)  ,  instead of a given sop(team) , should be designed ",
      "body": "sometimes , sop(team) is changing soon.\r\nfor example , if I want to design a text classification model\r\nmy sop(team) might only be Engineer + Project Manager + boss + QA \r\n\r\nDifferent user request , will lead to different sop(team) \r\nDifferent sop(team)  , will lead to different code repo dynamically",
      "state": "closed",
      "author": "CoderYiFei",
      "author_type": "User",
      "created_at": "2024-10-20T16:32:01Z",
      "updated_at": "2024-12-29T00:33:54Z",
      "closed_at": "2024-12-29T00:33:54Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1521/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1521",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1521",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:31.528434",
      "comments": [
        {
          "author": "geekan",
          "body": "In a real-life scenario, you will have a team and distribute requirements freely, activating each member dynamically. In 1.0 we will see this feature.",
          "created_at": "2024-10-21T03:30:47Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-04T00:33:18Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-29T00:33:53Z"
        }
      ]
    },
    {
      "issue_number": 1528,
      "title": "[very important] streaming video/audio information to llm ,  should be supported.",
      "body": "The metagpt 's system needs to have the capability to support streaming video/audio input. \r\nFor example, in a game, it should be able to stream the screen information to a large world model (LWM). The LWM would then need to control the keyboard and mouse to simulate the game's operation, identify issues during gameplay, modify the code, and then restart the game, repeating this process iteratively. \r\nThis function should be add to game design task's sop(team).... ",
      "state": "closed",
      "author": "CoderYiFei",
      "author_type": "User",
      "created_at": "2024-10-21T16:06:53Z",
      "updated_at": "2024-12-29T00:33:53Z",
      "closed_at": "2024-12-29T00:33:53Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1528/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1528",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1528",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:31.727528",
      "comments": [
        {
          "author": "geekan",
          "body": "This work is being done and will be open sourced later",
          "created_at": "2024-10-22T04:14:43Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-04T00:33:17Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-29T00:33:52Z"
        }
      ]
    },
    {
      "issue_number": 1598,
      "title": "å…³äºä½¿ç”¨è‡ªå®šä¹‰æœ¬åœ°LLM",
      "body": "è¯·é—®å¦‚ä½•è°ƒç”¨æœ¬åœ°çš„å¤§æ¨¡å‹æ¥è¿›è¡Œä½¿ç”¨å‘¢",
      "state": "closed",
      "author": "White-Friday",
      "author_type": "User",
      "created_at": "2024-11-13T10:49:01Z",
      "updated_at": "2024-12-29T00:33:50Z",
      "closed_at": "2024-12-29T00:33:49Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1598/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1598",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1598",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:31.894765",
      "comments": [
        {
          "author": "better629",
          "body": "refs to `https://docs.deepwisdom.ai/main/en/guide/tutorials/integration_with_open_llm.html`",
          "created_at": "2024-11-13T11:06:51Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-14T00:32:05Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-29T00:33:49Z"
        }
      ]
    },
    {
      "issue_number": 1597,
      "title": "metagpt.ext.aflow.scripts.optimizer:optimize:93 - Error occurred: object list can't be used in 'await' expression. Retrying... (Attempt 1/1)",
      "body": "**Bug description**\r\nmetagpt.ext.aflow.scripts.optimizer:optimize:93 - Error occurred: object list can't be used in 'await' expression. Retrying... (Attempt 1/1)\r\n\r\n**Bug solved method**\r\nnot solved\r\n\r\nAn error occurred when running AFLOW with this command:\r\n```\r\npython -m examples.aflow.optimize --dataset custom --max_rounds 1 --validation_rounds 3 --sample 2\r\n```\r\n\r\n**Environment information**\r\n- LLM type and model name:OpenAI grok-beta\r\n- System version:Windows 11\r\n- Python version:conda python 3.11.1\r\n- MetaGPT version or branch:2024.11 main\r\n\r\n\r\n- packages version:unknown\r\n- installation method: pip install -e .\r\n\r\n**Screenshots or logs**\r\n2024-11-13 17:12:16.364 | INFO     | metagpt.const:get_metagpt_package_root:21 - Package root set to B:\\software\\MetaGPT\r\n2024-11-13 17:12:20.381 | INFO     | metagpt.ext.aflow.scripts.optimizer:optimize:93 - Error occurred: object list can't be used in 'await' expression. Retrying... (Attempt 1/1)\r\n2024-11-13 17:12:20.382 | INFO     | metagpt.ext.aflow.scripts.optimizer:optimize:95 - Max retries reached. Moving to next round.\r\n2024-11-13 17:12:25.384 | INFO     | metagpt.ext.aflow.scripts.optimizer:optimize:106 - Score for round 2: None\r\n",
      "state": "closed",
      "author": "CALMCRAZY",
      "author_type": "User",
      "created_at": "2024-11-13T09:46:11Z",
      "updated_at": "2024-12-29T00:33:50Z",
      "closed_at": "2024-12-29T00:33:50Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1597/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1597",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1597",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:32.098719",
      "comments": [
        {
          "author": "didiforgithub",
          "body": "Hi, thanks for your usage.\r\n\r\nFor this question, maybe you need to first determine that the custom dataset is set in DatasetType.\r\n\r\nSubsequently, you can check your eval function to ensure that graph_evaluate returns the correct score, avg_cost, and total_cost. If the problem still cannot be resolv",
          "created_at": "2024-11-13T11:05:06Z"
        },
        {
          "author": "CALMCRAZY",
          "body": "> Hi, thanks for your usage.\r\n> \r\n> For this question, maybe you need to first determine that the custom dataset is set in DatasetType.\r\n> \r\n> Subsequently, you can check your eval function to ensure that graph_evaluate returns the correct score, avg_cost, and total_cost. If the problem still cannot",
          "created_at": "2024-11-13T13:32:18Z"
        },
        {
          "author": "didiforgithub",
          "body": "Sincerely thank you for your discovery, we will fix the BUG as soon as possible!",
          "created_at": "2024-11-13T13:38:33Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-14T00:32:06Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-29T00:33:50Z"
        }
      ]
    },
    {
      "issue_number": 1530,
      "title": "data-interpreter needs a dataset generation function",
      "body": "Sometimes , ds tasks need trained data from web page , or generated by llm.\r\ndata-interpreter should determine to get useful trained data from webpage,\r\nor generate useful data by it self.\r\n\r\nI mean it should be part of machine learning pipelines.\r\nIncluding:\r\n(1) has user provided labeled trained data?\r\n(2) if not , can llm get good labeled trained data from webpage?\r\n(3) it not , can llm generate  labeled trained data by it self?\r\n(4) to generate labeled trained data by llm it self ...\r\nthen llm get well-done labeled  trained data, and starting training\r\n\r\nFor example , I want to train a text translation model.\r\nThen , llm should determine , can it get English to Chinese text data from webpage,\r\nif it can not, than llm should generate some English to Chinese text data by it self,\r\nthen , start model training...",
      "state": "closed",
      "author": "CoderYiFei",
      "author_type": "User",
      "created_at": "2024-10-22T05:14:33Z",
      "updated_at": "2024-12-28T00:29:59Z",
      "closed_at": "2024-12-28T00:29:59Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1530/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1530",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1530",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:32.304085",
      "comments": [
        {
          "author": "geekan",
          "body": "Part of this issue corresponds to a research topic called dataset generation.\r\n- Your intuition is good, but it takes a lot of time to do it well, and it's also very difficult for humans.\r\n- Here are some obvious questions: How to ensure data quality? How to ensure the scientific nature of evaluatio",
          "created_at": "2024-10-22T05:41:58Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-04T00:33:15Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-28T00:29:58Z"
        }
      ]
    },
    {
      "issue_number": 1531,
      "title": "o1-mini æ¨¡å‹æŠ¥é”™",
      "body": "**Bug description**\r\n<!-- Clearly and directly describe the current bug -->\r\nå½“model: \"o1-mini\"çš„æ—¶å€™, ä¼šå‡ºç°bug,\r\n```\r\nFinished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 86.782(s), this was the 1st time calling it. exp: Error code: 400 - {'error': {'message': \"Unsupported value: 'messages[0].role' does not support 'system' with this model.     (request id: 20241022224433123206060zGFL5WKQ) (request id: 2024102222443296560188YMHkpVsa) (request id: 2024102222443292570479MKCUGfgl) (request id: 20241022224431807183774j4pHfuUY)\", 'type': 'invalid_request_error', 'param': 'messages[0].role', 'code': 'unsupported_value'}}\r\n```\r\n\r\n\r\n**Bug solved method**\r\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\r\n\r\n**Environment information**\r\n<!-- Environmentï¼šSystem version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\r\n\r\n- LLM type and model name: OpenAI  o1-mini\r\n- System version: win11\r\n- Python version: 3.10\r\n- MetaGPT version or branch:  main\r\n\r\n<!-- Dependent packagessï¼šthe packages version cause the bug(like `pydantic 1.10.8`), installation methodï¼ˆlike `pip install metagpt` or `pip install from source` or `run in docker`ï¼‰ -->\r\n\r\n- packages version: \r\n- installation method:  pip install \r\n\r\n**Screenshots or logs**\r\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\r\n![image](https://github.com/user-attachments/assets/7d6f335f-f330-4fcb-864b-b69977795765)\r\n",
      "state": "closed",
      "author": "MiangChen",
      "author_type": "User",
      "created_at": "2024-10-22T14:47:31Z",
      "updated_at": "2024-12-28T00:29:58Z",
      "closed_at": "2024-12-28T00:29:57Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1531/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1531",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1531",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:32.526281",
      "comments": [
        {
          "author": "better629",
          "body": "refs to `https://docs.deepwisdom.ai/main/en/guide/get_started/configuration/llm_api_configuration.html#steps`",
          "created_at": "2024-10-23T01:50:27Z"
        },
        {
          "author": "geekan",
          "body": "I feel it should be made into a default configuration that can be triggered by the model name.",
          "created_at": "2024-10-23T03:02:27Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-03T00:33:51Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-28T00:29:57Z"
        }
      ]
    },
    {
      "issue_number": 1591,
      "title": "Two questions about DI",
      "body": "\r\nHello, thank you for the excellent code and paper. Regarding DI, I have the following two questions: 1. Are the codes or logs generated after DI work placed in a certain folder like MetaGpt? 2. Is there any implementation code for the evaluation indicator CS mentioned in the paper?\r\nLooking Forward to your answer!",
      "state": "closed",
      "author": "kirainy",
      "author_type": "User",
      "created_at": "2024-11-11T08:07:50Z",
      "updated_at": "2024-12-28T00:29:56Z",
      "closed_at": "2024-12-28T00:29:56Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1591/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1591",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1591",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:32.713913",
      "comments": [
        {
          "author": "krish240574",
          "body": "1. Look at save_history(role = <the DI variable>)  - from metagpt.utils.recovery_util import save_history, also in examples/di/data_visualization.py\r\n2. Don't know, sorry. ",
          "created_at": "2024-11-11T15:31:16Z"
        },
        {
          "author": "kirainy",
          "body": "thanks for your replyï¼",
          "created_at": "2024-11-12T01:51:38Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-13T00:33:27Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-28T00:29:55Z"
        }
      ]
    },
    {
      "issue_number": 1585,
      "title": "ä½¿ç”¨web_browser_engine_selenium+chromeå‡ºç°å¤§é‡é¡µé¢æœªå…³é—­çš„æƒ…å†µ",
      "body": "# å¼‚å¸¸æè¿°\r\n<img width=\"938\" alt=\"a03496e9de82d63cc52544c27956596\" src=\"https://github.com/user-attachments/assets/9cab7747-7488-4cd5-b3c7-3bfe00e8a3f7\">\r\n\r\n# ç‰ˆæœ¬ä¿¡æ¯\r\nGoogle Chrome 119.0.6045.199 \r\nChromeDriver 119.0.6045.105 \r\nmetagpt 0.8",
      "state": "closed",
      "author": "QiMingChina",
      "author_type": "User",
      "created_at": "2024-11-08T09:38:51Z",
      "updated_at": "2024-12-27T00:30:23Z",
      "closed_at": "2024-12-27T00:30:22Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1585/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "shenchucheng"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1585",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1585",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:32.927206",
      "comments": [
        {
          "author": "shenchucheng",
          "body": "ç”±https://github.com/geekan/MetaGPT/issues/1584 å¯¼è‡´",
          "created_at": "2024-11-11T04:04:26Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-12T00:32:59Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-27T00:30:22Z"
        }
      ]
    },
    {
      "issue_number": 1584,
      "title": "ä½¿ç”¨web_brower_engine_seleniumå‡ºç°çš„The process started from chrome location /opt/google/chrome/chrome is no longer runningé—®é¢˜",
      "body": "## é—®é¢˜æè¿°\r\nä½¿ç”¨web_brower_engine_seleniumå·¥å…·è¿›è¡Œé¡µé¢æŠ“å–\r\n![image](https://github.com/user-attachments/assets/0d23dbc9-a6a7-4ab3-8d92-df18dcce8ae6)\r\n\r\n## ç‰ˆæœ¬ä¿¡æ¯\r\nChromeDriver 119.0.6045.105 (é…ç½®åœ¨/usr/bin/chromedriver)\r\nGoogle Chrome 119.0.6045.199\r\n",
      "state": "closed",
      "author": "QiMingChina",
      "author_type": "User",
      "created_at": "2024-11-08T09:30:35Z",
      "updated_at": "2024-12-27T00:30:23Z",
      "closed_at": "2024-12-27T00:30:23Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1584/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "shenchucheng"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1584",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1584",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:33.132006",
      "comments": [
        {
          "author": "shenchucheng",
          "body": "deepin æ¡Œé¢ç‰ˆï¼ŒChromeDriver 119.0.6045.105ï¼ŒGoogle Chrome 119.0.6045.199ï¼Œæ— æ³•å¤ç°è¿™ä¸ªé—®é¢˜ï¼Œ èƒ½æä¾›æ›´è¯¦ç»†çš„å¤ç°ä¿¡æ¯å—ï¼Œæ¯”å¦‚ä½¿ç”¨çš„Linuxç‰ˆæœ¬ï¼Œæœºå™¨çš„èµ„æºä¿¡æ¯ç­‰ã€‚æˆ–è€…å°è¯•ç”¨playwrightå‘¢ï¼Ÿ",
          "created_at": "2024-11-11T04:01:50Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-12T00:33:00Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-27T00:30:23Z"
        }
      ]
    },
    {
      "issue_number": 1532,
      "title": "Can metagpt show more comparison with AgileCoder",
      "body": "AgileCoder: \r\nhttps://github.com/FSoft-AI4Code/AgileCoder",
      "state": "closed",
      "author": "CoderYiFei",
      "author_type": "User",
      "created_at": "2024-10-23T02:34:58Z",
      "updated_at": "2024-12-26T00:30:18Z",
      "closed_at": "2024-12-26T00:30:18Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1532/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1532",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1532",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:35.022613",
      "comments": [
        {
          "author": "stellaHSR",
          "body": "Hi CoderYiFei,\r\n\r\nThank you for your suggestion regarding a comparison with AgileCoder. I believe Agile(https://en.wikipedia.org/wiki/Agile_software_development) is a great development methodology, particularly emphasizing feedback-based iteration and incremental improvement, which can significantly",
          "created_at": "2024-10-23T06:58:49Z"
        },
        {
          "author": "CoderYiFei",
          "body": "For comparing metrics,\r\nI recommend  https://github.com/ActivityWatch/activitywatch/tree/master \r\nwe can assign some general hard software project to a programmer,\r\nAnd let him use different multi-agent tools, to find the difference of time cost , and the times human engaged.\r\n\r\nI am hoping 1.0 's v",
          "created_at": "2024-10-23T13:55:01Z"
        },
        {
          "author": "stellaHSR",
          "body": "I think this is a great idea. \r\nRegarding the observation of time consumption across different tools, are you referring to metrics similar to Jira, such as task hours, meeting times, and usage proportions of related development tools? Tracking these tools and their usage duration can indeed reflect ",
          "created_at": "2024-10-24T04:19:14Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-03T00:33:50Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-26T00:30:17Z"
        }
      ]
    },
    {
      "issue_number": 1533,
      "title": "Is it possible to  make more RPA support, like Claude 3.5 sonnet's computer-use feature",
      "body": "Claude 3.5 sonnet's new feature, computer-use 's function looks pretty useful\r\nCan metagpt show a computer-use based project in its examples dir?\r\nsomehow, like video shown here\r\nhttps://www.youtube.com/watch?v=vH2f7cjXjKI\r\n\r\n",
      "state": "closed",
      "author": "CoderYiFei",
      "author_type": "User",
      "created_at": "2024-10-23T03:37:37Z",
      "updated_at": "2024-12-25T00:30:07Z",
      "closed_at": "2024-12-25T00:30:06Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1533/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1533",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1533",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:35.204692",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-03T00:33:49Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-25T00:30:06Z"
        }
      ]
    },
    {
      "issue_number": 1576,
      "title": "Prompt word switching between Chinese and English?",
      "body": "When writing code from the data_interpreter agent, it is very important to split the userrequirement into sub-tasks as follows:\r\n\r\n![image](https://github.com/user-attachments/assets/83e92911-6cc8-484f-9528-e8a0b1690492)\r\n\r\n\r\nBut now the output prompt words are in English, and read the source code, basically are English prompt words, please ask, for the need for Chinese scenes, how to deal with?\r\n\r\n![bda7f93612ed91991fff30b40ff5be4](https://github.com/user-attachments/assets/e6479742-29aa-42b4-aae1-b542c4ff81c2)\r\n\r\neg:\r\n![1730869541315](https://github.com/user-attachments/assets/4674e00d-b406-4465-bc6f-e21eb45e7d38)\r\n![image](https://github.com/user-attachments/assets/71122ef8-5f7a-4c80-9ba7-d11bcb2099ef)\r\n\r\n\r\nHow to solve it?\r\n\r\n",
      "state": "closed",
      "author": "RyanOvO",
      "author_type": "User",
      "created_at": "2024-11-06T03:03:22Z",
      "updated_at": "2024-12-24T00:30:31Z",
      "closed_at": "2024-12-24T00:30:30Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1576/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1576",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1576",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:35.441411",
      "comments": [
        {
          "author": "geekan",
          "body": "Hello, plz wait for our 1.0 version, we have fixed this issue.",
          "created_at": "2024-11-06T08:51:01Z"
        },
        {
          "author": "RyanOvO",
          "body": "> Hello, plz wait for our 1.0 version, we have fixed this issue.\r\n\r\nAs for prompt, I suggest that all modules should consider switching between English and Chinese for the prompt word, after all, there should be many such scenarios",
          "created_at": "2024-11-07T00:50:44Z"
        },
        {
          "author": "geekan",
          "body": "This idea has crossed my mind numerous times throughout history. But I still haven't done this because, like the game text, it's a bit cumbersome to maintain. I'm not sure whether this idea is effective in the end, and since subtle differences in prompt words can lead to huge differences in effects,",
          "created_at": "2024-11-07T07:12:51Z"
        },
        {
          "author": "RyanOvO",
          "body": "> This idea has crossed my mind numerous times throughout history. But I still haven't done this because, like the game text, it's a bit cumbersome to maintain. I'm not sure whether this idea is effective in the end, and since subtle differences in prompt words can lead to huge differences in effect",
          "created_at": "2024-11-08T02:19:22Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-09T00:34:33Z"
        }
      ]
    },
    {
      "issue_number": 1534,
      "title": "Can metagpt support AI based search enginee Tavily",
      "body": "Maybe add TAVILY_API_KEY in [config2.example.yaml](https://github.com/geekan/MetaGPT/blob/main/config/config2.example.yaml)\r\nand its calling in necessary places\r\n\r\nrefering:\r\nhttps://docs.tavily.com/docs/python-sdk/tavily-search/examples",
      "state": "closed",
      "author": "CoderYiFei",
      "author_type": "User",
      "created_at": "2024-10-23T06:39:11Z",
      "updated_at": "2024-12-22T00:33:45Z",
      "closed_at": "2024-12-22T00:33:44Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1534/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1534",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1534",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:35.643665",
      "comments": [
        {
          "author": "geekan",
          "body": "Looks good. If you are interested, you can raise a PR.",
          "created_at": "2024-10-23T12:03:18Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-03T00:33:48Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-22T00:33:44Z"
        }
      ]
    },
    {
      "issue_number": 1568,
      "title": "[bug] Can not download the dataset of SELA",
      "body": "Can not download the dataset of SELA. I guess it is the problem of the path file.\r\n\r\n### Operations\r\n```\r\ncd to *****/sela/data\r\npython dataset.py --save_analysis_pool\r\n```\r\n\r\n### Errors\r\n\r\n```\r\n(terminal) data % python dataset.py --save_analysis_pool \r\n2024-11-03 23:18:**** | INFO     | metagpt.const:get_metagpt_package_root:21 - Package root set to /MetaGPT\r\nTraceback (most recent call last):\r\n  File \"/MetaGPT/metagpt/ext/sela/data/dataset.py\", line 12, in <module>\r\n    from metagpt.ext.sela.insights.solution_designer import SolutionDesigner\r\n  File \"/MetaGPT/metagpt/ext/sela/insights/solution_designer.py\", line 3, in <module>\r\n    from metagpt.ext.sela.utils import clean_json_from_rsp, load_data_config\r\n  File \"/MetaGPT/metagpt/ext/sela/utils.py\", line 21, in <module>\r\n    DATASET_CONFIG = load_data_config(\"datasets.yaml\")\r\n  File \"/MetaGPT/metagpt/ext/sela/utils.py\", line 16, in load_data_config\r\n    with open(file_path, \"r\") as stream:\r\nFileNotFoundError: [Errno 2] No such file or directory: 'datasets.yaml'\r\n```\r\n\r\n### Envs:\r\n```\r\nmacOS 16\r\npython = 3.10\r\nmategpt: cloned from the main branch\r\n```\r\n\r\n\r\n**Can I submit a PR to fix it?**",
      "state": "closed",
      "author": "Appointat",
      "author_type": "User",
      "created_at": "2024-11-03T15:26:43Z",
      "updated_at": "2024-12-21T00:30:14Z",
      "closed_at": "2024-12-21T00:30:14Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1568/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1568",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1568",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:35.829914",
      "comments": [
        {
          "author": "garylin2099",
          "body": "Yes, please feel free to submit a PR if you find the cause! In the meantime, @cyzus can you take a look too?",
          "created_at": "2024-11-04T07:41:54Z"
        },
        {
          "author": "cyzus",
          "body": "Can you try \r\n```\r\npython data/dataset.py\r\n```\r\nstarting from the sela folder instead of the data folder.\r\n\r\nI will update this to the readme\r\n",
          "created_at": "2024-11-04T08:43:55Z"
        },
        {
          "author": "Appointat",
          "body": "Great. I will retry it.",
          "created_at": "2024-11-05T05:49:48Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-06T00:33:08Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-21T00:30:13Z"
        }
      ]
    },
    {
      "issue_number": 1536,
      "title": "[Very important] metagpt need to send some question and related choices to human, to get feedback from human",
      "body": "It needs to do:\r\n1. During its developing\r\n(1) Is this part a key point during total developing circle? If so, (or human decide to) ,  trigger (2)...\r\n(2) What kind of question and choices should be sent to human?\r\n(3) Then send question and choices to human and receive feedback\r\n(4) How to change its following work, after receiving human choices.\r\n\r\n2. At the begging of work\r\nAnd at the begging of incremental work(or normal work),\r\nIt also needs to show its understanding of current user's code repo and user's requirement.....and to let human to answer\r\n\"correct understanding\" or \"incorrect understanding\"\r\nadditionally,\r\nsending key question and choices it designed , to clarify its understanding.\r\n\r\nProduct rules:\r\nTo choose \"A B C D\", or to answer \"correct or incorrect\" , is easy for human.\r\nTo write complex words and code, is hard for human.\r\n",
      "state": "closed",
      "author": "CoderYiFei",
      "author_type": "User",
      "created_at": "2024-10-23T10:44:43Z",
      "updated_at": "2024-12-20T00:30:36Z",
      "closed_at": "2024-12-20T00:30:36Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1536/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1536",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1536",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:36.044351",
      "comments": [
        {
          "author": "geekan",
          "body": "Yes. These are available in our 1.0 version. However, this problem is actually not as simple as we think. For example, \"Buy me an apple\" is simple for humans, but it is very complex for machines.\r\n\r\nBecause we donâ€™t know whether we are looking for mobile phones or fruits, we donâ€™t know the required ",
          "created_at": "2024-10-23T12:13:34Z"
        },
        {
          "author": "CoderYiFei",
          "body": "> Yes. These are available in our 1.0 version. However, this problem is actually not as simple as we think. For example, \"Buy me an apple\" is simple for humans, but it is very complex for machines.\r\n> \r\n> Because we donâ€™t know whether we are looking for mobile phones or fruits, we donâ€™t know the req",
          "created_at": "2024-10-23T13:13:16Z"
        },
        {
          "author": "LimFang",
          "body": "> It needs to do:\r\n> \r\n> 1. During its developing\r\n>    (1) Is this part a key point during total developing circle? If so, (or human decide to) ,  trigger (2)...\r\n>    (2) What kind of question and choices should be sent to human?\r\n>    (3) Then send question and choices to human and receive feedba",
          "created_at": "2024-10-24T06:20:41Z"
        },
        {
          "author": "CoderYiFei",
          "body": "You mean metagpt's agent message subscription mechanism not good enough,\r\nor you mean general mechanism and theory,  not good enough in all alternatives projects",
          "created_at": "2024-10-24T06:42:14Z"
        },
        {
          "author": "LimFang",
          "body": "Message subscription in metagpt is more likely a centralized pool pattern. Every agent pulls and pushes its designed or desired information. That is not good enough for timely interaction between machines and humans.",
          "created_at": "2024-10-24T07:01:24Z"
        }
      ]
    },
    {
      "issue_number": 1550,
      "title": "A verifier is needed ...... after AFlow Sela and FACT",
      "body": "AFlow is used for workflow construction;\r\nSela handles the tasks related to AutoML; \r\nFACT is responsible for multi-fact incremental retrieval. \r\n\r\nIt seems that a verifier, \r\nthat all of its indicators tops arxiv metrics just like AFlow Sela and FACT, is needed,\r\n\r\nto verify whether the result of execution of code ,\r\nmeets the user's requirement documentation.\r\n\r\nThen Programer will only need to ask questions....\r\nFACT will help to search useful information,  \r\nAFlow generate good workflow , based on PRD and FACT's searching,\r\nSela generate useful ml agents code , based on workflow, PRD and FACT's searching.\r\nFinally \"verifier\" will run code and will review result , and will update PRD , to start next loop.\r\n",
      "state": "closed",
      "author": "CoderYiFei",
      "author_type": "User",
      "created_at": "2024-10-29T14:46:06Z",
      "updated_at": "2024-12-19T00:32:21Z",
      "closed_at": "2024-12-19T00:32:20Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1550/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1550",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1550",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:36.289875",
      "comments": [
        {
          "author": "geekan",
          "body": "You have good intuition. I'm curious what your background is?",
          "created_at": "2024-10-30T02:16:50Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has no activity in the past 30 days. Please comment on the issue if you have anything to add.",
          "created_at": "2024-12-03T00:33:46Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue was closed due to 45 days of inactivity. If you feel this issue is still relevant, please reopen the issue to continue the discussion.",
          "created_at": "2024-12-19T00:32:19Z"
        }
      ]
    },
    {
      "issue_number": 1551,
      "title": "About testing and generated documents",
      "body": "1. Why are there no contents in tests and test_outputs in the generated code directory? How do you generate relevant documents and code? (ç”Ÿæˆçš„ä»£ç ç›®å½•ä¸‹ï¼Œä¸ºä»€ä¹ˆtestså’Œtest_outputsé‡Œé¢æ²¡æœ‰å†…å®¹ï¼Ÿå¦‚æœæƒ³è¦ç”Ÿæˆç›¸å…³æ–‡æ¡£ï¼Œè¯¥å¦‚ä½•æ“ä½œå‘¢ï¼Ÿ)\r\n\r\n2. The generated documents, such as those in the PRD directory, are in MD format. Is it possible to create documents in Word format? (å·²ç”Ÿæˆçš„æ–‡æ¡£ï¼Œå¦‚prdç›®å½•ä¸‹çš„æ–‡æ¡£ï¼Œæ˜¯mdæ ¼å¼çš„ã€‚è¯·é—®æ˜¯å¦å¯ä»¥ç”Ÿæˆwordæ ¼å¼çš„æ–‡æ¡£ã€‚)",
      "state": "closed",
      "author": "lily-toru",
      "author_type": "User",
      "created_at": "2024-10-30T02:28:59Z",
      "updated_at": "2024-12-18T00:32:17Z",
      "closed_at": "2024-12-18T00:32:16Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1551/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "iorisa"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1551",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1551",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:36.512198",
      "comments": [
        {
          "author": "geekan",
          "body": "Thank you for your question. Just ask in **English** is ok.",
          "created_at": "2024-10-30T02:33:24Z"
        },
        {
          "author": "iorisa",
          "body": "1. When executing the `metagpt` command, add the `--run-tests` parameter, and also set a larger number for the `--n-round` parameter, such as 99, to enter the unit testing phase. [See more...](https://docs.deepwisdom.ai/main/en/guide/get_started/quickstart.html#usage )\r\n\r\n2. Markdown documents are r",
          "created_at": "2024-10-30T07:17:18Z"
        },
        {
          "author": "lily-toru",
          "body": "1. It is directly added after the metagpt command, just like this [metagpt \"Write a xxx function\" -- run tests]?\r\nHowever, after running, there's still no content in the \"tests\" and \"test_outputs\" folders.\r\nCan you provide an example of a command that includes setting the --n-round parameter?",
          "created_at": "2024-10-30T08:32:17Z"
        },
        {
          "author": "geekan",
          "body": "I feel it would be more efficient to discuss this issue in version 1.0. The current design will actually be obsolete in version 1.0.",
          "created_at": "2024-10-30T17:10:29Z"
        },
        {
          "author": "lily-toru",
          "body": "> I feel it would be more efficient to discuss this issue in version 1.0. The current design will actually be obsolete in version 1.0.\r\n\r\nThat is to say, in the current version, there will no further updates regarding the test section.\r\nMay I ask will the version 1.0 be released soon?",
          "created_at": "2024-10-31T01:14:42Z"
        }
      ]
    },
    {
      "issue_number": 1553,
      "title": "ValueError: Creator not registered for key: LLMType.OLLAMA",
      "body": "**Bug description**\r\n<!-- Clearly and directly describe the current bug -->\r\nI using ***MetaGPT ver 0.8.1*** but when use RAG with method **SimpleEngine.from_docs** have error ***ValueError: Creator not registered for key: LLMType.OLLAMA***\r\n\r\n<!--  **Bug solved method**  -->\r\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\r\n\r\n**Environment information**\r\n<!-- Environmentï¼šSystem version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\r\n\r\n- LLM type and model name: ollama and model: hf.co/hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF\r\n- System version:\r\n- Python version: 3.10\r\n- MetaGPT version or branch: 0.8.1\r\n\r\n<!-- Dependent packagessï¼šthe packages version cause the bug(like `pydantic 1.10.8`), installation methodï¼ˆlike `pip install metagpt` or `pip install from source` or `run in docker`ï¼‰ -->\r\n\r\n- packages version:\r\n- installation method: \r\n\r\n**Screenshots or logs**\r\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\r\n***config2.yaml***\r\nembedding:\r\n  api_type: \"ollama\"\r\n  model: \"hf.co/hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF\"\r\n  base_url: \"http://127.0.0.1:11434/api\"\r\n\r\nllm:\r\n  api_type: \"ollama\"\r\n  model: \"hf.co/hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF\"\r\n  base_url: \"http://127.0.0.1:11434/api\"\r\n\r\n***Error Response***\r\n[/usr/local/lib/python3.10/dist-packages/metagpt/rag/factories/base.py](https://localhost:8080/#) in get_instance(self, key, **kwargs)\r\n     27             return creator(**kwargs)\r\n     28 \r\n---> 29         raise ValueError(f\"Creator not registered for key: {key}\")\r\n     30 \r\n     31 \r\n\r\nValueError: Creator not registered for key: LLMType.OLLAMA\r\n",
      "state": "closed",
      "author": "vanhocpham",
      "author_type": "User",
      "created_at": "2024-10-30T07:10:51Z",
      "updated_at": "2024-12-18T00:32:15Z",
      "closed_at": "2024-12-18T00:32:14Z",
      "labels": [
        "inactive"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1553/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "better629"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1553",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1553",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:36.695713",
      "comments": [
        {
          "author": "better629",
          "body": "@vanhocpham try the main branch, it supports ollama in `https://github.com/geekan/MetaGPT/blob/main/metagpt/rag/factories/embedding.py#L26`",
          "created_at": "2024-10-30T07:17:01Z"
        },
        {
          "author": "vanhocpham",
          "body": "@better629 i using pip install is working?",
          "created_at": "2024-10-30T07:18:29Z"
        },
        {
          "author": "better629",
          "body": "@vanhocpham refs to `https://docs.deepwisdom.ai/main/en/guide/get_started/installation.html#install-in-development-mode`\r\n```\r\ncd MetaGPT\r\npip3 install -e .\r\n```",
          "created_at": "2024-10-30T07:25:18Z"
        },
        {
          "author": "vanhocpham",
          "body": "@better629 Thanks, I will try and get back to you",
          "created_at": "2024-10-30T07:28:32Z"
        },
        {
          "author": "vanhocpham",
          "body": "@better629 I tried the way you instructed but another error occurred \r\n\r\n```\r\n/usr/local/lib/python3.10/dist-packages/metagpt/rag/engines/simple.py in from_docs(cls, input_dir, input_files, transformations, embed_model, llm, retriever_configs, ranker_configs)\r\n    116         nodes = run_transformat",
          "created_at": "2024-10-30T09:17:06Z"
        }
      ]
    },
    {
      "issue_number": 1251,
      "title": "MetaGPT+Zhipu glm-4 generated the cli_blackjack game can not run",
      "body": "**Bug description**\r\n<!-- Clearly and directly describe the current bug -->\r\n\r\nlooks like the generated code has dependency issues among the classes.\r\n\r\n% python main.py\r\nDo you want to play a game of Blackjack? [Y/n] Y\r\nTraceback (most recent call last):\r\n  File \"/Users/xuxiaotian/project/metaGPT/MetaGPT/workspace/cli_blackjack/cli_blackjack/main.py\", line 98, in <module>\r\n    main()\r\n  File \"/Users/xuxiaotian/project/metaGPT/MetaGPT/workspace/cli_blackjack/cli_blackjack/main.py\", line 94, in main\r\n    game.play()\r\n  File \"/Users/xuxiaotian/project/metaGPT/MetaGPT/workspace/cli_blackjack/cli_blackjack/main.py\", line 19, in play\r\n    if not self.player.bet(10):  # Default bet amount is 10\r\n  File \"/Users/xuxiaotian/project/metaGPT/MetaGPT/workspace/cli_blackjack/cli_blackjack/player.py\", line 26, in bet\r\n    self.hands.append(Hand())  # Add a new hand for the player\r\nNameError: name 'Hand' is not defined\r\n\r\n**Bug solved method**\r\n<!-- If you solved the bug, describe the idea or process to solve the current bug. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\r\n\r\n**Environment information**\r\n<!-- Environmentï¼šSystem version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\r\n\r\n- LLM type and model name: zhipu, glm-4\r\n- System version: MacOS 14.4.1,\r\n- Python version: 3.9\r\n- MetaGPT version or branch: dev version\r\n\r\n<!-- Dependent packagessï¼šthe packages version cause the bug(like `pydantic 1.10.8`), installation methodï¼ˆlike `pip install metagpt` or `pip install from source` or `run in docker`ï¼‰ -->\r\n\r\n- packages version:\r\n- installation method:  pip install from source\r\n\r\n**Screenshots or logs**\r\n<!-- Screenshots or logs of the bug can help us understand the problem more quickly -->\r\n",
      "state": "closed",
      "author": "xiaotiancd",
      "author_type": "User",
      "created_at": "2024-05-08T05:47:00Z",
      "updated_at": "2024-10-20T07:04:19Z",
      "closed_at": "2024-10-20T07:04:19Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1251/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1251",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1251",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:38.763606",
      "comments": [
        {
          "author": "LyndonZhao",
          "body": "I met the same problem, it seems that zhipu glm-4 is bad at code generation.",
          "created_at": "2024-06-15T15:15:36Z"
        },
        {
          "author": "better629",
          "body": "Due to the lack of updates or replies by the user for a long time, we will close it. Please reopen it if necessary.",
          "created_at": "2024-10-10T02:09:08Z"
        },
        {
          "author": "geekan",
          "body": "This issue has been closed because it took too long.",
          "created_at": "2024-10-20T07:04:19Z"
        }
      ]
    },
    {
      "issue_number": 1168,
      "title": "metagpt \"Create a 2048 game\" report error \"Another program is using this file and the process cannot access it\"",
      "body": "**Bug description**\r\n2024-04-09 16:41:38.825 | WARNING  | metagpt.utils.git_repository:rename_root:214 - Move C:\\Users\\longw\\projectspace\\MetaGPT\\workspace\\20240409164058 to C:\\Users\\longw\\projectspace\\MetaGPT\\workspace\\game_2048 error: [WinError 32] Another program is using this file and the process cannot access it. : 'C:\\\\Users\\\\longw\\\\projectspace\\\\MetaGPT\\\\workspace\\\\20240409164058'\r\n\r\n\r\n**Environment information**\r\n<!-- Environmentï¼šSystem version (like ubuntu 22.04), Python version (conda python 3.7), LLM type and model (OpenAI gpt-4-1106-preview) -->\r\n\r\n- LLM type and model name: gpt-4-turbo-preview\r\n- System version:Window11\r\n- Python version:3.10.11\r\n- MetaGPT version or branch: main\r\n\r\n<!-- Dependent packagessï¼šthe packages version cause the bug(like `pydantic 1.10.8`), installation methodï¼ˆlike `pip install metagpt` or `pip install from source` or `run in docker`ï¼‰ -->\r\n\r\n![å¾®ä¿¡å›¾ç‰‡_20240409170335](https://github.com/geekan/MetaGPT/assets/166496192/7ef173bd-d832-47a5-83a3-4af6c24a47ce)\r\n\r\n",
      "state": "closed",
      "author": "longweiii",
      "author_type": "User",
      "created_at": "2024-04-09T09:05:38Z",
      "updated_at": "2024-10-20T07:03:03Z",
      "closed_at": "2024-10-20T07:03:02Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1168/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1168",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1168",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:38.932544",
      "comments": [
        {
          "author": "seehi",
          "body": "Does it affect the result? According to the log, the rename action was finally success. Check the [code](https://github.com/geekan/MetaGPT/blob/main/metagpt/utils/git_repository.py#L219) for details.",
          "created_at": "2024-04-09T12:49:35Z"
        },
        {
          "author": "longweiii",
          "body": "it seems the doc folder contains .json file, not .doc or .pdf file, is it correct?\r\n![å¾®ä¿¡å›¾ç‰‡_20240410092032](https://github.com/geekan/MetaGPT/assets/166496192/c5e2faa4-7cbf-4cc1-bae3-2f5d0eb5dae4)\r\n",
          "created_at": "2024-04-10T01:22:47Z"
        },
        {
          "author": "longweiii",
          "body": "And I got this issue when I install python websockets:\r\n![å¾®ä¿¡å›¾ç‰‡_20240410093259](https://github.com/geekan/MetaGPT/assets/166496192/d406e5bd-4549-4772-85c5-685ee216e960)\r\n",
          "created_at": "2024-04-10T01:34:04Z"
        },
        {
          "author": "longweiii",
          "body": "Should I use main branch or v0.8-release branch to buildï¼Ÿ",
          "created_at": "2024-04-10T01:40:24Z"
        },
        {
          "author": "longweiii",
          "body": "I use below command for 3 timesï¼š\r\nmetagpt \"Create a 2048 game\"\r\n\r\nBut the generated code have bugs each time.\r\nHow could I make metagpt generate correct code?",
          "created_at": "2024-04-10T04:07:36Z"
        }
      ]
    },
    {
      "issue_number": 1187,
      "title": "DataInterpreter - Could the saving of tabular data(dynamically generated) and plots be improved?",
      "body": "**Feature description**\r\n<!-- Clear and direct description of the functionality of the currently submitted or proposed feature -->\r\nProposed feature: \r\nThe true value of DataInterpreter will be exploited when all data analysis is presented as a report. \r\nA lot of tabular data gets generated, during the course of plan execution. There is a lot of slice and dice of data happening, plots generated, etc, during a full run of the DI. \r\nI manage to get history using save_history(), but the intermediate tabular results and plots generated are not clearly saved in the plan.json or code.ipynb. \r\n\r\nCould every intermediate table be saved clearly and links to plots generated be saved in the plan.json, for future use? For tables, just add it as part of the plan.json inside each \"results\" node and for the plots - have an option to say \"save_plots_dir\" - the path where the plots would get saved, and all plots would get dumped inside that path - then these paths are saved in plan.json, in the correct sequence. \r\n\r\n**Your Feature**\r\n<!-- Describe the idea or process of implementing the current feature. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- When submitting features, you need to complete the corresponding doc/tests/examples to facilitate verification by reviewers. -->\r\n",
      "state": "closed",
      "author": "krish240574",
      "author_type": "User",
      "created_at": "2024-04-12T05:53:54Z",
      "updated_at": "2024-10-11T15:20:44Z",
      "closed_at": "2024-10-11T15:20:44Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1187/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1187",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1187",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:39.145629",
      "comments": [
        {
          "author": "seehi",
          "body": "FYI: @garylin2099 ",
          "created_at": "2024-04-12T07:13:45Z"
        },
        {
          "author": "garylin2099",
          "body": "Hi, the plots can be viewed inside the code.ipynb. If you want the plots to be saved as images in other directory, you can specify it in the requirement prompt, just add \"please save the plots under xxx/xxx/\". Data Interpreter should be able to write code to realize the saving. Let me know if this w",
          "created_at": "2024-10-11T13:09:14Z"
        },
        {
          "author": "krish240574",
          "body": "Yes, it works, I shall use that - thank you. ",
          "created_at": "2024-10-11T15:20:44Z"
        }
      ]
    },
    {
      "issue_number": 1185,
      "title": "metagpt generate too many inconsistent invocation code between different source files",
      "body": "metagpt always generate inconsistent code between different source files. \r\nFor example,\r\nin source file A, it contains a method a(p1,p2),this method have 2 parameters, but in source file B, it will generate invocation code for the method a(p1) which only contains 1 parameters of that method, and sometime in source file A, it will generate invocation code for a non-exist method in other source file, and there are too many such cases in project for me to fix them,\r\nis there any good way to avoid such inconsistent codesï¼Ÿ",
      "state": "closed",
      "author": "longweiii",
      "author_type": "User",
      "created_at": "2024-04-12T01:55:20Z",
      "updated_at": "2024-10-11T13:10:25Z",
      "closed_at": "2024-10-11T13:10:25Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1185/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1185",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1185",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:39.365723",
      "comments": [
        {
          "author": "longweiii",
          "body": "And sometimes the generated source code will call a non-exist attribute of a object, these inconsistent codes make project unable to run.",
          "created_at": "2024-04-12T02:01:02Z"
        },
        {
          "author": "seehi",
          "body": "What's your LLM model, prefer `gpt-4-turbo`",
          "created_at": "2024-04-12T02:29:10Z"
        },
        {
          "author": "longweiii",
          "body": "> What's your LLM model, prefer `gpt-4-turbo`\r\nI use this LLM model\r\n![å¾®ä¿¡å›¾ç‰‡_20240412104847](https://github.com/geekan/MetaGPT/assets/166496192/3185e372-dd4e-4acb-97d3-fd416d9a0f37)\r\n",
          "created_at": "2024-04-12T02:50:38Z"
        },
        {
          "author": "longweiii",
          "body": "is gpt-4-turbo-preview different from gpt-4-turbo?",
          "created_at": "2024-04-12T02:51:28Z"
        },
        {
          "author": "seehi",
          "body": "[gpt-4-turbo](https://platform.openai.com/docs/models/continuous-model-upgrades) is the latest model. \r\nYou can check [these cases](https://www.deepwisdom.ai/usecases), they are all generated by `metagpt`, sometimes it's neccessary to adjust the code.",
          "created_at": "2024-04-12T03:07:31Z"
        }
      ]
    },
    {
      "issue_number": 915,
      "title": "å¿½ç•¥ç”¨æˆ·éœ€æ±‚ï¼Œè½¬è€Œäº§å‡ºgame.py",
      "body": "**Bug description**\r\næå‡ºä¸€ä¸ªä¸­ç­‰å¤æ‚çš„éœ€æ±‚ï¼Œæ— æ³•äº§å‡ºå¯¹åº”éœ€æ±‚ï¼Œmetagptä¸­é—´å‡ºç°é”™è¯¯ï¼ˆwarningæˆ–è€…errorï¼‰åä¼šè½¬å‘è¾“å‡ºgame.py,main.pyã€‚\r\n\r\n**Bug solved method**\r\n<!-- If not, provide more auxiliary information to facilitate our further positioning and investigation  -->\r\næˆ‘ä¸ªäººè®¤ä¸ºå¯èƒ½æ¯”è¾ƒæœ‰ç”¨çš„ä¿¡æ¯ï¼š\r\n- C:\\project\\MetaGPT\\workspace\\video_search\\resources\\data_api_design\\20240221092626        \r\nä¿¡æ¯: ç”¨æä¾›çš„æ¨¡å¼æ— æ³•æ‰¾åˆ°æ–‡ä»¶ã€‚\r\n- 2024-02-21 09:26:26.482 | WARNING  | metagpt.utils.git_repository:rename_root:214 - Move C:\\project\\MetaGPT\\workspace\\20240221092607 to C:\\project\\MetaGPT\\workspace\\video_search error: [WinError 32] å¦\r\nä¸€ä¸ªç¨‹åºæ­£åœ¨ä½¿ç”¨æ­¤æ–‡ä»¶ï¼Œè¿›ç¨‹æ— æ³•è®¿é—®ã€‚: 'C:\\\\project\\\\MetaGPT\\\\workspace\\\\20240221092607'ï¼ˆè¿™ä¸ªé—®é¢˜æˆ‘ç”¨ç®¡ç†è€…æ¨¡å¼å¯åŠ¨pycharmæˆ–è€…åˆ é™¤ç”Ÿæˆçš„é¡¹ç›®æ–‡ä»¶å¤¹ä¹Ÿä¸èƒ½é¿å…ï¼Œä¸è¿‡ä¸æ˜¯æ¯æ¬¡éƒ½ä¼šå‡ºç°ï¼Œåœ¨æˆ‘åˆæ¬¡è°ƒç”¨æ˜¯æˆåŠŸè¿‡ä¸€æ¬¡ï¼Œåé¢å°±å†ä¹Ÿæ²¡æˆåŠŸè¿‡äº†ï¼‰\r\n\r\n**Environment information**\r\n- LLM type and model name:gemini\r\n- System version:win10+metagpt 0.7\r\n- Python version:3.11.8\r\n\r\n<!-- Dependent packagessï¼šthe packages version cause the bug(like `pydantic 1.10.8`), installation methodï¼ˆlike `pip install metagpt` or `pip install from source` or `run in docker`ï¼‰ -->\r\n\r\n- packages version:æŒ‰ç…§requirementså®‰è£…\r\n- installation method:git clone,ç„¶åä»¥å¼€å‘è€…æ¨¡å¼install \r\n\r\n**Screenshots or logs**\r\n(MetaGPT_ENV) PS C:\\project\\MetaGPT> metagpt \"Please help me complete a project, which is divided into front-end and back-end. The front-end uses the Vue framework, and the back-end uses java+springboo\r\nt+springmvc+mybatis plus+mysql. Please carefully analyze the requirements and implement each function. The project requirements are as followsï¼š{'Video Search ': {'Background Management End': {'Persona\r\nl Center ': {'Login': {'Method ':' User Name+Password Login '},' Password Management ': {'Function ': ['Forgot Password ',' Send Verification Code to Modify via Email ',' Change Password '},' Logout ':\r\n {}},' Permission Management System ': {'General Permission Management System': {}}, 'Attendance Ma nagement': {'Attendance Personnel Management ': {'Function': 'Add, Delete, Change'}, 'Attendance Reco\r\nrds': {},' Attendance Machine Management ': {'Function': ['On ',' Off ']}, 'Personnel Search': {'Onl ine Personnel Monitoring ': {'Function': ['Single person monitoring ',' Multi person monitoring ',' \r\nView historical images']}, 'Offline Search': {'Function ':' Access videos and personnel images, batch  search for the location of personnel in the video '},' Priority Implementation ': 2},' Congestion \r\nMonitoring ': {'Online Video': {'Function ': ['Monitor traffic lights',' Monitor intersection vehicle  conditions']}, 'Notification': {'Method ': ['Email', 'Topic', 'SMS',' Notification Strategy ']}, '\r\nCall algorithm platform interface': {}}, 'Big screen, cockpit': {}, 'Data access': {' Bottom layer data  access': {'Collected by': 'edge computing', 'Data': {'Video data': {'Type': 'Real time data'}, '\r\nOther data': {}}}, 'Big data': {}}}\"\r\n2024-02-21 09:26:00.055 | INFO     | metagpt.const:get_metagpt_package_root:29 - Package root set to c:\\project\\metagpt\r\n2024-02-21 09:26:07.075 | INFO     | metagpt.team:invest:90 - Investment: $3.0.\r\n2024-02-21 09:26:07.084 | INFO     | metagpt.roles.role:_act:399 - Alice(Product Manager): to do PrepareDocuments(PrepareDocuments)\r\n2024-02-21 09:26:07.512 | INFO     | metagpt.utils.file_repository:save:60 - save to: C:\\project\\MetaGPT\\workspace\\20240221092607\\docs\\requirement.txt\r\n2024-02-21 09:26:07.520 | INFO     | metagpt.roles.role:_act:399 - Alice(Product Manager): to do WritePRD(WritePRD)\r\n2024-02-21 09:26:07.527 | INFO     | metagpt.actions.write_prd:run:86 - New requirement detected: Please help me complete a project, which is divided into front-end and back-end. The front-end uses the\r\n Vue framework, and the back-end uses java+springboot+springmvc+mybatis plus+mysql. Please carefully analyze the requirements and implement each function. The project requirements are as followsï¼š{'Vid\r\neo Search ': {'Background Management End': {'Personal Center ': {'Login': {'Method ':' User Name+Password Login '},' Password Management ': {'Function ': ['Forgot Password ',' Send Verification Code to\r\n Modify via Email ',' Change Password '},' Logout ': {}},' Permission Management System ': {'General Permission Management System': {}}, 'Attendance Ma nagement': {'Attendance Personnel Management ': {\r\n'Function': 'Add, Delete, Change'}, 'Attendance Records': {},' Attendance Machine Management ': {'Function': ['On ',' Off ']}, 'Personnel Search': {'Onl ine Personnel Monitoring ': {'Function': ['Singl\r\ne person monitoring ',' Multi person monitoring ',' View historical images']}, 'Offline Search': {'Function ':' Access videos and personnel images, batch  search for the location of personnel in the vi\r\ndeo '},' Priority Implementation ': 2},' Congestion Monitoring ': {'Online Video': {'Function ': ['Monitor traffic lights',' Monitor intersection vehicle  conditions']}, 'Notification': {'Method ': ['E\r\nmail', 'Topic', 'SMS',' Notification Strategy ']}, 'Call algorithm platform interface': {}}, 'Big screen, cockpit': {}, 'Data access': {' Bottom layer data  access': {'Collected by': 'edge computing', \r\n'Data': {'Video data': {'Type': 'Real time data'}, 'Other data': {}}}, 'Big data': {}}}\r\n[CONTENT]\r\n{\r\n    \"Language\": \"en_us\",\r\n    \"Programming Language\": \"Java\",\r\n    \"Original Requirements\": \"Please help me complete a project, which is divided into front-end and back-end. The front-end uses the Vue framework, and the back-end uses java+springboot+springmvc+myba\r\ntis plus+mysql. Please carefully analyze the requirements and implement each function. The project requirements are as followsï¼š{'Video Search ': {'Background Management End': {'Personal Center ': {'Lo\r\ngin': {'Method ':' User Name+Password Login '},' Password Management ': {'Function ': ['Forgot Password ',' Send Verification Code to Modify via Email ',' Change Password '},' Logout ': {}},' Permissio\r\nn Management System ': {'General Permission Management System': {}}, 'Attendance Ma nagement': {'Attendance Personnel Management ': {'Function': 'Add, Delete, Change'}, 'Attendance Records': {},' Atten\r\ndance Machine Management ': {'Function': ['On ',' Off ']}, 'Personnel Search': {'Onl ine Personnel Monitoring ': {'Function': ['Single person monitoring ',' Multi person monitoring ',' View historical \r\nimages']}, 'Offline Search': {'Function ':' Access videos and personnel images, batch  search for the location of personnel in the video '},' Priority Implementation ': 2},' Congestion Monitoring ': {'\r\nOnline Video': {'Function ': ['Monitor traffic lights',' Monitor intersection vehicle  conditions']}, 'Notification': {'Method ': ['Email', 'Topic', 'SMS',' Notification Strategy ']}, 'Call algorithm p\r\nlatform interface': {}}, 'Big screen, cockpit': {}, 'Data access': {' Bottom layer data  access': {'Collected by': 'edge computing', 'Data': {'Video data': {'Type': 'Real time data'}, 'Other data': {}}\r\n}, 'Big data': {}}}\",\r\n    \"Project Name\": \"video_search\",\r\n    \"Product Goals\": [\r\n        \"Provide a comprehensive video search solution\",\r\n        \"Enhance security and access control\",\r\n        \"Improve operational efficiency\"\r\n    ],\r\n    \"User Stories\": [\r\n        \"As a user, I want to be able to search for videos by multiple criteria\",\r\n        \"As a user, I want to be able to manage my personal information and permissions\",\r\n        \"As a user, I want to be able to monitor personnel and traffic conditions in real-time\",\r\n        \"As a user, I want to be able to receive notifications when there are important events\",\r\n        \"As a user, I want to be able to access data from multiple sources\"\r\n    ],\r\n    \"Competitive Analysis\": [\r\n        \"Product A: Provides basic video search functionality, but lacks advanced features\",\r\n        \"Product B: Offers more advanced features, but is more expensive and complex to use\",\r\n        \"Product C: Focuses on security and access control, but has limited video search capabilities\"\r\n    ],\r\n    \"Competitive Quadrant Chart\": \"quadrantChart\\n    title \\\"Reach and engagement of campaigns\\\"\\n    x-axis \\\"Low Reach\\\" --> \\\"High Reach\\\"\\n    y-axis \\\"Low Engagement\\\" --> \\\"High Engagement\\\"\\n  \r\n  quadrant-1 \\\"We should expand\\\"\\n    quadrant-2 \\\"Need to promote\\\"\\n    quadrant-3 \\\"Re-evaluate\\\"\\n    quadrant-4 \\\"May be improved\\\"\\n    \\\"Campaign A\\\": [0.3, 0.6]\\n    \\\"Campaign B\\\": [0.45, 0.2\r\n3]\\n    \\\"Campaign C\\\": [0.57, 0.69]\\n    \\\"Campaign D\\\": [0.78, 0.34]\\n    \\\"Campaign E\\\": [0.40, 0.34]\\n    \\\"Campaign F\\\": [0.35, 0.78]\\n    \\\"Our Target Product\\\": [0.5, 0.6]\",\r\n    \"Requirement Analysis\": \"The project requirements are comprehensive and cover a wide range of functionality. The system should be able to search for videos by multiple criteria, manage user permiss\r\nions, monitor personnel and traffic conditions in real-time, send notifications, and access data from multiple sources. The system should also be secure and easy to use.\",\r\n    \"Requirement Pool\": [\r\n        [\r\n            \"P0\",\r\n            \"Implement basic video search functionality\"\r\n        ],\r\n        [\r\n            \"P1\",\r\n            \"Implement advanced video search features\"\r\n        ],\r\n        [\r\n            \"P2\",\r\n            \"Implement user management and permission control\"\r\n        ],\r\n        [\r\n            \"P3\",\r\n            \"Implement real-time monitoring of personnel and traffic conditions\"\r\n        ],\r\n        [\r\n            \"P4\",\r\n            \"Implement notification system\"\r\n        ],\r\n        [\r\n            \"P5\",\r\n            \"Implement data access from multiple sources\"\r\n        ]\r\n    ],\r\n    \"UI Design draft\": \"The UI should be clean and easy to use. The main features should be easily accessible from the home page. The search bar should be prominent and allow users to search for videos\r\n by multiple criteria. The results page should display the videos in a clear and concise manner. The user management and permission control pages should be easy to navigate and allow administrators to \r\nmanage users and permissions effectively. The real-time monitoring page should display the personnel and traffic conditions in a clear and concise manner. The notification system should be easy to conf\r\nigure and use.\",\r\n    \"Anything UNCLEAR\": \"There are no unclear aspects of the project requirements.\"\r\n}\r\n[/CONTENT]\r\n2024-02-21 09:26:26.258 | INFO     | metagpt.utils.cost_manager:update_cost:52 - Total running cost: $0.001 | Max budget: $10.000 | Current cost: $0.001, prompt_tokens: 1312, completion_tokens: 1155\r\n2024-02-21 09:26:26.272 | INFO     | metagpt.utils.git_repository:rename_root:203 - Delete directory C:\\project\\MetaGPT\\workspace\\video_search\r\n2024-02-21 09:26:26.482 | WARNING  | metagpt.utils.git_repository:rename_root:214 - Move C:\\project\\MetaGPT\\workspace\\20240221092607 to C:\\project\\MetaGPT\\workspace\\video_search error: [WinError 32] å¦\r\nä¸€ä¸ªç¨‹åºæ­£åœ¨ä½¿ç”¨æ­¤æ–‡ä»¶ï¼Œè¿›ç¨‹æ— æ³•è®¿é—®ã€‚: 'C:\\\\project\\\\MetaGPT\\\\workspace\\\\20240221092607'\r\n2024-02-21 09:26:26.483 | INFO     | metagpt.utils.git_repository:rename_root:219 - Rename directory C:\\project\\MetaGPT\\workspace\\20240221092607 to C:\\project\\MetaGPT\\workspace\\video_search\r\n2024-02-21 09:26:26.847 | INFO     | metagpt.utils.file_repository:save:60 - save to: C:\\project\\MetaGPT\\workspace\\video_search\\docs\\prd\\20240221092626.json\r\nä¿¡æ¯: ç”¨æä¾›çš„æ¨¡å¼æ— æ³•æ‰¾åˆ°æ–‡ä»¶ã€‚\r\n2024-02-21 09:26:27.039 | WARNING  | metagpt.utils.mermaid:mermaid_to_file:39 - RUN `npm install -g @mermaid-js/mermaid-cli` to install mmdc,or consider changing engine to `playwright`, `pyppeteer`, or\r\n `ink`.\r\n2024-02-21 09:26:27.044 | INFO     | metagpt.utils.file_repository:save:60 - save to: C:\\project\\MetaGPT\\workspace\\video_search\\resources\\prd\\20240221092626.md\r\n2024-02-21 09:26:27.050 | INFO     | metagpt.roles.role:_act:399 - Bob(Architect): to do WriteDesign(WriteDesign)\r\n[CONTENT]\r\n{\r\n    \"Implementation approach\": \"We will use the Vue framework for the front-end and the Java+springboot+springmvc+mybatis plus+mysql stack for the back-end. We will use a modular approach to developmen\r\nt, with each module responsible for a specific set of functionality. This will make it easier to maintain and update the system in the future.\",\r\n    \"File list\": [\r\n        \"main.py\",\r\n        \"game.py\"\r\n    ],\r\n    \"Data structures and interfaces\": \"\\nclassDiagram\\n    class User {\\n        - username: str\\n        - password: str\\n        - email: str\\n        - permissions: list\\n        +login()\\n        +\r\nlogout()\\n        +change_password()\\n        +reset_password()\\n    }\\n    class Permission {\\n        - name: str\\n        - description: str\\n        +check()\\n    }\\n    class Role {\\n        - nam\r\ne: str\\n        - description: str\\n        - permissions: list\\n        +assign()\\n        +revoke()\\n    }\\n    class Attendance {\\n        - date: date\\n        - time: time\\n        - location: str\r\n\\n        - employee: User\\n        +check_in()\\n        +check_out()\\n    }\\n    class Congestion {\\n        - date: date\\n        - time: time\\n        - location: str\\n        - severity: int\\n     \r\n   +report()\\n    }\\n    class Notification {\\n        - type: str\\n        - message: str\\n        - recipient: User\\n        +send()\\n    }\\n    class Video {\\n        - id: int\\n        - title: str\r\n\\n        - description: str\\n        - url: str\\n        - tags: list\\n        +search()\\n        +view()\\n        +download()\\n    }\\n    class SearchEngine {\\n        - index: Index\\n        - ranki\r\nng: Ranking\\n        - summary: Summary\\n        +search(query: str) list\\n    }\\n    class Index {\\n        - data: dict\\n        +create_index(data: dict)\\n        +query_index(query: str) list\\n    \r\n}\\n    class Ranking {\\n        +rank_results(results: list) list\\n    }\\n    class Summary {\\n        +summarize_results(results: list) str\\n    }\\n    User --> Attendance\\n    User --> Congestion\\n  \r\n  User --> Notification\\n    User --> Video\\n    SearchEngine --> Index\\n    SearchEngine --> Ranking\\n    SearchEngine --> Summary\\n\",\r\n    \"Program call flow\": \"\\nsequenceDiagram\\n    participant M as Main\\n    participant SE as SearchEngine\\n    participant I as Index\\n    participant R as Ranking\\n    participant S as Summary\\n    M\r\n->>SE: search(query)\\n    SE->>I: query_index(query)\\n    I->>SE: return results\\n    SE->>R: rank_results(results)\\n    R-->>SE: return ranked_results\\n    SE->>S: summarize_results(ranked_results)\\n \r\n   S-->>SE: return summary\\n    SE-->>M: return summary\\n\",\r\n    \"Anything UNCLEAR\": \"Clarification needed on third-party API integration, ...\"\r\n}\r\n[/CONTENT]\r\n2024-02-21 09:26:49.444 | INFO     | metagpt.utils.cost_manager:update_cost:52 - Total running cost: $0.001 | Max budget: $10.000 | Current cost: $0.001, prompt_tokens: 1741, completion_tokens: 766\r\n2024-02-21 09:26:49.453 | INFO     | metagpt.utils.file_repository:save:60 - save to: C:\\project\\MetaGPT\\workspace\\video_search\\docs\\system_design\\20240221092626.json\r\n2024-02-21 09:26:49.458 | INFO     | metagpt.utils.file_repository:save:65 - update dependency: C:\\project\\MetaGPT\\workspace\\video_search\\docs\\system_design\\20240221092626.json:{'docs\\\\prd\\\\20240221092\r\n626.json'}\r\nä¿¡æ¯: ç”¨æä¾›çš„æ¨¡å¼æ— æ³•æ‰¾åˆ°æ–‡ä»¶ã€‚\r\n2024-02-21 09:26:49.627 | WARNING  | metagpt.utils.mermaid:mermaid_to_file:39 - RUN `npm install -g @mermaid-js/mermaid-cli` to install mmdc,or consider changing engine to `playwright`, `pyppeteer`, or\r\n `ink`.\r\n2024-02-21 09:26:49.629 | INFO     | metagpt.actions.design_api:_save_data_api_design:107 - Save class view to C:\\project\\MetaGPT\\workspace\\video_search\\resources\\data_api_design\\20240221092626        \r\nä¿¡æ¯: ç”¨æä¾›çš„æ¨¡å¼æ— æ³•æ‰¾åˆ°æ–‡ä»¶ã€‚\r\n2024-02-21 09:26:49.808 | WARNING  | metagpt.utils.mermaid:mermaid_to_file:39 - RUN `npm install -g @mermaid-js/mermaid-cli` to install mmdc,or consider changing engine to `playwright`, `pyppeteer`, or\r\n `ink`.\r\n2024-02-21 09:26:49.811 | INFO     | metagpt.actions.design_api:_save_seq_flow:116 - Saving sequence flow to C:\\project\\MetaGPT\\workspace\\video_search\\resources\\seq_flow\\20240221092626\r\n2024-02-21 09:26:49.816 | INFO     | metagpt.utils.file_repository:save:60 - save to: C:\\project\\MetaGPT\\workspace\\video_search\\resources\\system_design\\20240221092626.md\r\n2024-02-21 09:26:49.820 | INFO     | metagpt.roles.role:_act:399 - Eve(Project Manager): to do WriteTasks(WriteTasks)\r\n[CONTENT]\r\n{\r\n    \"Required Python packages\": [\r\n        \"flask==1.1.2\",\r\n        \"bcrypt==3.2.0\"\r\n    ],\r\n    \"Required Other language third-party packages\": [\r\n        \"No third-party dependencies required\"\r\n    ],\r\n    \"Logic Analysis\": [\r\n        [\r\n            \"game.py\",\r\n            \"Contains Game class and ... functions\"\r\n        ],\r\n        [\r\n            \"main.py\",\r\n            \"Contains main function, from game import Game\"\r\n        ]\r\n    ],\r\n    \"Task list\": [\r\n        \"game.py\",\r\n        \"main.py\"\r\n    ],\r\n    \"Shared Knowledge\": \"`game.py` contains functions shared across the project.\",\r\n    \"Anything UNCLEAR\": \"Clarification needed on how to start and initialize third-party libraries.\"\r\n}\r\n[/CONTENT]\r\n2024-02-21 09:26:55.292 | INFO     | metagpt.utils.cost_manager:update_cost:52 - Total running cost: $0.000 | Max budget: $10.000 | Current cost: $0.000, prompt_tokens: 1244, completion_tokens: 192\r\n2024-02-21 09:26:55.300 | ERROR    | metagpt.utils.common:log_it:476 - Finished call to 'metagpt.actions.action_node.ActionNode._aask_v1' after 5.110(s), this was the 1st time calling it. exp: 1 valida\r\ntion error for PM_NODE_AN\r\n  Value error, Missing fields: {'Full API spec'} [type=value_error, input_value={'Required Python package...third-party libraries.'}, input_type=dict]\r\n    For further information visit https://errors.pydantic.dev/2.5/v/value_error\r\n[CONTENT]\r\n{\r\n    \"Required Python packages\": [],\r\n    \"Required Other language third-party packages\": [],\r\n    \"Logic Analysis\": [\r\n        [\r\n            \"main.py\",\r\n            \"Contains main function, from game import Game\"\r\n        ],\r\n        [\r\n            \"game.py\",\r\n            \"Contains Game class and ... functions\"\r\n        ]\r\n    ],\r\n    \"Task list\": [\r\n        \"main.py\",\r\n        \"game.py\"\r\n    ],\r\n    \"Full API spec\": \"No API spec required\",\r\n    \"Shared Knowledge\": \"`game.py` contains functions shared across the project.\",\r\n    \"Anything UNCLEAR\": \"Clarification needed on how to start and initialize third-party libraries.\"\r\n}\r\n[/CONTENT]\r\n2024-02-21 09:27:00.834 | INFO     | metagpt.utils.cost_manager:update_cost:52 - Total running cost: $0.001 | Max budget: $10.000 | Current cost: $0.000, prompt_tokens: 1244, completion_tokens: 167\r\n2024-02-21 09:27:00.846 | INFO     | metagpt.utils.file_repository:save:60 - save to: C:\\project\\MetaGPT\\workspace\\video_search\\docs\\task\\20240221092626.json\r\n2024-02-21 09:27:00.852 | INFO     | metagpt.utils.file_repository:save:65 - update dependency: C:\\project\\MetaGPT\\workspace\\video_search\\docs\\task\\20240221092626.json:{'docs\\\\system_design\\\\2024022109\r\n2626.json'}\r\n2024-02-21 09:27:00.855 | INFO     | metagpt.utils.file_repository:save:60 - save to: C:\\project\\MetaGPT\\workspace\\video_search\\requirements.txt\r\n2024-02-21 09:27:01.330 | INFO     | metagpt.actions.write_code:run:147 - Writing main.py..\r\n## Code: main.py\r\n```python\r\nfrom game import Game\r\n\r\ndef main():\r\n    \"\"\"\r\n    Main function.\r\n    \"\"\"\r\n\r\n    # Create a new game.\r\n    game = Game()\r\n\r\n    # Start the game.\r\n    game.start()\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n2024-02-21 09:27:07.416 | INFO     | metagpt.utils.cost_manager:update_cost:52 - Total running cost: $0.000 | Max budget: $10.000 | Current cost: $0.000, prompt_tokens: 1201, completion_tokens: 72\r\n2024-02-21 09:27:07.420 | INFO     | metagpt.actions.write_code_review:run:183 - Code review and rewrite main.py: 1/2 | len(iterative_code)=193, len(self.i_context.code_doc.content)=193\r\n## Code Review: main.py\r\n1. Yes.\r\n2. Yes.\r\n3. Yes.\r\n4. Yes.\r\n5. Yes.\r\n6. Yes.\r\n\r\n## Actions\r\npass\r\n\r\n## Code Review Result\r\nLGTM\r\n2024-02-21 09:27:11.272 | INFO     | metagpt.utils.cost_manager:update_cost:52 - Total running cost: $0.001 | Max budget: $10.000 | Current cost: $0.000, prompt_tokens: 1654, completion_tokens: 51\r\n2024-02-21 09:27:11.284 | INFO     | metagpt.utils.file_repository:save:60 - save to: C:\\project\\MetaGPT\\workspace\\video_search\\video_search\\main.py\r\n2024-02-21 09:27:11.289 | INFO     | metagpt.utils.file_repository:save:65 - update dependency: C:\\project\\MetaGPT\\workspace\\video_search\\video_search\\main.py:{'docs\\\\system_design\\\\20240221092626.json\r\n', 'docs\\\\task\\\\20240221092626.json'}\r\n2024-02-21 09:27:11.293 | INFO     | metagpt.actions.write_code:run:147 - Writing game.py..\r\n,\r\n2024-02-21 09:27:14.455 | INFO     | metagpt.utils.cost_manager:update_cost:52 - Total running cost: $0.001 | Max budget: $10.000 | Current cost: $0.000, prompt_tokens: 1201, completion_tokens: 2\r\n2024-02-21 09:27:14.458 | ERROR    | metagpt.utils.common:parse_code:280 - ```.*?\\s+(.*?)``` not match following text:\r\n2024-02-21 09:27:14.459 | ERROR    | metagpt.utils.common:parse_code:281 - ,\r\n2024-02-21 09:27:14.462 | INFO     | metagpt.actions.write_code_review:run:183 - Code review and rewrite game.py: 1/2 | len(iterative_code)=1, len(self.i_context.code_doc.content)=1\r\n## Code Review: game.py\r\n1. The code is not implemented as per the requirements. The `handle_events` method should update the game state only if a move is successful.\r\n   ```python\r\n   def handle_events(self):\r\n       for event in pygame.event.get():\r\n           if event.type == pygame.QUIT:\r\n               return False\r\n           if event.type == pygame.KEYDOWN:\r\n               moved = False\r\n               if event.key == pygame.K_UP:\r\n                   moved = self.game.move('UP')\r\n               elif event.key == pygame.K_DOWN:\r\n                   moved = self.game.move('DOWN')\r\n               elif event.key == pygame.K_LEFT:\r\n                   moved = self.game.move('LEFT')\r\n               elif event.key == pygame.K_RIGHT:\r\n                   moved = self.game.move('RIGHT')\r\n               if moved:\r\n                   # Update the game state only if a move was successful\r\n                   self.render()\r\n       return True\r\n   ```\r\n2. The code logic is not completely correct. The `move` function is not implemented.\r\n   ```python\r\n   def move(self, direction):\r\n       # Implement the move logic here\r\n       pass\r\n   ```\r\n3. The existing code does not follow the \"Data structures and interfaces\". The `Game` class should have a `move` method that takes a direction as an argument and returns a boolean indicating whether th\r\ne move was successful.\r\n4. The `move` function is not implemented.\r\n5. All necessary pre-dependencies have been imported.\r\n6. Methods from other files are not being reused.\r\n\r\n## Actions\r\n1. Implement the `move` function in the `Game` class.\r\n2. Update the `handle_events` method to update the game state only if a move is successful.\r\n\r\n## Code Review Result\r\nLBTM\r\n2024-02-21 09:27:24.155 | INFO     | metagpt.utils.cost_manager:update_cost:52 - Total running cost: $0.002 | Max budget: $10.000 | Current cost: $0.001, prompt_tokens: 1596, completion_tokens: 407\r\n## Rewrite Code: game.py\r\n```python\r\nimport pygame\r\n\r\nclass Game:\r\n    def __init__(self):\r\n        self.game_state = ...  # Initialize the game state here\r\n\r\n    def move(self, direction):\r\n        # Implement the move logic here\r\n        # Return True if the move was successful, False otherwise\r\n        pass\r\n\r\n    def render(self):\r\n        # Implement the rendering logic here\r\n        pass\r\n\r\nclass GameEngine:\r\n    def __init__(self):\r\n        self.game = Game()\r\n\r\n    def handle_events(self):\r\n        for event in pygame.event.get():\r\n            if event.type == pygame.QUIT:\r\n                return False\r\n            if event.type == pygame.KEYDOWN:\r\n                moved = False\r\n                if event.key == pygame.K_UP:\r\n                    moved = self.game.move('UP')\r\n                elif event.key == pygame.K_DOWN:\r\n                    moved = self.game.move('DOWN')\r\n                elif event.key == pygame.K_LEFT:\r\n                    moved = self.game.move('LEFT')\r\n                elif event.key == pygame.K_RIGHT:\r\n                    moved = self.game.move('RIGHT')\r\n                if moved:\r\n                    # Update the game state only if a move was successful\r\n                    self.game.render()\r\n        return True\r\n\r\n    def run(self):\r\n        while self.handle_events():\r\n            # Update the game logic here\r\n            pass\r\n\r\nif __name__ == '__main__':\r\n    engine = GameEngine()\r\n    engine.run()\r\n```\r\n2024-02-21 09:27:31.668 | INFO     | metagpt.utils.cost_manager:update_cost:52 - Total running cost: $0.002 | Max budget: $10.000 | Current cost: $0.001, prompt_tokens: 1466, completion_tokens: 347\r\n2024-02-21 09:27:31.670 | INFO     | metagpt.actions.write_code_review:run:183 - Code review and rewrite game.py: 2/2 | len(iterative_code)=1374, len(self.i_context.code_doc.content)=1\r\n## Code Review: Ordered List. Based on the \"Code to be Reviewed\", provide key, clear, concise, and specific answer. If any answer is no, explain how to fix it step by step.\r\n1. Yes.\r\n2. Yes.\r\n3. Yes.\r\n4. Yes.\r\n5. Yes.\r\n6. Yes.\r\n\r\n## Actions: Ordered List. Things that should be done after CR, such as implementing class A and function B\r\n\r\n## Code Review Result: str. If the code doesn't have bugs, we don't need to rewrite it, so answer LGTM and stop. ONLY ANSWER LGTM/LBTM.\r\nLGTM\r\n2024-02-21 09:27:36.275 | INFO     | metagpt.utils.cost_manager:update_cost:52 - Total running cost: $0.003 | Max budget: $10.000 | Current cost: $0.001, prompt_tokens: 1928, completion_tokens: 141\r\n2024-02-21 09:27:36.287 | INFO     | metagpt.utils.file_repository:save:60 - save to: C:\\project\\MetaGPT\\workspace\\video_search\\video_search\\game.py\r\n2024-02-21 09:27:36.292 | INFO     | metagpt.utils.file_repository:save:65 - update dependency: C:\\project\\MetaGPT\\workspace\\video_search\\video_search\\game.py:{'docs\\\\system_design\\\\20240221092626.json\r\n', 'docs\\\\task\\\\20240221092626.json'}\r\n2024-02-21 09:27:36.497 | INFO     | metagpt.utils.git_repository:archive:168 - Archive: ['.dependencies.json', 'docs/prd/20240221092626.json', 'docs/requirement.txt', 'docs/system_design/2024022109262\r\n6.json', 'docs/task/20240221092626.json', 'requirements.txt', 'resources/competitive_analysis/20240221092626.mmd', 'resources/data_api_design/20240221092626.mmd', 'resources/prd/20240221092626.md', 're\r\nsources/seq_flow/20240221092626.mmd', 'resources/system_design/20240221092626.md', 'video_search/game.py', 'video_search/main.py']\r\n",
      "state": "closed",
      "author": "1010936691",
      "author_type": "User",
      "created_at": "2024-02-21T01:40:23Z",
      "updated_at": "2024-10-11T09:56:39Z",
      "closed_at": "2024-10-11T09:56:39Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/915/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "geekan"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/915",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/915",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:39.563394",
      "comments": [
        {
          "author": "iorisa",
          "body": "```text\r\n2024-02-21 09:26:26.482 | WARNING | metagpt.utils.git_repository:rename_root:214 - Move C:\\project\\MetaGPT\\workspace\\20240221092607 to C:\\project\\MetaGPT\\workspace\\video_search error: [WinError 32] å¦\r\nä¸€ä¸ªç¨‹åºæ­£åœ¨ä½¿ç”¨æ­¤æ–‡ä»¶ï¼Œè¿›ç¨‹æ— æ³•è®¿é—®ã€‚: 'C:\\project\\MetaGPT\\workspace\\20240221092607'\r\n```\r\nWindowsä¸‹æ­¤å¤„çš„å¼‚å¸¸åªä¼šå¯¼è‡´",
          "created_at": "2024-03-04T04:00:43Z"
        },
        {
          "author": "geekan",
          "body": "TODO\r\n1. Prompt optimization\r\n2. Review & revise until the output meets expectations",
          "created_at": "2024-03-21T06:13:21Z"
        },
        {
          "author": "geekan",
          "body": "This bug will be fixed in our later versions. This issue will be closed first and then opened at any time.",
          "created_at": "2024-10-11T09:56:39Z"
        }
      ]
    },
    {
      "issue_number": 333,
      "title": "Iterating on a solution",
      "body": "Is it possible to iterate on a completed solution, or provide feedback on the chosen path? When setting long term memory to True and running again with revised instructions the execution prints the directives, but does not run any further steps.\r\n\r\npython startup.py \"This should be an emacs lisp package not a python package. The package should be a fork of gptel. Please modify the gptel package to interact with flowise\" --n_round=25 --code_review=True --investment=5\r\n2023-09-18 00:32:13.938 | INFO     | metagpt.config:__init__:44 - Config loading done.\r\n2023-09-18 00:32:13.942 | WARNING  | metagpt.config:__init__:77 - LONG_TERM_MEMORY is True\r\n2023-09-18 00:32:24.259 | WARNING  | metagpt.memory.longterm_memory:recover_memory:32 - Agent Alice(Product Manager) has existed memory storage with 3 messages and has recovered them.\r\n2023-09-18 00:32:24.297 | WARNING  | metagpt.memory.longterm_memory:recover_memory:32 - Agent Bob(Architect) has existed memory storage with 3 messages and has recovered them.\r\n2023-09-18 00:32:24.307 | WARNING  | metagpt.memory.longterm_memory:recover_memory:32 - Agent Eve(Project Manager) has existed memory storage with 1 messages and has recovered them.\r\n2023-09-18 00:32:24.330 | WARNING  | metagpt.memory.longterm_memory:recover_memory:32 - Agent Alex(Engineer) has existed memory storage with 2 messages and has recovered them.\r\n2023-09-18 00:32:24.334 | INFO     | metagpt.software_company:invest:39 - Investment: $5.",
      "state": "closed",
      "author": "rmulligan",
      "author_type": "User",
      "created_at": "2023-09-18T00:33:06Z",
      "updated_at": "2024-10-11T06:37:42Z",
      "closed_at": "2024-10-11T06:37:42Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 10,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/333/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "iorisa"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/333",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/333",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:39.822330",
      "comments": [
        {
          "author": "samuelmukoti",
          "body": "I'm wondering the same thing.  I happy to contribute a PR with some guidance of course?  Is anyone else already working on this? Is it part of the roadmap? \r\n\r\nI'd be happy to put together a pull request to address the iteration capabilities and contribute to the project. \r\n\r\nBefore jumping into cod",
          "created_at": "2023-09-23T22:06:02Z"
        },
        {
          "author": "javadan",
          "body": "SkyNet v1.0 here we go!  \r\n\r\n@samuelmukoti let me know if you work it out, i think this would be an ideal next feature.  \r\n\r\ngreat project @geekan - any advice for how best to implement ?  ",
          "created_at": "2023-10-01T21:07:36Z"
        },
        {
          "author": "geekan",
          "body": "@rmulligan @samuelmukoti @javadan check latest code and we've incremental dev now.",
          "created_at": "2023-12-21T09:24:13Z"
        },
        {
          "author": "javadan",
          "body": "Nice.\r\nA few errors I came across  (from github head):  \r\n- Only MetaGPT/config/config.yaml was used, not ~/.metagpt/key.yaml  resulting in `metagpt.config.NotConfiguredException: You should config a LLM configuration first`\r\n- When not specifying a project path, it will generate a project name unde",
          "created_at": "2023-12-25T11:58:15Z"
        },
        {
          "author": "kevb10",
          "body": "i'm also getting an error at \r\n```py\r\nif path.exists() and not CONFIG.inc:\r\n```\r\nwhen using the flags `--inc --project-path /path/here`\r\n\r\nwrapping it in a Path is the answer but @javadan you're rewrapping it \r\ni'm happy to submit a PR @geekan \r\n```py\r\n def _init_repo(self):\r\n        \"\"\"Initialize t",
          "created_at": "2023-12-28T00:10:59Z"
        }
      ]
    },
    {
      "issue_number": 1095,
      "title": "bug: Fixing existing code does not work",
      "body": "**Bug description**\r\n- `main` branch\r\n- logs:\r\n[20240321.txt](https://github.com/geekan/MetaGPT/files/14739821/20240321.txt)\r\n\r\n`Engineer` ignores error information in `_act_code_plan_and_change()`",
      "state": "closed",
      "author": "iorisa",
      "author_type": "User",
      "created_at": "2024-03-25T06:48:30Z",
      "updated_at": "2024-10-11T06:32:53Z",
      "closed_at": "2024-10-11T06:32:52Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1095/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1095",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1095",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:40.056711",
      "comments": [
        {
          "author": "iorisa",
          "body": "<img width=\"1121\" alt=\"æˆªå±2024-03-25 15 02 37\" src=\"https://github.com/geekan/MetaGPT/assets/46912756/b9935d42-1a8a-49af-abdc-30b754c3a21e\">\r\n\r\nThe error information is excluded when formatting the prompt:\r\n<img width=\"1011\" alt=\"æˆªå±2024-03-25 15 05 32\" src=\"https://github.com/geekan/MetaGPT/assets/46",
          "created_at": "2024-03-25T07:10:49Z"
        },
        {
          "author": "iorisa",
          "body": "I've consolidated all the incremental development-related issues into #1498 to make it easier to follow up. Any new issues will be discussed in this newly opened issue, and the old issue will be closed.",
          "created_at": "2024-10-11T06:32:52Z"
        }
      ]
    },
    {
      "issue_number": 1210,
      "title": "Fixing existing code does not work again",
      "body": "**Bug description**\r\nI generated metagpt project. But I am not satisfied with dummy logic implementation. I want to apply corrections to generated project\r\nI tried:\r\n--project-path ... --inc\r\nand\r\n--project-path ... only\r\nThe docs and resources changes. But the generated code doesn't. The .py code files in project does not change. The new file mentioned in log are not created.\r\nRunning metagpt on existing project doesn't call metagpt.actions.write_code:run. Only metagpt.actions.write_code_plan_and_change_an:run.\r\nDoes metagpt support applying new requirements to project? \r\n\r\n**Bug solved method**\r\nHave not tried to solve yet.\r\n\r\n**Environment information**\r\nDebian, python=3.11.2-1+b1, venv, \r\nI have this bug as on pip metagpt version, as on newest metagpt github release.\r\n\r\nModel gpt-3.5-turbo",
      "state": "closed",
      "author": "AndPim4912",
      "author_type": "User",
      "created_at": "2024-04-18T17:14:18Z",
      "updated_at": "2024-10-11T06:31:37Z",
      "closed_at": "2024-10-11T06:31:37Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1210/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1210",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1210",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:40.247366",
      "comments": [
        {
          "author": "seehi",
          "body": "According to the [document](https://docs.deepwisdom.ai/main/en/guide/in_depth_guides/incremental_development.html#unresolved-issues), there are still some unresolved issues in incremental development.",
          "created_at": "2024-04-19T03:04:46Z"
        },
        {
          "author": "iorisa",
          "body": "I've consolidated all the incremental development-related issues into #1498 to make it easier to follow up. Any new issues will be discussed in this newly opened issue, and the old issue will be closed.",
          "created_at": "2024-10-11T06:31:37Z"
        }
      ]
    },
    {
      "issue_number": 5,
      "title": "å¦‚ä½•ç»†åŒ–éœ€æ±‚ï¼Ÿ",
      "body": "åªç”¨ä¸€å¥è¯å»åˆ›å»ºæ•´ä¸ªé¡¹ç›®ä»å•†ä¸šè®¾è®¡ä¸Šæ¥è®²æ˜¯ä¸é è°±çš„é™¤éæ˜¯å¾ˆç®€å•çš„é€»è¾‘æ¯”å¦‚â€œåˆ›å»ºä¸€ä¸ªjsç‰ˆæœ¬çš„è´ªé£Ÿè›‡â€ã€‚ä½†æ˜¯å½“æˆ‘ä»¬è¦ä¾èµ–AIå»è®¾è®¡æ›´å¤§è§„æ¨¡çš„ç³»ç»Ÿæ—¶ï¼Œæˆ‘å»ºè®®è¿˜æ˜¯éœ€è¦å¢åŠ æ›´åŠ å¤æ‚çš„äº¤äº’å¼è®¾è®¡é€šè¿‡AIå»æ”¶é›†å¤šè½®å¯¹è¯çš„éœ€æ±‚ä»¥åŠæ›´å¤šçš„ç»†èŠ‚è®©æ•´ä¸ªé¡¹ç›®çš„ç”Ÿæˆå˜å¾—æ›´åŠ å¯é ã€‚å¦‚æœæ˜¯çœŸçš„è€ƒè™‘å•†ä¸šåŒ–è½åœ°çš„è¯",
      "state": "closed",
      "author": "sd797994",
      "author_type": "User",
      "created_at": "2023-07-04T08:29:39Z",
      "updated_at": "2024-10-10T06:44:05Z",
      "closed_at": "2024-10-10T06:44:05Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/5/reactions",
        "total_count": 3,
        "+1": 3,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "geekan"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/5",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/5",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:42.150050",
      "comments": [
        {
          "author": "geekan",
          "body": "æ˜¯çš„ã€‚åœ¨todo listä¸Šï¼Œè¯·ç­‰å¾…1-2å¤©",
          "created_at": "2023-07-04T08:59:37Z"
        },
        {
          "author": "geekan",
          "body": "https://github.com/geekan/MetaGPT/blob/main/docs/ROADMAP.md\r\n\r\nè¿™æ˜¯ç›®å‰çš„ROADMAPï¼Œå…¶ä¸­Complete the design and implementation of module breakdownä»»åŠ¡ä¸æ­¤å¯¹åº”",
          "created_at": "2023-07-05T07:02:09Z"
        },
        {
          "author": "WangShuXian6",
          "body": "ç›®å‰æˆ‘æ˜¯ç›´æ¥ä½¿ç”¨è¯¦ç»†çš„äº§å“éœ€æ±‚å»ç»™åˆ°MetaGPT,å‡ ç™¾ä¸ªå­—æ²¡é—®é¢˜~~",
          "created_at": "2023-07-23T11:33:43Z"
        }
      ]
    },
    {
      "issue_number": 17,
      "title": "å…³äºè‡ªåŠ¨ç”Ÿæˆçš„é¡¹ç›®çš„å®Œæ•´æ€§",
      "body": "æˆ‘è‡ªå·±åœ¨æœ¬åœ°æµ‹è¯•äº†å‡ æ¬¡ï¼Œç”Ÿæˆçš„é¡¹ç›®éƒ½ä¸èƒ½ç›´æ¥æ‰§è¡Œï¼Œä¼šæœ‰å„ç§é—®é¢˜ï¼Œæ¯”å¦‚å†™å‘½ä»¤è¡Œè´ªåƒè›‡ï¼Œcursesåº“æ€»æ˜¯æŠ›å‡ºé”™è¯¯ï¼š\r\n  File \"/*****\", line 28, in _draw_snake\r\n    self.screen.addch(position[0], position[1], \"O\")\r\n_curses.error: add_wch() returned ERR\r\næˆ‘æ³¨æ„åˆ°è¯¥ä»“åº“é•¿æœŸè§„åˆ’ä¸­ä¼šæ·»åŠ æµ‹è¯•è§’è‰²ï¼Œæ‰€ä»¥æˆ‘æƒ³é—®ä¸‹å½“å‰è‡ªåŠ¨ç”Ÿæˆçš„é¡¹ç›®æ— æ³•å®Œæ•´æ‰§è¡Œæ˜¯å¦æ˜¯æ­£å¸¸æƒ…å†µğŸ˜‚è°¢è°¢ï¼\r\n",
      "state": "closed",
      "author": "Lucas66Zhang",
      "author_type": "User",
      "created_at": "2023-07-07T06:24:44Z",
      "updated_at": "2024-10-10T06:43:32Z",
      "closed_at": "2024-10-10T06:43:32Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/17/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "geekan"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/17",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/17",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:42.337215",
      "comments": [
        {
          "author": "geekan",
          "body": "æ˜¯ç”¨4è¿˜æ˜¯3.5ï¼Ÿ",
          "created_at": "2023-07-07T07:47:12Z"
        },
        {
          "author": "Lucas66Zhang",
          "body": "4",
          "created_at": "2023-07-07T08:57:59Z"
        },
        {
          "author": "geekan",
          "body": "è¿›ç¾¤ï¼Œå‘ä¸€ä¸‹log",
          "created_at": "2023-07-07T12:21:07Z"
        },
        {
          "author": "cc-qq-gg",
          "body": "\r\n\r\n\r\n\r\n> è¿›ç¾¤ï¼Œå‘ä¸€ä¸‹log\r\n\r\nè¯·é—®æ€ä¹ˆåŠ ç¾¤",
          "created_at": "2023-07-11T01:35:28Z"
        },
        {
          "author": "geekan",
          "body": "@cc-qq-gg https://github.com/geekan/MetaGPT/blob/main/docs/resources/MetaGPT-WeChat-Personal.jpeg",
          "created_at": "2023-07-12T16:52:16Z"
        }
      ]
    },
    {
      "issue_number": 19,
      "title": "Require open source llms like ChatGLM, ChatRWKV, MPT-30b support.",
      "body": "Whether it is possible to deploy open source llms like ChatGLM, ChatRWKV, MPT-30b support to the project MetaGPT ?",
      "state": "closed",
      "author": "stc2001",
      "author_type": "User",
      "created_at": "2023-07-07T13:26:01Z",
      "updated_at": "2024-10-10T06:43:17Z",
      "closed_at": "2024-10-10T06:43:17Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/19/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/19",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/19",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:42.512731",
      "comments": [
        {
          "author": "geekan",
          "body": "Sure. It should be very easy to implement a provider or provide an OpenAI-compatible API, which requires development",
          "created_at": "2023-07-07T13:34:40Z"
        },
        {
          "author": "NetTecture",
          "body": "Actually no - does huggingface not expose them in an OpenAi compatible API?",
          "created_at": "2023-07-25T12:57:05Z"
        },
        {
          "author": "better629",
          "body": "`https://docs.deepwisdom.ai/main/en/guide/tutorials/integration_with_open_llm.html`",
          "created_at": "2024-10-10T06:43:17Z"
        }
      ]
    },
    {
      "issue_number": 20,
      "title": "Other Programming Languages",
      "body": "Right now, python language is hard coded. It would be nice if, it took the language from the initial prompt, or took the programming language as a command line argument.",
      "state": "closed",
      "author": "zerofill",
      "author_type": "User",
      "created_at": "2023-07-07T16:34:20Z",
      "updated_at": "2024-10-10T06:42:57Z",
      "closed_at": "2024-10-10T06:42:56Z",
      "labels": [
        "todo"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/20/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/20",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/20",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:42.697975",
      "comments": [
        {
          "author": "geekan",
          "body": "We will try to provide a multi-language version within a week.",
          "created_at": "2023-07-08T06:01:04Z"
        },
        {
          "author": "magick93",
          "body": "To add to this, it would be good if:\r\n- user can specify language(s) and frameworks, eg, specify a frontent - vuejs, svelte, etc\r\n- add requested 3rd party npm, pip etc modules to use - and include a github repo, or docs url\r\n- include a link to developer docs, api docs for any relevant sources",
          "created_at": "2023-07-28T09:02:32Z"
        },
        {
          "author": "geekan",
          "body": "This progress is slow because the first two weeks were filled with other high priorities. I try to finish writing this feature by 0804. This feature needs to be changed in 10 places, and there is some debugging work",
          "created_at": "2023-07-28T13:38:43Z"
        },
        {
          "author": "p971607",
          "body": "> è¿™ä¸€è¿›å±•ç¼“æ…¢ï¼Œå› ä¸ºå¤´ä¸¤å‘¨å……æ»¡äº†å…¶ä»–é«˜åº¦ä¼˜å…ˆäº‹é¡¹ã€‚æˆ‘å°è¯•åœ¨ 0804 ä¹‹å‰å®Œæˆæ­¤åŠŸèƒ½çš„ç¼–å†™ã€‚æ­¤åŠŸèƒ½éœ€è¦åœ¨ 10 å¤„æ›´æ”¹ï¼Œå¹¶ä¸”æœ‰ä¸€äº›è°ƒè¯•å·¥ä½œ\r\n\r\nå¤ªæ£’äº†ï¼Œé«˜åº¦é«˜åº¦é«˜åº¦æœŸå¾…\r\n\r\n> \r\nå¤ªæ£’äº† ï¼ï¼ï¼é«˜åº¦æœŸå¾…è¿™é¡¹å·¥ä½œå•Š~~å‘å‡ºåœŸæ‹¨é¼ ä¹‹å°–å«~~ï¼ï¼\r\n",
          "created_at": "2023-08-03T00:43:39Z"
        },
        {
          "author": "iamalin",
          "body": "> We will try to provide a multi-language version within a week.\r\n\r\nIs there any schedule for this proposal?",
          "created_at": "2024-03-11T09:59:49Z"
        }
      ]
    },
    {
      "issue_number": 31,
      "title": "Error communicating with openai ",
      "body": "  File \"/Users/r/Documents/1-projects/MetaGPT/venv/lib/python3.11/site-packages/aiohttp/connector.py\", line 982, in _wrap_create_connection\r\n    raise ClientConnectorCertificateError(req.connection_key, exc) from exc\r\naiohttp.client_exceptions.ClientConnectorCertificateError: Cannot connect to host api.openai.com:443 ssl:True [SSLCertVerificationError: (1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:992)')]\r\n\r\n\r\nI've checked that I have correct CA Bundle certificates and I can connect to api.openai.com easily",
      "state": "closed",
      "author": "rubywwwilde",
      "author_type": "User",
      "created_at": "2023-07-10T12:30:21Z",
      "updated_at": "2024-10-10T06:41:22Z",
      "closed_at": "2024-10-10T06:41:22Z",
      "labels": [
        "network"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/31/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "geekan"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/31",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/31",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:42.878383",
      "comments": [
        {
          "author": "geekan",
          "body": "Could you try this: https://github.com/beidongjiedeguang/openai-forward ?",
          "created_at": "2023-07-10T14:40:47Z"
        }
      ]
    },
    {
      "issue_number": 36,
      "title": "è¯·é—®è¿™ä¸ªæ˜¯ä¸æ˜¯å¿…é¡»è¦è¦å¼€é€šopenai çš„plusä¼šå‘˜æ‰èƒ½å»è®¿é—®gpt-4ï¼Ÿ",
      "body": "å› ä¸ºæˆ‘é‡Œé¢åªæœ‰5ç¾å…ƒï¼Œè·‘ä½ è¿™é‡Œçš„å®ä¾‹ä»£ç éƒ½è·‘ä¸é€š</br>\r\nassert not isinstance(response, OpenAIResponse)",
      "state": "closed",
      "author": "liaogulou",
      "author_type": "User",
      "created_at": "2023-07-12T03:52:20Z",
      "updated_at": "2024-10-10T06:41:03Z",
      "closed_at": "2024-10-10T06:41:03Z",
      "labels": [
        "question"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/36/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/36",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/36",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:43.095813",
      "comments": [
        {
          "author": "liaogulou",
          "body": "> å› ä¸ºæˆ‘é‡Œé¢åªæœ‰5ç¾å…ƒï¼Œè·‘ä½ è¿™é‡Œçš„å®ä¾‹ä»£ç éƒ½è·‘ä¸é€š assert not isinstance(response, OpenAIResponse)\r\n\r\nè¿˜æœ‰å¯¼å…¥åŒ…çš„æ—¶å€™ï¼Œä¹ŸæŠ¥é”™</br>\r\nfrom metagpt.software_company import SoftwareCompany\r\n</br>\r\nException: Project root not found.",
          "created_at": "2023-07-12T03:53:44Z"
        },
        {
          "author": "geekan",
          "body": "#37 å¯ä»¥è®©GPT-3.5-TURBOä¹Ÿæœ‰æˆåŠŸæ¦‚ç‡ï¼ˆä½†ä¸é«˜ï¼‰ï¼Œè¿˜æ˜¯å»ºè®®GPT-4ä¼˜å…ˆ\r\n\r\nException: Project root not found.\r\nè¿™ä¸ªè¯·æä¾›æ›´è¯¦ç»†çš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ‰§è¡Œæ—¶æ‰€å¤„äºçš„è·¯å¾„ã€OSã€Pythonç‰ˆæœ¬ã€æ—¥å¿—ç­‰",
          "created_at": "2023-07-12T16:28:12Z"
        },
        {
          "author": "ToviHe",
          "body": "è¯è¯´  å¦‚æœæ˜¯éplus è´¦æˆ·ï¼Œè¿™ä¸ª OPENAI_API_BASE å‚æ•°åœ¨å“ªé‡Œçœ‹çš„ï¼Ÿ",
          "created_at": "2023-07-13T09:22:07Z"
        },
        {
          "author": "geekan",
          "body": "@ToviHe @liaogulou apiä¸éœ€è¦plusã€‚è®¿é—®openaiçš„apié¡µé¢æŸ¥çœ‹",
          "created_at": "2023-07-13T11:02:10Z"
        },
        {
          "author": "apas008",
          "body": "OPENAI_API_MODEL: \"gpt-3.5-turbo\"  æ”¹æˆè¿™ä¸ªè·‘ä¸èµ·æ¥ï¼Œlogä¸­æ˜¯waiting news",
          "created_at": "2023-07-28T08:29:16Z"
        }
      ]
    },
    {
      "issue_number": 39,
      "title": "RetryError[<Future at 0x7f806d336a60 state=finished raised ValidationError>]",
      "body": "(mgpt) dope@dope:~/Documents/metagpt$ python startup.py \"Write a cli snake game\"\r\n2023-07-12 21:00:39.873 | INFO     | metagpt.config:__init__:43 - Config loading done.\r\n2023-07-12 21:00:39.873 | INFO     | metagpt.config:__init__:49 - Set OPENAI_API_BASE in case of network issues\r\n2023-07-12 21:00:40.585 | INFO     | metagpt.software_company:invest:39 - Investment: $3.0.\r\n2023-07-12 21:00:40.586 | INFO     | metagpt.roles.role:_act:155 - Alice(Product Manager): ready to WritePRD\r\n2023-07-12 21:00:40.586 | WARNING  | metagpt.actions.search_and_summarize:run:114 - Configure SERPAPI_API_KEY to unlock full feature\r\n## Original Requirements:\r\n\r\nThe boss wants a command-line snake game.\r\n\r\n## Product Goals:\r\n\r\n- Create a fun and engaging snake game that can be played in the command-line interface.\r\n- Provide a challenging gameplay experience for users.\r\n- Implement intuitive controls and smooth animations for a seamless gaming experience.\r\n\r\n## User Stories:\r\n\r\n- As a user, I want to be able to control the snake using arrow keys.\r\n- As a user, I want the snake to grow longer each time it eats food.\r\n- As a user, I want the game to end if the snake collides with the wall or itself.\r\n- As a user, I want to see my score displayed on the screen.\r\n- As a user, I want the game to have different levels of difficulty.\r\n\r\n## Competitive Analysis:\r\n\r\n- Python Snake Game: A basic snake game implemented in Python with simple graphics.\r\n- Snake Xenzia: A popular snake game with improved graphics and additional features.\r\n- Snake VS Block: A modern twist on the classic snake game with obstacles and power-ups.\r\n- Slither.io: An online multiplayer snake game with a competitive leaderboard.\r\n- Snake '97: A nostalgic recreation of the classic snake game from the Nokia 3310.\r\n- Snake Rivals: A multiplayer snake game with real-time battles and customizable snakes.\r\n- Snake Zone: A 3D snake game with immersive graphics and challenging levels.\r\n\r\n## Competitive Quadrant Chart:\r\n\r\n```mermaid\r\nquadrantChart\r\n    title Reach and engagement of snake games\r\n    x-axis Low Reach --> High Reach\r\n    y-axis Low Engagement --> High Engagement\r\n    quadrant-1 Basic Games\r\n    quadrant-2 Popular Games\r\n    quadrant-3 Innovative Games\r\n    quadrant-4 Advanced Games\r\n    \"Python Snake Game\": [0.2, 0.3]\r\n    \"Snake Xenzia\": [0.4, 0.4]\r\n    \"Snake VS Block\": [0.6, 0.6]\r\n    \"Slither.io\": [0.8, 0.7]\r\n    \"Snake '97\": [0.3, 0.2]\r\n    \"Snake Rivals\": [0.7, 0.8]\r\n    \"Snake Zone\": [0.9, 0.9]\r\n    \"Our Target Product\": [0.5, 0.6]\r\n```\r\n\r\n## Requirement Analysis:\r\n\r\nThe product should be a command-line snake game with intuitive controls, smooth animations, and challenging gameplay. It should have different levels of difficulty and display the user's score on the screen. The game should end if the snake collides with the wall or itself.\r\n\r\n## Requirement Pool:\r\n\r\n```python\r\n[\r\n    (\"Implement arrow key controls for the snake\", \"P0\"),\r\n    (\"Implement snake growth when it eats food\", \"P0\"),\r\n    (\"Detect collision with the wall or snake's body\", \"P0\"),\r\n    (\"Display the user's score on the screen\", \"P1\"),\r\n    (\"Implement different levels of difficulty\", \"P1\")\r\n]\r\n```\r\n\r\n## Anything UNCLEAR:\r\n\r\nThere are no unclear points.\r\nWarning: gpt-3.5-turbo may change over time. Returning num tokens assuming gpt-3.5-turbo-0301.\r\n2023-07-12 21:00:55.796 | INFO     | metagpt.provider.openai_api:update_cost:89 - Total running cost: $0.003 | Max budget: $3.000 | Current cost: $0.003, prompt_tokens=800, completion_tokens=625\r\n## Original Requirements:\r\nThe boss wants you to create a command-line snake game.\r\n\r\n## Product Goals:\r\n- Create a fun and engaging snake game.\r\n- Provide a smooth and responsive user experience.\r\n- Include customizable game settings for different difficulty levels.\r\n\r\n## User Stories:\r\n- As a user, I want to be able to control the snake using arrow keys.\r\n- As a user, I want the snake to grow longer when it eats food.\r\n- As a user, I want the game to end if the snake hits the wall or its own body.\r\n- As a user, I want to be able to pause and resume the game.\r\n- As a user, I want to see my current score and the highest score achieved.\r\n\r\n## Competitive Analysis:\r\n- Python Snake Game: A simple snake game implemented in Python with basic features.\r\n- Snake Xenzia: A classic snake game with improved graphics and sound effects.\r\n- Snake.io: A multiplayer snake game where players compete against each other.\r\n- Slither.io: A popular online multiplayer snake game with a large player base.\r\n- Snake '97: A nostalgic snake game that replicates the experience of playing on an old Nokia phone.\r\n- Snake Blast: A modern twist on the snake game with power-ups and special abilities.\r\n- Snake Rewind: A snake game with a rewind feature that allows players to undo their moves.\r\n\r\n## Competitive Quadrant Chart:\r\n```mermaid\r\nquadrantChart\r\n    title Reach and engagement of snake games\r\n    x-axis Low Reach --> High Reach\r\n    y-axis Low Engagement --> High Engagement\r\n    quadrant-1 We should expand\r\n    quadrant-2 Need to promote\r\n    quadrant-3 Re-evaluate\r\n    quadrant-4 May be improved\r\n    \"Python Snake Game\": [0.3, 0.6]\r\n    \"Snake Xenzia\": [0.45, 0.23]\r\n    \"Snake.io\": [0.57, 0.69]\r\n    \"Slither.io\": [0.78, 0.34]\r\n    \"Snake '97\": [0.40, 0.34]\r\n    \"Snake Blast\": [0.35, 0.78]\r\n    \"Snake Rewind\": [0.6, 0.7]\r\n    \"Our Target Product\": [0.5, 0.6]\r\n```\r\n\r\n## Requirement Analysis:\r\nThe product should be a command-line snake game with basic features such as controlling the snake, growing longer when eating food, and ending the game if the snake hits the wall or its own body. It should also include additional features like pausing and resuming the game, displaying the current score and highest score achieved, and customizable game settings for different difficulty levels.\r\n\r\n## Requirement Pool:\r\n```python\r\n[\r\n    (\"End game when snake hits the wall or its own body\", \"P0\"),\r\n    (\"Allow pausing and resuming the game\", \"P1\"),\r\n    (\"Display current score and highest score achieved\", \"P1\"),\r\n    (\"Customizable game settings for different difficulty levels\", \"P2\")\r\n]\r\n```\r\n\r\n## Anything UNCLEAR:\r\nThere are no unclear points.\r\nWarning: gpt-3.5-turbo may change over time. Returning num tokens assuming gpt-3.5-turbo-0301.\r\n2023-07-12 21:01:11.573 | INFO     | metagpt.provider.openai_api:update_cost:89 - Total running cost: $0.006 | Max budget: $3.000 | Current cost: $0.003, prompt_tokens=800, completion_tokens=636\r\nTraceback (most recent call last):\r\n  File \"/home/dope/anaconda3/envs/mgpt/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 50, in __call__\r\n    result = await fn(*args, **kwargs)\r\n  File \"/home/dope/Documents/metagpt/metagpt/actions/action.py\", line 60, in _aask_v1\r\n    instruct_content = output_class(**parsed_data)\r\n  File \"pydantic/main.py\", line 331, in pydantic.main.BaseModel.__init__\r\npydantic.error_wrappers.ValidationError: 3 validation errors for prd\r\nProduct Goals\r\n  value is not a valid list (type=type_error.list)\r\nUser Stories\r\n  value is not a valid list (type=type_error.list)\r\nCompetitive Analysis\r\n  value is not a valid list (type=type_error.list)\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/dope/Documents/metagpt/startup.py\", line 29, in <module>\r\n    fire.Fire(main)\r\n  File \"/home/dope/anaconda3/envs/mgpt/lib/python3.9/site-packages/fire-0.5.0-py3.9.egg/fire/core.py\", line 141, in Fire\r\n    component_trace = _Fire(component, args, parsed_flag_args, context, name)\r\n  File \"/home/dope/anaconda3/envs/mgpt/lib/python3.9/site-packages/fire-0.5.0-py3.9.egg/fire/core.py\", line 475, in _Fire\r\n    component, remaining_args = _CallAndUpdateTrace(\r\n  File \"/home/dope/anaconda3/envs/mgpt/lib/python3.9/site-packages/fire-0.5.0-py3.9.egg/fire/core.py\", line 691, in _CallAndUpdateTrace\r\n    component = fn(*varargs, **kwargs)\r\n  File \"/home/dope/Documents/metagpt/startup.py\", line 25, in main\r\n    asyncio.run(startup(idea, investment, n_round))\r\n  File \"/home/dope/anaconda3/envs/mgpt/lib/python3.9/asyncio/runners.py\", line 44, in run\r\n    return loop.run_until_complete(main)\r\n  File \"/home/dope/anaconda3/envs/mgpt/lib/python3.9/asyncio/base_events.py\", line 647, in run_until_complete\r\n    return future.result()\r\n  File \"/home/dope/Documents/metagpt/startup.py\", line 15, in startup\r\n    await company.run(n_round=n_round)\r\n  File \"/home/dope/Documents/metagpt/metagpt/software_company.py\", line 60, in run\r\n    await self.environment.run()\r\n  File \"/home/dope/Documents/metagpt/metagpt/environment.py\", line 64, in run\r\n    await asyncio.gather(*futures)\r\n  File \"/home/dope/Documents/metagpt/metagpt/roles/role.py\", line 229, in run\r\n    rsp = await self._react()\r\n  File \"/home/dope/Documents/metagpt/metagpt/roles/role.py\", line 200, in _react\r\n    return await self._act()\r\n  File \"/home/dope/Documents/metagpt/metagpt/roles/role.py\", line 156, in _act\r\n    response = await self._rc.todo.run(self._rc.important_memory)\r\n  File \"/home/dope/Documents/metagpt/metagpt/actions/write_prd.py\", line 138, in run\r\n    prd = await self._aask_v1(prompt, \"prd\", OUTPUT_MAPPING)\r\n  File \"/home/dope/anaconda3/envs/mgpt/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\r\n    return await fn(*args, **kwargs)\r\n  File \"/home/dope/anaconda3/envs/mgpt/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 47, in __call__\r\n    do = self.iter(retry_state=retry_state)\r\n  File \"/home/dope/anaconda3/envs/mgpt/lib/python3.9/site-packages/tenacity/__init__.py\", line 326, in iter\r\n    raise retry_exc from fut.exception()\r\ntenacity.RetryError: RetryError[<Future at 0x7f806d336a60 state=finished raised ValidationError>]",
      "state": "closed",
      "author": "luberion",
      "author_type": "User",
      "created_at": "2023-07-12T13:02:58Z",
      "updated_at": "2024-10-10T06:40:52Z",
      "closed_at": "2024-10-10T06:40:52Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/39/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "qa6300525"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/39",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/39",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:43.306127",
      "comments": [
        {
          "author": "qa6300525",
          "body": "The issue fundamentally arises from a discrepancy between the output of the LLM and our expectations. \r\n\r\nWe anticipated this:\r\n\r\n## Product Goals:\r\n```python\r\n[\r\n    \"Create ...\",\r\n    \"Provide ...\",\r\n    \"Implement ...\"\r\n]\r\n```\r\nHowever, the actual output was:\r\n\r\n## Product Goals:\r\n 1. Create ...\r",
          "created_at": "2023-07-12T23:23:02Z"
        },
        {
          "author": "geekan",
          "body": "@qa6300525 Some fields can actually be ignored, because the post-role has no dependence on them, even if the parsing error does not affect the effect",
          "created_at": "2023-07-13T01:32:45Z"
        },
        {
          "author": "geekan",
          "body": "https://github.com/geekan/MetaGPT/pull/41 almost fix this issue. pull & retry.",
          "created_at": "2023-07-13T06:26:08Z"
        }
      ]
    },
    {
      "issue_number": 75,
      "title": "How to edit already existing Repos?",
      "body": "Is there a way to edit already existing repositories?\r\nIf so what's the command for that?",
      "state": "closed",
      "author": "Gyro0o",
      "author_type": "User",
      "created_at": "2023-07-25T02:11:04Z",
      "updated_at": "2024-10-10T06:39:22Z",
      "closed_at": "2024-10-10T06:39:21Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/75/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/75",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/75",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:43.488970",
      "comments": [
        {
          "author": "geekan",
          "body": "In the process of doing it, it will take some time. but the idea is very clear",
          "created_at": "2023-07-25T16:47:08Z"
        },
        {
          "author": "better629",
          "body": "`https://docs.deepwisdom.ai/main/en/guide/in_depth_guides/incremental_development.html`",
          "created_at": "2024-10-10T06:39:21Z"
        }
      ]
    },
    {
      "issue_number": 371,
      "title": ". environment for key and variable ",
      "body": "Why is there ko .env variable for storage sou keys to protect user from potentially crime or is not not jedd want to work on that ",
      "state": "closed",
      "author": "martcpp",
      "author_type": "User",
      "created_at": "2023-09-27T08:49:59Z",
      "updated_at": "2024-10-10T05:53:58Z",
      "closed_at": "2024-10-10T05:53:58Z",
      "labels": [
        "discussion"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/371/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/371",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/371",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:45.395455",
      "comments": [
        {
          "author": "iorisa",
          "body": "Could you please provide more details? I'm not quite sure what you mean by 'ko .env'.\r\n\r\n",
          "created_at": "2023-09-29T14:15:27Z"
        },
        {
          "author": "syaikhipin",
          "body": "It means that the config.yaml will be turned into .env on the top file",
          "created_at": "2023-11-29T04:13:49Z"
        },
        {
          "author": "geekan",
          "body": "https://github.com/theskumar/python-dotenv\r\n",
          "created_at": "2023-12-21T09:21:04Z"
        },
        {
          "author": "better629",
          "body": "Since no further responses are needed, we will close it. Please reopen it if necessary.",
          "created_at": "2024-10-10T05:53:58Z"
        }
      ]
    },
    {
      "issue_number": 381,
      "title": "upgrading the installing guided to a set easy setup on the readme.md",
      "body": "i want update the installation guide with step to eg\r\ninstalling using virtual environments virtual and anacondas\r\nthis issues should be assigned to me and label hacktober let me wok on it",
      "state": "closed",
      "author": "martcpp",
      "author_type": "User",
      "created_at": "2023-10-01T01:39:16Z",
      "updated_at": "2024-10-10T05:48:54Z",
      "closed_at": "2024-10-10T05:48:54Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/381/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/381",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/381",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:45.587186",
      "comments": [
        {
          "author": "iorisa",
          "body": "Nice",
          "created_at": "2023-10-11T10:59:51Z"
        },
        {
          "author": "martcpp",
          "body": "Still waiting for it to be assigned before I start working on it @geekan ",
          "created_at": "2023-10-11T11:40:20Z"
        },
        {
          "author": "better629",
          "body": "Since no further responses are needed, we will close it. Please reopen it if necessary.",
          "created_at": "2024-10-10T05:48:54Z"
        }
      ]
    },
    {
      "issue_number": 389,
      "title": "Search example doesn't work",
      "body": "I am running the example search_google.py  and i get the following error. But I put a set & uncomment from the config file. `GOOGLE_API_KEY: \"xxx\"`   and take the # away from it so its all uncommented. technically it should work.\r\n\r\n```\r\nâ¯ python search_google.py\r\n2023-10-02 22:26:46.137 | INFO     | metagpt.config:__init__:44 - Config loading done.\r\n2023-10-02 22:26:47.243 | INFO     | metagpt.roles.seacher:_act_sp:54 - Alice(Smart Assistant): ready to SearchAndSummarize\r\n2023-10-02 22:26:47.243 | WARNING  | metagpt.actions.search_and_summarize:run:118 - Configure one of SERPAPI_API_KEY, SERPER_API_KEY, GOOGLE_API_KEY to unlock full feature\r\n```",
      "state": "closed",
      "author": "thurft",
      "author_type": "User",
      "created_at": "2023-10-02T21:39:01Z",
      "updated_at": "2024-10-10T04:11:06Z",
      "closed_at": "2024-10-10T04:11:06Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/389/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/389",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/389",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:45.754833",
      "comments": [
        {
          "author": "neilpaulmartin",
          "body": "Have you removed the \"\" also?",
          "created_at": "2023-10-04T20:27:48Z"
        },
        {
          "author": "iorisa",
          "body": "SERPAPI_API_KEY, SERPER_API_KEY, and GOOGLE_API_KEY are all reported as unavailable in the log. Please ensure that the key you used is uncommented and that the value is usable.",
          "created_at": "2023-10-11T10:25:43Z"
        },
        {
          "author": "olsn",
          "body": "The example is poorly documented, after browsing the source-code I found the following solution:\r\nThe default search-engine used in the `Searcher` is SERPAPI.\r\nIf you want to use direct google, you will have to modify the example to to the following:\r\n```\r\n...\r\nfrom metagpt.tools import SearchEngine",
          "created_at": "2023-10-17T14:25:18Z"
        }
      ]
    },
    {
      "issue_number": 467,
      "title": "Adding Contributors section to the readme.md ",
      "body": "Why Contributors section:- A \"Contributors\" section in a repo gives credit to and acknowledges \r\nthe people who have helped with the project, fosters a sense of community, and helps others\r\n know who to contact for questions or issues related to the project.\r\n\r\n**Issue type**\r\n\r\n- [âœ…] Docs\r\n\r\nExpected Behaviour:- \r\n\r\n![3](https://github.com/geekan/MetaGPT/assets/146939900/6689c0f1-c77a-47e5-b786-5b7b7cfbb448)\r\n",
      "state": "closed",
      "author": "mohitd404",
      "author_type": "User",
      "created_at": "2023-10-29T09:24:51Z",
      "updated_at": "2024-10-10T04:10:51Z",
      "closed_at": "2024-10-10T04:10:51Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/467/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "mohitd404"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/467",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/467",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:45.916352",
      "comments": [
        {
          "author": "mohitd404",
          "body": "@stellaHSR  Kindly assign this, issue to me ! I would love to work on it ! Thank you !",
          "created_at": "2023-10-29T09:25:20Z"
        },
        {
          "author": "mohitd404",
          "body": "@stellaHSR I have made the changes kindly review !!",
          "created_at": "2023-10-29T18:19:26Z"
        },
        {
          "author": "martcpp",
          "body": "Can you share outcome of change using pictures @mohitd404 ",
          "created_at": "2023-11-09T08:32:43Z"
        }
      ]
    },
    {
      "issue_number": 468,
      "title": "Adding code-of-conduct File to the repo !",
      "body": "code-of-conduct:- We propose adding a comprehensive Code of Conduct to our repository to ensure \r\na safe, respectful, and inclusive environment for all contributors and users. This code will \r\nserve as a guideline for behavior, promoting diversity, reducing conflicts, and attracting a \r\nwider range of perspectives.\r\n\r\n**Issue type**\r\n\r\n- [âœ…] Docs\r\n\r\n@ kindly assign this issue to me ! I would love to work on it ! Thank you !",
      "state": "closed",
      "author": "mohitd404",
      "author_type": "User",
      "created_at": "2023-10-29T09:26:46Z",
      "updated_at": "2024-10-10T04:10:27Z",
      "closed_at": "2024-10-10T04:10:26Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/468/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "mohitd404"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/468",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/468",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:46.095723",
      "comments": [
        {
          "author": "mohitd404",
          "body": "@stellaHSR  kindly assign this issue to me ! I would love to work on it ! Thank you !",
          "created_at": "2023-10-29T09:30:06Z"
        },
        {
          "author": "stellaHSR",
          "body": "Hi, thank you! We would like to have the code of conduct document included in our repository.",
          "created_at": "2023-10-29T16:07:10Z"
        },
        {
          "author": "mohitd404",
          "body": "@stellaHSR I have made the changes kindly review it ! ",
          "created_at": "2023-10-29T18:21:43Z"
        }
      ]
    },
    {
      "issue_number": 737,
      "title": "unsupported operand type(s) for +: 'generator' and 'list' when running researcher case",
      "body": "**Bug description**\r\n<!-- Clearly and directly describe the current bug -->\r\nTypeError: unsupported operand type(s) for +: 'generator' and 'list' occured when I tried to run the researcher case. I thought it was something wrong with my environment, but I tried it in the docker container again and still got the same error.\r\n\r\n**Environment information**\r\n- System version: ubuntu 22.04\r\n- From docker: metagpt/metagpt:latest\r\n- LLM type and model name: gpt-3.5-turbo-16k\r\n\r\n**Snippets from the key.yaml**\r\n```yaml\r\nOPENAI_API_MODEL: \"gpt-3.5-turbo-16k\"\r\nMAX_TOKENS: 4096\r\nRPM: 10\r\nTIMEOUT: 60\r\n\r\nSEARCH_ENGINE: serpapi\r\nWEB_BROWSER_ENGINE: playwright\r\n\r\n### for Research\r\nMODEL_FOR_RESEARCHER_SUMMARY: gpt-3.5-turbo\r\nMODEL_FOR_RESEARCHER_REPORT: gpt-3.5-turbo-16k\r\n```\r\n\r\n**logs**\r\n\r\n```text\r\nTraceback (most recent call last):\r\n  File \"/app/metagpt/metagpt/utils/common.py\", line 497, in wrapper\r\n    return await func(self, *args, **kwargs)\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 482, in run\r\n    rsp = await self.react()\r\n  File \"/app/metagpt/metagpt/roles/researcher.py\", line 105, in react\r\n    msg = await super().react()\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 452, in react\r\n    rsp = await self._act_by_order()\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 439, in _act_by_order\r\n    rsp = await self._act()\r\n  File \"/app/metagpt/metagpt/roles/researcher.py\", line 74, in _act\r\n    summaries = await asyncio.gather(*todos)\r\n  File \"/app/metagpt/metagpt/actions/research.py\", line 223, in run\r\n    for prompt in generate_prompt_chunk(\r\n  File \"/app/metagpt/metagpt/utils/text.py\", line 68, in generate_prompt_chunk\r\n    paragraphs = split_paragraph(paragraph) + paragraphs\r\nTypeError: unsupported operand type(s) for +: 'generator' and 'list'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"/usr/local/lib/python3.9/runpy.py\", line 87, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/app/metagpt/metagpt/roles/researcher.py\", line 126, in <module>\r\n    fire.Fire(main)\r\n  File \"/usr/local/lib/python3.9/site-packages/fire/core.py\", line 141, in Fire\r\n    component_trace = _Fire(component, args, parsed_flag_args, context, name)\r\n  File \"/usr/local/lib/python3.9/site-packages/fire/core.py\", line 466, in _Fire\r\n    component, remaining_args = _CallAndUpdateTrace(\r\n  File \"/usr/local/lib/python3.9/site-packages/fire/core.py\", line 679, in _CallAndUpdateTrace\r\n    component = loop.run_until_complete(fn(*varargs, **kwargs))\r\n  File \"/usr/local/lib/python3.9/asyncio/base_events.py\", line 647, in run_until_complete\r\n    return future.result()\r\n  File \"/app/metagpt/metagpt/roles/researcher.py\", line 124, in main\r\n    await role.run(topic)\r\n  File \"/app/metagpt/metagpt/utils/common.py\", line 513, in wrapper\r\n    raise Exception(format_trackback_info(limit=None))\r\nException: Traceback (most recent call last):\r\n  File \"/app/metagpt/metagpt/utils/common.py\", line 497, in wrapper\r\n    return await func(self, *args, **kwargs)\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 482, in run\r\n    rsp = await self.react()\r\n  File \"/app/metagpt/metagpt/roles/researcher.py\", line 105, in react\r\n    msg = await super().react()\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 452, in react\r\n    rsp = await self._act_by_order()\r\n  File \"/app/metagpt/metagpt/roles/role.py\", line 439, in _act_by_order\r\n    rsp = await self._act()\r\n  File \"/app/metagpt/metagpt/roles/researcher.py\", line 74, in _act\r\n    summaries = await asyncio.gather(*todos)\r\n  File \"/app/metagpt/metagpt/actions/research.py\", line 223, in run\r\n    for prompt in generate_prompt_chunk(\r\n  File \"/app/metagpt/metagpt/utils/text.py\", line 68, in generate_prompt_chunk\r\n    paragraphs = split_paragraph(paragraph) + paragraphs\r\nTypeError: unsupported operand type(s) for +: 'generator' and 'list'\r\n\r\n[\"dataiku\", \"datarobot\"][\"dataiku vs datarobot\", \"comparison between dataiku and datarobot\", \"features of dataiku and datarobot\", \"pros and cons of dataiku and datarobot\"][1, 2, 3, 0, 4][1, 2, 3, 0, 4][0, 1, 2, 4, 5, 6][0, 2, 3, 5, 6]\r\n```\r\n",
      "state": "closed",
      "author": "tappat225",
      "author_type": "User",
      "created_at": "2024-01-12T07:37:25Z",
      "updated_at": "2024-10-10T03:54:28Z",
      "closed_at": "2024-10-10T03:54:28Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/737/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "shenchucheng"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/737",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/737",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:46.282328",
      "comments": [
        {
          "author": "tappat225",
          "body": "Solved. It turns out that there is no value check for the max_token which is calculated from the code `max_token = TOKEN_MAX.get(model_name, 2048) - reserved - 100`. As I set `MAX_TOKENS: 4096` in `key.yaml` to 4096, it leads to the calculation result to be less than 0.\r\n\r\n**Solution**\r\nSet `MAX_TOK",
          "created_at": "2024-01-15T10:13:28Z"
        },
        {
          "author": "geekan",
          "body": "@shenchucheng Can you confirm if this issue has been resolved?",
          "created_at": "2024-03-21T11:51:55Z"
        },
        {
          "author": "shenchucheng",
          "body": "> @shenchucheng Can you confirm if this issue has been resolved?\r\n\r\n@geekan Fixxed by https://github.com/geekan/MetaGPT/pull/867.",
          "created_at": "2024-03-22T12:09:07Z"
        }
      ]
    },
    {
      "issue_number": 816,
      "title": "Error because of exceeding max completion tokens",
      "body": "I'm trying out the researcher role example. The code is running fine generating questions, doing web search etc. After a while however it throws an error because it is exceeding the max completion tokens. This happens with every example starting prompt I tried.  I understand that the latest GPT-4 Turbo model has a 128k input tokens context window, but only a 4,096 tokens completion output window. There does not seem to be an easy fix - I checked. \r\n\r\nThings I've tried:\r\n- specifiying my research prompt\r\n- increasing MAX_TOKENS variable (but that was silly as it only controls the input context window)\r\n- setting the long term memory variable to false\r\n- adjusting the class ConductResearch(Action) to try and create chunks of the completions but didn't work out\r\n\r\nAny other ideas?",
      "state": "closed",
      "author": "pas-mllr",
      "author_type": "User",
      "created_at": "2024-01-31T23:31:08Z",
      "updated_at": "2024-10-10T02:54:26Z",
      "closed_at": "2024-10-10T02:54:26Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/816/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "shenchucheng"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/816",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/816",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:46.441930",
      "comments": [
        {
          "author": "pas-mllr",
          "body": "@geekan kind sir?",
          "created_at": "2024-02-01T17:45:17Z"
        },
        {
          "author": "geekan",
          "body": "@pas-mllr thanks for your kind comments, i've reproduced the bug.\r\n\r\n@shenchucheng could you plz check this?",
          "created_at": "2024-03-20T14:47:25Z"
        }
      ]
    },
    {
      "issue_number": 1009,
      "title": "the Bug  sourceï¼špython examples/di/imitate_webpage.py   is   Incomplete, shutdown  error info",
      "body": "**Bug description**\r\n\r\n\r\n- LLM type and model name:\r\n- openai\r\n-  model: \"gpt-4-1106-preview\" \r\n- Python 3.10:\r\n \r\n\r\n\r\n- packages version:\r\n- MetaGPT  0.76  \r\n\r\n \r\n**Screenshots or code logs**\r\n`File \"/home/miniconda3/envs/metaGpt/lib/python3.11/site-packages/metagpt/roles/di/data_interpreter.py\", line 46, in _act_on_task\r\n    code, result, is_success = await self._write_and_exec_code()\r\n                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/miniconda3/envs/metaGpt/lib/python3.11/site-packages/metagpt/roles/di/data_interpreter.py\", line 58, in _write_and_exec_code\r\n    self.working_memory.add(Message(content=code[\"code\"], role=\"assistant\", cause_by=cause_by))\r\n                                            ~~~~^^^^^^^^\r\nKeyError: 'code'\r\n\r\nDuring handling of the above exception, another exception occurred:`\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/data/MetaGPT/examples/di/imitate_webpage.py\", line 25, in <module>\r\n    asyncio.run(main())\r\n  File \"/home/miniconda3/envs/metaGpt/lib/python3.11/asyncio/runners.py\", line 190, in run\r\n    return runner.run(main)\r\n           ^^^^^^^^^^^^^^^^\r\n  File \"/home/miniconda3/envs/metaGpt/lib/python3.11/asyncio/runners.py\", line 118, in run\r\n    return self._loop.run_until_complete(task)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/miniconda3/envs/metaGpt/lib/python3.11/asyncio/base_events.py\", line 653, in run_until_complete\r\n    return future.result()\r\n           ^^^^^^^^^^^^^^^\r\n  File \"/data/MetaGPT/examples/di/imitate_webpage.py\", line 19, in main\r\n    await di.run(prompt)\r\n  File \"/home/miniconda3/envs/metaGpt/lib/python3.11/site-packages/metagpt/utils/common.py\", line 585, in wrapper\r\n    raise Exception(format_trackback_info(limit=None))\r\nException: Traceback (most recent call last):\r\n  File \"/home/miniconda3/envs/metaGpt/lib/python3.11/site-packages/metagpt/utils/common.py\", line 563, in wrapper\r\n    return await func(self, *args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/miniconda3/envs/metaGpt/lib/python3.11/site-packages/metagpt/roles/role.py\", line 558, in run\r\n    rsp = await self.react()\r\n          ^^^^^^^^^^^^^^^^^^\r\n  File \"/home/miniconda3/envs/metaGpt/lib/python3.11/site-packages/metagpt/roles/role.py\", line 529, in react\r\n    rsp = await self._plan_and_act()\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/miniconda3/envs/metaGpt/lib/python3.11/site-packages/metagpt/roles/role.py\", line 497, in _plan_and_act\r\n    task_result = await self._act_on_task(task)\r\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/miniconda3/envs/metaGpt/lib/python3.11/site-packages/metagpt/roles/di/data_interpreter.py\", line 46, in _act_on_task\r\n    code, result, is_success = await self._write_and_exec_code()\r\n                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/miniconda3/envs/metaGpt/lib/python3.11/site-packages/metagpt/roles/di/data_interpreter.py\", line 58, in _write_and_exec_code\r\n    self.working_memory.add(Message(content=code[\"code\"], role=\"assistant\", cause_by=cause_by))\r\n                                            ~~~~^^^^^^^^\r\nKeyError: 'code'\r\n\r\n(metaGpt) root@xjspace:/data/MetaGPT# [IPKernelApp] WARNING | Parent appears to have exited, shutting down.\r\n",
      "state": "closed",
      "author": "xjspace",
      "author_type": "User",
      "created_at": "2024-03-14T07:03:15Z",
      "updated_at": "2024-10-10T02:45:10Z",
      "closed_at": "2024-10-10T02:45:09Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1009/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "garylin2099"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1009",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1009",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:46.633053",
      "comments": [
        {
          "author": "garylin2099",
          "body": "Previous version of `code` variable is a dict, but it is changed to a string and properly handled. Try pulling the latest codes and this issue should be fixed.",
          "created_at": "2024-03-14T09:16:12Z"
        },
        {
          "author": "xjspace",
          "body": "> Previous version of `code` variable is a dict, but it is changed to a string and properly handled. Try pulling the latest codes and this issue should be fixed.\r\nI'll give it a try\r\n",
          "created_at": "2024-03-14T12:04:31Z"
        },
        {
          "author": "geekan",
          "body": "@xjspace Can you confirm that this issue has been resolved?",
          "created_at": "2024-03-21T03:35:30Z"
        },
        {
          "author": "better629",
          "body": "Due to the lack of updates or replies by the user for a long time, we will close it. Please reopen it if necessary.",
          "created_at": "2024-10-10T02:45:09Z"
        }
      ]
    },
    {
      "issue_number": 1013,
      "title": "ProjectRepo raise `ValueError(\"Invalid root\")` when using `--recover-path`",
      "body": "**Bug description**\r\n![image](https://github.com/geekan/MetaGPT/assets/46912756/9f1a6626-6e24-407b-8cb6-d1303c5dd32a)",
      "state": "closed",
      "author": "iorisa",
      "author_type": "User",
      "created_at": "2024-03-15T09:01:29Z",
      "updated_at": "2024-10-10T02:44:25Z",
      "closed_at": "2024-10-10T02:44:25Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1013/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 1
      },
      "assignees": [
        "better629"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1013",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1013",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:46.832260",
      "comments": []
    },
    {
      "issue_number": 1023,
      "title": "AttributeError: 'NoneType' object has no attribute 'startswith' when running \"Researcher\" example with Gemini",
      "body": "**Bug description**\r\nRunning an example provided on the web site - https://docs.deepwisdom.ai/main/en/guide/use_cases/agent/researcher.html - fails when using \"gemini\" model:\r\n\r\n**Environment information**\r\nSystem version - Windows 11\r\nPython version - Python 3.10.9\r\nLLM type and model - Gemini\r\n\r\nInstallation method: \"development mode\"\r\ngit clone https://github.com/geekan/MetaGPT.git\r\n\r\nconfig2.example.yaml:\r\nllm:\r\n  api_type: 'gemini'\r\n  api_key: 'XXXXXXXXXXXXXXXXXXXXXXXXXXX'\r\n\r\nsearch:\r\n  api_type: \"google\"\r\n  api_key: \"XXXXXXXXXXXXXXXXXXXXXXXXXXX\"\r\n  cse_id: \"XXXXXXXXXXXXXX\"\r\n\r\n\r\n\r\n(metagpt) PS C:\\Users\\user\\code\\test\\MetaGPT> python -m metagpt.roles.researcher \"tensorflow vs. pytorch\"\r\n2024-03-17 18:28:13.795 | INFO     | metagpt.const:get_metagpt_package_root:29 - Package root set to C:\\Users\\user\\code\\test\\MetaGPT\r\n2024-03-17 18:28:23.681 | INFO     | __main__:_act:56 - David(Researcher): to do CollectLinks(David)\r\n[\"Machine learning\", \"Natural language processing\"]\r\n2024-03-17 18:28:24.807 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.000 | Max budget: $10.000 | Current cost: $0.000, prompt_tokens: 37, completion_tokens: 10\r\n2024-03-17 18:28:25.233 | WARNING  | metagpt.utils.common:wrapper:647 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\utils\\common.py\", line 638, in wrapper\r\n    return await func(self, *args, **kwargs)\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\roles\\role.py\", line 548, in run\r\n    rsp = await self.react()\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\roles\\researcher.py\", line 105, in react\r\n    msg = await super().react()\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\roles\\role.py\", line 517, in react\r\n    rsp = await self._act_by_order()\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\roles\\role.py\", line 471, in _act_by_order\r\n    rsp = await self._act()\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\roles\\researcher.py\", line 67, in _act\r\n    links = await todo.run(topic, 4, 4)\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\actions\\research.py\", line 137, in run\r\n    prompt = reduce_message_length(gen_msg(), model_name, system_text, config.llm.max_token)\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\utils\\text.py\", line 26, in reduce_message_length\r\n    max_token = TOKEN_MAX.get(model_name, 2048) - count_string_tokens(system_text, model_name) - reserved\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\utils\\token_counter.py\", line 262, in count_string_tokens\r\n    encoding = tiktoken.encoding_for_model(model_name)\r\n  File \"C:\\Users\\user\\scoop\\apps\\miniconda3\\current\\envs\\metagpt\\lib\\site-packages\\tiktoken\\model.py\", line 97, in encoding_for_model\r\n    return get_encoding(encoding_name_for_model(model_name))\r\n  File \"C:\\Users\\user\\scoop\\apps\\miniconda3\\current\\envs\\metagpt\\lib\\site-packages\\tiktoken\\model.py\", line 80, in encoding_name_for_model\r\n    if model_name.startswith(model_prefix):\r\nAttributeError: 'NoneType' object has no attribute 'startswith'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\user\\scoop\\apps\\miniconda3\\current\\envs\\metagpt\\lib\\runpy.py\", line 196, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"C:\\Users\\user\\scoop\\apps\\miniconda3\\current\\envs\\metagpt\\lib\\runpy.py\", line 86, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\roles\\researcher.py\", line 126, in <module>\r\n    fire.Fire(main)\r\n  File \"C:\\Users\\user\\scoop\\apps\\miniconda3\\current\\envs\\metagpt\\lib\\site-packages\\fire\\core.py\", line 141, in Fire\r\n    component_trace = _Fire(component, args, parsed_flag_args, context, name)\r\n  File \"C:\\Users\\user\\scoop\\apps\\miniconda3\\current\\envs\\metagpt\\lib\\site-packages\\fire\\core.py\", line 466, in _Fire\r\n    component, remaining_args = _CallAndUpdateTrace(\r\n  File \"C:\\Users\\user\\scoop\\apps\\miniconda3\\current\\envs\\metagpt\\lib\\site-packages\\fire\\core.py\", line 679, in _CallAndUpdateTrace\r\n    component = loop.run_until_complete(fn(*varargs, **kwargs))\r\n  File \"C:\\Users\\user\\scoop\\apps\\miniconda3\\current\\envs\\metagpt\\lib\\asyncio\\base_events.py\", line 649, in run_until_complete\r\n    return future.result()\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\roles\\researcher.py\", line 124, in main\r\n    await role.run(topic)\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\utils\\common.py\", line 660, in wrapper\r\n    raise Exception(format_trackback_info(limit=None))\r\nException: Traceback (most recent call last):\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\utils\\common.py\", line 638, in wrapper\r\n    return await func(self, *args, **kwargs)\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\roles\\role.py\", line 548, in run\r\n    rsp = await self.react()\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\roles\\researcher.py\", line 105, in react\r\n    msg = await super().react()\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\roles\\role.py\", line 517, in react\r\n    rsp = await self._act_by_order()\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\roles\\role.py\", line 471, in _act_by_order\r\n    rsp = await self._act()\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\roles\\researcher.py\", line 67, in _act\r\n    links = await todo.run(topic, 4, 4)\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\actions\\research.py\", line 137, in run\r\n    prompt = reduce_message_length(gen_msg(), model_name, system_text, config.llm.max_token)\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\utils\\text.py\", line 26, in reduce_message_length\r\n    max_token = TOKEN_MAX.get(model_name, 2048) - count_string_tokens(system_text, model_name) - reserved\r\n  File \"C:\\Users\\user\\code\\test\\MetaGPT\\metagpt\\utils\\token_counter.py\", line 262, in count_string_tokens\r\n    encoding = tiktoken.encoding_for_model(model_name)\r\n  File \"C:\\Users\\user\\scoop\\apps\\miniconda3\\current\\envs\\metagpt\\lib\\site-packages\\tiktoken\\model.py\", line 97, in encoding_for_model\r\n    return get_encoding(encoding_name_for_model(model_name))\r\n  File \"C:\\Users\\user\\scoop\\apps\\miniconda3\\current\\envs\\metagpt\\lib\\site-packages\\tiktoken\\model.py\", line 80, in encoding_name_for_model\r\n    if model_name.startswith(model_prefix):\r\nAttributeError: 'NoneType' object has no attribute 'startswith'\r\n\r\n\r\n\r\n",
      "state": "closed",
      "author": "vmsysadm",
      "author_type": "User",
      "created_at": "2024-03-18T00:38:48Z",
      "updated_at": "2024-10-10T02:43:46Z",
      "closed_at": "2024-10-10T02:43:46Z",
      "labels": [
        "documentation"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1023/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "geekan"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1023",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1023",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:46.832279",
      "comments": [
        {
          "author": "iorisa",
          "body": "This log indicates that `model_name` is None:\r\n```text\r\nif model_name.startswith(model_prefix):\r\nAttributeError: 'NoneType' object has no attribute 'startswith'\r\n```\r\nAccording to the source code:\r\n```python\r\n        model_name = config.llm.model\r\n        prompt = reduce_message_length(gen_msg(), mo",
          "created_at": "2024-03-19T05:27:45Z"
        },
        {
          "author": "vmsysadm",
          "body": "Thank you for the information, that works! You may want to update your \"Configuration\" page https://docs.deepwisdom.ai/main/en/guide/get_started/configuration.html to mention that the Gemini model must be specified explicitly:\r\n\r\nGoogle Gemini\r\n\r\nsupports default model gemini-pro\r\nllm:\r\n  api_type: ",
          "created_at": "2024-03-19T19:14:01Z"
        },
        {
          "author": "geekan",
          "body": "Added to document. Will show up when it is redeployed",
          "created_at": "2024-03-21T03:29:08Z"
        }
      ]
    },
    {
      "issue_number": 1028,
      "title": "What kind of computer can run this model?",
      "body": "Can mac studio run this model?\r\nHow much memory dose this memory need?",
      "state": "closed",
      "author": "learningendless",
      "author_type": "User",
      "created_at": "2024-03-18T08:45:25Z",
      "updated_at": "2024-10-10T02:43:23Z",
      "closed_at": "2024-10-10T02:43:23Z",
      "labels": [
        "dataset"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1028/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "voidking"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1028",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1028",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:47.021097",
      "comments": [
        {
          "author": "devinambron",
          "body": "Yes, a Mac Studio with at least 16 GB RAM can run MetaGPT for basic tasks. Depending on what you're utilizing the model for, 32 GB RAM or more might work best.",
          "created_at": "2024-03-18T21:42:29Z"
        },
        {
          "author": "voidking",
          "body": "MetaGPT will call the remote LLM during operation, so it requires very few local resources.\r\nIf you just run MetaGPT on Mac Stutio, I think 4C8G is completely sufficient. \r\nIf you just run MetaGPT on Linux, I think 1C2G is sufficient.",
          "created_at": "2024-03-21T03:31:15Z"
        },
        {
          "author": "geekan",
          "body": "Maybe we need to have a list of different task success rates for different language models. This may be a data set requirement, but it is reasonable",
          "created_at": "2024-03-21T05:28:33Z"
        },
        {
          "author": "xenon0906",
          "body": "> Yes, a Mac Studio with at least 16 GB RAM can run MetaGPT for basic tasks. Depending on what you're utilizing the model for, 32 GB RAM or more might work best.\r\n\r\nI believe it totally depends on the size of the dataset and number of time the data is gonna be train in the model \r\nAs per my consider",
          "created_at": "2024-09-18T05:26:15Z"
        }
      ]
    },
    {
      "issue_number": 1052,
      "title": "Snake demo issue; FileNotFoundError: [Errno 2] No such file or directory: 'node_modules/.bin/browsers'",
      "body": "\r\nWhen I tried to run a demo using WSLg in Docker on WSL, I encountered the following error:\r\n\r\nHow can I fix this issue?\r\n\r\n```bash\r\n2024-03-20 02:39:20.007 | INFO     | metagpt.utils.file_repository:save:60 - save to: /app/metagpt/workspace/20240320023843/resources/prd/20240320023917.md\r\n2024-03-20 02:39:20.009 | INFO     | metagpt.roles.role:_act:399 - Bob(Architect): to do WriteDesign(WriteDesign)\r\n2024-03-20 02:39:20.064 | INFO     | metagpt.actions.design_api:run:67 - Nothing has changed.\r\n2024-03-20 02:39:20.066 | INFO     | metagpt.roles.role:_act:399 - Eve(Project Manager): to do WriteTasks(WriteTasks)\r\n2024-03-20 02:39:20.121 | INFO     | metagpt.actions.project_management:run:54 - Nothing has changed.\r\n2024-03-20 02:39:20.256 | INFO     | metagpt.utils.git_repository:archive:168 - Archive: ['node_modules/.bin/browsers', 'node_modules/.bin/extract-zip', 'node_modules/.bin/js-yaml', 'node_modules/.bin/mmdc', 'node_modules/.package-lock.json', 'node_modules/@babel/code-frame/LICENSE', 'node_modules/@babel/code-frame/README.md', 'node_modules/@babel/code-frame/node_modules/ansi-styles/index.js', 'node_modules/@babel/code-frame/node_modules/ansi-styles/license', 'node_modules/@babel/code-frame/node_modules/ansi-styles/package.json', 'node_modules/@babel/code-frame/node_modules/ansi-styles/readme.md', 'node_modules/@babel/code-frame/node_modules/chalk/index.js', 'nod\r\n\r\n...\r\n\r\n2024-03-20 02:39:20.281 | ERROR    | metagpt.utils.common:wrapper:553 - Exception occurs, start to serialize the project, exp:\r\nTraceback (most recent call last):\r\n  File \"/app/metagpt/metagpt/utils/common.py\", line 548, in wrapper\r\n    result = await func(self, *args, **kwargs)\r\n  File \"/app/metagpt/metagpt/team.py\", line 135, in run\r\n    self.env.archive(auto_archive)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'node_modules/.bin/browsers'\r\n```",
      "state": "closed",
      "author": "Sunwood-ai-labs",
      "author_type": "User",
      "created_at": "2024-03-20T02:44:53Z",
      "updated_at": "2024-10-10T02:41:30Z",
      "closed_at": "2024-10-10T02:41:30Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1052/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "better629"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1052",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1052",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:47.183948",
      "comments": [
        {
          "author": "iorisa",
          "body": "It seems caused by this issue: #1035.\r\nTry out main branch.",
          "created_at": "2024-03-20T03:29:42Z"
        }
      ]
    },
    {
      "issue_number": 1100,
      "title": "debate example fail to work with gemini",
      "body": "**Bug description**\r\ndebate example throws error with gemini-pro 1.5.\r\nWebsearch works with gemini-pro\r\n\r\n**Bug solved method**\r\n\r\n**Environment information**\r\nPython 3.9\r\nConda\r\n\r\n- LLM type and model name: Gemini-Pro\r\n- System version:\r\n- Python version: 3.9\r\n\r\n\r\n**Screenshots or logs**\r\npython3 debate.py \"Talk about Artificial General Intelligence\"\r\n2024-03-25 17:57:01.666 | INFO     | metagpt.const:get_metagpt_package_root:29 - Package root set to /Users/samsaha2\r\n2024-03-25 17:57:03.800 | INFO     | metagpt.team:invest:90 - Investment: $3.0.\r\n2024-03-25 17:57:03.801 | INFO     | __main__:_act:63 - Biden(Democrat): to do SpeakAloud(SpeakAloud)\r\n2024-03-25 17:57:06.072 | WARNING  | metagpt.utils.common:wrapper:572 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.\r\n2024-03-25 17:57:06.081 | ERROR    | metagpt.utils.common:wrapper:554 - Exception occurs, start to serialize the project, exp:\r\nTraceback (most recent call last):\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/metagpt/utils/common.py\", line 563, in wrapper\r\n    return await func(self, *args, **kwargs)\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/metagpt/roles/role.py\", line 558, in run\r\n    rsp = await self.react()\r\nValueError: The `response.text` quick accessor only works for simple (single-`Part`) text responses. This response is not simple text.Use the `result.parts` accessor or the full `result.candidates[index].content.parts` lookup instead.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/metagpt/utils/common.py\", line 549, in wrapper\r\n    result = await func(self, *args, **kwargs)\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/metagpt/team.py\", line 134, in run\r\n    await self.env.run()\r\nException: Traceback (most recent call last):\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/metagpt/utils/common.py\", line 563, in wrapper\r\n    return await func(self, *args, **kwargs)\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/metagpt/roles/role.py\", line 558, in run\r\n    rsp = await self.react()\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/metagpt/roles/role.py\", line 525, in react\r\n    rsp = await self._react()\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/metagpt/roles/role.py\", line 471, in _react\r\n    rsp = await self._act()\r\n  File \"/Users/samsaha2/debate.py\", line 70, in _act\r\n    rsp = await todo.run(context=context, name=self.name, opponent_name=self.opponent_name)\r\n  File \"/Users/samsaha2/debate.py\", line 41, in run\r\n    rsp = await self._aask(prompt)\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/metagpt/actions/action.py\", line 93, in _aask\r\n    return await self.llm.aask(prompt, system_msgs)\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/metagpt/provider/base_llm.py\", line 89, in aask\r\n    rsp = await self.acompletion_text(message, stream=stream, timeout=timeout)\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\r\n    return await fn(*args, **kwargs)\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 47, in __call__\r\n    do = self.iter(retry_state=retry_state)\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/tenacity/__init__.py\", line 314, in iter\r\n    return fut.result()\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/concurrent/futures/_base.py\", line 439, in result\r\n    return self.__get_result()\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/concurrent/futures/_base.py\", line 391, in __get_result\r\n    raise self._exception\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 50, in __call__\r\n    result = await fn(*args, **kwargs)\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/metagpt/provider/google_gemini_api.py\", line 147, in acompletion_text\r\n    return await self._achat_completion_stream(messages)\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/metagpt/provider/google_gemini_api.py\", line 127, in _achat_completion_stream\r\n    content = chunk.text\r\n  File \"/Users/samsaha2/miniconda3/envs/metagpt/lib/python3.9/site-packages/google/generativeai/types/generation_types.py\", line 328, in text\r\n    raise ValueError(\r\nValueError: The `response.text` quick accessor only works for simple (single-`Part`) text responses. This response is not simple text.Use the `result.parts` accessor or the full `result.candidates[index].content.parts` lookup instead.\r\n\r\n\r\n",
      "state": "closed",
      "author": "iitrsamrat",
      "author_type": "User",
      "created_at": "2024-03-25T12:31:43Z",
      "updated_at": "2024-10-10T02:40:14Z",
      "closed_at": "2024-10-10T02:40:14Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1100/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1100",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1100",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:47.390938",
      "comments": [
        {
          "author": "iorisa",
          "body": "It's blocked by gemini:\r\n```\r\n[category: HARM_CATEGORY_SEXUALLY_EXPLICIT\r\nprobability: NEGLIGIBLE\r\n, category: HARM_CATEGORY_HATE_SPEECH\r\nprobability: NEGLIGIBLE\r\n, category: HARM_CATEGORY_HARASSMENT\r\nprobability: NEGLIGIBLE\r\n, category: HARM_CATEGORY_DANGEROUS_CONTENT\r\nprobability: NEGLIGIBLE\r\n]\r\n`",
          "created_at": "2024-03-25T13:24:05Z"
        },
        {
          "author": "iitrsamrat",
          "body": "My prompt for debate is the following.\r\n\"\r\n\"Talk about Artificial General Intelligence\"\r\n\"\r\nHow to debug if it is blocked I am just running on command line as below.\r\n\r\npython3 debate.py \"Talk about Artificial General Intelligence\"",
          "created_at": "2024-03-25T13:33:27Z"
        },
        {
          "author": "geekan",
          "body": "Try `examples/debate_simple.py`?\r\n\r\nremove line 17 and line 19 to use your config in the file.",
          "created_at": "2024-03-25T13:38:03Z"
        },
        {
          "author": "iitrsamrat",
          "body": "\r\nGot the following error.\r\n\r\nModified debate_simple.py\r\n`\r\n#!/usr/bin/env python\r\n# -*- coding: utf-8 -*-\r\n\"\"\"\r\n@Time    : 2023/12/22\r\n@Author  : alexanderwu\r\n@File    : debate_simple.py\r\n\"\"\"\r\nimport asyncio\r\n\r\nfrom metagpt.actions import Action\r\nfrom metagpt.config2 import Config\r\nfrom metagpt.env",
          "created_at": "2024-03-25T13:44:04Z"
        },
        {
          "author": "iorisa",
          "body": "I'll add some codes to throw a `ValueError` exception when gemini blocked the chat, in order to notify the external user.",
          "created_at": "2024-03-25T13:51:29Z"
        }
      ]
    },
    {
      "issue_number": 1117,
      "title": "å…³äºç‹¼äººé¡¹ç›®çš„è·Ÿè¿›",
      "body": "ä½ ä»¬å¥½ï¼Œæˆ‘å·²ç»æ ¹æ®ä½ ä»¬ä¹‹å‰çš„ç‹¼äººé¡¹ç›®è¿›è¡Œæ”¹è¿›ï¼Œå¹¶åšäº†ä¸€äº›æœ‰æ„æ€çš„å·¥ä½œï¼Œä½†æ˜¯æˆ‘è§‚å¯Ÿåˆ°metagptæ–°ç‰ˆæœ¬æœ‰å¾ˆå¤šæ¿€åŠ¨äººå¿ƒçš„åŠŸèƒ½ï¼Œä½†ç‹¼äººé¡¹ç›®è·Ÿè¿™ä¸ªç‰ˆæœ¬å·®å¼‚è¿‡å¤§ï¼Œå¹¶ä¸èƒ½ä½¿ç”¨è¿™äº›æ–°åŠŸèƒ½ï¼Œå› æ­¤æƒ³é—®ä¸€ä¸‹å…³äºç‹¼äººé¡¹ç›®çš„è¿ç§»ï¼Œè¿‘æœŸæ˜¯å¦æœ‰æ‰“ç®—å»åšå‘¢ï¼Ÿ\r\nä¸‡åˆ†æ„Ÿè°¢ã€‚",
      "state": "closed",
      "author": "nameBai",
      "author_type": "User",
      "created_at": "2024-03-27T04:53:39Z",
      "updated_at": "2024-10-10T02:36:41Z",
      "closed_at": "2024-10-10T02:36:41Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1117/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "better629"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1117",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1117",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:47.647871",
      "comments": [
        {
          "author": "geekan",
          "body": "Can you tell us about â€œinteresting jobsâ€? Then we might know how to modify it",
          "created_at": "2024-03-27T07:40:45Z"
        },
        {
          "author": "iorisa",
          "body": "å¯ä»¥æPRï¼Œæˆ–è€…æŠŠé—®é¢˜ä»£ç è´´å‡ºæ¥ï¼Œæˆ‘å‘Šä½ æ€ä¹ˆå‡çº§åˆ°æœ€æ–°metagptä»£ç ã€‚",
          "created_at": "2024-03-27T07:57:14Z"
        },
        {
          "author": "nameBai",
          "body": "å¥½çš„ï¼Œæˆ‘å…ˆçœ‹çœ‹ï¼Œæœ‰é—®é¢˜æˆ‘ä¼šæå‡º",
          "created_at": "2024-03-27T08:09:56Z"
        },
        {
          "author": "nameBai",
          "body": "> Can you tell us about â€œinteresting jobsâ€? Then we might know how to modify it\r\n\r\næˆ‘ä»¬æ‰“ç®—åˆ©ç”¨metagptåšä¸€ä¸ªæ•™å­¦åœºæ™¯çš„å¤æ‚æ¨¡æ‹Ÿï¼Œæ–°çš„æ¡†æ¶è°ƒæ•´äº†è§’è‰²è®°å¿†å’Œç¯å¢ƒçš„é€»è¾‘ï¼Œæ¯ä¸ªè§’è‰²ä½¿ç”¨ä¸ç”¨çš„llm_configä»¥åŠåŸç”Ÿæ”¯æŒå„ç±»çš„å•†ä¸šå¤§æ¨¡å‹çš„ç‰¹ç‚¹ï¼Œè¿™éƒ½æ˜¯åŸæœ‰æ¡†æ¶æ²¡æœ‰çš„ã€‚",
          "created_at": "2024-03-27T08:42:04Z"
        },
        {
          "author": "geekan",
          "body": "Do you mean tutorial on werewolf scene? Or it's a real education scene?",
          "created_at": "2024-03-28T07:02:05Z"
        }
      ]
    },
    {
      "issue_number": 1132,
      "title": "Minecraft Environment which is contained in the release version is not adapted by Windows",
      "body": "The Release version somehow put Minecraft (which is a independent branch, not in the main branch) in to it.\r\nThis \"Minecraft Environment\" has several packages which are only supported in Linux such as Langchain.\r\nIf you just use `pip install metagpt` in Windows, you will get error \"No module named pwd\" as the package pwd is Unix Specific Service\r\nTry to use manual installation rather than pip. And please fix this thank you.\r\n\r\nä¸­æ–‡ç‰ˆæœ¬ï¼ˆChinese Versionï¼‰ï¼š\r\nå‘è¡Œç‰ˆæœ¬ä¸­ï¼Œä¸çŸ¥æ€ä¹ˆæçš„æŠŠMinecrafté‚£ä¸ªBranchæ‹¿è¿›æ¥äº†ã€‚è¿™ä¸ªBranché‡Œæœ‰ä¸€äº›Linuxä¾èµ–ï¼Œä¾‹å¦‚Langchainã€‚ç›´æ¥`pip install metagpt`ä¼šæŠ¥é”™\"No module named pwd\"ï¼Œå»ºè®®æ‰‹åŠ¨å®‰è£…ã€‚è¯·ä½œè€…ä¿®å¤è¿™ä¸ªé—®é¢˜ï¼Œç§»é™¤Minecraftç¯å¢ƒï¼Œæˆ–è€…è®©Minecraftç¯å¢ƒå˜å¾—åŒæ—¶é€‚é…Windowså’ŒLinuxã€‚\r\n",
      "state": "closed",
      "author": "RyanLoil",
      "author_type": "User",
      "created_at": "2024-03-28T10:07:26Z",
      "updated_at": "2024-10-10T02:35:42Z",
      "closed_at": "2024-10-10T02:35:42Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 16,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1132/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "better629"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1132",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1132",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:47.843094",
      "comments": [
        {
          "author": "geekan",
          "body": "@RyanLoil We should not have any dependencies on langchain (main branch) now. Can you post your specific environment and package version?",
          "created_at": "2024-03-28T14:56:42Z"
        },
        {
          "author": "RyanLoil",
          "body": "Here is the dependencies requirement list from [Metagpt 0.7.7 release version](https://files.pythonhosted.org/packages/bc/22/732a40ccd2da1164e5ce0b4e57fbf6ac530aae1e390fa475673cf862fb64/metagpt-0.7.7.tar.gz) from pypi\r\n\r\n> aiohttp==3.8.4\r\n> channels==4.0.0\r\n> faiss_cpu==1.7.4\r\n> fire==0.4.0\r\n> typer",
          "created_at": "2024-03-29T05:43:12Z"
        },
        {
          "author": "RyanLoil",
          "body": "Also I highly recommended that please do not use the dependencies versions which are too specific, many frameworks got abandoned due to this issue.",
          "created_at": "2024-03-29T05:45:45Z"
        },
        {
          "author": "better629",
          "body": "@RyanLoil maybe you can try main which removed langchain.",
          "created_at": "2024-03-29T06:17:52Z"
        },
        {
          "author": "RyanLoil",
          "body": "> @RyanLoil maybe you can try main which removed langchain.\r\n\r\nI have already done that. Just in case I submitted this issue.",
          "created_at": "2024-03-29T06:19:06Z"
        }
      ]
    },
    {
      "issue_number": 1240,
      "title": "æ€ä¹ˆåœ¨MetaGPTåŸºç¡€ä¸Šä½¿ç”¨ComfyUI? æ€ä¹ˆæŠŠåŸºæœ¬å¤§æ¨¡å‹æ¥å£å˜æˆOllama?",
      "body": "**Feature description**\r\n<!-- Clear and direct description of the functionality of the currently submitted or proposed feature -->\r\næ€ä¹ˆåœ¨MetaGPTåŸºç¡€ä¸Šä½¿ç”¨ComfyUI? æ€ä¹ˆæŠŠåŸºæœ¬å¤§æ¨¡å‹æ¥å£å˜æˆOllama?\r\n\r\n**Your Feature**\r\n<!-- Describe the idea or process of implementing the current feature. Of course, you can also paste the URL address of your Pull Request. -->\r\n<!-- When submitting features, you need to complete the corresponding doc/tests/examples to facilitate verification by reviewers. -->\r\n\r\nç”»å›¾:\r\n\r\n`ollama` <-> `MetaGPT` <->  `ComfyUI` \r\n\r\nä»¥æ­¤ç»„è£…ä¸€ä¸ªä»£ç†å·¥ä½œæµ?",
      "state": "closed",
      "author": "qwas982",
      "author_type": "User",
      "created_at": "2024-05-01T11:51:21Z",
      "updated_at": "2024-10-10T02:12:09Z",
      "closed_at": "2024-10-10T02:12:08Z",
      "labels": [
        "enhancement"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1240/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "better629"
      ],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1240",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1240",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:48.068178",
      "comments": [
        {
          "author": "qwas982",
          "body": "ComfyUIåŸæ¥æ˜¯ç”»ç”»ä¸“ç”¨,\r\næˆ‘æƒ³æŠŠå®ƒç”¨ä½œcoding. \r\nå¦‚ä½•åš?",
          "created_at": "2024-05-01T11:52:56Z"
        },
        {
          "author": "better629",
          "body": "using ollama according to `https://docs.deepwisdom.ai/main/en/guide/tutorials/integration_with_open_llm.html#ollama`",
          "created_at": "2024-05-25T06:05:53Z"
        },
        {
          "author": "qwas982",
          "body": "æˆ‘è®¤ä¸ºæ¶æ„éƒ½è¦é‡æ–°è®¾è®¡,\r\n\r\nå¤§æ¨¡å‹å®ƒä¸å¯èƒ½è‡ªåŠ¨è®¿é—®å‘¨è¾¹çš„å·¥å…·,è™½ç„¶éƒ½åœ¨ç”µè„‘é‡Œ,åœ¨æ“ä½œç³»ç»Ÿé‡Œ,\r\nåœ¨è¿™ç§æƒ…å†µä¸‹,ç”¨pyå†™ä¸€äº›ä»£ç å»æ§åˆ¶å¤§æ¨¡å‹åšäº‹,æœ‰äº›ç–²äºå¥”å‘½ å—è¾•åŒ—è¾™.\r\næœ€å¥½çš„æ–¹å¼æ˜¯è®©å¤§æ¨¡å‹è‡ªåŠ¨è¯†åˆ«ä»£ç†å·¥ä½œæµçš„å„æ­¥éª¤,è®©å®ƒæ¨¡ä»¿äººçš„æ“ä½œæµç¨‹,\r\nè®©å®ƒå†™ç å°±åœ¨VSCodeé‡Œå†™,è®¿é—®ç½‘é¡µå°±åœ¨æµè§ˆå™¨é‡Œæµè§ˆ,ç”»å›¾å°±ç”¨blenderç”»,\r\n\r\nä½†æ˜¯å¤§æ¨¡å‹æ²¡é•¿æ‰‹,è¿™ç§æƒ…å†µä¸‹æ€ä¹ˆåŠ?\r\nå¤§æ¨¡å‹å¦‚ä½•å»å¯åŠ¨è¿™äº›å·¥å…·,å¦‚ä½•åœ¨å·¥å…·é‡Œæ“ä½œ?\r\nå¾®è½¯æœ€è¿‘çš„å‘å¸ƒä¼š` Build 2024 `ç»™å‡ºäº†ç­”æ¡ˆ,\r\n\r\n# æ”¾ä¸€ä¸ªæ‘„åƒå¤´ç…§å±å¹•,æŠŠå›¾åƒå®æ—¶ä¼ è¾“ç»™å¤§æ¨¡å‹,æŠŠé¼ æ ‡æˆ–é”®ç›˜çš„è¾“å…¥æ§åˆ¶äº¤ç»™å¤§æ¨¡å‹,   \r\nè¿™é‡Œå¾—å‡ºçš„ç»“è®ºæ˜¯",
          "created_at": "2024-05-28T02:51:18Z"
        },
        {
          "author": "geekan",
          "body": "éå¸¸æ„Ÿè°¢ä½ çƒ­æƒ…æ´‹æº¢çš„å‘è¨€ï¼Œä½†æ˜¯å¤§è¯­è¨€æ¨¡å‹æ“ä½œè®¡ç®—æœºæˆåŠŸç‡ç›®å‰æ™®éä½äº 15",
          "created_at": "2024-06-01T06:50:15Z"
        },
        {
          "author": "qwas982",
          "body": "> éå¸¸æ„Ÿè°¢ä½ çƒ­æƒ…æ´‹æº¢çš„å‘è¨€ï¼Œä½†æ˜¯å¤§è¯­è¨€æ¨¡å‹æ“ä½œè®¡ç®—æœºæˆåŠŸç‡ç›®å‰æ™®éä½äº 15\r\n\r\nä¸å®¢æ°”,\r\nåŸæ¥è¿˜å¤„äºæ¯”è¾ƒåˆå§‹çš„æ°´å¹³,\r\nçœ‹æ¥å¤§æ¨¡å‹è¡Œä¸šè¿˜æœ‰å·¨å¤§æ½œåŠ›",
          "created_at": "2024-06-25T02:22:42Z"
        }
      ]
    },
    {
      "issue_number": 1275,
      "title": "Function _achat_completion_stream in metagpt/provider/openai_api.py produced TypeError: openai.types.completion_usage.CompletionUsage() argument after ** must be a mapping, not NoneType",
      "body": "**Bug description**\r\nRunning the example code llm_hello_world.py on branch v0.8-release will produce a TypeError. See logs below.\r\n\r\n**Screenshots or logs**\r\n\r\nTraceback (most recent call last):\r\n  File \"/workspaces/MetaGPT/examples/llm_hello_world.py\", line 43, in <module>\r\n    asyncio.run(main())\r\n  File \"/usr/local/lib/python3.9/asyncio/runners.py\", line 44, in run\r\n    return loop.run_until_complete(main)\r\n  File \"/usr/local/lib/python3.9/asyncio/base_events.py\", line 647, in run_until_complete\r\n    return future.result()\r\n  File \"/workspaces/MetaGPT/examples/llm_hello_world.py\", line 19, in main\r\n    logger.info(await llm.aask(question))\r\n  File \"/workspaces/MetaGPT/metagpt/provider/base_llm.py\", line 150, in aask\r\n    rsp = await self.acompletion_text(message, stream=stream, timeout=self.get_timeout(timeout))\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\r\n    return await fn(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 47, in __call__\r\n    do = self.iter(retry_state=retry_state)\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/__init__.py\", line 314, in iter\r\n    return fut.result()\r\n  File \"/usr/local/lib/python3.9/concurrent/futures/_base.py\", line 439, in result\r\n    return self.__get_result()\r\n  File \"/usr/local/lib/python3.9/concurrent/futures/_base.py\", line 391, in __get_result\r\n    raise self._exception\r\n  File \"/usr/local/lib/python3.9/site-packages/tenacity/_asyncio.py\", line 50, in __call__\r\n    result = await fn(*args, **kwargs)\r\n  File \"/workspaces/MetaGPT/metagpt/provider/openai_api.py\", line 141, in acompletion_text\r\n    return await self._achat_completion_stream(messages, timeout=timeout)\r\n  File \"/workspaces/MetaGPT/metagpt/provider/openai_api.py\", line 94, in _achat_completion_stream\r\n    usage = CompletionUsage(**chunk.usage)\r\nTypeError: openai.types.completion_usage.CompletionUsage() argument after ** must be a mapping, not NoneType\r\n",
      "state": "closed",
      "author": "garylin2099",
      "author_type": "User",
      "created_at": "2024-05-15T08:48:36Z",
      "updated_at": "2024-10-10T01:47:39Z",
      "closed_at": "2024-10-10T01:47:39Z",
      "labels": [
        "bug"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1275/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/FoundationAgents/MetaGPT/issues/1275",
      "api_url": "https://api.github.com/repos/FoundationAgents/MetaGPT/issues/1275",
      "repository": "FoundationAgents/MetaGPT",
      "extraction_date": "2025-06-21T22:47:48.272162",
      "comments": []
    }
  ]
}