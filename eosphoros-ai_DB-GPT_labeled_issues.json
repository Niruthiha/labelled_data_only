{
  "repository": "eosphoros-ai/DB-GPT",
  "repository_info": {
    "repo": "eosphoros-ai/DB-GPT",
    "stars": 16814,
    "language": "Python",
    "description": "AI Native Data App Development framework with AWEL(Agentic Workflow Expression Language) and Agents",
    "url": "https://github.com/eosphoros-ai/DB-GPT",
    "topics": [
      "agents",
      "bgi",
      "database",
      "deepseek",
      "gpt",
      "gpt-4",
      "hacktoberfest",
      "llm",
      "private",
      "rag",
      "security",
      "vicuna"
    ],
    "created_at": "2023-04-13T14:52:43Z",
    "updated_at": "2025-06-21T17:45:56Z",
    "search_query": "ai agent language:python stars:>3 -framework",
    "total_issues_estimate": 116,
    "labeled_issues_estimate": 103,
    "labeling_rate": 88.9,
    "sample_labeled": 32,
    "sample_total": 36,
    "has_issues": true,
    "repo_id": 627480054,
    "default_branch": "main",
    "size": 431626
  },
  "extraction_date": "2025-06-21T23:40:24.179956",
  "extraction_type": "LABELED_ISSUES_ONLY",
  "total_labeled_issues": 500,
  "issues": [
    {
      "issue_number": 2784,
      "title": "多租户计划",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n是否提供多租户支持，涉及多用户、资源池分配、模型与数据权限、场景权限隔离等方面，没有这种权限构架支撑，这个项目也只能简单玩一玩，很难进一步推广，希望社区能充分考虑。\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "ycc15",
      "author_type": "User",
      "created_at": "2025-06-20T08:34:46Z",
      "updated_at": "2025-06-20T08:34:46Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2784/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2784",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2784",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:46.938437",
      "comments": []
    },
    {
      "issue_number": 2711,
      "title": "[Bug] [ChatData] 数据库添加postgreSQL数据源报错：ValueError: Test connection Failure!No module named 'psycopg2'",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [x] Chat Data\n- [ ] Chat Excel\n- [x] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nwin11，集显，使用deepseek代理模式\n\n### Models information\n\ndeepseek-R1\n\n### What happened\n\n通过源码部署了DB-GPT, 使用代理模式，大模型使用的deepseek官方。在“应用管理”-“数据库”添加postgreSQL数据源报错：ValueError: Test connection Failure!No module named 'psycopg2'。\n\nPycharm控制台报错信息：\n\n`  File \"D:\\WorkSpace\\Projects\\DB-GPT\\packages\\dbgpt-serve\\src\\dbgpt_serve\\datasource\\service\\service.py\", line 288, in test_connection\n    return self.datasource_manager.test_connection(request)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\WorkSpace\\Projects\\DB-GPT\\packages\\dbgpt-serve\\src\\dbgpt_serve\\datasource\\manages\\connector_manager.py\", line 290, in test_connection\n    raise ValueError(f\"Test connection Failure!{str(e)}\")\nValueError: Test connection Failure!No module named 'psycopg2'\n`\n\n### What you expected to happen\n\n缺少依赖\n\n### How to reproduce\n\n1.登录DB-GPT\n2.选择应用管理→数据源→添加数据源，选择postgreSQL数据库类型\n3.输入数据库连接信息后点击提交\n\n### Additional context\n\n建议：\n1.进一步完善开发文档\n2.及时更新docker镜像\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "flycohuang",
      "author_type": "User",
      "created_at": "2025-05-21T02:40:32Z",
      "updated_at": "2025-06-20T06:59:21Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2711/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2711",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2711",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:46.938464",
      "comments": [
        {
          "author": "chenliang15405",
          "body": "it seem have not install postgreSQL depencey, please refer to this doc:[http://docs.dbgpt.cn/docs/installation/integrations/postgres_install](http://docs.dbgpt.cn/docs/installation/integrations/postgres_install) ",
          "created_at": "2025-05-21T09:20:52Z"
        },
        {
          "author": "yeyeywye123",
          "body": "缺少pg库的依赖，cd到项目根目录pip install一下就可以解决",
          "created_at": "2025-06-20T06:59:21Z"
        }
      ]
    },
    {
      "issue_number": 2782,
      "title": "[Bug] [Module Name] Bug title",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU 96*4\n\n### Models information\n\nllm: huanyuan-turbo-latest\n\n### What happened\n\n配置mcp后调用报错\n\n![Image](https://github.com/user-attachments/assets/58be0c2d-4754-40fe-9944-5a0f197ff719)\n\n### What you expected to happen\n\n1、正常调用mcp中提供的server\n2、多次自动调用mcp\n\n### How to reproduce\n\n按照官网提供的配置就能出现这个报错\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "hiro110110",
      "author_type": "User",
      "created_at": "2025-06-19T07:57:13Z",
      "updated_at": "2025-06-20T05:45:57Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2782/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2782",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2782",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:47.121471",
      "comments": [
        {
          "author": "chenliang15405",
          "body": " Could you provide more information that How should i reproduce it? ",
          "created_at": "2025-06-19T12:44:12Z"
        },
        {
          "author": "hiro110110",
          "body": "> Could you provide more information that How should i reproduce it?\n\nthis problem occour after upgrade to verssion 0.7.2",
          "created_at": "2025-06-20T05:45:57Z"
        }
      ]
    },
    {
      "issue_number": 2779,
      "title": "[Bug] [Module Name] mcp中的资源只能调用一次",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU  96G*4\n\n### Models information\n\nllm: hunyuan-turbos-latest\n\n### What happened\n\n![Image](https://github.com/user-attachments/assets/91357d64-dc1f-4eed-9d92-8cd769d75227)\n\n![Image](https://github.com/user-attachments/assets/0f70a8a0-045b-4788-b2b7-5a89b6cc9701)\n\n单智能体中选择ToolExpert，提供的mcp是sse ，如图所示，mcp的server中有3个工具，每次执行都只能执行一个工具\n\n### What you expected to happen\n\n![Image](https://github.com/user-attachments/assets/821e35f5-e235-44c7-9d58-3226b58a2626)\n我希望的样子是llm识别到多个工具后能指引mcp服务器按需多次调用，实际已经有很多已经实现了这个功能，如截图，使用相同的模型、mcp server，执行后的效果在dbgpt中就是只能调用工具一次\n\n### How to reproduce\n\n上面的截图已经展示的很清楚\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "hiro110110",
      "author_type": "User",
      "created_at": "2025-06-18T09:25:54Z",
      "updated_at": "2025-06-20T03:49:15Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2779/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2779",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2779",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:47.299386",
      "comments": [
        {
          "author": "WangzJi",
          "body": "Hi @fangyinc @Aries-ckt.\nI’ve looked into this a bit and would like to work on a fix. Please assign me if that’s okay.",
          "created_at": "2025-06-20T03:49:15Z"
        }
      ]
    },
    {
      "issue_number": 2775,
      "title": "[Bug] [ChatDB] mysql表字段获取不全",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [x] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [x] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nLLM:deepseek-ai/DeepSeek-V3\nEmbedding model:BAAI/bge-m3\n\n### What happened\n\n1.获取mysql表结构信息时，表字段有五十多个，实际只返回了10个字段\n2.看日志是从知识库中直接获取的，说明在构建数据库DDL知识库时应该就没有构建完整的表结构\n3.这样的话，如果要生成sql，没有传递完整的表结构信息，那么生成的SQL很可能是不准确的\n\n![Image](https://github.com/user-attachments/assets/625d5361-8f50-491d-b3c4-a6ce284a1d45)\n\n![Image](https://github.com/user-attachments/assets/95e4bfdd-0e16-4d58-b6e3-d1e227a67854)\n\n### What you expected to happen\n\n1.初始化时应该构建完整的表结构，而不是部分字段。\n2.如果是可以通过参数调整的，请告诉我调整的配置文件目录和名称以及配置值。\n\n### How to reproduce\n\n1.部署最新的dbgpt，使用dbgpt-proxy-siliconflow-mysql.toml；\n2.连接mysql，包括一些大表，字段数比较多\n3.进行chatDB问答\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Kun-Zhang-x",
      "author_type": "User",
      "created_at": "2025-06-16T07:03:02Z",
      "updated_at": "2025-06-20T02:57:10Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2775/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2775",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2775",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:47.469340",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "日志能截图全一点吗，给模型之前有没有更全面的表的日志信息？",
          "created_at": "2025-06-18T15:01:54Z"
        },
        {
          "author": "WangzJi",
          "body": "If this is indeed a bug, I'm willing to work on a fix and open a PR for it.",
          "created_at": "2025-06-20T02:10:17Z"
        },
        {
          "author": "xieyatao",
          "body": "![Image](https://github.com/user-attachments/assets/24b31d9e-15dc-485c-9b3d-5993c1ea998c)\n\n![Image](https://github.com/user-attachments/assets/78033332-d15e-4626-bd5e-6cc6003bcb68)\n设置环境变量KNOWLEDGE_SEARCH_TOP_SIZE的值，可控制返回的表字段个数。",
          "created_at": "2025-06-20T02:57:10Z"
        }
      ]
    },
    {
      "issue_number": 2355,
      "title": "Question about zip1 format",
      "body": "I upload the zip file , but meet the error(Unsupported knowledge document type 'zip').\nwhat means the **zip1** format? Can you give some help?\n\n![Image](https://github.com/user-attachments/assets/83ac5bab-bf5b-462d-b55b-8963faab8c92)",
      "state": "open",
      "author": "caiduoduo12138",
      "author_type": "User",
      "created_at": "2025-02-19T01:51:31Z",
      "updated_at": "2025-06-19T21:05:23Z",
      "closed_at": null,
      "labels": [
        "stale"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2355/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2355",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2355",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:47.663559",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-06-19T21:05:22Z"
        }
      ]
    },
    {
      "issue_number": 2356,
      "title": "[Feature][AWEL] Configurable card indentation",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n![Image](https://github.com/user-attachments/assets/2baa66e7-ede0-4576-b763-531b034725dd)\n配置较长的链路时，配置卡片较大，可视化展示较差\n\n### Use case\n\n1、卡片配置完可缩进；\n2、多资源配置支持；\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "yuerf",
      "author_type": "User",
      "created_at": "2025-02-19T03:11:46Z",
      "updated_at": "2025-06-19T21:05:21Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2356/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2356",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2356",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:47.887781",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-06-19T21:05:21Z"
        }
      ]
    },
    {
      "issue_number": 2736,
      "title": "[Bug] [Module Name] Bug title",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [x] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU \n\n### Models information\n\nqwen2.5        \n\n### What happened\n\n1. dbgpt app install financial-robot-app financial-report-knowledge-factory\n\n2. dbgpt app list    (报一下错误：)\n\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-core/src/dbgpt/util/dbgpts/loader.py\", line 324, in _load_package_from_path\n    parsed_packages.append(parse_package_metadata(package))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-core/src/dbgpt/util/dbgpts/loader.py\", line 282, in parse_package_metadata\n    return FlowPackage.build_from(pkg_dict, ext_metadata)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-core/src/dbgpt/util/dbgpts/loader.py\", line 121, in build_from\n    return FlowPythonPackage.build_from(values, ext_dict)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-core/src/dbgpt/util/dbgpts/loader.py\", line 131, in build_from\n    _, _, mods = cls.load_module_class(values, DAG)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-core/src/dbgpt/util/dbgpts/loader.py\", line 109, in load_module_class\n    raise e\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-core/src/dbgpt/util/dbgpts/loader.py\", line 95, in load_module_class\n    with pkg_resources.path(name, \"__init__.py\") as path:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib64/python3.11/importlib/resources/_legacy.py\", line 25, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib64/python3.11/importlib/resources/_legacy.py\", line 121, in path\n    return _common.as_file(_common.files(package) / normalize_path(resource))\n                           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib64/python3.11/importlib/resources/_common.py\", line 22, in files\n    return from_package(get_package(package))\n                        ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib64/python3.11/importlib/resources/_common.py\", line 53, in get_package\n    resolved = resolve(package)\n               ^^^^^^^^^^^^^^^^\n  File \"/usr/lib64/python3.11/importlib/resources/_common.py\", line 44, in resolve\n    return cand if isinstance(cand, types.ModuleType) else importlib.import_module(cand)\n                                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib64/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/financial_report_knowledge_factory/__init__.py\", line 24, in <module>\n    from dbgpt.datasource.db_conn_info import DBConfig\nModuleNotFoundError: No module named 'dbgpt.datasource.db_conn_info'\n\n### What you expected to happen\n\n正常加载dbgpts\n\n### How to reproduce\n\n1. dbgpt app install financial-robot-app financial-report-knowledge-factory\n\n2. dbgpt app list    (报一下错误：)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-core/src/dbgpt/util/dbgpts/loader.py\", line 324, in _load_package_from_path\n    parsed_packages.append(parse_package_metadata(package))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-core/src/dbgpt/util/dbgpts/loader.py\", line 282, in parse_package_metadata\n    return FlowPackage.build_from(pkg_dict, ext_metadata)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-core/src/dbgpt/util/dbgpts/loader.py\", line 121, in build_from\n    return FlowPythonPackage.build_from(values, ext_dict)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-core/src/dbgpt/util/dbgpts/loader.py\", line 131, in build_from\n    _, _, mods = cls.load_module_class(values, DAG)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-core/src/dbgpt/util/dbgpts/loader.py\", line 109, in load_module_class\n    raise e\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-core/src/dbgpt/util/dbgpts/loader.py\", line 95, in load_module_class\n    with pkg_resources.path(name, \"__init__.py\") as path:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib64/python3.11/importlib/resources/_legacy.py\", line 25, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib64/python3.11/importlib/resources/_legacy.py\", line 121, in path\n    return _common.as_file(_common.files(package) / normalize_path(resource))\n                           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib64/python3.11/importlib/resources/_common.py\", line 22, in files\n    return from_package(get_package(package))\n                        ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib64/python3.11/importlib/resources/_common.py\", line 53, in get_package\n    resolved = resolve(package)\n               ^^^^^^^^^^^^^^^^\n  File \"/usr/lib64/python3.11/importlib/resources/_common.py\", line 44, in resolve\n    return cand if isinstance(cand, types.ModuleType) else importlib.import_module(cand)\n                                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib64/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/financial_report_knowledge_factory/__init__.py\", line 24, in <module>\n    from dbgpt.datasource.db_conn_info import DBConfig\nModuleNotFoundError: No module named 'dbgpt.datasource.db_conn_info'\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "maco6096",
      "author_type": "User",
      "created_at": "2025-05-27T02:59:04Z",
      "updated_at": "2025-06-19T13:03:38Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2736/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2736",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2736",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:48.173287",
      "comments": [
        {
          "author": "chenliang15405",
          "body": "if you want use `financial-report` ,please swtich DB-GPT version to 0.6.2 or lower",
          "created_at": "2025-06-19T13:03:38Z"
        }
      ]
    },
    {
      "issue_number": 2741,
      "title": "[Bug] [Module Name] Summarizer 模块输出内容与原数据库查询出的内容不一致",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\ndevice：CPU\n通过 proxy 方式调用的模型\n\n### Models information\n\nLLM：qwen3\nembeddings：bge-large-zh-v1.5\nrerankers：bge-reranker-v2-m3\n\n### What happened\n\n自建智能体，通过 DataScientist 查询数据，然后再通过 Summarizer 进行总结时，输出的总结内容会修改原有数据。\n\n![Image](https://github.com/user-attachments/assets/d1d4b4d1-d50d-4e4c-a2b3-a2e58dd584ce)\n\n![Image](https://github.com/user-attachments/assets/a87bb48d-c434-4b74-9b3c-84328005e8d6)\n\n大部分的人员姓名被修改，SQL 查询出来是正常的，但是 Summarizer 总结时会对人员姓名进行修改。\n\n\n配置信息\n\n![Image](https://github.com/user-attachments/assets/1f57fffd-7958-4e0d-be5a-bac110a0c9c4)\n\n![Image](https://github.com/user-attachments/assets/34ac14ad-830b-4780-95fe-865b2719c32f)\n\n### What you expected to happen\n\n可以进行正常的 Summarizer 总结\n\n### How to reproduce\n\n我愿意提供数据表结构及数据内容\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "hhaishen",
      "author_type": "User",
      "created_at": "2025-05-29T09:04:20Z",
      "updated_at": "2025-06-19T13:01:03Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2741/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2741",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2741",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:48.514024",
      "comments": [
        {
          "author": "fangyinc",
          "body": "这是模型的问题。",
          "created_at": "2025-06-09T09:20:10Z"
        },
        {
          "author": "hhaishen",
          "body": "> 这是模型的问题。\n\n是 embeddings 的问题还是 LLM 的问题，大佬方便给个方向吗",
          "created_at": "2025-06-10T01:19:07Z"
        },
        {
          "author": "chenliang15405",
          "body": "> > 这是模型的问题。\n> \n> 是 embeddings 的问题还是 LLM 的问题，大佬方便给个方向吗\n\n可以根据输出的prompt和思考日志排查下，可能是LLM的问题",
          "created_at": "2025-06-19T13:01:03Z"
        }
      ]
    },
    {
      "issue_number": 2777,
      "title": "[Bug] [agent] MCP 工具调用时不走Tool Expert agent，而是直接调用工具本身，从而报错",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nNot Related\n\n### Models information\n\nNot Related\n\n### What happened\n\n依照 DB-GPT 0.7.0 更新日志, 创建了一个连接 MCP SSE 的多智能体应用。其中包含了一个带有 zhipuai 网络搜索工具的 MCP 服务器的 Tool Expert 和 Summarizer\n\n![Image](https://github.com/user-attachments/assets/ba816d33-4daf-42e2-8cb0-e607d4e02b4a)\n\n但是在进行应用对话时，自带的 plan manager 经常会直接调用 MCP 服务器中的工具，跳过 Tool Expert，导致输出失败。\n\n![Image](https://github.com/user-attachments/assets/b258af36-e224-4748-95b6-2234ce4806da)\n\n部分终端输出已经附在最后的 Additional Context 中，可以看到 plan manager 直接将工具本身当做了一个 agent\n\n### What you expected to happen\n\n按理说想调用工具必须要通过 Tool Expert 这个 agent，但是由于 MCP 里的工具被直接注册为可用 Resource，并且与 agent 的优先级相当，导致 plan manager 会错误地直接调用 tool 本身。\n\n也许可以通过更改默认的 plan manager prompt 来避免让 plan manager 选择 resource 中的 tool，然后直接选择可用的 agent。\n\n如果在对话中严格限制使用的 agent，应用对话成功\n\n![Image](https://github.com/user-attachments/assets/be00d502-49fc-4d5a-9241-87fa707527bf)\n\n返回了预期结果\n\n### How to reproduce\n\n想复制这个 bug 可以尝试去诱导 plan manager，应该也会直接调用 resource 中的 tool\n\n### Additional context\n\n2025-06-18 12:21:18 computer dbgpt.model.cluster.worker.default_worker[3842] INFO llm_adapter: <_DynProxyLLMModelAdapter model_name=robotgpt-qw-72b model_path=None>\n\nmodel prompt: \n\nsystem: 你是一个 Planner, 名字叫 Planner.\n你的目标是 Understand each of the following intelligent agents and their capabilities, using the provided resources, solve user problems by coordinating intelligent agents. Please utilize your LLM's knowledge and understanding ability to comprehend the intent and goals of the user's problem, generating a task plan that can be completed through the collaboration of intelligent agents without user assistance..请一步一步思考完根据下面给出的已知信息和用户问题完成目标，同时请严格遵守下面\"重要提醒\"中的约束和规范。\n已知资源信息：\nzhipu_tool：调用此工具与 zhipu_tool API进行交互。zhipu_tool API 有什么用？Web search and return the results as a markdown string. Please set number of results not less than 5 for rich search results. 参数：[{\"name\": \"query\", \"type\": \"string\", \"description\": \"{'title': 'Query', 'type': 'string'}\", \"required\": true}, {\"name\": \"num_results\", \"type\": \"integer\", \"description\": \"{'default': 5, 'title': 'Num Results', 'type': 'integer'}\", \"required\": false}] \nAvailable Intelligent Agents:\n - Summarizer:You can summarize provided text content according to user's questions and output the summarization.\n- ToolExpert:You can use the following tools to complete the task objectives, tool information: {tool_infos} \n\n*** 重要提醒 ***\n请用简体中文进行回答.\n当前时间是:2025-06-18 12:21:18\n1. Every step of the task plan should exist to advance towards solving the user's goals. Do not generate meaningless task steps; ensure that each step has a clear goal and its content is complete.\n2. Pay attention to the dependencies and logic of each step in the task plan. For the steps that are depended upon, consider the data they depend on and whether it can be obtained based on the current goal. If it cannot be obtained, please indicate in the goal that the dependent data needs to be generated.\n3. Each step must be an independently achievable goal. Ensure that the logic and information are complete. Avoid steps with unclear objectives, like 'Analyze the retrieved issues data,' where it's unclear what specific content needs to be analyzed.\n4. Please ensure that only the intelligent agents mentioned above are used, and you may use only the necessary parts of them. Allocate them to appropriate steps strictly based on their described capabilities and limitations. Each intelligent agent can be reused.\n5. Utilize the provided resources to assist in generating the plan steps according to the actual needs of the user's goals. Do not use unnecessary resources.\n6. Each step should ideally use only one type of resource to accomplish a sub-goal. If the current goal can be broken down into multiple subtasks of the same type, you can create mutually independent parallel tasks.\n7. Data resources can be loaded and utilized by the appropriate intelligent agents without the need to consider the issues related to data loading links.\n8. Try to merge continuous steps that have sequential dependencies. If the user's goal does not require splitting, you can create a single-step task with content that is the user's goal.\n9. Carefully review the plan to ensure it comprehensively covers all information involved in the user's problem and can ultimately achieve the goal. Confirm whether each step includes the necessary resource information, such as URLs, resource names, etc.\n\n你也可以参考如下对话示例:\n\nuser:help me build a sales report summarizing our key metrics and trends\nassistants:[\n    {{\n        \"serial_number\": \"1\",\n        \"agent\": \"DataScientist\",\n        \"content\": \"Retrieve total sales, average sales, and number of transactions grouped by \"product_category\"'.\",\n        \"rely\": \"\"\n    }},\n    {{\n        \"serial_number\": \"2\",\n        \"agent\": \"DataScientist\",\n        \"content\": \"Retrieve monthly sales and transaction number trends.\",\n        \"rely\": \"\"\n    }},\n    {{\n        \"serial_number\": \"3\",\n        \"agent\": \"Reporter\",\n        \"content\": \"Integrate analytical data into the format required to build sales reports.\",\n        \"rely\": \"1,2\"\n    }}\n]\n Please reply strictly in the following json format:\n        [\n  {\n    \"serial_number\": \"Number of sub-tasks\",\n    \"agent\": \"The agent name to complete current task\",\n    \"content\": \"The task content of current step, make sure it can by executed by agent\",\n    \"rely\": \"The rely task number(serial_number), e.g. 1,2,3, empty if no rely\"\n  }\n]\n        Make sure the reply content only has the correct json. \nhuman: \n用户输入: db-gpt的7.2更新了什么\n\n\n=== Model Inference Metrics ===\n\n▶ Latency:\n  • First Token Latency: N/A\n\n▶ Speed:\n  • Prefill Speed: N/A\n  • Decode Speed: N/A\n\n▶ Tokens:\n  • Prompt Tokens: N/A\n  • Completion Tokens: N/A\n2025-06-18 12:21:22 computer dbgpt.model.cluster.worker.embedding_worker[3842] INFO Receive embeddings request, model: bge_zh\n\n--------------------------------------------------------------------------------\nPlanner (to AutoPlanChatManager)-[robotgpt-qw-72b]:\n\n\"[\\n  {\\n    \\\"serial_number\\\": \\\"1\\\",\\n    \\\"agent\\\": \\\"zhipu_tool\\\",\\n    \\\"content\\\": \\\"查询db-gpt 7.2版本的更新内容，返回至少5条搜索结果。\\\",\\n    \\\"rely\\\": \\\"\\\"\\n  },\\n  {\\n    \\\"serial_number\\\": \\\"2\\\",\\n    \\\"agent\\\": \\\"Summarizer\\\",\\n    \\\"content\\\": \\\"根据搜索结果，总结db-gpt 7.2版本的更新内容。\\\",\\n    \\\"rely\\\": \\\"1\\\"\\n  }\\n]\"\n>>>>>>>>Planner Review info: \nPass(None)\n>>>>>>>>Planner Action report: \nexecution succeeded,\n[\n  {\n    \"serial_number\": \"1\",\n    \"agent\": \"zhipu_tool\",\n    \"content\": \"查询db-gpt 7.2版本的更新内容，返回至少5条搜索结果。\",\n    \"rely\": \"\"\n  },\n  {\n    \"serial_number\": \"2\",\n    \"agent\": \"Summarizer\",\n    \"content\": \"根据搜索结果，总结db-gpt 7.2版本的更新内容。\",\n    \"rely\": \"1\"\n  }\n]\n\n--------------------------------------------------------------------------------\nAutoPlanChatManager (to User)-[]:\n\n\"db-gpt的7.2更新了什么\"\n>>>>>>>>AutoPlanChatManager Review info: \nPass(None)\n>>>>>>>>AutoPlanChatManager Action report: \nexecution failed,\nAn exception was encountered during the execution of the current plan step.Unable to select next speaker!\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "stevenlx96",
      "author_type": "User",
      "created_at": "2025-06-18T04:56:05Z",
      "updated_at": "2025-06-19T12:46:43Z",
      "closed_at": "2025-06-19T12:46:43Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2777/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2777",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2777",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:48.708701",
      "comments": []
    },
    {
      "issue_number": 2780,
      "title": "[Feature][model] Support MLX inference for Apple silicon",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nhttps://github.com/ml-explore/mlx\n\nhttps://github.com/ml-explore/mlx-lm\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "fangyinc",
      "author_type": "User",
      "created_at": "2025-06-18T14:00:40Z",
      "updated_at": "2025-06-19T01:30:59Z",
      "closed_at": "2025-06-19T01:30:59Z",
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2780/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2780",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2780",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:48.708733",
      "comments": []
    },
    {
      "issue_number": 2349,
      "title": "[Bug] [Module Name] Bug title related question error.",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU集群\n\n### Models information\n\ntext2vec-large-chinese\n智谱代理\n\n### What happened\n\n![Image](https://github.com/user-attachments/assets/d7322a23-693e-492e-b3e8-7300a995aaec)\n在对知识库里的文档添加关联问题的时候弹出如下报错，添加不了关联问题。\n\n### What you expected to happen\n\n请问如何处理解决报错\n\n### How to reproduce\n\n源码部署，创建随机知识库，点击知识库的某个文档，关联问题，提交即报错\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "w371803361",
      "author_type": "User",
      "created_at": "2025-02-13T00:41:45Z",
      "updated_at": "2025-06-18T21:05:28Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2349/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2349",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2349",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:48.708744",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "what is your LOCAL_DB_TYPE in .env",
          "created_at": "2025-02-16T14:58:59Z"
        },
        {
          "author": "w371803361",
          "body": "> LOCAL_DB_TYPE\n\n我的是LOCAL_DB_TYPE=sqlite",
          "created_at": "2025-02-18T00:39:21Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-06-18T21:05:27Z"
        }
      ]
    },
    {
      "issue_number": 2755,
      "title": "[Feature][Knowlege RAG] db-gpt针对总结性问答是如何解决",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n    目前db-gpt对总结性问答对话中譬如：这个文章是讲解什么？ 能概括的总结性下这个文档吗？针对这样的问题，能完整的说下：目前DB-Gpt是如何解决的，或者将来对这样的问题有什么样的想法建议。\n    项目里面目前有一个单独的class:SummaryAssembler,这个作为一个单独的功能接口对外提供，但是作为对话功能没有融入这部分功能。\n\n",
      "state": "open",
      "author": "liuhaozhebj",
      "author_type": "User",
      "created_at": "2025-06-09T08:44:49Z",
      "updated_at": "2025-06-18T15:05:35Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2755/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2755",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2755",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:48.897588",
      "comments": [
        {
          "author": "chenliang15405",
          "body": "whether you want to use chat knowledge?\n",
          "created_at": "2025-06-10T13:01:29Z"
        },
        {
          "author": "liuhaozhebj",
          "body": "use chat knowledge",
          "created_at": "2025-06-10T23:59:54Z"
        },
        {
          "author": "Aries-ckt",
          "body": "这里确实没用到，这里做法是可以前期构建把doc摘要提前构建好，给模型时把文章摘要带上。",
          "created_at": "2025-06-18T15:05:35Z"
        }
      ]
    },
    {
      "issue_number": 2770,
      "title": "[Bug] [Module Name] 在单智能体创建页面，可以选择多个智能体",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\ngpu\n\n### Models information\n\nllm\n\n### What happened\n\n![Image](https://github.com/user-attachments/assets/8e2bc820-4e34-45ee-89b5-c0e142018bf2)\n\n![Image](https://github.com/user-attachments/assets/2e90556a-6054-4c2e-907a-97b3c380e220)\n\n在创建单智能体时，可以选择多个智能体模板；\n\n### What you expected to happen\n\n1.  只能选择一个\n\n### How to reproduce\n\n版本=DB-GPT-0.7.1\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "darrenlei123",
      "author_type": "User",
      "created_at": "2025-06-13T07:56:50Z",
      "updated_at": "2025-06-18T15:03:28Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2770/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2770",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2770",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:49.054142",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "这里前端没有限制，确实只能支持一个",
          "created_at": "2025-06-18T15:03:28Z"
        }
      ]
    },
    {
      "issue_number": 2776,
      "title": "[Feature][Module Name] 请问如何同时使用多个数据源?  How can I use multiple data sources simultaneously?",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n请问如何同时使用多个数据源?\n比如: \n数据源1: doris数据库 \n数据源2: 本地knowledge库\n\n现在想实现的功能为: 创建一个native_app或agent, 在问答时会自动根据问题选择对应的数据源, 接着进行查询并回复。\n请问这个需求该如何实现\n\n\n\nHow can I use multiple data sources simultaneously?\n\nFor example:\nData Source 1: Doris Database\nData Source 2: Local Knowledge Base\n\nThe desired functionality is to create a native app or agent that automatically selects the appropriate data source based on the question during a Q&A session, then performs the query and responds accordingly. How can this requirement be implemented?\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "leap233",
      "author_type": "User",
      "created_at": "2025-06-17T07:10:38Z",
      "updated_at": "2025-06-18T14:58:40Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2776/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2776",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2776",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:49.237166",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "你好，你有没有试过创建一个数据分析agent，同时绑定数据源和知识库的？",
          "created_at": "2025-06-18T14:58:40Z"
        }
      ]
    },
    {
      "issue_number": 2348,
      "title": "[Bug] [Module Name] Bug title Delete knowledge base error",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU:48G\n\n### Models information\n\nqwen\nbge-large-zh-v1.5\n\n### What happened\n\nWhen the knowledge base name is a pure number, it cannot be deleted\n\n### What you expected to happen\n\n![Image](https://github.com/user-attachments/assets/e0be8896-55fb-44a8-91d3-e3368a44c338)\n\n### How to reproduce\n\n![Image](https://github.com/user-attachments/assets/90158185-03bd-4194-a924-241f04fa0842)\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "liuyu970321",
      "author_type": "User",
      "created_at": "2025-02-13T00:21:50Z",
      "updated_at": "2025-06-17T21:05:36Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2348/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2348",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2348",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:49.412238",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "it looks like your graph space have not create successfully. check your graph config and check tugraph connect config?",
          "created_at": "2025-02-16T15:00:37Z"
        },
        {
          "author": "liuyu970321",
          "body": "> it looks like your graph space have not create successfully. check your graph config and check tugraph connect config?\n\nRegarding the connection to the graph database, it seems there is no issue. According to a test I conducted, when the knowledge base name contains non-purely numeric characters, ",
          "created_at": "2025-02-17T01:14:26Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-06-17T21:05:35Z"
        }
      ]
    },
    {
      "issue_number": 2342,
      "title": "[Bug] Connect SQL server error，No module named ‘pymssql’",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [x] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [x] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU数量：1\nGPU内存：24g\n\n### Models information\n\nLLM：qwen2.5:32b\nEmbedding：bge-m3\n\n### What happened\n\n连接SQL server时报错，显示如下：No module named ‘pymssql’\n\n![Image](https://github.com/user-attachments/assets/cbb0fa69-e41d-4110-8822-3a0ffafe9991)\n\n修改docker配置文件后，又报新的错误：(pymssql.exceptions.OperationalError) (20009, b'DB-Lib error message 20009, severity 9: Unable to connect: Adaptive Server is unavailable or does not exist (XXXX）\n\n![Image](https://github.com/user-attachments/assets/4f3b5028-55be-4653-b67b-0543d2ca0eb1)\n\n![Image](https://github.com/user-attachments/assets/1761e58c-9927-4b45-a71e-4fdd666619b6)\n\n### What you expected to happen\n\ndocker配置文件缺少其他依赖\n\n### How to reproduce\n\n使用docker本地部署DB-GPT最新版本，连接SQL server数据库即会遇到该报错\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Danrry1996",
      "author_type": "User",
      "created_at": "2025-02-10T10:02:49Z",
      "updated_at": "2025-06-16T21:05:47Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2342/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2342",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2342",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:49.622484",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "try `pip install pymssql`",
          "created_at": "2025-02-16T15:02:48Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-06-16T21:05:46Z"
        }
      ]
    },
    {
      "issue_number": 2345,
      "title": "[Bug] [Module Name] Bug title dbgpt.app.openapi.api_v1.editor.api_editor_v1.editor_chart_run  286line error",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nMacOS(M1, M2...)\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [x] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice CPU\n\n### Models information\n\nLLM：通义千问\n\n### What happened\n\n<img width=\"840\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/0270e20d-141e-412e-a471-41a1a364921f\" />查询报错\n\n### What you expected to happen\n\ntimeout参数未定义错误\n\n### How to reproduce\n\ndashboard -> Editor ->run \n\n### Additional context\n\ndbgpt.datasource.rdbms.base.RDBMSConnector.query_ex 增加timeout入参，并修改如下\n\n def query_ex(self, query: str, fetch: str = \"all\",timeout: Optional[int] = None):\n        \"\"\"Execute a SQL command and return the results.\n\n        Only for query command.\n\n        Args:\n            query (str): SQL query to run\n            fetch (str): fetch type\n\n        Returns:\n            List: result list\n        \"\"\"\n        logger.info(f\"Query[{query}]\")\n        if not query:\n            return [], None\n        with self.session.connection() as connection:\n            if timeout is not None:\n                connection.execution_options(timeout=timeout)\n            # cursor = self.session.execute(text(query))\n            cursor = connection.execute(text(query))\n            if cursor.returns_rows:\n                if fetch == \"all\":\n                    result = cursor.fetchall()\n                elif fetch == \"one\":\n                    result = cursor.fetchone()  # type: ignore\n                else:\n                    raise ValueError(\"Fetch parameter must be either 'one' or 'all'\")\n                field_names = list(cursor.keys())\n\n                result = list(result)\n                return field_names, result\n        return [], None\n\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "465366128",
      "author_type": "User",
      "created_at": "2025-02-11T14:29:51Z",
      "updated_at": "2025-06-16T21:05:46Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2345/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2345",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2345",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:49.834695",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-06-16T21:05:45Z"
        }
      ]
    },
    {
      "issue_number": 2751,
      "title": "[Bug] [RAG] TuGraph 创建过程中返回报错 collection not found ",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [x] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice: CPU\n\n### Models information\n\n模型调用阿里云百炼平台API：\nLLM: qwen-plus\nembedding: text-embedding-v3\n\n\n### What happened\n\n版本0.7.1，数据库采用Tugraph，Milvus，Mysql，启动服务后，上传文件，存储类型采用Knowledge Graph，运行过程中出现如下报错：\n2025-06-06 09:24:14 | INFO | dbgpt_ext.storage.vector_store.milvus_store | begin truncate milvus collection:e6b58be8af953636315f434f4d4d554e4954595f53554d4d415259\n2025-06-06 09:24:14 | INFO | dbgpt_ext.storage.vector_store.milvus_store | truncate milvus collection e6b58be8af953636315f434f4d4d554e4954595f53554d4d415259 success\n2025-06-06 09:24:14 | INFO | dbgpt.storage.base | Loading 1 chunks in 1 groups with 1 threads.\n2025-06-06 09:24:14 | INFO | dbgpt.model.cluster.worker.embedding_worker | Receive embeddings request, model: text-embedding-v3\n2025-06-06 09:24:14,469 [ERROR][handler]: RPC error: [batch_insert], <MilvusException: (code=100, message=collection not found[collection=458474964967163188])>, <Time:{'RPC start': '2025-06-06 09:24:14.468058', 'RPC error': '2025-06-06 09:24:14.469627'}> (decorators.py:140)\n2025-06-06 09:24:14 | ERROR | pymilvus.decorators | RPC error: [batch_insert], <MilvusException: (code=100, message=collection not found[collection=458474964967163188])>, <Time:{'RPC start': '2025-06-06 09:24:14.468058', 'RPC error': '2025-06-06 09:24:14.469627'}>\n2025-06-06 09:24:14 | ERROR | dbgpt_serve.rag.service.service | document embedding, failed:测试1.docx, Failed to load chunk group 1: Failed to load chunk group 1: <MilvusException: (code=100, message=collection not found[collection=458474964967163188])>\n2025-06-06 09:24:16 | INFO | dbgpt_app.knowledge.api | /document/list params: 测试661, doc_name=None doc_ids=[5] doc_type=None status=None page=1 page_size=20\n\n### What you expected to happen\n\n请大佬帮我看看\n\n### How to reproduce\n\n1、创建知识库\n2、存储类型采用Knowledge Graph\n3、上传文件\n4、切片选择chunk_size 512,chunk_overlap: 50\n5、切片处理\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Tycoonman-ML",
      "author_type": "User",
      "created_at": "2025-06-06T02:28:36Z",
      "updated_at": "2025-06-15T09:37:58Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2751/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2751",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2751",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:50.053578",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "sorry about that, try switch your vector type is `Chroma` and check KG function. ",
          "created_at": "2025-06-06T15:24:44Z"
        },
        {
          "author": "Tycoonman-ML",
          "body": "> sorry about that, try switch your vector type is `Chroma` and check KG function.\n\n\nWhen my vector type is Chroma, the service works normally, but Milvus still reports that error.\n",
          "created_at": "2025-06-09T01:24:43Z"
        },
        {
          "author": "BrucePayton",
          "body": "**Instructions Regarding This Issue**  \n\n1. You should be familiar with Milvus.  \n2. **Do not use TuGraph in the production environment**, as its related code is outdated. However, you can still use it in the testing environment to support your work on **DB-GPT & TuGraph**.  \n3. **Client Functions &",
          "created_at": "2025-06-15T09:37:58Z"
        }
      ]
    },
    {
      "issue_number": 2764,
      "title": "[Bug] [Module Name] 上传知识到Milvus中，上传报错，删除也报错。",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nLLM：gpt-4o\nembeddings：text-embedding-3-small\n\n### What happened\n\nmilvus配置：\n客服端版本: pymilvus=2.3.0\n\n![Image](https://github.com/user-attachments/assets/85777b1e-6840-4f16-8e56-7d8bd4759ae0)\n\n创建知识库，上传成功后，切片时报错：\n\n![Image](https://github.com/user-attachments/assets/aab33a89-c006-49e6-8745-3f10eb581fe9)\n\n![Image](https://github.com/user-attachments/assets/e3a5528d-8803-45ea-baa1-a44ded5e6192)\n\n删除创建的知识库报错：\n\n![Image](https://github.com/user-attachments/assets/453063e8-10d9-4ea3-a6cd-240a52ef3e75)\n\n相关的md文档：\n无法传上去，但是在chromadb中，切片存储是成功的。\n\n### What you expected to happen\n\n1. 切片存储到milvus不报错。\n2. 删除不报错。\n\n### How to reproduce\n\n1.切换配置milvus\n2.从知识库中，创建知识库->配置知识库名称->上传md->切片\n3. md文档内容如下：\n# 烹饪管理数据库设计文档(2)\n\n## 系统概述\n\n本系统用于管理和追踪用户的烹饪活动，支持烹饪达标考核、数据统计分析等功能。\n\n## 核心功能\n\n\\- 食品信息管理\n\n\\- 烹饪记录追踪\n\n\\- 用户达标考核\n\n\\- 数据统计分析\n\n## 技术规范\n\n\\- 数据库：PostgreSQL 14+\n\n\\- 字符集：UTF-8\n\n\\- 时区：Asia/Shanghai\n\n## 表结构说明\n\n### ods.topsea\\_food (食品表)\n\n用于存储系统中所有食品的基础信息。\n\nCREATE TABLE \"ods\".\"topsea\\_food\" (\n\n  \"id\" int8 NOT NULL,\n\n  \"name\" varchar(255) COLLATE \"pg\\_catalog\".\"default\",\n\n  \"code\" varchar(255) COLLATE \"pg\\_catalog\".\"default\",\n\n  \"create\\_time\" timestamp(6),\n\n  \"update\\_time\" timestamp(6),\n\n  CONSTRAINT \"liyo\\_food\\_pkey\" PRIMARY KEY (\"id\")\n\n)\n\n;\n\nALTER TABLE \"ods\".\"topsea\\_food\" \n\n  OWNER TO \"test\\_realtime\\_metrics\";\n\nCOMMENT ON COLUMN \"ods\".\"topsea\\_food\".\"id\" IS '食品ID，主键';\n\nCOMMENT ON COLUMN \"ods\".\"topsea\\_food\".\"name\" IS '食品名称';\n\nCOMMENT ON COLUMN \"ods\".\"topsea\\_food\".\"code\" IS '食品编码';\n\nCOMMENT ON COLUMN \"ods\".\"topsea\\_food\".\"create\\_time\" IS '创建时间';\n\nCOMMENT ON COLUMN \"ods\".\"topsea\\_food\".\"update\\_time\" IS '修改时间';\n\nCOMMENT ON TABLE \"ods\".\"topsea\\_food\" IS '食品表';\n\n### ods.topsea\\_pr\\_record (烹饪记录表)\n\n记录用户的烹饪活动信息。\n\nCREATE TABLE \"ods\".\"topsea\\_pr\\_record\" (\n\n  \"id\" int8 NOT NULL,\n\n  \"food\\_id\" int8,\n\n  \"event\\_time\" timestamp(6),\n\n  \"account\\_id\" int8,\n\n  \"org\\_id\" int4,\n\n  \"create\\_time\" timestamp(6),\n\n  \"modify\\_time\" timestamp(6),\n\n  \"device\\_id\" int8,\n\n  CONSTRAINT \"pr\\_record\\_pkey\" PRIMARY KEY (\"id\")\n\n)\n\n;\n\nALTER TABLE \"ods\".\"topsea\\_pr\\_record\" \n\n  OWNER TO \"test\\_realtime\\_metrics\";\n\nCOMMENT ON COLUMN \"ods\".\"topsea\\_pr\\_record\".\"id\" IS '烹饪记录ID，主键';\n\nCOMMENT ON COLUMN \"ods\".\"topsea\\_pr\\_record\".\"food\\_id\" IS '食品ID';\n\nCOMMENT ON COLUMN \"ods\".\"topsea\\_pr\\_record\".\"event\\_time\" IS '烹饪时间';\n\nCOMMENT ON COLUMN \"ods\".\"topsea\\_pr\\_record\".\"account\\_id\" IS '用户ID';\n\nCOMMENT ON COLUMN \"ods\".\"topsea\\_pr\\_record\".\"org\\_id\" IS '组织ID';\n\nCOMMENT ON COLUMN \"ods\".\"topsea\\_pr\\_record\".\"create\\_time\" IS '创建时间';\n\nCOMMENT ON COLUMN \"ods\".\"topsea\\_pr\\_record\".\"modify\\_time\" IS '修改时间';\n\nCOMMENT ON COLUMN \"ods\".\"topsea\\_pr\\_record\".\"device\\_id\" IS '设备ID';\n\nCOMMENT ON TABLE \"ods\".\"topsea\\_pr\\_record\" IS '烹饪记录表';\n\n### ods.topsea\\_user (用户表)\n\n存储系统用户基本信息。\n\nCREATE TABLE \"ods\".\"topsea\\_user\" (\n\n  \"id\" int8 NOT NULL,\n\n  \"user\\_name\" varchar(255) COLLATE \"pg\\_catalog\".\"default\",\n\n  \"phone\" varchar(255) COLLATE \"pg\\_catalog\".\"default\",\n\n  \"create\\_time\" timestamp(6),\n\n  \"modify\\_time\" timestamp(6),\n\n  \"sex\" varchar(255) COLLATE \"pg\\_catalog\".\"default\",\n\n  CONSTRAINT \"liyo\\_user\\_pkey\" PRIMARY KEY (\"id\")\n\n)\n\n;\n\nALTER TABLE \"ods\".\"topsea\\_user\" \n\n  OWNER TO \"test\\_realtime\\_metrics\";\n\nCOMMENT ON COLUMN \"ods\".\"topsea\\_user\".\"id\" IS '用户ID，主键';\n\nCOMMENT ON COLUMN \"ods\".\"topsea\\_user\".\"user\\_name\" IS '用户名称';\n\nCOMMENT ON COLUMN \"ods\".\"topsea\\_user\".\"phone\" IS '用户电话号码';\n\nCOMMENT ON COLUMN \"ods\".\"topsea\\_user\".\"create\\_time\" IS '创建时间';\n\nCOMMENT ON COLUMN \"ods\".\"topsea\\_user\".\"modify\\_time\" IS '修改时间';\n\nCOMMENT ON COLUMN \"ods\".\"topsea\\_user\".\"sex\" IS '性别：1 男 ,2 女';\n\nCOMMENT ON TABLE \"ods\".\"topsea\\_user\" IS '用户表';\n\n### ods.topsea\\_device (设备表)\n\n存储烹饪设备基本信息。\n\nCREATE TABLE \"ods\".\"topsea\\_device\" (\n\n  \"id\" int8 NOT NULL,\n\n  \"name\" varchar(255) COLLATE \"pg\\_catalog\".\"default\",\n\n  \"code\" varchar(255) COLLATE \"pg\\_catalog\".\"default\",\n\n  \"create\\_time\" timestamp(6),\n\n  \"modify\\_time\" timestamp(6),\n\n  CONSTRAINT \"topsea\\_device\\_pkey\" PRIMARY KEY (\"id\")\n\n)\n\n;\n\nALTER TABLE \"ods\".\"topsea\\_device\" \n\n  OWNER TO \"test\\_realtime\\_metrics\";\n\nCOMMENT ON COLUMN \"ods\".\"topsea\\_device\".\"id\" IS '设备ID';\n\nCOMMENT ON COLUMN \"ods\".\"topsea\\_device\".\"name\" IS '设备名称';\n\nCOMMENT ON COLUMN \"ods\".\"topsea\\_device\".\"code\" IS '设备编码';\n\nCOMMENT ON COLUMN \"ods\".\"topsea\\_device\".\"create\\_time\" IS '创建时间';\n\nCOMMENT ON COLUMN \"ods\".\"topsea\\_device\".\"modify\\_time\" IS '修改时间';\n\nCOMMENT ON TABLE \"ods\".\"topsea\\_device\" IS '设备信息表';\n\n### ods.topsea\\_standard (标准配置表)\n\n存储组织级别的标准值配置。\n\nCREATE TABLE \"ods\".\"topsea\\_standard\" (\n\n  \"id\" int8 NOT NULL,\n\n  \"standard\\_value\" float8,\n\n  \"org\\_id\" int8,\n\n  \"create\\_time\" timestamp(6),\n\n  \"modify\\_time\" timestamp(6),\n\n  CONSTRAINT \"liyo\\_standard\\_pkey\" PRIMARY KEY (\"id\")\n\n)\n\n;\n\nALTER TABLE \"ods\".\"topsea\\_standard\" \n\n  OWNER TO \"test\\_realtime\\_metrics\";\n\nCOMMENT ON COLUMN \"ods\".\"topsea\\_standard\".\"id\" IS '主键ID';\n\nCOMMENT ON COLUMN \"ods\".\"topsea\\_standard\".\"standard\\_value\" IS '标准值';\n\nCOMMENT ON COLUMN \"ods\".\"topsea\\_standard\".\"org\\_id\" IS '组织ID';\n\nCOMMENT ON COLUMN \"ods\".\"topsea\\_standard\".\"create\\_time\" IS '创建时间';\n\nCOMMENT ON COLUMN \"ods\".\"topsea\\_standard\".\"modify\\_time\" IS '修改时间';\n\nCOMMENT ON TABLE \"ods\".\"topsea\\_standard\" IS '标准配置表';\n\n## 表关系\n\n定义源表和目标表的关联关系。\n\nods.topsea\\_pr\\_record.food\\_id=ods.topsea\\_food.id\n\nods.topsea\\_pr\\_record.account\\_id=ods.topsea\\_user.id\n\nods.topsea\\_pr\\_record.org\\_id=ods.topsea\\_standard.org\\_id\n\nods.topsea\\_pr\\_record.device\\_id=ods.topsea\\_device.id\n\n## 业务规则\n\n### 烹饪达标规则\n\n#### 计算周期\n\n\\- 基本周期：自然月（每月 1 号 00:00:00 重新计算）\n\n\\- 特殊周期：可按组织配置（周、双周、月、季度）\n\n#### 计算规则\n\n\\- 基本公式：\n\n    达标判定：月烹饪次数 ≥ 标准值\n\n    达标率：月烹饪次数/标准值\\*100\n\n#### 使用场景\n\n\\- 用户月度考核\n\n\\- 组织达标率统计\n\n\\- 激励制度依据\n\n### 偏差率计算\n\n\\- 计算公式：(烹饪次数-标准值)/标准值\n\n\\- 阈值范围：\n\n  - 正常：-10% ~ +10%\n\n  - 警告：-30% ~ -10% 或 +10% ~ +30%\n\n  - 异常：< -30% 或 > +30%\n\n\\- 使用场景：用于评估用户烹饪频次与标准值的符合程度\n\n## 索引设计\n\n### ods.topsea\\_food\n\n\\- 主键索引：\\`PRIMARY KEY (id)\\`\n\n\\- 唯一索引：\\`UNIQUE INDEX idx\\_food\\_code (code)\\`\n\n\\- 普通索引：\n\n  - \\`INDEX idx\\_food\\_name (name)\\`\n\n  - \\`INDEX idx\\_food\\_status (status)\\`\n\n### ods.topsea\\_pr\\_record\n\n\\- 主键索引：\\`PRIMARY KEY (id)\\`\n\n\\- 复合索引：\n\n  - \\`INDEX idx\\_pr\\_account\\_time (account\\_id, event\\_time)\\`\n\n  - \\`INDEX idx\\_pr\\_org\\_time (org\\_id, event\\_time)\\`\n\n\\- 外键索引：\n\n  - \\`INDEX idx\\_pr\\_food (food\\_id)\\`\n\n  - \\`INDEX idx\\_pr\\_account (account\\_id)\\`\n\n  - \\`INDEX idx\\_pr\\_org (org\\_id)\\`\n\n### ods.topsea\\_user\n\n\\- 主键索引：\\`PRIMARY KEY (id)\\`\n\n\\- 唯一索引：\\`UNIQUE INDEX idx\\_user\\_phone (phone)\\`\n\n\\- 普通索引：\n\n  - \\`INDEX idx\\_user\\_name (user\\_name)\\`\n\n### ods.topsea\\_device\n\n\\- 主键索引：\\`PRIMARY KEY (id)\\`\n\n\\- 唯一索引：\\`UNIQUE INDEX idx\\_code (code)\\`\n\n\\- 普通索引：\n\n  - \\`INDEX idx\\_user\\_name (user\\_name)\\`\n\n### ods.topsea\\_standard\n\n\\- 主键索引：\\`PRIMARY KEY (id)\\`\n\n\\- 复合索引：\n\n  - \\`INDEX idx\\_standard\\_org (org\\_id)\\`\n\n## 数据字典\n\n### 通用字段说明\n\n\\- create\\_time: 记录创建时间，系统自动生成，精确到微秒\n\n\\- modify\\_time/update\\_time: 记录更新时间，系统自动更新，精确到微秒\n\n\\- create\\_by/update\\_by: 操作人 ID，关联用户表\n\n\\- status: 记录状态，通常 1-有效，0-无效\n\n\\- org\\_id: 组织 ID，关联组织信息表\n\n\\- standard\\_value: 烹饪次数标准值\n\n### 字段格式规范\n\n\\- 电话号码(phone):\n\n  - 格式：1\\[3-9\\]\\\\d{9}\n\n  - 长度：11 位\n\n  - 示例：13800138000\n\n\\- 标准值(standard\\_value):\n\n  - 范围：1-100\n\n  - 精度：整数\n\n\\- 时间戳(TIMESTAMP):\n\n  - 格式：YYYY-MM-DD HH:mm:ss.SSSSSS\n\n  - 时区：Asia/Shanghai\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "jxlhxyp",
      "author_type": "User",
      "created_at": "2025-06-11T09:54:34Z",
      "updated_at": "2025-06-13T10:09:13Z",
      "closed_at": "2025-06-13T10:09:13Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2764/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2764",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2764",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:50.230892",
      "comments": [
        {
          "author": "jxlhxyp",
          "body": "![Image](https://github.com/user-attachments/assets/2e2f45ce-3793-4caf-8d36-6cafe1f1578e)\n有些中文名称，16进制后，会以数字开头，为保证字母开头，加前缀dbgpt。\n上传知识库时，如果前面不加清除fields，会出现fields中出现一份重复的字段。导致读取chunk，插入报错。",
          "created_at": "2025-06-13T10:08:43Z"
        }
      ]
    },
    {
      "issue_number": 2732,
      "title": "[Bug] [ Module: prompt] 公共Promotes 无法创建",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nMacOS(x86)\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n设备：Apple M4\n\n### Models information\n\nLLM：Qwen3-32B  \n\n### What happened\n\n无法创建公共的Promote， 因为Agent创建需要选择Promote。\n\n### What you expected to happen\n\n公共的Promote可以使用。去年的版本好像是可以用的。现在是只有新增Promotes还没有公共的Promotes嘛\n\n### How to reproduce\n\n公共Promotes  点击无任何触发\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "yunfeng1993",
      "author_type": "User",
      "created_at": "2025-05-26T11:12:18Z",
      "updated_at": "2025-06-13T09:53:10Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2732/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2732",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2732",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:50.430877",
      "comments": []
    },
    {
      "issue_number": 2617,
      "title": "[Bug] 启动异常终止 RAG Embedding",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nprovider = \"proxy/siliconflow\"\nLLM：Qwen/Qwen2.5-Coder-32B-Instruct\nembeddings：BAAI/bge-m3\n\n\n### What happened\n\n启动异常终止\n2025-04-12 21:48:19 LAPTOP-VF852O5K dbgpt.storage.base[35772] INFO Loading 118 chunks in 12 groups with 1 threads.\n2025-04-12 21:48:19 LAPTOP-VF852O5K dbgpt_ext.storage.vector_store.chroma_store[35772] INFO ChromaStore load document\n2025-04-12 21:48:19 LAPTOP-VF852O5K dbgpt.model.cluster.worker.embedding_worker[35772] INFO Receive embeddings request, model: BAAI/bge-m3\n2025-04-12 21:48:19 LAPTOP-VF852O5K dbgpt.storage.base[35772] INFO Loaded 10 chunks, total 118 chunks.\n2025-04-12 21:48:20 LAPTOP-VF852O5K dbgpt.storage.base[35772] INFO Loaded 20 chunks, total 118 chunks.\n2025-04-12 21:48:20 LAPTOP-VF852O5K dbgpt_ext.storage.vector_store.chroma_store[35772] INFO ChromaStore load document\n2025-04-12 21:48:20 LAPTOP-VF852O5K dbgpt.model.cluster.worker.embedding_worker[35772] INFO Receive embeddings request, model: BAAI/bge-m3\n...\n2025-04-12 21:48:22 LAPTOP-VF852O5K dbgpt.storage.base[35772] INFO Loaded 90 chunks, total 118 chunks.\n2025-04-12 21:48:22 LAPTOP-VF852O5K dbgpt.model.cluster.worker.embedding_worker[35772] INFO Receive embeddings request, model: BAAI/bge-m3\n到这就异常终止了\n\n### What you expected to happen\n\n默认默认加载 10 chunks，但是total 似乎超过100，就会异常终止，我的total 118 chunks.\n\n### How to reproduce\n\n在mysql中多建入几张表后，重启项目就异常终止了\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "QGcPV7EBU58rclpM",
      "author_type": "User",
      "created_at": "2025-04-12T13:56:53Z",
      "updated_at": "2025-06-13T03:21:01Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2617/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2617",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2617",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:50.430897",
      "comments": [
        {
          "author": "QGcPV7EBU58rclpM",
          "body": "我将max_chunks_once_load调整为1之后：\n2025-04-12 22:08:24 LAPTOP-VF852O5K dbgpt.storage.base[34824] INFO Loaded 96 chunks, total 118 chunks.\n2025-04-12 22:08:24 LAPTOP-VF852O5K dbgpt.model.cluster.worker.embedding_worker[34824] INFO Receive embeddings request, model: BAAI/bge-m3\n2025-04-12 22:08:24 LAPTOP-V",
          "created_at": "2025-04-12T14:10:31Z"
        },
        {
          "author": "xigan-bit",
          "body": "请问解决了嘛\n",
          "created_at": "2025-05-10T07:58:03Z"
        },
        {
          "author": "china-zhz",
          "body": "问题+1  换了chromadb的版本可以了，原文链接：https://github.com/chroma-core/chroma/issues/2513：\n\n![Image](https://github.com/user-attachments/assets/3dbcb6a5-9ed9-43c8-8250-a9c488fdbb6a)",
          "created_at": "2025-05-17T09:50:43Z"
        },
        {
          "author": "kokossk",
          "body": "请问这个问题解决了嘛，我部署也遇到了这个问题 ",
          "created_at": "2025-06-12T02:24:39Z"
        },
        {
          "author": "kokossk",
          "body": "问题已解决，load_document() → _add_texts() → embed_documents() → sync_embeddings() → embeddings()\n问题出在 _add_texts()  这一步，问题集中在  self._collection.upsert(...）  程序直接崩溃没有异常抛出。 \n\nstep1 、调整  ChromaStore.__init__\n\nchroma_settings = Settings(\n            # chroma_db_impl=\"duckdb+parquet\", => deprecated configurat",
          "created_at": "2025-06-13T03:21:01Z"
        }
      ]
    },
    {
      "issue_number": 2757,
      "title": "[Bug] [Module Name] db chat回答效果",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nmac m3pro\n\n### Models information\n\n# Model Configurations\n[models]\n[[models.llms]]\nname = \"Qwen/Qwen2.5-Coder-32B-Instruct\"\nprovider = \"proxy/siliconflow\"\napi_key = \"${env:SILICONFLOW_API_KEY}\"\n\n[[models.embeddings]]\nname = \"BAAI/bge-large-zh-v1.5\"\nprovider = \"proxy/openai\"\napi_url = \"https://api.siliconflow.cn/v1/embeddings\"\napi_key = \"${env:SILICONFLOW_API_KEY}\"\n\n[[models.rerankers]]\ntype = \"reranker\"\nname = \"BAAI/bge-reranker-v2-m3\"\nprovider = \"proxy/siliconflow\"\napi_key = \"${env:SILICONFLOW_API_KEY}\"\n\n### What happened\n\n为什么不能执行sql \n\n![Image](https://github.com/user-attachments/assets/b61b1e2b-b6b1-4f05-98bb-acdb3d585a93)\n\n### What you expected to happen\n\n能够直接回答我的问题 回答执行sql后的问题  比如我要他统计某个值，应该直接返回统计数据，而不是给一个sql\n\n### How to reproduce\n\n数据库为pgsql  建立连接后使用db chat\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "Jaylenwa",
      "author_type": "User",
      "created_at": "2025-06-09T11:22:24Z",
      "updated_at": "2025-06-12T11:59:59Z",
      "closed_at": "2025-06-12T11:59:59Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2757/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2757",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2757",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:50.652408",
      "comments": [
        {
          "author": "fangyinc",
          "body": "Please try `Chat Data`",
          "created_at": "2025-06-09T11:31:37Z"
        }
      ]
    },
    {
      "issue_number": 2766,
      "title": "[Bug] [core] Executing _format_api_context with SQL-containing raw_api_context results in invalid SQL",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [x] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nUnrelated to this issue\n\n### Models information\n\nUnrelated to this issue\n\n### What happened\n\nWhen executing the [ApiCall._format_api_context](https://github.com/eosphoros-ai/DB-GPT/blob/3f88299b29720a83e17debabdef20fb6b48ddb81/packages/dbgpt-core/src/dbgpt/agent/util/api_call.py#L108) funcation, if raw_api_context contains SQL statements along with their comments, the `raw_api_context.replace(\"\\n\", \" \")` operation will cause comments and SQL to end up on the same line. This ultimately results in invalid SQL syntax.  \n\nFor Example:\n```sql\n-- 整体统计数据 WITH overall_stats AS (     SELECT          COUNT(*) AS total_records,         SUM(销售金额) AS total_sales_amount,         AVG(销售单价) AS avg_sales_price,         AVG(销售数量) AS avg_sales_quantity     FROM data_analysis_table ), -- 商品销售分析 top_products AS (     SELECT          商品名称,         SUM(销售数量) AS total_sales_quantity,         SUM(销售金额) AS total_sales_amount     FROM data_analysis_table     GROUP BY 商品名称     ORDER BY total_sales_amount DESC     LIMIT 5 ), -- 收银员销售表现 cashier_performance AS (     SELECT          收银员名称,         COUNT(*) AS total_transactions,         SUM(销售金额) AS total_sales_amount     FROM data_analysis_table     GROUP BY 收银员名称 ) SELECT * FROM overall_stats UNION ALL SELECT * FROM top_products UNION ALL SELECT * FROM cashier_performance;\n```\n\n\n### What you expected to happen\n\nNormal SQL execution\n\n### How to reproduce\n\nExecute SQL\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "geebytes",
      "author_type": "User",
      "created_at": "2025-06-12T09:27:26Z",
      "updated_at": "2025-06-12T09:27:26Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2766/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2766",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2766",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:50.909477",
      "comments": []
    },
    {
      "issue_number": 2765,
      "title": "[Bug] [lyric code]  Consider calling `pyo3::prepare_freethreaded_python()` before attempting to use Python APIs.",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nMacOS(M1, M2...)\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [x] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [x] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nLLM: Qwen-plus\n\n### What happened\n\nthread 'lyric-event-thread-7' panicked at /Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/pyo3-0.22.6/src/gil.rs:198:21:\nassertion `left != right` failed: The Python interpreter is not initialized and the `auto-initialize` feature is not enabled.\n\nConsider calling `pyo3::prepare_freethreaded_python()` before attempting to use Python APIs.\n  left: 0\n right: 0\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\n\n\n### What you expected to happen\n\nrust pyo3 Rust bindings for the Python interpreter\n\n### How to reproduce\n\nIDE Debug\n\n### Additional context\n\nrustc --version\nrustc 1.87.0 (17067e9ac 2025-05-09)\n\ncargo --version\ncargo 1.87.0 (99624be96 2025-05-06)\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "xydz",
      "author_type": "User",
      "created_at": "2025-06-12T02:05:43Z",
      "updated_at": "2025-06-12T02:05:43Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2765/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2765",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2765",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:50.909498",
      "comments": []
    },
    {
      "issue_number": 2244,
      "title": "[Feature]Support other embedding model",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n想知道支不支持指定其它embedding模型，如IEITYuan/Yuan-embedding-1.0, dunzhang/stella_en_400M_v5, Conan-embedding-v1等这些榜单上不错的模型，如果支持，需要在哪里改动？ 谢谢\r\n\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "chuangzhidan",
      "author_type": "User",
      "created_at": "2024-12-23T10:24:19Z",
      "updated_at": "2025-06-11T06:50:15Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2244/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2244",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2244",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:50.909505",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "we provide Embeddings interface for other Embeddings service.\r\n- interface `DB-GPT/dbgpt/core/interface/embeddings.py`\r\n```python\r\nclass Embeddings(ABC):\r\n    \"\"\"Interface for embedding models.\r\n\r\n    Refer to `Langchain Embeddings <https://github.com/langchain-ai/langchain/tree/\r\n    master/libs/la",
          "created_at": "2024-12-23T11:54:54Z"
        },
        {
          "author": "chuangzhidan",
          "body": "> we provide Embeddings interface for other Embeddings service.\r\n> \r\n> * interface `DB-GPT/dbgpt/core/interface/embeddings.py`\r\n> \r\n> ```python\r\n> class Embeddings(ABC):\r\n>     \"\"\"Interface for embedding models.\r\n> \r\n>     Refer to `Langchain Embeddings <https://github.com/langchain-ai/langchain/tre",
          "created_at": "2024-12-25T16:49:00Z"
        },
        {
          "author": "chuangzhidan",
          "body": "> we provide Embeddings interface for other Embeddings service.\r\n> \r\n> * interface `DB-GPT/dbgpt/core/interface/embeddings.py`\r\n> \r\n> ```python\r\n> class Embeddings(ABC):\r\n>     \"\"\"Interface for embedding models.\r\n> \r\n>     Refer to `Langchain Embeddings <https://github.com/langchain-ai/langchain/tre",
          "created_at": "2024-12-25T16:50:10Z"
        },
        {
          "author": "sy960923",
          "body": "想调用xinference的embedding模型要怎么设置呢？",
          "created_at": "2025-01-14T02:23:37Z"
        },
        {
          "author": "sy960923",
          "body": "怎么绑定多个xinference部署的LLM模型？",
          "created_at": "2025-01-14T02:24:22Z"
        }
      ]
    },
    {
      "issue_number": 2103,
      "title": "[Bug]financial_report_knowledge_factory，import error：Embedding dim mension 1024 does not match collection dimensionality 768",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [X] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nXinference模拟openai接口，用的m3e-large\r\nEMBEDDING_MODEL=proxy_http_openapi\r\nproxy_http_openapi_proxy_server_url=http://192.168.1.110:9997/v1/embeddings\r\nproxy_http_openapi_proxy_api_key=1dce29a6d66b4e2dbfec67044edbb924\r\nproxy_http_openapi_proxy_backend=m3e-large-custom\r\n#*******************************************************************#\r\n#**                     FINANCIAL CHAT Config                     **#\r\n#*******************************************************************#\r\nFIN_REPORT_MODEL=proxy_http_openapi\n\n### What happened\n\n2024-10-29 09:28:49 | INFO | dbgpt.core.awel.runner.local_runner | Run operator <class 'financial_report_knowledge_factory.VectorStorageOperator'>(d52f048f-1002-49ab-b8b8-5c4ac561ab5d) error, error message: Traceback (most recent call last):\r\n  File \"d:\\workspace\\python\\pycharmprojects\\aigc\\dbgpt\\db-gpt\\dbgpt\\core\\awel\\runner\\local_runner.py\", line 192, in _execute_node\r\n    await node._run(dag_ctx, task_ctx.log_id)\r\n  File \"d:\\workspace\\python\\pycharmprojects\\aigc\\dbgpt\\db-gpt\\dbgpt\\core\\awel\\operators\\base.py\", line 248, in _run\r\n    return await self._do_run(dag_ctx)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"d:\\workspace\\python\\pycharmprojects\\aigc\\dbgpt\\db-gpt\\dbgpt\\core\\awel\\operators\\common_operator.py\", line 190, in _do_run\r\n    input_ctx: InputContext = await curr_task_ctx.task_input.map(map_function)\r\n                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"d:\\workspace\\python\\pycharmprojects\\aigc\\dbgpt\\db-gpt\\dbgpt\\core\\awel\\task\\task_impl.py\", line 538, in map\r\n    new_outputs, results = await self._apply_func(map_func)\r\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"d:\\workspace\\python\\pycharmprojects\\aigc\\dbgpt\\db-gpt\\dbgpt\\core\\awel\\task\\task_impl.py\", line 533, in _apply_func\r\n    results = await asyncio.gather(*map_tasks)\r\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"d:\\workspace\\python\\pycharmprojects\\aigc\\dbgpt\\db-gpt\\dbgpt\\core\\awel\\task\\task_impl.py\", line 126, in map\r\n    out = await self._apply_func(map_func)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"d:\\workspace\\python\\pycharmprojects\\aigc\\dbgpt\\db-gpt\\dbgpt\\core\\awel\\task\\task_impl.py\", line 112, in _apply_func\r\n    out = await func(self._data)\r\n          ^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\workspace\\python\\PycharmProjects\\python_env\\DBGPT_env\\python-3.11.1.amd64\\Lib\\site-packages\\financial_report_knowledge_factory\\__init__.py\", line 750, in map\r\n    await vector_store.aload_document_with_limit(chunks, max_chunks_once_load)\r\n  File \"d:\\workspace\\python\\pycharmprojects\\aigc\\dbgpt\\db-gpt\\dbgpt\\rag\\index\\base.py\", line 179, in aload_document_with_limit\r\n    return await blocking_func_to_async(\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"d:\\workspace\\python\\pycharmprojects\\aigc\\dbgpt\\db-gpt\\dbgpt\\util\\executor_utils.py\", line 67, in blocking_func_to_async\r\n    return await loop.run_in_executor(executor, run_with_context)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\workspace\\python\\PycharmProjects\\python_env\\DBGPT_env\\python-3.11.1.amd64\\Lib\\concurrent\\futures\\thread.py\", line 58, in run\r\n    result = self.fn(*self.args, **self.kwargs)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"d:\\workspace\\python\\pycharmprojects\\aigc\\dbgpt\\db-gpt\\dbgpt\\util\\executor_utils.py\", line 64, in run_with_context\r\n    return ctx.run(partial(func, *args, **kwargs))\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"d:\\workspace\\python\\pycharmprojects\\aigc\\dbgpt\\db-gpt\\dbgpt\\rag\\index\\base.py\", line 157, in load_document_with_limit\r\n    success_ids = future.result()\r\n                  ^^^^^^^^^^^^^^^\r\n  File \"D:\\workspace\\python\\PycharmProjects\\python_env\\DBGPT_env\\python-3.11.1.amd64\\Lib\\concurrent\\futures\\_base.py\", line 456, in result\r\n    return self.__get_result()\r\n           ^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\workspace\\python\\PycharmProjects\\python_env\\DBGPT_env\\python-3.11.1.amd64\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\r\n    raise self._exception\r\n  File \"D:\\workspace\\python\\PycharmProjects\\python_env\\DBGPT_env\\python-3.11.1.amd64\\Lib\\concurrent\\futures\\thread.py\", line 58, in run\r\n    result = self.fn(*self.args, **self.kwargs)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"d:\\workspace\\python\\pycharmprojects\\aigc\\dbgpt\\db-gpt\\dbgpt\\storage\\vector_store\\chroma_store.py\", line 180, in load_document\r\n    self._add_texts(texts=texts, metadatas=chroma_metadatas, ids=ids)\r\n  File \"d:\\workspace\\python\\pycharmprojects\\aigc\\dbgpt\\db-gpt\\dbgpt\\storage\\vector_store\\chroma_store.py\", line 269, in _add_texts\r\n    self._collection.upsert(\r\n  File \"D:\\workspace\\python\\PycharmProjects\\python_env\\DBGPT_env\\python-3.11.1.amd64\\Lib\\site-packages\\chromadb\\api\\models\\Collection.py\", line 302, in upsert\r\n    self._client._upsert(\r\n  File \"D:\\workspace\\python\\PycharmProjects\\python_env\\DBGPT_env\\python-3.11.1.amd64\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py\", line 146, in wrapper\r\n    return f(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\workspace\\python\\PycharmProjects\\python_env\\DBGPT_env\\python-3.11.1.amd64\\Lib\\site-packages\\chromadb\\api\\segment.py\", line 467, in _upsert\r\n    self._validate_embedding_record_set(coll, records_to_submit)\r\n  File \"D:\\workspace\\python\\PycharmProjects\\python_env\\DBGPT_env\\python-3.11.1.amd64\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py\", line 146, in wrapper\r\n    return f(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\workspace\\python\\PycharmProjects\\python_env\\DBGPT_env\\python-3.11.1.amd64\\Lib\\site-packages\\chromadb\\api\\segment.py\", line 735, in _validate_embedding_record_set\r\n    self._validate_dimension(\r\n  File \"D:\\workspace\\python\\PycharmProjects\\python_env\\DBGPT_env\\python-3.11.1.amd64\\Lib\\site-packages\\chromadb\\api\\segment.py\", line 751, in _validate_dimension\r\n    raise InvalidDimensionException(\r\nchromadb.errors.InvalidDimensionException: Embedding dimension 1024 does not match collection dimensionality 768\n\n### What you expected to happen\n\n/\n\n### How to reproduce\n\n/\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "fryng",
      "author_type": "User",
      "created_at": "2024-10-29T02:39:00Z",
      "updated_at": "2025-06-11T06:47:02Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2103/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2103",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2103",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:51.092625",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "i guess you use different embedding model in same knowledge space, try create another space",
          "created_at": "2024-10-29T15:14:17Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-02-26T21:05:08Z"
        },
        {
          "author": "William-715",
          "body": "我同样是用的xinference部署的bge m3 embedding模型，上传文件到知识库失败：2025-06-11 06:33:26 ebbcb7df35ef dbgpt_app.knowledge.api[1] INFO Received params: test, doc_ids=[5] model_name=None pre_separator=None separators=None chunk_size=None chunk_overlap=None\ncurrent session:<sqlalchemy.orm.session.Session object at 0x751b5",
          "created_at": "2025-06-11T06:47:02Z"
        }
      ]
    },
    {
      "issue_number": 1471,
      "title": "[Feature]DB-GPT integrate xinference",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n你好，我想给dbgpt增加一个xinference的adapter，我目前已经写好了代码，但是我不知道你们原先的adapter是如何被调用的，也就没办法进行测试，请问方便给一些具体的指导嘛？谢谢\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "xiaodouzi666",
      "author_type": "User",
      "created_at": "2024-04-26T08:35:31Z",
      "updated_at": "2025-06-11T06:43:17Z",
      "closed_at": "2024-06-13T21:05:40Z",
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 12,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1471/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "xiaodouzi666"
      ],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1471",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1471",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:51.297729",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "hi, @xiaodouzi666 ，good suggestion, xinference is a good framework, do you join the wechat group? and  @fangyinc will give some how to integrate and how to test suggestion.",
          "created_at": "2024-04-27T11:56:20Z"
        },
        {
          "author": "xiaodouzi666",
          "body": "hi! I don't have your wechat group QR Code since it has been invalid, can u give me a new one? :)",
          "created_at": "2024-04-28T02:49:31Z"
        },
        {
          "author": "Aries-ckt",
          "body": "wechat group code: https://github.com/eosphoros-ai/DB-GPT/blob/main/README.zh.md#%E8%81%94%E7%B3%BB%E6%88%91%E4%BB%AC",
          "created_at": "2024-04-28T06:41:31Z"
        },
        {
          "author": "huang-x-h",
          "body": "Is there any progress？",
          "created_at": "2024-05-06T09:16:44Z"
        },
        {
          "author": "fangyinc",
          "body": "> Is there any progress？\r\n@xiaodouzi666  is developing this feature.",
          "created_at": "2024-05-06T10:43:17Z"
        }
      ]
    },
    {
      "issue_number": 2003,
      "title": "[Bug] [Module Name] How to connect LLM deployed by Xinference to DBGPT？",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n-\n\n### Models information\n\n-\n\n### What happened\n\n通过xinference部署了大模型，如何在前端配置调用xinference部署的大模型\n\n### What you expected to happen\n\n指导我如何配置，前端或在配置文件里\n\n### How to reproduce\n\n-\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "yuerf",
      "author_type": "User",
      "created_at": "2024-09-11T06:31:58Z",
      "updated_at": "2025-06-11T06:39:57Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2003/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2003",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2003",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:51.521900",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "/assign @fangyinc ",
          "created_at": "2024-09-13T15:34:57Z"
        },
        {
          "author": "ericzhi123",
          "body": "Xinference挺好用的，希望能增加对Xinference的支持。",
          "created_at": "2024-10-09T01:56:13Z"
        },
        {
          "author": "bujianbusan",
          "body": "目前有进展了吗？xinference是否已经能够支持了呢？",
          "created_at": "2024-12-24T07:44:22Z"
        },
        {
          "author": "William-715",
          "body": "config文件夹下面新建一个文件（yaml文件指定这个即可，LLM目前看可用，但是embedding bge m3调试有点问题）：dbgpt-xinference-mysql.toml                \n[system]\nlanguage = \"${env:DBGPT_LANG:-zh}\"\napi_keys = []\nencrypt_key = \"your_secret_key\"\n\n[service.web]\nhost = \"0.0.0.0\"\nport = 5670\n\n[service.web.database]\ntype = \"mysql\"\nhost = \"${env:MYS",
          "created_at": "2025-06-11T06:39:57Z"
        }
      ]
    },
    {
      "issue_number": 2335,
      "title": "[Bug] [Module Name] Bug title [ChatKnowledge] document embedding failed Resource not found",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice: CPU\n\n### Models information\n\nLLM: proxy llm azure\nembedding llm: azure\n\n### What happened\n\ncreate a knowledge base, and upload a local file in vector mode, found error:\n\n![Image](https://github.com/user-attachments/assets/6f892637-f0cc-46f9-a334-4934f0dbf0cf)\n\n### What you expected to happen\n\n2025-02-08 16:38:01 ubuntu-jianxin dbgpt.app.knowledge.api[949346] INFO /document/list params: 安全检查, doc_name=None doc_ids=[10] doc_type=None status=None page=1 page_size=20\ncurrent session:<sqlalchemy.orm.session.Session object at 0x7df3a024cbe0>\nINFO:     127.0.0.1:51284 - \"POST /knowledge/%E5%AE%89%E5%85%A8%E6%A3%80%E6%9F%A5/document/list HTTP/1.1\" 200 OK\n2025-02-08 16:38:04 ubuntu-jianxin dbgpt.app.knowledge.api[949346] INFO /document/list params: 安全检查, doc_name=None doc_ids=[10] doc_type=None status=None page=1 page_size=20\ncurrent session:<sqlalchemy.orm.session.Session object at 0x7df3a024eda0>\nINFO:     127.0.0.1:51284 - \"POST /knowledge/%E5%AE%89%E5%85%A8%E6%A3%80%E6%9F%A5/document/list HTTP/1.1\" 200 OK\n2025-02-08 16:38:07 ubuntu-jianxin dbgpt.app.knowledge.api[949346] INFO /document/list params: 安全检查, doc_name=None doc_ids=[10] doc_type=None status=None page=1 page_size=20\ncurrent session:<sqlalchemy.orm.session.Session object at 0x7df3a0237fa0>\nINFO:     127.0.0.1:51284 - \"POST /knowledge/%E5%AE%89%E5%85%A8%E6%A3%80%E6%9F%A5/document/list HTTP/1.1\" 200 OK\n2025-02-08 16:38:07 ubuntu-jianxin dbgpt.serve.rag.service.service[949346] ERROR document embedding, failed:COEKB06 职业卫生档案管理规范.docx, Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}\n2025-02-08 16:38:10 ubuntu-jianxin dbgpt.app.knowledge.api[949346] INFO /document/list params: 安全检查, doc_name=None doc_ids=[10] doc_type=None status=None page=1 page_size=20\ncurrent session:<sqlalchemy.orm.session.Session object at 0x7df3a0312d10>\nINFO:     127.0.0.1:51284 - \"POST /knowledge/%E5%AE%89%E5%85%A8%E6%A3%80%E6%9F%A5/document/list HTTP/1.1\" 200 OK\n/space/list params:\nINFO:     127.0.0.1:51284 - \"POST /knowledge/space/list HTTP/1.1\" 200 OK\n/space/list params:\nINFO:     127.0.0.1:51284 - \"POST /knowledge/space/list HTTP/1.1\" 200 OK\n/knowledge/space/arguments params:\n2025-02-08 16:38:14 ubuntu-jianxin dbgpt.app.knowledge.api[949346] INFO /document/list params: 安全检查, doc_name=None doc_ids=None doc_type=None status=None page=1 page_size=18\n2025-02-08 16:38:14 ubuntu-jianxin dbgpt.app.knowledge.api[949346] INFO /document/list params: 安全检查, doc_name=None doc_ids=None doc_type=None status=None page=1 page_size=18\nINFO:     127.0.0.1:47876 - \"POST /knowledge/%E5%AE%89%E5%85%A8%E6%A3%80%E6%9F%A5/document/list HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:47888 - \"POST /knowledge/%E5%AE%89%E5%85%A8%E6%A3%80%E6%9F%A5/document/list HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:51284 - \"POST /knowledge/%E5%AE%89%E5%85%A8%E6%A3%80%E6%9F%A5/arguments HTTP/1.1\" 200 OK\n2025-02-08 16:40:06 ubuntu-jianxin dbgpt.app.knowledge.api[949346] INFO Received params: 安全检查, doc_ids=[10] model_name=None pre_separator=None separators=None chunk_size=None chunk_overlap=None\ncurrent session:<sqlalchemy.orm.session.Session object at 0x7df3a034c0d0>\n2025-02-08 16:40:06 ubuntu-jianxin dbgpt.serve.rag.connector[949346] INFO VectorStore:<class 'dbgpt.storage.vector_store.chroma_store.ChromaStore'>\n2025-02-08 16:40:06 ubuntu-jianxin dbgpt.serve.rag.service.service[949346] INFO begin save document chunks, doc:COEKB06 职业卫生档案管理规范.docx\n2025-02-08 16:40:10 ubuntu-jianxin dbgpt.serve.rag.service.service[949346] INFO async doc persist sync, doc:COEKB06 职业卫生档案管理规范.docx\n2025-02-08 16:40:21 ubuntu-jianxin dbgpt.util.api_utils[949346] WARNING Health check failed for http://127.0.0.1:5670, error: HTTPConnectionPool(host='127.0.0.1', port=5670): Read timed out. (read timeout=10)\nINFO:     127.0.0.1:59078 - \"POST /knowledge/%E5%AE%89%E5%85%A8%E6%A3%80%E6%9F%A5/document/sync HTTP/1.1\" 200 OK\n2025-02-08 16:40:43 ubuntu-jianxin dbgpt.rag.index.base[949346] INFO Loading 18 chunks in 2 groups with 1 threads.\n2025-02-08 16:40:43 ubuntu-jianxin dbgpt.storage.vector_store.chroma_store[949346] INFO ChromaStore load document\n2025-02-08 16:40:43 ubuntu-jianxin dbgpt.storage.vector_store.chroma_store[949346] INFO ChromaStore load document\n2025-02-08 16:41:00 ubuntu-jianxin dbgpt.serve.rag.service.service[949346] ERROR document embedding, failed:COEKB06 职业卫生档案管理规范.docx, Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}\n\n![Image](https://github.com/user-attachments/assets/8323f10a-ff63-473c-92ee-05e2b8e59d98)\n\n\n### How to reproduce\n\nINFO:     127.0.0.1:43016 - \"POST /knowledge/%E5%AE%89%E5%85%A8%E6%A3%80%E6%9F%A5/document/sync HTTP/1.1\" 200 OK\n2025-02-08 16:41:57 ubuntu-jianxin dbgpt.rag.index.base[949346] INFO Loading 18 chunks in 2 groups with 1 threads.\n2025-02-08 16:41:57 ubuntu-jianxin dbgpt.storage.vector_store.chroma_store[949346] INFO ChromaStore load document\n2025-02-08 16:41:57 ubuntu-jianxin dbgpt.storage.vector_store.chroma_store[949346] INFO ChromaStore load document\n2025-02-08 16:42:07 ubuntu-jianxin dbgpt.serve.rag.service.service[949346] ERROR document embedding, failed:COEKB06 职业卫生档案管理规范.docx, Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}\n2025-02-08 16:42:16 ubuntu-jianxin dbgpt.app.knowledge.api[949346] INFO Received params: 安全检查, doc_ids=[10] model_name=None pre_separator=None separators=None chunk_size=None chunk_overlap=None\ncurrent session:<sqlalchemy.orm.session.Session object at 0x7df3b1507c40>\n2025-02-08 16:42:16 ubuntu-jianxin dbgpt.serve.rag.connector[949346] INFO VectorStore:<class 'dbgpt.storage.vector_store.chroma_store.ChromaStore'>\n2025-02-08 16:42:16 ubuntu-jianxin dbgpt.serve.rag.service.service[949346] INFO begin save document chunks, doc:COEKB06 职业卫生档案管理规范.docx\n2025-02-08 16:42:16 ubuntu-jianxin dbgpt.serve.rag.service.service[949346] INFO async doc persist sync, doc:COEKB06 职业卫生档案管理规范.docx\n2025-02-08 16:42:32 ubuntu-jianxin dbgpt.util.api_utils[949346] WARNING Health check failed for http://127.0.0.1:5670, error: HTTPConnectionPool(host='127.0.0.1', port=5670): Read timed out. (read timeout=10)\nINFO:     127.0.0.1:41878 - \"POST /knowledge/%E5%AE%89%E5%85%A8%E6%A3%80%E6%9F%A5/document/sync HTTP/1.1\" 200 OK\n2025-02-08 16:42:46 ubuntu-jianxin dbgpt.rag.index.base[949346] INFO Loading 18 chunks in 2 groups with 1 threads.\n2025-02-08 16:42:46 ubuntu-jianxin dbgpt.storage.vector_store.chroma_store[949346] INFO ChromaStore load document\n2025-02-08 16:42:46 ubuntu-jianxin dbgpt.storage.vector_store.chroma_store[949346] INFO ChromaStore load document\n2025-02-08 16:43:14 ubuntu-jianxin dbgpt.util.api_utils[949346] WARNING Health check failed for http://127.0.0.1:5670, error: HTTPConnectionPool(host='127.0.0.1', port=5670): Read timed out. (read timeout=10)\n2025-02-08 16:43:14 ubuntu-jianxin dbgpt.serve.rag.service.service[949346] ERROR document embedding, failed:COEKB06 职业卫生档案管理规范.docx, Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}\n\n### Additional context\n\nI tried pdf, docx and text, all of them has this issue\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "jianxinxie",
      "author_type": "User",
      "created_at": "2025-02-08T09:03:34Z",
      "updated_at": "2025-06-10T21:05:52Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2335/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2335",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2335",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:51.719268",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "can you show your embedding settings in .env? ",
          "created_at": "2025-02-09T15:14:41Z"
        },
        {
          "author": "jianxinxie",
          "body": "> can you show your embedding settings in .env?\n\nThis is my embedding setings in .env\n\nEMBEDDING_MODEL=proxy_azure\nproxy_openai_proxy_server_url=https://openai-south.openai.azure.com\nproxy_openai_proxy_api_key=xxxxxx\nproxy_openai_proxy_backend=text-embedding-3-large\n",
          "created_at": "2025-02-10T02:07:17Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-06-10T21:05:51Z"
        }
      ]
    },
    {
      "issue_number": 2340,
      "title": "[Bug] [qwen2/2.5-7b-instruct] VLLM加载模型失败",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU RTX 4090*2\n\n### Models information\n\nLLM_MODEL=qwen2.5-7b-instruct\nEMBEDDING_MODEL=bge-m3\n\n### What happened\n\n正常加载\n\n### What you expected to happen\n\n0\n\n### How to reproduce\n\n0\n\n### Additional context\n\nRERAN2025-02-10 16:13:43 DESKTOP-E9OPQK4 dbgpt.model.adapter.vllm_adapter[48572] INFO Start vllm AsyncLLMEngine with args:\n\n=========================== VLLMModelParameters ===========================\n\ntask: auto\ntokenizer: None\nskip_tokenizer_init: False\nrevision: None\ncode_revision: None\ntokenizer_revision: None\ntokenizer_mode: auto\ntrust_remote_code: True\nallowed_local_media_path: None\ndownload_dir: None\nload_format: auto\nconfig_format: ConfigFormat.AUTO\ndtype: auto\nkv_cache_dtype: auto\nmax_model_len: None\nguided_decoding_backend: xgrammar\nlogits_processor_pattern: None\nmodel_impl: auto\ndistributed_executor_backend: None\npipeline_parallel_size: 1\ntensor_parallel_size: 2\nmax_parallel_loading_workers: None\nray_workers_use_nsight: False\nblock_size: None\nenable_prefix_caching: None\ndisable_sliding_window: False\nuse_v2_block_manager: True\nnum_lookahead_slots: 0\nseed: 0\nswap_space: 4\ncpu_offload_gb: 0\ngpu_memory_utilization: 0.9\nnum_gpu_blocks_override: None\nmax_num_batched_tokens: None\nmax_num_seqs: None\nmax_logprobs: 20\ndisable_log_stats: False\nquantization: None\nrope_scaling: None\nrope_theta: None\nhf_overrides: None\nenforce_eager: False\nmax_seq_len_to_capture: 8192\ndisable_custom_all_reduce: False\ntokenizer_pool_size: 0\ntokenizer_pool_type: ray\ntokenizer_pool_extra_config: None\nlimit_mm_per_prompt: None\nmm_processor_kwargs: None\ndisable_mm_preprocessor_cache: False\nenable_lora: False\nenable_lora_bias: False\nmax_loras: 1\nmax_lora_rank: 16\nlora_extra_vocab_size: 256\nlora_dtype: auto\nlong_lora_scaling_factors: None\nmax_cpu_loras: None\nfully_sharded_loras: False\nenable_prompt_adapter: False\nmax_prompt_adapters: 1\nmax_prompt_adapter_token: 0\ndevice: auto\nnum_scheduler_steps: 1\nmulti_step_stream_outputs: True\nscheduler_delay_factor: 0.0\nenable_chunked_prefill: None\nspeculative_model: None\nspeculative_model_quantization: None\nnum_speculative_tokens: None\nspeculative_disable_mqa_scorer: False\nspeculative_draft_tensor_parallel_size: None\nspeculative_max_model_len: None\nspeculative_disable_by_batch_size: None\nngram_prompt_lookup_max: None\nngram_prompt_lookup_min: None\nspec_decoding_acceptance_method: rejection_sampler\ntypical_acceptance_sampler_posterior_threshold: None\ntypical_acceptance_sampler_posterior_alpha: None\ndisable_logprobs_during_spec_decoding: None\nmodel_loader_extra_config: None\nignore_patterns: None\npreemption_mode: None\nserved_model_name: None\nqlora_adapter_name_or_path: None\notlp_traces_endpoint: None\ncollect_detailed_traces: None\ndisable_async_output_proc: False\nscheduling_policy: fcfs\noverride_neuron_config: None\noverride_pooler_config: None\ncompilation_config: None\nkv_transfer_config: None\nworker_cls: auto\ngeneration_config: None\noverride_generation_config: None\nenable_sleep_mode: False\ncalculate_kv_scales: False\ndisable_log_requests: False\nmodel_name: qwen2.5-7b-instruct\nmodel_path: /mnt/d/project/DB-GPT-main/models/Qwen2.5-7B-Instruct\nmodel_type: vllm\nprompt_template: None\n\n======================================================================\n\n\n2025-02-10 16:13:43 DESKTOP-E9OPQK4 dbgpt.model.cluster.worker.manager[48572] ERROR Error starting worker manager: model qwen2.5-7b-instruct@vllm(172.17.86.174:5670) start failed, Traceback (most recent call last):\n  File \"/mnt/d/project/DB-GPT-main/dbgpt/model/cluster/worker/manager.py\", line 507, in _start_worker\n    await self.run_blocking_func(\n  File \"/mnt/d/project/DB-GPT-main/dbgpt/model/cluster/worker/manager.py\", line 105, in run_blocking_func\n    return await loop.run_in_executor(self.executor, func, *args)\n  File \"/home/lei/anaconda3/envs/dbgpt/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/mnt/d/project/DB-GPT-main/dbgpt/model/cluster/worker/default_worker.py\", line 117, in start\n    self.model, self.tokenizer = self.ml.loader_with_params(\n  File \"/mnt/d/project/DB-GPT-main/dbgpt/model/adapter/loader.py\", line 132, in loader_with_params\n    return llm_adapter.load_from_params(model_params)\n  File \"/mnt/d/project/DB-GPT-main/dbgpt/model/adapter/vllm_adapter.py\", line 78, in load_from_params\n    engine = AsyncLLMEngine.from_engine_args(engine_args)\n  File \"/home/lei/anaconda3/envs/dbgpt/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py\", line 639, in from_engine_args\n    engine_config = engine_args.create_engine_config(usage_context)\n  File \"/home/lei/anaconda3/envs/dbgpt/lib/python3.10/site-packages/vllm/engine/arg_utils.py\", line 1075, in create_engine_config\n    model_config = self.create_model_config()\n  File \"/home/lei/anaconda3/envs/dbgpt/lib/python3.10/site-packages/vllm/engine/arg_utils.py\", line 998, in create_model_config\n    return ModelConfig(\n  File \"/home/lei/anaconda3/envs/dbgpt/lib/python3.10/site-packages/vllm/config.py\", line 302, in __init__\n    hf_config = get_config(self.model, trust_remote_code, revision,\n  File \"/home/lei/anaconda3/envs/dbgpt/lib/python3.10/site-packages/vllm/transformers_utils/config.py\", line 250, in get_config\n    raise ValueError(f\"Unsupported config format: {config_format}\")\nValueError: Unsupported config format: ConfigFormat.AUTO\n\nINFO:     Shutting down\nINFO:     Waiting for application shutdown.\n2025-02-10 16:13:43 DESKTOP-E9OPQK4 dbgpt.model.cluster.worker.manager[48572] INFO Stop all workers\n2025-02-10 16:13:43 DESKTOP-E9OPQK4 dbgpt.model.cluster.worker.manager[48572] INFO Apply req: None, apply_func: <function LocalWorkerManager._stop_all_worker.<locals>._stop_worker at 0x7f6ef8a409d0>\n2025-02-10 16:13:43 DESKTOP-E9OPQK4 dbgpt.model.cluster.worker.manager[48572] INFO Apply to all workers\n2025-02-10 16:13:43 DESKTOP-E9OPQK4 dbgpt.model.cluster.worker.default_worker[48572] WARNING Model has been stopped!!\n2025-02-10 16:13:45 DESKTOP-E9OPQK4 dbgpt.util.code.server[48572] INFO Code server is ready\n2025-02-10 16:13:45 DESKTOP-E9OPQK4 dbgpt.util.api_utils[48572] WARNING No healthy urls found, selecting randomly\n2025-02-10 16:13:45 DESKTOP-E9OPQK4 dbgpt.util.api_utils[48572] WARNING No healthy urls found, selecting randomly\n2025-02-10 16:13:45 DESKTOP-E9OPQK4 dbgpt.model.cluster.worker.manager[48572] WARNING Stop worker, ignored exception from deregister_func: All connection attempts failed\n2025-02-10 16:13:45 DESKTOP-E9OPQK4 dbgpt.model.cluster.worker.manager[48572] WARNING Stop worker, ignored exception from deregister_func: All connection attempts failed\nINFO:     Application shutdown complete.\nINFO:     Finished server process [48572]\nin order to avoid chroma db atexit problemK_MODEL=bge-reranker-v2-m3\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "xuanxuanzl",
      "author_type": "User",
      "created_at": "2025-02-10T08:19:22Z",
      "updated_at": "2025-06-10T21:05:50Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2340/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2340",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2340",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:51.948611",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-06-10T21:05:49Z"
        }
      ]
    },
    {
      "issue_number": 2763,
      "title": "[Bug] [ChatData] 启动项目向量化Oracle数据库数据时程序卡住了，没有报错信息",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [x] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice: CPU\n\n### Models information\n\nEmbedding Model:bge-small-zh-v1.5（本地）\n\n### What happened\n\n1.之前已经对Oracle数据向量完成了，但是遇到问题：提问的时候未检索相关表，而是直接加载所有的表结构信息到prompt中了。搜索相关issue有一条回答是重新向量化数据即可\n2.使用的向量数据库是chroma,删除了pilot下面生成的data跟message。\n3.配置了mysql，sqlite，Oracle三个数据库。前两个都能正常向量化完成，oracle数据库向量化到一半（90chunks/136chunks)卡住不动了。\n\n![Image](https://github.com/user-attachments/assets/1d27c027-75fb-4ae8-8369-b9b3019e7966)\n\n### What you expected to happen\n\n程序未正常启动，导致后端服务不可用\n\n### How to reproduce\n\n1.新增oracle（最好有不相关联系的表以验证是否全部召回）数据库配置，重启项目向量化数据库信息\n2.如果向量化成功的话查看日志，确认是否只召回相关问题的表结构还是召回全部表了\n3.如果召回的是全部表，删除pilot下面的data跟message两个chroma生成的文件，重启项目。\n\n我个人是按照上面步骤操作然后现在启动服务会卡在oracle向量化这一块导致服务启动不起来\n无报错信息，程序卡住相关代码如下：\n文件：packages/dbgpt-ext/src/dbgpt_ext/storage/vector_store/chroma_store.py\n方法：_add_texts\n问题代码：self._collection.upsert(\n                    metadatas=metadatas,\n                    embeddings=embeddings, \n                    documents=texts,\n                    ids=ids,\n                )\n该方法调用的依赖包：.venv/Lib/site-packages/chromadb/api/models/Collection.py\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "chenchenyyds",
      "author_type": "User",
      "created_at": "2025-06-10T10:10:14Z",
      "updated_at": "2025-06-10T10:10:14Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2763/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2763",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2763",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:52.148205",
      "comments": []
    },
    {
      "issue_number": 1937,
      "title": "[Feature][ChatData] add document about table relation, question-sql pair to ChatData",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n```\r\nCurrent ChatData process：Get table information + llm generates sql + exec sql\r\n\r\nDesired process：Get table information + Get information about table relationships + Get related question-sql pair info llm generates sql + exec sql\r\n```\n\n### Use case\n\nChatData, ChatDB\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "dusx1981",
      "author_type": "User",
      "created_at": "2024-09-01T07:40:25Z",
      "updated_at": "2025-06-09T08:40:28Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1937/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1937",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1937",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:52.148230",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-12-30T21:04:51Z"
        },
        {
          "author": "chenchenyyds",
          "body": "我当前是修改了gpt_apps表中param_need的配置,并在前后端实现了多资源的支持，实现chatdata场景支持同时选择数据库以及知识库，使用知识库来协助理解表关系以及相关查询关键字的具体解释。",
          "created_at": "2025-06-09T08:40:27Z"
        }
      ]
    },
    {
      "issue_number": 2744,
      "title": "[Feature][model] Support DeepSeek R1 0528",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n_No response_\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "fangyinc",
      "author_type": "User",
      "created_at": "2025-05-30T15:12:26Z",
      "updated_at": "2025-06-09T08:23:11Z",
      "closed_at": "2025-06-09T08:23:11Z",
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2744/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2744",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2744",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:52.344343",
      "comments": []
    },
    {
      "issue_number": 2753,
      "title": "[Feature][Module Name] 提供没有CUDA 依赖版本的的镜像",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n大模型、embedding 模型全部调用在线api, 希望可以提供纯CPU版本的镜像\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "verigle",
      "author_type": "User",
      "created_at": "2025-06-09T07:58:37Z",
      "updated_at": "2025-06-09T08:02:03Z",
      "closed_at": "2025-06-09T08:02:03Z",
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2753/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2753",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2753",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:52.344364",
      "comments": [
        {
          "author": "fangyinc",
          "body": "Please try [eosphorosai/dbgpt-openai](https://hub.docker.com/r/eosphorosai/dbgpt-openai)",
          "created_at": "2025-06-09T08:02:00Z"
        }
      ]
    },
    {
      "issue_number": 2330,
      "title": "[Feature]深度思考模型前端渲染",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n各位大佬，随着deepseek r1 的火爆，能否考虑给前端增加一个思考输出的渲染呢？例如deepseek r1模型会先输出思考过程，该过程包裹在<think>标签内，但目前不支持对该标签渲染，导致思考过程和结果是混到一起的\n\n<img width=\"770\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/2957b65e-6dbd-4206-9d01-fe11480c7513\" />\n\n### Use case\n\n \n\n### Related issues\n\n \n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "paul-yangmy",
      "author_type": "User",
      "created_at": "2025-02-07T02:15:01Z",
      "updated_at": "2025-06-09T06:23:31Z",
      "closed_at": "2025-06-09T06:23:31Z",
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2330/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2330",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2330",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:52.546827",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "good suggestion, we will take it into consider.",
          "created_at": "2025-02-07T04:42:05Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-06-07T21:04:52Z"
        },
        {
          "author": "fangyinc",
          "body": "Done.",
          "created_at": "2025-06-09T06:23:31Z"
        }
      ]
    },
    {
      "issue_number": 2334,
      "title": "金融财报分析助手指标库查询时出错",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n金融财报分析助手，江苏安靠智能输电工程科技股份有限公司资产负债率查询时，出现以下错误\n\n\n2025-02-08 12:00:19 DESKTOP-SL3CI44 dbgpt.core.awel.runner.local_runner[13996] INFO Run operator <class 'financial_robot_app.chat_indicator.ChatIndicatorOperator'>(555cdc8e-6c8c-4164-b006-7421db1a4be3) error, error message: Traceback (most recent call last):\n  File \"F:\\pyproject\\DB-GPT\\dbgpt\\core\\awel\\runner\\local_runner.py\", line 192, in _execute_node\n    await node._run(dag_ctx, task_ctx.log_id)\n  File \"F:\\pyproject\\DB-GPT\\dbgpt\\core\\awel\\operators\\base.py\", line 248, in _run\n    return await self._do_run(dag_ctx)\n  File \"F:\\pyproject\\DB-GPT\\dbgpt\\core\\awel\\operators\\common_operator.py\", line 190, in _do_run\n    input_ctx: InputContext = await curr_task_ctx.task_input.map(map_function)\n  File \"F:\\pyproject\\DB-GPT\\dbgpt\\core\\awel\\task\\task_impl.py\", line 538, in map\n    new_outputs, results = await self._apply_func(map_func)\n  File \"F:\\pyproject\\DB-GPT\\dbgpt\\core\\awel\\task\\task_impl.py\", line 533, in _apply_func\n    results = await asyncio.gather(*map_tasks)\n  File \"F:\\pyproject\\DB-GPT\\dbgpt\\core\\awel\\task\\task_impl.py\", line 126, in map\n    out = await self._apply_func(map_func)\n  File \"F:\\pyproject\\DB-GPT\\dbgpt\\core\\awel\\task\\task_impl.py\", line 112, in _apply_func\n    out = await func(self._data)\n  File \"D:\\devpinstall\\anaconda3\\envs\\dbgpt_env\\lib\\site-packages\\financial_robot_app\\chat_indicator.py\", line 252, in map\n    table_infos = await self.get_db_summary(\n  File \"D:\\devpinstall\\anaconda3\\envs\\dbgpt_env\\lib\\site-packages\\financial_robot_app\\common.py\", line 136, in get_db_summary\n    retriever = DBSchemaRetriever(top_k=top_k, index_store=index_store)\nTypeError: DBSchemaRetriever.__init__() missing 1 required positional argument: 'table_vector_store_connector'\n\n### Use case\n\n金融财报分析助手，江苏安靠智能输电工程科技股份有限公司资产负债率查询时\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "gezongyang",
      "author_type": "User",
      "created_at": "2025-02-08T06:05:16Z",
      "updated_at": "2025-06-08T21:04:55Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2334/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2334",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2334",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:52.785498",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "what's your dbgpt version? v0.6.3?\n",
          "created_at": "2025-02-08T07:59:39Z"
        },
        {
          "author": "gezongyang",
          "body": "\n\n> what's your dbgpt version? v0.6.3?\n更新到最新版本了\n",
          "created_at": "2025-02-08T08:05:02Z"
        },
        {
          "author": "Aries-ckt",
          "body": "try to downgrade to v0.6.2, dbgpts's financial app did not adapt for v0.6.3 new feature.",
          "created_at": "2025-02-08T08:10:48Z"
        },
        {
          "author": "gezongyang",
          "body": "![Image](https://github.com/user-attachments/assets/f91ac222-2017-4dea-92c9-fc5bd8bedd7d)\nVECTOR_STORE_TYPE=Chroma   向量存储类型设置的是Chroma\n",
          "created_at": "2025-02-08T08:11:09Z"
        },
        {
          "author": "gezongyang",
          "body": "> try to downgrade to v0.6.2, dbgpts's financial app did not adapt for v0.6.3 new feature.\n\nok,thanks",
          "created_at": "2025-02-08T08:11:43Z"
        }
      ]
    },
    {
      "issue_number": 2333,
      "title": "Support deepseek R1?",
      "body": "如题，我想把模型切换到deepseek R1，但是不太清楚具体要改哪些参数，我在代码`model_config.py`里看到有`deepseek_proxyllm`这个选项,但是看起来好像只是指定了厂商为deepseek，没有指定模型，不太清楚怎么指定到 R1 模型。",
      "state": "open",
      "author": "JV-X",
      "author_type": "User",
      "created_at": "2025-02-08T01:47:53Z",
      "updated_at": "2025-06-08T21:04:55Z",
      "closed_at": null,
      "labels": [
        "stale"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2333/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 1
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2333",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2333",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:53.003613",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "```\nLLM_MODEL=deepseek_proxyllm\n# deepseek-chat or deepseek-reasoner\nDEEPSEEK_MODEL_VERSION=deepseek-chat\nDEEPSEEK_API_KEY=sk-xxx\n```",
          "created_at": "2025-02-08T03:37:54Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-06-08T21:04:55Z"
        }
      ]
    },
    {
      "issue_number": 2336,
      "title": "[Feature][Native Scene] Native Scene supports update prompt through UI.",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nNative Scene supports update prompt through UI.\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Aries-ckt",
      "author_type": "User",
      "created_at": "2025-02-08T12:17:07Z",
      "updated_at": "2025-06-08T21:04:53Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2336/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "Aries-ckt"
      ],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2336",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2336",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:53.178700",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-06-08T21:04:52Z"
        }
      ]
    },
    {
      "issue_number": 2752,
      "title": "[Bug] [Module Name] Bug title 最新的v0.7.0以上的版本如何安装？",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n最新的v0.7.0以上的版本如何安装？\n\n### Models information\n\n最新的v0.7.0以上的版本如何安装？\n\n### What happened\n\n最新的v0.7.0以上的版本如何安装？\n\n### What you expected to happen\n\n最新的v0.7.0以上的版本如何安装？\n\n### How to reproduce\n\n最新的v0.7.0以上的版本如何安装？\n\n### Additional context\n\n最新的v0.7.0以上的版本如何安装？很多安装的都不太行\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "wzhiqing",
      "author_type": "User",
      "created_at": "2025-06-06T10:51:26Z",
      "updated_at": "2025-06-08T07:14:59Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2752/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2752",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2752",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:53.388493",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "reference http://docs.dbgpt.cn/docs/next/quickstart",
          "created_at": "2025-06-06T15:21:18Z"
        },
        {
          "author": "wzhiqing",
          "body": "![Image](https://github.com/user-attachments/assets/731c9b52-60fb-4cfc-b08c-c66e1512bf9d)\n一直卡在这，这个是啥原因啊？",
          "created_at": "2025-06-07T06:13:34Z"
        },
        {
          "author": "wzhiqing",
          "body": "uv sync --all-packages --frozen \\\n--extra \"base\" \\\n--extra \"proxy_openai\" \\\n--extra \"rag\" \\\n--extra \"storage_chromadb\" \\\n--extra \"dbgpts\"\n⠼ Preparing packages... (315/316)                       ",
          "created_at": "2025-06-07T06:17:08Z"
        },
        {
          "author": "chenliang15405",
          "body": "maybe network issue, try using this：\n```\nuv sync --all-packages \\\n--extra \"base\" \\\n--extra \"proxy_openai\" \\\n--extra \"rag\" \\\n--extra \"storage_chromadb\" \\\n--extra \"dbgpts\" \\\n--index-url=https://pypi.tuna.tsinghua.edu.cn/simple\n```",
          "created_at": "2025-06-08T07:14:58Z"
        }
      ]
    },
    {
      "issue_number": 2688,
      "title": "No module named 'oracledb'",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [x] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [x] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\ndefault\n\n### What happened\n\nWhen I was creating an Oracle database connection, an error occurred \n\n![Image](https://github.com/user-attachments/assets/826a223c-bd63-459e-ae6e-227ad9a1809e)\n\n### What you expected to happen\n\nSuccessfully created Oracle database connection\n\n### How to reproduce\n\nAfter filling in the connection information, click submit\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "DuskBelievers",
      "author_type": "User",
      "created_at": "2025-05-13T08:23:21Z",
      "updated_at": "2025-06-08T07:11:36Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2688/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2688",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2688",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:53.574524",
      "comments": [
        {
          "author": "chenliang15405",
          "body": "It look like the default Docker image does not include Oracle dependencies occur question, maybe you can refer the [Docker Build Guid](http://docs.dbgpt.cn/docs/next/installation/docker-build-guide) document to build a custom image with oracle database.\n\nOracle Extra Package is : `datasource_oracle`",
          "created_at": "2025-05-15T12:11:56Z"
        },
        {
          "author": "zack-cz",
          "body": "> It look like the default Docker image does not include Oracle dependencies occur question, maybe you can refer the [Docker Build Guid](http://docs.dbgpt.cn/docs/next/installation/docker-build-guide) document to build a custom image with oracle database.\n> \n> Oracle Extra Package is : `datasource_o",
          "created_at": "2025-05-22T09:57:44Z"
        },
        {
          "author": "DuskBelievers",
          "body": "@zack-cz You should install 'oracledb' package inside Docker because the error message is \"No module named 'oracledb' \"",
          "created_at": "2025-05-23T06:08:01Z"
        },
        {
          "author": "chenliang15405",
          "body": "> > It look like the default Docker image does not include Oracle dependencies occur question, maybe you can refer the [Docker Build Guid](http://docs.dbgpt.cn/docs/next/installation/docker-build-guide) document to build a custom image with oracle database.\n> > Oracle Extra Package is : `datasource_",
          "created_at": "2025-06-08T07:11:35Z"
        }
      ]
    },
    {
      "issue_number": 2332,
      "title": "[Bug] [Module Name] Bug title await queue.put(\"[DONE]\") AttributeError: 'NoneType' object has no attribute 'put'",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\ngpu\n2 counts\n80G*2\n\n### Models information\n\nLLM:glm-4-9b-chat\nembedding:text2vec\n\n### What happened\n\n调用单一Agent应用的api时出现报错，但前端对话方式无问题，之前同样的调用方式在0.6.1版本可以实现成功调用，但后来升级0.6.3之后出现这个问题，后续降级版本也未解决\n代码：\nfrom dbgpt.client import Client\n\nDBGPT_API_KEY = \"dbgpt\"\nAPP_ID=\"xxx\"\n\nclient = Client(api_key=DBGPT_API_KEY)\n\nasync for data in client.chat_stream(\n    messages=\"等太久了\", \n    model=\"glm-4-9b-chat\", \n    chat_mode=\"chat_app\", \n    chat_param=APP_ID,\n\n\n\n):\n    print(data)\n    # if \"大类\" in data:\n\n报错：\n2025-02-07 17:39:41 gpu-node dbgpt.serve.agent.agents.controller[1248478] INFO agent_chat_v2 conv_id:5fb1d034-95fa-4371-988e-e011f11f44aa,gpts_name:d66a1cf8-a581-11ef-8487-9cc2c455fa2d,user_query:等太久了\n2025-02-07 17:39:41 gpu-node dbgpt.serve.agent.agents.controller[1248478] INFO gpts_conversations count:5fb1d034-95fa-4371-988e-e011f11f44aa,0\nINFO:     127.0.0.1:59450 - \"POST /api/v2/chat/completions HTTP/1.1\" 200 OK\n2025-02-07 17:39:42 gpu-node dbgpt.serve.rag.connector[1248478] INFO VectorStore:<class 'dbgpt.storage.vector_store.chroma_store.ChromaStore'>\n\n--------------------------------------------------------------------------------\nUser (to Aristotle)-[]:\n\n\"等太久了\"\n\n--------------------------------------------------------------------------------\n2025-02-07 17:39:42 gpu-node dbgpt.agent.core.base_agent[1248478] INFO generate agent reply!sender=profile=ProfileConfig(profile_id=0, name='User', role='Human', goal=<dbgpt.util.configure.base.ConfigInfo object at 0x7fdbc30f5540>, retry_goal=<dbgpt.util.configure.base.ConfigInfo object at 0x7fdbc30f5510>, constraints=<dbgpt.util.configure.base.ConfigInfo object at 0x7fdbc30f5570>, retry_constraints=<dbgpt.util.configure.base.ConfigInfo object at 0x7fdbc30f5990>, desc=<dbgpt.util.configure.base.ConfigInfo object at 0x7fdbc30f5a20>, expand_prompt=<dbgpt.util.configure.base.ConfigInfo object at 0x7fdbc30f5ab0>, examples=<dbgpt.util.configure.base.ConfigInfo object at 0x7fdbc30f5b10>, system_prompt_template=<dbgpt.util.configure.base.ConfigInfo object at 0x7fdbc30f5b70>, user_prompt_template=<dbgpt.util.configure.base.ConfigInfo object at 0x7fdbc30f5bd0>, write_memory_template=<dbgpt.util.configure.base.ConfigInfo object at 0x7fdbc30f5c30>, factory=None) memory=<dbgpt.agent.core.memory.agent_memory.AgentMemory object at 0x7fdae850b1f0> fixed_subgoal=None language='zh' is_human=True is_team=False template_env=<jinja2.sandbox.SandboxedEnvironment object at 0x7fdae8508100> agent_context=AgentContext(conv_id='5fb1d034-95fa-4371-988e-e011f11f44aa_1', gpts_app_code='d66a1cf8-a581-11ef-8487-9cc2c455fa2d', gpts_app_name='差评分类', language='zh', max_chat_round=100, max_retry_round=10, max_new_tokens=1024, temperature=0.5, allow_format_str_template=False, verbose=False, app_link_start=False, enable_vis_message=True) actions=[] resource=None llm_config=None bind_prompt=None max_retry_count=3 llm_client=None stream_out=True show_reference=False executor=<concurrent.futures.thread.ThreadPoolExecutor object at 0x7fdae850bc10> ask_user=False, rely_messages_len=None\n2025-02-07 17:39:42 gpu-node dbgpt.agent.core.base_agent[1248478] INFO Depends on the number of historical messages:0！\nClient disconnected\n2025-02-07 17:39:42 gpu-node dbgpt.serve.agent.agents.controller[1248478] INFO Chat to App d66a1cf8-a581-11ef-8487-9cc2c455fa2d:5fb1d034-95fa-4371-988e-e011f11f44aa_1 Cancel!\n2025-02-07 17:39:42 gpu-node dbgpt.serve.agent.agents.controller[1248478] INFO save agent chat info！5fb1d034-95fa-4371-988e-e011f11f44aa\n2025-02-07 17:39:42 gpu-node asyncio[1248478] ERROR Task exception was never retrieved\nfuture: <Task finished name='Task-7841' coro=<MultiAgents.agent_team_chat_new() done, defined at /data/soft/DB-GPT/dbgpt/serve/agent/agents/controller.py:409> exception=AttributeError(\"'NoneType' object has no attribute 'put'\")>\nTraceback (most recent call last):\n  File \"/data/soft/DB-GPT/dbgpt/serve/agent/agents/controller.py\", line 526, in agent_team_chat_new\n    await user_proxy.initiate_chat(\n  File \"/data/soft/DB-GPT/dbgpt/agent/core/base_agent.py\", line 651, in initiate_chat\n    await self.send(\n  File \"/data/soft/DB-GPT/dbgpt/agent/core/base_agent.py\", line 226, in send\n    await recipient.receive(\n  File \"/data/soft/DB-GPT/dbgpt/agent/core/base_agent.py\", line 269, in receive\n    reply = await self.generate_reply(\n  File \"/data/soft/DB-GPT/dbgpt/agent/core/base_agent.py\", line 363, in generate_reply\n    thinking_messages, resource_info = await self._load_thinking_messages(\n  File \"/data/soft/DB-GPT/dbgpt/agent/core/base_agent.py\", line 991, in _load_thinking_messages\n    resource_prompt_str, resource_references = await self.load_resource(\n  File \"/data/soft/DB-GPT/dbgpt/agent/expand/summary_assistant_agent.py\", line 108, in load_resource\n    resource_prompt, resource_reference = await self.resource.get_prompt(\n  File \"/data/soft/DB-GPT/dbgpt/util/cache_utils.py\", line 77, in wrapper\n    val = await func(*args, **kwargs)\n  File \"/data/soft/DB-GPT/dbgpt/agent/resource/knowledge.py\", line 69, in get_prompt\n    chunks = await self.retrieve(question)\n  File \"/data/soft/DB-GPT/dbgpt/agent/resource/knowledge.py\", line 152, in retrieve\n    return await self.retriever.aretrieve_with_scores(query, score, filters)\n  File \"/data/soft/DB-GPT/dbgpt/rag/retriever/base.py\", line 100, in aretrieve_with_scores\n    return await self._aretrieve_with_score(query, score_threshold, filters)\n  File \"/data/soft/DB-GPT/dbgpt/serve/rag/retriever/knowledge_space.py\", line 158, in _aretrieve_with_score\n    return await self._retriever_chain.aretrieve_with_scores(\n  File \"/data/soft/DB-GPT/dbgpt/rag/retriever/base.py\", line 100, in aretrieve_with_scores\n    return await self._aretrieve_with_score(query, score_threshold, filters)\n  File \"/data/soft/DB-GPT/dbgpt/serve/rag/retriever/retriever_chain.py\", line 90, in _aretrieve_with_score\n    candidates_with_scores = await retriever.aretrieve_with_scores(\n  File \"/data/soft/DB-GPT/dbgpt/rag/retriever/base.py\", line 100, in aretrieve_with_scores\n    return await self._aretrieve_with_score(query, score_threshold, filters)\n  File \"/data/soft/DB-GPT/dbgpt/serve/rag/retriever/qa_retriever.py\", line 181, in _aretrieve_with_score\n    candidates_with_score = await blocking_func_to_async(\n  File \"/data/soft/DB-GPT/dbgpt/util/executor_utils.py\", line 67, in blocking_func_to_async\n    return await loop.run_in_executor(executor, run_with_context)\nasyncio.exceptions.CancelledError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/data/soft/DB-GPT/dbgpt/serve/agent/agents/controller.py\", line 546, in agent_team_chat_new\n    await self.memory.complete(conv_uid)\n  File \"/data/soft/DB-GPT/dbgpt/agent/core/memory/gpts/gpts_memory.py\", line 117, in complete\n    await queue.put(\"[DONE]\")\nAttributeError: 'NoneType' object has no attribute 'put'\n\n\n### What you expected to happen\n\n问ai返回下面信息，不确定是否是Pydantic 版本问题导致的，当前pip版本\npydantic                                 2.10.0\npydantic_core                            2.27.0\npydantic-settings                        2.7.0\n：\n从错误信息来看，问题主要出现在以下几个方面：\nChatCompletionStreamResponse缺少字段：根据错误信息，Pydantic 模型验证失败，缺少字段 usage。这意味着返回的数据没有完全符合模型的要求，usage 字段是必填项。\nNoneType对象没有put方法：这是由于尝试在 None 对象上调用 put 方法。这个错误通常意味着在某些情况下，队列对象没有正确初始化，或者在调用时对象不存在。\n根据这些信息，我建议你检查以下几点：\n1. 确保 SSE 数据结构正确\n错误指示SSE数据中的字段不完整，可能是返回的 API 数据结构与预期的不匹配。你需要确认 ChatCompletionStreamResponse 类的定义，确保其正确匹配 API 返回的数据格式。如果没有 usage 字段，可能需要检查 API 是否有变化，或者手动添加缺失的字段。\n2. 处理NoneType对象\n出现 NoneType 错误可能与内存管理或消息处理部分的逻辑有关。检查队列或代理的初始化是否正确，确保在执行操作之前对象已被正确创建和传递。\n3. 确保client.chat_stream调用的参数正确\n你传入 client.chat_stream 的参数可能导致了响应格式问题。确保messages, model, chat_mode, chat_param 等参数格式正确，且与你的 API 服务的要求相符。\n调试步骤：\n检查 API 数据返回格式：你可以打印或调试 sse_data，看看返回数据中是否有遗漏字段。\n修复 usage 字段缺失：根据 Pydantic 错误，补充 usage 字段的处理或检查返回数据的源头。\n检查对象初始化：确保所有使用的对象，如队列、代理等，在使用之前已经正确初始化。\n如果问题依然存在，建议你查看相关文档或联系 API 提供方，以确认 API 是否发生了更改，或者是否有新的参数要求。\n这个错误信息表明在执行 client.chat_stream 时，发生了两个问题：\nNoneType object has no attribute 'put'：\n这个错误意味着代码在尝试调用 queue.put(\"[DONE]\") 时，queue 是 None 类型，导致无法执行 put 方法。这个问题通常是因为初始化的 queue 对象没有正确赋值，或者在代码中没有创建 queue。\nasyncio.exceptions.CancelledError：\n这是异步操作被取消时抛出的异常。通常在并发操作中，某些任务被取消可能会引发此异常。\n可能的解决方案：\n1. 检查 queue 初始化：\n在错误日志中，queue.put(\"[DONE]\") 被调用时，queue 是 None，这通常是因为 queue 没有被正确初始化。你需要检查以下几点：\n确保在使用 queue 前已经创建并初始化了 queue 对象。\n如果 queue 是在某个地方动态创建的，确保它在出错的地方是有效的，并且没有被提前销毁或置为 None。\n检查如下代码：\n# 确保初始化队列\nqueue = asyncio.Queue()\n2. 检查异步操作的取消：\nasyncio.exceptions.CancelledError 通常表示某个异步任务被取消。你需要确保在执行异步任务时，没有其他地方取消了它。\n如果你手动取消任务，确保有合适的异常处理。\n确保异步任务的 await 操作没有被其他逻辑中断。\n示例：\ntry:\n    await some_async_function()\nexcept asyncio.CancelledError:\n    # 在任务被取消时执行的代码\n    print(\"Task was cancelled.\")\n3. 检查连接和 API 调用：\n由于错误日志涉及到 client.chat_stream 调用，可能需要检查 API 调用部分，确保所有参数（例如 messages、model 等）都是正确的，且服务端能够正常响应。如果服务端返回了连接中断或取消任务的消息，你也可能遇到这种异常。\n4. 日志详细分析：\n日志中显示了很多与 memory 和 agent 相关的操作，可能是因为某些资源在任务执行过程中被取消，导致某些操作未能完成。可以检查涉及 memory 和 agent 管理的部分，看看是否存在资源管理上的问题。\n总结：\n确保初始化了 queue。\n处理异步任务被取消的情况。\n检查 API 请求的正确性和稳定性。\n如果问题仍然存在，可以提供更多代码细节，帮助进一步分析问题。\n\n### How to reproduce\n\n出现这个问题之后降级过0.5.9  0.5.10  .0.6.2等版本  都有不同的报错  最后0.6.0版本以上基本属于这种报错\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "uniquecdmx",
      "author_type": "User",
      "created_at": "2025-02-07T09:49:56Z",
      "updated_at": "2025-06-07T21:04:51Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2332/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2332",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2332",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:53.795663",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-06-07T21:04:51Z"
        }
      ]
    },
    {
      "issue_number": 2749,
      "title": "[Feature][Module Name] add AI/ML API as provider",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nHi!\n\nI'm Sergey from the Integrations team over at [AI/ML API](https://aimlapi.com/), a startup with 150K+ users, providing over 300 AI models in one place\n\nYour project looks dope, so we'd like to have a native integration with it. We already got integrations with Langflow, AutoGPT, and LiteLLM - so our integrations team is pretty seasoned :)\n\nSay you're interested, and we'll test the compatibility, update the code/docs to include us, create a PR and add a tutorial on using DB-GPT with AI/ML API to our docs\n\nIf you guys give us a green light, we could get on it next week 👷\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "OctavianTheI",
      "author_type": "User",
      "created_at": "2025-06-05T06:34:52Z",
      "updated_at": "2025-06-06T15:29:21Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2749/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2749",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2749",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:54.144845",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "We are delighted that you recognize the value of our product. We are also very pleased to collaborate with your company. Previously, we have cooperated with SiliconFlow as well (https://docs.siliconflow.cn/en/usercases/use-siliconcloud-in-DB-GPT). We can integrate the model services you provide, and",
          "created_at": "2025-06-06T15:29:20Z"
        }
      ]
    },
    {
      "issue_number": 2687,
      "title": "[Bug] [Module Name] windows  Segmentation fault",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU\ngpu count：1\ngpu memoryl4G\n\n### Models information\n\nLLM:OLLAMA\n\n\n### What happened\n\nUse pycharm debug to start the code. At first, it can be accessed normally, but later the page prompts that it cannot be accessed, and the console does not respond directly. Use UV source code to start, and it also starts normally at the beginning. Wait for 10-20 seconds, output Segmentation fault, and add an import fault handler in dbgpt_server\nfaulthandler.enable()， You can see the logs：\nWindows fatal exception: access violation\n\nCurrent thread 0x0000992c (most recent call first):\nFile \"G:\\dbgpt\\dbgpt.venv\\Lib\\site-packages\\chromadb\\segment\\impl\\vector\\local_hnsw.py\", line 279 in apply_batch\nFile \"G:\\dbgpt\\dbgpt.venv\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry_init.py\", line 150 in wrapper\nFile \"G:\\dbgpt\\dbgpt.venv\\Lib\\site-packages\\chromadb\\segment\\impl\\vector\\local_persistent_hnsw.py\", line 281 in apply_batch\nFile \"G:\\dbgpt\\dbgpt.venv\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry_init.py\", line 150 in wrapper\nFile \"G:\\dbgpt\\dbgpt.venv\\Lib\\site-packages\\chromadb\\segment\\impl\\vector\\local_persistent_hnsw.py\", line 349 in write_records\nFile \"G:\\dbgpt\\dbgpt.venv\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry_init.py\", line 150 in wrapper\nFile \"G:\\dbgpt\\dbgpt.venv\\Lib\\site-packages\\chromadb\\db\\mixins\\embeddings_queue.py\", line 450 in notify_one\nFile \"G:\\dbgpt\\dbgpt.venv\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry_init.py\", line 150 in wrapper\nFile \"G:\\dbgpt\\dbgpt.venv\\Lib\\site-packages\\chromadb\\db\\mixins\\embeddings_queue.py\", line 430 in notify_all\nFile \"G:\\dbgpt\\dbgpt.venv\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry_init.py\", line 150 in wrapper\nFile \"G:\\dbgpt\\dbgpt.venv\\Lib\\site-packages\\chromadb\\db\\mixins\\embeddings_queue.py\", line 265 in submit_embeddings\nFile \"G:\\dbgpt\\dbgpt.venv\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry_init_.py\", line 150 in wrapper\nFile \"G:\\dbgpt\\dbgpt.venv\\Lib\\site-packages\\chromadb\\api\\segment.py\", line 564 in upsert\nFile \"G:\\dbgpt\\dbgpt.venv\\Lib\\site-packages\\chromadb\\rate_limit\\simple_rate_limit_init.py\", line 24 in wrapper\nFile \"G:\\dbgpt\\dbgpt.venv\\Lib\\site-packages\\chromadb\\api\\segment.py\", line 103 in wrapper\nFile \"G:\\dbgpt\\dbgpt.venv\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry_init_.py\", line 150 in wrapper\nFile \"G:\\dbgpt\\dbgpt.venv\\Lib\\site-packages\\chromadb\\api\\models\\Collection.py\", line 344 in upsert\nFile \"G:\\dbgpt\\\\packages\\dbgpt-ext\\src\\dbgpt_ext\\storage\\vector_store\\chroma_store.py\", line 347 in _add_texts\nFile \"G:\\dbgpt\\\\packages\\dbgpt-ext\\src\\dbgpt_ext\\storage\\vector_store\\chroma_store.py\", line 227 in load_document\nFile \"G:\\python311\\Lib\\concurrent\\futures\\thread.py\", line 58 in run\nFile \"G:\\python311\\Lib\\concurrent\\futures\\thread.py\", line 83 in _worker\nFile \"G:\\python311\\Lib\\threading.py\", line 982 in run\nFile \"G:\\python311\\Lib\\threading.py\", line 1045 in _bootstrap_inner\nFile \"G:\\python311\\Lib\\threading.py\", line 1002 in _bootstrap\n\nThread 0x00009868 (most recent call first):\nFile \"G:\\python311\\Lib\\threading.py\", line 331 in wait\nFile \"G:\\python311\\Lib\\queue.py\", line 180 in get\nFile \"G:\\dbgpt\\dbgpt.venv\\Lib\\site-packages\\posthog\\consumer.py\", line 107 in next\nFile \"G:\\dbgpt\\dbgpt.venv\\Lib\\site-packages\\posthog\\consumer.py\", line 76 in upload\nFile \"G:\\dbgpt\\dbgpt.venv\\Lib\\site-packages\\posthog\\consumer.py\", line 65 in run\nFile \"G:\\python311\\Lib\\threading.py\", line 1045 in _bootstrap_inner\nFile \"G:\\python311\\Lib\\threading.py\", line 1002 in _bootstrap\n\nThread 0x00008944 (most recent call first):\nFile \"G:\\python311\\Lib\\threading.py\", line 327 in wait\nFile \"G:\\python311\\Lib\\concurrent\\futures_base.py\", line 451 in result\nFile \"G:\\dbgpt\\packages\\dbgpt-core\\src\\dbgpt\\storage\\base.py\", line 134 in load_document_with_limit\nFile \"G:\\dbgpt\\packages\\dbgpt-ext\\src\\dbgpt_ext\\rag\\assembler\\db_schema.py\", line 134 in persist\nFile \"G:\\dbgpt\\packages\\dbgpt-serve\\src\\dbgpt_serve\\datasource\\service\\db_summary_client.py\", line 127 in init_db_profile\nFile \"G:\\dbgpt\\packages\\dbgpt-serve\\src\\dbgpt_serve\\datasource\\service\n\n### What you expected to happen\n\nfix\n\n### How to reproduce\n\nfix\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "yqyqyqyqyqyq",
      "author_type": "User",
      "created_at": "2025-05-13T07:06:10Z",
      "updated_at": "2025-06-04T09:14:06Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2687/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2687",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2687",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:54.400809",
      "comments": [
        {
          "author": "chenliang15405",
          "body": "no more error and behavior information, maybe It seems like that the machine  memory is insufficient error.",
          "created_at": "2025-06-04T09:14:06Z"
        }
      ]
    },
    {
      "issue_number": 2747,
      "title": "[Bug] [连接doris数据库出错] ValueError: Test connection Failure!Can't load plugin: sqlalchemy.dialects:doris",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [x] Chat Data\n- [ ] Chat Excel\n- [x] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [x] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nlinux ubuntu20.04\nGPU\n\n### Models information\n\n[[models.llms]]\nname = \"deepseek-chat\"\nprovider = \"proxy/deepseek\"\napi_key = \"xxxx\"\n\n[[models.embeddings]]\nname = \"BAAI/bge-m3\"\nprovider = \"hf\"\npath = \"/app/models/BAAI-bge-m3\"\n\n\n### What happened\n\n我的docker启动命令:\ndocker run --ipc host --gpus all \\\n  -it --rm \\\n  -p 15670:15670 \\\n  -v $(pwd)/dbgpt-local-gpu.toml:/app/configs/dbgpt-local-gpu.toml \\\n  -v $(pwd)/models:/app/models \\\n  -v $(pwd)/pilot/data:/app/pilot/data \\\n  -v $(pwd)/pilot/message:/app/pilot/message \\\n  -v $(pwd)/pilot/alembic_versions:/app/pilot/meta_data/alembic/versions \\\n  --name dbgpt eosphorosai/dbgpt:latest \\\n  dbgpt start webserver --config /app/configs/dbgpt-local-gpu.toml\n\n\n启动后连接 doris数据库报错:\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 409, in run_asgi\n    result = await app(  # type: ignore[func-returns-value]\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n    return await self.app(scope, receive, send)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    await self.simple_response(scope, receive, send, request_headers=headers)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    await self.app(scope, receive, send)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/fastapi/applications.py\", line 1054, in __call__\n    await super().__call__(scope, receive, send)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/applications.py\", line 113, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 187, in __call__\n    raise exc\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    await self.app(scope, receive, _send)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 185, in __call__\n    with collapse_excgroups():\n  File \"/usr/lib/python3.11/contextlib.py\", line 155, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/_utils.py\", line 83, in collapse_excgroups\n    raise exc\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 187, in __call__\n    response = await self.dispatch_func(request, call_next)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/util/tracer/tracer_middleware.py\", line 49, in dispatch\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 163, in call_next\n    raise app_exc\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 149, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n    raise exc\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    await app(scope, receive, sender)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/routing.py\", line 715, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/routing.py\", line 735, in app\n    await route.handle(scope, receive, send)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n    raise exc\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    await app(scope, receive, sender)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/routing.py\", line 73, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 301, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    return await dependant.call(**values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-serve/src/dbgpt_serve/datasource/api/endpoints.py\", line 239, in test_connection\n    res = await blocking_func_to_async(\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-serve/src/dbgpt_serve/core/__init__.py\", line 32, in blocking_func_to_async\n    return await _blocking_func_to_async(executor, func, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/util/executor_utils.py\", line 70, in blocking_func_to_async\n    return await loop.run_in_executor(executor, run_with_context)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/util/executor_utils.py\", line 67, in run_with_context\n    return ctx.run(partial(func, *args, **kwargs))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/service.py\", line 288, in test_connection\n    return self.datasource_manager.test_connection(request)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-serve/src/dbgpt_serve/datasource/manages/connector_manager.py\", line 273, in test_connection\n    raise ValueError(f\"Test connection Failure!{str(e)}\")\nValueError: Test connection Failure!Can't load plugin: sqlalchemy.dialects:doris\n\n\n我使用源代码启动也报同样的错误, 并且我搜索了一些之前的issue, 安装了一些包:\nsudo apt install -y mysql-client libmysqlclient-dev pkg-config\npip install mysqlclient==2.1.0\npip install pydoris==1.0.6\npip install SQLAlchemy==2.0.25\n\n此时连接doris数据库时报错:\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/nlp/project/DB-GPT/.venv/lib/python3.11/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 409, in run_asgi\n    result = await app(  # type: ignore[func-returns-value]\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/nlp/project/DB-GPT/.venv/lib/python3.11/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n    return await self.app(scope, receive, send)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/nlp/project/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    await self.simple_response(scope, receive, send, request_headers=headers)\n  File \"/home/nlp/project/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    await self.app(scope, receive, send)\n  File \"/home/nlp/project/DB-GPT/.venv/lib/python3.11/site-packages/fastapi/applications.py\", line 1054, in __call__\n    await super().__call__(scope, receive, send)\n  File \"/home/nlp/project/DB-GPT/.venv/lib/python3.11/site-packages/starlette/applications.py\", line 113, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/home/nlp/project/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 187, in __call__\n    raise exc\n  File \"/home/nlp/project/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    await self.app(scope, receive, _send)\n  File \"/home/nlp/project/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 185, in __call__\n    with collapse_excgroups():\n  File \"/home/nlp/.local/share/uv/python/cpython-3.11.12-linux-x86_64-gnu/lib/python3.11/contextlib.py\", line 158, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/home/nlp/project/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_utils.py\", line 83, in collapse_excgroups\n    raise exc\n  File \"/home/nlp/project/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 187, in __call__\n    response = await self.dispatch_func(request, call_next)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/nlp/project/DB-GPT/packages/dbgpt-core/src/dbgpt/util/tracer/tracer_middleware.py\", line 49, in dispatch\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/nlp/project/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 163, in call_next\n    raise app_exc\n  File \"/home/nlp/project/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 149, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/home/nlp/project/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/home/nlp/project/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n    raise exc\n  File \"/home/nlp/project/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/home/nlp/project/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 715, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/home/nlp/project/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 735, in app\n    await route.handle(scope, receive, send)\n  File \"/home/nlp/project/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"/home/nlp/project/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/home/nlp/project/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n    raise exc\n  File \"/home/nlp/project/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/home/nlp/project/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 73, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"/home/nlp/project/DB-GPT/.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 301, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/nlp/project/DB-GPT/.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    return await dependant.call(**values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/nlp/project/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/api/endpoints.py\", line 239, in test_connection\n    res = await blocking_func_to_async(\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/nlp/project/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/core/__init__.py\", line 32, in blocking_func_to_async\n    return await _blocking_func_to_async(executor, func, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/nlp/project/DB-GPT/packages/dbgpt-core/src/dbgpt/util/executor_utils.py\", line 70, in blocking_func_to_async\n    return await loop.run_in_executor(executor, run_with_context)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/nlp/.local/share/uv/python/cpython-3.11.12-linux-x86_64-gnu/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/nlp/project/DB-GPT/packages/dbgpt-core/src/dbgpt/util/executor_utils.py\", line 67, in run_with_context\n    return ctx.run(partial(func, *args, **kwargs))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/nlp/project/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/service.py\", line 288, in test_connection\n    return self.datasource_manager.test_connection(request)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/nlp/project/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/manages/connector_manager.py\", line 290, in test_connection\n    raise ValueError(f\"Test connection Failure!{str(e)}\")\nValueError: Test connection Failure!Not an executable object: 'DESCRIBE `crawl`.`app_comment`'\n\n### What you expected to happen\n\n请告诉我如何连接doris数据库\n\n### How to reproduce\n\n启动项目后连接doirs数据库就会报错, 但mysql数据库正常\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "leap233",
      "author_type": "User",
      "created_at": "2025-06-04T06:22:37Z",
      "updated_at": "2025-06-04T06:24:24Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2747/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2747",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2747",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:54.640024",
      "comments": []
    },
    {
      "issue_number": 2746,
      "title": "请同步更新一下最新版本的安装文档 谢谢!",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n请同步更新一下最新版本的安装文档 谢谢!\nPlease synchronize and update the installation documentation to the latest version. Thank you!\n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "leap233",
      "author_type": "User",
      "created_at": "2025-06-03T09:43:01Z",
      "updated_at": "2025-06-03T09:46:12Z",
      "closed_at": "2025-06-03T09:46:12Z",
      "labels": [
        "documentation",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2746/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2746",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2746",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:54.640043",
      "comments": []
    },
    {
      "issue_number": 2324,
      "title": "[Bug] [GraphRAG] DataNotMatchException: (code=1, message=The data doesn't match with schema fields, expect 4 list, got 20)",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU\nGPU Count:1\ngpu memory:24G\n\n### Models information\n\nLLM_MODEL: qwen2.5-7b-instruct\nEMBEDDING_MODEL:m3e-base\n\n### What happened\n\n使用milvus作为向量库，新建知识图谱或者向量类型的知识库时，上传第一个文件后，进行文件同步时报错DataNotMatchException: (code=1, message=The data doesn't match with schema fields, expect 4 list, got 20)；\n**目前测试的情况是只有第一个文件的第一次同步会报错。**\n\n### What you expected to happen\n\n只有新建的知识库在上传第一个文件进行同步时才会提示以上错误，初步定位到文件milvus_store的init_schema_and_load方法中，成员变量self.fields的字段长度应该是4，但是以上报错是因为它的长度变为20，其实是4个字段重复出现了5次，导致总共是20次，看起来像是线程不安全导致的问题\n\n### How to reproduce\n\n1.构建一个知识图谱/向量类型的知识库；\n2.上传一个文件；\n3.选择上传的文件，点击\"同步\"\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "xuxl2024",
      "author_type": "User",
      "created_at": "2025-01-24T09:19:16Z",
      "updated_at": "2025-06-02T21:05:20Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2324/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2324",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2324",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:54.640050",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "which milvus server version you deploy?",
          "created_at": "2025-01-24T16:47:11Z"
        },
        {
          "author": "xuxl2024",
          "body": "> which milvus server version you deploy?\n\n2.5.2-gpu",
          "created_at": "2025-02-02T10:02:58Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-06-02T21:05:19Z"
        }
      ]
    },
    {
      "issue_number": 2742,
      "title": "[Bug] [dbgpts]0.7.1版本已支持视觉理解模型，但当前已支持模型中视觉模型很稀少",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [x] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nA100\n\n### Models information\n\nQwen2.5-72B\n\n### What happened\n\n更新版本后尝试部署视觉模型，测试视觉交互能力  但发现绝大部分视觉模型都不支持  如Qwen2.5-VL系列\n\n### What you expected to happen\n\n增加视觉模型适配\n\n### How to reproduce\n\n1\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "PPdot-cn",
      "author_type": "User",
      "created_at": "2025-05-30T03:54:53Z",
      "updated_at": "2025-05-30T15:43:23Z",
      "closed_at": "2025-05-30T15:43:23Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2742/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2742",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2742",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:54.829853",
      "comments": []
    },
    {
      "issue_number": 2600,
      "title": "连接2300张表的MySql数据库失败",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\ncpu\n\n### Models information\n\n LLM_MODEL=siliconflow_proxyllm\nSILICONFLOW_MODEL_VERSION=THUDM/glm-4-9b-chat\n\n### What happened\n\n2025-04-09 11:44:13 | ERROR | dbgpt.datasource.manages.connector_manager | poweraec Test connect Failure!'TABLENAME'\n\n### What you expected to happen\n\n表名：格式、表数量、以及整个库的数据量有限制吗\n\n### How to reproduce\n\nMySql数据库 —— create\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "dwh1",
      "author_type": "User",
      "created_at": "2025-04-09T03:47:47Z",
      "updated_at": "2025-05-30T07:46:48Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2600/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2600",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2600",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:54.829879",
      "comments": [
        {
          "author": "dusx1981",
          "body": "你连接信息有问题",
          "created_at": "2025-05-07T03:09:57Z"
        },
        {
          "author": "dwh1",
          "body": "肯定不是数据库连接信息的问题，减少一些表能正常连接，因为表太多，而且表名不是很规范，也会存在中文表名，具体不清楚是表名不规范，还是表数量太多，还是其他原因导致",
          "created_at": "2025-05-07T06:26:56Z"
        },
        {
          "author": "dusx1981",
          "body": "问题解决的怎么样，有进展吗\n",
          "created_at": "2025-05-30T01:57:23Z"
        },
        {
          "author": "dwh1",
          "body": "并没有\r\n\r\n\r\n\r\n\r\n男人要敢担当\r\n***@***.***",
          "created_at": "2025-05-30T07:46:46Z"
        }
      ]
    },
    {
      "issue_number": 2404,
      "title": "[Bug] [Module Name] Startup failed when uv run dbgpt start webserver --config configs/dbgpt-proxy-deepseek.toml",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\ndeepseek-reasoner\nBAAI/bge-large-zh-v1.5\n\n### What happened\n\nError starting worker manager: model deepseek-reasoner@proxy/deepseek(192.168.1.223:5670) start failed, Traceback (most recent call last):\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/torch/__init__.py\", line 300, in _load_global_deps\n    ctypes.CDLL(global_deps_lib_path, mode=ctypes.RTLD_GLOBAL)\n  File \"/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/ctypes/__init__.py\", line 376, in __init__\n    self._handle = _dlopen(self._name, mode)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^\nOSError: libcudart.so.12: cannot open shared object file: No such file or directory\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/cluster/worker/manager.py\", line 631, in _start_worker\n    await self.run_blocking_func(\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/cluster/worker/manager.py\", line 146, in run_blocking_func\n    return await loop.run_in_executor(self.executor, func, *args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/cluster/worker/default_worker.py\", line 102, in start\n    _try_import_torch()\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/cluster/worker/default_worker.py\", line 626, in _try_import_torch\n    import torch\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/torch/__init__.py\", line 366, in <module>\n    _load_global_deps()\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/torch/__init__.py\", line 324, in _load_global_deps\n    _preload_cuda_deps(lib_folder, lib_name)\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/torch/__init__.py\", line 284, in _preload_cuda_deps\n    raise ValueError(f\"{lib_name} not found in the system path {sys.path}\")\nValueError: libcublas.so.*[0-9] not found in the system path ['.', '.', '.', '.', '/root/DB-GPT/.venv/bin', '/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python311.zip', '/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11', '/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/lib-dynload', '/root/DB-GPT/.venv/lib/python3.11/site-packages', '/root/DB-GPT/packages/dbgpt-core/src', '/root/DB-GPT/packages/dbgpt-app/src', '/root/DB-GPT/packages/dbgpt-client/src', '/root/DB-GPT/packages/dbgpt-ext/src', '/root/DB-GPT/packages/dbgpt-serve/src', '/root/DB-GPT/packages/dbgpt-app', '/root/DB-GPT/packages/dbgpt-app']\n\n;model BAAI/bge-large-zh-v1.5@hf(192.168.1.223:5670) start failed, Traceback (most recent call last):\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/torch/__init__.py\", line 300, in _load_global_deps\n    ctypes.CDLL(global_deps_lib_path, mode=ctypes.RTLD_GLOBAL)\n  File \"/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/ctypes/__init__.py\", line 376, in __init__\n    self._handle = _dlopen(self._name, mode)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^\nOSError: libcudart.so.12: cannot open shared object file: No such file or directory\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/cluster/worker/manager.py\", line 631, in _start_worker\n    await self.run_blocking_func(\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/cluster/worker/manager.py\", line 146, in run_blocking_func\n    return await loop.run_in_executor(self.executor, func, *args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/cluster/worker/embedding_worker.py\", line 84, in start\n    self._embeddings_impl = self._adapter.load_from_params(self._model_params)\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/adapter/base.py\", line 829, in load_from_params\n    return model_adapter_cls.from_parameters(params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/rag/embedding/embeddings.py\", line 487, in from_parameters\n    return cls(\n           ^^^^\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/rag/embedding/embeddings.py\", line 460, in __init__\n    import sentence_transformers\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/sentence_transformers/__init__.py\", line 9, in <module>\n    from sentence_transformers.backend import (\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/sentence_transformers/backend.py\", line 11, in <module>\n    from sentence_transformers.util import disable_datasets_caching, is_datasets_available\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/sentence_transformers/util.py\", line 17, in <module>\n    import torch\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/torch/__init__.py\", line 366, in <module>\n    _load_global_deps()\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/torch/__init__.py\", line 324, in _load_global_deps\n    _preload_cuda_deps(lib_folder, lib_name)\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/torch/__init__.py\", line 284, in _preload_cuda_deps\n    raise ValueError(f\"{lib_name} not found in the system path {sys.path}\")\nValueError: libcublas.so.*[0-9] not found in the system path ['.', '.', '.', '.', '/root/DB-GPT/.venv/bin', '/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python311.zip', '/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11', '/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/lib-dynload', '/root/DB-GPT/.venv/lib/python3.11/site-packages', '/root/DB-GPT/packages/dbgpt-core/src', '/root/DB-GPT/packages/dbgpt-app/src', '/root/DB-GPT/packages/dbgpt-client/src', '/root/DB-GPT/packages/dbgpt-ext/src', '/root/DB-GPT/packages/dbgpt-serve/src', '/root/DB-GPT/packages/dbgpt-app', '/root/DB-GPT/packages/dbgpt-app']\n\n\n### What you expected to happen\n\nI confirm that I have obtained the latest file, and there are no issues with the operation steps.\nI noticed a similar issue #2396, but the method mentioned doesn't seem to work for me.\n\n### How to reproduce\n\n1、git clone https://github.com/eosphoros-ai/DB-GPT.git\n2、uv sync --all-packages --extra \"base\" --extra \"proxy_openai\" --extra \"rag\" --extra \"storage_chromadb\" --extra \"dbgpts\" --extra \"hf\"\n3、vi /configs/dbgpt-proxy-deepseek.toml\n4、uv run dbgpt start webserver --config configs/dbgpt-proxy-deepseek.toml\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "DuskBelievers",
      "author_type": "User",
      "created_at": "2025-03-06T07:32:16Z",
      "updated_at": "2025-05-29T11:19:54Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2404/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2404",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2404",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:55.019571",
      "comments": [
        {
          "author": "microexpression",
          "body": "Using the latest source code deployment (0.7.1), this problem still exists. Can it be solved?",
          "created_at": "2025-05-29T11:19:54Z"
        }
      ]
    },
    {
      "issue_number": 2740,
      "title": "[Bug] [Module Name] Unable to initiate new operator/resource",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [x] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nN/A\n\n### Models information\n\nN/A\n\n### What happened\n\nWhen creating new operators/resources using 'dbgpt new app...' command. An error message pops up saying '[Errno 2] No such file or directory: '/path_to_repo/operators/operator-name/operator_name/__init__.py'\n\nThe error message exists due to the drive created by the command line actually being '/path_to_repo/operators/operator-name/src/operator_name/', thus the path to the '__init__.py' becomes '/path_to_repo/operators/operator-name/src/operator_name/__init__.py'\n\n### What you expected to happen\n\nI expect it to work as the docs said. \n\n### How to reproduce\n\n1. Deploy DB-GPT and dbgpts\n2. Use command 'dbgpt new app ...'\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "li552233",
      "author_type": "User",
      "created_at": "2025-05-29T03:35:01Z",
      "updated_at": "2025-05-29T03:35:01Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2740/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2740",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2740",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:55.224965",
      "comments": []
    },
    {
      "issue_number": 2718,
      "title": "[Bug] [dbgpt-core] Agent binding knowledge retrieval error",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice: CPU\n\n### Models information\n\nLLM: DeepSeek-V3\n\n### What happened\n\nCreate an agent application. For example, if the binding of the Assistant Agent to the knowledge base fails\n\n<img width=\"742\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/93017107-abb9-4990-8fe3-3afd7b19280f\" />\n\n### What you expected to happen\n\nthe reason is that the initialization of the RetrieverResource fails due to the lack of a configured reranker\n\n### How to reproduce\n\nCreate an agent application binding a knowledge and without reranker configeration\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "FOkvj",
      "author_type": "User",
      "created_at": "2025-05-23T01:46:50Z",
      "updated_at": "2025-05-28T09:46:50Z",
      "closed_at": "2025-05-28T09:46:50Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2718/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2718",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2718",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:55.224986",
      "comments": []
    },
    {
      "issue_number": 2734,
      "title": "[Bug] [dbgpts] financial report can not run. error:  Load package failed!No module named 'dbgpt.datasource.db_conn_info'",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [x] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU \n\n### Models information\n\nqwen2.5        \n\n### What happened\n\n1. dbgpt app install financial-robot-app financial-report-knowledge-factory\n\n2. dbgpt app list    (报一下错误：)\n\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-core/src/dbgpt/util/dbgpts/loader.py\", line 324, in _load_package_from_path\n    parsed_packages.append(parse_package_metadata(package))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-core/src/dbgpt/util/dbgpts/loader.py\", line 282, in parse_package_metadata\n    return FlowPackage.build_from(pkg_dict, ext_metadata)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-core/src/dbgpt/util/dbgpts/loader.py\", line 121, in build_from\n    return FlowPythonPackage.build_from(values, ext_dict)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-core/src/dbgpt/util/dbgpts/loader.py\", line 131, in build_from\n    _, _, mods = cls.load_module_class(values, DAG)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-core/src/dbgpt/util/dbgpts/loader.py\", line 109, in load_module_class\n    raise e\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-core/src/dbgpt/util/dbgpts/loader.py\", line 95, in load_module_class\n    with pkg_resources.path(name, \"__init__.py\") as path:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib64/python3.11/importlib/resources/_legacy.py\", line 25, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib64/python3.11/importlib/resources/_legacy.py\", line 121, in path\n    return _common.as_file(_common.files(package) / normalize_path(resource))\n                           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib64/python3.11/importlib/resources/_common.py\", line 22, in files\n    return from_package(get_package(package))\n                        ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib64/python3.11/importlib/resources/_common.py\", line 53, in get_package\n    resolved = resolve(package)\n               ^^^^^^^^^^^^^^^^\n  File \"/usr/lib64/python3.11/importlib/resources/_common.py\", line 44, in resolve\n    return cand if isinstance(cand, types.ModuleType) else importlib.import_module(cand)\n                                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib64/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/financial_report_knowledge_factory/__init__.py\", line 24, in <module>\n    from dbgpt.datasource.db_conn_info import DBConfig\nModuleNotFoundError: No module named 'dbgpt.datasource.db_conn_info'\n\n### What you expected to happen\n\n正常加载dbgpts\n\n### How to reproduce\n\n1. dbgpt app install financial-robot-app financial-report-knowledge-factory\n\n2. dbgpt app list    (报一下错误：)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-core/src/dbgpt/util/dbgpts/loader.py\", line 324, in _load_package_from_path\n    parsed_packages.append(parse_package_metadata(package))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-core/src/dbgpt/util/dbgpts/loader.py\", line 282, in parse_package_metadata\n    return FlowPackage.build_from(pkg_dict, ext_metadata)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-core/src/dbgpt/util/dbgpts/loader.py\", line 121, in build_from\n    return FlowPythonPackage.build_from(values, ext_dict)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-core/src/dbgpt/util/dbgpts/loader.py\", line 131, in build_from\n    _, _, mods = cls.load_module_class(values, DAG)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-core/src/dbgpt/util/dbgpts/loader.py\", line 109, in load_module_class\n    raise e\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-core/src/dbgpt/util/dbgpts/loader.py\", line 95, in load_module_class\n    with pkg_resources.path(name, \"__init__.py\") as path:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib64/python3.11/importlib/resources/_legacy.py\", line 25, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib64/python3.11/importlib/resources/_legacy.py\", line 121, in path\n    return _common.as_file(_common.files(package) / normalize_path(resource))\n                           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib64/python3.11/importlib/resources/_common.py\", line 22, in files\n    return from_package(get_package(package))\n                        ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib64/python3.11/importlib/resources/_common.py\", line 53, in get_package\n    resolved = resolve(package)\n               ^^^^^^^^^^^^^^^^\n  File \"/usr/lib64/python3.11/importlib/resources/_common.py\", line 44, in resolve\n    return cand if isinstance(cand, types.ModuleType) else importlib.import_module(cand)\n                                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib64/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/financial_report_knowledge_factory/__init__.py\", line 24, in <module>\n    from dbgpt.datasource.db_conn_info import DBConfig\nModuleNotFoundError: No module named 'dbgpt.datasource.db_conn_info'\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "maco6096",
      "author_type": "User",
      "created_at": "2025-05-27T02:06:28Z",
      "updated_at": "2025-05-28T09:39:59Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2734/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2734",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2734",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:55.224993",
      "comments": [
        {
          "author": "chenliang15405",
          "body": "financial-report app don't t support use in 0.7.0 version, if you want use it, please switch to 0.6.2 version or lower",
          "created_at": "2025-05-28T09:39:58Z"
        }
      ]
    },
    {
      "issue_number": 2730,
      "title": "[Feat][Web] Enhance table-chart formatting and generalization for dashboard scenario",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nEnhance the table-chart component for better formatting and generalization in dashboard scenarios.\n\n\n### Use case\n\n- Merge type-value structure into a single row for clearer data presentation.\n- Unify number formatting (keep two decimals for scores/percentages) to improve readability.\n- Remove hardcoded mappings, making the code more robust and maintainable.\n- Improve cell and column formatting for a better user experience.\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nHigh\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "WangzJi",
      "author_type": "User",
      "created_at": "2025-05-26T10:10:29Z",
      "updated_at": "2025-05-28T09:36:22Z",
      "closed_at": "2025-05-28T09:36:22Z",
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2730/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2730",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2730",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:55.419197",
      "comments": []
    },
    {
      "issue_number": 2737,
      "title": "[Doc][Module Name] document sync batch error Graph storage is not configured.please check your config.reference configs/dbgpt-graphrag.toml",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n这个怎么配置？\n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "wade-liwei",
      "author_type": "User",
      "created_at": "2025-05-27T08:00:36Z",
      "updated_at": "2025-05-27T08:00:36Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2737/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2737",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2737",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:55.419221",
      "comments": []
    },
    {
      "issue_number": 2735,
      "title": "[Bug] [Embedding] When the system is started for the first time or after a period of time, the service freezes when the system is used in the embedding scenario of siliconflow",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [x] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nLLM: Siliconflow /Qwen/Qwen3-32B\nEmbedding: Siliconflow BAAI/bge-m3\n\n### What happened\n\n 2025-05-27 10:04:56 a6a434a09dd0 dbgpt_serve.agent.agents.controller[1] INFO agent_chat_v2 conv_id:17e79e2a-3a9d-11f0-95fa-22e75349de3f,gpts_name:721934d6-0888-11f0-bc28-5fe89bb390c8,user_query:2024年各部门收入\ndbgpt-server  | 2025-05-27 10:04:56 a6a434a09dd0 dbgpt_serve.agent.agents.controller[1] INFO gpts_conversations count:17e79e2a-3a9d-11f0-95fa-22e75349de3f, 1\ndbgpt-server  | 2025-05-27 10:04:56 a6a434a09dd0 dbgpt_serve.agent.agents.controller[1] INFO last conversation status:{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x7f780054ea50>, 'team_mode': 'single_agent', 'conv_id': '17e79e2a-3a9d-11f0-95fa-22e75349de3f_1', 'user_goal': '2024年各部门收入', 'max_auto_reply_round': 0, 'user_code': '8', 'created_at': datetime.datetime(2025, 5, 27, 1, 51, 25), 'gpts_name': '721934d6-0888-11f0-bc28-5fe89bb390c8', 'id': 1440, 'state': 'failed', 'auto_reply_count': 0, 'sys_code': None, 'updated_at': datetime.datetime(2025, 5, 27, 1, 51, 26)}\ndbgpt-server  | INFO:     192.168.110.59:1782 - \"POST /api/v1/chat/completions HTTP/1.1\" 200 OK\ndbgpt-server  | 2025-05-27 10:04:56 a6a434a09dd0 dbgpt.model.cluster.worker.embedding_worker[1] INFO Receive embeddings request, model: BAAI/bge-m3\ndbgpt-server  | 2025-05-27 10:05:07 a6a434a09dd0 dbgpt.util.api_utils[1] WARNING Health check failed for http://127.0.0.1:5670, error: HTTPConnectionPool(host='127.0.0.1', port=5670): Read timed out. (read timeout=10)\ndbgpt-server  | 2025-05-27 10:05:22 a6a434a09dd0 dbgpt.util.api_utils[1] WARNING Health check failed for http://127.0.0.1:5670, error: HTTPConnectionPool(host='127.0.0.1', port=5670): Read timed out. (read timeout=10)\ndbgpt-server  | 2025-05-27 10:05:37 a6a434a09dd0 dbgpt.util.api_utils[1] WARNING Health check failed for http://127.0.0.1:5670, error: HTTPConnectionPool(host='127.0.0.1', port=5670): Read timed out. (read timeout=10)\ndbgpt-server  | 2025-05-27 10:05:52 a6a434a09dd0 dbgpt.util.api_utils[1] WARNING Health check failed for http://127.0.0.1:5670, error: HTTPConnectionPool(host='127.0.0.1', port=5670): Read timed out. (read timeout=10)\ndbgpt-server  | 2025-05-27 10:05:56 a6a434a09dd0 dbgpt_serve.agent.agents.controller[1] ERROR Chat to App 721934d6-0888-11f0-bc28-5fe89bb390c8 Failed!HTTPSConnectionPool(host='api.siliconflow.cn', port=443): Read timed out. (read timeout=60)\ndbgpt-server  | Traceback (most recent call last):\ndbgpt-server  |   File \"//opt/.uv.venv/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 534, in _make_request\ndbgpt-server  |     response = conn.getresponse()\ndbgpt-server  |                ^^^^^^^^^^^^^^^^^^\ndbgpt-server  |   File \"//opt/.uv.venv/lib/python3.11/site-packages/urllib3/connection.py\", line 516, in getresponse\ndbgpt-server  |     httplib_response = super().getresponse()\ndbgpt-server  |                        ^^^^^^^^^^^^^^^^^^^^^\ndbgpt-server  |   File \"/usr/lib/python3.11/http/client.py\", line 1395, in getresponse\ndbgpt-server  |     response.begin()\ndbgpt-server  |   File \"/usr/lib/python3.11/http/client.py\", line 325, in begin\ndbgpt-server  |     version, status, reason = self._read_status()\ndbgpt-server  |                               ^^^^^^^^^^^^^^^^^^^\ndbgpt-server  |   File \"/usr/lib/python3.11/http/client.py\", line 286, in _read_status\ndbgpt-server  |     line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\ndbgpt-server  |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ndbgpt-server  |   File \"/usr/lib/python3.11/socket.py\", line 718, in readinto\ndbgpt-server  |     return self._sock.recv_into(b)\ndbgpt-server  |            ^^^^^^^^^^^^^^^^^^^^^^^\ndbgpt-server  |   File \"/usr/lib/python3.11/ssl.py\", line 1314, in recv_into\ndbgpt-server  |     return self.read(nbytes, buffer)\ndbgpt-server  |            ^^^^^^^^^^^^^^^^^^^^^^^^^\ndbgpt-server  |   File \"/usr/lib/python3.11/ssl.py\", line 1166, in read\ndbgpt-server  |     return self._sslobj.read(len, buffer)\ndbgpt-server  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ndbgpt-server  | TimeoutError: The read operation timed out\ndbgpt-server  |\ndbgpt-server  | The above exception was the direct cause of the following exception:\ndbgpt-server  |\ndbgpt-server  | Traceback (most recent call last):\ndbgpt-server  |   File \"//opt/.uv.venv/lib/python3.11/site-packages/requests/adapters.py\", line 667, in send\ndbgpt-server  |     resp = conn.urlopen(\ndbgpt-server  |            ^^^^^^^^^^^^^\ndbgpt-server  |   File \"//opt/.uv.venv/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 841, in urlopen\ndbgpt-server  |     retries = retries.increment(\ndbgpt-server  |               ^^^^^^^^^^^^^^^^^^\ndbgpt-server  |   File \"//opt/.uv.venv/lib/python3.11/site-packages/urllib3/util/retry.py\", line 474, in increment\ndbgpt-server  |     raise reraise(type(error), error, _stacktrace)\ndbgpt-server  |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ndbgpt-server  |   File \"//opt/.uv.venv/lib/python3.11/site-packages/urllib3/util/util.py\", line 39, in reraise\ndbgpt-server  |     raise value\ndbgpt-server  |   File \"//opt/.uv.venv/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\ndbgpt-server  |     response = self._make_request(\ndbgpt-server  |                ^^^^^^^^^^^^^^^^^^^\ndbgpt-server  |   File \"//opt/.uv.venv/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 536, in _make_request\ndbgpt-server  |     self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\ndbgpt-server  |   File \"//opt/.uv.venv/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 367, in _raise_timeout\ndbgpt-server  |     raise ReadTimeoutError(\ndbgpt-server  | urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='api.siliconflow.cn', port=443): Read timed out. (read timeout=60)\ndbgpt-server  |\ndbgpt-server  | During handling of the above exception, another exception occurred:\ndbgpt-server  |\ndbgpt-server  | Traceback (most recent call last):\ndbgpt-server  |   File \"/app/packages/dbgpt-serve/src/dbgpt_serve/agent/agents/controller.py\", line 441, in app_agent_chat\ndbgpt-server  |     async for task, chunk, agent_conv_id in multi_agents.agent_chat_v2(\ndbgpt-server  |   File \"/app/packages/dbgpt-serve/src/dbgpt_serve/agent/agents/controller.py\", line 319, in agent_chat_v2\ndbgpt-server  |     agent_memory = self.get_or_build_agent_memory(conv_id, gpts_name)\ndbgpt-server  |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ndbgpt-server  |   File \"/app/packages/dbgpt-serve/src/dbgpt_serve/agent/agents/controller.py\", line 146, in get_or_build_agent_memory\ndbgpt-server  |     vector_store = storage_manager.create_vector_store(index_name=index_name)\ndbgpt-server  |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ndbgpt-server  |   File \"/app/packages/dbgpt-serve/src/dbgpt_serve/rag/storage_manager.py\", line 70, in create_vector_store\ndbgpt-server  |     return vector_store_config.create_store(\ndbgpt-server  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ndbgpt-server  |   File \"/app/packages/dbgpt-ext/src/dbgpt_ext/storage/vector_store/milvus_store.py\", line 173, in create_store\ndbgpt-server  |     return MilvusStore(vector_store_config=self, **kwargs)\ndbgpt-server  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ndbgpt-server  |   File \"/app/packages/dbgpt-ext/src/dbgpt_ext/storage/vector_store/milvus_store.py\", line 291, in __init__\ndbgpt-server  |     self.col = self.create_collection(collection_name=self.collection_name)\ndbgpt-server  |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ndbgpt-server  |   File \"/app/packages/dbgpt-ext/src/dbgpt_ext/storage/vector_store/milvus_store.py\", line 324, in create_collection\ndbgpt-server  |     embeddings = self.embedding.embed_query(collection_name)\ndbgpt-server  |                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ndbgpt-server  |   File \"/app/packages/dbgpt-core/src/dbgpt/model/cluster/embedding/remote_embedding.py\", line 20, in embed_query\ndbgpt-server  |     return self.embed_documents([text])[0]\ndbgpt-server  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ndbgpt-server  |   File \"/app/packages/dbgpt-core/src/dbgpt/model/cluster/embedding/remote_embedding.py\", line 16, in embed_documents\ndbgpt-server  |     return self.worker_manager.sync_embeddings(params)\ndbgpt-server  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ndbgpt-server  |   File \"/app/packages/dbgpt-core/src/dbgpt/model/cluster/worker/manager.py\", line 838, in sync_embeddings\ndbgpt-server  |     return self.worker_manager.sync_embeddings(params)\ndbgpt-server  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ndbgpt-server  |   File \"/app/packages/dbgpt-core/src/dbgpt/model/cluster/worker/manager.py\", line 519, in sync_embeddings\ndbgpt-server  |     return worker_run_data.worker.embeddings(params)\ndbgpt-server  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ndbgpt-server  |   File \"/app/packages/dbgpt-core/src/dbgpt/model/cluster/worker/embedding_worker.py\", line 121, in embeddings\ndbgpt-server  |     return self._embeddings_impl.embed_documents(textx)\ndbgpt-server  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ndbgpt-server  |   File \"/app/packages/dbgpt-core/src/dbgpt/rag/embedding/embeddings.py\", line 863, in embed_documents\ndbgpt-server  |     res = self.session.post(  # type: ignore\ndbgpt-server  |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ndbgpt-server  |   File \"//opt/.uv.venv/lib/python3.11/site-packages/requests/sessions.py\", line 637, in post\ndbgpt-server  |     return self.request(\"POST\", url, data=data, json=json, **kwargs)\ndbgpt-server  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ndbgpt-server  |   File \"//opt/.uv.venv/lib/python3.11/site-packages/requests/sessions.py\", line 589, in request\ndbgpt-server  |     resp = self.send(prep, **send_kwargs)\ndbgpt-server  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ndbgpt-server  |   File \"//opt/.uv.venv/lib/python3.11/site-packages/requests/sessions.py\", line 703, in send\ndbgpt-server  |     r = adapter.send(request, **kwargs)\ndbgpt-server  |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ndbgpt-server  |   File \"//opt/.uv.venv/lib/python3.11/site-packages/requests/adapters.py\", line 713, in send\ndbgpt-server  |     raise ReadTimeout(e, request=request)\ndbgpt-server  | requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='api.siliconflow.cn', port=443): Read timed out. (read timeout=60)\ndbgpt-server  | 2025-05-27 10:05:56 a6a434a09dd0 dbgpt_serve.agent.agents.controller[1] INFO save agent chat info！17e79e2a-3a9d-11f0-95fa-22e75349de3f\ndbgpt-server  | 2025-05-27 10:05:56 a6a434a09dd0 dbgpt_serve.core.schemas[1] ERROR common_exception_handler catch Exception: success=False err_code='E0003' err_msg=\"'NoneType' object has no attribute 'replace'\" data=None\ndbgpt-server  | ERROR:    Exception in ASGI application\ndbgpt-server  |   + Exception Group Traceback (most recent call last):\ndbgpt-server  |   |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/_utils.py\", line 77, in collapse_excgroups\ndbgpt-server  |   |     yield\ndbgpt-server  |   |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 186, in __call__\ndbgpt-server  |   |     async with anyio.create_task_group() as task_group:\ndbgpt-server  |   |   File \"//opt/.uv.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 772, in __aexit__\ndbgpt-server  |   |     raise BaseExceptionGroup(\ndbgpt-server  |   | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\ndbgpt-server  |   +-+---------------- 1 ----------------\ndbgpt-server  |     | Exception Group Traceback (most recent call last):\ndbgpt-server  |     |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 188, in __call__\ndbgpt-server  |     |     await response(scope, wrapped_receive, send)\ndbgpt-server  |     |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 222, in __call__\ndbgpt-server  |     |     async for chunk in self.body_iterator:\ndbgpt-server  |     |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 179, in body_stream\ndbgpt-server  |     |     raise app_exc\ndbgpt-server  |     |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 149, in coro\ndbgpt-server  |     |     await self.app(scope, receive_or_disconnect, send_no_error)\ndbgpt-server  |     |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\ndbgpt-server  |     |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\ndbgpt-server  |     |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\ndbgpt-server  |     |     raise exc\ndbgpt-server  |     |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\ndbgpt-server  |     |     await app(scope, receive, sender)\ndbgpt-server  |     |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/routing.py\", line 715, in __call__\ndbgpt-server  |     |     await self.middleware_stack(scope, receive, send)\ndbgpt-server  |     |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/routing.py\", line 735, in app\ndbgpt-server  |     |     await route.handle(scope, receive, send)\ndbgpt-server  |     |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/routing.py\", line 288, in handle\ndbgpt-server  |     |     await self.app(scope, receive, send)\ndbgpt-server  |     |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/routing.py\", line 76, in app\ndbgpt-server  |     |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\ndbgpt-server  |     |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\ndbgpt-server  |     |     raise exc\ndbgpt-server  |     |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\ndbgpt-server  |     |     await app(scope, receive, sender)\ndbgpt-server  |     |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/routing.py\", line 74, in app\ndbgpt-server  |     |     await response(scope, receive, send)\ndbgpt-server  |     |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/responses.py\", line 250, in __call__\ndbgpt-server  |     |     async with anyio.create_task_group() as task_group:\ndbgpt-server  |     |   File \"//opt/.uv.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 772, in __aexit__\ndbgpt-server  |     |     raise BaseExceptionGroup(\ndbgpt-server  |     | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\ndbgpt-server  |     +-+---------------- 1 ----------------\ndbgpt-server  |       | Traceback (most recent call last):\ndbgpt-server  |       |   File \"//opt/.uv.venv/lib/python3.11/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 409, in run_asgi\ndbgpt-server  |       |     result = await app(  # type: ignore[func-returns-value]\ndbgpt-server  |       |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ndbgpt-server  |       |   File \"//opt/.uv.venv/lib/python3.11/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\ndbgpt-server  |       |     return await self.app(scope, receive, send)\ndbgpt-server  |       |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ndbgpt-server  |       |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 93, in __call__\ndbgpt-server  |       |     await self.simple_response(scope, receive, send, request_headers=headers)\ndbgpt-server  |       |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\ndbgpt-server  |       |     await self.app(scope, receive, send)\ndbgpt-server  |       |   File \"//opt/.uv.venv/lib/python3.11/site-packages/fastapi/applications.py\", line 1054, in __call__\ndbgpt-server  |       |     await super().__call__(scope, receive, send)\ndbgpt-server  |       |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/applications.py\", line 113, in __call__\ndbgpt-server  |       |     await self.middleware_stack(scope, receive, send)\ndbgpt-server  |       |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 187, in __call__\ndbgpt-server  |       |     raise exc\ndbgpt-server  |       |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 165, in __call__\ndbgpt-server  |       |     await self.app(scope, receive, _send)\ndbgpt-server  |       |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 185, in __call__\ndbgpt-server  |       |     with collapse_excgroups():\ndbgpt-server  |       |   File \"/usr/lib/python3.11/contextlib.py\", line 158, in __exit__\ndbgpt-server  |       |     self.gen.throw(typ, value, traceback)\ndbgpt-server  |       |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/_utils.py\", line 83, in collapse_excgroups\ndbgpt-server  |       |     raise exc\ndbgpt-server  |       |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/responses.py\", line 253, in wrap\ndbgpt-server  |       |     await func()\ndbgpt-server  |       |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/responses.py\", line 242, in stream_response\ndbgpt-server  |       |     async for chunk in self.body_iterator:\ndbgpt-server  |       |   File \"/app/packages/dbgpt-serve/src/dbgpt_serve/agent/agents/controller.py\", line 472, in app_agent_chat\ndbgpt-server  |       |     default_final_message = default_final_message.replace(\"data:\", \"\")\ndbgpt-server  |       |                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ndbgpt-server  |       | AttributeError: 'NoneType' object has no attribute 'replace'\ndbgpt-server  |       +------------------------------------\ndbgpt-server  |\ndbgpt-server  | During handling of the above exception, another exception occurred:\ndbgpt-server  |\ndbgpt-server  | Traceback (most recent call last):\ndbgpt-server  |   File \"//opt/.uv.venv/lib/python3.11/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 409, in run_asgi\ndbgpt-server  |     result = await app(  # type: ignore[func-returns-value]\ndbgpt-server  |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ndbgpt-server  |   File \"//opt/.uv.venv/lib/python3.11/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\ndbgpt-server  |     return await self.app(scope, receive, send)\ndbgpt-server  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ndbgpt-server  |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 93, in __call__\ndbgpt-server  |     await self.simple_response(scope, receive, send, request_headers=headers)\ndbgpt-server  |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\ndbgpt-server  |     await self.app(scope, receive, send)\ndbgpt-server  |   File \"//opt/.uv.venv/lib/python3.11/site-packages/fastapi/applications.py\", line 1054, in __call__\ndbgpt-server  |     await super().__call__(scope, receive, send)\ndbgpt-server  |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/applications.py\", line 113, in __call__\ndbgpt-server  |     await self.middleware_stack(scope, receive, send)\ndbgpt-server  |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 187, in __call__\ndbgpt-server  |     raise exc\ndbgpt-server  |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 165, in __call__\ndbgpt-server  |     await self.app(scope, receive, _send)\ndbgpt-server  |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 185, in __call__\ndbgpt-server  |     with collapse_excgroups():\ndbgpt-server  |   File \"/usr/lib/python3.11/contextlib.py\", line 158, in __exit__\ndbgpt-server  |     self.gen.throw(typ, value, traceback)\ndbgpt-server  |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/_utils.py\", line 83, in collapse_excgroups\ndbgpt-server  |     raise exc\ndbgpt-server  |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/responses.py\", line 253, in wrap\ndbgpt-server  |     await func()\ndbgpt-server  |   File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/responses.py\", line 242, in stream_response\ndbgpt-server  |     async for chunk in self.body_iterator:\ndbgpt-server  |   File \"/app/packages/dbgpt-serve/src/dbgpt_serve/agent/agents/controller.py\", line 472, in app_agent_chat\ndbgpt-server  |     default_final_message = default_final_message.replace(\"data:\", \"\")\ndbgpt-server  |                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ndbgpt-server  | AttributeError: 'NoneType' object has no attribute 'replace'\ndbgpt-server  | INFO:     192.168.110.59:1786 - \"GET /chat/?scene=chat_agent&id=17e79e2a-3a9d-11f0-95fa-22e75349de3f&model=Qwen/Qwen3-32B HTTP/1.1\" 304 Not Modified\n\n\n### What you expected to happen\n\nThe siliconflow  API can be called normally at any time\n\n### How to reproduce\n\n\n# Model Configurations\n[models]\n[[models.llms]]\nname = \"Qwen/Qwen3-32B\"\nprovider = \"proxy/siliconflow\"\napi_key = \"${env:SILICONFLOW_API_KEY}\"\n\n\n[[models.embeddings]]\nname = \"BAAI/bge-m3\"\nprovider = \"proxy/openai\"\napi_url = \"https://api.siliconflow.cn/v1/embeddings\"\napi_key = \"${env:SILICONFLOW_API_KEY}\"\n\n[[models.rerankers]]\ntype = \"reranker\"\nname = \"BAAI/bge-reranker-v2-m3\"\nverbose= \"True\"\nprovider = \"proxy/siliconflow\"\napi_url = \"https://api.siliconflow.cn/v1/rerank\"\napi_key = \"${env:SILICONFLOW_API_KEY}\"\n\n\n\n\n### Additional context\n\nThe same issue occurs with calling the siliconflow Reranker API\n\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "vnicers",
      "author_type": "User",
      "created_at": "2025-05-27T02:14:22Z",
      "updated_at": "2025-05-27T05:39:37Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2735/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2735",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2735",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:55.419228",
      "comments": [
        {
          "author": "vnicers",
          "body": "I use the local model, after embedding, it will also cause the server to freeze and cannot respond.",
          "created_at": "2025-05-27T05:39:36Z"
        }
      ]
    },
    {
      "issue_number": 2733,
      "title": "[Feature][Module: ChatData] 推理简洁，快速出结果。",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n使用过程中推理过程合理且详细，但是会导致数据出的特别慢。即使是一张宽表出结果也要大概3-5分钟。如果多个Agent结合持续的时间可能多达7-10分钟。\n用的是模型是：Qwen/Qwen3-235B-A22B\n\n### Use case\n\n简化推理过程，或者提供多个选项没有推理过程，直接出结果。有推理过程，慢。\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nMedium\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "yunfeng1993",
      "author_type": "User",
      "created_at": "2025-05-26T11:18:55Z",
      "updated_at": "2025-05-26T11:18:55Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2733/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2733",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2733",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:55.627456",
      "comments": []
    },
    {
      "issue_number": 2728,
      "title": "[Bug] [Prompt] Prompt template not found for chat_dashboard scene",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nMacOS(M1, M2...)\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [x] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice: CPU\n\n### Models information\n\nLLM\n\n### What happened\n\nWhen attempting to add a new prompt in the prompt management interface, the system throws an error stating \"当前场景没有找到可用的Prompt模版，chat_dashboard\" (No available prompt template found for current scene, chat_dashboard).\n\nThe error occurs when:\n1. User selects \"Scene\" as prompt type\n2. User selects \"chat_dashboard\" as target scene\n3. System tries to load the template via `/prompt/template/load` API\n4. The system fails to find a Chinese language prompt template for the chat_dashboard scene\n\n### What you expected to happen\n\nThe system should successfully load the prompt template for the chat_dashboard scene when the language is set to Chinese (zh), or provide a fallback mechanism to load the English template if Chinese is not available.\n\n**Error Details:**\n- API endpoint: `POST /prompt/template/load?prompt_type=Scene&target=chat_dashboard`\n- Error message: `ValueError: 当前场景没有找到可用的Prompt模版，chat_dashboard`\n- Language context: `language: zh` (Chinese)\n- Scene name: `chat_dashboard`\n\n**Log snippet:**\n```\n2025-05-26 15:42:30 MacBook-Pro.local dbgpt.core._private.prompt_registry[37970] INFO Get prompt template of scene_name: chat_dashboard with model_name: None, proxyllm_backend: None, language: zh\n2025-05-26 15:42:30 MacBook-Pro.local dbgpt_serve.core.schemas[37970] ERROR common_exception_handler catch Exception: success=False err_code='E0003' err_msg='当前场景没有找到可用的Prompt模版，chat_dashboard' data=None\n```\n\n### How to reproduce\n\n1. Start DB-GPT server with Chinese language environment\n2. Navigate to the prompt management interface (construct/prompt)\n3. Click \"Add\" to create a new prompt\n4. Select \"Scene\" from the Type dropdown\n5. Select \"chat_dashboard\" from the target scene dropdown\n6. Observe the error message: \"当前场景没有找到可用的Prompt模版，chat_dashboard\"\n\n### Additional context\n\nhis appears to be a language localization issue where:\n- The prompt template registry contains templates for the chat_dashboard scene\n- However, these templates may not be properly registered with Chinese language support\n- The system expects language-specific templates but falls back incorrectly when Chinese templates are missing\n- This affects the user experience in non-English environments\n\nThe issue seems to be in the prompt template loading mechanism where language-specific templates are not properly handled or registered during system initialization.\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "WangzJi",
      "author_type": "User",
      "created_at": "2025-05-26T08:05:21Z",
      "updated_at": "2025-05-26T10:52:53Z",
      "closed_at": "2025-05-26T10:52:53Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2728/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2728",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2728",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:55.627475",
      "comments": []
    },
    {
      "issue_number": 2321,
      "title": "[Feature] [GraphRAG] milvus_store did not provide truncate()",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU\nGPU Count:1\ngpu memory:24G\n\n### Models information\n\nLLM_MODEL: qwen2.5-7b-instruct\nEMBEDDING_MODEL:m3e-base\n\n### What happened\n\n构建社区摘要时（community_store.py中的build_communities方法），先清空向量存储，仅提供了ChromaStore对于实现truncate方法，未提供MilvusStore对于该方法的实现，当使用milvus作为向量数据库时会抛出错误“NotImplementedError”\n\n### What you expected to happen\n\n提供一种实现\n```python\ndef truncate(self):\n        \"\"\"Drop milvus collection.\n        \"\"\"\n        logger.info(f\"begin truncate milvus collection:{self.collection_name}\")\n        from pymilvus import utility\n        if utility.has_collection(self.collection_name):\n            utility.drop_collection(self.collection_name)\n\n        logger.info(\n            f\"truncate milvus collection {self.collection_name} success\"\n        )\n```\n\n### How to reproduce\n\n1.构建一个知识图谱类型的知识库；\n2.上传一个文件；\n3.选择上传的文件，点击\"同步\"\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "xuxl2024",
      "author_type": "User",
      "created_at": "2025-01-23T06:32:13Z",
      "updated_at": "2025-05-24T21:04:45Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2321/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2321",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2321",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:55.627481",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "sorry about that, we will fix in version v0.7.0, but you can also submit pr to solve that.",
          "created_at": "2025-01-23T08:09:57Z"
        },
        {
          "author": "xuxl2024",
          "body": "> sorry about that, we will fix in version v0.7.0, but you can also submit pr to solve that.\n\nfatal: unable to access 'https://github.com/eosphoros-ai/DB-GPT.git/': The requested URL returned error: 403",
          "created_at": "2025-01-23T10:00:26Z"
        },
        {
          "author": "Aries-ckt",
          "body": "network problem? try again ? or use vpn?",
          "created_at": "2025-01-24T06:18:00Z"
        },
        {
          "author": "xuxl2024",
          "body": "> network problem? try again ? or use vpn?\n\nI guess it's because my account doesn't have the permission to push code？",
          "created_at": "2025-01-24T10:11:31Z"
        },
        {
          "author": "edwardzjl",
          "body": "> permission\n\nYou need to first fork this repo, commit your changes to your forked-repo, and then make PRs to this repo.\n",
          "created_at": "2025-01-24T10:21:24Z"
        }
      ]
    },
    {
      "issue_number": 2319,
      "title": "customize operator in awel error.",
      "body": "我自定义了一个str2stream_operator.py算子主要用于将Datasource Executor Operator算子输出的内容中data数据提取出来并转成流式输出：\n1.算子放在目录dbgpt\\core\\interface\\operators下，参考案例继承StreamifyAbsOperator实现该功能。\n2.修改了dbgpt\\core\\operators的__init__.py文件添加算子的信息\nfrom dbgpt.core.interface.operators.str2stream_operator import (  # noqa: F401\n    str2streamOperator,\n)\n3.建立测试工作流测试算子是否能够正常运行，经过测试算子在以下工作流中可正常运行。\n![Image](https://github.com/user-attachments/assets/8e2213c1-3495-4deb-b9d0-7d3aa292fc36)\n![Image](https://github.com/user-attachments/assets/7de7a29c-00cf-4bbc-b2af-e507a10ee31a)\n\n4.将算子添加到带LLM Operator的工作流中出现错误。\n![Image](https://github.com/user-attachments/assets/5a049c49-4b22-42eb-befd-25dffe62eaff)\n![Image](https://github.com/user-attachments/assets/78042756-7407-41e8-830d-a76c9309d563)\n2025-01-23 08:59:15 DESKTOP-TMVQ7II dbgpt.core.awel.runner.local_runner[9124] INFO Run operator <class 'dbgpt.core.interface.operators.str2stream_operator.str2streamOperator'>(86039032-ed2b-4e1d-85e5-33fc903bb263) error, error message: Traceback (most recent call last):\n  File \"j:\\db-gpt-main\\dbgpt\\core\\awel\\runner\\local_runner.py\", line 192, in _execute_node\n    await node._run(dag_ctx, task_ctx.log_id)\n  File \"j:\\db-gpt-main\\dbgpt\\core\\awel\\operators\\base.py\", line 248, in _run\n    return await self._do_run(dag_ctx)\n  File \"j:\\db-gpt-main\\dbgpt\\core\\awel\\operators\\stream_operator.py\", line 27, in _do_run\n    output = await curr_task_ctx.task_input.parent_outputs[0].task_output.streamify(\n  File \"j:\\db-gpt-main\\dbgpt\\core\\awel\\task\\base.py\", line 185, in streamify\n    raise NotImplementedError\nNotImplementedError\nINFO:     127.0.0.1:53741 - \"GET /api/v1/chat/dialogue/list HTTP/1.1\" 200 OK\n2025-01-23 08:59:33 DESKTOP-TMVQ7II asyncio[9124] ERROR Task exception was never retrieved\nfuture: <Task finished name='Task-741' coro=<<async_generator_athrow without __name__>()> exception=RuntimeError('DAG context not found with event loop task id 2159373769280, task_name: Task-741')>\nTraceback (most recent call last):\n  File \"j:\\db-gpt-main\\dbgpt\\core\\awel\\util\\chat_util.py\", line 87, in safe_chat_stream_with_dag_task\n    async for output in chat_stream_with_dag_task(\n  File \"j:\\db-gpt-main\\dbgpt\\core\\awel\\util\\chat_util.py\", line 162, in chat_stream_with_dag_task\n    async for output in await task.call_stream(request):\n  File \"j:\\db-gpt-main\\dbgpt\\core\\awel\\operators\\base.py\", line 337, in call_stream\n    out_ctx = await self._runner.execute_workflow(\n  File \"j:\\db-gpt-main\\dbgpt\\core\\awel\\runner\\local_runner.py\", line 114, in execute_workflow\n    await self._execute_node(\n  File \"j:\\db-gpt-main\\dbgpt\\core\\awel\\runner\\local_runner.py\", line 213, in _execute_node\n    raise e\n  File \"j:\\db-gpt-main\\dbgpt\\core\\awel\\runner\\local_runner.py\", line 192, in _execute_node\n    await node._run(dag_ctx, task_ctx.log_id)\n  File \"j:\\db-gpt-main\\dbgpt\\core\\awel\\operators\\base.py\", line 248, in _run\n    return await self._do_run(dag_ctx)\n  File \"j:\\db-gpt-main\\dbgpt\\core\\awel\\operators\\stream_operator.py\", line 27, in _do_run\n    output = await curr_task_ctx.task_input.parent_outputs[0].task_output.streamify(\n  File \"j:\\db-gpt-main\\dbgpt\\core\\awel\\task\\base.py\", line 185, in streamify\n    raise NotImplementedError\nNotImplementedError\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"j:\\db-gpt-main\\dbgpt\\core\\awel\\util\\chat_util.py\", line 95, in safe_chat_stream_with_dag_task\n    yield ModelOutput(error_code=1, text=simple_error_msg, incremental=incremental)\nGeneratorExit\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"j:\\db-gpt-main\\dbgpt\\core\\awel\\util\\chat_util.py\", line 98, in safe_chat_stream_with_dag_task\n    await task.dag._after_dag_end(task.current_event_loop_task_id)\n  File \"j:\\db-gpt-main\\dbgpt\\core\\awel\\dag\\base.py\", line 926, in _after_dag_end\n    raise RuntimeError(\nRuntimeError: DAG context not found with event loop task id 2159373769280, task_name: Task-741\n5.算子代码如下\nhttps://github.com/atczyh/paddletest/blob/master/str2stream_operator.py\n请问以上问题该如何解决？已困扰我很长时间了。\n注：我的操作系统是win10，采用Miniconda进行源码部署，python=3.10，部署版本为V0.6.3\n",
      "state": "open",
      "author": "atczyh",
      "author_type": "User",
      "created_at": "2025-01-23T02:24:11Z",
      "updated_at": "2025-05-24T21:04:45Z",
      "closed_at": null,
      "labels": [
        "stale"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2319/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2319",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2319",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:55.812374",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "```python\ntry:\n            print('streamify',data)\n            parsed_data=data.replace(\"data:```vis-db-chart\",'').replace(\"```vis-db-chart\\n\",'').replace(\"\\n```\",'')\n            print('streamify2',parsed_data)\n            parsed_data = json.loads(parsed_data)\n            data_dd=parsed_data['data']",
          "created_at": "2025-01-23T08:25:50Z"
        },
        {
          "author": "atczyh",
          "body": "> try:\n>             print('streamify',data)\n>             parsed_data=data.replace(\"data:```vis-db-chart\",'').replace(\"```vis-db-chart\\n\",'').replace(\"\\n```\",'')\n>             print('streamify2',parsed_data)\n>             parsed_data = json.loads(parsed_data)\n>             data_dd=parsed_data['data",
          "created_at": "2025-01-24T04:01:46Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-05-24T21:04:44Z"
        }
      ]
    },
    {
      "issue_number": 2303,
      "title": "[Bug] [chatdata] /api/v2/chat/completions\"err_msg\": \"float() argument must be a string or a real number, not 'NoneType'\"",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [X] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [X] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU:4\r\nGPU Memory:24G\n\n### Models information\n\nLLM: chatglm4-9b\r\nembedding: m3e\n\n### What happened\n\n call\r\n curl -X POST \"http://localhost:5670/api/v2/chat/completions\" \\\r\n    -H \"Authorization: Bearer dbgpt\" \\\r\n    -H \"accept: application/json\" \\\r\n    -H \"Content-Type: application/json\" \\\r\n    -d \"{\\\"messages\\\":\\\"G720250113收单量多少\\\",\\\"model\\\":\\\"proxyllm\\\", \\\"chat_mode\\\": \\\"chat_data\\\", \\\"chat_param\\\": \\\"pcs_data_collection_g7\\\",\\\"stream\\\":\\\"false\\\"}\"\r\n报错返回：\r\n{\r\n    \"success\": false,\r\n    \"err_code\": \"E0003\",\r\n    \"err_msg\": \"float() argument must be a string or a real number, not 'NoneType'\",\r\n    \"data\": null\r\n}\r\n![image](https://github.com/user-attachments/assets/de43343b-1626-4748-ba32-29bfec6cba6e)\r\n\r\n\r\n\n\n### What you expected to happen\n\n正常调用\n\n### How to reproduce\n\n正常调用\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Sloane9511",
      "author_type": "User",
      "created_at": "2025-01-14T04:01:43Z",
      "updated_at": "2025-05-23T21:05:21Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2303/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2303",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2303",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:56.002154",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "can you execute in dbgpt webserver?",
          "created_at": "2025-01-15T10:03:39Z"
        },
        {
          "author": "2u0ta0",
          "body": "try add \n    \"temperature\": 0.7,\n    \"max_new_tokens\": 2000\ninto your -d\n\nit should work",
          "created_at": "2025-01-17T01:34:41Z"
        },
        {
          "author": "Aries-ckt",
          "body": "can you show the error log?",
          "created_at": "2025-01-23T08:27:08Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-05-23T21:05:20Z"
        }
      ]
    },
    {
      "issue_number": 2305,
      "title": "[Bug] [Module Name] /spaces/{space_id}/retrieve",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n-\n\n### Models information\n\n-\n\n### What happened\n\n![image](https://github.com/user-attachments/assets/8619fbe8-de82-42f3-8709-da830b48a521)\r\n偶然发现这个接口是干什么的，还飘红的呢\n\n### What you expected to happen\n\n-\n\n### How to reproduce\n\n-\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "yuerf",
      "author_type": "User",
      "created_at": "2025-01-14T12:13:42Z",
      "updated_at": "2025-05-23T21:05:19Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2305/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2305",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2305",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:56.204325",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "It is of no use at the moment. It was originally used as a retrieval interface. We will remove it later.",
          "created_at": "2025-01-14T15:33:43Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-05-23T21:05:18Z"
        }
      ]
    },
    {
      "issue_number": 2316,
      "title": "[Bug] [GraphRAG] SchemaNotReadyException: (code=1, message=Collection 'test1_CHUNK_HISTORY' not exist, or you can pass in schema to create one",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU\nGPU Count:1\ngpu memory:24G\n\n### Models information\n\nLLM_MODEL: qwen2.5-7b-instruct\nEMBEDDING_MODEL:m3e-base\n\n### What happened\n\n在构建知识图谱类型的知识库时，上传文件后，进行文件同步时报错\ndocument embedding failed<SchemaNotReadyException: (code=1, message=Collection 'test1_CHUNK_HISTORY' not exist, or you can pass in schema to create one.)>\n\n### What you expected to happen\n\n报错信息来自于milvus_store.py文件中的similar_search_with_scores方法（我使用的向量数据库时milvus），它是由graph_extrator.py的aload_chunk_context方法会调用的，我认为这里的代码逻辑是有缺陷的，在milvus中的collection还没创建的时候，就先调用了similar_search_with_scores方法，而该方法的实现逻辑里并没有判断collection是否存在，所以导致报错提示collection不存在。\n修复建议，在similar_search_with_scores方法中增加判断collection是否存在的代码。\n原代码如下：\n```        \ntry:\n    from pymilvus import Collection, DataType\nexcept ImportError:\n    raise ValueError(\n        \"Could not import pymilvus python package. \"\n        \"Please install it with `pip install pymilvus`.\"\n    )\n\nself.col = Collection(self.collection_name)\n```\n\n修复后的代码如下：\n```        \ntry:\n    from pymilvus import Collection, DataType, utility\nexcept ImportError:\n    raise ValueError(\n        \"Could not import pymilvus python package. \"\n        \"Please install it with `pip install pymilvus`.\"\n    )\n\nif not utility.has_collection(self.collection_name):\n    return []\nself.col = Collection(self.collection_name)\n```\n\n### How to reproduce\n\n1.构建一个知识图谱类型的知识库；\n2.上传一个文件；\n3.选择上传的文件，点击\"同步\"\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "xuxl2024",
      "author_type": "User",
      "created_at": "2025-01-21T03:30:55Z",
      "updated_at": "2025-05-23T21:05:16Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2316/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2316",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2316",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:56.397886",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "which dbgpt version?\n",
          "created_at": "2025-01-23T06:01:21Z"
        },
        {
          "author": "xuxl2024",
          "body": "> which dbgpt version?\n\nthe latest version\n\n",
          "created_at": "2025-01-23T06:20:44Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-05-23T21:05:16Z"
        }
      ]
    },
    {
      "issue_number": 2697,
      "title": "[Bug] [Dashboard] Fix stream parameter not working in chat_dashboard mode for API v1",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nMacOS(M1, M2...)\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [x] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nLLM: Qwen/Qwen2.5-72B-Instruct\nembeddings: BAAI/bge-large-zh-v1.5\nrerankers: BAAI/bge-reranker-v2-m3\n\n### What happened\n\nWhen using chat_dashboard mode through api_v1, the API always returns streaming responses without the ability to control this behavior via parameters. This makes it difficult for some client scenarios (such as when a complete result is needed at once) to process the response properly.\n\n### What you expected to happen\n\n1. By default, continue using streaming responses to maintain backward compatibility\n2. When \"stream\": false is set, return a complete JSON object instead of a streaming response\n3. The returned JSON should be in raw format, without escape characters and external quotes\n\n### How to reproduce\n\ncurl --location 'http://localhost:5690/api/v1/chat/completions' \\\n--header 'Content-Type: application/json' \\\n--data '{\n    \"select_param\": \"xxx\",\n    \"chat_mode\": \"chat_dashboard\",\n    \"model_name\": \"Qwen3-235B-A22B-FP8\",\n    \"user_input\": \"xxxx\",\n    \"conv_uid\": \"53a6bfd4-2cb2-11f0-89c1-a2f85211c6ae\",\n    \"stream\": false\n}'\n\nven without setting the stream parameter, or when setting \"stream\": false, the API still returns a streaming response.\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "WangzJi",
      "author_type": "User",
      "created_at": "2025-05-15T09:25:00Z",
      "updated_at": "2025-05-23T14:21:18Z",
      "closed_at": "2025-05-23T14:21:18Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2697/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2697",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2697",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:56.605876",
      "comments": []
    },
    {
      "issue_number": 2668,
      "title": "[Feature][RAG]Hybrid Retrieve Based on Knowledge Space.",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n_No response_\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "Aries-ckt",
      "author_type": "User",
      "created_at": "2025-05-04T15:35:19Z",
      "updated_at": "2025-05-23T10:54:23Z",
      "closed_at": "2025-05-23T10:54:23Z",
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2668/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "Aries-ckt"
      ],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2668",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2668",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:56.605899",
      "comments": []
    },
    {
      "issue_number": 2628,
      "title": "[Doc][Module Name] Prompts Unable to perform scenario application",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nI’m unable to apply prompt templates in DB-GPT. I have already created the related prompts and configured them in the chat data scenario, but it keeps throwing errors.\n\nFrom my understanding, once the prompt templates are properly configured, the database and the user input parameters should be passed through variables, and I shouldn’t need to configure anything else manually. I’ve searched for similar issues in the Issues section, but unfortunately, there’s no solution available.\n\nI’ve also read the official documentation and followed the instructions to create prompts accordingly, but I still can’t get them to work.\n\nOfficial example: http://docs.dbgpt.cn/docs/application/prompts\nI followed the official example step-by-step to create prompts, but they still don’t work in the scenario, not even in the Chat Dashboard. I did notice that someone else raised a similar issue (https://github.com/eosphoros-ai/DB-GPT/issues/2199), but I have no idea how they resolved it.\n\nHonestly, the examples in the official documentation are way too limited.\n\nRight now, I don’t know how I should configure it. Could you please provide me with a working example?\n\nIn my understanding, each database instance serves its own business context, and each business comes with its own terminology. That’s why prompt templates are needed to link to each application scenario.\n\nI really don’t know what to do anymore, and there’s no one I can turn to for help.\n\n\n![Image](https://github.com/user-attachments/assets/e371d05b-6e37-4c53-be2f-5f6ec1021d2e)\n\n![Image](https://github.com/user-attachments/assets/fae8a32c-41d7-4e5c-aed1-8329c06d46b4)\n\n![Image](https://github.com/user-attachments/assets/61204f60-b404-4caa-9eda-d67d60de590c)\n\n![Image](https://github.com/user-attachments/assets/46e4b388-3720-4a9c-bc84-6744debe7b82)\n\n\n### Documentation Links\n\nOfficial example: http://docs.dbgpt.cn/docs/application/prompts\n\nhttps://github.com/eosphoros-ai/DB-GPT/issues/2199\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!\n\n###  error log：\n\n2025-04-15 16:24:14 localhost.localdomain dbgpt_app.openapi.api_v1.api_v1[1277848] ERROR stream_generator error\nTraceback (most recent call last):\n  File \"/home/DB-GPT/packages/dbgpt-app/src/dbgpt_app/openapi/api_v1/api_v1.py\", line 732, in stream_generator\n    async for chunk in chat.stream_call(\n  File \"/home/DB-GPT/packages/dbgpt-app/src/dbgpt_app/scene/base_chat.py\", line 342, in stream_call\n    payload = await self._build_model_request()\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/DB-GPT/packages/dbgpt-app/src/dbgpt_app/scene/base_chat.py\", line 320, in _build_model_request\n    model_request: ModelRequest = await node.call(call_data=node_input)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/DB-GPT/packages/dbgpt-core/src/dbgpt/core/awel/operators/base.py\", line 283, in call\n    out_ctx = await self._runner.execute_workflow(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/DB-GPT/packages/dbgpt-core/src/dbgpt/core/awel/runner/local_runner.py\", line 114, in execute_workflow\n    await self._execute_node(\n  File \"/home/DB-GPT/packages/dbgpt-core/src/dbgpt/core/awel/runner/local_runner.py\", line 212, in _execute_node\n    raise e\n  File \"/home/DB-GPT/packages/dbgpt-core/src/dbgpt/core/awel/runner/local_runner.py\", line 192, in _execute_node\n    await node._run(dag_ctx, task_ctx.log_id)\n  File \"/home/DB-GPT/packages/dbgpt-core/src/dbgpt/core/awel/operators/base.py\", line 248, in _run\n    return await self._do_run(dag_ctx)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/DB-GPT/packages/dbgpt-core/src/dbgpt/core/awel/operators/common_operator.py\", line 186, in _do_run\n    output: TaskOutput[OUT] = await wrapped_call_data.map(map_function)\n                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/DB-GPT/packages/dbgpt-core/src/dbgpt/core/awel/task/task_impl.py\", line 127, in map\n    out = await self._apply_func(map_func)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/DB-GPT/packages/dbgpt-core/src/dbgpt/core/awel/task/task_impl.py\", line 113, in _apply_func\n    out = await func(self._data)\n          ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/DB-GPT/packages/dbgpt-app/src/dbgpt_app/scene/operators/app_operator.py\", line 92, in map\n    messages = await end_node.call(\n               ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/DB-GPT/packages/dbgpt-core/src/dbgpt/core/awel/operators/base.py\", line 283, in call\n    out_ctx = await self._runner.execute_workflow(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/DB-GPT/packages/dbgpt-core/src/dbgpt/core/awel/runner/local_runner.py\", line 114, in execute_workflow\n    await self._execute_node(\n  File \"/home/DB-GPT/packages/dbgpt-core/src/dbgpt/core/awel/runner/local_runner.py\", line 212, in _execute_node\n    raise e\n  File \"/home/DB-GPT/packages/dbgpt-core/src/dbgpt/core/awel/runner/local_runner.py\", line 192, in _execute_node\n    await node._run(dag_ctx, task_ctx.log_id)\n  File \"/home/DB-GPT/packages/dbgpt-core/src/dbgpt/core/awel/operators/base.py\", line 248, in _run\n    return await self._do_run(dag_ctx)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/DB-GPT/packages/dbgpt-core/src/dbgpt/core/awel/operators/common_operator.py\", line 62, in _do_run\n    input_ctx: InputContext = await curr_task_ctx.task_input.map_all(\n                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/DB-GPT/packages/dbgpt-core/src/dbgpt/core/awel/task/task_impl.py\", line 579, in map_all\n    map_res = await map_func(*outputs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/DB-GPT/packages/dbgpt-core/src/dbgpt/util/function_utils.py\", line 169, in async_wrapper\n    return await func(*sorted_args, **sorted_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/DB-GPT/packages/dbgpt-core/src/dbgpt/core/interface/operators/prompt_operator.py\", line 432, in merge_history\n    return await self.format_prompt(self._prompt, prompt_dict)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/DB-GPT/packages/dbgpt-core/src/dbgpt/core/interface/operators/prompt_operator.py\", line 121, in format_prompt\n    messages = prompt.format_messages(**pass_kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/DB-GPT/packages/dbgpt-core/src/dbgpt/core/interface/prompt.py\", line 236, in format_messages\n    result_messages.extend(message.format_messages(**pass_kwargs))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/DB-GPT/packages/dbgpt-core/src/dbgpt/core/interface/prompt.py\", line 149, in format_messages\n    content = self.prompt.format(**kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/DB-GPT/packages/dbgpt-core/src/dbgpt/core/interface/prompt.py\", line 87, in format\n    return _DEFAULT_FORMATTER_MAPPING[self.template_format](\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/string.py\", line 190, in format\n    return self.vformat(format_string, args, kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/DB-GPT/packages/dbgpt-core/src/dbgpt/util/formatting.py\", line 31, in vformat\n    return super().vformat(format_string, args, kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/string.py\", line 194, in vformat\n    result, _ = self._vformat(format_string, args, kwargs, used_args, 2)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/string.py\", line 234, in _vformat\n    obj, arg_used = self.get_field(field_name, args, kwargs)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/string.py\", line 299, in get_field\n    obj = self.get_value(first, args, kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/string.py\", line 256, in get_value\n    return kwargs[key]\n           ~~~~~~^^^^^\nKeyError: 'response'\n2025-04-15 16:24:14 localhost.localdomain dbgpt.datasource.rdbms.base[1277848] INFO Closing RDBMS connector resources...\nINFO:     10.37.93.63:60069 - \"GET /api/v1/chat/dialogue/list HTTP/1.1\" 200 OK\n",
      "state": "closed",
      "author": "hhaishen",
      "author_type": "User",
      "created_at": "2025-04-15T08:39:01Z",
      "updated_at": "2025-05-23T09:05:57Z",
      "closed_at": "2025-05-23T09:05:57Z",
      "labels": [
        "documentation",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2628/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2628",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2628",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:58.504953",
      "comments": [
        {
          "author": "2054859196",
          "body": "Same question in chatData.",
          "created_at": "2025-04-16T14:07:09Z"
        },
        {
          "author": "trust-23",
          "body": "同问\n",
          "created_at": "2025-05-10T07:00:39Z"
        },
        {
          "author": "china-zhz",
          "body": "同问+1",
          "created_at": "2025-05-14T10:29:01Z"
        },
        {
          "author": "csk7788",
          "body": "+1",
          "created_at": "2025-05-20T01:33:21Z"
        },
        {
          "author": "chenliang15405",
          "body": "This question look like caused by the can not parse the `response` keyword placeholder in the prompt.  I'll try to get at this sometime soonish.",
          "created_at": "2025-05-20T08:56:53Z"
        }
      ]
    },
    {
      "issue_number": 2723,
      "title": "[Feature][prompt] 提示词里面的用户输入和messages里用户输入内容冗余",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n![Image](https://github.com/user-attachments/assets/ada27b69-eda6-4fe2-9c5e-71c27d15a7e9)\n这些提示词模板中有用户输入信息，实际调用时messages里也会有用户输入，这样信息是不是冗余了，是否可以删除默认提示词模板中的用户输入变量占位？\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "china-zhz",
      "author_type": "User",
      "created_at": "2025-05-23T05:54:17Z",
      "updated_at": "2025-05-23T07:56:26Z",
      "closed_at": "2025-05-23T07:08:58Z",
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2723/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2723",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2723",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:58.693577",
      "comments": [
        {
          "author": "fangyinc",
          "body": "This isn't redundant messaging - it's specially designed and works particularly well in multi-turn conversation scenarios.",
          "created_at": "2025-05-23T07:08:58Z"
        },
        {
          "author": "china-zhz",
          "body": "> This isn't redundant messaging - it's specially designed and works particularly well in multi-turn conversation scenarios.\n\n真心请教下，为什么多轮会话中system消息中加上用户的问题效果好呢，而且在多轮会话历史记录中这个system消息里的用户输入部分好像一直是第一次的用户问题吧，新问题不会更新system消息中的内容。",
          "created_at": "2025-05-23T07:55:38Z"
        }
      ]
    },
    {
      "issue_number": 2713,
      "title": "可以利用本地模型实现图形Graph RAG功能吗？",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n看了一下dbgpt-graphrag.toml中好像只有调用API模型，可以用自己本地的模型吗？\n\n### Use case\n\n利用本地模型实现图形Graph RAG功能\n\n### Related issues\n\n无\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "star-wise",
      "author_type": "User",
      "created_at": "2025-05-21T07:45:37Z",
      "updated_at": "2025-05-23T07:35:10Z",
      "closed_at": "2025-05-23T07:35:10Z",
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2713/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2713",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2713",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:58.869851",
      "comments": [
        {
          "author": "fangyinc",
          "body": "Yes, just modiy your toml file according to other local LLM config.",
          "created_at": "2025-05-23T07:35:10Z"
        }
      ]
    },
    {
      "issue_number": 2714,
      "title": "[Bug] [Module Name] Milvus and Mysql not compatiable",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [x] Chat Data\n- [ ] Chat Excel\n- [x] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [x] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice: GPU\nCount: 1\nMemory: 24G\n\n### Models information\n\nLLM:Qwen2.5-14B\nEmbedding:bge-large-zh-v1.5\n\n### What happened\n\nMysql integration and milvus integration is incompatiable. \nWith pymilvus not installed, apps like Chat Data and Chat DB works fine, but unable to use RAG features with vector bases (milvus under my situation, to be specified). \nWith pymilvus installed, the features using vector bases works fine, but these apps appear not be able to retrieve metadata of databases.\n\n### What you expected to happen\n\nMysql and milvus not compatiable.\n\n### How to reproduce\n\n1. Install with docker compose. \n2. Chat with Chat Knowledge, it will not be able to work, and showing 'pip install pymilvus' blabla.\n3. Pip install pymilvus in the container. It will show a compatiable message saying dbgpt 0.7.1 requires python-dotenv>=1.0.1, but pymilvus requires python-dotenv==1.0.0.  \n4. Chat with Chat Knowledge will now work fine, but Chat DB and Chat Data will not be able to retrieve metadata of mysql dbs.\n5. Tried with installation from source code, and manage packages with uv as instructed in quick start. Having the same issue.\n\n### Additional context\n\nAny suggestions on how to integrate milvus into the project?\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "li552233",
      "author_type": "User",
      "created_at": "2025-05-21T08:52:55Z",
      "updated_at": "2025-05-23T07:17:05Z",
      "closed_at": "2025-05-23T07:17:05Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2714/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2714",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2714",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:59.058574",
      "comments": []
    },
    {
      "issue_number": 2720,
      "title": "[Bug] [AWEL] 参考db_expert_assitant设计AWEL工作流利用Agent Branch operator ,拼接后报错All inputs are empty",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nRAM 32.0 GB \nNVIDIA RTX A2000 12GB\n\n\n### Models information\n\nqwen3-8b（ollama）\nqwen2.5-7b-instruct\n\n### What happened\n\n1 参考db_expert_assitant设计AWEL工作流利用Agent Branch operator ,\n2 拼接后报错All inputs are empty，后台日志没报错，前台界面报错All inputs are empty\n3 目前效果是拼接了10+的自写智能体，单独运行或者串联都是可以的，证明不是智能体问题\n4 如下是我拼接截图\n<!-- Failed to upload \"image.png\" -->\n\n### What you expected to happen\n\n期望是和串行awel不一样，不是问一句话就全部跑一编=遍智能体，而是精准匹配只跑对应智能体\n期望和dify一样，如下截图\n\n![Image](https://github.com/user-attachments/assets/025e9142-6f63-4f37-9cf2-b0b8fb54c6fe)\n\n### How to reproduce\n\n参考我发的json格式文件调试 \n\n### Additional context\n\n[PA-Full-MAP-branchMode.json](https://github.com/user-attachments/files/20403447/PA-Full-MAP-branchMode.json)\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "gucciillf",
      "author_type": "User",
      "created_at": "2025-05-23T03:19:24Z",
      "updated_at": "2025-05-23T03:21:48Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2720/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2720",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2720",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:59.058596",
      "comments": [
        {
          "author": "gucciillf",
          "body": "下图为拼接流程截图\n![Image](https://github.com/user-attachments/assets/cd2abfac-843b-4c9c-9582-f6adf0db4bd3)",
          "created_at": "2025-05-23T03:20:54Z"
        },
        {
          "author": "gucciillf",
          "body": "下图为前端报错\n\n![Image](https://github.com/user-attachments/assets/d0e60858-64ad-4f9e-a2bb-defac0e61920)",
          "created_at": "2025-05-23T03:21:46Z"
        }
      ]
    },
    {
      "issue_number": 2708,
      "title": "[Feature][Web] Dashboard supports Pie Chart visualization",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nDescription\nAdd Pie Chart support to the dashboard visualization components.\nNew file: web/components/chart/pie-chart.tsx implements the Pie Chart rendering logic.\nModified file: web/components/chart/index.tsx integrates the new Pie Chart component into the dashboard chart rendering flow.\nSupports Pie Chart preview in Dashboard Editor mode.\n\n### Use case\n\nAs a user, I want to visualize my data in the form of a Pie Chart on the dashboard, so that I can better understand the proportion of different categories in my dataset.\nThis feature allows users to select Pie Chart as a visualization type, and see their data rendered as a pie chart alongside other chart types (bar, line, table, etc.).\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nHigh\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "WangzJi",
      "author_type": "User",
      "created_at": "2025-05-20T09:06:27Z",
      "updated_at": "2025-05-22T09:38:17Z",
      "closed_at": "2025-05-22T09:38:17Z",
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2708/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2708",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2708",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:59.310742",
      "comments": []
    },
    {
      "issue_number": 2710,
      "title": "[Bug] [GraphRAG] `success_ids` in `aload_document_with_limit` may be Exception objects",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nunrelated\n\n### Models information\n\nunrelated\n\n### What happened\n\nIn the [`aload_document_with_limit`](https://github.com/eosphoros-ai/DB-GPT/blob/7e7581e891dbafbf61f9a1ee6187b16e601a38d1/packages/dbgpt-core/src/dbgpt/storage/base.py#L190) method, the results obtained via await `self._run_tasks_with_concurrency(tasks, max_threads) `may contain Exception objects. This occurs because `_run_tasks_with_concurrency `uses `asyncio.gather(*batch, return_exceptions=True)`, which returns exceptions as values instead of raising them when tasks fail.\n\nHowever, the code directly assumes success_ids is a List[str] and calls ids.extend(success_ids). If success_ids is actually an Exception (e.g., ValueError), this will raise an AttributeError (e.g., exceptions are not iterable) or cause logical errors (e.g., treating an exception object as a string ID).\n\n### What you expected to happen\n\nChecking the type of `success_ids`, and for `Exception` objects, raise an exception explicitly.\n\n### How to reproduce\n\nRC\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "geebytes",
      "author_type": "User",
      "created_at": "2025-05-20T17:01:50Z",
      "updated_at": "2025-05-22T09:00:05Z",
      "closed_at": "2025-05-22T09:00:05Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2710/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2710",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2710",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:59.310763",
      "comments": []
    },
    {
      "issue_number": 2307,
      "title": "[Datasource][elasticsearch] data source module does not support elasticsearch",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nThe data source module does not support Elasticsearch. We look forward to supporting this data source or providing a data source plugin development method\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "douglli",
      "author_type": "User",
      "created_at": "2025-01-16T02:45:08Z",
      "updated_at": "2025-05-21T21:05:25Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2307/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2307",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2307",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:59.310771",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "sorry about that, we use elasticsearch as a vector storage and full text storage. ",
          "created_at": "2025-01-21T16:16:07Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-05-21T21:05:25Z"
        }
      ]
    },
    {
      "issue_number": 2317,
      "title": "[Feature][Agent] Add File Upload Support to Agent Module",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nHi team,\nI would like to request a new feature for the agent module. It would be incredibly useful to have an interface that supports file uploads, similar to the functionality provided by chatExcel. This would allow users to upload a file directly to the agent module, enhancing its usability and flexibility.\n\n### Use case\n\nWeb Interface:\nUsers should be able to upload files while interacting with multiple agents chat through the web interface.\nThe file upload option should be easily accessible and intuitive to use.\nAgent Module API:\nThe agent module should include an API endpoint to handle the uploaded files.\nThe API should process the files appropriately, enabling agents to utilize the file data in their operations.\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nHigh\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "RongLei-intel",
      "author_type": "User",
      "created_at": "2025-01-21T08:15:43Z",
      "updated_at": "2025-05-21T21:05:24Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2317/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2317",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2317",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:59.539376",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-05-21T21:05:23Z"
        }
      ]
    },
    {
      "issue_number": 2313,
      "title": "[Feature][GraphRAG] stable reference generation in graphrag",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nAnswer generated by GraphRAG sometimes do not include references of original document.\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "SonglinLyu",
      "author_type": "User",
      "created_at": "2025-01-20T09:52:07Z",
      "updated_at": "2025-05-20T21:05:23Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2313/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2313",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2313",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:38:59.787558",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-05-20T21:05:22Z"
        }
      ]
    },
    {
      "issue_number": 2689,
      "title": "[Bug] [Chat Excel] 上传csv文件后，问答后的Data里的时间变成了1970-01-21，跟原来的csv里时间列对不上",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [x] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [x] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nQwen3-8B\n\n### What happened\n\n[Chat Excel] 上传csv文件后，问答后的Data里的时间全部变成了1970-01-21，跟原来的csv里时间列对不上\n\n### What you expected to happen\n\n1.希望能够看看如何debug这个时间错误?\n2.同时，docker部署的话，如何查看数据库？\n3.如何把Chat Excel这个应用页面单独剥离？\n\n### How to reproduce\n\ndocker pull eosphorosai/dbgpt-openai:latest\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "HuntZhaozq",
      "author_type": "User",
      "created_at": "2025-05-13T08:26:53Z",
      "updated_at": "2025-05-20T11:24:29Z",
      "closed_at": "2025-05-20T11:24:29Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2689/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2689",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2689",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:00.015530",
      "comments": [
        {
          "author": "chenliang15405",
          "body": "Sorry, Could you please describe the problem more detail information? such as attach a screenshot or the de-sensitized data from the Excel",
          "created_at": "2025-05-14T13:07:35Z"
        },
        {
          "author": "HuntZhaozq",
          "body": "I am sorry. The data is inside which can not access the internet. But can you tell me how to check the database in the docker? I want to debug this process.",
          "created_at": "2025-05-15T01:45:08Z"
        },
        {
          "author": "chenliang15405",
          "body": "> I am sorry. The data is inside which can not access the internet. But can you tell me how to check the database in the docker? I want to debug this process.\n\nexcel data will be stored in DuckDB. The default path for temporary files is pilot/data/_chat_excel_tmp/  directory",
          "created_at": "2025-05-19T08:29:44Z"
        },
        {
          "author": "chenliang15405",
          "body": "It look like pandas format timestamp serialization problem,  I'll try fix it\n",
          "created_at": "2025-05-19T14:01:14Z"
        }
      ]
    },
    {
      "issue_number": 2706,
      "title": "[Bug] [AWEL] AttributeError: 'CommonLLMHttpRequestBody' object has no attribute 'get'",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nLLM：deepseek-v3\nEMBEDDING：BAAI/bge-large-zh-v1.5\n\n\n### What happened\n\nWhen testing the `embedding_process_workflow` template, I encountered an AttributeError after saving and starting the conversation. The error suggests that `CommonLLMHttpRequestBody` doesn't have a `get` attribute.\n\n**Error Log**:\n```\n2025-05-20 16:19:31 LAPTOP-EN7AFHC7 dbgpt_app.openapi.api_v1.api_v1[4772] INFO chat_completions:chat_flow,c4e21916-b30c-4fd3-a721-755f226ce63f,deepseek-v3, timestamp=1747729171632\n2025-05-20 16:19:31 LAPTOP-EN7AFHC7 dbgpt.core.awel.runner.local_runner[4772] INFO Begin run workflow from end operator, id: fc9251ae-3f36-47a3-96b3-1ef89b3e2535, runner: <dbgpt.core.awel.runner.local_runner.DefaultWorkflowRunner object at 0x00000173AFF8F650>\n2025-05-20 16:19:31 LAPTOP-EN7AFHC7 dbgpt.core.awel.runner.local_runner[4772] INFO Run operator <class 'dbgpt_ext.rag.operators.knowledge.KnowledgeOperator'>(27398d5e-56b9-4164-957e-26400572bd63) error, error message: Traceback (most recent call last):\n  File \"E:\\uxun\\projects\\uxun-dbgpt\\packages\\dbgpt-core\\src\\dbgpt\\core\\awel\\runner\\local_runner.py\", line 192, in _execute_node\n    await node._run(dag_ctx, task_ctx.log_id)\n  File \"E:\\uxun\\projects\\uxun-dbgpt\\packages\\dbgpt-core\\src\\dbgpt\\core\\awel\\operators\\base.py\", line 248, in _run\n    return await self._do_run(dag_ctx)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\uxun\\projects\\uxun-dbgpt\\packages\\dbgpt-core\\src\\dbgpt\\core\\awel\\operators\\common_operator.py\", line 190, in _do_run\n    input_ctx: InputContext = await curr_task_ctx.task_input.map(map_function)\n                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\uxun\\projects\\uxun-dbgpt\\packages\\dbgpt-core\\src\\dbgpt\\core\\awel\\task\\task_impl.py\", line 539, in map\n    new_outputs, results = await self._apply_func(map_func)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\uxun\\projects\\uxun-dbgpt\\packages\\dbgpt-core\\src\\dbgpt\\core\\awel\\task\\task_impl.py\", line 534, in _apply_func\n    results = await asyncio.gather(*map_tasks)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\uxun\\projects\\uxun-dbgpt\\packages\\dbgpt-core\\src\\dbgpt\\core\\awel\\task\\task_impl.py\", line 127, in map\n    out = await self._apply_func(map_func)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\uxun\\projects\\uxun-dbgpt\\packages\\dbgpt-core\\src\\dbgpt\\core\\awel\\task\\task_impl.py\", line 113, in _apply_func\n    out = await func(self._data)\n          ^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\uxun\\projects\\uxun-dbgpt\\packages\\dbgpt-ext\\src\\dbgpt_ext\\rag\\operators\\knowledge.py\", line 94, in map\n    source = datasource.get(\"source\")\n             ^^^^^^^^^^^^^^\n  File \"E:\\uxun\\projects\\uxun-dbgpt\\.venv\\Lib\\site-packages\\pydantic\\main.py\", line 994, in __getattr__\n    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')\nAttributeError: 'CommonLLMHttpRequestBody' object has no attribute 'get'\n```\n\n**Expected Behavior**:\nThe workflow should execute without attribute errors.\n\n**Environment**:\n- Date/time of error: 2025-05-20 16:19:31\n- Appears to be running on Windows\n\n### What you expected to happen\n\nThe KnowledgeOperator appears to expect a dictionary-like object (trying to call .get()), but is receiving a CommonLLMHttpRequestBody Pydantic model instead.\n\n### How to reproduce\n\n**Steps to Reproduce**:\n1. Create an AWEL workflow using the `embedding_process_workflow` template\n2. Save the workflow\n3. Click \"Start Conversation\" and sent \"hi\"\n4. Observe the error\n\n### Additional context\n\n**Additional Context**:\nThe error occurs when the KnowledgeOperator tries to call `.get()` on what appears to be a Pydantic model (`CommonLLMHttpRequestBody`).\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "PhotonYao",
      "author_type": "User",
      "created_at": "2025-05-20T08:37:22Z",
      "updated_at": "2025-05-20T08:37:22Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2706/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2706",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2706",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:00.283946",
      "comments": []
    },
    {
      "issue_number": 2655,
      "title": "[开发指南第一个示例]'NoneType' object has no attribute 'put'",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n按照步骤运行代码报错：\ncontext: AgentContext(conv_id='test123', gpts_app_code=None, gpts_app_name=None, language='zh', max_chat_round=100, max_retry_round=10, max_new_tokens=2048, temperature=0.5, allow_format_str_template=False, verbose=False, app_link_start=False, enable_vis_message=True)\nagent_memory: <dbgpt.agent.core.memory.agent_memory.AgentMemory object at 0x000001D76F158B10>\nagent_memory.gpts_memory: <dbgpt.agent.core.memory.gpts.gpts_memory.GptsMemory object at 0x000001D76F158E10>\nTraceback (most recent call last):\n  File \"d:\\conda_env\\dbgptenv\\Lib\\runpy.py\", line 198, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\conda_env\\dbgptenv\\Lib\\runpy.py\", line 88, in _run_code      \n    exec(code, run_globals)\n  File \"c:\\Users\\chh\\.vscode\\extensions\\ms-python.debugpy-2025.6.0-win32-x64\\bundled\\libs\\debugpy\\launcher/../..\\debugpy\\__main__.py\", line 71, \nin <module>\n    cli.main()\n  File \"c:\\Users\\chh\\.vscode\\extensions\\ms-python.debugpy-2025.6.0-win32-x64\\bundled\\libs\\debugpy\\launcher/../..\\debugpy/..\\debugpy\\server\\cli.py\", line 501, in main\n    run()\n  File \"c:\\Users\\chh\\.vscode\\extensions\\ms-python.debugpy-2025.6.0-win32-x64\\bundled\\libs\\debugpy\\launcher/../..\\debugpy/..\\debugpy\\server\\cli.py\", line 351, in run_file\n    runpy.run_path(target, run_name=\"__main__\")\n  File \"c:\\Users\\chh\\.vscode\\extensions\\ms-python.debugpy-2025.6.0-win32-x64\\bundled\\libs\\debugpy\\_vendored\\pydevd\\_pydevd_bundle\\pydevd_runpy.py\", line 310, in run_path\n    return _run_module_code(code, init_globals, run_name, pkg_name=pkg_name, script_name=fname)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\chh\\.vscode\\extensions\\ms-python.debugpy-2025.6.0-win32-x64\\bundled\\libs\\debugpy\\_vendored\\pydevd\\_pydevd_bundle\\pydevd_runpy.py\", line 127, in _run_module_code\n    _run_code(code, mod_globals, init_globals, mod_name, mod_spec, pkg_name, script_name)\n  File \"c:\\Users\\chh\\.vscode\\extensions\\ms-python.debugpy-2025.6.0-win32-x64\\bundled\\libs\\debugpy\\_vendored\\pydevd\\_pydevd_bundle\\pydevd_runpy.py\", line 118, in _run_code\n    exec(code, run_globals)\n  File \"d:\\project\\AI\\ph-huanyu\\example\\googleagent\\run.py\", line 36, in <module>\n    asyncio.run(main())\n  File \"d:\\conda_env\\dbgptenv\\Lib\\asyncio\\runners.py\", line 190, in run \n    return runner.run(main)\n           ^^^^^^^^^^^^^^^^\n  File \"d:\\conda_env\\dbgptenv\\Lib\\asyncio\\runners.py\", line 118, in run \n    return self._loop.run_until_complete(task)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\conda_env\\dbgptenv\\Lib\\asyncio\\base_events.py\", line 654, in \nrun_until_complete\n    return future.result()\n           ^^^^^^^^^^^^^^^\n  File \"d:\\project\\AI\\ph-huanyu\\example\\googleagent\\run.py\", line 26, in main\n    await user_proxy.initiate_chat(\n  File \"d:\\conda_env\\dbgptenv\\Lib\\site-packages\\dbgpt\\agent\\core\\base_agent.py\", line 714, in initiate_chat\n    await self.send(\n  File \"d:\\conda_env\\dbgptenv\\Lib\\site-packages\\dbgpt\\agent\\core\\base_agent.py\", line 238, in send\n    await recipient.receive(\n  File \"d:\\conda_env\\dbgptenv\\Lib\\site-packages\\dbgpt\\agent\\core\\base_agent.py\", line 279, in receive\n    await self._a_process_received_message(message, sender)\n  File \"d:\\conda_env\\dbgptenv\\Lib\\site-packages\\dbgpt\\agent\\core\\base_agent.py\", line 839, in _a_process_received_message\n    valid = await self._a_append_message(message, None, sender)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\conda_env\\dbgptenv\\Lib\\site-packages\\dbgpt\\agent\\core\\base_agent.py\", line 793, in _a_append_message\n    await self.memory.gpts_memory.append_message(\n  File \"d:\\conda_env\\dbgptenv\\Lib\\site-packages\\dbgpt\\agent\\core\\memory\\gpts\\gpts_memory.py\", line 130, in append_message\n    await self.push_message(conv_id)\n  File \"d:\\conda_env\\dbgptenv\\Lib\\site-packages\\dbgpt\\agent\\core\\memory\\gpts\\gpts_memory.py\", line 105, in push_message\n    await queue.put(message_view)\n          ^^^^^^^^^\nAttributeError: 'NoneType' object has no attribute 'put'\n\n### Documentation Links\n\n http://docs.dbgpt.cn/docs/agents/introduction/#write-your-first-calculator-with-agent\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "haochenhh",
      "author_type": "User",
      "created_at": "2025-04-25T03:30:47Z",
      "updated_at": "2025-05-19T12:42:33Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2655/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2655",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2655",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:00.283967",
      "comments": [
        {
          "author": "chenliang15405",
          "body": "please refer to this latest doc: [http://docs.dbgpt.cn/docs/next/agents/introduction/](http://docs.dbgpt.cn/docs/next/agents/introduction/)",
          "created_at": "2025-05-19T12:42:33Z"
        }
      ]
    },
    {
      "issue_number": 2704,
      "title": "[Bug] [web] DBGPT折线图在手机端显示不会自适应大小",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU\n\n### Models information\n\ntext2vec\n\n### What happened\n\n图标不能自适应，无法完整显示\n\n### What you expected to happen\n\n在移动客户端模式下，构造折线图等图标返回，显示不完整\n\n### How to reproduce\n\n1\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Ayanami-li",
      "author_type": "User",
      "created_at": "2025-05-19T10:18:25Z",
      "updated_at": "2025-05-19T10:18:25Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2704/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2704",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2704",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:00.525603",
      "comments": []
    },
    {
      "issue_number": 2703,
      "title": "[Bug] [Chat data] 数据库中有22张表，但我让他告诉我多少张表，他无论如何都只说16张。",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nMacOS(x86)\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [x] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU：\n8G\n\n\n### Models information\n\ndeepseek R1 reasoner\n\n### What happened\n\nI am doing some poc in DBGPT Chat-data, using mysql sample database sakila, which contains 22 tables. All is good in general scenarios. But I notice some basic default like it can't response number of tables in databases correctly, it reponse 10 tables while actually it has 22. I looked into the source code and found a default config parameter top_k=10, which seems the key to this error, then I changed it to 1000, and other limitations like max_token_lenght, but the result is 16, it does better but wrong still.\nI guess the max_new_token parameter took effect in this scene?\n\n### What you expected to happen\n\nIt should respond number of tables correctly.\n\n### How to reproduce\n\nJust like I described above.\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "playerunknown2023",
      "author_type": "User",
      "created_at": "2025-05-19T07:43:09Z",
      "updated_at": "2025-05-19T07:43:09Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2703/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2703",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2703",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:00.525620",
      "comments": []
    },
    {
      "issue_number": 1252,
      "title": "begin run _add_app_startup_event",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [X] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\ncpu\n\n### Models information\n\nintel i5\n\n### What happened\n\n![微信图片_20240304202109](https://github.com/eosphoros-ai/DB-GPT/assets/77387991/8df1d3d7-24b1-4689-9227-49e2759e1466) 启动之后卡在这里一直不动了\r\n\n\n### What you expected to happen\n\n我也不清楚哪里出问题了\n\n### How to reproduce\n\n启动后出现问题\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "PanYuQi66666666",
      "author_type": "User",
      "created_at": "2024-03-04T12:22:45Z",
      "updated_at": "2025-05-16T07:07:09Z",
      "closed_at": "2024-04-23T21:04:39Z",
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1252/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1252",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1252",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:00.525627",
      "comments": [
        {
          "author": "PanYuQi66666666",
          "body": "please！！！！\r\n",
          "created_at": "2024-03-04T12:23:11Z"
        },
        {
          "author": "csunny",
          "body": "@PanYuQi66666666  Can you access http://127.0.0.1:5000?",
          "created_at": "2024-03-04T14:05:09Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-04-03T21:05:25Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue bas been closed, because it has been marked as `stale` and there has been no activity for over 7 days.",
          "created_at": "2024-04-23T21:04:39Z"
        },
        {
          "author": "yzywdd",
          "body": "> please！！！！\n\nplease Have you solved it？？？？ help me\n",
          "created_at": "2025-05-16T06:59:42Z"
        }
      ]
    },
    {
      "issue_number": 874,
      "title": "[Bug] [Module Name] Bug title 源码启动卡在begin run _add_app_startup_event",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU Count:4\r\nCPU Memory:32G\n\n### Models information\n\nLLM: proxyllm\r\nEmbedding Model:m3e-base\n\n### What happened\n\n按照文档步骤操作，启动之后卡在begin run _add_app_startup_event不动。已经更新最新代码。分别在MAC，Ubuntu环境下进行测试，都是同样的问题\n\n### What you expected to happen\n\nINFO  [pilot.model.cluster.worker.default_worker] Begin load model, model params:\r\n\r\n=========================== ProxyModelParameters ===========================\r\n\r\nmodel_name: proxyllm\r\nmodel_path: chatgpt_proxyllm\r\nproxy_server_url: https://api.openai.com/v1/chat/completions\r\nproxy_api_key: s******7\r\nproxy_api_base: None\r\nproxy_api_app_id: None\r\nproxy_api_secret: None\r\nproxy_api_type: None\r\nproxy_api_version: None\r\nhttp_proxy: None\r\nproxyllm_backend: None\r\nmodel_type: proxy\r\ndevice: cpu\r\nprompt_template: None\r\nmax_context_size: 4096\r\n\r\n======================================================================\r\n\r\n\r\nINFO  [pilot.model.loader] Load proxyllm\r\nINFO:     127.0.0.1:54596 - \"POST /api/controller/models HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:54598 - \"POST /api/controller/models HTTP/1.1\" 200 OK\r\nbegin run _add_app_startup_event\n\n### How to reproduce\n\n按照文档部署，选OPENAI + M3E-BASE应该可以复现\n\n### Additional context\n\nINFO  [pilot.model.cluster.worker.default_worker] Begin load model, model params:\r\n\r\n=========================== ProxyModelParameters ===========================\r\n\r\nmodel_name: proxyllm\r\nmodel_path: chatgpt_proxyllm\r\nproxy_server_url: https://api.openai.com/v1/chat/completions\r\nproxy_api_key: s******7\r\nproxy_api_base: None\r\nproxy_api_app_id: None\r\nproxy_api_secret: None\r\nproxy_api_type: None\r\nproxy_api_version: None\r\nhttp_proxy: None\r\nproxyllm_backend: None\r\nmodel_type: proxy\r\ndevice: cpu\r\nprompt_template: None\r\nmax_context_size: 4096\r\n\r\n======================================================================\r\n\r\n\r\nINFO  [pilot.model.loader] Load proxyllm\r\nINFO:     127.0.0.1:54596 - \"POST /api/controller/models HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:54598 - \"POST /api/controller/models HTTP/1.1\" 200 OK\r\nbegin run _add_app_startup_event\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "shanchxxx",
      "author_type": "User",
      "created_at": "2023-11-30T14:20:30Z",
      "updated_at": "2025-05-16T06:50:52Z",
      "closed_at": "2024-02-25T21:04:43Z",
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 16,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/874/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/874",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/874",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:00.762384",
      "comments": [
        {
          "author": "yulongwanxue",
          "body": "有大佬解决没？\r\n",
          "created_at": "2023-11-30T17:32:31Z"
        },
        {
          "author": "shanchxxx",
          "body": "> 有大佬解决没？\r\n\r\n你也有同样的问题吗，我切回老版本没问题了",
          "created_at": "2023-12-01T02:45:59Z"
        },
        {
          "author": "Mike4Ellis",
          "body": "所以到这步还没启动结束是吗？那你在这步访问网站前端会出现Uncaught SyntaxError: Unexpected token '<'报错吗？",
          "created_at": "2023-12-05T07:05:01Z"
        },
        {
          "author": "MangoFF",
          "body": "我也是这样\r\nINFO:     127.0.0.1:53394 - \"POST /api/controller/models HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:53420 - \"POST /api/controller/models HTTP/1.1\" 200 OK\r\nbegin run _add_app_startup_event",
          "created_at": "2023-12-08T03:05:26Z"
        },
        {
          "author": "MangoFF",
          "body": "我发现我的问题了，对我来说，似乎卡在这里并没有什么问题。我因为连接的是跳板机，所以端口没有开放给本地，所以无法访问到。",
          "created_at": "2023-12-08T05:46:26Z"
        }
      ]
    },
    {
      "issue_number": 2306,
      "title": "[Bug] [Libro Lab] When libro lab is started in windows, the awel file path cannot be loaded correctly",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [X] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice: GPU\r\nGPU: count 1\r\nGPU Memory: 24G\n\n### Models information\n\nLLM: gpt-4o\r\nEmbedding: text-embedding-3-small\n\n### What happened\n\nThe path of the all_in_one_entrance awel file cannot be read in windows.\n\n### What you expected to happen\n\nThank you for your feedback! To better understand the issue:\r\n\r\n1、I observed that Libro reads the USERPROFILE environment variable by default, which on windows is /Users/{Username}, so I tried logging into the Libro lab web page(http://127.0.0.1:5671/) and found that the initial directory was indeed set to /Users/{Username} \r\n![image](https://github.com/user-attachments/assets/533e7935-18a5-48f5-b9f6-ecc22dfa5cee)\r\n\r\n2、I took a look at the startup log and it confirmed my point\r\n![image](https://github.com/user-attachments/assets/82183782-5ea7-4ac4-943c-e7259ae64594)\r\n\r\n3、Therefore, I guess whether the root path is /Users/{Username}, resulting in the repeated addition of /Users/{Username} to the request api, resulting in the failure to find the awel file. I tried to modify the api address and delete the corresponding part of the USERPROFILE environment variable, and the modified connection is 【http://127.0.0.1:5671/api/contents/.dbgpts/packages/b01e70f9f4fefdf6fba0d1e3339728e9/all-in-one-entrance/all_in_one_entrance?1736912687405】  the file path can be read normally\r\n![image](https://github.com/user-attachments/assets/979d508f-06b8-4b5f-a72e-f744f19c286b)\r\n\r\n4、Summary bug speculation: When Windows Libro loads, the path of USERPROFILE is read, the default root path is already /Users/{Username}, but when the api interface is spliced, it is still spliced from the root path of \"/\", resulting in inconsistent context paths and no awel file\n\n### How to reproduce\n\nstep to reproduce the behavior:\r\n\r\n**1、Operation procedure**\r\n![image](https://github.com/user-attachments/assets/75fc6147-6805-47a3-85c0-3fc3c5efa202)\r\n\r\n**2、Error Message**\r\n![image](https://github.com/user-attachments/assets/0a607271-4003-4365-8f9a-15bf1e0c170d)\r\n\r\n**3、api Request 404**\r\n【GET】http://127.0.0.1:5671/api/contents/Users/{Username}/.dbgpts/packages/b01e70f9f4fefdf6fba0d1e3339728e9/all-in-one-entrance/all_in_one_entrance?1736912687405   \r\n\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "memoryDemo",
      "author_type": "User",
      "created_at": "2025-01-15T04:04:54Z",
      "updated_at": "2025-05-15T21:05:24Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2306/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2306",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2306",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:01.005489",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "sorry about that, we will check out.\r\n",
          "created_at": "2025-01-15T16:05:42Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-05-15T21:05:23Z"
        }
      ]
    },
    {
      "issue_number": 2522,
      "title": "代码部署，如果数据库的chunks超过100，会在第99的时候卡一下，然后程序直接中断",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [x] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nIntel(R) Core(TM) i5-10210U CPU @ 1.60GHz   2.10 GHz   未使用GPU。\n\n### Models information\n\nLLM：qwen-plus  嵌入模型：text-embedding-v3\n\n### What happened\n\n如果数据库的表结构比较多，添加完数据库连接后，进行初始化向量，但是如果超过100个chunks，程序就会中断直接退出，没有报任何错误信息\n\n![Image](https://github.com/user-attachments/assets/73c4f0ec-689f-4ab9-a686-3d860a9cc016)\n\n\n\n### What you expected to happen\n\n希望数据库表多的时候，超过100个chunks依然可以正常向量\n\n### How to reproduce\n\n1、创建数据库连接（MYSQL5.7）\n2、创建完成后系统开始向量，但是超过100个就会出现程序中断并退出\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "sunxc-dev",
      "author_type": "User",
      "created_at": "2025-03-25T06:46:45Z",
      "updated_at": "2025-05-15T14:19:27Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2522/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2522",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2522",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:01.224270",
      "comments": [
        {
          "author": "QGcPV7EBU58rclpM",
          "body": "相同的问题，怎么解决啊",
          "created_at": "2025-04-10T08:46:31Z"
        },
        {
          "author": "xigan-bit",
          "body": "请问解决了吗",
          "created_at": "2025-05-10T07:59:49Z"
        },
        {
          "author": "QGcPV7EBU58rclpM",
          "body": "\n\n\n> 请问解决了吗\n\n解决了，是chroma版本太高了，需要降低版本",
          "created_at": "2025-05-15T14:19:09Z"
        }
      ]
    },
    {
      "issue_number": 2694,
      "title": "[Bug] [ChatDashboard] 自定义提示词模板变量名不匹配导致KeyError: 'question'错误",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nMacOS(M1, M2...)\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [x] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nLLM: Qwen/Qwen2.5-72B-Instruct\nembeddings: BAAI/bge-large-zh-v1.5\nrerankers: BAAI/bge-reranker-v2-m3\n\n### What happened\n\n在使用自定义提示词（通过`prompt_code`参数）时，系统抛出`KeyError: 'question'`错误。这是因为在`base_chat.py`中创建自定义提示词模板时使用了`{question}`作为变量名，但实际传递的参数中使用的是`input`键。\n\n\n### 错误日志\n[DEBUG] Formatting prompt template with variables: ['question']\n[DEBUG] Received kwargs keys: []\n[WARNING] [DEBUG] Missing variables in kwargs: ['question']. This might cause KeyError if not handled.\n[WARNING] [DEBUG] Cannot find any source for 'question' variable\n[WARNING] [DEBUG] After variable mapping, still missing: ['question']. This will likely cause KeyError.\nKeyError: 'question'\n\n### What you expected to happen\n\n在`packages/dbgpt-app/src/dbgpt_app/scene/base_chat.py`中，当使用自定义提示词时，系统创建了以下模板：\n```python\nchat_prompt_template = ChatPromptTemplate(\n    messages=[\n        SystemPromptTemplate.from_template(prompt_template.template),\n        MessagesPlaceholder(variable_name=\"chat_history\"),\n        HumanPromptTemplate.from_template(\"{question}\"),  # 使用了question变量\n    ]\n)\n```\n\n然而，默认的`chat_dashboard`场景使用的是`{input}`作为变量名：\n```python\nHumanPromptTemplate.from_template(\"{input}\")\n```\n\n而`generate_input_values()`方法返回的字典中使用的键是`input`而不是`question`，导致变量名不匹配。\n\n### How to reproduce\n\n1. 创建一个自定义Dashboard提示词模板并获取`prompt_code`\n2. 使用该`prompt_code`调用`/api/v1/chat/completions`接口\n3. 系统返回错误：`KeyError: 'question'`\n\n### Additional context\n\n错误日志\n[DEBUG] Formatting prompt template with variables: ['question']\n[DEBUG] Received kwargs keys: []\n[WARNING] [DEBUG] Missing variables in kwargs: ['question']. This might cause KeyError if not handled.\n[WARNING] [DEBUG] Cannot find any source for 'question' variable\n[WARNING] [DEBUG] After variable mapping, still missing: ['question']. This will likely cause KeyError.\nKeyError: 'question'\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "WangzJi",
      "author_type": "User",
      "created_at": "2025-05-14T11:23:24Z",
      "updated_at": "2025-05-15T08:41:40Z",
      "closed_at": "2025-05-15T08:41:40Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2694/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2694",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2694",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:01.396164",
      "comments": []
    },
    {
      "issue_number": 2658,
      "title": "[Bug] [Module Name] 上传pdf文件 切片知识库报错document embedding, failed",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\ndevice:cpu\n\n### Models information\n\ndeepseek-r1\n\n### What happened\n\n![Image](https://github.com/user-attachments/assets/857c0e8d-49fe-4625-abb0-f841b3deab18)\n上传知识库，选择pdf文件，切片时候报错地方：\n\n![Image](https://github.com/user-attachments/assets/d6d7b33d-5141-46fd-ac69-c1033f4ca097)\n\n### What you expected to happen\n\n上传成功切片成功\n\n### How to reproduce\n\n上传知识库，选择pdf文件，切片时候报错地方：\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "lishidetainan",
      "author_type": "User",
      "created_at": "2025-04-27T03:12:05Z",
      "updated_at": "2025-05-15T07:31:30Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2658/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2658",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2658",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:01.396188",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "hi, can you show your error log?",
          "created_at": "2025-05-14T14:41:28Z"
        },
        {
          "author": "lishidetainan",
          "body": "> hi, can you show your error log?\n\n![Image](https://github.com/user-attachments/assets/aafee3a9-76db-4f94-8579-a48c46f171d5)",
          "created_at": "2025-05-15T07:30:26Z"
        },
        {
          "author": "lishidetainan",
          "body": "使用的是milvus 向量库存储的向量",
          "created_at": "2025-05-15T07:31:30Z"
        }
      ]
    },
    {
      "issue_number": 2691,
      "title": "[Bug] [web] Build error occurred 前端构建失败",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\ngpu:L40\n\n### Models information\n\ndeepseek-r1-1.5b\n\n### What happened\n\n拉取源码后使用package.json中的配置构建web前端，构建失败：\n```\ninfo  - Need to disable some ESLint rules? Learn more here: https://nextjs.org/docs/basic-features/eslint#disabling-rules\n- info Linting\n- info Collecting page data ..Error [ERR_REQUIRE_ESM]: require() of ES Module G:\\DB-GPT_7\\web\\node_modules\\@antv\\g2-extension-plot\\node_modules\\d3-hierarchy\\src\\index.js from G:\\DB-GPT_7\\web\\node_modules\\@antv\\g2-extension-plot\\lib\\utils\\hierarchy\\partition.js not supported.\nInstead change the require of index.js in G:\\DB-GPT_7\\web\\node_modules\\@antv\\g2-extension-plot\\lib\\utils\\hierarchy\\partition.js to a dynamic import() which is available in all CommonJS modules.\n    at Object.<anonymous> (G:\\DB-GPT_7\\web\\node_modules\\@antv\\g2-extension-plot\\lib\\utils\\hierarchy\\partition.js:27:34) {\n  code: 'ERR_REQUIRE_ESM'\n}\n\n> Build error occurred\nError: Failed to collect page data for /construct/knowledge/chunk\n    at G:\\DB-GPT_7\\web\\node_modules\\next\\dist\\build\\utils.js:1161:15\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5) {\n  type: 'Error'\n}\n```\n\n### What you expected to happen\n\n构建成功\n\n### How to reproduce\n\n拉取git，打开./web，运行 NODE_OPTIONS=--max_old_space_size=8192 next build\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "EdwinOlders11",
      "author_type": "User",
      "created_at": "2025-05-14T01:39:36Z",
      "updated_at": "2025-05-14T12:15:01Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2691/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2691",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2691",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:01.567827",
      "comments": [
        {
          "author": "chenliang15405",
          "body": "Do you want to build web project?  maybe web/README file can help you",
          "created_at": "2025-05-14T12:14:59Z"
        }
      ]
    },
    {
      "issue_number": 2692,
      "title": "[Bug] [Chat data] ERROR Test connection Failure!(oracledb.exceptions.DatabaseError) DPY-4027: no configuration directory specified",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [x] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nqwen2.5-14b\n\n### What happened\n\n2025-05-14 15:52:19 EPAY-T-MODEL-1 dbgpt_serve.datasource.manages.connector_manager[2626483] ERROR Test connection Failure!(oracledb.exceptions.DatabaseError) DPY-4027: no configuration directory specified\n(Background on this error at: https://sqlalche.me/e/20/4xp6)\n2025-05-14 15:52:19 EPAY-T-MODEL-1 dbgpt_serve.core.schemas[2626483] ERROR common_exception_handler catch Exception: success=False err_code='E0003' err_msg='Test connection Failure!(oracledb.exceptions.DatabaseError) DPY-4027: no configuration directory specified\\n(Background on this error at: https://sqlalche.me/e/20/4xp6)' data=None\nINFO:     10.1.51.130:50835 - \"POST /api/v2/serve/datasources/test-connection HTTP/1.1\" 400 Bad Request\nERROR:    Exception in ASGI application\n  + Exception Group Traceback (most recent call last):\n  |   File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/starlette/_utils.py\", line 77, in collapse_excgroups\n  |     yield\n  |   File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/starlette/middleware/base.py\", line 186, in __call__\n  |     async with anyio.create_task_group() as task_group:\n  |   File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 772, in __aexit__\n  |     raise BaseExceptionGroup(\n  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 409, in run_asgi\n    |     result = await app(  # type: ignore[func-returns-value]\n    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n    |     return await self.app(scope, receive, send)\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    |     await self.simple_response(scope, receive, send, request_headers=headers)\n    |   File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    |     await self.app(scope, receive, send)\n    |   File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/fastapi/applications.py\", line 1054, in __call__\n    |     await super().__call__(scope, receive, send)\n    |   File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/starlette/applications.py\", line 113, in __call__\n    |     await self.middleware_stack(scope, receive, send)\n    |   File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/starlette/middleware/errors.py\", line 187, in __call__\n    |     raise exc\n    |   File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    |     await self.app(scope, receive, _send)\n    |   File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/starlette/middleware/base.py\", line 185, in __call__\n    |     with collapse_excgroups():\n    |   File \"/usr/lib64/python3.11/contextlib.py\", line 158, in __exit__\n    |     self.gen.throw(typ, value, traceback)\n    |   File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/starlette/_utils.py\", line 83, in collapse_excgroups\n    |     raise exc\n    |   File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/starlette/middleware/base.py\", line 187, in __call__\n    |     response = await self.dispatch_func(request, call_next)\n    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/data/DB-GPT-0.7.1/packages/dbgpt-core/src/dbgpt/util/tracer/tracer_middleware.py\", line 49, in dispatch\n    |     response = await call_next(request)\n    |                ^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/starlette/middleware/base.py\", line 163, in call_next\n    |     raise app_exc\n    |   File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/starlette/middleware/base.py\", line 149, in coro\n    |     await self.app(scope, receive_or_disconnect, send_no_error)\n    |   File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n    |   File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n    |     raise exc\n    |   File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/starlette/routing.py\", line 715, in __call__\n    |     await self.middleware_stack(scope, receive, send)\n    |   File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/starlette/routing.py\", line 735, in app\n    |     await route.handle(scope, receive, send)\n    |   File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/starlette/routing.py\", line 288, in handle\n    |     await self.app(scope, receive, send)\n    |   File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/starlette/routing.py\", line 76, in app\n    |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n    |   File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n    |     raise exc\n    |   File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/starlette/routing.py\", line 73, in app\n    |     response = await f(request)\n    |                ^^^^^^^^^^^^^^^^\n    |   File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/fastapi/routing.py\", line 301, in app\n    |     raw_response = await run_endpoint_function(\n    |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    |     return await dependant.call(**values)\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/data/DB-GPT-0.7.1/packages/dbgpt-serve/src/dbgpt_serve/datasource/api/endpoints.py\", line 239, in test_connection\n    |     res = await blocking_func_to_async(\n    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/data/DB-GPT-0.7.1/packages/dbgpt-serve/src/dbgpt_serve/core/__init__.py\", line 32, in blocking_func_to_async\n    |     return await _blocking_func_to_async(executor, func, *args, **kwargs)\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/data/DB-GPT-0.7.1/packages/dbgpt-core/src/dbgpt/util/executor_utils.py\", line 70, in blocking_func_to_async\n    |     return await loop.run_in_executor(executor, run_with_context)\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/usr/lib64/python3.11/concurrent/futures/thread.py\", line 58, in run\n    |     result = self.fn(*self.args, **self.kwargs)\n    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/data/DB-GPT-0.7.1/packages/dbgpt-core/src/dbgpt/util/executor_utils.py\", line 67, in run_with_context\n    |     return ctx.run(partial(func, *args, **kwargs))\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/data/DB-GPT-0.7.1/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/service.py\", line 288, in test_connection\n    |     return self.datasource_manager.test_connection(request)\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/data/DB-GPT-0.7.1/packages/dbgpt-serve/src/dbgpt_serve/datasource/manages/connector_manager.py\", line 290, in test_connection\n    |     raise ValueError(f\"Test connection Failure!{str(e)}\")\n    | ValueError: Test connection Failure!(oracledb.exceptions.DatabaseError) DPY-4027: no configuration directory specified\n    | (Background on this error at: https://sqlalche.me/e/20/4xp6)\n    +------------------------------------\n\n### What you expected to happen\n\n正常配置oracle连接\n\n### How to reproduce\n\n我们oracle数据库里表太多，有2千张表， 新建了一个用户，只能创建视图，通过这种方式缩小表数量。\n但是新建的这个用户创建oracle连接一直报错。\n\n通过test_conn_oracle.py测试， 是可以连接到oracle的。\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "maco6096",
      "author_type": "User",
      "created_at": "2025-05-14T08:07:57Z",
      "updated_at": "2025-05-14T08:07:57Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2692/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2692",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2692",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:01.795910",
      "comments": []
    },
    {
      "issue_number": 2300,
      "title": "instanll summarizer-agent-exampleError, package conflict, depends on 0.6.0. After installing this example, 0.6.3 will be uninstalled, causing dbgpt_server.py to keep refreshing the screen and reporting errors. After uninstalling the example, it returns to normal.",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nqwen2.5\n\n### What happened\n\ninstanll summarizer-agent-example报错，包冲突，依赖的是0.6.0，安装该例子后会卸载0.6.3导致dbgpt_server.py不停刷屏报错，卸载例子后恢复正常\r\ndbpgt install uninstall、pip install -e \".[default]\"相关日志：\r\n\r\nRequirement already satisfied: types-python-dateutil>=2.8.10 in /opt/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=2.13.0->libro-server>=0.1.10->libro>=0.1.25->dbgpt==0.6.3) (2.9.0.20241206)\r\nInstalling collected packages: dbgpt\r\n  Attempting uninstall: dbgpt\r\n    Found existing installation: dbgpt 0.6.3\r\n    Uninstalling dbgpt-0.6.3:\r\n      Successfully uninstalled dbgpt-0.6.3\r\n  DEPRECATION: Legacy editable install of dbgpt[default]==0.6.3 from file:///opt/DB-GPT/DB-GPT (setup.py develop) is deprecated. pip 25.0 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\r\n  Running setup.py develop for dbgpt\r\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\nsummarizer-agent-example 0.1.2 requires dbgpt[agent]<0.6.0,>=0.5.6rc1, but you have dbgpt 0.6.3 which is incompatible.\r\nSuccessfully installed dbgpt\r\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\r\n\r\n\r\n\r\ndbgpt app list日志\r\n2025-01-13 14:02:35 | root | WARNING | Integrating dbgpt webserver command line tool failed: No module named 'dbgpt.app'\r\n2025-01-13 14:02:35 | root | WARNING | Integrating dbgpt knowledge command line tool failed: No module named 'dbgpt.app'\r\n2025-01-13 14:02:35 | root | WARNING | Integrating dbgpt serve command line tool failed: No module named 'dbgpt.serve'\r\n\r\nInstalling collected packages: dbgpt, summarizer-agent-example\r\n  Attempting uninstall: dbgpt\r\n    Found existing installation: dbgpt 0.6.3\r\n    Uninstalling dbgpt-0.6.3:\r\n      Successfully uninstalled dbgpt-0.6.3\r\nSuccessfully installed dbgpt-0.5.10 summarizer-agent-example-0.1.2\r\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. \r\n\r\ndbgpt_server.py日志\r\n--- Logging error ---\r\nTraceback (most recent call last):\r\n  File \"/opt/DB-GPT/DB-GPT/dbgpt/util/dbgpts/loader.py\", line 449, in load_package\r\n    self._register_packages(package)\r\n  File \"/opt/DB-GPT/DB-GPT/dbgpt/util/dbgpts/loader.py\", line 488, in _register_packages\r\n    agent_manager.register_agent(agent_cls, ignore_duplicate=True)\r\n  File \"/opt/DB-GPT/DB-GPT/dbgpt/agent/core/agent_manage.py\", line 91, in register_agent\r\n    inst = cls()\r\n  File \"/opt/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/summarizer_agent_example/__init__.py\", line 64, in __init__\r\n    self._init_actions([SummaryAction])\r\n  File \"/opt/DB-GPT/DB-GPT/dbgpt/agent/core/base_agent.py\", line 696, in _init_actions\r\n    self.actions.append(action(language=self.language))\r\nTypeError: SummaryAction.__init__() got an unexpected keyword argument 'language'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/opt/miniconda3/envs/dbgpt_env/lib/python3.10/logging/__init__.py\", line 1100, in emit\r\n    msg = self.format(record)\r\n  File \"/opt/miniconda3/envs/dbgpt_env/lib/python3.10/logging/__init__.py\", line 943, in format\r\n    return fmt.format(record)\r\n  File \"/opt/miniconda3/envs/dbgpt_env/lib/python3.10/logging/__init__.py\", line 678, in format\r\n    record.message = record.getMessage()\r\n  File \"/opt/miniconda3/envs/dbgpt_env/lib/python3.10/logging/__init__.py\", line 368, in getMessage\r\n    msg = msg % self.args\r\nTypeError: not all arguments converted during string formatting\r\nCall stack:\r\n  File \"/opt/miniconda3/envs/dbgpt_env/lib/python3.10/threading.py\", line 973, in _bootstrap\r\n    self._bootstrap_inner()\r\n  File \"/opt/miniconda3/envs/dbgpt_env/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\r\n    self.run()\r\n  File \"/opt/miniconda3/envs/dbgpt_env/lib/python3.10/threading.py\", line 953, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/opt/DB-GPT/DB-GPT/dbgpt/app/initialization/scheduler.py\", line 46, in _scheduler\r\n    schedule.run_pending()\r\n  File \"/opt/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/schedule/__init__.py\", line 854, in run_pending\r\n    default_scheduler.run_pending()\r\n  File \"/opt/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/schedule/__init__.py\", line 101, in run_pending\r\n    self._run_job(job)\r\n  File \"/opt/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/schedule/__init__.py\", line 173, in _run_job\r\n    ret = job.run()\r\n  File \"/opt/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/schedule/__init__.py\", line 691, in run\r\n    ret = self.job_func()\r\n  File \"/opt/DB-GPT/DB-GPT/dbgpt/util/dbgpts/loader.py\", line 451, in load_package\r\n    logger.warning(f\"Load dbgpts package error: {e}\", e)\r\nMessage: \"Load dbgpts package error: SummaryAction.__init__() got an unexpected keyword argument 'language'\"\r\nArguments: (TypeError(\"SummaryAction.__init__() got an unexpected keyword argument 'language'\"),)\r\n--- Logging error ---\r\nTraceback (most recent call last):\r\n  File \"/opt/DB-GPT/DB-GPT/dbgpt/util/dbgpts/loader.py\", line 449, in load_package\r\n    self._register_packages(package)\r\n  File \"/opt/DB-GPT/DB-GPT/dbgpt/util/dbgpts/loader.py\", line 488, in _register_packages\r\n    agent_manager.register_agent(agent_cls, ignore_duplicate=True)\r\n  File \"/opt/DB-GPT/DB-GPT/dbgpt/agent/core/agent_manage.py\", line 91, in register_agent\r\n    inst = cls()\r\n  File \"/opt/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/summarizer_agent_example/__init__.py\", line 64, in __init__\r\n    self._init_actions([SummaryAction])\r\n  File \"/opt/DB-GPT/DB-GPT/dbgpt/agent/core/base_agent.py\", line 696, in _init_actions\r\n    self.actions.append(action(language=self.language))\r\nTypeError: SummaryAction.__init__() got an unexpected keyword argument 'language'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/opt/miniconda3/envs/dbgpt_env/lib/python3.10/logging/__init__.py\", line 1100, in emit\r\n    msg = self.format(record)\r\n  File \"/opt/miniconda3/envs/dbgpt_env/lib/python3.10/logging/__init__.py\", line 943, in format\r\n    return fmt.format(record)\r\n  File \"/opt/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/coloredlogs/__init__.py\", line 1140, in format\r\n    return logging.Formatter.format(self, record)\r\n  File \"/opt/miniconda3/envs/dbgpt_env/lib/python3.10/logging/__init__.py\", line 678, in format\r\n    record.message = record.getMessage()\r\n  File \"/opt/miniconda3/envs/dbgpt_env/lib/python3.10/logging/__init__.py\", line 368, in getMessage\r\n    msg = msg % self.args\r\nTypeError: not all arguments converted during string formatting\r\nCall stack:\r\n  File \"/opt/miniconda3/envs/dbgpt_env/lib/python3.10/threading.py\", line 973, in _bootstrap\r\n    self._bootstrap_inner()\r\n  File \"/opt/miniconda3/envs/dbgpt_env/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\r\n    self.run()\r\n  File \"/opt/miniconda3/envs/dbgpt_env/lib/python3.10/threading.py\", line 953, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/opt/DB-GPT/DB-GPT/dbgpt/app/initialization/scheduler.py\", line 46, in _scheduler\r\n    schedule.run_pending()\r\n  File \"/opt/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/schedule/__init__.py\", line 854, in run_pending\r\n    default_scheduler.run_pending()\r\n  File \"/opt/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/schedule/__init__.py\", line 101, in run_pending\r\n    self._run_job(job)\r\n  File \"/opt/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/schedule/__init__.py\", line 173, in _run_job\r\n    ret = job.run()\r\n  File \"/opt/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/schedule/__init__.py\", line 691, in run\r\n    ret = self.job_func()\r\n  File \"/opt/DB-GPT/DB-GPT/dbgpt/util/dbgpts/loader.py\", line 451, in load_package\r\n    logger.warning(f\"Load dbgpts package error: {e}\", e)\r\nMessage: \"Load dbgpts package error: SummaryAction.__init__() got an unexpected keyword argument 'language'\"\r\nArguments: (TypeError(\"SummaryAction.__init__() got an unexpected keyword argument 'language'\"),)\r\n\r\n\r\n\n\n### What you expected to happen\n\n帮忙修复此问题，是不是summarizer-agent-example调整依赖为dbgpt0.6.3即可？\n\n### How to reproduce\n\ndbgpt app install summarizer-agent-example\n\n### Additional context\n\n帮忙修复此问题，是不是summarizer-agent-example调整依赖为dbgpt0.6.3即可？\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "qzjqzjqzj",
      "author_type": "User",
      "created_at": "2025-01-13T06:32:19Z",
      "updated_at": "2025-05-13T21:05:22Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2300/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2300",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2300",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:01.795936",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-05-13T21:05:21Z"
        }
      ]
    },
    {
      "issue_number": 2301,
      "title": "[Bug] No module named 'clickhouse_connect'",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [X] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [X] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nPRETTY_NAME=\"Ubuntu 24.04.1 LTS\"\r\nNVIDIA A100 80GB PCIe\n\n### Models information\n\nLLM_MODEL=vicuna-13b-v1.5\n\n### What happened\n\nI added the ClickHouse database source and this error occurred when I clicked save.\r\n```\r\n2025-01-13 14:14:49 668e9edb038d dbgpt.datasource.manages.connect_config_db[1] INFO Result: <sqlalchemy.engine.cursor.CursorResult object at 0x75b2c35b1000>\r\n2025-01-13 14:14:49 668e9edb038d dbgpt.rag.summary.db_summary_client[1] WARNING default , clickhouse summary error!No module named 'clickhouse_connect', detail: Traceback (most recent calllast):\r\n  File \"/app/dbgpt/rag/summary/db_summary_client.py\", line 82, in init_db_summary\r\n    self.db_summary_embedding(item[\"db_name\"], item[\"db_type\"])\r\n  File \"/app/dbgpt/rag/summary/db_summary_client.py\", line 46, in db_summary_embedding\r\n    db_summary_client = self.create_summary_client(dbname, db_type)\r\n  File \"/app/dbgpt/rag/summary/db_summary_client.py\", line 163, in create_summary_client\r\n    return RdbmsSummary(dbname, db_type)\r\n  File \"/app/dbgpt/rag/summary/rdbms_db_summary.py\", line 38, in __init__\r\n    self.db = db_manager.get_connector(name)\r\n  File \"/app/dbgpt/datasource/manages/connector_manager.py\", line 130, in get_connector\r\n    return connect_instance.from_uri_db(  # type: ignore\r\n  File \"/app/dbgpt/datasource/rdbms/conn_clickhouse.py\", line 57, in from_uri_db\r\n    import clickhouse_connect\r\nModuleNotFoundError: No module named 'clickhouse_connect'\r\n```\n\n### What you expected to happen\n\nI can solve the problem temporarily by executing the following command:\r\n```\r\ndocker exec -it db-gpt-webserver-1 bash\r\npip install clickhouse_connect\r\n```\r\n\r\nBut when I need to docker compose down, docker compose up -d restart, this error will appear again.\r\n\r\nI understand that the clickhouse_connect package should be built into the container\n\n### How to reproduce\n\n```\r\ngit clone https://github.com/eosphoros-ai/DB-GPT.git && cd DB-GPT\r\ndocker compose up -d\r\nOpen the UI, add the clickhouse data source, and click save\r\n```\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "shaxiaozz",
      "author_type": "User",
      "created_at": "2025-01-13T14:20:38Z",
      "updated_at": "2025-05-13T21:05:20Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2301/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2301",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2301",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:01.985883",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "sorry about that, `clickhouse_connect` is not in dbgpt default datasource.  so we have not put `ck` in container, we recommend you to deploy in source code.",
          "created_at": "2025-01-13T15:25:20Z"
        },
        {
          "author": "shaxiaozz",
          "body": "@Aries-ckt The same is true for Python virtual environment installation. It is recommended to add clickhouse_connect to the dependencies",
          "created_at": "2025-01-13T15:27:01Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-05-13T21:05:19Z"
        }
      ]
    },
    {
      "issue_number": 2685,
      "title": "[Bug] [ChatKnowledge] 知识库上传文件被删除切片时该文件仍然存在",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nOS: windows 11\nCPU: Intel(R) Core(TM) i5-1035G1 CPU @ 1.00GHz 1.19 GHz\n\n### Models information\n\nLLM: deepseek:32b\nembedding: bge-m3\n\n### What happened\n\n知识库新增数据源，上传多个文档，删除某个文档后点击下一步分片，被删除的文档仍然存在。\n\n### What you expected to happen\n\n被删除的文档不进行分片\n\n### How to reproduce\n\n1. 进入知识库点击新增数据源\n2. 选择类型为文档，上传多个文档\n3. 删除某个文档后点击下一步\n4. 分片步骤可以看到被删除的文档仍然存在\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "cumbersun",
      "author_type": "User",
      "created_at": "2025-05-13T03:37:16Z",
      "updated_at": "2025-05-13T03:37:16Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2685/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2685",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2685",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:02.186372",
      "comments": []
    },
    {
      "issue_number": 2683,
      "title": "[Bug] [Chat data] oracle Error in ORA-00923: FROM keyword not found where expected",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [x] Chat Data\n- [ ] Chat Excel\n- [x] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU \n\n### Models information\n\nqwen2.5-8b\nnormic\n\n### What happened\n\n2025-05-12 16:30:03 EPAY-T-MODEL-1 dbgpt_serve.datasource.manages.connector_manager[2623804] INFO -------------Oracle Datasource------------\n2025-05-12 16:30:40 EPAY-T-MODEL-1 dbgpt.component[2623804] INFO Dialect: oracle\nINFO:     10.1.51.130:52205 - \"POST /api/v1/chat/completions HTTP/1.1\" 200 OK\n2025-05-12 16:30:40 EPAY-T-MODEL-1 dbgpt_ext.storage.vector_store.chroma_store[2623804] INFO ChromaStore similar search with scores\n2025-05-12 16:30:40 EPAY-T-MODEL-1 dbgpt.model.cluster.worker.embedding_worker[2623804] INFO Receive embeddings request, model: bge-m3:latest\n2025-05-12 16:30:44 EPAY-T-MODEL-1 dbgpt.component[2623804] ERROR Retrieved table info error: no such column: embedding_metadata.bool_value\n2025-05-12 16:30:44 EPAY-T-MODEL-1 dbgpt.datasource.rdbms.base[2623804] ERROR Error in session scope: (oracledb.exceptions.DatabaseError) ORA-00923: FROM keyword not found where expected\nHelp: https://docs.oracle.com/error-help/db/ora-00923/\n[SQL: SELECT DATABASE()]\n(Background on this error at: https://sqlalche.me/e/20/4xp6)\n2025-05-12 16:30:44 EPAY-T-MODEL-1 dbgpt_app.openapi.api_v1.api_v1[2623804] ERROR stream_generator error\nTraceback (most recent call last):\n  File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/sqlalchemy/engine/base.py\", line 1970, in _exec_single_context\n    self.dialect.do_execute(\n  File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/sqlalchemy/engine/default.py\", line 924, in do_execute\n    cursor.execute(statement, parameters)\n  File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/oracledb/cursor.py\", line 708, in execute\n    impl.execute(self)\n  File \"src/oracledb/impl/thin/cursor.pyx\", line 277, in oracledb.thin_impl.ThinCursorImpl.execute\n  File \"src/oracledb/impl/thin/protocol.pyx\", line 450, in oracledb.thin_impl.Protocol._process_single_message\n  File \"src/oracledb/impl/thin/protocol.pyx\", line 451, in oracledb.thin_impl.Protocol._process_single_message\n  File \"src/oracledb/impl/thin/protocol.pyx\", line 443, in oracledb.thin_impl.Protocol._process_message\n  File \"src/oracledb/impl/thin/messages/base.pyx\", line 105, in oracledb.thin_impl.Message._check_and_raise_exception\noracledb.exceptions.DatabaseError: ORA-00923: FROM keyword not found where expected\nHelp: https://docs.oracle.com/error-help/db/ora-00923/\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-app/src/dbgpt_app/openapi/api_v1/api_v1.py\", line 738, in stream_generator\n    async for chunk in chat.stream_call(\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-app/src/dbgpt_app/scene/base_chat.py\", line 377, in stream_call\n    payload = await self._build_model_request()\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-app/src/dbgpt_app/scene/base_chat.py\", line 316, in _build_model_request\n    input_values = await self.generate_input_values()\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-core/src/dbgpt/util/tracer/tracer_impl.py\", line 255, in async_wrapper\n    return await func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-app/src/dbgpt_app/scene/chat_db/professional_qa/chat.py\", line 72, in generate_input_values\n    table_infos = await blocking_func_to_async(\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib64/python3.11/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-core/src/dbgpt/util/executor_utils.py\", line 67, in run_with_context\n    return ctx.run(partial(func, *args, **kwargs))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-core/src/dbgpt/datasource/rdbms/base.py\", line 310, in table_simple_info\n    table_schema=\"{self.get_current_db_name()}\" group by TABLE_NAME;\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/DB-GPT-0.7.1/packages/dbgpt-core/src/dbgpt/datasource/rdbms/base.py\", line 302, in get_current_db_name\n    cursor = session.execute(text(\"SELECT DATABASE()\"))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/sqlalchemy/orm/session.py\", line 2306, in execute\n    return self._execute_internal(\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/sqlalchemy/orm/session.py\", line 2200, in _execute_internal\n    result = conn.execute(\n             ^^^^^^^^^^^^^\n  File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/sqlalchemy/engine/base.py\", line 1421, in execute\n    return meth(\n           ^^^^^\n  File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/sqlalchemy/sql/elements.py\", line 514, in _execute_on_connection\n    return connection._execute_clauseelement(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/sqlalchemy/engine/base.py\", line 1643, in _execute_clauseelement\n    ret = self._execute_context(\n          ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/sqlalchemy/engine/base.py\", line 1849, in _execute_context\n    return self._exec_single_context(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/sqlalchemy/engine/base.py\", line 1989, in _exec_single_context\n    self._handle_dbapi_exception(\n  File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/sqlalchemy/engine/base.py\", line 2356, in _handle_dbapi_exception\n    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e\n  File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/sqlalchemy/engine/base.py\", line 1970, in _exec_single_context\n    self.dialect.do_execute(\n  File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/sqlalchemy/engine/default.py\", line 924, in do_execute\n    cursor.execute(statement, parameters)\n  File \"/data/DB-GPT-0.7.1/.venv/lib64/python3.11/site-packages/oracledb/cursor.py\", line 708, in execute\n    impl.execute(self)\n  File \"src/oracledb/impl/thin/cursor.pyx\", line 277, in oracledb.thin_impl.ThinCursorImpl.execute\n  File \"src/oracledb/impl/thin/protocol.pyx\", line 450, in oracledb.thin_impl.Protocol._process_single_message\n  File \"src/oracledb/impl/thin/protocol.pyx\", line 451, in oracledb.thin_impl.Protocol._process_single_message\n  File \"src/oracledb/impl/thin/protocol.pyx\", line 443, in oracledb.thin_impl.Protocol._process_message\n  File \"src/oracledb/impl/thin/messages/base.pyx\", line 105, in oracledb.thin_impl.Message._check_and_raise_exception\nsqlalchemy.exc.DatabaseError: (oracledb.exceptions.DatabaseError) ORA-00923: FROM keyword not found where expected\nHelp: https://docs.oracle.com/error-help/db/ora-00923/\n[SQL: SELECT DATABASE()]\n(Background on this error at: https://sqlalche.me/e/20/4xp6)\n\n### What you expected to happen\n\n能正产使用\n\n### How to reproduce\n\n1. 配置oracle数据库， 我们是两台oracle rac\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "maco6096",
      "author_type": "User",
      "created_at": "2025-05-13T01:27:03Z",
      "updated_at": "2025-05-13T01:27:03Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2683/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2683",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2683",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:02.186395",
      "comments": []
    },
    {
      "issue_number": 2293,
      "title": "[Bug][Chat Dashboard]Qwen Dashboard analysis error.",
      "body": "### Search before asking\r\n\r\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\r\n\r\n\r\n### Operating system information\r\n\r\nLinux\r\n\r\n### Python version information\r\n\r\n>=3.11\r\n\r\n### DB-GPT version\r\n\r\nmain\r\n\r\n### Related scenes\r\n\r\n- [ ] Chat Data\r\n- [ ] Chat Excel\r\n- [ ] Chat DB\r\n- [ ] Chat Knowledge\r\n- [ ] Model Management\r\n- [X] Dashboard\r\n- [ ] Plugins\r\n\r\n### Installation Information\r\n\r\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\r\n\r\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\r\n\r\n- [ ] AutoDL Image\r\n- [ ] Other\r\n\r\n### Device information\r\n\r\n代理的大模型\r\n\r\n### Models information\r\n\r\n通义大模型代理\r\n\r\n### What happened\r\n\r\n报表分析代理通义千问，其他功能正常，报表分析报错\r\n\r\n### What you expected to happen\r\n\r\n报表分析代理通义千问，其他功能正常，报表分析报错\r\n\r\n### How to reproduce\r\n\r\nINFO editor_chart_run:{'db_name': 'case_1_student_manager', 'sql': 'SELECT\\n  c.course_name\\nFROM\\n  courses c\\nGROUP BY\\n  c.course_id\\nORDER BY\\n  c.course_name;', 'chart_type': '使用柱状图（BarChart）来展示每个维度的数据，这样可以直观地比较不同课程之间的差异。'}\r\n2025-01-10 10:02:42 LAPTOP-9AI05STR dbgpt.datasource.manages.connect_config_db[1772] INFO Result: <sqlalchemy.engine.cursor.CursorResult object at 0x7ff6f02dfac0>\r\n2025-01-10 10:02:42 LAPTOP-9AI05STR dbgpt.app.openapi.api_v1.editor.api_editor_v1[1772] ERROR Chart sql run failed!\r\n\r\n\r\n报表分析代理通义千问，其他功能正常，报表分析报错，INFO editor_chart_run:{'db_name': 'case_1_student_manager', 'sql': 'SELECT\\n c.course_name\\nFROM\\n courses c\\nGROUP BY\\n c.course_id\\nORDER BY\\n c.course_name;', 'chart_type': '使用柱状图（BarChart）来展示每个维度的数据，这样可以直观地比较不同课程之间的差异。'} 2025-01-10 10:02:42 LAPTOP-9AI05STR dbgpt.datasource.manages.connect_config_db[1772] INFO Result: <sqlalchemy.engine.cursor.CursorResult object at 0x7ff6f02dfac0> 2025-01-10 10:02:42 LAPTOP-9AI05STR dbgpt.app.openapi.api_v1.editor.api_editor_v1[1772] ERROR Chart sql run failed! 报表分析代理通义千问，其他功能正常，报表分析报错，INFO editor_chart_run:{'db_name': 'case_1_student_manager', 'sql': 'SELECT\\n c.course_name\\nFROM\\n courses c\\nGROUP BY\\n c.course_id\\nORDER BY\\n c.course_name;', 'chart_type': '使用柱状图（BarChart）来展示每个维度的数据，这样可以直观地比较不同课程之间的差异。'} 2025-01-10 10:02:42 LAPTOP-9AI05STR dbgpt.datasource.manages.connect_config_db[1772] INFO Result: <sqlalchemy.engine.cursor.CursorResult object at 0x7ff6f02dfac0> 2025-01-10 10:02:42 LAPTOP-9AI05STR dbgpt.app.openapi.api_v1.editor.api_editor_v1[1772] ERROR Chart sql run failed!Traceback (most recent call last): File \"/mnt/d/DB-GPT/dbgpt/app/openapi/api_v1/editor/api_editor_v1.py\", line 286, in editor_chart_run colunms, sql_result = db_conn.query_ex(sql, timeout=30) TypeError: RDBMSConnector.query_ex() got an unexpected keyword argument 'timeout' [3 days ago](https://github.com/eosphoros-ai/DB-GPT/issues/2293#event-15875817151)\r\n### Additional context\r\n\r\n_No response_\r\n\r\n### Are you willing to submit PR?\r\n\r\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "zhaopengfeigithup",
      "author_type": "User",
      "created_at": "2025-01-10T02:23:42Z",
      "updated_at": "2025-05-12T21:05:21Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2293/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2293",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2293",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:02.186403",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-05-12T21:05:20Z"
        }
      ]
    },
    {
      "issue_number": 2294,
      "title": "[Feature][rag]Does dbgpt can integrate kag's plan",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n使用kag生成知识图谱是不是更精准一些，生成的图谱能不能增加手动编辑的功能\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "maco6096",
      "author_type": "User",
      "created_at": "2025-01-10T02:35:36Z",
      "updated_at": "2025-05-12T21:05:20Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2294/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2294",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2294",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:02.408647",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "hi, thanks for your suggestion, KAG is a very good kg framework, we will take consider into it very seriously.",
          "created_at": "2025-01-10T02:43:44Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-05-12T21:05:19Z"
        }
      ]
    },
    {
      "issue_number": 2680,
      "title": "TypeError: Can't instantiate abstract class PGVectorStore with abstract method similar_search_with_scores",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [x] Chat Data\n- [ ] Chat Excel\n- [x] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nJust use cpu, proxy deepseek model, when i add mysql datasource, it's success; Bug when i add pg datasource, get error,\n\n### Models information\n\nproxy deepseek model, config like this:\n[system]\n# Load language from environment variable(It is set by the hook)\nlanguage = \"${env:DBGPT_LANG:-zh}\"\napi_keys = []\nencrypt_key = \"your_secret_key\"\n\n# Server Configurations\n[service.web]\nhost = \"0.0.0.0\"\nport = 5670\n[service.web.auth]\nenabled = true\nsecret_key = \"your_jwt_secret\"\ntoken_expire_minutes = 1440  # 令牌有效期（分钟）\n\n[service.web.database]\ntype = \"mysql\"\nhost = \"127.0.0.1\"\nport = 3306\nuser = \"root\"\npassword = \"****\"\ndatabase = \"dbgpt\"\n# 驱动配置（默认使用mysql-connector-python）\ndriver = \"mysql+mysqlconnector\"\n[service.web.database.pool]\npool_size = 10          # 最大连接数\nmax_overflow = 5        # 临时超额连接数\npool_recycle = 3600     # 连接回收时间（秒）\n\n[service.model.worker]\nhost = \"127.0.0.1\"\n\n[rag.storage]\n[rag.storage.vector]\ntype = \"pgvector\"\nconnection_string = \"postgresql://root:****@localhost:5432/vector_db?sslmode=disable\"\nuser = \"root\"\npassword = \"****\"\n#[rag.storage.vector]\n#type = \"chroma\"\n#persist_path = \"pilot/data\"\n\n# Model Configurations\n[models]\n[[models.llms]]\nname = \"deepseek-chat\"\n# name = \"deepseek-chat\"\nprovider = \"proxy/deepseek\"\napi_key = \"sk-*******\"\n\n[[models.embeddings]]\nname = \"BAAI/bge-large-zh-v1.5\"\nprovider = \"hf\"\n\n### What happened\n\n when i add mysql datasource, it's success; Bug when i add pg datasource, get error,\n\n2025-05-11 18:49:51 LAPTOP-12  dbgpt_serve.datasource.service.db_summary_client[23904] WARNING vector_db, postgresql summary error!Can't instantiate abstract class PGVectorStore with abstract method similar_search_with_scores, detail: Traceback (most recent call last):\n  File \"C:\\Users\\lenovo\\PycharmProjects\\DB-GPT\\packages\\dbgpt-serve\\src\\dbgpt_serve\\datasource\\service\\db_summary_client.py\", line 53, in db_summary_embedding\n    self.init_db_profile(db_summary_client, dbname)\n  File \"C:\\Users\\lenovo\\PycharmProjects\\DB-GPT\\packages\\dbgpt-serve\\src\\dbgpt_serve\\datasource\\service\\db_summary_client.py\", line 106, in init_db_profile\n    self._get_vector_connector_by_db(dbname)\n  File \"C:\\Users\\lenovo\\PycharmProjects\\DB-GPT\\packages\\dbgpt-serve\\src\\dbgpt_serve\\datasource\\service\\db_summary_client.py\", line 164, in _get_vector_connector_by_db\n    table_vector_store = storage_manager.create_vector_store(\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\lenovo\\PycharmProjects\\DB-GPT\\packages\\dbgpt-serve\\src\\dbgpt_serve\\rag\\storage_manager.py\", line 70, in create_vector_store\n    return vector_store_config.create_store(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\lenovo\\PycharmProjects\\DB-GPT\\packages\\dbgpt-ext\\src\\dbgpt_ext\\storage\\vector_store\\pgvector_store.py\", line 57, in create_store\n    return PGVectorStore(vector_store_config=self, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: Can't instantiate abstract class PGVectorStore with abstract method similar_search_with_scores\n\n### What you expected to happen\n\nwhen i use chat-data,i can add mysql datasource, when i add pg datasource, i get error\n\n### How to reproduce\n\nwhen you add pg datasource\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "zparkgao",
      "author_type": "User",
      "created_at": "2025-05-11T10:59:55Z",
      "updated_at": "2025-05-11T10:59:55Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2680/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2680",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2680",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:02.644482",
      "comments": []
    },
    {
      "issue_number": 2292,
      "title": "[Bug] [dbgpt_server] dbgpt_server.py: error: the following arguments are required: --model_path",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [X] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU\r\ncount 1\r\n10G\n\n### Models information\n\nQWen 2.5\n\n### What happened\n\ndbgpt_server.py: error: the following arguments are required: --model_path\n\n### What you expected to happen\n\nrun server normally\n\n### How to reproduce\n\ninstall and start as doc\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "yuanhn5206",
      "author_type": "User",
      "created_at": "2025-01-09T15:41:52Z",
      "updated_at": "2025-05-10T21:04:47Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2292/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2292",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2292",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:02.644499",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "hi, how did you start dbgpt_server, by source code or by docker?",
          "created_at": "2025-01-10T02:40:29Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-05-10T21:04:46Z"
        }
      ]
    },
    {
      "issue_number": 2291,
      "title": "[Feature][workflow] Enable workflow nodes to run step by step on the awel orchestration page",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nThe AWEL function is excellent and flexible, but the AWEL visualization/orchestration  page is still quite simple. Here are some of my suggestions:\r\n1. Allow nodes to run step by step for easier debugging, so that you can check if the operation is successful and view the input and output values.\r\n2. Similar to other similar software, it should be possible to run the workflow and start a conversation on this page.\r\n3. There are too many upstream nodes of the streaming LLM operator. Can they be integrated into one or two? This will make it easier for beginners to use\r\n4. Can the current workflow name be displayed continuously on this page? Also, add a return button in the upper left corner?\r\n5. It would be best if it supported undo and redo.\r\n![image](https://github.com/user-attachments/assets/2d871f43-4af7-4380-be66-e68182917c8a)\r\n\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "lkp0000",
      "author_type": "User",
      "created_at": "2025-01-09T07:51:21Z",
      "updated_at": "2025-05-10T21:04:47Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2291/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2291",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2291",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:02.868879",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "Thanks for your suggestion, we have already consider run step by step on the awel workflow. Now we need to design it very carefully.",
          "created_at": "2025-01-10T02:31:35Z"
        },
        {
          "author": "lkp0000",
          "body": "That's great",
          "created_at": "2025-01-10T13:10:54Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-05-10T21:04:47Z"
        }
      ]
    },
    {
      "issue_number": 2297,
      "title": "[Bug] [agent] The LLM response content from the agent is missing.",
      "body": "### Search before asking\r\n\r\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\r\n\r\n\r\n### Operating system information\r\n\r\nLinux\r\n\r\n### Python version information\r\n\r\n>=3.11\r\n\r\n### DB-GPT version\r\n\r\nmain\r\n\r\n### Related scenes\r\n\r\n- [ ] Chat Data\r\n- [ ] Chat Excel\r\n- [ ] Chat DB\r\n- [ ] Chat Knowledge\r\n- [ ] Model Management\r\n- [ ] Dashboard\r\n- [ ] Plugins\r\n\r\n### Installation Information\r\n\r\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\r\n\r\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\r\n\r\n- [ ] AutoDL Image\r\n- [ ] Other\r\n\r\n### Device information\r\n\r\n*\r\n\r\n### Models information\r\n\r\ndeepseek v3\r\n\r\n### What happened\r\n\r\n*\r\n\r\n### What you expected to happen\r\n\r\nIn the agent module, when processing the LLM's response, if the response contains the ### symbol, the content before ### will be truncated.\r\n\r\n### How to reproduce\r\n\r\n1. execute the coede below\r\n ```python\r\n\r\nimport asyncio\r\n\r\nfrom dbgpt.agent import AgentContext, AgentMemory, LLMConfig, UserProxyAgent, ProfileConfig, ConversableAgent, \\\r\n    BlankAction\r\nfrom dbgpt.model.proxy import SiliconFlowLLMClient\r\n\r\n\r\nasync def main():\r\n\r\n    llm_client = SiliconFlowLLMClient(\r\n        model_alias=os.getenv(\r\n            \"SILICONFLOW_MODEL_VERSION\", \"Qwen/Qwen2.5-Coder-32B-Instruct\"\r\n        ),\r\n    )\r\n    context: AgentContext = AgentContext(conv_id=\"test456\")\r\n\r\n    agent_memory = AgentMemory()\r\n    agent_memory.gpts_memory.init(conv_id=\"test456\")\r\n\r\n    user_proxy = await UserProxyAgent().bind(agent_memory).bind(context).build()\r\n\r\n    # 代码优化助手\r\n    code_optimizer_profile = ProfileConfig(\r\n        name=\"Jack\",\r\n        role=\"CodeOptimizer\",\r\n        goal=\"优化用户给的代码。\",\r\n        desc=\"专门对用户代码进行优化\",\r\n        constraints=[\"要给出代码优化前后的对比，用markdown格式展示代码\"],\r\n    )\r\n    code_optimizer = (\r\n        await ConversableAgent(profile=code_optimizer_profile)\r\n        .bind(context)\r\n        .bind(LLMConfig(llm_client=llm_client))\r\n        .bind(agent_memory)\r\n        .bind(BlankAction)\r\n        .build()\r\n    )\r\n\r\n    await user_proxy.initiate_chat(\r\n        recipient=code_optimizer,\r\n        reviewer=user_proxy,\r\n        message=\"select * from table 帮我优化代码，解释部分和代码用###分割\",\r\n    )\r\n\r\n    ## dbgpt-vis message infos\r\n    print(await agent_memory.gpts_memory.app_link_chat_message(\"test456\"))\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    asyncio.run(main())\r\n\r\n```\r\n\r\n**model original output**\r\n````t\r\n### Explanation\r\nThe SQL query `SELECT * FROM table` retrieves all columns from the specified table. While this is a simple and straightforward query, it can be optimized in several ways depending on the context:\r\n\r\n1. **Specific Columns**: Instead of selecting all columns (`*`), specify only the columns you need. This reduces the amount of data transferred and processed, which can improve performance, especially for large tables.\r\n\r\n2. **Index Usage**: Ensure that the columns you are querying are indexed, especially if you are filtering or sorting the data. This can significantly speed up the query.\r\n\r\n3. **Limit Clause**: If you only need a subset of the data, consider using a `LIMIT` clause to restrict the number of rows returned.\r\n\r\n4. **Avoiding SELECT ***: Using `SELECT *` can lead to issues if the table schema changes (e.g., columns are added or removed). Explicitly listing the columns you need makes your query more robust.\r\n\r\n### Optimized Code\r\nHere’s an optimized version of the query, assuming you only need specific columns and a limited number of rows:\r\n\r\n```sql\r\n-- Original Query\r\nSELECT * FROM table;\r\n\r\n-- Optimized Query\r\nSELECT column1, column2, column3 \r\nFROM table\r\nLIMIT 100;\r\n```\r\n\r\n### Explanation of Optimized Code\r\n- **Specific Columns**: The optimized query selects only `column1`, `column2`, and `column3` instead of all columns. This reduces the amount of data processed and transferred.\r\n- **LIMIT Clause**: The `LIMIT 100` clause restricts the result set to 100 rows, which can be useful if you only need a sample of the data or are working with a large dataset.\r\n\r\nThis optimized query is more efficient and safer to use in production environments.\r\n````\r\n\r\n**processed output**\r\n\r\n````\r\n Explanation of Optimized Code\r\n- **Specific Columns**: The optimized query selects only `column1`, `column2`, and `column3` instead of all columns. This reduces the amount of data processed and transferred.\r\n- **LIMIT Clause**: The `LIMIT 100` clause restricts the result set to 100 rows, which can be useful if you only need a sample of the data or are working with a large dataset.\r\n\r\nThis optimized query is more efficient and safer to use in production environments.\r\n````\r\n\r\n\r\n### Additional context\r\n\r\n_No response_\r\n\r\n### Are you willing to submit PR?\r\n\r\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "FOkvj",
      "author_type": "User",
      "created_at": "2025-01-10T10:28:59Z",
      "updated_at": "2025-05-10T21:04:45Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2297/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2297",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2297",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:03.137918",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-05-10T21:04:44Z"
        }
      ]
    },
    {
      "issue_number": 2661,
      "title": "[Bug] [Module Name] mcp在多agent自动规划模式下异常",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU： 13700k\nGPU：4070ti\nos：linux\n\n### Models information\n\nmodelServer： ollama\nmodel：deepseek-r1:14b\n\n### What happened\n\n版本：0.7.0\n系统：Linux\n使用多Agent的模式创建应用，配置如下：\n\n![Image](https://github.com/user-attachments/assets/84139a03-2721-44d0-a329-26209f756258)\n\n\n询问问题：\n\n![Image](https://github.com/user-attachments/assets/4dc00ece-a06d-40f2-a5bc-1b2893ac2bf8)\n\n详细报错信息如下：\n\ndb-gpt-070-webserver-1  | 2025-04-27 17:14:03 f0c8715849d1 mcp.client.sse[1] INFO Connecting to SSE endpoint: http://192.168.5.3:18080/mcp\ndb-gpt-070-webserver-1  | 2025-04-27 17:14:03 f0c8715849d1 mcp.client.sse[1] INFO Received endpoint URL: http://192.168.5.3:18080/mcp/messages/?session_id=237456bb727940dd8979a4ca65d6b9c7\ndb-gpt-070-webserver-1  | 2025-04-27 17:14:03 f0c8715849d1 mcp.client.sse[1] INFO Starting post writer with endpoint URL: http://192.168.5.3:18080/mcp/messages/?session_id=237456bb727940dd8979a4ca65d6b9c7\ndb-gpt-070-webserver-1  | 2025-04-27 17:14:03 f0c8715849d1 dbgpt.agent.core.base_agent[1] ERROR Generate reply exception!\ndb-gpt-070-webserver-1  |   + Exception Group Traceback (most recent call last):\ndb-gpt-070-webserver-1  |   |   File \"/usr/lib/python3.11/contextlib.py\", line 222, in __aexit__\ndb-gpt-070-webserver-1  |   |     await self.gen.athrow(typ, value, traceback)\ndb-gpt-070-webserver-1  |   |   File \"/usr/lib/python3.11/contextlib.py\", line 222, in __aexit__\ndb-gpt-070-webserver-1  |   |     await self.gen.athrow(typ, value, traceback)\ndb-gpt-070-webserver-1  |   |   File \"//opt/.uv.venv/lib/python3.11/site-packages/httpx/_client.py\", line 1590, in stream\ndb-gpt-070-webserver-1  |   |     yield response\ndb-gpt-070-webserver-1  |   |   File \"//opt/.uv.venv/lib/python3.11/site-packages/httpx_sse/_api.py\", line 70, in aconnect_sse\ndb-gpt-070-webserver-1  |   |     yield EventSource(response)\ndb-gpt-070-webserver-1  |   |   File \"//opt/.uv.venv/lib/python3.11/site-packages/mcp/client/sse.py\", line 137, in sse_client\ndb-gpt-070-webserver-1  |   |     yield read_stream, write_stream\ndb-gpt-070-webserver-1  |   |   File \"/app/packages/dbgpt-core/src/dbgpt/agent/resource/tool/pack.py\", line 367, in preload_resource\ndb-gpt-070-webserver-1  |   |     async with ClientSession(read, write) as session:\ndb-gpt-070-webserver-1  |   |   File \"//opt/.uv.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 767, in __aexit__\ndb-gpt-070-webserver-1  |   |     raise BaseExceptionGroup(\ndb-gpt-070-webserver-1  |   | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\ndb-gpt-070-webserver-1  |   +-+---------------- 1 ----------------\ndb-gpt-070-webserver-1  |     | Traceback (most recent call last):\ndb-gpt-070-webserver-1  |     |   File \"/app/packages/dbgpt-core/src/dbgpt/agent/resource/tool/pack.py\", line 393, in preload_resource\ndb-gpt-070-webserver-1  |     |     self.add_command(\ndb-gpt-070-webserver-1  |     |   File \"/app/packages/dbgpt-core/src/dbgpt/agent/resource/tool/pack.py\", line 151, in add_command\ndb-gpt-070-webserver-1  |     |     self.append(ft)\ndb-gpt-070-webserver-1  |     |   File \"/app/packages/dbgpt-core/src/dbgpt/agent/resource/pack.py\", line 86, in append\ndb-gpt-070-webserver-1  |     |     raise ValueError(f\"Resource {name} already exists in the pack.\")\ndb-gpt-070-webserver-1  |     | ValueError: Resource extract_text already exists in the pack.\ndb-gpt-070-webserver-1  |     +------------------------------------\ndb-gpt-070-webserver-1  | \ndb-gpt-070-webserver-1  | During handling of the above exception, another exception occurred:\ndb-gpt-070-webserver-1  | \ndb-gpt-070-webserver-1  |   + Exception Group Traceback (most recent call last):\ndb-gpt-070-webserver-1  |   |   File \"/app/packages/dbgpt-core/src/dbgpt/agent/core/base_agent.py\", line 459, in generate_reply\ndb-gpt-070-webserver-1  |   |     act_out: ActionOutput = await self.act(\ndb-gpt-070-webserver-1  |   |                             ^^^^^^^^^^^^^^^\ndb-gpt-070-webserver-1  |   |   File \"/app/packages/dbgpt-core/src/dbgpt/agent/core/plan/team_auto_plan.py\", line 190, in act\ndb-gpt-070-webserver-1  |   |     await PlannerAgent()\ndb-gpt-070-webserver-1  |   |   File \"/app/packages/dbgpt-core/src/dbgpt/agent/core/base_agent.py\", line 147, in build\ndb-gpt-070-webserver-1  |   |     await self.preload_resource()\ndb-gpt-070-webserver-1  |   |   File \"/app/packages/dbgpt-core/src/dbgpt/agent/core/base_agent.py\", line 142, in preload_resource\ndb-gpt-070-webserver-1  |   |     await self.resource.preload_resource()\ndb-gpt-070-webserver-1  |   |   File \"/app/packages/dbgpt-core/src/dbgpt/agent/resource/pack.py\", line 55, in preload_resource\ndb-gpt-070-webserver-1  |   |     await sub_resource.preload_resource()\ndb-gpt-070-webserver-1  |   |   File \"/app/packages/dbgpt-core/src/dbgpt/agent/resource/tool/pack.py\", line 366, in preload_resource\ndb-gpt-070-webserver-1  |   |     async with sse_client(url=server, headers=server_headers) as (read, write):\ndb-gpt-070-webserver-1  |   |   File \"/usr/lib/python3.11/contextlib.py\", line 222, in __aexit__\ndb-gpt-070-webserver-1  |   |     await self.gen.athrow(typ, value, traceback)\ndb-gpt-070-webserver-1  |   |   File \"//opt/.uv.venv/lib/python3.11/site-packages/mcp/client/sse.py\", line 43, in sse_client\ndb-gpt-070-webserver-1  |   |     async with anyio.create_task_group() as tg:\ndb-gpt-070-webserver-1  |   |   File \"//opt/.uv.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 767, in __aexit__\ndb-gpt-070-webserver-1  |   |     raise BaseExceptionGroup(\ndb-gpt-070-webserver-1  |   | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\ndb-gpt-070-webserver-1  |   +-+---------------- 1 ----------------\ndb-gpt-070-webserver-1  |     | Traceback (most recent call last):\ndb-gpt-070-webserver-1  |     |   File \"/app/packages/dbgpt-core/src/dbgpt/agent/resource/tool/pack.py\", line 393, in preload_resource\ndb-gpt-070-webserver-1  |     |     self.add_command(\ndb-gpt-070-webserver-1  |     |   File \"/app/packages/dbgpt-core/src/dbgpt/agent/resource/tool/pack.py\", line 151, in add_command\ndb-gpt-070-webserver-1  |     |     self.append(ft)\ndb-gpt-070-webserver-1  |     |   File \"/app/packages/dbgpt-core/src/dbgpt/agent/resource/pack.py\", line 86, in append\ndb-gpt-070-webserver-1  |     |     raise ValueError(f\"Resource {name} already exists in the pack.\")\ndb-gpt-070-webserver-1  |     | ValueError: Resource extract_text already exists in the pack.\ndb-gpt-070-webserver-1  |     | \ndb-gpt-070-webserver-1  |     | During handling of the above exception, another exception occurred:\ndb-gpt-070-webserver-1  |     | \ndb-gpt-070-webserver-1  |     | Exception Group Traceback (most recent call last):\ndb-gpt-070-webserver-1  |     |   File \"/usr/lib/python3.11/contextlib.py\", line 222, in __aexit__\ndb-gpt-070-webserver-1  |     |     await self.gen.athrow(typ, value, traceback)\ndb-gpt-070-webserver-1  |     |   File \"/usr/lib/python3.11/contextlib.py\", line 222, in __aexit__\ndb-gpt-070-webserver-1  |     |     await self.gen.athrow(typ, value, traceback)\ndb-gpt-070-webserver-1  |     |   File \"//opt/.uv.venv/lib/python3.11/site-packages/httpx/_client.py\", line 1590, in stream\ndb-gpt-070-webserver-1  |     |     yield response\ndb-gpt-070-webserver-1  |     |   File \"//opt/.uv.venv/lib/python3.11/site-packages/httpx_sse/_api.py\", line 70, in aconnect_sse\ndb-gpt-070-webserver-1  |     |     yield EventSource(response)\ndb-gpt-070-webserver-1  |     |   File \"//opt/.uv.venv/lib/python3.11/site-packages/mcp/client/sse.py\", line 137, in sse_client\ndb-gpt-070-webserver-1  |     |     yield read_stream, write_stream\ndb-gpt-070-webserver-1  |     |   File \"/app/packages/dbgpt-core/src/dbgpt/agent/resource/tool/pack.py\", line 367, in preload_resource\ndb-gpt-070-webserver-1  |     |     async with ClientSession(read, write) as session:\ndb-gpt-070-webserver-1  |     |   File \"//opt/.uv.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 767, in __aexit__\ndb-gpt-070-webserver-1  |     |     raise BaseExceptionGroup(\ndb-gpt-070-webserver-1  |     | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\ndb-gpt-070-webserver-1  |     +-+---------------- 1 ----------------\ndb-gpt-070-webserver-1  |       | Traceback (most recent call last):\ndb-gpt-070-webserver-1  |       |   File \"/app/packages/dbgpt-core/src/dbgpt/agent/resource/tool/pack.py\", line 393, in preload_resource\ndb-gpt-070-webserver-1  |       |     self.add_command(\ndb-gpt-070-webserver-1  |       |   File \"/app/packages/dbgpt-core/src/dbgpt/agent/resource/tool/pack.py\", line 151, in add_command\ndb-gpt-070-webserver-1  |       |     self.append(ft)\ndb-gpt-070-webserver-1  |       |   File \"/app/packages/dbgpt-core/src/dbgpt/agent/resource/pack.py\", line 86, in append\ndb-gpt-070-webserver-1  |       |     raise ValueError(f\"Resource {name} already exists in the pack.\")\ndb-gpt-070-webserver-1  |       | ValueError: Resource extract_text already exists in the pack.\ndb-gpt-070-webserver-1  |       +------------------------------------\ndb-gpt-070-webserver-1  | \ndb-gpt-070-webserver-1  | --------------------------------------------------------------------------------\ndb-gpt-070-webserver-1  | AutoPlanChatManager (to User)-[]:\ndb-gpt-070-webserver-1  | \ndb-gpt-070-webserver-1  | \"unhandled errors in a TaskGroup (1 sub-exception)\"\ndb-gpt-070-webserver-1  | \ndb-gpt-070-webserver-1  | --------------------------------------------------------------------------------\ndb-gpt-070-webserver-1  | 2025-04-27 17:14:03 f0c8715849d1 dbgpt_serve.agent.agents.controller[1] INFO save agent chat info！03d7279e-238b-11f0-a42a-0242ac1b0003\n\n\n\n### What you expected to happen\n\n多Agent配置Mcp server调用规划正常    \n\n### How to reproduce\n\n无\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "ogj130",
      "author_type": "User",
      "created_at": "2025-04-27T17:19:10Z",
      "updated_at": "2025-05-10T09:52:42Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2661/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2661",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2661",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:03.333438",
      "comments": [
        {
          "author": "ogj130",
          "body": "使用同样的mcp server，然后使用单Agent的方式进行chat正常：\n\n\n![Image](https://github.com/user-attachments/assets/d71f9402-b724-4c99-af0d-7cb766335a9e)\n\n\n![Image](https://github.com/user-attachments/assets/54100e8a-327e-480d-9f05-0552dd8a96c5)\n\n",
          "created_at": "2025-04-27T17:24:35Z"
        },
        {
          "author": "dusx1981",
          "body": "看着像是聊天记录重复了",
          "created_at": "2025-05-10T09:52:42Z"
        }
      ]
    },
    {
      "issue_number": 2675,
      "title": "[Bug] Unknown type value: proxy/ollama, known types: ['hf', 'proxy/openapi', 'proxy/siliconflow', 'proxy/tei', 'proxy/infiniai']",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nw11\n4090\n\n\n### Models information\n\n[system]\n# Load language from environment variable(It is set by the hook)\nlanguage = \"${env:DBGPT_LANG:-zh}\"\napi_keys = []\nencrypt_key = \"your_secret_key\"\n\n# Server Configurations\n[service.web]\nhost = \"0.0.0.0\"\nport = 5670\n\n[service.web.database]\ntype = \"sqlite\"\npath = \"pilot/meta_data/dbgpt.db\"\n\n[rag.storage]\n[rag.storage.vector]\ntype = \"chroma\"\npersist_path = \"pilot/data\"\n\n# Model Configurations\n[models]\n[[models.llms]]\nname = \"qwen2.5-coder:32b-instruct-q4_K_M\"\nprovider = \"proxy/ollama\"\napi_base = \"http://xxxx:11434\"\napi_key = \"\"\n\n[[models.embeddings]]\nname = \"bge-m3:latest\"\nprovider = \"proxy/ollama\"\napi_url = \"http://xxxx:11434\"\napi_key = \"\"\n\n[[models.rerankers]]\ntype = \"reranker\"\nname = \"xitao/bge-reranker-v2-m3:latest\"\nprovider = \"proxy/ollama\"\napi_key = \"\"\napi_url = \"http://xxxx:11434\"\n\n\n### What happened\n\n[system]\n# Load language from environment variable(It is set by the hook)\nlanguage = \"${env:DBGPT_LANG:-zh}\"\napi_keys = []\nencrypt_key = \"your_secret_key\"\n\n# Server Configurations\n[service.web]\nhost = \"0.0.0.0\"\nport = 5670\n\n[service.web.database]\ntype = \"sqlite\"\npath = \"pilot/meta_data/dbgpt.db\"\n\n[rag.storage]\n[rag.storage.vector]\ntype = \"chroma\"\npersist_path = \"pilot/data\"\n\n# Model Configurations\n[models]\n[[models.llms]]\nname = \"qwen2.5-coder:32b-instruct-q4_K_M\"\nprovider = \"proxy/ollama\"\napi_base = \"http://xxxx:11434\"\napi_key = \"\"\n\n[[models.embeddings]]\nname = \"bge-m3:latest\"\nprovider = \"proxy/ollama\"\napi_url = \"http://xxxx:11434\"\napi_key = \"\"\n\n[[models.rerankers]]\ntype = \"reranker\"\nname = \"xitao/bge-reranker-v2-m3:latest\"\nprovider = \"proxy/ollama\"\napi_key = \"\"\napi_url = \"http://xxxxx:11434\"\n\n\n\n\n采用uv安装的：\nuv sync --all-packages --frozen --extra \"base\" --extra \"proxy_ollama\" --extra \"rag\" --extra \"storage_chromadb\" --extra \"dbgpts\" --link-mode=copy\n采用uv运行的：\n(db-agent) PS D:\\DB-GPT> uv sync --all-packages --extra \"base\" --extra \"proxy_ollama\" --extra \"rag\" --extra \"storage_chromadb\" --extra \"dbgpts\"\nResolved 537 packages in 3m 00s\nAudited 319 packages in 1ms\n(db-agent) PS D:\\DB-GPT> uv run dbgpt start webserver --config configs/dbgpt-proxy-ollama.toml\nTraceback (most recent call last):                                                                                                                                             \n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\configure\\manager.py\", line 526, in _convert_value\n    return self._convert_to_dataclass(field_type, value)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\configure\\manager.py\", line 572, in _convert_to_dataclass\n    concrete_cls = _get_concrete_class(cls, data)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\configure\\manager.py\", line 244, in _get_concrete_class\n    raise ValueError(\nValueError: Unknown type value: proxy/ollama, known types: ['hf', 'proxy/openapi', 'proxy/siliconflow', 'proxy/tei', 'proxy/infiniai']\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\configure\\manager.py\", line 502, in _convert_value\n    return [self._convert_value(item, element_type) for item in value]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\configure\\manager.py\", line 502, in <listcomp>\n    return [self._convert_value(item, element_type) for item in value]\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\configure\\manager.py\", line 528, in _convert_value\n    raise ValueError(f\"Invalid data for {field_type.__name__}: {str(e)}\")\nValueError: Invalid data for RerankerDeployModelParameters: Unknown type value: proxy/ollama, known types: ['hf', 'proxy/openapi', 'proxy/siliconflow', 'proxy/tei', 'proxy/infiniai']\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\configure\\manager.py\", line 526, in _convert_value\n    return self._convert_to_dataclass(field_type, value)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\configure\\manager.py\", line 604, in _convert_to_dataclass\n    prepared_field_values = prepare_data_func(concrete_cls, data)\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\configure\\manager.py\", line 593, in prepare_data_func\n    field_values[fd.name] = self._convert_value(field_value, field_type)\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\configure\\manager.py\", line 504, in _convert_value\n    raise ValueError(f\"Invalid list element type: {str(e)}\")\nValueError: Invalid list element type: Invalid data for RerankerDeployModelParameters: Unknown type value: proxy/ollama, known types: ['hf', 'proxy/openapi', 'proxy/siliconflow', 'proxy/tei', 'proxy/infiniai']\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"D:\\DB-GPT\\.venv\\Scripts\\dbgpt.exe\\__main__.py\", line 10, in <module>\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\cli\\cli_scripts.py\", line 229, in main\n    return cli()\n           ^^^^^\n  File \"D:\\DB-GPT\\.venv\\Lib\\site-packages\\click\\core.py\", line 1161, in __call__\n    return self.main(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\.venv\\Lib\\site-packages\\click\\core.py\", line 1082, in main\n    rv = self.invoke(ctx)\n         ^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\.venv\\Lib\\site-packages\\click\\core.py\", line 1697, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\.venv\\Lib\\site-packages\\click\\core.py\", line 1697, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\.venv\\Lib\\site-packages\\click\\core.py\", line 1443, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\.venv\\Lib\\site-packages\\click\\core.py\", line 788, in invoke\n    return __callback(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\model\\cli.py\", line 458, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\packages\\dbgpt-app\\src\\dbgpt_app\\_cli.py\", line 25, in start_webserver\n    run_webserver(config)\n  File \"D:\\DB-GPT\\packages\\dbgpt-app\\src\\dbgpt_app\\dbgpt_server.py\", line 221, in run_webserver\n    param = load_config(config_file)\n            ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\packages\\dbgpt-app\\src\\dbgpt_app\\dbgpt_server.py\", line 302, in load_config\n    app_config = cfg.parse_config(ApplicationConfig, hook_section=\"hooks\")\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\configure\\manager.py\", line 658, in parse_config\n    return self._convert_to_dataclass(cls, config_section)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\configure\\manager.py\", line 604, in _convert_to_dataclass\n    prepared_field_values = prepare_data_func(concrete_cls, data)\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\configure\\manager.py\", line 593, in prepare_data_func\n    field_values[fd.name] = self._convert_value(field_value, field_type)\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\configure\\manager.py\", line 528, in _convert_value\n    raise ValueError(f\"Invalid data for {field_type.__name__}: {str(e)}\")\nValueError: Invalid data for ModelsDeployParameters: Invalid list element type: Invalid data for RerankerDeployModelParameters: Unknown type value: proxy/ollama, known types: ['hf', 'proxy/openapi', 'proxy/siliconflow', 'proxy/tei', 'proxy/infiniai']\n\n\n### What you expected to happen\n\n官方的配置文件里面写的是proxy/ollama\n但实际运行的时候说不支持\n\n### How to reproduce\n\n(db-agent) PS D:\\DB-GPT> uv sync --all-packages --extra \"base\" --extra \"proxy_ollama\" --extra \"rag\" --extra \"storage_chromadb\" --extra \"dbgpts\"\nResolved 537 packages in 3m 00s\nAudited 319 packages in 1ms\n(db-agent) PS D:\\DB-GPT> uv run dbgpt start webserver --config configs/dbgpt-proxy-ollama.toml\nTraceback (most recent call last):                                                                                                                                             \n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\configure\\manager.py\", line 526, in _convert_value\n    return self._convert_to_dataclass(field_type, value)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\configure\\manager.py\", line 572, in _convert_to_dataclass\n    concrete_cls = _get_concrete_class(cls, data)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\configure\\manager.py\", line 244, in _get_concrete_class\n    raise ValueError(\nValueError: Unknown type value: proxy/ollama, known types: ['hf', 'proxy/openapi', 'proxy/siliconflow', 'proxy/tei', 'proxy/infiniai']\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\configure\\manager.py\", line 502, in _convert_value\n    return [self._convert_value(item, element_type) for item in value]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\configure\\manager.py\", line 502, in <listcomp>\n    return [self._convert_value(item, element_type) for item in value]\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\configure\\manager.py\", line 528, in _convert_value\n    raise ValueError(f\"Invalid data for {field_type.__name__}: {str(e)}\")\nValueError: Invalid data for RerankerDeployModelParameters: Unknown type value: proxy/ollama, known types: ['hf', 'proxy/openapi', 'proxy/siliconflow', 'proxy/tei', 'proxy/infiniai']\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\configure\\manager.py\", line 526, in _convert_value\n    return self._convert_to_dataclass(field_type, value)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\configure\\manager.py\", line 604, in _convert_to_dataclass\n    prepared_field_values = prepare_data_func(concrete_cls, data)\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\configure\\manager.py\", line 593, in prepare_data_func\n    field_values[fd.name] = self._convert_value(field_value, field_type)\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\configure\\manager.py\", line 504, in _convert_value\n    raise ValueError(f\"Invalid list element type: {str(e)}\")\nValueError: Invalid list element type: Invalid data for RerankerDeployModelParameters: Unknown type value: proxy/ollama, known types: ['hf', 'proxy/openapi', 'proxy/siliconflow', 'proxy/tei', 'proxy/infiniai']\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"D:\\DB-GPT\\.venv\\Scripts\\dbgpt.exe\\__main__.py\", line 10, in <module>\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\cli\\cli_scripts.py\", line 229, in main\n    return cli()\n           ^^^^^\n  File \"D:\\DB-GPT\\.venv\\Lib\\site-packages\\click\\core.py\", line 1161, in __call__\n    return self.main(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\.venv\\Lib\\site-packages\\click\\core.py\", line 1082, in main\n    rv = self.invoke(ctx)\n         ^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\.venv\\Lib\\site-packages\\click\\core.py\", line 1697, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\.venv\\Lib\\site-packages\\click\\core.py\", line 1697, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\.venv\\Lib\\site-packages\\click\\core.py\", line 1443, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\.venv\\Lib\\site-packages\\click\\core.py\", line 788, in invoke\n    return __callback(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\model\\cli.py\", line 458, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\packages\\dbgpt-app\\src\\dbgpt_app\\_cli.py\", line 25, in start_webserver\n    run_webserver(config)\n  File \"D:\\DB-GPT\\packages\\dbgpt-app\\src\\dbgpt_app\\dbgpt_server.py\", line 221, in run_webserver\n    param = load_config(config_file)\n            ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\packages\\dbgpt-app\\src\\dbgpt_app\\dbgpt_server.py\", line 302, in load_config\n    app_config = cfg.parse_config(ApplicationConfig, hook_section=\"hooks\")\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\configure\\manager.py\", line 658, in parse_config\n    return self._convert_to_dataclass(cls, config_section)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\configure\\manager.py\", line 604, in _convert_to_dataclass\n    prepared_field_values = prepare_data_func(concrete_cls, data)\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\configure\\manager.py\", line 593, in prepare_data_func\n    field_values[fd.name] = self._convert_value(field_value, field_type)\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\configure\\manager.py\", line 528, in _convert_value\n    raise ValueError(f\"Invalid data for {field_type.__name__}: {str(e)}\")\nValueError: Invalid data for ModelsDeployParameters: Invalid list element type: Invalid data for RerankerDeployModelParameters: Unknown type value: proxy/ollama, known types: ['hf', 'proxy/openapi', 'proxy/siliconflow', 'proxy/tei', 'proxy/infiniai']\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "xigan-bit",
      "author_type": "User",
      "created_at": "2025-05-10T03:43:35Z",
      "updated_at": "2025-05-10T09:09:51Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2675/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2675",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2675",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:03.532918",
      "comments": [
        {
          "author": "fangyinc",
          "body": "Hi @xigan-bit . The Ollama reranker model is not supported now. ",
          "created_at": "2025-05-10T09:05:39Z"
        },
        {
          "author": "xigan-bit",
          "body": "> 您好。现在不支持 Ollama reranker 模型。\n\n好的感谢，已经修复。但是遇到了新问题，我连接mysql后，程序会异常退出，并不报任何错误：\ndbgpt.storage.base[8408] INFO Loading 350 chunks in 35 groups with 1 threads.\n2025-05-10 15:53:33 DESKTOP-IDMA10B dbgpt_ext.storage.vector_store.chroma_store[8408] INFO ChromaStore load document\n2025-05-10 15:53:33 DESKTOP",
          "created_at": "2025-05-10T09:09:50Z"
        }
      ]
    },
    {
      "issue_number": 2667,
      "title": "[Feature][RAG] Tree-Retriever Based on document directory level",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n_No response_\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "Aries-ckt",
      "author_type": "User",
      "created_at": "2025-05-04T15:27:56Z",
      "updated_at": "2025-05-10T05:02:27Z",
      "closed_at": "2025-05-10T05:02:27Z",
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2667/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "Aries-ckt"
      ],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2667",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2667",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:03.727059",
      "comments": []
    },
    {
      "issue_number": 2286,
      "title": "[Bug] [i18n] Both the front-end and back-end can switch languages, but they are not synchronized",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [X] Chat Data\n- [X] Chat Excel\n- [X] Chat DB\n- [X] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\ncpu\n\n### Models information\n\nllm:openai proxy\n\n### What happened\n\n    i can change the LANGUAGE value in the env file.it will take effect after restart.and the front-end can also swith languages, but the back-end remains in its original language.\n\n### What you expected to happen\n\n       Can the authorities solve this problem? For example, adding 'content-language' field in the api header\n\n### How to reproduce\n\nchange language can reproduce.such as app list page.\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "lkp0000",
      "author_type": "User",
      "created_at": "2025-01-08T06:44:54Z",
      "updated_at": "2025-05-09T21:05:08Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2286/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2286",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2286",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:03.727083",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "hi sorry about influence your experience, could you show the what app you use and what expect language you want, en or zh?",
          "created_at": "2025-01-08T12:18:05Z"
        },
        {
          "author": "lkp0000",
          "body": "> hi sorry about influence your experience, could you show the what app you use and what expect language you want, en or zh?\r\n\r\nI may know the reason now, maybe it's because some data is read from the database. But I think there are still some small issues：\r\n![image](https://github.com/user-attachme",
          "created_at": "2025-01-09T04:58:02Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-05-09T21:05:07Z"
        }
      ]
    },
    {
      "issue_number": 2277,
      "title": "[Bug] [rag] <asyncio.locks.Semaphore object at 0x7f81fad08a60 [locked]",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [X] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nLLM: qwen2\r\nembedding: normic\n\n### What happened\n\n混合知识流程，执行完，再次执行时报错：\r\ncurl --location --request POST 'http://localhost:5670/api/v1/awel/trigger/rag/knowledge/hybrid/process' --header 'Content-Type: application/json' --data-raw '{}'\r\n{\"success\":false,\"err_code\":\"E0003\",\"err_msg\":\"<asyncio.locks.Semaphore object at 0x7f81fad08a60 [locked]> is bound to a different event loop\",\"data\":null}\n\n### What you expected to happen\n\n能过多次执行\n\n### How to reproduce\n\n混合知识流程，执行完，再次执行时报错：\r\ncurl --location --request POST 'http://localhost:5670/api/v1/awel/trigger/rag/knowledge/hybrid/process' --header 'Content-Type: application/json' --data-raw '{}'\r\n{\"success\":false,\"err_code\":\"E0003\",\"err_msg\":\"<asyncio.locks.Semaphore object at 0x7f81fad08a60 [locked]> is bound to a different event loop\",\"data\":null}\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "maco6096",
      "author_type": "User",
      "created_at": "2025-01-06T05:46:14Z",
      "updated_at": "2025-05-08T21:05:32Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2277/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2277",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2277",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:03.955492",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "hi, could you post your process file?",
          "created_at": "2025-01-06T07:31:40Z"
        },
        {
          "author": "maco6096",
          "body": "[hybrid-knowledge-process-workflow (1).json](https://github.com/user-attachments/files/18340653/hybrid-knowledge-process-workflow.1.json)\r\n",
          "created_at": "2025-01-08T01:47:10Z"
        },
        {
          "author": "maco6096",
          "body": "就是自带的那个文件， 知识改了加载文件的参数",
          "created_at": "2025-01-08T01:48:08Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-05-08T21:05:31Z"
        }
      ]
    },
    {
      "issue_number": 2283,
      "title": "[Bug] [Module Name] After shutting down the entire service, the lyric background process remains running?",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n-\n\n### Models information\n\n-\n\n### What happened\n\n启动整体服务断开，重复几次，发现有多个lyric进程还在占用内存，一直占着？\r\n![image](https://github.com/user-attachments/assets/c52fa4c5-04ea-4157-ad66-d0e998fa5bdb)\r\n\n\n### What you expected to happen\n\n是否能够随着服务断开而释放\n\n### How to reproduce\n\n-\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "yuerf",
      "author_type": "User",
      "created_at": "2025-01-08T01:16:40Z",
      "updated_at": "2025-05-08T21:05:30Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2283/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2283",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2283",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:04.229928",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "@fangyinc",
          "created_at": "2025-01-08T12:11:00Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-05-08T21:05:29Z"
        }
      ]
    },
    {
      "issue_number": 2285,
      "title": "[Feature][Agent] let agent app support upload excel file",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n    there are several build-in agent in dbgpt.such as DataScientist、Summarizer、Reporter、etc. but they don't support uploading files.the native_app ChatExcel supports upload file, but the agent surprisingly does not support it.\r\n\r\n    I want to develop an agent that allows dbgpt to help me analyze data in excel,without using the awel mode,which may be too complex for beginners.\r\n\r\n\r\n    as shown in the following figure.there is no button to enable upload function.\r\n![image](https://github.com/user-attachments/assets/fe264498-d0bb-4da5-846e-da1fd446e9da)\r\n\r\n\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "lkp0000",
      "author_type": "User",
      "created_at": "2025-01-08T06:29:14Z",
      "updated_at": "2025-05-08T21:05:29Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2285/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2285",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2285",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:04.438073",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-05-08T21:05:28Z"
        }
      ]
    },
    {
      "issue_number": 2559,
      "title": "The docker container starting is error: ModuleNotFoundError: No module named 'sentence_transformers'.",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [x] Chat Data\n- [ ] Chat Excel\n- [x] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [x] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice: CPU\n\n### Models information\n\nLLM: QwQ-32B\nEmbeddings: text2vec-large-chinese\n\n### What happened\n\nI use image eosphorosai/dbgpt-openai:latest，The docker container starting is error: ModuleNotFoundError: No module named 'sentence_transformers'. The details:\nINFO: Uvicorn running on http://0.0.0.0:5670/ (Press CTRL+C to quit)\n2025-03-28 06:23:10 14f6e17aef24 dbgpt.util.code.server[1] INFO Code server is ready\n2025-03-28 06:23:10 14f6e17aef24 dbgpt.util.api_utils[1] WARNING No healthy urls found, selecting randomly\nINFO: 127.0.0.1:59786 - \"POST /api/controller/models HTTP/1.1\" 200 OK\n2025-03-28 06:23:10 14f6e17aef24 dbgpt.model.cluster.worker.embedding_worker[1] INFO Load embeddings model: BAAI/bge-large-zh-v1.5\n2025-03-28 06:23:10 14f6e17aef24 dbgpt.model.cluster.worker.manager[1] ERROR Error starting worker manager: model QwQ-32B@proxy/deepseek(172.17.0.2:5670) start successfully\n;model BAAI/bge-large-zh-v1.5@hf(172.17.0.2:5670) start failed, Traceback (most recent call last):\nFile \"/app/packages/dbgpt-core/src/dbgpt/rag/embedding/embeddings.py\", line 460, in init\nimport sentence_transformers\nModuleNotFoundError: No module named 'sentence_transformers'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\nFile \"/app/packages/dbgpt-core/src/dbgpt/model/cluster/worker/manager.py\", line 631, in _start_worker\nawait self.run_blocking_func(\nFile \"/app/packages/dbgpt-core/src/dbgpt/model/cluster/worker/manager.py\", line 146, in run_blocking_func\nreturn await loop.run_in_executor(self.executor, func, *args)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile \"/usr/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\nresult = self.fn(*self.args, **self.kwargs)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile \"/app/packages/dbgpt-core/src/dbgpt/model/cluster/worker/embedding_worker.py\", line 84, in start\nself._embeddings_impl = self._adapter.load_from_params(self._model_params)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile \"/app/packages/dbgpt-core/src/dbgpt/model/adapter/base.py\", line 829, in load_from_params\nreturn model_adapter_cls.from_parameters(params)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile \"/app/packages/dbgpt-core/src/dbgpt/rag/embedding/embeddings.py\", line 487, in from_parameters\nreturn cls(\n^^^^\nFile \"/app/packages/dbgpt-core/src/dbgpt/rag/embedding/embeddings.py\", line 463, in init\nraise ImportError(\nImportError: Could not import sentence_transformers python package. Please install it with pip install sentence_transformers.\n\nINFO: Shutting down\nINFO: Waiting for application shutdown.\n2025-03-28 06:23:10 14f6e17aef24 dbgpt.model.cluster.worker.manager[1] INFO Stop all workers\n2025-03-28 06:23:10 14f6e17aef24 dbgpt.model.cluster.worker.manager[1] INFO Apply req: None, apply_func: <function LocalWorkerManager._stop_all_worker.._stop_worker at 0x7f900e45aa20>\n2025-03-28 06:23:10 14f6e17aef24 dbgpt.model.cluster.worker.manager[1] INFO Apply to all workers\n2025-03-28 06:23:10 14f6e17aef24 dbgpt.util.model_utils[1] WARNING Torch not installed, skip clear torch cache\n2025-03-28 06:23:12 14f6e17aef24 dbgpt.util.api_utils[1] WARNING No healthy urls found, selecting randomly\n2025-03-28 06:23:12 14f6e17aef24 dbgpt.util.api_utils[1] WARNING Health check failed for http://127.0.0.1:5670/, error: HTTPConnectionPool(host='127.0.0.1', port=5670): Max retries exceeded with url: /api/health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9044da4050>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-03-28 06:23:12 14f6e17aef24 dbgpt.model.cluster.worker.manager[1] WARNING Send heartbeat func error: All connection attempts failed\n2025-03-28 06:23:12 14f6e17aef24 dbgpt.util.api_utils[1] WARNING No healthy urls found, selecting randomly\n2025-03-28 06:23:12 14f6e17aef24 dbgpt.util.api_utils[1] WARNING No healthy urls found, selecting randomly\n2025-03-28 06:23:12 14f6e17aef24 dbgpt.util.api_utils[1] WARNING No healthy urls found, selecting randomly\n2025-03-28 06:23:12 14f6e17aef24 dbgpt.model.cluster.worker.manager[1] WARNING Stop worker, ignored exception from deregister_func: All connection attempts failed\n2025-03-28 06:23:12 14f6e17aef24 dbgpt.model.cluster.worker.manager[1] WARNING Stop worker, ignored exception from deregister_func: All connection attempts failed\n2025-03-28 06:23:12 14f6e17aef24 dbgpt.model.cluster.worker.manager[1] WARNING Stop worker, ignored exception from deregister_func: All connection attempts failed\nINFO: Application shutdown complete.\nINFO: Finished server process [1]\nin order to avoid chroma db atexit problem\n\n### What you expected to happen\n\nThe docker image  eosphorosai/dbgpt-openai:latest have bugs.\n\n### How to reproduce\n\n1. docker run -d \\\n   --restart unless-stopped \\\n   --name dbgpt \\\n   -p 5670:5670 \\\n   -v /opt/dbgpt/configs:/app/configs \\\n   -v /opt/dbgpt/data/models:/app/models \\\n   -e LOCAL_DB_TYPE=sqlite \\\n   -e LOCAL_DB_PATH=data/default_sqlite.db \\\n   -e LANGUAGE=zh \\\n   eosphorosai/dbgpt-openai:latest \\\n   dbgpt start webserver --config /app/configs/dbgpt-proxy-qwq.toml\n2. the docker container run log occurred ModuleNotFoundError: No module named 'sentence_transformers'.\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "zhenglibing",
      "author_type": "User",
      "created_at": "2025-03-31T03:45:35Z",
      "updated_at": "2025-05-08T09:41:31Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2559/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2559",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2559",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:04.681857",
      "comments": [
        {
          "author": "lililill",
          "body": "same question",
          "created_at": "2025-04-08T08:25:31Z"
        },
        {
          "author": "zzzsudo",
          "body": "same",
          "created_at": "2025-04-10T05:54:03Z"
        },
        {
          "author": "fangyinc",
          "body": "Same #2452",
          "created_at": "2025-04-11T06:22:19Z"
        },
        {
          "author": "zzzsudo",
          "body": "> Same [#2452](https://github.com/eosphoros-ai/DB-GPT/issues/2452)\nI'm not using docker, i installed by uv, the problem still exist",
          "created_at": "2025-04-14T06:43:15Z"
        },
        {
          "author": "YangXiaojun1012",
          "body": "> > Same [#2452](https://github.com/eosphoros-ai/DB-GPT/issues/2452)\n> > I'm not using docker, i installed by uv, the problem still exist\n\nyes i also have this problem, I am not using docker",
          "created_at": "2025-04-14T08:47:51Z"
        }
      ]
    },
    {
      "issue_number": 2282,
      "title": "Plugin Install Error (\"Install dbgpts [agents:summarizer-agent-example] Failed! [Errno 2] No such file or directory: 'poetry'\", FileNotFoundError(2, 'No such file or directory'))",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [X] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU：1\r\nMemory：256G\n\n### Models information\n\nLLM：QWEN-2.5-72B\r\nembedding model ：bge-large-zh-v1.5\n\n### What happened\n\n在DBGPTS社区安装插件时，报错\r\n\r\nPlugin Install Error (\"Install dbgpts [agents:summarizer-agent-example] Failed! [Errno 2] No such file or directory: 'poetry'\", FileNotFoundError(2, 'No such file or directory'))\r\n\r\nPlugin Install Error (\"Install dbgpts [workflow:financial-robot-app] Failed! [Errno 2] No such file or directory: 'poetry'\", FileNotFoundError(2, 'No such file or directory'))\r\n\r\npoetry已安装：\r\npoetry                                   1.8.2\r\npoetry-core                              1.9.0\r\npoetry-plugin-export                     1.7.1\n\n### What you expected to happen\n\nDBGPTS社区安装插件正常\n\n### How to reproduce\n\nDBGPT v0.6.3\r\n1、点击“应用管理”；\r\n2、点击“DBGPTS社区”；\r\n3、点击“financial-robot-app”的install 按钮。\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Yue-Rain",
      "author_type": "User",
      "created_at": "2025-01-07T06:14:29Z",
      "updated_at": "2025-05-07T21:05:25Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2282/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2282",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2282",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:04.870681",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "please make sure your intent, you want to install `financial-robot-app`, but your log show you insall `Install dbgpts [agents:summarizer-agent-example] Failed! `",
          "created_at": "2025-01-07T15:37:42Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-05-07T21:05:23Z"
        }
      ]
    },
    {
      "issue_number": 2674,
      "title": "[Feature][Module Name] 如何在Spyder里运行dbgpt_server.py文件",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n在Spyder里运行dbgpt_server.py文件时报下图的错误\n\n<img width=\"1268\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/432b004c-5632-44d1-84dc-ac1bd9405fc3\" />\n\n<img width=\"718\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/b011b3d9-30bd-4814-9166-c7a5d4387f67\" />\n已排除端口被占用情况，仍然报错\n\n<img width=\"1274\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/67d9b5e8-e3a1-4cf7-9f35-221a9784c30d\" />\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Charon-hu",
      "author_type": "User",
      "created_at": "2025-05-07T07:02:35Z",
      "updated_at": "2025-05-07T07:02:35Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2674/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2674",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2674",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:05.054389",
      "comments": []
    },
    {
      "issue_number": 2494,
      "title": "[Doc][源码部署文档] uv部署到LLAMA-CPP报错,windows",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nuv sync --all-packages --frozen --extra \"base\" --extra \"proxy_openai\" --extra \"hf\" --extra \"llama_cpp\" --extra \"rag\" --extra \"storage_chromadb\" --extra \"dbgpts\" --extra \"quant_bnb\"\n  x Failed to build `llama-cpp-python==0.3.7`\n  |-> The build backend returned an error\n  `-> Call to `scikit_build_core.build.build_wheel` failed (exit code: 1)\n\n      [stdout]\n      *** scikit-build-core 0.11.0 using CMake 3.31.6 (wheel)\n      *** Configuring CMake...\n      loading initial cache file C:\\Users\\86189\\AppData\\Local\\Temp\\tmp4c_ck9ux\\build\\CMakeInit.txt\n      -- Building for: NMake Makefiles\n      -- Configuring incomplete, errors occurred!\n\n      [stderr]\n      2025-03-20 20:15:04,783 - scikit_build_core - WARNING - Can't find a Python library, got libdir=None,\n      ldlibrary=None, multiarch=None, masd=None\n      CMake Error at CMakeLists.txt:3 (project):\n        Running\n\n         'nmake' '-?'\n\n        failed with:\n\n         no such file or directory\n\n\n      CMake Error: CMAKE_C_COMPILER not set, after EnableLanguage\n      CMake Error: CMAKE_CXX_COMPILER not set, after EnableLanguage\n\n      *** CMake configuration failed\n\n      hint: This usually indicates a problem with the package or the build environment.\n  help: `llama-cpp-python` (v0.3.7) was included because `dbgpt[llama-cpp]` (v0.7.0) depends on `llama-cpp-python`\n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "panyp5164",
      "author_type": "User",
      "created_at": "2025-03-20T12:24:07Z",
      "updated_at": "2025-05-07T03:23:04Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2494/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2494",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2494",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:05.054410",
      "comments": [
        {
          "author": "fangyinc",
          "body": "See [here](https://github.com/abetlen/llama-cpp-python?tab=readme-ov-file#windows-notes)",
          "created_at": "2025-03-21T02:51:44Z"
        },
        {
          "author": "Belonger",
          "body": "你好请问解决了吗，我看了看还是不太行",
          "created_at": "2025-05-07T03:21:38Z"
        },
        {
          "author": "panyp5164",
          "body": "没有哦\r\n\r\n\r\n\r\n\r\n终点站\r\n***@***.***\r\n\r\n\r\n\r\n&nbsp;\r\n\r\n\r\n\r\n\r\n------------------&nbsp;原始邮件&nbsp;------------------\r\n发件人:                                                                                                                        \"eosphoros-ai/DB-GPT\"                                                ",
          "created_at": "2025-05-07T03:23:03Z"
        }
      ]
    },
    {
      "issue_number": 2548,
      "title": "chat dashboard error: db_name = run_param[\"db_name\"]     | KeyError: 'db_name'",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [x] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nMLU:24GB\n\n### Models information\n\nLLM:Qwen2.5-14B-Instruct\nembedding:text2vec-large-chinese\n\n\n\n### What happened\n\n我使用chatDashboard的时候报错：dbgpt.serve.core.schemas[2398978] ERROR common_exception_handler catch Exception: success=False err_code='E0003' err_msg=\"'db_name'\" data=None\n\nINFO:     111.34.65.59:58644 - \"POST /api/v1/editor/chart/run HTTP/1.1\" 400 Bad Request\nERROR:    Exception in ASGI application\n  + Exception Group Traceback (most recent call last):\n  |   File \"/torch/venv3/pytorch/lib/python3.10/site-packages/starlette/_utils.py\", line 77, in collapse_excgroups\n  |     yield\n  |   File \"/torch/venv3/pytorch/lib/python3.10/site-packages/starlette/middleware/base.py\", line 186, in __call__\n  |     async with anyio.create_task_group() as task_group:\n  |   File \"/torch/venv3/pytorch/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 763, in __aexit__\n  |     raise BaseExceptionGroup(\n  | exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"/torch/venv3/pytorch/lib/python3.10/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 409, in run_asgi\n    |     result = await app(  # type: ignore[func-returns-value]\n    |   File \"/torch/venv3/pytorch/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n    |     return await self.app(scope, receive, send)\n    |   File \"/torch/venv3/pytorch/lib/python3.10/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    |     await self.simple_response(scope, receive, send, request_headers=headers)\n    |   File \"/torch/venv3/pytorch/lib/python3.10/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    |     await self.app(scope, receive, send)\n    |   File \"/torch/venv3/pytorch/lib/python3.10/site-packages/fastapi/applications.py\", line 1054, in __call__\n    |     await super().__call__(scope, receive, send)\n    |   File \"/torch/venv3/pytorch/lib/python3.10/site-packages/starlette/applications.py\", line 113, in __call__\n    |     await self.middleware_stack(scope, receive, send)\n    |   File \"/torch/venv3/pytorch/lib/python3.10/site-packages/starlette/middleware/errors.py\", line 187, in __call__\n    |     raise exc\n    |   File \"/torch/venv3/pytorch/lib/python3.10/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    |     await self.app(scope, receive, _send)\n    |   File \"/torch/venv3/pytorch/lib/python3.10/site-packages/starlette/middleware/base.py\", line 185, in __call__\n    |     with collapse_excgroups():\n    |   File \"/opt/py3.10/lib/python3.10/contextlib.py\", line 153, in __exit__\n    |     self.gen.throw(typ, value, traceback)\n    |   File \"/torch/venv3/pytorch/lib/python3.10/site-packages/starlette/_utils.py\", line 83, in collapse_excgroups\n    |     raise exc\n    |   File \"/torch/venv3/pytorch/lib/python3.10/site-packages/starlette/middleware/base.py\", line 187, in __call__\n    |     response = await self.dispatch_func(request, call_next)\n    |   File \"/dmx/DB-GPT/dbgpt/util/tracer/tracer_middleware.py\", line 49, in dispatch\n    |     response = await call_next(request)\n    |   File \"/torch/venv3/pytorch/lib/python3.10/site-packages/starlette/middleware/base.py\", line 163, in call_next\n    |     raise app_exc\n    |   File \"/torch/venv3/pytorch/lib/python3.10/site-packages/starlette/middleware/base.py\", line 149, in coro\n    |     await self.app(scope, receive_or_disconnect, send_no_error)\n    |   File \"/torch/venv3/pytorch/lib/python3.10/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n    |   File \"/torch/venv3/pytorch/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n    |     raise exc\n    |   File \"/torch/venv3/pytorch/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/torch/venv3/pytorch/lib/python3.10/site-packages/starlette/routing.py\", line 715, in __call__\n    |     await self.middleware_stack(scope, receive, send)\n    |   File \"/torch/venv3/pytorch/lib/python3.10/site-packages/starlette/routing.py\", line 735, in app\n    |     await route.handle(scope, receive, send)\n    |   File \"/torch/venv3/pytorch/lib/python3.10/site-packages/starlette/routing.py\", line 288, in handle\n    |     await self.app(scope, receive, send)\n    |   File \"/torch/venv3/pytorch/lib/python3.10/site-packages/starlette/routing.py\", line 76, in app\n    |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n    |   File \"/torch/venv3/pytorch/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n    |     raise exc\n    |   File \"/torch/venv3/pytorch/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/torch/venv3/pytorch/lib/python3.10/site-packages/starlette/routing.py\", line 73, in app\n    |     response = await f(request)\n    |   File \"/torch/venv3/pytorch/lib/python3.10/site-packages/fastapi/routing.py\", line 301, in app\n    |     raw_response = await run_endpoint_function(\n    |   File \"/torch/venv3/pytorch/lib/python3.10/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    |     return await dependant.call(**values)\n    |   File \"/dmx/DB-GPT/dbgpt/app/openapi/api_v1/editor/api_editor_v1.py\", line 222, in editor_chart_run\n    |     db_name = run_param[\"db_name\"]\n    | KeyError: 'db_name'\n\n\n\n\n### What you expected to happen\n\n我查看了一下好像是前端页面发送请求到这里处理的时候没有拿到db_name这个参数值，就是这行代码处理的时候\nFile \"/dmx/DB-GPT/dbgpt/app/openapi/api_v1/editor/api_editor_v1.py\", line 222, in editor_chart_run\n    |     db_name = run_param[\"db_name\"]\n    | KeyError: 'db_name'\n\n### How to reproduce\n\n使用DB-GPT 0.6.3，llm模型使用如上的qwen，embeding使用如上\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "beiyangli88",
      "author_type": "User",
      "created_at": "2025-03-28T06:29:05Z",
      "updated_at": "2025-05-07T03:16:32Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2548/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2548",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2548",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:05.252679",
      "comments": [
        {
          "author": "dusx1981",
          "body": "你的应用有没有绑定数据库？\n",
          "created_at": "2025-05-07T03:16:31Z"
        }
      ]
    },
    {
      "issue_number": 2281,
      "title": "RAG TuGraph chat ERR",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [X] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice：GPU-GPU count:1-GPU Mermory：16GB\n\n### Models information\n\nLLM:qwen2.5:14b Embedding Model:bge-large-zh-v1.5\n\n### What happened\n\n向量数据库使用Milvus，使用TuGraph构建知识库问答：图已经构建成功，TuGraph里面能看到知识图谱的图结构，在DB-GPT提问时报错:Sorry, We meet some error, please try agin later.\r\n后台报错日志：2025-01-06 23:34:12 syh-MS-7D90 dbgpt.serve.core.schemas[8511] ERROR common_exception_handler catch Exception: success=False err_code='E0003' err_msg=\"<SchemaNotReadyException: (code=1, message=Collection 'ww_COMMUNITY_SUMMARY' not exist, or you can pass in schema to create one.)>\" data=None\r\nERROR:    Exception in ASGI application\r\n  + Exception Group Traceback (most recent call last):\r\n  |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/base.py\", line 188, in __call__\r\n  |     await response(scope, wrapped_receive, send)\r\n  |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/base.py\", line 222, in __call__\r\n  |     async for chunk in self.body_iterator:\r\n  |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/base.py\", line 179, in body_stream\r\n  |     raise app_exc\r\n  |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/base.py\", line 149, in coro\r\n  |     await self.app(scope, receive_or_disconnect, send_no_error)\r\n  |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\r\n  |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\r\n  |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\r\n  |     raise exc\r\n  |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\r\n  |     await app(scope, receive, sender)\r\n  |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/routing.py\", line 715, in __call__\r\n  |     await self.middleware_stack(scope, receive, send)\r\n  |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/routing.py\", line 735, in app\r\n  |     await route.handle(scope, receive, send)\r\n  |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/routing.py\", line 288, in handle\r\n  |     await self.app(scope, receive, send)\r\n  |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/routing.py\", line 76, in app\r\n  |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\r\n  |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\r\n  |     raise exc\r\n  |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\r\n  |     await app(scope, receive, sender)\r\n  |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/routing.py\", line 74, in app\r\n  |     await response(scope, receive, send)\r\n  |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/responses.py\", line 250, in __call__\r\n  |     async with anyio.create_task_group() as task_group:\r\n  |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 767, in __aexit__\r\n  |     raise BaseExceptionGroup(\r\n  | exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\r\n  +-+---------------- 1 ----------------\r\n    | Traceback (most recent call last):\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 409, in run_asgi\r\n    |     result = await app(  # type: ignore[func-returns-value]\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\r\n    |     return await self.app(scope, receive, send)\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/cors.py\", line 93, in __call__\r\n    |     await self.simple_response(scope, receive, send, request_headers=headers)\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\r\n    |     await self.app(scope, receive, send)\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/fastapi/applications.py\", line 1054, in __call__\r\n    |     await super().__call__(scope, receive, send)\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/applications.py\", line 113, in __call__\r\n    |     await self.middleware_stack(scope, receive, send)\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/errors.py\", line 187, in __call__\r\n    |     raise exc\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/errors.py\", line 165, in __call__\r\n    |     await self.app(scope, receive, _send)\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/base.py\", line 185, in __call__\r\n    |     with collapse_excgroups():\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/contextlib.py\", line 153, in __exit__\r\n    |     self.gen.throw(typ, value, traceback)\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/_utils.py\", line 83, in collapse_excgroups\r\n    |     raise exc\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/responses.py\", line 253, in wrap\r\n    |     await func()\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/responses.py\", line 242, in stream_response\r\n    |     async for chunk in self.body_iterator:\r\n    |   File \"/home/syh/DB-GPT/dbgpt/app/openapi/api_v1/api_v1.py\", line 673, in stream_generator\r\n    |     async for chunk in chat.stream_call():\r\n    |   File \"/home/syh/DB-GPT/dbgpt/app/scene/chat_knowledge/v1/chat.py\", line 116, in stream_call\r\n    |     async for output in super().stream_call():\r\n    |   File \"/home/syh/DB-GPT/dbgpt/app/scene/base_chat.py\", line 276, in stream_call\r\n    |     payload = await self._build_model_request()\r\n    |   File \"/home/syh/DB-GPT/dbgpt/app/scene/base_chat.py\", line 208, in _build_model_request\r\n    |     input_values = await self.generate_input_values()\r\n    |   File \"/home/syh/DB-GPT/dbgpt/util/tracer/tracer_impl.py\", line 217, in async_wrapper\r\n    |     return await func(*args, **kwargs)\r\n    |   File \"/home/syh/DB-GPT/dbgpt/app/scene/chat_knowledge/v1/chat.py\", line 157, in generate_input_values\r\n    |     candidates_with_scores = await run_async_tasks(tasks=tasks, concurrency_limit=1)\r\n    |   File \"/home/syh/DB-GPT/dbgpt/util/chat_util.py\", line 47, in run_async_tasks\r\n    |     return await _gather()\r\n    |   File \"/home/syh/DB-GPT/dbgpt/util/chat_util.py\", line 40, in _gather\r\n    |     return await asyncio.gather(\r\n    |   File \"/home/syh/DB-GPT/dbgpt/util/chat_util.py\", line 37, in _execute_task\r\n    |     return await task\r\n    |   File \"/home/syh/DB-GPT/dbgpt/app/scene/chat_knowledge/v1/chat.py\", line 260, in execute_similar_search\r\n    |     return await self._space_retriever.aretrieve_with_scores(\r\n    |   File \"/home/syh/DB-GPT/dbgpt/rag/retriever/base.py\", line 100, in aretrieve_with_scores\r\n    |     return await self._aretrieve_with_score(query, score_threshold, filters)\r\n    |   File \"/home/syh/DB-GPT/dbgpt/serve/rag/retriever/knowledge_space.py\", line 158, in _aretrieve_with_score\r\n    |     return await self._retriever_chain.aretrieve_with_scores(\r\n    |   File \"/home/syh/DB-GPT/dbgpt/rag/retriever/base.py\", line 100, in aretrieve_with_scores\r\n    |     return await self._aretrieve_with_score(query, score_threshold, filters)\r\n    |   File \"/home/syh/DB-GPT/dbgpt/serve/rag/retriever/retriever_chain.py\", line 90, in _aretrieve_with_score\r\n    |     candidates_with_scores = await retriever.aretrieve_with_scores(\r\n    |   File \"/home/syh/DB-GPT/dbgpt/rag/retriever/base.py\", line 100, in aretrieve_with_scores\r\n    |     return await self._aretrieve_with_score(query, score_threshold, filters)\r\n    |   File \"/home/syh/DB-GPT/dbgpt/rag/retriever/embedding.py\", line 209, in _aretrieve_with_score\r\n    |     res_candidates_with_score = await run_async_tasks(\r\n    |   File \"/home/syh/DB-GPT/dbgpt/util/chat_util.py\", line 47, in run_async_tasks\r\n    |     return await _gather()\r\n    |   File \"/home/syh/DB-GPT/dbgpt/util/chat_util.py\", line 40, in _gather\r\n    |     return await asyncio.gather(\r\n    |   File \"/home/syh/DB-GPT/dbgpt/util/chat_util.py\", line 37, in _execute_task\r\n    |     return await task\r\n    |   File \"/home/syh/DB-GPT/dbgpt/rag/retriever/embedding.py\", line 267, in _similarity_search_with_score\r\n    |     return await self._index_store.asimilar_search_with_scores(\r\n    |   File \"/home/syh/DB-GPT/dbgpt/storage/knowledge_graph/community_summary.py\", line 461, in asimilar_search_with_scores\r\n    |     communities = await self._community_store.search_communities(text)\r\n    |   File \"/home/syh/DB-GPT/dbgpt/storage/knowledge_graph/community/community_store.py\", line 65, in search_communities\r\n    |     return await self._meta_store.search(query)\r\n    |   File \"/home/syh/DB-GPT/dbgpt/storage/knowledge_graph/community/community_metastore.py\", line 40, in search\r\n    |     chunks = await self._vector_store.asimilar_search_with_scores(\r\n    |   File \"/home/syh/DB-GPT/dbgpt/rag/index/base.py\", line 220, in asimilar_search_with_scores\r\n    |     return await blocking_func_to_async_no_executor(\r\n    |   File \"/home/syh/DB-GPT/dbgpt/util/executor_utils.py\", line 72, in blocking_func_to_async_no_executor\r\n    |     return await blocking_func_to_async(None, func, *args, **kwargs)  # type: ignore\r\n    |   File \"/home/syh/DB-GPT/dbgpt/util/executor_utils.py\", line 67, in blocking_func_to_async\r\n    |     return await loop.run_in_executor(executor, run_with_context)\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\r\n    |     result = self.fn(*self.args, **self.kwargs)\r\n    |   File \"/home/syh/DB-GPT/dbgpt/util/executor_utils.py\", line 64, in run_with_context\r\n    |     return ctx.run(partial(func, *args, **kwargs))\r\n    |   File \"/home/syh/DB-GPT/dbgpt/storage/vector_store/milvus_store.py\", line 463, in similar_search_with_scores\r\n    |     self.col = Collection(self.collection_name)\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/pymilvus/orm/collection.py\", line 140, in __init__\r\n    |     raise SchemaNotReadyException(\r\n    | pymilvus.exceptions.SchemaNotReadyException: <SchemaNotReadyException: (code=1, message=Collection 'ww_COMMUNITY_SUMMARY' not exist, or you can pass in schema to create one.)>\r\n    +------------------------------------\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\n  + Exception Group Traceback (most recent call last):\r\n  |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/_utils.py\", line 77, in collapse_excgroups\r\n  |     yield\r\n  |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/base.py\", line 186, in __call__\r\n  |     async with anyio.create_task_group() as task_group:\r\n  |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 767, in __aexit__\r\n  |     raise BaseExceptionGroup(\r\n  | exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\r\n  +-+---------------- 1 ----------------\r\n    | Traceback (most recent call last):\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/responses.py\", line 257, in __call__\r\n    |     await wrap(partial(self.listen_for_disconnect, receive))\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/responses.py\", line 253, in wrap\r\n    |     await func()\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/responses.py\", line 230, in listen_for_disconnect\r\n    |     message = await receive()\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/base.py\", line 118, in receive_or_disconnect\r\n    |     async with anyio.create_task_group() as task_group:\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/base.py\", line 126, in receive_or_disconnect\r\n    |     message = await wrap(wrapped_receive)\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/base.py\", line 121, in wrap\r\n    |     result = await func()\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/base.py\", line 51, in wrapped_receive\r\n    |     msg = await self.receive()\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 563, in receive\r\n    |     await self.message_event.wait()\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/asyncio/locks.py\", line 214, in wait\r\n    |     await fut\r\n    | asyncio.exceptions.CancelledError: Cancelled by cancel scope 7234ce13e560\r\n    | \r\n    | During handling of the above exception, another exception occurred:\r\n    | \r\n    | Exception Group Traceback (most recent call last):\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/base.py\", line 188, in __call__\r\n    |     await response(scope, wrapped_receive, send)\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/base.py\", line 222, in __call__\r\n    |     async for chunk in self.body_iterator:\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/base.py\", line 179, in body_stream\r\n    |     raise app_exc\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/base.py\", line 149, in coro\r\n    |     await self.app(scope, receive_or_disconnect, send_no_error)\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\r\n    |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\r\n    |     raise exc\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\r\n    |     await app(scope, receive, sender)\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/routing.py\", line 715, in __call__\r\n    |     await self.middleware_stack(scope, receive, send)\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/routing.py\", line 735, in app\r\n    |     await route.handle(scope, receive, send)\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/routing.py\", line 288, in handle\r\n    |     await self.app(scope, receive, send)\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/routing.py\", line 76, in app\r\n    |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\r\n    |     raise exc\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\r\n    |     await app(scope, receive, sender)\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/routing.py\", line 74, in app\r\n    |     await response(scope, receive, send)\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/responses.py\", line 250, in __call__\r\n    |     async with anyio.create_task_group() as task_group:\r\n    |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 767, in __aexit__\r\n    |     raise BaseExceptionGroup(\r\n    | exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\r\n    +-+---------------- 1 ----------------\r\n      | Traceback (most recent call last):\r\n      |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 409, in run_asgi\r\n      |     result = await app(  # type: ignore[func-returns-value]\r\n      |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\r\n      |     return await self.app(scope, receive, send)\r\n      |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/cors.py\", line 93, in __call__\r\n      |     await self.simple_response(scope, receive, send, request_headers=headers)\r\n      |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\r\n      |     await self.app(scope, receive, send)\r\n      |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/fastapi/applications.py\", line 1054, in __call__\r\n      |     await super().__call__(scope, receive, send)\r\n      |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/applications.py\", line 113, in __call__\r\n      |     await self.middleware_stack(scope, receive, send)\r\n      |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/errors.py\", line 187, in __call__\r\n      |     raise exc\r\n      |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/errors.py\", line 165, in __call__\r\n      |     await self.app(scope, receive, _send)\r\n      |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/base.py\", line 185, in __call__\r\n      |     with collapse_excgroups():\r\n      |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/contextlib.py\", line 153, in __exit__\r\n      |     self.gen.throw(typ, value, traceback)\r\n      |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/_utils.py\", line 83, in collapse_excgroups\r\n      |     raise exc\r\n      |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/responses.py\", line 253, in wrap\r\n      |     await func()\r\n      |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/responses.py\", line 242, in stream_response\r\n      |     async for chunk in self.body_iterator:\r\n      |   File \"/home/syh/DB-GPT/dbgpt/app/openapi/api_v1/api_v1.py\", line 673, in stream_generator\r\n      |     async for chunk in chat.stream_call():\r\n      |   File \"/home/syh/DB-GPT/dbgpt/app/scene/chat_knowledge/v1/chat.py\", line 116, in stream_call\r\n      |     async for output in super().stream_call():\r\n      |   File \"/home/syh/DB-GPT/dbgpt/app/scene/base_chat.py\", line 276, in stream_call\r\n      |     payload = await self._build_model_request()\r\n      |   File \"/home/syh/DB-GPT/dbgpt/app/scene/base_chat.py\", line 208, in _build_model_request\r\n      |     input_values = await self.generate_input_values()\r\n      |   File \"/home/syh/DB-GPT/dbgpt/util/tracer/tracer_impl.py\", line 217, in async_wrapper\r\n      |     return await func(*args, **kwargs)\r\n      |   File \"/home/syh/DB-GPT/dbgpt/app/scene/chat_knowledge/v1/chat.py\", line 157, in generate_input_values\r\n      |     candidates_with_scores = await run_async_tasks(tasks=tasks, concurrency_limit=1)\r\n      |   File \"/home/syh/DB-GPT/dbgpt/util/chat_util.py\", line 47, in run_async_tasks\r\n      |     return await _gather()\r\n      |   File \"/home/syh/DB-GPT/dbgpt/util/chat_util.py\", line 40, in _gather\r\n      |     return await asyncio.gather(\r\n      |   File \"/home/syh/DB-GPT/dbgpt/util/chat_util.py\", line 37, in _execute_task\r\n      |     return await task\r\n      |   File \"/home/syh/DB-GPT/dbgpt/app/scene/chat_knowledge/v1/chat.py\", line 260, in execute_similar_search\r\n      |     return await self._space_retriever.aretrieve_with_scores(\r\n      |   File \"/home/syh/DB-GPT/dbgpt/rag/retriever/base.py\", line 100, in aretrieve_with_scores\r\n      |     return await self._aretrieve_with_score(query, score_threshold, filters)\r\n      |   File \"/home/syh/DB-GPT/dbgpt/serve/rag/retriever/knowledge_space.py\", line 158, in _aretrieve_with_score\r\n      |     return await self._retriever_chain.aretrieve_with_scores(\r\n      |   File \"/home/syh/DB-GPT/dbgpt/rag/retriever/base.py\", line 100, in aretrieve_with_scores\r\n      |     return await self._aretrieve_with_score(query, score_threshold, filters)\r\n      |   File \"/home/syh/DB-GPT/dbgpt/serve/rag/retriever/retriever_chain.py\", line 90, in _aretrieve_with_score\r\n      |     candidates_with_scores = await retriever.aretrieve_with_scores(\r\n      |   File \"/home/syh/DB-GPT/dbgpt/rag/retriever/base.py\", line 100, in aretrieve_with_scores\r\n      |     return await self._aretrieve_with_score(query, score_threshold, filters)\r\n      |   File \"/home/syh/DB-GPT/dbgpt/rag/retriever/embedding.py\", line 209, in _aretrieve_with_score\r\n      |     res_candidates_with_score = await run_async_tasks(\r\n      |   File \"/home/syh/DB-GPT/dbgpt/util/chat_util.py\", line 47, in run_async_tasks\r\n      |     return await _gather()\r\n      |   File \"/home/syh/DB-GPT/dbgpt/util/chat_util.py\", line 40, in _gather\r\n      |     return await asyncio.gather(\r\n      |   File \"/home/syh/DB-GPT/dbgpt/util/chat_util.py\", line 37, in _execute_task\r\n      |     return await task\r\n      |   File \"/home/syh/DB-GPT/dbgpt/rag/retriever/embedding.py\", line 267, in _similarity_search_with_score\r\n      |     return await self._index_store.asimilar_search_with_scores(\r\n      |   File \"/home/syh/DB-GPT/dbgpt/storage/knowledge_graph/community_summary.py\", line 461, in asimilar_search_with_scores\r\n      |     communities = await self._community_store.search_communities(text)\r\n      |   File \"/home/syh/DB-GPT/dbgpt/storage/knowledge_graph/community/community_store.py\", line 65, in search_communities\r\n      |     return await self._meta_store.search(query)\r\n      |   File \"/home/syh/DB-GPT/dbgpt/storage/knowledge_graph/community/community_metastore.py\", line 40, in search\r\n      |     chunks = await self._vector_store.asimilar_search_with_scores(\r\n      |   File \"/home/syh/DB-GPT/dbgpt/rag/index/base.py\", line 220, in asimilar_search_with_scores\r\n      |     return await blocking_func_to_async_no_executor(\r\n      |   File \"/home/syh/DB-GPT/dbgpt/util/executor_utils.py\", line 72, in blocking_func_to_async_no_executor\r\n      |     return await blocking_func_to_async(None, func, *args, **kwargs)  # type: ignore\r\n      |   File \"/home/syh/DB-GPT/dbgpt/util/executor_utils.py\", line 67, in blocking_func_to_async\r\n      |     return await loop.run_in_executor(executor, run_with_context)\r\n      |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\r\n      |     result = self.fn(*self.args, **self.kwargs)\r\n      |   File \"/home/syh/DB-GPT/dbgpt/util/executor_utils.py\", line 64, in run_with_context\r\n      |     return ctx.run(partial(func, *args, **kwargs))\r\n      |   File \"/home/syh/DB-GPT/dbgpt/storage/vector_store/milvus_store.py\", line 463, in similar_search_with_scores\r\n      |     self.col = Collection(self.collection_name)\r\n      |   File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/pymilvus/orm/collection.py\", line 140, in __init__\r\n      |     raise SchemaNotReadyException(\r\n      | pymilvus.exceptions.SchemaNotReadyException: <SchemaNotReadyException: (code=1, message=Collection 'ww_COMMUNITY_SUMMARY' not exist, or you can pass in schema to create one.)>\r\n      +------------------------------------\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 409, in run_asgi\r\n    result = await app(  # type: ignore[func-returns-value]\r\n  File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\r\n    return await self.app(scope, receive, send)\r\n  File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/cors.py\", line 93, in __call__\r\n    await self.simple_response(scope, receive, send, request_headers=headers)\r\n  File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\r\n    await self.app(scope, receive, send)\r\n  File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/fastapi/applications.py\", line 1054, in __call__\r\n    await super().__call__(scope, receive, send)\r\n  File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/applications.py\", line 113, in __call__\r\n    await self.middleware_stack(scope, receive, send)\r\n  File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/errors.py\", line 187, in __call__\r\n    raise exc\r\n  File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/errors.py\", line 165, in __call__\r\n    await self.app(scope, receive, _send)\r\n  File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/base.py\", line 185, in __call__\r\n    with collapse_excgroups():\r\n  File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/contextlib.py\", line 153, in __exit__\r\n    self.gen.throw(typ, value, traceback)\r\n  File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/_utils.py\", line 83, in collapse_excgroups\r\n    raise exc\r\n  File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/responses.py\", line 253, in wrap\r\n    await func()\r\n  File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/responses.py\", line 242, in stream_response\r\n    async for chunk in self.body_iterator:\r\n  File \"/home/syh/DB-GPT/dbgpt/app/openapi/api_v1/api_v1.py\", line 673, in stream_generator\r\n    async for chunk in chat.stream_call():\r\n  File \"/home/syh/DB-GPT/dbgpt/app/scene/chat_knowledge/v1/chat.py\", line 116, in stream_call\r\n    async for output in super().stream_call():\r\n  File \"/home/syh/DB-GPT/dbgpt/app/scene/base_chat.py\", line 276, in stream_call\r\n    payload = await self._build_model_request()\r\n  File \"/home/syh/DB-GPT/dbgpt/app/scene/base_chat.py\", line 208, in _build_model_request\r\n    input_values = await self.generate_input_values()\r\n  File \"/home/syh/DB-GPT/dbgpt/util/tracer/tracer_impl.py\", line 217, in async_wrapper\r\n    return await func(*args, **kwargs)\r\n  File \"/home/syh/DB-GPT/dbgpt/app/scene/chat_knowledge/v1/chat.py\", line 157, in generate_input_values\r\n    candidates_with_scores = await run_async_tasks(tasks=tasks, concurrency_limit=1)\r\n  File \"/home/syh/DB-GPT/dbgpt/util/chat_util.py\", line 47, in run_async_tasks\r\n    return await _gather()\r\n  File \"/home/syh/DB-GPT/dbgpt/util/chat_util.py\", line 40, in _gather\r\n    return await asyncio.gather(\r\n  File \"/home/syh/DB-GPT/dbgpt/util/chat_util.py\", line 37, in _execute_task\r\n    return await task\r\n  File \"/home/syh/DB-GPT/dbgpt/app/scene/chat_knowledge/v1/chat.py\", line 260, in execute_similar_search\r\n    return await self._space_retriever.aretrieve_with_scores(\r\n  File \"/home/syh/DB-GPT/dbgpt/rag/retriever/base.py\", line 100, in aretrieve_with_scores\r\n    return await self._aretrieve_with_score(query, score_threshold, filters)\r\n  File \"/home/syh/DB-GPT/dbgpt/serve/rag/retriever/knowledge_space.py\", line 158, in _aretrieve_with_score\r\n    return await self._retriever_chain.aretrieve_with_scores(\r\n  File \"/home/syh/DB-GPT/dbgpt/rag/retriever/base.py\", line 100, in aretrieve_with_scores\r\n    return await self._aretrieve_with_score(query, score_threshold, filters)\r\n  File \"/home/syh/DB-GPT/dbgpt/serve/rag/retriever/retriever_chain.py\", line 90, in _aretrieve_with_score\r\n    candidates_with_scores = await retriever.aretrieve_with_scores(\r\n  File \"/home/syh/DB-GPT/dbgpt/rag/retriever/base.py\", line 100, in aretrieve_with_scores\r\n    return await self._aretrieve_with_score(query, score_threshold, filters)\r\n  File \"/home/syh/DB-GPT/dbgpt/rag/retriever/embedding.py\", line 209, in _aretrieve_with_score\r\n    res_candidates_with_score = await run_async_tasks(\r\n  File \"/home/syh/DB-GPT/dbgpt/util/chat_util.py\", line 47, in run_async_tasks\r\n    return await _gather()\r\n  File \"/home/syh/DB-GPT/dbgpt/util/chat_util.py\", line 40, in _gather\r\n    return await asyncio.gather(\r\n  File \"/home/syh/DB-GPT/dbgpt/util/chat_util.py\", line 37, in _execute_task\r\n    return await task\r\n  File \"/home/syh/DB-GPT/dbgpt/rag/retriever/embedding.py\", line 267, in _similarity_search_with_score\r\n    return await self._index_store.asimilar_search_with_scores(\r\n  File \"/home/syh/DB-GPT/dbgpt/storage/knowledge_graph/community_summary.py\", line 461, in asimilar_search_with_scores\r\n    communities = await self._community_store.search_communities(text)\r\n  File \"/home/syh/DB-GPT/dbgpt/storage/knowledge_graph/community/community_store.py\", line 65, in search_communities\r\n    return await self._meta_store.search(query)\r\n  File \"/home/syh/DB-GPT/dbgpt/storage/knowledge_graph/community/community_metastore.py\", line 40, in search\r\n    chunks = await self._vector_store.asimilar_search_with_scores(\r\n  File \"/home/syh/DB-GPT/dbgpt/rag/index/base.py\", line 220, in asimilar_search_with_scores\r\n    return await blocking_func_to_async_no_executor(\r\n  File \"/home/syh/DB-GPT/dbgpt/util/executor_utils.py\", line 72, in blocking_func_to_async_no_executor\r\n    return await blocking_func_to_async(None, func, *args, **kwargs)  # type: ignore\r\n  File \"/home/syh/DB-GPT/dbgpt/util/executor_utils.py\", line 67, in blocking_func_to_async\r\n    return await loop.run_in_executor(executor, run_with_context)\r\n  File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\r\n    result = self.fn(*self.args, **self.kwargs)\r\n  File \"/home/syh/DB-GPT/dbgpt/util/executor_utils.py\", line 64, in run_with_context\r\n    return ctx.run(partial(func, *args, **kwargs))\r\n  File \"/home/syh/DB-GPT/dbgpt/storage/vector_store/milvus_store.py\", line 463, in similar_search_with_scores\r\n    self.col = Collection(self.collection_name)\r\n  File \"/home/syh/.conda/envs/dbgpt_env/lib/python3.10/site-packages/pymilvus/orm/collection.py\", line 140, in __init__\r\n    raise SchemaNotReadyException(\r\npymilvus.exceptions.SchemaNotReadyException: <SchemaNotReadyException: (code=1, message=Collection 'ww_COMMUNITY_SUMMARY' not exist, or you can pass in schema to create one.)>\r\nINFO:     127.0.0.1:38218 - \"GET /api/v1/chat/dialogue/list HTTP/1.1\" 200 OK\r\n\n\n### What you expected to happen\n\n错误表明 Milvus 数据库中缺少名为 `ww_COMMUNITY_SUMMARY` 的集合 (`Collection`)。这个集合可能尚未被创建，也可能是应用程序在访问集合之前未能正确初始化。\r\n### 问题的根本原因\r\n1. **错误信息显示：集合不存在。** 表明在数据库中没有定义所需的集合 `ww_COMMUNITY_SUMMARY`。\r\n2. **未提供模式 (schema)** 来定义集合。如果 Milvus 的集合不存在，则需要提供模式来创建集合\n\n### How to reproduce\n\n1、安装tugraph：docker run -d -p 7070:7070  -p 7687:7687 --name tugraph  tugraph/tugraph-runtime-centos7:4.3.2 lgraph_server -d run --enable_plugin true\r\n2、安装Milvus\r\n3、构建tugraph类型的知识库，倒入数据进行提问。\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "syhyfq",
      "author_type": "User",
      "created_at": "2025-01-06T15:39:23Z",
      "updated_at": "2025-05-06T21:05:25Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2281/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2281",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2281",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:05.428550",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "Thanks for your feedback, we will test graphrag community with milvus ",
          "created_at": "2025-01-06T16:08:20Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-05-06T21:05:23Z"
        }
      ]
    },
    {
      "issue_number": 2670,
      "title": "[Bug] [Chat Data] AI模型不理解数据库表结构的定义，导致生成的sql不准确。总是回复我提供的信息不足查询数据，如何优化呢？？？",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [x] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [x] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n无\n\n### Models information\n\nLLM：deepseek-ai/DeepSeek-R1\n\n\n\n### What happened\n\nThe AI model does not understand the definition of database table structure, resulting in inaccurate generated SQL. How can I optimize if the information I provide is insufficient for querying data???\n\n### What you expected to happen\n\nI think the AI model did not understand the definition of the database table, which led to query errors. The AI model replied to me with insufficient information. How can I solve this problem?\n\n### How to reproduce\n\nEnable the model to understand the definition of database tables and generate accurate SQL statements\n\n### Additional context\n\n![Image](https://github.com/user-attachments/assets/12b87e75-db80-4883-b371-21cb30048b79)\n\n![Image](https://github.com/user-attachments/assets/27fb7791-742e-43de-b139-4d0b8d28cc70)\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Kevinyjh123",
      "author_type": "User",
      "created_at": "2025-05-06T09:43:49Z",
      "updated_at": "2025-05-06T09:43:49Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2670/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2670",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2670",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:05.659914",
      "comments": []
    },
    {
      "issue_number": 1279,
      "title": "Can't load plugin: sqlalchemy.dialects:doris",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [X] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [X] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n链接dories库报错\n\n### Models information\n\n1\n\n### What happened\n\n1\n\n### What you expected to happen\n\n1\n\n### How to reproduce\n\n1\n\n### Additional context\n\n1\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "njhouse365",
      "author_type": "User",
      "created_at": "2024-03-12T05:20:17Z",
      "updated_at": "2025-05-06T06:53:37Z",
      "closed_at": "2024-04-18T21:04:39Z",
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1279/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1279",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1279",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:05.659934",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "refer https://github.com/eosphoros-ai/DB-GPT/pull/902",
          "created_at": "2024-03-12T14:51:06Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-04-11T21:04:32Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue bas been closed, because it has been marked as `stale` and there has been no activity for over 7 days.",
          "created_at": "2024-04-18T21:04:39Z"
        },
        {
          "author": "vinartis",
          "body": "这个解决了吗？我用最新版本0.7.1版本，添加doris数据库链接，还是报这个错误\n` File \"/opt/db-gpt/DB-GPT-0.7.1/packages/dbgpt-serve/src/dbgpt_serve/datasource/manages/connector_manager.py\", line 290, in test_connection\n    raise ValueError(f\"Test connection Failure!{str(e)}\")\nValueError: Test connection Failure!Can't load plugin: sqla",
          "created_at": "2025-05-06T06:53:36Z"
        }
      ]
    },
    {
      "issue_number": 2266,
      "title": "[Feature][Vector Store] Support TiDB Vector",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n[dbgpt/storage/vector_store](https://github.com/eosphoros-ai/DB-GPT/tree/main/dbgpt/storage/vector_store)\n\n### Use case\n\nimplement https://github.com/eosphoros-ai/DB-GPT/tree/main/dbgpt/storage/vector_store/base.py\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nMedium\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Weaxs",
      "author_type": "User",
      "created_at": "2025-01-02T07:48:53Z",
      "updated_at": "2025-05-05T21:05:20Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2266/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2266",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2266",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:05.904515",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "We are glad to wait for your tidb vector pr.",
          "created_at": "2025-01-05T14:38:59Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-05-05T21:05:18Z"
        }
      ]
    },
    {
      "issue_number": 2252,
      "title": "[PR][Chat Data] Chat data supports exporting full data",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n1、Chat data 和数据库交互后，产生的记过数据支持导出\r\n2、是全量导出【可以在内部批量导出，然后将导出的文件压缩成一个压缩包 给web导出】\n\n### Use case\n\n增加一个导出按钮在Chat Data的回答界面上支持导出sql结果文件\n\n### Related issues\n\n无\n\n### Feature Priority\n\nMedium\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "luyang-yanglu",
      "author_type": "User",
      "created_at": "2024-12-27T06:56:34Z",
      "updated_at": "2025-05-03T21:04:43Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2252/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2252",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2252",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:06.192767",
      "comments": [
        {
          "author": "luyang-yanglu",
          "body": "请问后续有完善这个功能的规划吗？",
          "created_at": "2025-01-03T02:39:49Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-05-03T21:04:42Z"
        }
      ]
    },
    {
      "issue_number": 2248,
      "title": "[Bug] [Module Name] Bug title document embedding, failed:xxx.pdf, <asyncio.locks.Semaphore object at 0x175938820 [locked]> is bound to a different event loop",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nMacOS(M1, M2...)\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [X] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nLLM:qwen-72B\r\nembedding: bge-large-zh\n\n### What happened\n\n进行Tugraph构建的时候报错：\r\n<img width=\"1415\" alt=\"Snipaste_2024-12-24_16-47-30\" src=\"https://github.com/user-attachments/assets/dfaea2e9-2fe2-4892-8d3d-3fa0840d65d6\" />\r\n\n\n### What you expected to happen\n\n想要使用Tugraph构建DB的关系图，大概有100张表，文件大概有209 KB\n\n### How to reproduce\n\n[database_tables_info.md](https://github.com/user-attachments/files/18237858/database_tables_info.md)\r\n \n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "FlintYu",
      "author_type": "User",
      "created_at": "2024-12-24T08:54:39Z",
      "updated_at": "2025-05-02T21:05:16Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2248/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2248",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2248",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:06.416215",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "\r\nIs there only one pdf? How big is your pdf and is it easy to share?",
          "created_at": "2024-12-24T08:58:06Z"
        },
        {
          "author": "FlintYu",
          "body": "> Is there only one pdf? How big is your pdf and is it easy to share?\r\n\r\nOne Markdown file，the file link has been uploaded to the problem description",
          "created_at": "2024-12-24T09:01:14Z"
        },
        {
          "author": "Aries-ckt",
          "body": "sorry about that, we will test your markdown soon.",
          "created_at": "2024-12-26T02:35:20Z"
        },
        {
          "author": "kenny1109",
          "body": "I encountered the same issue. db-gpt version 0.6.2",
          "created_at": "2024-12-26T07:25:39Z"
        },
        {
          "author": "huicewang",
          "body": "I encountered the same issue. db-gpt version 0.6.3",
          "created_at": "2024-12-27T11:55:05Z"
        }
      ]
    },
    {
      "issue_number": 2620,
      "title": "[Bug] [Module Name] 增加Pg数据库配置后开始频繁崩溃退出",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [x] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU INTEL 集显\n\n### Models information\n\nLLM：qwen2.5:7b\nEmbedding:bge-m3\n\n### What happened\n\n增加postgresql数据库后\n控制台提示：dbgpt.storage.base[17244] INFO Loading 193 chunks in 20 groups with 1 threads.\n执行到dbgpt.storage.base[17244] INFO Loaded 90 chunks, total 193 chunks.时程序退出。\n\n### What you expected to happen\n\n不加数据库没问题，不会报错\n\n### How to reproduce\n\n不知道\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "qile3897",
      "author_type": "User",
      "created_at": "2025-04-14T02:01:20Z",
      "updated_at": "2025-04-30T05:12:19Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2620/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2620",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2620",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:06.660139",
      "comments": [
        {
          "author": "qile3897",
          "body": "重启之后，开始频繁退出。删除pilot/data后，现象复现\n控制台提示：dbgpt.storage.base[17244] INFO Loading 193 chunks in 20 groups with 1 threads.\n执行到dbgpt.storage.base[17244] INFO Loaded 90 chunks, total 193 chunks.时程序退出。",
          "created_at": "2025-04-14T02:02:41Z"
        },
        {
          "author": "QGcPV7EBU58rclpM",
          "body": "+1",
          "created_at": "2025-04-23T06:35:33Z"
        },
        {
          "author": "dusx1981",
          "body": "数据库里面有多少表？",
          "created_at": "2025-04-28T04:02:37Z"
        },
        {
          "author": "dusx1981",
          "body": "有没有非常多列的宽表？",
          "created_at": "2025-04-28T05:30:46Z"
        },
        {
          "author": "John-zzy",
          "body": "我也出现了一样的问题，请问解决了吗？",
          "created_at": "2025-04-30T05:12:17Z"
        }
      ]
    },
    {
      "issue_number": 2666,
      "title": "[Bug] [LLM] dbgp does not support qwen3 calling non-streaming output.",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nMacOS(M1, M2...)\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\n0.7.0\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [x] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\npip install, and version = 0.7.0\n\n### Device information\n\nMAC OS\n\n### Models information\n\nLLM_NAME=qwen3-235b-a22b\nLLM_ENDPOINT=https://dashscope.aliyuncs.com/compatible-mode/v1\n\n### What happened\n\n* This model eray support Stream hec, preabie the scream parameter to acces the model i type teevalid request error a message\nchatmp1-9a39c445-6838-9404-9ecd-87fd32tfdd66', 'request_id\": \"9a390445-6038-9404-9d-87fd32+fd66**\n\n### What you expected to happen\n\nusing LLM generate(), and success\n\n### How to reproduce\n\nusing LLM generate()\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Appointat",
      "author_type": "User",
      "created_at": "2025-04-30T04:11:57Z",
      "updated_at": "2025-04-30T04:13:10Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2666/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2666",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2666",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:06.910481",
      "comments": []
    },
    {
      "issue_number": 2567,
      "title": "文档和代码不一致。文档中说有 .env ,但是代码中没有找到，无论是docker compose 启动还是源码启动，都存在这个问题",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [x] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [x] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\ndevice : CPU\n使用docker compose 和与源码启动\n\n### Models information\n\n=========================== SiliconFlowDeployModelParameters ===========================\n\nname: Qwen/Qwen2.5-Coder-32B-Instruct\nprovider: proxy/siliconflow\nverbose: False\nconcurrency: 100\nbackend: None\nprompt_template: None\ncontext_length: None\nreasoning_model: None\napi_base: https://api.siliconflow.cn/v1\napi_key:\napi_type: None\napi_version: None\nhttp_proxy: None\n\n======================================================================\n\nllm client class: <class 'dbgpt.model.proxy.llms.siliconflow.SiliconFlowLLMClient'>\n2025-03-31 11:00:36 21e2c87d6a35 dbgpt.util.model_utils[1] WARNING Torch not installed, skip clear torch cache\n2025-03-31 11:00:36 21e2c87d6a35 dbgpt.model.cluster.worker.embedding_worker[1] INFO Load embeddings model: BAAI/bge-large-zh-v1.5\n2025-03-31 11:00:38 21e2c87d6a35 dbgpt.util.api_utils[1] WARNING No healthy urls found, selecting randomly\nINFO:     127.0.0.1:54044 - \"POST /api/controller/models HTTP/1.1\" 200 OK\n2025-03-31 11:00:38 21e2c87d6a35 dbgpt.model.cluster.worker.embedding_worker[1] INFO Load rerank embeddings model: BAAI/bge-reranker-v2-m3\nINFO:     127.0.0.1:54062 - \"POST /api/controller/models HTTP/1.1\" 200 OK\n2025-03-31 11:00:39 21e2c87d6a35 dbgpt.model.cluster.worker.manager[1] ERROR Error starting worker manager: model Qwen/Qwen2.5-Coder-32B-Instruct@proxy/siliconflow(172.18.0.3:5670) start failed, Traceback (most recent call last):\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/cluster/worker/manager.py\", line 631, in _start_worker\n    await self.run_blocking_func(\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/cluster/worker/manager.py\", line 146, in run_blocking_func\n    return await loop.run_in_executor(self.executor, func, *args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/cluster/worker/default_worker.py\", line 117, in start\n    self.model, self.tokenizer = self.ml.loader_with_params(\n                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/adapter/loader.py\", line 70, in loader_with_params\n    return llm_adapter.load_from_params(model_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/adapter/proxy_adapter.py\", line 72, in load_from_params\n    proxy_llm_client = dynamic_llm_client_class.new_client(params)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/proxy/llms/chatgpt.py\", line 200, in new_client\n    return cls(\n           ^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/proxy/llms/siliconflow.py\", line 106, in __init__\n    raise ValueError(\nValueError: SiliconFlow API key is required, please set 'SILICONFLOW_API_KEY' in environment or pass it as an argument.\n\n;model BAAI/bge-large-zh-v1.5@proxy/openai(172.18.0.3:5670) start successfully\n;model BAAI/bge-reranker-v2-m3@proxy/siliconflow(172.18.0.3:5670) start successfully\nINFO:     Shutting down\nINFO:     Waiting for application shutdown.\n2025-03-31 11:00:39 21e2c87d6a35 dbgpt.model.cluster.worker.manager[1] INFO Stop all workers\n2025-03-31 11:00:39 21e2c87d6a35 dbgpt.model.cluster.worker.manager[1] INFO Apply req: None, apply_func: <function LocalWorkerManager._stop_all_worker.<locals>._stop_worker at 0x7fcd524a2ac0>\n2025-03-31 11:00:39 21e2c87d6a35 dbgpt.model.cluster.worker.manager[1] INFO Apply to all workers\n2025-03-31 11:00:39 21e2c87d6a35 dbgpt.model.cluster.worker.default_worker[1] WARNING Model has been stopped!!\n2025-03-31 11:00:39 21e2c87d6a35 dbgpt.model.cluster.worker.manager[1] WARNING Stop worker, ignored exception from deregister_func: All connection attempts failed\n2025-03-31 11:00:39 21e2c87d6a35 dbgpt.util.model_utils[1] WARNING Torch not installed, skip clear torch cache\n2025-03-31 11:00:39 21e2c87d6a35 dbgpt.util.model_utils[1] WARNING Torch not installed, skip clear torch cache\n2025-03-31 11:00:39 21e2c87d6a35 dbgpt.model.cluster.worker.manager[1] WARNING Stop worker, ignored exception from deregister_func: All connection attempts failed\n2025-03-31 11:00:39 21e2c87d6a35 dbgpt.model.cluster.worker.manager[1] WARNING Stop worker, ignored exception from deregister_func: All connection attempts failed\n2025-03-31 11:00:39 21e2c87d6a35 dbgpt.model.cluster.worker.manager[1] WARNING Stop worker, ignored exception from deregister_func: All connection attempts failed\nINFO:     Application shutdown complete.\nINFO:     Finished server process [1]\nin order to avoid chroma db atexit problem\n\n### What happened\n\n1，源码启动，出现了文档和代码的不一致\n代码中没有找到.env 文件\n![Image](https://github.com/user-attachments/assets/20746212-0167-4449-a8e3-cdb5cd41aef5)\n\n2.docker compose 启动出现了问题\n找不到环境变量的配置，文档中的启动和实际的代码不一致\n\n![Image](https://github.com/user-attachments/assets/d59cb698-dadd-4303-bbf2-5f18d4e813fe)\n\nLibro Server start!\nstart libro exception！[Errno 2] No such file or directory: 'libro'\n2025-03-31 11:00:36 21e2c87d6a35 dbgpt.model.cluster.worker.manager[1] INFO Begin start all worker, apply_req: None\n2025-03-31 11:00:36 21e2c87d6a35 dbgpt.model.cluster.worker.manager[1] INFO Apply req: None, apply_func: <function LocalWorkerManager._start_all_worker.<locals>._start_worker at 0x7fcd524a2e80>\n2025-03-31 11:00:36 21e2c87d6a35 dbgpt.model.cluster.worker.manager[1] INFO Apply to all workers\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://0.0.0.0:5670 (Press CTRL+C to quit)\n2025-03-31 11:00:36 21e2c87d6a35 dbgpt.model.cluster.worker.default_worker[1] INFO Begin load model, model params:\n\n=========================== SiliconFlowDeployModelParameters ===========================\n\nname: Qwen/Qwen2.5-Coder-32B-Instruct\nprovider: proxy/siliconflow\nverbose: False\nconcurrency: 100\nbackend: None\nprompt_template: None\ncontext_length: None\nreasoning_model: None\napi_base: https://api.siliconflow.cn/v1\napi_key:\napi_type: None\napi_version: None\nhttp_proxy: None\n\n======================================================================\n\n\n2025-03-31 11:00:36 21e2c87d6a35 dbgpt.model.adapter.proxy_adapter[1] INFO Load model from params:\n\n=========================== SiliconFlowDeployModelParameters ===========================\n\nname: Qwen/Qwen2.5-Coder-32B-Instruct\nprovider: proxy/siliconflow\nverbose: False\nconcurrency: 100\nbackend: None\nprompt_template: None\ncontext_length: None\nreasoning_model: None\napi_base: https://api.siliconflow.cn/v1\napi_key:\napi_type: None\napi_version: None\nhttp_proxy: None\n\n======================================================================\n\nllm client class: <class 'dbgpt.model.proxy.llms.siliconflow.SiliconFlowLLMClient'>\n2025-03-31 11:00:36 21e2c87d6a35 dbgpt.util.model_utils[1] WARNING Torch not installed, skip clear torch cache\n2025-03-31 11:00:36 21e2c87d6a35 dbgpt.model.cluster.worker.embedding_worker[1] INFO Load embeddings model: BAAI/bge-large-zh-v1.5\n2025-03-31 11:00:38 21e2c87d6a35 dbgpt.util.api_utils[1] WARNING No healthy urls found, selecting randomly\nINFO:     127.0.0.1:54044 - \"POST /api/controller/models HTTP/1.1\" 200 OK\n2025-03-31 11:00:38 21e2c87d6a35 dbgpt.model.cluster.worker.embedding_worker[1] INFO Load rerank embeddings model: BAAI/bge-reranker-v2-m3\nINFO:     127.0.0.1:54062 - \"POST /api/controller/models HTTP/1.1\" 200 OK\n2025-03-31 11:00:39 21e2c87d6a35 dbgpt.model.cluster.worker.manager[1] ERROR Error starting worker manager: model Qwen/Qwen2.5-Coder-32B-Instruct@proxy/siliconflow(172.18.0.3:5670) start failed, Traceback (most recent call last):\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/cluster/worker/manager.py\", line 631, in _start_worker\n    await self.run_blocking_func(\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/cluster/worker/manager.py\", line 146, in run_blocking_func\n    return await loop.run_in_executor(self.executor, func, *args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/cluster/worker/default_worker.py\", line 117, in start\n    self.model, self.tokenizer = self.ml.loader_with_params(\n                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/adapter/loader.py\", line 70, in loader_with_params\n    return llm_adapter.load_from_params(model_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/adapter/proxy_adapter.py\", line 72, in load_from_params\n    proxy_llm_client = dynamic_llm_client_class.new_client(params)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/proxy/llms/chatgpt.py\", line 200, in new_client\n    return cls(\n           ^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/proxy/llms/siliconflow.py\", line 106, in __init__\n    raise ValueError(\nValueError: SiliconFlow API key is required, please set 'SILICONFLOW_API_KEY' in environment or pass it as an argument.\n\n;model BAAI/bge-large-zh-v1.5@proxy/openai(172.18.0.3:5670) start successfully\n;model BAAI/bge-reranker-v2-m3@proxy/siliconflow(172.18.0.3:5670) start successfully\nINFO:     Shutting down\nINFO:     Waiting for application shutdown.\n2025-03-31 11:00:39 21e2c87d6a35 dbgpt.model.cluster.worker.manager[1] INFO Stop all workers\n2025-03-31 11:00:39 21e2c87d6a35 dbgpt.model.cluster.worker.manager[1] INFO Apply req: None, apply_func: <function LocalWorkerManager._stop_all_worker.<locals>._stop_worker at 0x7fcd524a2ac0>\n2025-03-31 11:00:39 21e2c87d6a35 dbgpt.model.cluster.worker.manager[1] INFO Apply to all workers\n2025-03-31 11:00:39 21e2c87d6a35 dbgpt.model.cluster.worker.default_worker[1] WARNING Model has been stopped!!\n2025-03-31 11:00:39 21e2c87d6a35 dbgpt.model.cluster.worker.manager[1] WARNING Stop worker, ignored exception from deregister_func: All connection attempts failed\n2025-03-31 11:00:39 21e2c87d6a35 dbgpt.util.model_utils[1] WARNING Torch not installed, skip clear torch cache\n2025-03-31 11:00:39 21e2c87d6a35 dbgpt.util.model_utils[1] WARNING Torch not installed, skip clear torch cache\n2025-03-31 11:00:39 21e2c87d6a35 dbgpt.model.cluster.worker.manager[1] WARNING Stop worker, ignored exception from deregister_func: All connection attempts failed\n2025-03-31 11:00:39 21e2c87d6a35 dbgpt.model.cluster.worker.manager[1] WARNING Stop worker, ignored exception from deregister_func: All connection attempts failed\n2025-03-31 11:00:39 21e2c87d6a35 dbgpt.model.cluster.worker.manager[1] WARNING Stop worker, ignored exception from deregister_func: All connection attempts failed\nINFO:     Application shutdown complete.\nINFO:     Finished server process [1]\nin order to avoid chroma db atexit problem\n\n\n### What you expected to happen\n\n文档要和代码一致，不要出现文档中的启动和实际代码不一致的问题，\n\n### How to reproduce\n\ngit clone DB-GPT \ncd  DB-GPT\ndocker compose up -d \n容器可以启动成功，但是程序运行报错\n\n![Image](https://github.com/user-attachments/assets/e6ab382f-b152-4340-8d5d-4021e7a8fa6c)\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "dshwei",
      "author_type": "User",
      "created_at": "2025-04-01T02:54:00Z",
      "updated_at": "2025-04-30T03:26:48Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2567/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2567",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2567",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:06.910501",
      "comments": [
        {
          "author": "Fangpeng-77",
          "body": "可以参考最新的版本安装方法。\n英文：http://docs.dbgpt.cn/docs/next/installation/sourcecode/\n中文(0.7.0)：https://www.yuque.com/eosphoros/dbgpt-docs/nh6zd314859l38qa\n",
          "created_at": "2025-04-01T11:34:48Z"
        },
        {
          "author": "lizhouyang",
          "body": "因为docker-compose中设置了/data映射，去掉之后，docker-compose起来了。`SILICONFLOW_API_KEY=${SILICONFLOW_API_KEY} docker compose up -d`也设置了。\n但是报如下错误。\nValueError: Invalid data for ModelsDeployParameters: Invalid list element type: Invalid data for EmbeddingDeployModelParameters: Unknown type value: proxy/siliconflow, k",
          "created_at": "2025-04-24T08:42:08Z"
        },
        {
          "author": "lifx2015",
          "body": "应该镜像出问题了，请更新最新的代码，在docker-compose.yml中，添加如下配置- ./:/app。重新启动应该就可以，如果不行就删除镜像，重新启动就可以了\n\n![Image](https://github.com/user-attachments/assets/5bd343eb-5558-45f1-b386-c0d1a882e52d)",
          "created_at": "2025-04-25T16:20:49Z"
        },
        {
          "author": "echo-ikun",
          "body": "> ### Search before asking\n> * [x]  I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n> \n> ### Operating system information\n> Linux\n> \n> ### Python version information\n> > =3.11\n> \n> ### DB-GPT version\n> main\n> \n> ### Related scen",
          "created_at": "2025-04-30T03:26:47Z"
        }
      ]
    },
    {
      "issue_number": 2259,
      "title": "[Feature]Support user login and and user permissions.",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n_No response_\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "godchou",
      "author_type": "User",
      "created_at": "2024-12-30T03:12:47Z",
      "updated_at": "2025-04-29T21:05:23Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2259/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2259",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2259",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:07.087792",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "hi, thanks your suggestion, we provide `user_code`, `sys_code` in every table schemas, we hope community developers will  \r\nimplement it.",
          "created_at": "2024-12-30T05:51:02Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-04-29T21:05:22Z"
        }
      ]
    },
    {
      "issue_number": 2260,
      "title": "[Bug] [chat data] table schema haven't comment",
      "body": "### Search before asking\r\n\r\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\r\n\r\n\r\n### Operating system information\r\n\r\nWindows\r\n\r\n### Python version information\r\n\r\n3.10\r\n\r\n### DB-GPT version\r\n\r\nmain\r\n\r\n### Related scenes\r\n\r\n- [X] Chat Data\r\n- [ ] Chat Excel\r\n- [ ] Chat DB\r\n- [ ] Chat Knowledge\r\n- [ ] Model Management\r\n- [ ] Dashboard\r\n- [ ] Plugins\r\n\r\n### Installation Information\r\n\r\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\r\n\r\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\r\n\r\n- [ ] AutoDL Image\r\n- [ ] Other\r\n\r\n### Device information\r\n\r\n- 4090\r\n- GPU Count: 1\r\n- GPU Memory: 24G\r\n\r\n### Models information\r\n\r\nm3e\r\n\r\n### What happened\r\n\r\n表结构定义没有表注释信息导致查询不到内容\r\n![image](https://github.com/user-attachments/assets/d0ffeba5-f78c-4ca7-b9b6-0963fab693f1)\r\n\r\n\r\n### What you expected to happen\r\n\r\nmessages:\r\n[{'role': 'system', 'content': '\\n请根据用户选择的数据库和该库的部分可用表结构定义来回答用户问题.\\n数据库名:\\n    gzt_boot\\n表结构定义:\\n    [(\\'ops_task_order(trouble_level_id,ops_team_manager_opinion,safe_production_opinion,safe_production_user_name,safe_production_user_account,safe_producti ... (742 characters truncated) ... om_point_name,custom_point_id,ops_team_name,custom_dept_id,custom_company_name,custom_company_id,start_user_name,start_user_account,start_user_id,fi)\\',)]\\n\\n约束:\\n    1. 请根据用户问题理解用户意图，使用给出表结构定义创建一个语法正确的 mysql sql，如果不需要sql，则直接回答用户问题。\\n    2. 除非用户在问题中指定了他希望获得的具体数据行数，否则始终将查询限制为最多 50 个结果。\\n    3. 只能使用表结构信息中提供的表来生成 sql，如果无法根据提供的表结构中生成 sql ，请说：“提供的表结构信息不足以生成 sql 查询。” 禁止随意捏造信息。\\n    4. 请注意生成SQL时不要弄错表和列的关系。\\n   12. 请从如下给出的展示方式种选择最优的一种用以进行数据渲染，将类型名称放入返回要求格式的name参数值种，如果找不到最合适的则使用\\'Table\\'作为展示方式，可用数据展示方式如下: response_line_chart:used to display comparative trend analysis data. 当需要展示折线图时使用.\\nresponse_bar_chart:used to display comparative trend analysis data. 当需要展示条形图时使用.\\nresponse_column_chart:used to display comparative trend analysis data. 当需要展示柱状图时使用.\\nresponse_pie_chart:suitable for scenarios such as proportion and distribution statistics\\nresponse_table:suitable for display with many display columns or non-numeric columns\\nresponse_scatter_plot:Suitable for exploring relationships between variables, detecting outliers, etc.\\nresponse_bubble_chart:Suitable for relationships between multiple variables, highlighting outliers or special situations, etc.\\nresponse_donut_chart:Suitable for hierarchical structure representation, category proportion display and highlighting key categories, etc.\\nresponse_area_chart:Suitable for visualization of time series data, comparison of multiple groups of data, analysis of data change trends, etc.\\nresponse_heatmap:Suitable for visual analysis of time series data, large-scale data sets, distribution of classified data, etc.\\n用户问题:\\n    故障类别占比情况\\n请一步步思考并按照以下JSON格式回复：\\n      \"{\\\\n    \\\\\"thoughts\\\\\": \\\\\"thoughts summary to say to user\\\\\",\\\\n    \\\\\"sql\\\\\": \\\\\"SQL Query to run\\\\\",\\\\n    \\\\\"display_type\\\\\": \\\\\"Data display method\\\\\"\\\\n}\"\\n确保返回正确的json并且可以被Python json.loads方法解析.\\n必须使用用户提问的语言进行回复\\n\\n'}, {'role': 'user', 'content': '故障类别占比情况'}]\r\nllm_adapter: <OpenAIProxyLLMModelAdapter model_name=proxyllm model_path=chatgpt_proxyllm>\r\n\r\nmodel prompt: \r\n\r\nsystem: \r\n请根据用户选择的数据库和该库的部分可用表结构定义来回答用户问题.\r\n数据库名:\r\n    gzt_boot\r\n表结构定义:\r\n    [('ops_task_order(trouble_level_id,ops_team_manager_opinion,safe_production_opinion,safe_production_user_name,safe_production_user_account,safe_producti ... (742 characters truncated) ... om_point_name,custom_point_id,ops_team_name,custom_dept_id,custom_company_name,custom_company_id,start_user_name,start_user_account,start_user_id,fi)',)]\r\n\r\n约束:\r\n    1. 请根据用户问题理解用户意图，使用给出表结构定义创建一个语法正确的 mysql sql，如果不需要sql，则直接回答用户问题。\r\n    2. 除非用户在问题中指定了他希望获得的具体数据行数，否则始终将查询限制为最多 50 个结果。\r\n    3. 只能使用表结构信息中提供的表来生成 sql，如果无法根据提供的表结构中生成 sql ，请说：“提供的表结构信息不足以生成 sql 查询。” 禁止随意捏造信息。\r\n    4. 请注意生成SQL时不要弄错表和列的关系。\r\n\r\n### How to reproduce\r\n\r\nnone\r\n\r\n### Additional context\r\n\r\n_No response_\r\n\r\n### Are you willing to submit PR?\r\n\r\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "305607610",
      "author_type": "User",
      "created_at": "2024-12-30T03:22:13Z",
      "updated_at": "2025-04-29T07:39:36Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 10,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2260/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2260",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2260",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:07.269631",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "hi, are there any comment in your mysql table schema?",
          "created_at": "2024-12-30T05:49:10Z"
        },
        {
          "author": "305607610",
          "body": "![image](https://github.com/user-attachments/assets/ff008507-85d1-4607-a48e-9be00d6c8e30)\r\n",
          "created_at": "2024-12-30T06:10:08Z"
        },
        {
          "author": "Aries-ckt",
          "body": "what's your dbgpt version and how many columns in this table?",
          "created_at": "2024-12-31T03:52:39Z"
        },
        {
          "author": "305607610",
          "body": "version: v0.6.3\r\n84 columns ",
          "created_at": "2024-12-31T06:49:32Z"
        },
        {
          "author": "Aries-ckt",
          "body": "hi, try delete the datasource in dbgpt web, and add the ops_task_order again.\r\nand when delete the datasource, make sure DB-GPT/pilot/data/{datasource_name}.vectordb is deleted.",
          "created_at": "2025-01-01T14:59:09Z"
        }
      ]
    },
    {
      "issue_number": 2663,
      "title": "[Feature][model] Support Qwen3 models",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nThe Qwen3 series models are about to be released and we need to support these models.\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "fangyinc",
      "author_type": "User",
      "created_at": "2025-04-28T09:51:26Z",
      "updated_at": "2025-04-29T01:55:29Z",
      "closed_at": "2025-04-29T01:55:29Z",
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2663/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2663",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2663",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:07.499554",
      "comments": []
    },
    {
      "issue_number": 2662,
      "title": "[Bug] [Module Name] 使用dbgpt_hub微调之后的权重推理报错“找不到adapter”",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [x] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU:3090*1\n\n### Models information\n\nLLM：codellama/CodeLlama-7b-Instruct-hf（自定义）\nadapter_config.json：\n```\n{\n  \"auto_mapping\": null,\n  \"base_model_name_or_path\": \"codellama/CodeLlama-7b-Instruct-hf\",\n  \"bias\": \"none\",\n  \"fan_in_fan_out\": false,\n  \"inference_mode\": true,\n  \"init_lora_weights\": true,\n  \"layers_pattern\": null,\n  \"layers_to_transform\": null,\n  \"lora_alpha\": 32.0,\n  \"lora_dropout\": 0.1,\n  \"modules_to_save\": null,\n  \"peft_type\": \"LORA\",\n  \"r\": 64,\n  \"revision\": null,\n  \"target_modules\": [\n    \"q_proj\",\n    \"v_proj\"\n  ],\n  \"task_type\": \"CAUSAL_LM\"\n}\n```\n\n### What happened\n\n在dbgpt_hub基础上用qlora策略在spider数据集上面微调了codellama7b，微调之后测试推理都正常，adapter_config.json参数如下：\n```\n {\n  \"auto_mapping\": null,\n  \"base_model_name_or_path\": \"codellama/CodeLlama-7b-Instruct-hf\",\n  \"bias\": \"none\",\n  \"fan_in_fan_out\": false,\n  \"inference_mode\": true,\n  \"init_lora_weights\": true,\n  \"layers_pattern\": null,\n  \"layers_to_transform\": null,\n  \"lora_alpha\": 32.0,\n  \"lora_dropout\": 0.1,\n  \"modules_to_save\": null,\n  \"peft_type\": \"LORA\",\n  \"r\": 64,\n  \"revision\": null,\n  \"target_modules\": [\n    \"q_proj\",\n    \"v_proj\"\n  ],\n  \"task_type\": \"CAUSAL_LM\"\n}\n```\n\n自定义了一个config.toml文件用于dbgpt启动：\n```\n[system]\n# Load language from environment variable(It is set by the hook)\nlanguage = \"${env:DBGPT_LANG:-zh}\"\napi_keys = []\nencrypt_key = \"your_secret_key\"\n\n# Server Configurations\n[service.web]\nhost = \"0.0.0.0\"\nport = 5670\n\n[service.web.database]\ntype = \"sqlite\"\npath = \"pilot/meta_data/dbgpt.db\"\n\n[rag.storage]\n[rag.storage.vector]\ntype = \"chroma\"\npersist_path = \"pilot/data\"\n\n# Model Configurations\n[models]\n[[models.llms]]\nname = \"codellama/CodeLlama-7b-Instruct-hf\"\npath = \"models/CodeLlama-7b-instruct-qlora\"\n\n\n[[models.embeddings]]\nname = \"BAAI/bge-large-zh-v1.5\"\nprovider = \"hf\"\npath = \"models/BAAI/bge-large-zh-v1.5\"\n```\n\n报错如下：\n\n```\nFile \"/data/lylin/DB-GPT-main/.venv/lib/python3.11/site-packages/click/core.py\", line 1697, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/lylin/DB-GPT-main/.venv/lib/python3.11/site-packages/click/core.py\", line 1443, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/lylin/DB-GPT-main/.venv/lib/python3.11/site-packages/click/core.py\", line 788, in invoke\n    return __callback(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/lylin/DB-GPT-main/packages/dbgpt-core/src/dbgpt/model/cli.py\", line 458, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/lylin/DB-GPT-main/packages/dbgpt-app/src/dbgpt_app/_cli.py\", line 25, in start_webserver\n    run_webserver(config)\n  File \"/data/lylin/DB-GPT-main/packages/dbgpt-app/src/dbgpt_app/dbgpt_server.py\", line 244, in run_webserver\n    param = initialize_app(param)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/lylin/DB-GPT-main/packages/dbgpt-app/src/dbgpt_app/dbgpt_server.py\", line 159, in initialize_app\n    initialize_worker_manager_in_client(\n  File \"/data/lylin/DB-GPT-main/packages/dbgpt-core/src/dbgpt/model/cluster/worker/manager.py\", line 1244, in initialize_worker_manager_in_client\n    _start_local_worker(\n  File \"/data/lylin/DB-GPT-main/packages/dbgpt-core/src/dbgpt/model/cluster/worker/manager.py\", line 1168, in _start_local_worker\n    worker_manager.worker_manager.add_worker(\n  File \"/data/lylin/DB-GPT-main/packages/dbgpt-core/src/dbgpt/model/cluster/worker/manager.py\", line 228, in add_worker\n    worker.load_worker(model_name, deploy_model_params)\n  File \"/data/lylin/DB-GPT-main/packages/dbgpt-core/src/dbgpt/model/cluster/worker/default_worker.py\", line 74, in load_worker\n    self.llm_adapter = get_llm_model_adapter(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/lylin/DB-GPT-main/packages/dbgpt-core/src/dbgpt/model/adapter/model_adapter.py\", line 61, in get_llm_model_adapter\n    raise ValueError(f\"Can not find adapter for model {model_name}\")\nValueError: Can not find adapter for model codellama/CodeLlama-7b-Instruct-hf\n```\n\n### What you expected to happen\n\n我认为应该有自动读取adapter_config.json并且自动适配的能力，使代码可以兼容自己微调后的模型，猜想应该要修改`model_adapter.py`\n\n### How to reproduce\n\n我是这样启动后报错的：uv run dbgpt start webserver --config configs/dbgpt-local-codellama.toml\n但是我无法把握的模型文件整个传上来\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Lylinnnnn",
      "author_type": "User",
      "created_at": "2025-04-28T02:28:46Z",
      "updated_at": "2025-04-28T05:47:43Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2662/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2662",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2662",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:07.499578",
      "comments": [
        {
          "author": "Lylinnnnn",
          "body": "手动更改了get_llm_model_adapter函数之后可以正确运行：\n```\n@cache\ndef get_llm_model_adapter(\n    model_name: str,\n    model_path: Optional[str] = None,\n    use_fastchat: bool = True,\n    use_fastchat_monkey_patch: bool = False,\n    model_type: str = None,\n) -> LLMModelAdapter:\n    # 添加调试信息\n    logger.info(f\"尝试查找适配器:",
          "created_at": "2025-04-28T05:47:41Z"
        }
      ]
    },
    {
      "issue_number": 2652,
      "title": "[BUG]0.7.0版本使用chatdata功能后台似乎没有把字段的数据类型、备注等信息上传给大模型",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nlinux\n\n### Models information\n\n0.7.0\n\n### What happened\n\n使用chatdata功能后台似乎没有把字段的数据类型、备注等信息上传给大模型，而是只是简单的字段名称，我使用的是0.7.0，0.6.3版本后台的上传的信息是对的，反倒是版本0.7.0的信息上传只有类似于  表名(字段1名称，字段2名称..............)请问有解决办法吗，我初步debug一下感觉问题是出在pilot/data那里，0.6.3版本会在那里创建一个缓存文件，好像0.7.0版本我在那个文件夹找不到类似的文件\n\n### What you expected to happen\n\n上传备注等信息给大模型\n\n### How to reproduce\n\n。\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "zzzsudo",
      "author_type": "User",
      "created_at": "2025-04-24T08:10:40Z",
      "updated_at": "2025-04-28T03:57:37Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2652/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2652",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2652",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:07.672184",
      "comments": [
        {
          "author": "zzzsudo",
          "body": "具体的后台信息如下\n`[{'role': 'system', 'content': '\\n请根据用户选择的数据库和该库的部分可用表结构定义来回答用户问题.\\n数据库名:\\n    case_1_student_manager\\n表结构定义:\\n    [(\\'courses(course_id,course_name,credit)\\',), (\\'scores(student_id,course_id,score,semester)\\',), (\\'students(student_id,student_name,major,year_of_enrollment,student_age)\\'",
          "created_at": "2025-04-24T08:14:44Z"
        },
        {
          "author": "dusx1981",
          "body": "查看 Databaseknowledge 相关代码",
          "created_at": "2025-04-28T03:57:36Z"
        }
      ]
    },
    {
      "issue_number": 2462,
      "title": "[Doc][源码部署文档]源码部署文档按照步骤走不下去呢？",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n源码部署文档按照步骤走不下去呢？\n1、.env.template不在跟目录，web目录下有一个\n2、$ python dbgpt/app/dbgpt_server.py 这个也无法执行，整个目录不存在，也没写怎么生成\n建议检查一下整个文档\n\n\n### Documentation Links\n\nhttps://www.yuque.com/eosphoros/dbgpt-docs/urh3fcx8tu0s9xmb#kG6eq\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "haochenhh",
      "author_type": "User",
      "created_at": "2025-03-14T02:05:37Z",
      "updated_at": "2025-04-27T11:43:34Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2462/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2462",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2462",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:07.882836",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "最新分支部署参考http://docs.dbgpt.cn/docs/next/quickstart",
          "created_at": "2025-03-14T05:26:42Z"
        },
        {
          "author": "Fangpeng-77",
          "body": "1.最新版本使用的是uv管理安装包，具体链接：http://docs.dbgpt.cn/docs/next/quickstart\n2.如果是服务器部署，uv无法解决网络镜像/网络不可达的问题，则可在本地使用uv部署好之后，使用pip将包导出到requirements.txt中，在服务器端使用pip -i 重新安装对应的包，即可解决。",
          "created_at": "2025-03-23T15:18:54Z"
        },
        {
          "author": "FaderYin",
          "body": "小白哭晕在厕所，刚下的conda\n",
          "created_at": "2025-04-27T11:43:33Z"
        }
      ]
    },
    {
      "issue_number": 2659,
      "title": "[Bug] [Module Name] 'NoneType' object has no attribute 'replace'",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\ndeepseek-r1:7b\n\n### What happened\n\nI create an app according to  https://www.yuque.com/eosphoros/dbgpt-docs/aiagvxeb86iarq6r\nWhen I try to chat the app, it shows: Sorry, We meet some error, please try agin later.\n\nThe log:\n\ndbgpt_serve.core.schemas[23092] ERROR common_exception_handler catch Exception: success=False err_code='E0003' err_msg=\"'NoneType' object has no attribute 'replace'\" data=None\nERROR:    Exception in ASGI application\n  + Exception Group Traceback (most recent call last):\n  |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\_utils.py\", line 77, in collapse_excgroups\n  |     yield\n  |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\middleware\\base.py\", line 186, in __call__\n  |     async with anyio.create_task_group() as task_group:\n  |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 772, in __aexit__\n  |     raise BaseExceptionGroup(\n  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Exception Group Traceback (most recent call last):\n    |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\middleware\\base.py\", line 188, in __call__\n    |     await response(scope, wrapped_receive, send)\n    |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\middleware\\base.py\", line 222, in __call__\n    |     async for chunk in self.body_iterator:\n    |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\middleware\\base.py\", line 179, in body_stream\n    |     raise app_exc\n    |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\middleware\\base.py\", line 149, in coro\n    |     await self.app(scope, receive_or_disconnect, send_no_error)\n    |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 62, in __call__    |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n    |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 62, in wrapped_app    |     raise exc\n    |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 51, in wrapped_app    |     await app(scope, receive, sender)\n    |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\routing.py\", line 715, in __call__\n    |     await self.middleware_stack(scope, receive, send)\n    |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\routing.py\", line 735, in app\n    |     await route.handle(scope, receive, send)\n    |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\routing.py\", line 288, in handle\n    |     await self.app(scope, receive, send)\n    |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\routing.py\", line 76, in app\n    |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n    |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 62, in wrapped_app    |     raise exc\n    |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 51, in wrapped_app    |     await app(scope, receive, sender)\n    |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\routing.py\", line 74, in app\n    |     await response(scope, receive, send)\n    |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\responses.py\", line 250, in __call__\n    |     async with anyio.create_task_group() as task_group:\n    |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 772, in __aexit__\n    |     raise BaseExceptionGroup(\n    | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n    +-+---------------- 1 ----------------\n      | Traceback (most recent call last):\n      |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\uvicorn\\protocols\\http\\httptools_impl.py\", line 409, in run_asgi\n      |     result = await app(  # type: ignore[func-returns-value]\n      |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n      |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 60, in __call__\n      |     return await self.app(scope, receive, send)\n      |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n      |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\middleware\\cors.py\", line 93, in __call__\n      |     await self.simple_response(scope, receive, send, request_headers=headers)\n      |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\middleware\\cors.py\", line 144, in simple_response\n      |     await self.app(scope, receive, send)\n      |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\fastapi\\applications.py\", line 1054, in __call__\n      |     await super().__call__(scope, receive, send)\n      |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\applications.py\", line 113, in __call__\n      |     await self.middleware_stack(scope, receive, send)\n      |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 187, in __call__\n      |     raise exc\n      |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 165, in __call__\n      |     await self.app(scope, receive, _send)\n      |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\middleware\\base.py\", line 185, in __call__\n      |     with collapse_excgroups():\n      |   File \"C:\\Users\\nancy.jiang\\AppData\\Roaming\\uv\\python\\cpython-3.11.12-windows-x86_64-none\\Lib\\contextlib.py\", line 158, in __exit__\n      |     self.gen.throw(typ, value, traceback)\n      |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\_utils.py\", line 83, in collapse_excgroups\n      |     raise exc\n      |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\responses.py\", line 253, in wrap\n      |     await func()\n      |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\responses.py\", line 242, in stream_response\n      |     async for chunk in self.body_iterator:\n      |   File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\packages\\dbgpt-serve\\src\\dbgpt_serve\\agent\\agents\\controller.py\", line 472, in app_agent_chat\n      |     default_final_message = default_final_message.replace(\"data:\", \"\")\n      |                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n      | AttributeError: 'NoneType' object has no attribute 'replace'\n      +------------------------------------\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\uvicorn\\protocols\\http\\httptools_impl.py\", line 409, in run_asgi\n    result = await app(  # type: ignore[func-returns-value]\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 60, in __call__\n    return await self.app(scope, receive, send)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\middleware\\cors.py\", line 93, in __call__\n    await self.simple_response(scope, receive, send, request_headers=headers)\n  File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\middleware\\cors.py\", line 144, in simple_response\n    await self.app(scope, receive, send)\n  File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\fastapi\\applications.py\", line 1054, in __call__\n    await super().__call__(scope, receive, send)\n  File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\applications.py\", line 113, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 187, in __call__\n    raise exc\n  File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 165, in __call__\n    await self.app(scope, receive, _send)\n  File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\middleware\\base.py\", line 185, in __call__\n    with collapse_excgroups():\n  File \"C:\\Users\\nancy.jiang\\AppData\\Roaming\\uv\\python\\cpython-3.11.12-windows-x86_64-none\\Lib\\contextlib.py\", line 158, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\_utils.py\", line 83, in collapse_excgroups\n    raise exc\n  File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\responses.py\", line 253, in wrap\n    await func()\n  File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\.venv\\Lib\\site-packages\\starlette\\responses.py\", line 242, in stream_response\n    async for chunk in self.body_iterator:\n  File \"D:\\ai\\dbgpt\\dbgpt\\DB-GPT\\packages\\dbgpt-serve\\src\\dbgpt_serve\\agent\\agents\\controller.py\", line 472, in app_agent_chat\n    default_final_message = default_final_message.replace(\"data:\", \"\")\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'NoneType' object has no attribute 'replace'\n\n\n### What you expected to happen\n\nFix it.\n\n### How to reproduce\n\nhttps://www.yuque.com/eosphoros/dbgpt-docs/aiagvxeb86iarq6r\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "appleteamwh",
      "author_type": "User",
      "created_at": "2025-04-27T07:33:09Z",
      "updated_at": "2025-04-27T07:33:09Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2659/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2659",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2659",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:08.054712",
      "comments": []
    },
    {
      "issue_number": 2657,
      "title": "[Bug] [Module Name] milvus 无法对数据库创建collection，但是没有数据",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice: GPU\nGPU Count: 1\nGPU Memory: 12G\n\n### Models information\n\nLLM:l Qwen/Qwen2.5-Coder-32B-Instruct \nembedding model: BAAI/bge-m3\npymilvus 版本：  2.5.7\n\n### What happened\n\n服务启动的时候，milvus 总是能够创建collection，但是collection下面没有数据\n\n### What you expected to happen\n\n期望：\n1、milvus collection 能够正常创建\n2、collection可以存数数据表基本信息和字段信息\n\n### How to reproduce\n\n切换配置到milvus ，启动即可。pymilvus 版本：2.5.7\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "lifx2015",
      "author_type": "User",
      "created_at": "2025-04-25T15:56:26Z",
      "updated_at": "2025-04-27T02:55:04Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2657/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2657",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2657",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:08.054736",
      "comments": [
        {
          "author": "lifx2015",
          "body": "文件 ![Image](https://github.com/user-attachments/assets/385c7a41-cf10-4998-bec9-75b85e75b0a0) table_vector_connector, field_vector_connector = (\n            self._get_vector_connector_by_db(dbname)\n        ) 总是先只执行，table_vector_connector就会被创建。那么这个代码 if not table_vector_connector.vector_name_exists():",
          "created_at": "2025-04-25T15:59:58Z"
        },
        {
          "author": "zzzsudo",
          "body": "请问怎么切换到milvus",
          "created_at": "2025-04-27T02:20:02Z"
        },
        {
          "author": "zzzsudo",
          "body": "好像用choma也有这个问题，有解决的办法吗",
          "created_at": "2025-04-27T02:55:04Z"
        }
      ]
    },
    {
      "issue_number": 2247,
      "title": "awel with sub DAG",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [X] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n1\n\n### Models information\n\n1\n\n### What happened\n\n自定义了一个awel operator里整合了几个基础operator，并初始化了相应的dag流程，但在最外层dag中执行会报错\r\n![image](https://github.com/user-attachments/assets/ac20392e-a6d6-470f-b697-09a1fc70572d)\r\n报错信息如下：\r\n<img width=\"574\" alt=\"8f77a44ede29c24119336db36e7b417\" src=\"https://github.com/user-attachments/assets/b3fedb5b-d9d0-48fb-9c18-abeaf4ab6474\" />\r\n\n\n### What you expected to happen\n\n为了简化一些配置操作，想要将多个operator再封装一下来提供出去，这样方便处理比较复杂的分支流程。想要在外层dag中正常执行这个整合operator\n\n### How to reproduce\n\ndag中嵌套一个dag\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "paul-yangmy",
      "author_type": "User",
      "created_at": "2024-12-24T08:06:47Z",
      "updated_at": "2025-04-26T21:04:56Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2247/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2247",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2247",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:08.333777",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "Now AWEL don't support Nested DAG",
          "created_at": "2024-12-26T08:40:53Z"
        },
        {
          "author": "paul-yangmy",
          "body": "谢谢~我按照这个示例AppChatComposerOperator，它在算子内部自定义了一个dag，然后通过 node.call 来调用得",
          "created_at": "2024-12-27T01:31:33Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-04-26T21:04:55Z"
        }
      ]
    },
    {
      "issue_number": 2254,
      "title": "[Bug] [model] AsyncAnthropic.__init__() got an unexpected keyword argument 'proxies'",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nMacOS(M1, M2...)\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [X] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nPython3.11\r\nanthropic 0.42.0\n\n### Models information\n\n```    \r\n@property\r\n    def client(self) -> \"AsyncAnthropic\":\r\n        from anthropic import AsyncAnthropic\r\n\r\n        if self._client is None:\r\n            self._client = AsyncAnthropic(\r\n                api_key=self._api_key,\r\n                base_url=self._api_base,\r\n                proxies=self._proxies,\r\n                timeout=self._timeout,\r\n            )\r\n            \r\n```   \n\n### What happened\n\n```\r\n**Claude Generate Error, Please CheckErrorInfo.**: AsyncAnthropic.__init__() got an unexpected keyword argument 'proxies'\r\n```\n\n### What you expected to happen\n\nIt should generate normally.\n\n### How to reproduce\n\n```\r\n        self._llm_client: LLMClient = ClaudeLLMClient(\r\n            model_alias=****\r\n            api_base=***,\r\n            api_key=***,\r\n        )\r\n```\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Appointat",
      "author_type": "User",
      "created_at": "2024-12-27T09:41:07Z",
      "updated_at": "2025-04-26T21:04:55Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2254/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 1,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2254",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2254",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:10.389848",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-04-26T21:04:54Z"
        }
      ]
    },
    {
      "issue_number": 2245,
      "title": "[Bug] [Module Name] document chunk edit error",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [X] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU\r\nGPU Count:2\r\nGPU Memory:96G\n\n### Models information\n\nLLM: \r\nQwen2.5-72b-Instruct(Ollama)\r\nEmbedding model:\r\nnomic-embed-text\n\n### What happened\n\nWhen Adding question to a chunk in the knowledge database, I got th efollowing error:\r\ndocument chunk edit error (builtins.TypeError) SQLite DateTime type only accepts Python datetime and date objects as input. [SQL: UPDATE document_chunk SET questions=?, gmt_created=?, gmt_modified=? WHERE document_chunk.id = ?] [parameters: [{'questions': '[\"异味溯源场景的项目背景\"]', 'gmt_modified': '2024-12-24 10:08:25.984710', 'gmt_created': '2024-12-24 10:08:25.984708', 'document_chunk_id': 9061}]]\r\n\n\n### What you expected to happen\n\nThe question supposed to be added succussfully to a chunk as I did before.\n\n### How to reproduce\n\n1. Source Code Deployment\r\n2. Deploy Ollama\r\n3. Construct a knowledge database\r\n4. Click \"详情\"\r\n5. Click the chunk\r\n6. Click \"添加问题\"\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Carlycjl",
      "author_type": "User",
      "created_at": "2024-12-24T02:49:45Z",
      "updated_at": "2025-04-25T21:05:14Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2245/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2245",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2245",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:10.556754",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "what's your local_db_type in .env?\r\n",
          "created_at": "2024-12-26T08:41:43Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-04-25T21:05:13Z"
        }
      ]
    },
    {
      "issue_number": 2250,
      "title": "[Feature]Chat Data Module support  show db schema at web",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nChat DB\\Chat Data两个内置app，能否将内置的”数据库结构到知识库“这一步的结果知识库展示出来？\r\n并提供编辑按钮，方便使用者自主调整改进知识库内容；\r\n原因就是为了更好的自主管理、改进知识库。\n\n### Use case\n\nChat DB\\Chat Data关联数据库后，自动产生的内置知识库显式展示在知识库模块内\n\n### Related issues\n\n社区的钉钉群内，已经多次提出过这个需求\n\n### Feature Priority\n\nHigh\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "luyang-yanglu",
      "author_type": "User",
      "created_at": "2024-12-25T09:06:24Z",
      "updated_at": "2025-04-25T21:05:13Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2250/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2250",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2250",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:10.745646",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "感谢你的反馈，我们也在思考这部分能力应该怎么在产品侧去体现，后面会对这部分内容进行增强.",
          "created_at": "2024-12-26T02:32:43Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-04-25T21:05:12Z"
        }
      ]
    },
    {
      "issue_number": 2251,
      "title": "[Bug] [TuGraph] When creating RuGraphRAG, no chunk node and document node was created",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nMacOS(M1, M2...)\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [X] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nLLM:qwen-72B\r\nembedding: bge-large-zh\n\n### What happened\n\n创建TuGraph知识库的时候不会创建 chunk node 和 document node，\r\n创建的结构如下\r\n![image](https://github.com/user-attachments/assets/90b7c831-aa66-452a-8cf5-db2d863cc994)\r\n\n\n### What you expected to happen\n\n应该在创建完成后，创建chunk node 和 document node\n\n### How to reproduce\n\n使用的Markdown文件如下构建TuGraph知识库\r\n[小红帽的故事.md](https://github.com/user-attachments/files/18245686/default.md)\r\n\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "FlintYu",
      "author_type": "User",
      "created_at": "2024-12-25T11:29:55Z",
      "updated_at": "2025-04-25T21:05:12Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2251/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2251",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2251",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:10.938350",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "```\r\nGRAPH_STORE_TYPE=TuGraph\r\nTUGRAPH_HOST=127.0.0.1\r\nTUGRAPH_PORT=7687\r\nTUGRAPH_USERNAME=admin\r\nTUGRAPH_PASSWORD=73@TuGraph\r\nGRAPH_COMMUNITY_SUMMARY_ENABLED=True  # enable the graph community summary\r\nTRIPLET_GRAPH_ENABLED=True  # enable the graph search for the triplets\r\nDOCUMENT_GRAPH_ENABLED=Tr",
          "created_at": "2024-12-26T08:38:47Z"
        },
        {
          "author": "FlintYu",
          "body": "> ```\r\n> GRAPH_STORE_TYPE=TuGraph\r\n> TUGRAPH_HOST=127.0.0.1\r\n> TUGRAPH_PORT=7687\r\n> TUGRAPH_USERNAME=admin\r\n> TUGRAPH_PASSWORD=73@TuGraph\r\n> GRAPH_COMMUNITY_SUMMARY_ENABLED=True  # enable the graph community summary\r\n> TRIPLET_GRAPH_ENABLED=True  # enable the graph search for the triplets\r\n> DOCUMEN",
          "created_at": "2024-12-26T12:54:57Z"
        },
        {
          "author": "Aries-ckt",
          "body": " check your graph db schema?\r\n![image](https://github.com/user-attachments/assets/2a48e265-e560-4cfa-92fe-b0fd06887534)\r\n",
          "created_at": "2024-12-26T15:23:07Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-04-25T21:05:10Z"
        }
      ]
    },
    {
      "issue_number": 2656,
      "title": "如何更改可视化的风格样式呢？",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n如何更改可视化的风格样式呢？\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "kingsaction",
      "author_type": "User",
      "created_at": "2025-04-25T09:30:29Z",
      "updated_at": "2025-04-25T09:30:29Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2656/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2656",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2656",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:11.145265",
      "comments": []
    },
    {
      "issue_number": 2645,
      "title": "[Feature][Module Name] How to increase default max_new_tokens",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nHow to increase default max_new_tokens, 4000 is not enough. I find a ChatDashboardConfig Configuration parameter, but seems not working\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "liaoweiguo",
      "author_type": "User",
      "created_at": "2025-04-23T03:42:20Z",
      "updated_at": "2025-04-24T09:29:40Z",
      "closed_at": "2025-04-24T09:29:40Z",
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2645/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2645",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2645",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:11.145292",
      "comments": []
    },
    {
      "issue_number": 2024,
      "title": "[Bug] [ChatData] parse_view_response error!Can not find sql in response",
      "body": "### Search before asking\r\n\r\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\r\n\r\n\r\n### Operating system information\r\n\r\nLinux\r\n\r\n### Python version information\r\n\r\n>=3.11\r\n\r\n### DB-GPT version\r\n\r\nmain\r\n\r\n### Related scenes\r\n\r\n- [X] Chat Data\r\n- [ ] Chat Excel\r\n- [ ] Chat DB\r\n- [ ] Chat Knowledge\r\n- [ ] Model Management\r\n- [ ] Dashboard\r\n- [ ] Plugins\r\n\r\n### Installation Information\r\n\r\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\r\n\r\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\r\n\r\n- [X] AutoDL Image\r\n- [ ] Other\r\n\r\n### Device information\r\n\r\n镜像: eosphoros-ai/DB-GPT/dbgpt:v0.5.10\r\nGPU: RTX 4090D(24GB) * 1\r\nCPU: 16 vCPU Intel(R) Xeon(R) Platinum 8481C\r\n内存: 80GB\r\n硬盘: 30 GB\r\n\r\n### Models information\r\n\r\nLLM: qwen2-0.5b-instruct\r\n\r\n### What happened\r\n\r\nWhen using ChatData, the returned JSON is not in a qualified format, Causing inability to parse SQL.\r\n\r\n### What you expected to happen\r\n\r\nReturn the correct JSON format\r\n\r\n### How to reproduce\r\n\r\n1. Create container with AutoDL Images, version is: eosphoros-ai/DB-GPT/dbgpt:v0.5.10\r\n2. Import my MySQL datasource.\r\n3. Use chatdata module.\r\n4. Return incorrect JSON format\r\n\r\n### Additional context\r\n\r\n```\r\n2024-09-18 10:10:47 autodl-container-a1364fba4b-1ef9d419 dbgpt.app.scene.chat_db.auto_execute.out_parser[1278] ERROR json load failed:{      \"thoughts \":  \"There are several validation rules to be included in this system.           \"sql \":  \"SELECT COUNT(*) AS total_rules FROM audit_rules WHERE status='active'      \"}\r\n```\r\n\r\n### Are you willing to submit PR?\r\n\r\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "MilkWangStudio",
      "author_type": "User",
      "created_at": "2024-09-18T02:20:57Z",
      "updated_at": "2025-04-24T08:13:16Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2024/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2024",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2024",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:11.145301",
      "comments": [
        {
          "author": "ygbingo",
          "body": "我也遇到了这个问题，用的0.6.0的镜像，也是大模型回复的内容解析json失败，导致无法提取sql字段",
          "created_at": "2024-09-18T05:26:08Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-16T21:04:55Z"
        },
        {
          "author": "taojinglong",
          "body": "解决了么？",
          "created_at": "2025-04-24T08:13:14Z"
        }
      ]
    },
    {
      "issue_number": 2646,
      "title": "[Bug] [Module Name] ERROR model response parse failed！'old_column_name'",
      "body": "### Desc\n**LLM**: qwen2.5:32b   _same issues with qwq32/gemma3: 27b_\n**Embeddings**: bge-m3:latest\n\n_db-gpt version: v0.7\ndb-gpt install with ollama proxy_\n\n**ollama proxy config** \n```\n# Model Configurations\n[models]\n[[models.llms]]\nname = \"qwen2.5:32b\"\nprovider = \"proxy/ollama\"\napi_base = \"http://10.9.100.44:11434\"\napi_key = \"\"\n\n[[models.embeddings]]\nname = \"bge-m3:latest\"\nprovider = \"proxy/ollama\"\napi_url = \"http://10.9.100.39:11434\"\napi_key = \"\"\n```\n\n### Errors\n\nUse the example.xlsx file provided by the official repo \n\n![Image](https://github.com/user-attachments/assets/2f867843-1df2-408c-9454-45ae498993e7)\n\n![Image](https://github.com/user-attachments/assets/b4937811-639b-4f51-9831-b56bdf0cbaa6)\n",
      "state": "open",
      "author": "ming12713",
      "author_type": "User",
      "created_at": "2025-04-23T08:59:41Z",
      "updated_at": "2025-04-23T09:11:39Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2646/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2646",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2646",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:11.341455",
      "comments": []
    },
    {
      "issue_number": 2637,
      "title": "[Bug] [Chat] Chat Failed, build agent_memory failed",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nLLM proxy deepseek\nEmbedding: proxy bge-m3\n\n### What happened\n\n![Image](https://github.com/user-attachments/assets/fd7bf672-beb4-4547-ae05-662326220b48)\nAn error occurred when creating a Chroma Collection, _agent_memory_ does not comply with the naming convention\n\n2025-04-19 12:12:54 tam dbgpt_serve.agent.agents.controller[55700] ERROR Chat to App ad7c11e2-151a-11f0-afc6-04ed33eb9690 Failed!Expected collection name that (1) contains 3-63 characters, (2) starts and ends with an alphanumeric character, (3) otherwise contains only alphanumeric characters, underscores or hyphens (-), (4) contains no two consecutive periods (..) and (5) is not a valid IPv4 address, got _agent_memory_\nTraceback (most recent call last):\n  File \"D:\\workspace\\backend\\my\\DB-GPT\\packages\\dbgpt-serve\\src\\dbgpt_serve\\agent\\agents\\controller.py\", line 441, in app_agent_chat\n    async for task, chunk, agent_conv_id in multi_agents.agent_chat_v2(\n  File \"D:\\workspace\\backend\\my\\DB-GPT\\packages\\dbgpt-serve\\src\\dbgpt_serve\\agent\\agents\\controller.py\", line 319, in agent_chat_v2\n    agent_memory = self.get_or_build_agent_memory(conv_id, gpts_name)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\workspace\\backend\\my\\DB-GPT\\packages\\dbgpt-serve\\src\\dbgpt_serve\\agent\\agents\\controller.py\", line 148, in get_or_build_agent_memory\n    vector_store.create_collection(collection_name=index_name)\n  File \"D:\\workspace\\backend\\my\\DB-GPT\\packages\\dbgpt-ext\\src\\dbgpt_ext\\storage\\vector_store\\chroma_store.py\", line 152, in create_collection\n    return self._chroma_client.get_or_create_collection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\workspace\\backend\\my\\DB-GPT\\.venv\\Lib\\site-packages\\chromadb\\api\\client.py\", line 194, in get_or_create_collection\n    model = self._server.get_or_create_collection(\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\workspace\\backend\\my\\DB-GPT\\.venv\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py\", line 150, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"D:\\workspace\\backend\\my\\DB-GPT\\.venv\\Lib\\site-packages\\chromadb\\api\\segment.py\", line 103, in wrapper\n    return self._rate_limit_enforcer.rate_limit(func)(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\workspace\\backend\\my\\DB-GPT\\.venv\\Lib\\site-packages\\chromadb\\rate_limit\\simple_rate_limit\\__init__.py\", line 24, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\workspace\\backend\\my\\DB-GPT\\.venv\\Lib\\site-packages\\chromadb\\api\\segment.py\", line 288, in get_or_create_collection\n    return self.create_collection(\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\workspace\\backend\\my\\DB-GPT\\.venv\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py\", line 150, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"D:\\workspace\\backend\\my\\DB-GPT\\.venv\\Lib\\site-packages\\chromadb\\api\\segment.py\", line 103, in wrapper\n    return self._rate_limit_enforcer.rate_limit(func)(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\workspace\\backend\\my\\DB-GPT\\.venv\\Lib\\site-packages\\chromadb\\rate_limit\\simple_rate_limit\\__init__.py\", line 24, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\workspace\\backend\\my\\DB-GPT\\.venv\\Lib\\site-packages\\chromadb\\api\\segment.py\", line 218, in create_collection\n    check_index_name(name)\n  File \"D:\\workspace\\backend\\my\\DB-GPT\\.venv\\Lib\\site-packages\\chromadb\\api\\segment.py\", line 92, in check_index_name\n    raise ValueError(msg)\nValueError: Expected collection name that (1) contains 3-63 characters, (2) starts and ends with an alphanumeric character, (3) otherwise contains only alphanumeric characters, underscores or hyphens (-), (4) contains no two consecutive periods (..) and (5) is not a valid IPv4 address, got _agent_memory_\n\n### What you expected to happen\n\nchat sucess\n\n### How to reproduce\n\nPull the latest code\nCreate a conversation\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "vnicers",
      "author_type": "User",
      "created_at": "2025-04-19T04:23:38Z",
      "updated_at": "2025-04-23T05:49:57Z",
      "closed_at": "2025-04-23T05:49:56Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2637/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2637",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2637",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:11.341479",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "it looks like agent memory collection name is not allowed started or ended with \"_\".",
          "created_at": "2025-04-20T15:42:37Z"
        },
        {
          "author": "liam1985",
          "body": "I have encountered the same bug, and fix it by stripping the beginning and ending '_'.",
          "created_at": "2025-04-22T06:22:57Z"
        }
      ]
    },
    {
      "issue_number": 2643,
      "title": "[Feature][Module Name] Feature title: how to classify user prompt and query related KB in workflow",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nlike fastgpt workflow\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "liaoweiguo",
      "author_type": "User",
      "created_at": "2025-04-23T02:18:45Z",
      "updated_at": "2025-04-23T02:18:45Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2643/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2643",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2643",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:11.537990",
      "comments": []
    },
    {
      "issue_number": 2207,
      "title": "[Bug]Native APP chat not supported call API",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [X] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [X] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU COUNT:2\r\n24G\n\n### Models information\n\nLLM: chatglm4-9b\r\nembedding: m3e\n\n### What happened\n\ncall POST /api/v2/chat/completions\r\n DBGPT_API_KEY=dbgpt\r\n APP_ID={YOUR_APP_ID}\r\n\r\n curl -X POST \"http://localhost:5670/api/v2/chat/completions\" \\\r\n    -H \"Authorization: Bearer $DBGPT_API_KEY\" \\\r\n    -H \"accept: application/json\" \\\r\n    -H \"Content-Type: application/json\" \\\r\n    -d \"{\\\"messages\\\":\\\"Hello\\\",\\\"model\\\":\\\"chatgpt_proxyllm\\\", \\\"chat_mode\\\": \\\"chat_app\\\", \\\"chat_param\\\": \\\"$APP_ID\\\"}\"\r\n\r\n报错：‘Native APP chat not supported’\r\n\n\n### What you expected to happen\n\n可是我需要调用chat data这个应用的对话功能，怎么样可以正常调用API呢\n\n### How to reproduce\n\n希望可以通过API调用与native APP的对话\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Sloane9511",
      "author_type": "User",
      "created_at": "2024-12-16T07:32:21Z",
      "updated_at": "2025-04-22T21:05:15Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2207/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2207",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2207",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:11.538004",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "Sorry about that,  try http://docs.dbgpt.cn/docs/api/datasource",
          "created_at": "2024-12-16T15:49:21Z"
        },
        {
          "author": "Sloane9511",
          "body": "many thanks!",
          "created_at": "2024-12-23T00:58:59Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-04-22T21:05:14Z"
        }
      ]
    },
    {
      "issue_number": 2238,
      "title": "[Bug] [Module Name] Code Dict to Model Request Operator does't work.os error 10049",
      "body": "### Search before asking\r\n\r\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\r\n\r\n\r\n### Operating system information\r\n\r\nWindows\r\n\r\n### Python version information\r\n\r\n3.10\r\n\r\n### DB-GPT version\r\n\r\n0.6.2\r\n\r\n### Related scenes\r\n\r\n- [ ] Chat Data\r\n- [ ] Chat Excel\r\n- [ ] Chat DB\r\n- [ ] Chat Knowledge\r\n- [ ] Model Management\r\n- [ ] Dashboard\r\n- [ ] Plugins\r\n\r\n### Installation Information\r\n\r\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\r\n\r\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\r\n\r\n- [ ] AutoDL Image\r\n- [ ] Other\r\n\r\n### Device information\r\n\r\ncpu\r\n\r\n### Models information\r\n\r\nqwen\r\n\r\n### What happened\r\n\r\n相同代码和相同的awel在同事电脑上可以正常运行。\r\n\r\n环境：conda python=3.10\r\n现象：awel中的Code Dict to Model Request Operator算子无法运行，报错如下：\r\n\r\n2024-12-22 12:37:51 LAPTOP-FQBK0DM0 dbgpt.util.code.server[14680] INFO Code server is ready\r\n2024-12-22 12:37:51 LAPTOP-FQBK0DM0 dbgpt.util.code.server[14680] INFO <lyric.driver.DefaultLyricDriver object at 0x000001C2B496DDB0>\r\n2024-12-22 12:37:51 LAPTOP-FQBK0DM0 dbgpt.app.operators.code[14680] INFO Code execution result: CodeResult(exit_code=1, stdout='', stderr='failed to invoke `lyric:task/interpreter-task@0.2.0.run1`\\n\\nCaused by:\\n    0: failed to invoke function\\n    1: 在其上下文中，该请求的地址无效。 (os error 10049)', output=None)\r\n2024-12-22 12:37:51 LAPTOP-FQBK0DM0 dbgpt.core.awel.runner.local_runner[14680] INFO Run operator <class 'dbgpt.app.operators.code.CodeDictToModelRequestOperator'>(5d52943e-cae3-4fb3-86c7-da41a00c7afa) error, error message: Traceback (most recent call last):\r\n  File \"E:\\project\\Auto-DB-GPT\\dbgpt\\core\\awel\\runner\\local_runner.py\", line 192, in _execute_node\r\n    await node._run(dag_ctx, task_ctx.log_id)\r\n  File \"E:\\project\\Auto-DB-GPT\\dbgpt\\core\\awel\\operators\\base.py\", line 248, in _run\r\n    return await self._do_run(dag_ctx)\r\n  File \"E:\\project\\Auto-DB-GPT\\dbgpt\\core\\awel\\operators\\common_operator.py\", line 190, in _do_run\r\n    input_ctx: InputContext = await curr_task_ctx.task_input.map(map_function)\r\n  File \"E:\\project\\Auto-DB-GPT\\dbgpt\\core\\awel\\task\\task_impl.py\", line 538, in map\r\n    new_outputs, results = await self._apply_func(map_func)\r\n  File \"E:\\project\\Auto-DB-GPT\\dbgpt\\core\\awel\\task\\task_impl.py\", line 533, in _apply_func\r\n    results = await asyncio.gather(*map_tasks)\r\n  File \"E:\\project\\Auto-DB-GPT\\dbgpt\\core\\awel\\task\\task_impl.py\", line 126, in map\r\n    out = await self._apply_func(map_func)\r\n  File \"E:\\project\\Auto-DB-GPT\\dbgpt\\core\\awel\\task\\task_impl.py\", line 112, in _apply_func\r\n    out = await func(self._data)\r\n  File \"E:\\project\\Auto-DB-GPT\\dbgpt\\app\\operators\\code.py\", line 311, in map\r\n    raise RuntimeError(f\"Code execution failed: {result.logs}\")\r\nRuntimeError: Code execution failed:\r\nfailed to invoke `lyric:task/interpreter-task@0.2.0.run1`\r\n\r\nCaused by:\r\n    0: failed to invoke function\r\n    1: 在其上下文中，该请求的地址无效。 (os error 10049)\r\n\r\n\r\n### What you expected to happen\r\n\r\nAble to run python code\r\n\r\n### How to reproduce\r\npython >= 3.10\r\nconda create -n dbgpt_env python=3.10\r\nconda activate dbgpt_env\r\npip install -e \".[default]\"\r\n\r\nAny workflow that uses Code Dict to Model Request Operator cannot be executed\r\n\r\n### Additional context\r\n\r\n_No response_\r\n\r\n### Are you willing to submit PR?\r\n\r\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "ggKe",
      "author_type": "User",
      "created_at": "2024-12-22T04:58:35Z",
      "updated_at": "2025-04-22T21:05:12Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2238/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2238",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2238",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:11.731903",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "what's your os, windows? and what is your colleague's os?  ",
          "created_at": "2024-12-22T16:08:03Z"
        },
        {
          "author": "ggKe",
          "body": "> what's your os, windows? and what is your colleague's os?\r\n\r\nmy os is windows11,my colleague's os macos。\r\nI found a new windows environment to install python and conda, and still reported the same error.",
          "created_at": "2024-12-23T01:15:11Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-04-22T21:05:11Z"
        }
      ]
    },
    {
      "issue_number": 2223,
      "title": "[Bug] [Module Name] Bug title Create DAG awel_flow_rag_chat_example_copy error, define_type: json, error: Unable to build operator task: operator_llm_operator___$$___llm___$$___v1_0, operator_cls: <class 'dbgpt.app.operators.llm.BaseHOLLMOperator'>, error: BaseHOLLMOperator.__init__() missing 1 required positional argument: 'prompt_template'",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU 2 MEMORY=80G\n\n### Models information\n\nLLm:glm-4-9b \r\nembedding:text2_chinese\n\n### What happened\n\n复制awel_flow_rag_chat_example工作流时候出现报错\r\nCreate DAG awel_flow_rag_chat_example_copy error, define_type: json, error: Unable to build operator task: operator_llm_operator___$$___llm___$$___v1_0, operator_cls: <class 'dbgpt.app.operators.llm.BaseHOLLMOperator'>, error: BaseHOLLMOperator.__init__() missing 1 required positional argument: 'prompt_template'\n\n### What you expected to happen\n\n复制awel_flow_rag_chat_example工作流时候出现报错\r\nCreate DAG awel_flow_rag_chat_example_copy error, define_type: json, error: Unable to build operator task: operator_llm_operator___$$___llm___$$___v1_0, operator_cls: <class 'dbgpt.app.operators.llm.BaseHOLLMOperator'>, error: BaseHOLLMOperator.__init__() missing 1 required positional argument: 'prompt_template'\n\n### How to reproduce\n\n复制awel_flow_rag_chat_example工作流时候出现报错\r\nCreate DAG awel_flow_rag_chat_example_copy error, define_type: json, error: Unable to build operator task: operator_llm_operator___$$___llm___$$___v1_0, operator_cls: <class 'dbgpt.app.operators.llm.BaseHOLLMOperator'>, error: BaseHOLLMOperator.__init__() missing 1 required positional argument: 'prompt_template'\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "uniquecdmx",
      "author_type": "User",
      "created_at": "2024-12-20T02:23:17Z",
      "updated_at": "2025-04-21T21:05:15Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2223/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2223",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2223",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:11.939489",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "Thanks for your feedback, we will check it.",
          "created_at": "2024-12-22T16:09:02Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-04-21T21:05:14Z"
        }
      ]
    },
    {
      "issue_number": 2609,
      "title": "[Bug] [Awel] Awel Agent Resource Knowledge node not work",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nLLM: proxy deepseek-r1\nEmbedding: proxy bge-m3\n\n### What happened\n\nIn the AWEL workflow, it is found that there are two types of knowledge base resources to choose from, but the second one (Awel Agent Resource Knowledge) cannot be used, and the answer will cause an error\n\n![Image](https://github.com/user-attachments/assets/ed90de8e-51b4-47e1-9009-34162a42f641)\n![Image](https://github.com/user-attachments/assets/e455b9b9-8a2e-4d94-bc6e-da11b62bd330)\n\n### What you expected to happen\n\nYou can bind the knowledge base normally\n\n### How to reproduce\n\nUse db-expert-assisant as an example workflow \n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "vnicers",
      "author_type": "User",
      "created_at": "2025-04-10T08:21:22Z",
      "updated_at": "2025-04-21T08:31:23Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2609/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2609",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2609",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:12.183332",
      "comments": [
        {
          "author": "fangyinc",
          "body": "Hi @vnicers  Thinks for your fedback， please provide  some logs.",
          "created_at": "2025-04-10T08:30:40Z"
        },
        {
          "author": "vnicers",
          "body": "2025-04-10 16:14:01 tam dbgpt.agent.core.plan.awel.team_awel_layout[18880] ERROR DAG run failed!Failed to build resource knowledge:dbgpt_serve.agent.resource.knowledge.KnowledgeSpaceRetrieverResource: 'int' object has no attribute 'copy'\nTraceback (most recent call last):\n  File \"D:\\workspace\\backen",
          "created_at": "2025-04-10T08:34:33Z"
        },
        {
          "author": "vnicers",
          "body": "@fangyinc 上面已提供",
          "created_at": "2025-04-10T08:35:21Z"
        },
        {
          "author": "moyaduo",
          "body": "@vnicers 解决了吗？我也遇到了相同问题",
          "created_at": "2025-04-16T14:32:19Z"
        },
        {
          "author": "vnicers",
          "body": "> [@vnicers](https://github.com/vnicers) 解决了吗？我也遇到了相同问题\n\n可以换上面的用.不影响功能\n\n![Image](https://github.com/user-attachments/assets/16de191b-9b24-489d-a698-f0173ef873f2)",
          "created_at": "2025-04-21T08:31:22Z"
        }
      ]
    },
    {
      "issue_number": 2622,
      "title": "ImportError: Could not import sentence_transformers python package. Please install it with `pip install sentence_transformers`.",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.9\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU:2\n\n### Models information\n\nQwen/Qwen2.5-Coder-0.5B-Instruct\nBAAI/bge-large-zh-v1.5\n\n### What happened\n\n执行了\n# Use uv to install dependencies needed for GLM4\n# Install core dependencies and select desired extensions\nuv sync --all-packages \\\n--extra \"base\" \\\n--extra \"cuda121\" \\\n--extra \"hf\" \\\n--extra \"rag\" \\\n--extra \"storage_chromadb\" \\\n--extra \"quant_bnb\" \\\n--extra \"dbgpts\"\n启动\nuv run dbgpt start webserver --config configs/dbgpt-local-glm.toml\n发现页面加载不出来\n\n于是下载了qwen的配置\n执行了\nuv sync --all-packages \\\n--extra \"base\" \\\n--extra \"proxy_tongyi\" \\\n--extra \"rag\" \\\n--extra \"storage_chromadb\" \\\n--extra \"dbgpts\"\n\n然后又执行了 uv run dbgpt start webserver --config configs/dbgpt-local-qwen.toml\n\n发现报错ImportError: Could not import sentence_transformers python package. Please install it with `pip install sentence_transformers`.\n\n\n\n[toml]\n[system]\n# Load language from environment variable(It is set by the hook)\nlanguage = \"${env:DBGPT_LANG:-zh}\"\napi_keys = []\nencrypt_key = \"your_secret_key\"\n\n# Server Configurations\n[service.web]\nhost = \"0.0.0.0\"\nport = 5670\n\n[service.web.database]\ntype = \"sqlite\"\npath = \"pilot/meta_data/dbgpt.db\"\n\n[rag.storage]\n[rag.storage.vector]\ntype = \"chroma\"\npersist_path = \"pilot/data\"\n\n# Model Configurations\n[models]\n[[models.llms]]\nname = \"Qwen2.5-Coder-0.5B-Instruct\"\nprovider = \"hf\"\n# If not provided, the model will be downloaded from the Hugging Face model hub\n# uncomment the following line to specify the model path in the local file system\n# path = \"the-model-path-in-the-local-file-system\"\n#path = \"models/Qwen2.5-Coder-0.5B-Instruct\"\npath = \"**********/Qwen/Qwen2.5-Coder-0.5B-Instruct\"\n\n[[models.embeddings]]\nname = \"BAAI/bge-large-zh-v1.5\"\nprovider = \"hf\"\n# If not provided, the model will be downloaded from the Hugging Face model hub\n# uncomment the following line to specify the model path in the local file system\n# path = \"the-model-path-in-the-local-file-system\"\n#path = \"models/BAAI/bge-large-zh-v1.5\"\npath = \"**********/BAAI/bge-large-zh-v1.5\"\n\n### What you expected to happen\n\nrun succeesfully\n\n### How to reproduce\n\n dd\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "YangXiaojun1012",
      "author_type": "User",
      "created_at": "2025-04-14T08:57:06Z",
      "updated_at": "2025-04-21T06:20:47Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2622/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2622",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2622",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:12.442919",
      "comments": [
        {
          "author": "fangyinc",
          "body": "Local embedding must sync with extra `--extra \"hf\"`",
          "created_at": "2025-04-14T09:03:41Z"
        },
        {
          "author": "YangXiaojun1012",
          "body": "> Local embedding must sync with extra `--extra \"hf\"`\n在哪里添加这个？",
          "created_at": "2025-04-21T06:20:46Z"
        }
      ]
    },
    {
      "issue_number": 2639,
      "title": "[Bug] [Module Name] When using App Starter, only one app can work.",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU Count:4\nGPU Memory: 192G\n\n\n### Models information\n\nLLM: DeepSeek-R1-Distill-Qwen-32B\n\n### What happened\n\nI has selected multiple apps in App Starter, but in actual use, only one specific app can be called. Additionally, the app list only displays one app.\n\n![Image](https://github.com/user-attachments/assets/0a71174b-a89d-40a9-8623-bed5c43d12f0)\n\n### What you expected to happen\n\nWhen I selected multiple apps, it should display multiple apps in the list self.resource.sub_resources.\n\n### How to reproduce\n\n1. create app - single agent - app starter\n2. select 2 or more apps as resources\n3. print all sub_resource._app_name in DB-GPT\\packages\\dbgpt-serve\\src\\dbgpt_serve\\agent\\agents\\expand\\app_resource_start_assisant_agent.py\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Carlycjl",
      "author_type": "User",
      "created_at": "2025-04-21T02:13:23Z",
      "updated_at": "2025-04-21T04:33:42Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2639/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2639",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2639",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:12.675624",
      "comments": [
        {
          "author": "vnicers",
          "body": "经过钉钉群里面的讨论, 这里的bug是agent resource name 重复导致的, 不过发现另外的问题, 如果app_starter 启动的是datascientist agent, 最终只会输出sql,不会显示结果和图表. 确认sql是执行了的, 似乎显示有问题, 麻烦 @fangyinc @Aries-ckt  看看",
          "created_at": "2025-04-21T04:33:41Z"
        }
      ]
    },
    {
      "issue_number": 2640,
      "title": "[Bug] [Module Name] Bug title",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [x] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n![Image](https://github.com/user-attachments/assets/02b35b64-db08-4e18-892e-fbd302e709cf)\n表结构的描述只有10个字段（实际肯定大于10个字段），连主键id都没有查出来\n\n\n### Models information\n\ndeepseek-r1\n\n### What happened\n\n使用chat db， 输入  描述表结构customer;\n\n\n\n### What you expected to happen\n\n使用chat db， 输入  描述表结构customer;\n\n\n\n### How to reproduce\n\n使用chat db， 输入  描述表结构customer;\n\n\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "SodisgaSoft",
      "author_type": "User",
      "created_at": "2025-04-21T03:52:37Z",
      "updated_at": "2025-04-21T03:52:37Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2640/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2640",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2640",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:12.949154",
      "comments": []
    },
    {
      "issue_number": 2338,
      "title": "[Bug] [KnowledgeGraph] connect vector store failed; document sync batch error!;document embedding, failed:santi.md",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [x] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n是用cpu运行的。\n\n### Models information\n\nLLM_MODEL = chatgpt_proxyllm[微软代理的gpt-3.5]\nEMBEDDING_MODEL=text2vec-large-chinese\nTuGraph的版本是4.5.1\n\n### What happened\n\n`| ERROR | dbgpt.serve.rag.connector | connect vector store failed: Query execution failed: {code: PluginDisabled} {message: No permission to load or delete plugin, please use correct config and restart server!This function has security risks, please enable it with caution!}`\n`| ERROR | dbgpt.app.knowledge.api | document sync batch error!\nTraceback (most recent call last):`\n`| ERROR | dbgpt.serve.rag.service.service | document embedding, failed:santi.md, Query execution failed: {code: InputError} {message:Plugin [_fma_leiden] does not exist.}`\n\n### What you expected to happen\n\n在创建知识图谱的时候发生的这些错误，似乎是文件配置问题，但是自己动手操作之后配置还是有问题，希望各位大佬能给我详细一些的说明，\n在刚开始生成知识图谱阶段，会生成大量错误的乱码，logs如第一个图所示，最终也会生成一点图谱，但是非常不完整。\n\n![Image](https://github.com/user-attachments/assets/48074a47-376e-40af-91a5-d03be75e840a)\n\n![Image](https://github.com/user-attachments/assets/27c51836-69e5-46ac-a119-140ff597e578)\n\n### How to reproduce\n\n启动‘./dbgpt/app/dbgpt_server.py’\n然后通过网页创建知识图谱，在创建的过程中日志就会报出这些错误\n\n### Additional context\n\n本人是初次尝试在这些平台上搭建rag等框架的小白，很多地方学的还不是很成熟，希望各位大佬不吝赐教，非常感谢！！\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "JUNK803",
      "author_type": "User",
      "created_at": "2025-02-10T02:24:42Z",
      "updated_at": "2025-04-21T03:15:04Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2338/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2338",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2338",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:12.949173",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "it looks like `| ERROR | dbgpt.serve.rag.service.service | document embedding, failed:santi.md, Query execution failed: {code: InputError} {message:Plugin [_fma_leiden] does not exist.}\n`\n",
          "created_at": "2025-02-16T15:07:19Z"
        },
        {
          "author": "JUNK803",
          "body": "> {message:Plugin [_fma_leiden] does not exist.}\n\nIt seems that this issue might be caused by this bug. Could you kindly help me understand how to resolve it? \nI would greatly appreciate your guidance and support. Thank you so much for your time and assistance!",
          "created_at": "2025-02-17T01:07:49Z"
        },
        {
          "author": "MarcoMaan",
          "body": "I encountered the same error, which is related to the TuGraph database. You can refer to this issue on GitHub for more details: [https://github.com/TuGraph-family/tugraph-db/issues/736 ](https://github.com/TuGraph-family/tugraph-db/issues/736).\n\nI installed TuGraph on Ubuntu 22 using the .deb packag",
          "created_at": "2025-04-21T03:15:03Z"
        }
      ]
    },
    {
      "issue_number": 2636,
      "title": "[Bug] [Rerank] Rerank not working",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nLLM: proxy deepseek r1\nEmbedding: proxy bge-m3\n\n### What happened\n\nThe rerank model of siliconflow was used in the configuration file, but neither the test recall nor the answer worked,\nthe CFG.RERANK_MODEL in the code is always none\n\n![Image](https://github.com/user-attachments/assets/ab76c626-7aa3-4eec-9b28-1180d594f179)\n\n![Image](https://github.com/user-attachments/assets/640c90c9-52f1-448c-997a-a2d334c50d76)\n\n### What you expected to happen\n\nIf the user chooses to use the rerank model in the configuration, the program is expected to be able to use it based on their own choices\n\n### How to reproduce\n\nknowledge base recall test\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "vnicers",
      "author_type": "User",
      "created_at": "2025-04-19T04:07:52Z",
      "updated_at": "2025-04-21T03:13:04Z",
      "closed_at": "2025-04-21T03:13:04Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2636/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2636",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2636",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:13.143465",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "sorry about that, we will check it soon.",
          "created_at": "2025-04-20T15:36:59Z"
        }
      ]
    },
    {
      "issue_number": 2635,
      "title": "[Bug] [数据源] db-gpt后台添加tugraph数据源报错",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [x] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nlinux 四核8G\n\n### Models information\n\ndeepseek-chat\n\n### What happened\n\n1. db-gpt后台添加tugraph数据源报错，不能添加其他的database，添加的时候弹出错误，如下图：\n\n![Image](https://github.com/user-attachments/assets/8068383f-68d4-4980-bd9e-5aac35d63743)\n\n![Image](https://github.com/user-attachments/assets/a481796b-ed45-4ad3-b56d-6ab27e68d95e)\n\n![Image](https://github.com/user-attachments/assets/cb7a7d6b-f2e2-4175-81ca-424254a100b2)\n\n2. 添加默认的database是可以的，比如default。但是数据源添加成功之后，通过chat-db基于tugraph数据源进行问答，chat-db貌似无法读取到tugraph的点和边\n\n![Image](https://github.com/user-attachments/assets/d55ba811-671c-4105-9727-b14cc8b6a2ea)\n\n![Image](https://github.com/user-attachments/assets/6fa71672-81cf-4d26-91f6-1ef3fbd59313)\n\n\n### What you expected to happen\n\n目前我们希望通过chat-db读取tugraph的模型数据，将自然语言转换成图数据的查询语言，以对话式（Chat）方式返回查询结果，并提供数据总结与分析。\n\n### How to reproduce\n\n已描述\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "danMe66",
      "author_type": "User",
      "created_at": "2025-04-18T06:51:11Z",
      "updated_at": "2025-04-20T16:52:20Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2635/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2635",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2635",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:13.350369",
      "comments": [
        {
          "author": "Appointat",
          "body": "hi. If I remember correctly, the current data chat module does not support direct interaction with the graph database. Currently, only the graph rag module relies on the graph database.\n\nYou can find \"GraphRAG\" in the documentation. @danMe66 ",
          "created_at": "2025-04-18T09:40:56Z"
        },
        {
          "author": "danMe66",
          "body": "> hi. 如果我记得没错，当前的数据聊天模块不支持直接与图数据库交互。目前只有图 RAG 模块依赖于图数据库。\n> \n> 您可以在文档中找到“GraphRAG”。[@danMe66](https://github.com/danMe66)\n\n后续有望支持么？或者我们通过什么方式可以实现这一功能，感谢您的回复 @Appointat ",
          "created_at": "2025-04-18T11:43:34Z"
        },
        {
          "author": "danMe66",
          "body": "> hi. 如果我记得没错，当前的数据聊天模块不支持直接与图数据库交互。目前只有图 RAG 模块依赖于图数据库。\n> \n> 您可以在文档中找到“GraphRAG”。[@danMe66](https://github.com/danMe66)\n\n为什么MYSQL数据源是支持的，tugraph数据源不支持呢，如果要支持，我们自己开发需要怎么做呢？😄 @Appointat ",
          "created_at": "2025-04-18T14:25:26Z"
        },
        {
          "author": "Appointat",
          "body": "> > hi. 如果我记得没错，当前的数据聊天模块不支持直接与图数据库交互。目前只有图 RAG 模块依赖于图数据库。\n> > 您可以在文档中找到“GraphRAG”。[@danMe66](https://github.com/danMe66)\n> \n> 后续有望支持么？或者我们通过什么方式可以实现这一功能，感谢您的回复 [@Appointat](https://github.com/Appointat)\n\nSupport for features similar to \"chat with tugraph\" requires the use of some fine-tuned text2gq",
          "created_at": "2025-04-20T16:52:19Z"
        }
      ]
    },
    {
      "issue_number": 2623,
      "title": "[Bug] [Web] The $ symbol in SQL conflicts with the $ formula symbol in Markdown syntax",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [x] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [x] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nN/A\n\n### Models information\n\nN/A\n\n### What happened\n\nIf JSON-related function syntax is used in SQL, the $ symbol will conflict with the $ symbol in Markdown, which will cause the page to render abnormally\nThe same issue can be found in knowledge base \n\n![Image](https://github.com/user-attachments/assets/a536293b-f785-406c-94b0-5b69626f0a2e)\n\n### What you expected to happen\n\nAble to render the ui normally\n\n### How to reproduce\n\n1,Chat DB conversations\n2,Let the answer be answered with a $ symbol in the sql statement\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "vnicers",
      "author_type": "User",
      "created_at": "2025-04-14T11:23:50Z",
      "updated_at": "2025-04-18T06:41:50Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2623/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2623",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2623",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:13.537697",
      "comments": [
        {
          "author": "fangyinc",
          "body": "Hi @vnicers.\nYou can find the math formula rendering implementation in `web/components/chat/chat-content/config.tsx`. If you're interested, you can try adjusting it.\n```tsx\nexport function preprocessLaTeX(content: any): string {\n  if (typeof content !== 'string') {\n    return content;\n  }\n  // Extra",
          "created_at": "2025-04-18T06:41:49Z"
        }
      ]
    },
    {
      "issue_number": 2631,
      "title": "how to start by uv offline",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nerror: Failed to fetch: `https://pypi.tuna.tsinghua.edu.cn/simple/typing-inspect/`\n  Caused by: Could not connect, are you offline?\n  Caused by: Request failed after 3 retries\n  Caused by: error sending request for url (https://pypi.tuna.tsinghua.edu.cn/simple/typing-inspect/)\n  Caused by: client error (Connect)\n  Caused by: dns error: 不知道这样的主机。 (os error 11001)\n  Caused by: 不知道这样的主机。 (os error 11001)\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "zzzsudo",
      "author_type": "User",
      "created_at": "2025-04-16T05:07:57Z",
      "updated_at": "2025-04-18T06:22:03Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2631/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2631",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2631",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:13.758015",
      "comments": [
        {
          "author": "zzzsudo",
          "body": "DBGPT based on private data, it's important to privide a way to run in offline environment",
          "created_at": "2025-04-17T07:28:16Z"
        },
        {
          "author": "fangyinc",
          "body": "@zzzsudo You can set up your internal PyPI address to install packages (`export UV_INDEX_URL={your internal PyPI address}`), or install them on a machine with internet access and then copy the environment to your server.",
          "created_at": "2025-04-17T11:33:05Z"
        },
        {
          "author": "zzzsudo",
          "body": "@fangyinc I have installed on my machine in a inline envirobnment successfully, but i have to let my machine to be offline ,so the uv start faild, i asked if there is away to uv start offline",
          "created_at": "2025-04-18T03:19:31Z"
        },
        {
          "author": "fangyinc",
          "body": "@zzzsudo I suggest first installing all dependencies on an online machine with the same CPU architecture and operating system, and then running it on the offline machine (directly using the python command to start, `python packages/dbgpt-app/src/dbgpt_app/dbgpt_server.py --config configs/your_config",
          "created_at": "2025-04-18T03:57:09Z"
        },
        {
          "author": "zzzsudo",
          "body": "@fangyinc no, it went wrong,\ni used this command\n\n`python packages/dbgpt-app/src/dbgpt_app/dbgpt_server.py --config configs/dbgpt-proxy-deepseek.toml`\nwhichi occurs:\nTraceback (most recent call last):\n  File \"C:\\Users\\ROG\\DB-GPT\\packages\\dbgpt-app\\src\\dbgpt_app\\dbgpt_server.py\", line 12, in <module>",
          "created_at": "2025-04-18T06:14:19Z"
        }
      ]
    },
    {
      "issue_number": 2216,
      "title": "[Feature][GraphRAG] GraphRAG Query Intention Recognition Based on AWEL / External Agent System",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n_No response_\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nMedium\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "fanzhidongyzby",
      "author_type": "User",
      "created_at": "2024-12-18T08:15:10Z",
      "updated_at": "2025-04-17T21:05:26Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale",
        "GraphRAG"
      ],
      "label_count": 4,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2216/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2216",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2216",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:13.965059",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-04-17T21:05:25Z"
        }
      ]
    },
    {
      "issue_number": 2634,
      "title": "[Feature][Module Name] 希望未来能增加对象存储 minio支持",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n希望未来能增加对象存储 minio支持\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Scoop3o3",
      "author_type": "User",
      "created_at": "2025-04-17T02:08:41Z",
      "updated_at": "2025-04-17T03:52:25Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2634/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2634",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2634",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:14.135613",
      "comments": [
        {
          "author": "fangyinc",
          "body": "Please see [S3 API Compatibility](https://min.io/docs/minio/linux/reference/s3-api-compatibility.html) and https://github.com/eosphoros-ai/DB-GPT/blob/main/configs/dbgpt-cloud-storage.example.toml",
          "created_at": "2025-04-17T03:52:24Z"
        }
      ]
    },
    {
      "issue_number": 2501,
      "title": "[Bug] [Knowledge] Query: CALL db.upsertVertex(\"document\", [{id: \"744dd733-1d2c-463a-97d3-f79533d9819d\", name: \"test.txt\", content: \"\"}])",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\n0.6.3\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nProxy LLM\n\n### What happened\n\n创建知识库时，Storage选择knowledge Graph,上传任意文档。TuGraph Version：4.5.2\n日志报错：\nERROR document embedding, failed:test.txt, Query execution failed: {code: InputError} {message: Label \"document\" does not exist.}\nQuery: CALL db.upsertVertex(\"document\", [{id: \"744dd733-1d2c-463a-97d3-f79533d9819d\", name: \"test.txt\", content: \"\"}])\n\n### What you expected to happen\n\n创建知识库时，Storage选择knowledge Graph,上传任意文档, 处理正常终了。\n\n### How to reproduce\n\n创建知识库时，Storage选择knowledge Graph,上传任意文档。\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "Hec-gitHub",
      "author_type": "User",
      "created_at": "2025-03-21T08:05:00Z",
      "updated_at": "2025-04-17T02:58:06Z",
      "closed_at": "2025-03-21T11:03:41Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2501/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2501",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2501",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:14.293884",
      "comments": [
        {
          "author": "watashiwastar-yun",
          "body": "请问这个问题最后是怎么解决的呀，是用cypher在tugraph里新增了vertex吗（不太熟悉cypher）",
          "created_at": "2025-04-08T17:03:41Z"
        },
        {
          "author": "watashiwastar-yun",
          "body": "@Hec-gitHub ",
          "created_at": "2025-04-08T17:04:41Z"
        },
        {
          "author": "Hec-gitHub",
          "body": "@watashiwastar-yun \n> 请问这个问题最后是怎么解决的呀，是用cypher在tugraph里新增了vertex吗（不太熟悉cypher）\n\n这个问题，我这边将tugraph 的plugin 插件有效化，然后重启服务就好了。\ntugraph 的plugin 插件有效：\ndocker exec -it docker_image_name bash\nlgraph_server -c /usr/local/etc/lgraph.json -d start --enable_plugin true",
          "created_at": "2025-04-17T02:57:47Z"
        }
      ]
    },
    {
      "issue_number": 2212,
      "title": "[Bug] [Module Name] Bug title The connection failed",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n<3.9\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [X] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [X] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n2C4G\n\n### Models information\n\ntext2vec-large-chinese\n\n### What happened\n\nAt first, I can connect to the Mysql database, during the conversation, I asked him to show the data of the table in the database, and it replied that there is no such table in the database, but there is this table in my database, and there is also data, so I deleted the connection information in the database and reconnected, and the result showed that the connection failed\r\n\r\n![image](https://github.com/user-attachments/assets/d1d41046-453a-4b63-901c-3a2c2d6b7532)\r\n\n\n### What you expected to happen\n\nThe database is successfully connected\n\n### How to reproduce\n\nI don't know what's going on, it's still possible to connect successfully at the beginning\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "cai417",
      "author_type": "User",
      "created_at": "2024-12-17T08:15:19Z",
      "updated_at": "2025-04-16T21:05:08Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2212/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2212",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2212",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:14.535033",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-04-16T21:05:08Z"
        }
      ]
    },
    {
      "issue_number": 2113,
      "title": "[Bug] [Module Name] Bug title Graph RAG query error.",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [X] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\ngpu 1 memory 24g\n\n### Models information\n\nqwen2.5 14B\n\n### What happened\n\n接口地址：/api/v1/chat/completions\r\n参数：{\"chat_mode\":\"chat_knowledge\",\"model_name\":\"proxyllm\",\"user_input\":\"有关特朗普的事情\",\"app_code\":\"chat_knowledge\",\"temperature\":0.5,\"select_param\":\"sad及哦啊接到哦i阿斯加德\",\"conv_uid\":\"cb6cd85a-97fc-11ef-a342-e89c252b45fe\"}\r\n报错：File \"/home/data/project/DB-GPT/dbgpt/app/scene/chat_knowledge/v1/chat.py\", line 166, in generate_input_values\r\n    chucks = self.chunk_dao.get_document_chunks(\r\n  File \"/home/data/project/DB-GPT/dbgpt/app/knowledge/chunk_db.py\", line 97, in get_document_chunks\r\n    result = document_chunks.all()\r\nsqlalchemy.exc.OperationalError: (sqlite3.OperationalError) LIKE or GLOB pattern too complex\n\n### What you expected to happen\n\n问答报错 期望能正确问答\n\n### How to reproduce\n\n1.创建知识库 选择存储类型Knowledge Graph\r\n2.新增数据（大量）\r\n3.知识库问答\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "ljhssga",
      "author_type": "User",
      "created_at": "2024-11-01T03:02:16Z",
      "updated_at": "2025-04-16T08:58:16Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2113/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2113",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2113",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:14.724133",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "it looks like plenty of documents will reproduce this problem. ",
          "created_at": "2024-11-01T15:40:56Z"
        },
        {
          "author": "ljhssga",
          "body": "> it looks like plenty of documents will reproduce this problem.\r\n\r\nSo what's the solution",
          "created_at": "2024-11-04T02:44:19Z"
        },
        {
          "author": "Appointat",
          "body": "hi @ljhssga . How many docs you have uploaded in one time? Can you provide me more info? thanks",
          "created_at": "2024-11-05T05:52:03Z"
        },
        {
          "author": "ljhssga",
          "body": "> hi @ljhssga . How many docs you have uploaded in one time? Can you provide me more info? thanks\r\n\r\nAbout 1000, all txt, the content length is not fixed.Language is English @Appointat ",
          "created_at": "2024-11-06T00:59:10Z"
        },
        {
          "author": "Appointat",
          "body": "Thanks for the info @ljhssga . \r\nTrue. And 1000 files is too many. If convenient, could I get your contact information? Perhaps chatting privately would help resolve the issue. My public email is: appointat@gmail.com\r\n",
          "created_at": "2024-11-08T12:57:04Z"
        }
      ]
    },
    {
      "issue_number": 1698,
      "title": "[Bug] TypeError: NullType() takes no arguments when running python ./dbgpt/app/dbgpt_server.py --host 0.0.0.0 --port 6006",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [X] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU: 2*A100,80G\n\n### Models information\n\ntongyiproxyllm\r\nbge-large\n\n### What happened\n\n运行时报错：python ./dbgpt/app/dbgpt_server.py  --host 0.0.0.0 --port 6006\r\n\r\n2024-07-05 14:19:39 gptai dbgpt.datasource.manages.connect_config_db[3070178] INFO Result: <sqlalchemy.engine.cursor.CursorResult object at 0x7f3e718a5cc0>\r\n2024-07-05 14:19:39 gptai dbgpt.storage.vector_store.connector[3070178] INFO VectorStore:<class 'dbgpt.storage.vector_store.chroma_store.ChromaStore'>\r\n2024-07-05 14:19:39 gptai chromadb.api.segment[3070178] INFO Collection langchain is not created.\r\n2024-07-05 14:19:39 gptai dbgpt.storage.vector_store.chroma_store[3070178] INFO Check persist_dir: /media/data/xgp/repo/DB-GPT/pilot/data/copilot_profile.vectordb\r\n2024-07-05 14:19:39 gptai dbgpt.rag.summary.db_summary_client[3070178] INFO Vector store name copilot_profile exist\r\n2024-07-05 14:19:39 gptai dbgpt.rag.summary.db_summary_client[3070178] INFO initialize db summary profile success...\r\n2024-07-05 14:19:39 gptai dbgpt.rag.summary.db_summary_client[3070178] INFO db summary embedding success\r\n2024-07-05 14:19:39 gptai dbgpt.datasource.manages.connect_config_db[3070178] INFO Result: <sqlalchemy.engine.cursor.CursorResult object at 0x7f3e718a7e20>\r\n2024-07-05 14:19:47 gptai dbgpt.storage.vector_store.connector[3070178] INFO VectorStore:<class 'dbgpt.storage.vector_store.chroma_store.ChromaStore'>\r\n2024-07-05 14:19:47 gptai chromadb.api.segment[3070178] INFO Collection langchain is not created.\r\n2024-07-05 14:19:47 gptai dbgpt.storage.vector_store.chroma_store[3070178] INFO Check persist_dir: /media/data/xgp/repo/DB-GPT/pilot/data/sx_adc_f2_profile.vectordb\r\n2024-07-05 14:19:47 gptai dbgpt.rag.summary.db_summary_client[3070178] INFO Vector store name sx_adc_f2_profile exist\r\n2024-07-05 14:19:47 gptai dbgpt.rag.summary.db_summary_client[3070178] INFO initialize db summary profile success...\r\n2024-07-05 14:19:47 gptai dbgpt.rag.summary.db_summary_client[3070178] INFO db summary embedding success\r\n2024-07-05 14:19:47 gptai dbgpt.datasource.manages.connect_config_db[3070178] INFO Result: <sqlalchemy.engine.cursor.CursorResult object at 0x7f3e47f74220>\r\n/media/data/xgp/repo/DB-GPT/dbgpt/datasource/rdbms/base.py:87: SAWarning: Did not recognize type 'DATE' of column 'discovery_date'\r\n  self._metadata.reflect(bind=self._engine)\r\n/media/data/xgp/repo/DB-GPT/dbgpt/datasource/rdbms/base.py:87: SAWarning: Did not recognize type 'VARCHAR' of column 'technology'\r\n  self._metadata.reflect(bind=self._engine)\r\n2024-07-05 14:19:47 gptai dbgpt.rag.summary.db_summary_client[3070178] WARNING adc, mysql summary error!NullType() takes no arguments, detail: Traceback (most recent call last):\r\n  File \"/media/data/xgp/repo/DB-GPT/dbgpt/rag/summary/db_summary_client.py\", line 75, in init_db_summary\r\n    self.db_summary_embedding(item[\"db_name\"], item[\"db_type\"])\r\n  File \"/media/data/xgp/repo/DB-GPT/dbgpt/rag/summary/db_summary_client.py\", line 43, in db_summary_embedding\r\n    db_summary_client = self.create_summary_client(dbname, db_type)\r\n  File \"/media/data/xgp/repo/DB-GPT/dbgpt/rag/summary/db_summary_client.py\", line 139, in create_summary_client\r\n    return RdbmsSummary(dbname, db_type)\r\n  File \"/media/data/xgp/repo/DB-GPT/dbgpt/rag/summary/**rdbms_db_summary.py\"**, line 38, in __init__\r\n    self.db = db_manager.get_connector(name)\r\n  File \"/media/data/xgp/repo/DB-GPT/dbgpt/datasource/manages/connector_manager.py\", line 126, in get_connector\r\n    return connect_instance.from_uri_db(  # type: ignore\r\n  File \"/media/data/xgp/repo/DB-GPT/dbgpt/datasource/rdbms/base.py\", line 133, in from_uri_db\r\n    return cls.from_uri(db_url, engine_args, **kwargs)\r\n  File \"/media/data/xgp/repo/DB-GPT/dbgpt/datasource/rdbms/base.py\", line 141, in from_uri\r\n    return cls(create_engine(database_uri, **_engine_args), **kwargs)\r\n  File \"/media/data/xgp/repo/DB-GPT/dbgpt/datasource/rdbms/base.py\", line 87, in __init__\r\n    self._metadata.reflect(bind=self._engine)\r\n  File \"/root/anaconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/sql/schema.py\", line 5831, in reflect\r\n    _reflect_info = insp._get_reflection_info(\r\n  File \"/root/anaconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/reflection.py\", line 2006, in _get_reflection_info\r\n    columns=run(\r\n  File \"/root/anaconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/reflection.py\", line 1992, in run\r\n    res = meth(filter_names=_fn, **kw)\r\n  File \"/root/anaconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/reflection.py\", line 921, in get_multi_columns\r\n    table_col_defs = dict(\r\n  File \"/root/anaconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py\", line 1101, in _default_multi_reflect\r\n    single_tbl_method(\r\n  File \"<string>\", line 2, in get_columns\r\n  File \"/root/anaconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/reflection.py\", line 97, in cache\r\n    ret = fn(self, con, *args, **kw)\r\n  File \"/root/anaconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/dialects/mysql/base.py\", line 2964, in get_columns\r\n    parsed_state = self._parsed_state_or_create(\r\n  File \"/root/anaconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/dialects/mysql/base.py\", line 3224, in _parsed_state_or_create\r\n    return self._setup_parser(\r\n  File \"<string>\", line 2, in _setup_parser\r\n  File \"/root/anaconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/reflection.py\", line 97, in cache\r\n    ret = fn(self, con, *args, **kw)\r\n  File \"/root/anaconda3/envs/dbgpt_env/lib/python3.10/site-packages/**sqlalchemy/dialects/mysql/base.py\",** line 3260, in _setup_parser\r\n    return parser.parse(sql, charset)\r\n  File \"/root/anaconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/dialects/mysql/reflection.py\", line 48, in parse\r\n    self._parse_column(line, state)\r\n  File \"/root/anaconda3/envs/dbgpt_env/lib/python3.10/site-packages/s**qlalchemy/dialects/mysql/reflection.py**\", line 284, in _parse_column\r\n    **type_instance = col_type(*type_args, **type_kw)\r\nTypeError: NullType() takes no arguments**\r\n\n\n### What you expected to happen\n\n不知道是什么错误，如果是解析解析数据库错误，希望直到如何纠正？\n\n### How to reproduce\n\n无\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "chuangzhidan",
      "author_type": "User",
      "created_at": "2024-07-05T06:24:41Z",
      "updated_at": "2025-04-16T06:48:05Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1698/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1698",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1698",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:14.936055",
      "comments": [
        {
          "author": "chuangzhidan",
          "body": "没人吗？",
          "created_at": "2024-07-29T02:17:50Z"
        },
        {
          "author": "CatInCloud",
          "body": "感觉这个项目没人维护了",
          "created_at": "2024-08-07T09:05:27Z"
        },
        {
          "author": "lushanyanyu-FJJ",
          "body": "我也遇到了这个问题\r\n",
          "created_at": "2024-11-13T13:13:51Z"
        },
        {
          "author": "panda-on",
          "body": "sqlalchemy在用MySQL驱动反射数据库实例的时候无法识别discovery_date和technology这个两个字段的数据类型，你的数据库是MySQL吗还是像starrocks这种兼容MySQL client的数据库？如果不是最好按照MySQL的数据类型命名的规则调整一下。另外要注意一下，数据库的版本也会有影响，因为不同版本的数据库在数据类型的命名的不同的，这有可能导致新的数据库驱动和老版本的数据库之间有些数据类型无法识别的问题。",
          "created_at": "2025-04-16T06:48:04Z"
        }
      ]
    },
    {
      "issue_number": 2198,
      "title": "[Bug] [Serve] 'proxyllm_backend' configed in the .env file not work in the Chat using ollama_proxyllm ",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [X] Chat Knowledge\n- [X] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU count: 1\r\nGPU Memory: 24GB\n\n### Models information\n\nEmbeddingmodel:text2vec-large-chinese\r\nmodel: \r\nollama/glm-4-9b-chat:latest\n\n### What happened\n\nwhen I configed the model part of .env file  as \r\n```\r\nLLM_MODEL=ollama_proxyllm\r\nPROXY_SERVER_URL=http://localhost:11434\r\nPROXYLLM_BACKEND=\"llama3:latest\"\r\nPROXY_API_KEY=not_used\r\n```\r\n\r\nthe description information listed as\r\n\r\n```\r\n=========================== ProxyModelParameters ===========================\r\n\r\nmodel_name: ollama_proxyllm\r\nmodel_path: ollama_proxyllm\r\nproxy_server_url: https://api.openai.com/v1/chat/completions\r\nproxy_api_key: {******}\r\nproxy_api_base: None\r\nproxy_api_app_id: None\r\nproxy_api_secret: None\r\nproxy_api_type: None\r\nproxy_api_version: None\r\nhttp_proxy: None\r\nproxyllm_backend: glm-4-9b-chat:latest\r\nmodel_type: proxy\r\ndevice: cuda\r\nprompt_template: None\r\nmax_context_size: 4096\r\nllm_client_class: None\r\n======================================================================\r\n``` \r\n\r\nThat meaned the configuration about ollama was sucessful, so did the ollama runtime environment.\r\n\r\nI attempted to chat normal using the ollama,  but failed with error information `httpx.ConnectError: [Errno 101] Network is unreachable`\r\n\r\n```\r\n2024-12-13 12:38:52 dell dbgpt.serve.agent.app.controller[470001] INFO app_detail:chat_normal,chat_normal\r\nINFO:     10.10.254.109:50546 - \"GET /api/v1/app/info?chat_scene=chat_normal&app_code=chat_normal HTTP/1.1\" 200 OK\r\nINFO:     10.10.254.109:50547 - \"GET /api/v1/chat/dialogue/messages/history?con_uid=277758ca-b90c-11ef-b767-c4cbe1e13cd8 HTTP/1.1\" 200 OK\r\n2024-12-13 12:39:02 dell dbgpt.app.openapi.api_v1.api_v1[470001] INFO chat_completions:chat_normal,,ollama_proxyllm, timestamp=1734064742075\r\n2024-12-13 12:39:02 dell dbgpt.app.openapi.api_v1.api_v1[470001] INFO get_chat_instance:conv_uid='277758ca-b90c-11ef-b767-c4cbe1e13cd8' user_input='这回能回答吗' user_name='001' chat_mode='chat_normal' app_code='chat_normal' temperature=0.5 select_param='' model_name='ollama_proxyllm' incremental=False sys_code=None ext_info={}\r\nGet prompt template of scene_name: chat_normal with model_name: ollama_proxyllm, proxyllm_backend: None, language: en\r\n```\r\n\r\nfrom the loading information, it's looks like the reason was that `proxyllm_backend: None`\n\n### What you expected to happen\n\nNormal chat should be sucess using the ollama and backend.\n\n### How to reproduce\n\nJust configuration with ollama and backend, then start the server, and chat normal.\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "toralee",
      "author_type": "User",
      "created_at": "2024-12-13T05:04:49Z",
      "updated_at": "2025-04-15T21:05:22Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2198/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2198",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2198",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:15.145109",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "/assign @fangyinc ",
          "created_at": "2024-12-16T16:15:36Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-04-15T21:05:20Z"
        }
      ]
    },
    {
      "issue_number": 2208,
      "title": "[Bug] [connection] Too many connections",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [X] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\n...\n\n### What happened\n\n[SERVER_ERROR](http://auto-db-gpt.thallo.autohome.com.cn/pymysql.err.OperationalError) (1040, 'Too many connections') (Background on this error at: https://sqlalche.me/e/20/e3q8)\n\n### What you expected to happen\n\nIt appears that there are database connection leaks.\r\n\r\n\n\n### How to reproduce\n\nchat with awel\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "dixingxing0",
      "author_type": "User",
      "created_at": "2024-12-16T07:42:42Z",
      "updated_at": "2025-04-15T21:05:20Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2208/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2208",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2208",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:15.398472",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "Can you describe what datasource you connect and how you operate?",
          "created_at": "2024-12-16T15:48:14Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-04-15T21:05:19Z"
        }
      ]
    },
    {
      "issue_number": 2625,
      "title": "[Bug] [core Controller]   RuntimeError: can't start new thread",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [x] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [x] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [x] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\n dbgpt start controller --config /app/configs/controller/db.physical.toml\n\n### What happened\n\n 1. run \n```bash\ndbgpt start controller --config /app/configs/controller/db.physical.toml\n```\ndb.physical.toml 如下\n```toml\n[service.model.controller]\nhost = \"0.0.0.0\"\nport = 8099\n\n[service.model.controller.log]\nlevel = \"INFO\"\nproject_name = \"db-controller\"\nproject_host = \"10.xxx..xxxXXX\"\nfile = \"./logs/controller_memory_project_run.log\"\n\n[service.model.controller.registry]\n[service.model.controller.registry.database]\ntype = \"mysql\"\nhost = \"${env:MYSQL_HOST}\"\nport = \"${env:MYSQL_PORT:}\"\ndatabase = \"${env:MYSQL_DATABASE:-dbgpt}\"\nuser = \"${env:MYSQL_USER:}\"\npassword =\"${env:MYSQL_PASSWORD}\"\n```\n\n2.  error message\ndbgpt start controller --config /app/configs/controller/db.physical.toml\nTraceback (most recent call last):\n  File \"/opt/.uv.venv/bin/dbgpt\", line 10, in <module>\n    sys.exit(main())\n             ^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/cli/cli_scripts.py\", line 229, in main\n    return cli()\n           ^^^^^\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/click/core.py\", line 1161, in __call__\n    return self.main(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/click/core.py\", line 1082, in main\n    rv = self.invoke(ctx)\n         ^^^^^^^^^^^^^^^^\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/click/core.py\", line 1697, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/click/core.py\", line 1697, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/click/core.py\", line 1443, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/click/core.py\", line 788, in invoke\n    return __callback(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/cli.py\", line 458, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/cli.py\", line 489, in start_model_controller\n    run_model_controller(config)\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/cluster/controller/controller.py\", line 383, in run_model_controller\n    registry = _create_registry(controller_params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/cluster/controller/controller.py\", line 320, in _create_registry\n    registry = StorageModelRegistry.from_url(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/cluster/registry_impl/storage.py\", line 218, in from_url\n    return cls(storage, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/cluster/registry_impl/storage.py\", line 181, in __init__\n    self.heartbeat_thread.start()\n  File \"/usr/local/lib/python3.11/threading.py\", line 964, in start\n    _start_new_thread(self._bootstrap, ())\nRuntimeError: can't start new thread\n\"2025-04-15T09:16:48.382+08:00\" \"-\"     \"dealer\"        \"dealer.arch\"   \"dbgpt\" \"-\"     \"172.17.0.17\"   \"/app/packages/dbgpt-core/src/dbgpt/datasource/rdbms/base.py\"   \"-\"     \"-\"     \"-\"     \"-\"  \"INFO\"   \"-\"     \"close\" \"-\"     \"877\"   \"dbgpt.datasource.rdbms.base\"   \"-\"     \"-\"     \"-\"     \"Closing RDBMS connector resources...\"  \"-\"     \"-\"\n\n### What you expected to happen\n\nRuntimeError: can't start new thread\n\n### How to reproduce\n\n1. docker/base/Dockerfile\n\n### Additional context\n\n```bash\ncat /etc/os-release\n```\nPRETTY_NAME=\"Ubuntu 22.04.5 LTS\"\nNAME=\"Ubuntu\"\nVERSION_ID=\"22.04\"\nVERSION=\"22.04.5 LTS (Jammy Jellyfish)\"\nVERSION_CODENAME=jammy\nID=ubuntu\nID_LIKE=debian\nHOME_URL=\"https://www.ubuntu.com/\"\nSUPPORT_URL=\"https://help.ubuntu.com/\"\nBUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\nPRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\nUBUNTU_CODENAME=jammy\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "xydz",
      "author_type": "User",
      "created_at": "2025-04-15T01:30:50Z",
      "updated_at": "2025-04-15T15:05:36Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2625/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2625",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2625",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:15.732047",
      "comments": [
        {
          "author": "fangyinc",
          "body": "The `RuntimeError: can't start new thread` error occurs when your container hits system resource limits. To resolve this issue:\n\n1. Increase the thread limits in your Docker container\n2. Allocate more memory resources to the container \n3. Check and adjust CPU allocation if needed\n",
          "created_at": "2025-04-15T15:05:34Z"
        }
      ]
    },
    {
      "issue_number": 2595,
      "title": "[Bug] [VectorDB] Collection 'agent_memory' not exist when use Milvus VectorDB",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nLLM: Proxy Deepseek-R1\nEmbedding: Proxy bge-m3\n\n### What happened\n\nWhen using the Milvus vector database, get the following error\n![Image](https://github.com/user-attachments/assets/1123bb83-43fc-4ec2-b9c9-59ba57170f5b)\n2025-04-08 21:24:56 tam dbgpt.agent.core.base_agent[36440] ERROR Generate reply exception!\nTraceback (most recent call last):\n  File \"D:\\workspace\\backend\\my\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\agent\\core\\base_agent.py\", line 402, in generate_reply\n    thinking_messages, resource_info = await self._load_thinking_messages(\n                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\workspace\\backend\\my\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\agent\\core\\base_agent.py\", line 1083, in _load_thinking_messages\n    memories = await self.read_memories(observation)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\workspace\\backend\\my\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\agent\\core\\role.py\", line 218, in read_memories\n    memories = await self.memory.read(question)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\workspace\\backend\\my\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\agent\\core\\memory\\agent_memory.py\", line 278, in read\n    return await self.memory.read(observation, alpha, beta, gamma)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\workspace\\backend\\my\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\agent\\core\\memory\\hybrid.py\", line 265, in read\n    ) = await self.fetch_memories(observation, self._short_term_memory)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\workspace\\backend\\my\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\agent\\core\\memory\\hybrid.py\", line 281, in fetch_memories\n    retrieved_long_term_memories = await self._long_term_memory.fetch_memories(\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\workspace\\backend\\my\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\agent\\core\\memory\\long_term.py\", line 305, in fetch_memories\n    retrieved_list = await blocking_func_to_async(\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\workspace\\backend\\my\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\executor_utils.py\", line 70, in blocking_func_to_async\n    return await loop.run_in_executor(executor, run_with_context)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\tam\\AppData\\Roaming\\uv\\python\\cpython-3.11.11-windows-x86_64-none\\Lib\\asyncio\\futures.py\", line 287, in __await__\n    yield self  # This tells Task to wait for completion.\n    ^^^^^^^^^^\n  File \"C:\\Users\\tam\\AppData\\Roaming\\uv\\python\\cpython-3.11.11-windows-x86_64-none\\Lib\\asyncio\\tasks.py\", line 349, in __wakeup\n    future.result()\n  File \"C:\\Users\\tam\\AppData\\Roaming\\uv\\python\\cpython-3.11.11-windows-x86_64-none\\Lib\\asyncio\\futures.py\", line 203, in result\n    raise self._exception.with_traceback(self._exception_tb)\n  File \"C:\\Users\\tam\\AppData\\Roaming\\uv\\python\\cpython-3.11.11-windows-x86_64-none\\Lib\\concurrent\\futures\\thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\workspace\\backend\\my\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\executor_utils.py\", line 67, in run_with_context\n    return ctx.run(partial(func, *args, **kwargs))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\workspace\\backend\\my\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\rag\\retriever\\base.py\", line 50, in retrieve\n    return self._retrieve(query, filters)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\workspace\\backend\\my\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\agent\\core\\memory\\long_term.py\", line 56, in _retrieve\n    return self._retrieve_vector_store_only(query, filters, current_time)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\workspace\\backend\\my\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\agent\\core\\memory\\long_term.py\", line 129, in _retrieve_vector_store_only\n    docs = self._index_store.similar_search_with_scores(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\workspace\\backend\\my\\DB-GPT\\packages\\dbgpt-ext\\src\\dbgpt_ext\\storage\\vector_store\\milvus_store.py\", line 500, in similar_search_with_scores\n    self.col = Collection(self.collection_name)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\workspace\\backend\\my\\DB-GPT\\.venv\\Lib\\site-packages\\pymilvus\\orm\\collection.py\", line 140, in __init__\n    raise SchemaNotReadyException(\npymilvus.exceptions.SchemaNotReadyException: <SchemaNotReadyException: (code=1, message=Collection '_agent_memory_' not exist, or you can pass in schema to create one.)>\n\n### What you expected to happen\n\nBe able to answer questions just like Chroma\n\n### How to reproduce\n\n1, use milvus vector db\n2, create app with workflow awel_flow_web_info_search\n3, ask question \n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "vnicers",
      "author_type": "User",
      "created_at": "2025-04-08T13:39:28Z",
      "updated_at": "2025-04-15T14:48:28Z",
      "closed_at": "2025-04-15T14:48:27Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2595/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "Aries-ckt"
      ],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2595",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2595",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:15.919556",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "sorry about that, it caused by `milvus_store.py` construct function did not initialize create collection.",
          "created_at": "2025-04-09T03:55:49Z"
        }
      ]
    },
    {
      "issue_number": 2579,
      "title": "[Bug] [Agent] AI Assistant Agent cannot be bound to multiple knowledge bases, and only one takes effect",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nLLM: proxy DeepSeek-R1\nEmbedding: proxy bge-m3\n\n### What happened\n\nWhen using an AI assistant to ask a question, there is always only one knowledge base recalled,I bind two simple knowledge bases, the current time and location, and when I asked related questions, I found that the resource_pompt parameter in the backend log only appeared in the time knowledge base, and there was no location\n![Image](https://github.com/user-attachments/assets/bd2980fd-98e7-4a2a-8c5c-316689a86018)\n\n![Image](https://github.com/user-attachments/assets/10c6fb63-c962-4f54-b85b-c487f975f632)\n\n![Image](https://github.com/user-attachments/assets/a8375a61-50cd-40f9-95c1-fd80fada8570)\n\n### What you expected to happen\n\nAI Assistant Agent can  bound to multiple knowledge bases\n\n### How to reproduce\n\n1, create sigle agent app with  AI assistant\n2, Bind 2 simple knowledge bases\n3, Ask questions related to the knowledge base\n4,Review the log output about resource references in model_pompt\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "vnicers",
      "author_type": "User",
      "created_at": "2025-04-02T12:34:29Z",
      "updated_at": "2025-04-15T12:38:14Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2579/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2579",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2579",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:16.094135",
      "comments": []
    },
    {
      "issue_number": 2580,
      "title": "[Bug] [AWEL] ToolExpert Agent cannot bind knowledge base in AWEL Workflow",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nLLM : proxy DeepSeek-R1\nEmbedding: bge-m3\n\n### What happened\n\nIn single-agent mode, ToolExport can be bound to a knowledge base, but in awel workflow, answering questions after binding always gives an error: \" Missing resources[ResourceType.Tool] required for runtime！\"\n\n![Image](https://github.com/user-attachments/assets/02003ecd-2713-4e12-a8c9-dcaf57f0ff5c)\n\n![Image](https://github.com/user-attachments/assets/753e71e4-a200-4c17-9823-643f8513c841)\n\n### What you expected to happen\n\nToolExport can be bound  knowledge base in awel workflow, \n\n### How to reproduce\n\n1, create awle workflow with ToolExport agent \n2, bind baidu_search tool and knowledge base\n3, ask questions after saving \n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "vnicers",
      "author_type": "User",
      "created_at": "2025-04-02T12:59:45Z",
      "updated_at": "2025-04-15T12:37:51Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2580/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2580",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2580",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:16.094157",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "now awel agent resource only support only one resource.",
          "created_at": "2025-04-06T12:41:42Z"
        },
        {
          "author": "vnicers",
          "body": "> now awel agent resource only support only one resource.\n\nDoes it currently support only one resource type or one resource, is this true for all agents? Are there plans to support more than one later?",
          "created_at": "2025-04-07T08:29:27Z"
        }
      ]
    },
    {
      "issue_number": 2586,
      "title": "[Bug] [Module Name] Bug title",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nMacOS(M1, M2...)\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [x] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n<img width=\"1007\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/d8d7b6ee-bfd6-41b9-a352-9416b9fc91cf\" />\n<img width=\"1074\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/dfee9d62-12c2-4112-aeae-471ea5ec6c92\" />\n\n### Models information\n\n计算出来的数据库显示商品名称，但是在preview显示不出来少一列\n\n### What happened\n\n要么计算出来显示不出来，要么现实出来少列\n\n### What you expected to happen\n\n要么计算出来显示不出来，要么现实出来少列\n\n### How to reproduce\n\n要么计算出来显示不出来，要么现实出来少列\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "braveryhui",
      "author_type": "User",
      "created_at": "2025-04-04T12:54:39Z",
      "updated_at": "2025-04-15T12:37:04Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2586/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2586",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2586",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:16.270702",
      "comments": [
        {
          "author": "braveryhui",
          "body": "2025-04-05 15:19:15 appledeMacBook-Pro-2.local dbgpt.agent.util.api_call[44219] ERROR data prepare exception！Data Query Exception!\\nSQL[ WITH  \"inventory_health\"  AS (   SELECT       \"product_code\"  AS 商品编码,      \"product_name\"  AS 商品名称,      \"unit\"  AS 单位,      \"current_inventory\"  AS 当前库存,      \"i",
          "created_at": "2025-04-05T07:42:22Z"
        },
        {
          "author": "braveryhui",
          "body": "这种问题 怎么调试",
          "created_at": "2025-04-05T07:43:10Z"
        },
        {
          "author": "braveryhui",
          "body": "[分析思路]\n双重补货因子：同步考虑安全库存保护与月销售速度\n需求精确预测：使用月销量/30*7换算7日需求（保留3位小数精度）\n动态库存计算：可用库存 = (current_inventory + procurement_in_transit) - 7日预测需求\n智能补货触发：当可用库存 < minimum_inventory时触发补货\n弹性补货公式：补货量=安全库存 + 7日需求 - 可用库存（最低补货量=周需求）\nError:Data Query Exception! SQL[ SELECT \"product_code\" AS 产品编码, \"product_name\" AS 产品名称, ",
          "created_at": "2025-04-05T10:06:04Z"
        }
      ]
    },
    {
      "issue_number": 2587,
      "title": "[Feature][ChatDB] MCP功能有问题",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nCan DB-GPT support xiyansql-qwencoder-3b based on MCP？（https://github.com/XGenerationLab/xiyan_mcp_server)\n\n\nNeed it badly. Thankssssssssss a lot!\n\n### Use case\n\n想通过mcp协议用DB-GPT调用XiYan-SQL的模型（们），不知道现在是否支持\n\n根据文档里面使用mcp的方法，我没办法调用自己写的服务端\n\n希望能给出mcp更详细的示例\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nHigh\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Lylinnnnn",
      "author_type": "User",
      "created_at": "2025-04-05T15:11:53Z",
      "updated_at": "2025-04-15T12:36:41Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2587/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 1
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2587",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2587",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:16.433215",
      "comments": [
        {
          "author": "fangyinc",
          "body": "Now just support MCP SSE API.",
          "created_at": "2025-04-10T08:21:27Z"
        }
      ]
    },
    {
      "issue_number": 2592,
      "title": "arm支持",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n你好，docker镜像能否添加arm支持\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "giszh86",
      "author_type": "User",
      "created_at": "2025-04-08T05:39:01Z",
      "updated_at": "2025-04-15T12:36:19Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2592/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2592",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2592",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:16.638464",
      "comments": []
    },
    {
      "issue_number": 2593,
      "title": "[Bug] [AWEL] workflow cannot config",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nMacOS(M1, M2...)\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [x] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nMAC M2\n\n### Models information\n\nuv run dbgpt start webserver --config configs/dbgpt-proxy-openai.toml  \n\n### What happened\n\n![Image](https://github.com/user-attachments/assets/4a288a03-6d45-4371-a82c-79dd8d6bd6f3)\n\n\nThere can not open and config.\n\n### What you expected to happen\n\nwhen add workflow node in chrome brower.\n\n### How to reproduce\n\n DB-GPT git:(main) ✗ uv run dbgpt start webserver --config configs/dbgpt-proxy-openai.toml  \n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "zyclove",
      "author_type": "User",
      "created_at": "2025-04-08T07:55:51Z",
      "updated_at": "2025-04-15T12:35:56Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2593/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2593",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2593",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:16.638506",
      "comments": []
    },
    {
      "issue_number": 2594,
      "title": "[Feature][ChatDB]如何可以实现多个数据库联查",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n想实现多个数据库联查，比如从A数据库获取人员基本信息，从B数据库获取人员的工作信息，查询入口都是人员的身份证号，但是人员的不同信息存储在不同的数据库系统中。麻烦请问这种可以实现吗？\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "oceankai",
      "author_type": "User",
      "created_at": "2025-04-08T10:11:31Z",
      "updated_at": "2025-04-15T12:35:33Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2594/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2594",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2594",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:16.638516",
      "comments": [
        {
          "author": "braveryhui",
          "body": "同问",
          "created_at": "2025-04-08T14:41:15Z"
        },
        {
          "author": "Franklinouy",
          "body": "没法，好垃圾这玩意",
          "created_at": "2025-04-11T06:44:17Z"
        }
      ]
    },
    {
      "issue_number": 2596,
      "title": "[Bug] 启动报错",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nRTX4090 24G\n\n### Models information\n\n硅基流动API\n\n### What happened\n\n使用启动命令：uv run dbgpt start webserver --config configs/dbgpt-proxy-siliconflow.toml\n报错无法启动：\n  x No solution found when resolving dependencies for split (python_full_version >= '3.12.4' and platform_machine ==\n  | 'x86_64' and sys_platform == 'darwin'):\n  `-> Because dbgpt-acc-auto:auto depends on torch{platform_machine == 'x86_64' and sys_platform ==\n      'darwin'}>=2.2.1,<2.3 and only the following versions of torch{platform_machine == 'x86_64' and sys_platform ==\n      'darwin'} are available:\n          torch{platform_machine == 'x86_64' and sys_platform == 'darwin'}<=2.2.1\n          torch{platform_machine == 'x86_64' and sys_platform == 'darwin'}==2.2.2\n          torch{platform_machine == 'x86_64' and sys_platform == 'darwin'}>2.3\n      we can conclude that dbgpt-acc-auto:auto depends on torch>=2.2.1,<=2.2.2.\n      And because dbgpt-mono depends on torch==2.4.0, we can conclude that dbgpt-mono and dbgpt-acc-auto:auto are\n      incompatible.\n      And because your workspace requires dbgpt-acc-auto:auto and dbgpt-mono, we can conclude that your workspace's\n      requirements are unsatisfiable.\n\n\n\n### What you expected to happen\n\n启动报错，touch依赖冲突，昨天还能启动的，早上突然就报错了，而且不知为何电脑老有概率会被卡死，只能强制重启解决\n\n### How to reproduce\n\n使用启动命令：uv run dbgpt start webserver --config configs/dbgpt-proxy-siliconflow.toml 报错\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "DESAKEY",
      "author_type": "User",
      "created_at": "2025-04-09T01:50:56Z",
      "updated_at": "2025-04-15T12:34:48Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2596/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2596",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2596",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:16.833770",
      "comments": []
    },
    {
      "issue_number": 2598,
      "title": "models-provider指定问题",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n我打算在内网部署使用我司自己的大模型应用，但是发现provider是固定几项，是否可以开放配置文件自定义呢\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "lixiaoyao-2019",
      "author_type": "User",
      "created_at": "2025-04-09T03:31:16Z",
      "updated_at": "2025-04-15T12:33:58Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2598/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2598",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2598",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:16.833797",
      "comments": [
        {
          "author": "lixiaoyao-2019",
          "body": "我想请问，配置文件中，\n[[models.llms]]\nname = \"gpt-4o\"\nprovider = \"proxy/openai\"\napi_base = \"${env:OPENAI_API_BASE:-[https://api.openai.com/v1}\"](https://api.openai.com/v1%7D%22)\napi_key = \"${env:OPENAI_API_KEY:-sk-xxx}\"\n比如我想使用我司自己的代理模型，内网部署，有指引方式么？",
          "created_at": "2025-04-09T06:06:47Z"
        },
        {
          "author": "fangyinc",
          "body": "See http://docs.dbgpt.cn/docs/next/installation/advanced_usage/More_proxyllms/",
          "created_at": "2025-04-10T08:20:36Z"
        },
        {
          "author": "lixiaoyao-2019",
          "body": "\n\n\n> See http://docs.dbgpt.cn/docs/next/installation/advanced_usage/More_proxyllms/\n\n按引导配置后\n\n![Image](https://github.com/user-attachments/assets/8fa2f1d2-fe8d-42ed-a0d4-6d7b82281231)\n可以启动，但是无法回答问题\n后台报错\n![Image](https://github.com/user-attachments/assets/d2d57b87-44b6-49ee-8062-42a6e00c8f17)",
          "created_at": "2025-04-11T10:09:42Z"
        }
      ]
    },
    {
      "issue_number": 2599,
      "title": "[Bug] [] 工作流应用多轮对话会产生多个chat history 记录",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nOS: windows 11\nCPU: Intel(R) Core(TM) i5-1035G1 CPU @ 1.00GHz 1.19 GHz\n\n### Models information\n\nLLM: deepseek:32b\nembedding: bge-m3\n\n### What happened\n\n工作流发布应用后，多轮对话会产生多个 chat history 记录，且原对话中样式展示不正确。\n\n![Image](https://github.com/user-attachments/assets/1054ee46-a3bd-47a0-a7f9-507b1781d488)\n\n![Image](https://github.com/user-attachments/assets/724e5181-9dd1-4d69-9244-ab729ab19bc7)\n\n![Image](https://github.com/user-attachments/assets/053aeb48-0c57-4226-9875-48fa7ed02c1b)\n\n### What you expected to happen\n\n只保留当前会话的 chat history 记录。\n\n### How to reproduce\n\n1. 基于 rag-chat-awel-flow-template-zh.json 模板导入创建 awel 工作流，关联已有知识库；\n2. 创建应用程序，关联对应 awel 工作流；\n3. 点击应用程序对话，进行首次对话，对话返回正常；\n\n### Additional context\n\n经排查发现对话结束后会触发2次`end_current_round`，第一次是触发 `BaseHOLLMOperator.after_dag_end`，第二次是`MultiAgents.app_agent_chat`主动触发。\n\n`MultiAgents.app_agent_chat`中 chat history 用的是原`conv_id`，`BaseHOLLMOperator.after_dag_end`用的是 `agent_conv_id` 每轮对话都会+1。\n\n目前尝试了2种修改方案都不行\n1. BaseHOLLMOperator.after_dag_end 使用 conv_id，数据重复保存时conv_id、index 冲突报错。\n2. BaseHOLLMOperator.after_dag_end 使用 conv_id，不触发`MultiAgents.app_agent_chat`中的`end_current_round`，问题在于 BaseHOLLMOperator 中未保存 think text。\n![Image](https://github.com/user-attachments/assets/d7e817e5-67ab-4d21-9ce3-2fd0f9bfe0b6)\n\n![Image](https://github.com/user-attachments/assets/daadf2d1-e656-4988-8974-19c9bc06b8b3)\n\n调试过程中有几个疑问：\n1. AI message 与 view message 有什么区别；\n2. TeamMode.AWEL_LAYOUT 类型工作流应用为何不直接走 ChatScene.ChatFlow 分支逻辑；\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "cumbersun",
      "author_type": "User",
      "created_at": "2025-04-09T03:38:40Z",
      "updated_at": "2025-04-15T12:33:35Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2599/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2599",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2599",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:17.029763",
      "comments": []
    },
    {
      "issue_number": 2610,
      "title": "[Bug] [Awel] workflow node copy not work",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nN/A\n\n### Models information\n\nN/A\n\n### What happened\n\nThe node created by clicking the Copy button cannot be saved, The error:\nResource resource_dbgpt.agent.core.plan.awel.agent_operator_resource.AWELAgentKnowledgeResource_0 not registered.\n![Image](https://github.com/user-attachments/assets/cfced3ae-75f0-492e-b1fc-0badce9f616d)\n![Image](https://github.com/user-attachments/assets/0ccfe8a3-15d5-40a3-b14b-255eae620bc6)\n\n### What you expected to happen\n\ncreate workflow success with copy node\n\n### How to reproduce\n\ncreate workflow and copy node,and save \n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "vnicers",
      "author_type": "User",
      "created_at": "2025-04-10T08:30:38Z",
      "updated_at": "2025-04-15T12:32:25Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2610/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2610",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2610",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:17.029790",
      "comments": []
    },
    {
      "issue_number": 2611,
      "title": "[Bug] [Module Name] Bug title 上传文档嵌入报错",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU和CPU都足够\n\n### Models information\n\nLLM: qwen2.5-72B\nembedding: m3e-base\n\n### What happened\n\n我在上传文档时给出了下面的错误，怎么解决，embedding模型是可以正常访问的，其它文档也可以正常上传，就是上传这个文档就给出了错误，其中这个文档是一个很大的文档，每次上传大的文档都是会出现下面的错误，小文档却没问题：\ndocument embedding, failed:test.docx, HTTPConnectionPool(host='localhost', port=9777): Max retries exceeded with url: /v1/embeddings (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fedbc1bad10>: Failed to establish a new connection: [Errno 111] Connection refused'))\n\n### What you expected to happen\n\n希望能尽快给我定位是什么问题然后解决\n\n### How to reproduce\n\n 可以测试上传大文件\n\n### Additional context\n\n \n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "deng-jinxiong",
      "author_type": "User",
      "created_at": "2025-04-10T09:19:04Z",
      "updated_at": "2025-04-15T12:32:01Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2611/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2611",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2611",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:17.029861",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "can you try transform docx -> pdf?",
          "created_at": "2025-04-11T01:47:24Z"
        }
      ]
    },
    {
      "issue_number": 2612,
      "title": "[Bug] [db_server] 配置加入pgsql数据源时，数据源中带了schema信息，但是大模型生成的语句执行取数据时，不会用到schema信息。",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [x] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\ncpu\n\n### Models information\n\nLLM:gpt-4o\nembedding:text-embedding-3-small\n用的都是代理模式\n\n### What happened\n\n![Image](https://github.com/user-attachments/assets/1496bd90-3920-4991-89af-e8ac640d22b8)\n\n![Image](https://github.com/user-attachments/assets/7cc2b53c-5fd2-4a2c-a1af-e3807ffd7ae6)\n\n![Image](https://github.com/user-attachments/assets/f019b93f-59f5-4ede-88cb-2dd60dde0154)\n\n![Image](https://github.com/user-attachments/assets/687934c8-4ea1-4c3e-adaa-5e9a42790246)\n我试过生成的语句是对的，拷贝到navicat对应的数据库的schema执行不报错。\n\n接下来是我的尝试修改过程：\n\n![Image](https://github.com/user-attachments/assets/9802f7a5-2e76-4869-be37-a369823ca41e)\n如上修改后，引发编译启动就报错：\n\n![Image](https://github.com/user-attachments/assets/6531ddee-1004-4e49-af70-98a84d31ee85)\n\n报错信息如上：\n\n![Image](https://github.com/user-attachments/assets/c5524d01-cdb4-4e5c-8da1-140ec5bf5989)\n\n### What you expected to happen\n\n对于pgsql这种有schema隔离的数据源，在提示词或者知识库中没有明确说明schema信息的情况下，生成语句虽然没有带上schema信息，但希望在用实际数据源执行时，要在正确的schema数据源下执行。\n\n### How to reproduce\n\n1. 建立一个pgsql数据源，有schema信息\n2. 针对该数据源，创建一个数据科学 agent\n3. 进行会话，询问一个简单的问题\n4. 生成的语句在重试多次后，仍然报错。因为没有schema信息，执行报错。\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "jxlhxyp",
      "author_type": "User",
      "created_at": "2025-04-11T03:09:37Z",
      "updated_at": "2025-04-15T12:31:37Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2612/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2612",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2612",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:17.195392",
      "comments": [
        {
          "author": "jxlhxyp",
          "body": "我自己调试后做了一些修改，验证可以了！\n改动如下：\n\n![Image](https://github.com/user-attachments/assets/40ad88aa-57d0-4b15-a9fd-2c705fcd9576)\n\n![Image](https://github.com/user-attachments/assets/7d60d1d7-4a36-4231-a071-b6e073df961b)\n增加get_colums函数的实现，否则在启动加载summary的时候，会报错\n\n![Image](https://github.com/user-attachments/assets",
          "created_at": "2025-04-11T07:24:24Z"
        },
        {
          "author": "fangyinc",
          "body": "@jxlhxyp  可以给社区提个修复的 PR",
          "created_at": "2025-04-11T08:49:09Z"
        },
        {
          "author": "jxlhxyp",
          "body": "@fangyinc 好的",
          "created_at": "2025-04-11T08:50:47Z"
        }
      ]
    },
    {
      "issue_number": 2613,
      "title": "无法连接MySql数据库",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\n LLM_MODEL=siliconflow_proxyllm\n SILICONFLOW_MODEL_VERSION=THUDM/glm-4-9b-chat\n SILICONFLOW_API_BASE=https://api.siliconflow.cn/v1\n SILICONFLOW_API_KEY=sk-\n\n\n\n### What happened\n\nMySql8.0.21，2368张表\nmysql.ini完整配置：\n[mysqld]\nlocal_infile=ON\ncharacter-set-server=utf8mb4\nbind-address=0.0.0.0\nport=3306\ndefault-storage-engine=INNODB\nsecure_file_priv=''\nlog_bin_trust_function_creators=1\nngram_token_size=1\nthread_stack=256K\ngroup_concat_max_len=102400\n\ninnodb_buffer_pool_size=512M\ninnodb_buffer_pool_chunk_size=128M\ninnodb_buffer_pool_instances=8\n# 最大连接数\nmax_connections=500\n# 缓存已创建线程的数量\nthread_cache_size=50\n# 非交互式链接超时时间（超过该时间后，自动关闭空闲连接）单位：秒\nwait_timeout=28800\n# 交互式连接超时时间\ninteractive_timeout=28800\n# 客户端连接超时\nconnect_timeout=600\n# 定义内存中临时表的最大大小。如果临时表超出此大小，则会被写入磁盘\n# tmp_table_size=16M\n# 定义用户创建的 MEMORY 表的最大大小，建议与 tmp_table_size 保持一致，以避免性能瓶颈\n# max_heap_table_size=16M\n# 最大打开文件数\n# open_files_limit = 65535\n# InnoDB 缓冲池大小\n# innodb_buffer_pool_size = 12G\n\nmax_connect_errors=500\n\n\n[client]\ndefault-character-set=utf8mb4\n\n\n### What you expected to happen\n\n添加数据库连接时报错：\nRequest error\npoweraec Test connect Failure!'TABLENAME'\n\n\n\n### How to reproduce\n\n应用管理—数据库—MySql—create\n\n### Additional context\n\n我想知道是哪个地方出的问题，功能肯定是正常的，默认脚本正常\n\n是数据表太多，还是存在不规范命名，还是mysql相关配置有问题\n\n然后应该如何处理，能够正常连接使用\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "dwh1",
      "author_type": "User",
      "created_at": "2025-04-11T03:18:33Z",
      "updated_at": "2025-04-15T12:31:15Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2613/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2613",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2613",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:17.400384",
      "comments": []
    },
    {
      "issue_number": 2618,
      "title": "[Feature][model] Support `moonshotai/Kimi-VL-A3B-Thinking`",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nhttps://huggingface.co/moonshotai/Kimi-VL-A3B-Thinking\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "fangyinc",
      "author_type": "User",
      "created_at": "2025-04-13T02:28:17Z",
      "updated_at": "2025-04-15T12:30:27Z",
      "closed_at": "2025-04-15T08:29:03Z",
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2618/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2618",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2618",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:17.400409",
      "comments": []
    },
    {
      "issue_number": 2621,
      "title": "[Bug] [Module Name] Load package failed!No module named 'dbgpt.datasource.db_conn_info",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nLLM: QWEN\n\n### What happened\n\n源码部署，运行过程中持续报错Load package failed!No module named 'dbgpt.datasource.db_conn_info\n--- Logging error ---\nTraceback (most recent call last):\n  File \"E:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\dbgpts\\loader.py\", line 324, in _load_package_from_path\n    parsed_packages.append(parse_package_metadata(package))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\dbgpts\\loader.py\", line 282, in parse_package_metadata\n    return FlowPackage.build_from(pkg_dict, ext_metadata)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\dbgpts\\loader.py\", line 121, in build_from\n    return FlowPythonPackage.build_from(values, ext_dict)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\dbgpts\\loader.py\", line 131, in build_from\n    _, _, mods = cls.load_module_class(values, DAG)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\dbgpts\\loader.py\", line 109, in load_module_class\n    raise e\n  File \"E:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\dbgpts\\loader.py\", line 95, in load_module_class\n    with pkg_resources.path(name, \"__init__.py\") as path:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ASUS\\AppData\\Roaming\\uv\\python\\cpython-3.11.11-windows-x86_64-none\\Lib\\importlib\\resources\\_legacy.py\", line 25, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ASUS\\AppData\\Roaming\\uv\\python\\cpython-3.11.11-windows-x86_64-none\\Lib\\importlib\\resources\\_legacy.py\", line 121, in path\n    return _common.as_file(_common.files(package) / normalize_path(resource))\n                           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ASUS\\AppData\\Roaming\\uv\\python\\cpython-3.11.11-windows-x86_64-none\\Lib\\importlib\\resources\\_common.py\", line 22, in files\n    return from_package(get_package(package))\n                        ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ASUS\\AppData\\Roaming\\uv\\python\\cpython-3.11.11-windows-x86_64-none\\Lib\\importlib\\resources\\_common.py\", line 53, in get_package\n    resolved = resolve(package)\n               ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ASUS\\AppData\\Roaming\\uv\\python\\cpython-3.11.11-windows-x86_64-none\\Lib\\importlib\\resources\\_common.py\", line 44, in resolve\n    return cand if isinstance(cand, types.ModuleType) else importlib.import_module(cand)\n                                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ASUS\\AppData\\Roaming\\uv\\python\\cpython-3.11.11-windows-x86_64-none\\Lib\\importlib\\__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"C:\\Users\\ASUS\\.dbgpts\\packages\\f50355a54b4757f9835a4825c2f91f13\\financial-report-knowledge-factory\\financial_report_knowledge_factory\\__init__.py\", line 24, in <module>\n    from dbgpt.datasource.db_conn_info import DBConfig\nModuleNotFoundError: No module named 'dbgpt.datasource.db_conn_info'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\ASUS\\AppData\\Roaming\\uv\\python\\cpython-3.11.11-windows-x86_64-none\\Lib\\logging\\__init__.py\", line 1110, in emit     \n    msg = self.format(record)\n          ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ASUS\\AppData\\Roaming\\uv\\python\\cpython-3.11.11-windows-x86_64-none\\Lib\\logging\\__init__.py\", line 953, in format    \n    return fmt.format(record)\n           ^^^^^^^^^^^^^^^^^^\n  File \"E:\\DB-GPT\\.venv\\Lib\\site-packages\\coloredlogs\\__init__.py\", line 1140, in format\n    return logging.Formatter.format(self, record)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ASUS\\AppData\\Roaming\\uv\\python\\cpython-3.11.11-windows-x86_64-none\\Lib\\logging\\__init__.py\", line 687, in format    \n    record.message = record.getMessage()\n                     ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ASUS\\AppData\\Roaming\\uv\\python\\cpython-3.11.11-windows-x86_64-none\\Lib\\logging\\__init__.py\", line 377, in getMessage\n    msg = msg % self.args\n          ~~~~^~~~~~~~~~~\nTypeError: not all arguments converted during string formatting\nCall stack:\n  File \"C:\\Users\\ASUS\\AppData\\Roaming\\uv\\python\\cpython-3.11.11-windows-x86_64-none\\Lib\\threading.py\", line 1002, in _bootstrap      \n    self._bootstrap_inner()\n  File \"C:\\Users\\ASUS\\AppData\\Roaming\\uv\\python\\cpython-3.11.11-windows-x86_64-none\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n    self.run()\n  File \"C:\\Users\\ASUS\\AppData\\Roaming\\uv\\python\\cpython-3.11.11-windows-x86_64-none\\Lib\\threading.py\", line 982, in run\n    self._target(*self._args, **self._kwargs)\n  File \"E:\\DB-GPT\\packages\\dbgpt-app\\src\\dbgpt_app\\initialization\\scheduler.py\", line 46, in _scheduler\n    schedule.run_pending()\n  File \"E:\\DB-GPT\\.venv\\Lib\\site-packages\\schedule\\__init__.py\", line 854, in run_pending\n    default_scheduler.run_pending()\n  File \"E:\\DB-GPT\\.venv\\Lib\\site-packages\\schedule\\__init__.py\", line 101, in run_pending\n    self._run_job(job)\n  File \"E:\\DB-GPT\\.venv\\Lib\\site-packages\\schedule\\__init__.py\", line 173, in _run_job\n    ret = job.run()\n  File \"E:\\DB-GPT\\.venv\\Lib\\site-packages\\schedule\\__init__.py\", line 691, in run\n    ret = self.job_func()\n  File \"E:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\dbgpts\\loader.py\", line 442, in load_package\n    packages = _load_package_from_path(self._install_dir)\n  File \"E:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\util\\dbgpts\\loader.py\", line 326, in _load_package_from_path\n    logger.warning(f\"Load package failed!{str(e)}\", e)\nMessage: \"Load package failed!No module named 'dbgpt.datasource.db_conn_info'\"\nArguments: (ModuleNotFoundError(\"No module named 'dbgpt.datasource.db_conn_info'\"),)\n\n### What you expected to happen\n\n源码部署，程序可以运行，但运行过程中持续报错Load package failed!No module named 'dbgpt.datasource.db_conn_info\n\n### How to reproduce\n\nwindows11 源码部署 运行程序\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "tianliangz76",
      "author_type": "User",
      "created_at": "2025-04-14T02:59:44Z",
      "updated_at": "2025-04-15T12:29:40Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2621/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2621",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2621",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:17.400417",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "sorry about that , financial case in dbgpts now do not support in v0.7.0, so we suggest you downgrade your dbgpt version in dbgpt v0.6.2.",
          "created_at": "2025-04-14T16:03:26Z"
        }
      ]
    },
    {
      "issue_number": 2199,
      "title": "[Bug] [ChatDashboard] Prompts are not displaying.",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [X] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU\n\n### Models information\n\nLLM\n\n### What happened\n\n![Screenshot from 2024-12-13 14-13-26](https://github.com/user-attachments/assets/36d9573e-e141-4596-8178-06fe06f3048f)\r\nIn the prompt box on the dashboard page, my prompts are not displaying.\n\n### What you expected to happen\n\nIt should display the prompts I created myself.\n\n### How to reproduce\n\nIn the prompt box on the dashboard page, my prompts are not displaying.\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "jhscut",
      "author_type": "User",
      "created_at": "2024-12-13T06:16:40Z",
      "updated_at": "2025-04-15T08:11:30Z",
      "closed_at": "2024-12-13T07:55:27Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2199/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2199",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2199",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:17.603874",
      "comments": [
        {
          "author": "jhscut",
          "body": "I have tried creating prompts and selecting the 'chat_dashboard' scenario, but they still do not display.",
          "created_at": "2024-12-13T06:20:54Z"
        },
        {
          "author": "jhscut",
          "body": "Solved",
          "created_at": "2024-12-13T07:55:25Z"
        },
        {
          "author": "hhaishen",
          "body": "> Solved  已解决\n\nHow did you solve it? I'm also encountering the same issue as you. Can you tell me about it?",
          "created_at": "2025-04-15T08:11:29Z"
        }
      ]
    },
    {
      "issue_number": 1240,
      "title": "[Bug][Chat Data] The Chinese data queried in the chat is garbled.",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [X] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\ncpu\n\n### Models information\n\ngpt\n\n### What happened\n\n![image](https://github.com/eosphoros-ai/DB-GPT/assets/19237481/0ff7d116-5697-432f-8c77-e20211ebfd8e)\r\n\n\n### What you expected to happen\n\n如图所示\n\n### How to reproduce\n\n希望可以给出修改建议\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "huicewang",
      "author_type": "User",
      "created_at": "2024-03-03T11:53:46Z",
      "updated_at": "2025-04-15T07:27:09Z",
      "closed_at": "2024-04-24T21:04:44Z",
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1240/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1240",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1240",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:17.774711",
      "comments": [
        {
          "author": "huicewang",
          "body": "数据库中存储的中文数据是正常显示的，不是乱码",
          "created_at": "2024-03-03T11:59:26Z"
        },
        {
          "author": "Aries-ckt",
          "body": "What database is it and what is the character set?",
          "created_at": "2024-03-03T14:39:16Z"
        },
        {
          "author": "huicewang",
          "body": "utf8mb4",
          "created_at": "2024-03-03T14:49:36Z"
        },
        {
          "author": "Aries-ckt",
          "body": "can you paste your chat history response through web console and we will check what happened.",
          "created_at": "2024-03-04T15:52:01Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-04-03T21:05:30Z"
        }
      ]
    },
    {
      "issue_number": 2138,
      "title": "ModuleNotFoundError: No module named 'lyric'",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [X] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\ndevice :GPU\n\n### Models information\n\nMODEL:glm-4-chat-9b\r\n\n\n### What happened\n\nlyric cannot pip in python3\n\n### What you expected to happen\n\nhow to pip lyric\n\n### How to reproduce\n\nno \n\n### Additional context\n\nlyric cannot pip in python3\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "yangqiheng2019",
      "author_type": "User",
      "created_at": "2024-11-20T02:25:14Z",
      "updated_at": "2025-04-15T03:41:33Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2138/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2138",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2138",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:18.006432",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "try:\r\n```\r\npip install -e \".[code]\"\r\n```",
          "created_at": "2024-11-20T02:53:28Z"
        },
        {
          "author": "wjyrun",
          "body": "pip install lyric-py",
          "created_at": "2024-12-10T03:34:14Z"
        },
        {
          "author": "sunnf",
          "body": "> pip install lyric-py\n正确的方法，解决了我的问题。\n\n",
          "created_at": "2025-04-15T03:41:32Z"
        }
      ]
    },
    {
      "issue_number": 2626,
      "title": "[Bug] ERROR Missing dependencies for SOCKS support.",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n-GPU count 2\n-GPU Memory 24G\n\n\n### Models information\n\ntongyi的qwen-plus\n\n\n### What happened\n\n建立知识库的时候会报错ERROR Missing dependencies for SOCKS support.    chat_normal，chat_excel都没有问题.LLM和embedding是配置的tongyi，具体配置如下：\nlanguage = \"${env:DBGPT_LANG:-en}\"\napi_keys = []\nencrypt_key = \"your_secret_key\"\n\n# Server Configurations\n[service.web]\nhost = \"[0.0.0.0](http://0.0.0.0/)\"\nport = 10201\n\n[service.web.database]\ntype = \"sqlite\"\npath = \"pilot/meta_data/dbgpt.db\"\n\n[rag.storage]\n[rag.storage.vector]\ntype = \"chroma\"\npersist_path = \"pilot/data\"\n\n# Model Configurations\n[models]\n[[models.llms]]\nname = \"qwen-plus\"\nprovider = \"proxy/tongyi\"\napi_base = \"https://dashscope.aliyuncs.com/compatible-mode/v1\"\napi_key = \"sk-***********\"\n\n[[models.embeddings]]\nname = \"text-embedding-v3\"\nprovider = \"proxy/tongyi\"\napi_url = \"https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings\"\napi_key = \"sk-******************************\"\n报的具体错误如下：\n2025-04-15 09:35:41 ubuntu dbgpt.component[1317257] INFO /opt/dbgpt/DB-GPT/pilot/data/_knowledge_cache_/44f22f6b-fa2a-4781-901c-a8f770224c57.pdf page 63 extract text success\n2025-04-15 09:35:41 ubuntu dbgpt.storage.base[1317257] INFO Loading 114 chunks in 12 groups with 1 threads.\n2025-04-15 09:35:41 ubuntu dbgpt_ext.storage.vector_store.chroma_store[1317257] INFO ChromaStore load document\n2025-04-15 09:35:41 ubuntu dbgpt.model.cluster.worker.embedding_worker[1317257] INFO Receive embeddings request, model: text-embedding-v3\n2025-04-15 09:35:41 ubuntu dbgpt_ext.storage.vector_store.chroma_store[1317257] INFO ChromaStore load document\n2025-04-15 09:35:41 ubuntu dashscope[1317257] ERROR Missing dependencies for SOCKS support.\n2025-04-15 09:35:41 ubuntu dbgpt_ext.storage.vector_store.chroma_store[1317257] INFO ChromaStore load document\n2025-04-15 09:35:41 ubuntu dbgpt_ext.storage.vector_store.chroma_store[1317257] INFO ChromaStore load document\n2025-04-15 09:35:41 ubuntu dbgpt_ext.storage.vector_store.chroma_store[1317257] INFO ChromaStore load document\n2025-04-15 09:35:41 ubuntu dbgpt_ext.storage.vector_store.chroma_store[1317257] INFO ChromaStore load document\n2025-04-15 09:35:41 ubuntu dbgpt.model.cluster.worker.embedding_worker[1317257] INFO Receive embeddings request, model: text-embedding-v3\n2025-04-15 09:35:41 ubuntu dbgpt.model.cluster.worker.embedding_worker[1317257] INFO Receive embeddings request, model: text-embedding-v3\n2025-04-15 09:35:41 ubuntu dbgpt_ext.storage.vector_store.chroma_store[1317257] INFO ChromaStore load document\n2025-04-15 09:35:41 ubuntu dbgpt.model.cluster.worker.embedding_worker[1317257] INFO Receive embeddings request, model: text-embedding-v3\n2025-04-15 09:35:41 ubuntu dbgpt_ext.storage.vector_store.chroma_store[1317257] INFO ChromaStore load document\n2025-04-15 09:35:41 ubuntu dbgpt.model.cluster.worker.embedding_worker[1317257] INFO Receive embeddings request, model: text-embedding-v3\n2025-04-15 09:35:41 ubuntu dbgpt_ext.storage.vector_store.chroma_store[1317257] INFO ChromaStore load document\n2025-04-15 09:35:41 ubuntu dashscope[1317257] ERROR Missing dependencies for SOCKS support.\n2025-04-15 09:35:41 ubuntu dbgpt_ext.storage.vector_store.chroma_store[1317257] INFO ChromaStore load document\n2025-04-15 09:35:41 ubuntu dbgpt_ext.storage.vector_store.chroma_store[1317257] INFO ChromaStore load document\n2025-04-15 09:35:41 ubuntu dashscope[1317257] ERROR Missing dependencies for SOCKS support.\n2025-04-15 09:35:41 ubuntu dbgpt.model.cluster.worker.embedding_worker[1317257] INFO Receive embeddings request, model: text-embedding-v3\n2025-04-15 09:35:41 ubuntu dashscope[1317257] ERROR Missing dependencies for SOCKS support.\n2025-04-15 09:35:41 ubuntu dbgpt.model.cluster.worker.embedding_worker[1317257] INFO Receive embeddings request, model: text-embedding-v3\n2025-04-15 09:35:41 ubuntu dbgpt.model.cluster.worker.embedding_worker[1317257] INFO Receive embeddings request, model: text-embedding-v3\n2025-04-15 09:35:41 ubuntu dbgpt_ext.storage.vector_store.chroma_store[1317257] INFO ChromaStore load document\n2025-04-15 09:35:41 ubuntu dashscope[1317257] ERROR Missing dependencies for SOCKS support.\n2025-04-15 09:35:41 ubuntu dbgpt.model.cluster.worker.embedding_worker[1317257] INFO Receive embeddings request, model: text-embedding-v3\n2025-04-15 09:35:41 ubuntu dbgpt_serve.rag.service.service[1317257] ERROR document embedding, failed:人工智能发展报告.pdf, Missing dependencies for SOCKS support.\n2025-04-15 09:35:41 ubuntu dbgpt.model.cluster.worker.embedding_worker[1317257] INFO Receive embeddings request, model: text-embedding-v3\n2025-04-15 09:35:41 ubuntu dbgpt.model.cluster.worker.embedding_worker[1317257] INFO Receive embeddings request, model: text-embedding-v3\n2025-04-15 09:35:41 ubuntu dashscope[1317257] ERROR Missing dependencies for SOCKS support.\n2025-04-15 09:35:41 ubuntu dashscope[1317257] ERROR Missing dependencies for SOCKS support.\n2025-04-15 09:35:41 ubuntu dashscope[1317257] ERROR Missing dependencies for SOCKS support.\n2025-04-15 09:35:41 ubuntu dbgpt.model.cluster.worker.embedding_worker[1317257] INFO Receive embeddings request, model: text-embedding-v3\n2025-04-15 09:35:41 ubuntu dashscope[1317257] ERROR Missing dependencies for SOCKS support.\n2025-04-15 09:35:41 ubuntu dashscope[1317257] ERROR Missing dependencies for SOCKS support.\n2025-04-15 09:35:41 ubuntu dashscope[1317257] ERROR Missing dependencies for SOCKS support.\n2025-04-15 09:35:41 ubuntu dashscope[1317257] ERROR Missing dependencies for SOCKS support.\n2025-04-15 09:35:42 ubuntu dbgpt_app.knowledge.api[1317257] INFO /document/list params: new_test, doc_name=None doc_ids=[6] doc_type=None status=None page=1 page_size=20\ncurrent session:<sqlalchemy.orm.session.Session object at 0x7f7056e26f10>\n/opt/dbgpt/DB-GPT/.venv/lib/python3.11/site-packages/pydantic/main.py:426: UserWarning: Pydantic serializer warnings:\n  Expected `DocumentResponse` but got `dict` with value `{'__tablename__': 'knowle...828), 'questions': None}` - serialized value may not be as expected\n  return self.__pydantic_serializer__.to_python(\n\n### What you expected to happen\n\n请问大家该怎么修改\n\n### How to reproduce\n\n看起来是embedding模型通信时的问题，但是同样的配置llm通信就没有问题\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "nilin1998",
      "author_type": "User",
      "created_at": "2025-04-15T01:49:34Z",
      "updated_at": "2025-04-15T01:49:34Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2626/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2626",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2626",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:18.285160",
      "comments": []
    },
    {
      "issue_number": 2225,
      "title": "Elasticsearch Connection Issues",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [X] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nA6000\n\n### Models information\n\nlarge-chinese\n\n### What happened\n\nI configured the IP address for ES, but why does it show localhost when an error occurs?\n\n### What you expected to happen\n\nes connect success\n\n### How to reproduce\n\ndeployment,and .env has been modified\r\n<img width=\"1091\" alt=\"微信图片_20241220105921\" src=\"https://github.com/user-attachments/assets/a77a0880-8c64-44ff-8bcd-eb3e9f1a665b\" />\r\n<img width=\"351\" alt=\"微信图片_20241220110236\" src=\"https://github.com/user-attachments/assets/ff353825-8563-4866-a24f-13617b9eb153\" />\r\n\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "yuqiao9",
      "author_type": "User",
      "created_at": "2024-12-20T03:02:43Z",
      "updated_at": "2025-04-13T03:13:43Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2225/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2225",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2225",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:18.285183",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "it looks like es connection error,.\r\n- make sure your connection\r\n- debug `ElasticsearchStore` connect module",
          "created_at": "2024-12-20T07:51:08Z"
        },
        {
          "author": "yuqiao9",
          "body": "> 看起来像 ES 连接错误，。\r\n> \r\n> * 确保您的连接\r\n> * debug connect 模块`ElasticsearchStore`\r\n\r\nIt’s a connection error, but I don’t understand why it still uses localhost after I modified the .env file.",
          "created_at": "2024-12-20T07:54:46Z"
        },
        {
          "author": "Aries-ckt",
          "body": "what is your `ELASTICSEARCH_URL` value in `.env`",
          "created_at": "2024-12-20T08:00:40Z"
        },
        {
          "author": "yuqiao9",
          "body": "> what is your `ELASTICSEARCH_URL` value in `.env`\r\n\r\nthis is in docker container\r\n<img width=\"351\" alt=\"微信图片_20241220110236\" src=\"https://github.com/user-attachments/assets/42d0580e-4d10-411d-bf7f-b0c0e9d7bd26\" />\r\n<img width=\"278\" alt=\"微信图片_20241220160512\" src=\"https://github.com/user-attachments/",
          "created_at": "2024-12-20T08:06:19Z"
        },
        {
          "author": "Aries-ckt",
          "body": "can you use telnet to connect `telnet 192.168.8.105 123456`",
          "created_at": "2024-12-20T08:11:04Z"
        }
      ]
    },
    {
      "issue_number": 2607,
      "title": "[Bug] [AgentMemory]  After several rounds of question/answer, an embedding error occurs",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [x] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nLLM: proxy deepseek-r1\nEmbedding: proxy bge-m3\n\n### What happened\n\nAfter multiple conversations and Q&A, the following embedding error occurs:\nIt seems that the user's most recent questions and answers will be put into the vector database every time, and if the user answers the question too many times, and the user uses the API to call the embedding model, it will cause the HTTP request body to be too large and the call will fail,In our scenario, the request body limit is 2MB\n\nCan you provide a parameter that allows the user to choose to remember only the last N questions and answers?\n\n2025-04-10 03:05:07 | INFO | dbgpt_ext.storage.vector_store.chroma_store | ChromaStore similar search with scores\n2025-04-10 03:05:07 | INFO | dbgpt_ext.storage.vector_store.chroma_store | ChromaStore similar search with scores\n2025-04-10 03:05:07 | INFO | dbgpt.model.cluster.worker.embedding_worker | Receive embeddings request, model: BAAI/bge-m3\n2025-04-10 03:05:07 | WARNING | chromadb.segment.impl.vector.local_persistent_hnsw | Number of requested results 200 is greater than number of elements in index 3, updating n_results = 3\n2025-04-10 03:05:07 | INFO | dbgpt.model.cluster.worker.embedding_worker | Receive embeddings request, model: BAAI/bge-m3\n2025-04-10 03:05:07 | INFO | dbgpt.model.cluster.worker.embedding_worker | Receive embeddings request, model: BAAI/bge-m3\n2025-04-10 03:05:08 | INFO | dbgpt_ext.storage.vector_store.chroma_store | ChromaStore load document\n2025-04-10 03:05:08 | INFO | dbgpt_ext.storage.vector_store.chroma_store | ChromaStore load document\n2025-04-10 03:05:08 | INFO | dbgpt.model.cluster.worker.embedding_worker | Receive embeddings request, model: BAAI/bge-m3\n2025-04-10 03:05:09 | INFO | dbgpt_ext.storage.vector_store.chroma_store | ChromaStore load document\n2025-04-10 03:05:09 | INFO | dbgpt_ext.storage.vector_store.chroma_store | ChromaStore load document\n2025-04-10 03:05:09 | INFO | dbgpt.model.cluster.worker.embedding_worker | Receive embeddings request, model: BAAI/bge-m3\n2025-04-10 03:05:09 | ERROR | dbgpt.agent.core.base_agent | Generate reply exception!\nTraceback (most recent call last):\n  File \"/app/packages/dbgpt-core/src/dbgpt/agent/core/base_agent.py\", line 402, in generate_reply\n    thinking_messages, resource_info = await self._load_thinking_messages(\n                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/agent/core/base_agent.py\", line 1086, in _load_thinking_messages\n    memories = await self.read_memories(observation)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/agent/core/role.py\", line 218, in read_memories\n    memories = await self.memory.read(question)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/agent/core/memory/agent_memory.py\", line 293, in read\n    return await self.memory.read(observation, alpha, beta, gamma)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/agent/core/memory/hybrid.py\", line 267, in read\n    await self.save_memories_after_retrieval(short_term_discarded_memories)\n  File \"/app/packages/dbgpt-core/src/dbgpt/agent/core/memory/hybrid.py\", line 322, in save_memories_after_retrieval\n    await self._long_term_memory.write_batch(all_memories, self.now)\n  File \"/app/packages/dbgpt-core/src/dbgpt/agent/core/memory/long_term.py\", line 272, in write_batch\n    await self.write(short_term_memory, now=current_datetime)\n  File \"/app/packages/dbgpt-core/src/dbgpt/agent/core/memory/long_term.py\", line 253, in write\n    await blocking_func_to_async(\n  File \"/app/packages/dbgpt-core/src/dbgpt/util/executor_utils.py\", line 70, in blocking_func_to_async\n    return await loop.run_in_executor(executor, run_with_context)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/util/executor_utils.py\", line 67, in run_with_context\n    return ctx.run(partial(func, *args, **kwargs))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/rag/retriever/time_weighted.py\", line 152, in load_document\n    return self._index_store.load_document(dup_docs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-ext/src/dbgpt_ext/storage/vector_store/chroma_store.py\", line 227, in load_document\n    self._add_texts(texts=texts, metadatas=chroma_metadatas, ids=ids)\n  File \"/app/packages/dbgpt-ext/src/dbgpt_ext/storage/vector_store/chroma_store.py\", line 344, in _add_texts\n    embeddings = self.embeddings.embed_documents(texts)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/cluster/embedding/remote_embedding.py\", line 16, in embed_documents\n    return self.worker_manager.sync_embeddings(params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/cluster/worker/manager.py\", line 838, in sync_embeddings\n    return self.worker_manager.sync_embeddings(params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/cluster/worker/manager.py\", line 519, in sync_embeddings\n    return worker_run_data.worker.embeddings(params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/cluster/worker/embedding_worker.py\", line 121, in embeddings\n    return self._embeddings_impl.embed_documents(textx)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/rag/embedding/embeddings.py\", line 869, in embed_documents\n    return _handle_request_result(res)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/rag/embedding/embeddings.py\", line 639, in _handle_request_result\n    res.raise_for_status()\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/requests/models.py\", line 1024, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 413 Client Error: Payload Too Large for url: http://10.132.122.228:8001/v1/embeddings\n2025-04-10 03:05:09 | ERROR | dbgpt.agent.core.base_agent | Generate reply exception!\nTraceback (most recent call last):\n  File \"/app/packages/dbgpt-core/src/dbgpt/agent/core/base_agent.py\", line 402, in generate_reply\n    thinking_messages, resource_info = await self._load_thinking_messages(\n                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/agent/core/base_agent.py\", line 1086, in _load_thinking_messages\n    memories = await self.read_memories(observation)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/agent/core/role.py\", line 218, in read_memories\n    memories = await self.memory.read(question)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/agent/core/memory/agent_memory.py\", line 293, in read\n    return await self.memory.read(observation, alpha, beta, gamma)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/agent/core/memory/hybrid.py\", line 267, in read\n    await self.save_memories_after_retrieval(short_term_discarded_memories)\n  File \"/app/packages/dbgpt-core/src/dbgpt/agent/core/memory/hybrid.py\", line 322, in save_memories_after_retrieval\n    await self._long_term_memory.write_batch(all_memories, self.now)\n  File \"/app/packages/dbgpt-core/src/dbgpt/agent/core/memory/long_term.py\", line 272, in write_batch\n    await self.write(short_term_memory, now=current_datetime)\n  File \"/app/packages/dbgpt-core/src/dbgpt/agent/core/memory/long_term.py\", line 253, in write\n    await blocking_func_to_async(\n  File \"/app/packages/dbgpt-core/src/dbgpt/util/executor_utils.py\", line 70, in blocking_func_to_async\n    return await loop.run_in_executor(executor, run_with_context)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/util/executor_utils.py\", line 67, in run_with_context\n    return ctx.run(partial(func, *args, **kwargs))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/rag/retriever/time_weighted.py\", line 152, in load_document\n    return self._index_store.load_document(dup_docs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-ext/src/dbgpt_ext/storage/vector_store/chroma_store.py\", line 227, in load_document\n    self._add_texts(texts=texts, metadatas=chroma_metadatas, ids=ids)\n  File \"/app/packages/dbgpt-ext/src/dbgpt_ext/storage/vector_store/chroma_store.py\", line 344, in _add_texts\n    embeddings = self.embeddings.embed_documents(texts)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/cluster/embedding/remote_embedding.py\", line 16, in embed_documents\n    return self.worker_manager.sync_embeddings(params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/cluster/worker/manager.py\", line 838, in sync_embeddings\n    return self.worker_manager.sync_embeddings(params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/cluster/worker/manager.py\", line 519, in sync_embeddings\n    return worker_run_data.worker.embeddings(params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/cluster/worker/embedding_worker.py\", line 121, in embeddings\n    return self._embeddings_impl.embed_documents(textx)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/rag/embedding/embeddings.py\", line 869, in embed_documents\n    return _handle_request_result(res)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/rag/embedding/embeddings.py\", line 639, in _handle_request_result\n    res.raise_for_status()\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/requests/models.py\", line 1024, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 413 Client Error: Payload Too Large for url: http://10.132.122.228:8001/v1/embeddings\n\n### What you expected to happen\n\nEnsure that the Q&A can proceed normally\n\n### How to reproduce\n\n1, Long prompt words\n2, The number of questions and answers more than 8 times\n3, Embedding request body set  2MB limit\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "vnicers",
      "author_type": "User",
      "created_at": "2025-04-10T03:55:43Z",
      "updated_at": "2025-04-12T12:49:01Z",
      "closed_at": "2025-04-12T12:49:01Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2607/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2607",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2607",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:18.542281",
      "comments": []
    },
    {
      "issue_number": 2193,
      "title": "[Bug] [agent] Missing resources required for runtime",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU COUNT:1 - 16G\n\n### Models information\n\nLLM: vocuna-13b-v1.5 Embedding model: text2vec-large-chinese\n\n### What happened\n\n![Screenshot from 2024-12-12 15-31-19](https://github.com/user-attachments/assets/b9b57093-d9bd-471e-8ae9-e7091eedf64d)\r\n![Screenshot from 2024-12-12 15-31-19](https://github.com/user-attachments/assets/b8b5bcdf-2b05-4fcb-b609-45f31cae19af)\r\nWhen using the AWEL agent resource knowledge, an error occurs with the message: 'Missing resources required for runtime!'\r\n\n\n### What you expected to happen\n\nPreviously, when using the knowledge base, this error did not occur.\n\n### How to reproduce\n\nI have shown through a diagram the error encountered when constructing the AWEL.\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "jhscut",
      "author_type": "User",
      "created_at": "2024-12-12T07:38:54Z",
      "updated_at": "2025-04-11T21:05:04Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2193/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2193",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2193",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:18.542305",
      "comments": [
        {
          "author": "jhscut",
          "body": "![Screenshot from 2024-12-12 15-32-08](https://github.com/user-attachments/assets/f6dc68fb-dcc5-4780-ad98-d57c1dc3a16b)\r\nSorry, the image was uploaded twice. This one is the correct AWEL image.",
          "created_at": "2024-12-12T07:40:22Z"
        },
        {
          "author": "Aries-ckt",
          "body": "DataScientist need Database Resource, not the Knowledge Resource",
          "created_at": "2024-12-12T14:37:43Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-04-11T21:05:02Z"
        }
      ]
    },
    {
      "issue_number": 2189,
      "title": "[Doc][Module Name] Chat Financial Report No context data",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n知识库切片里有信息，但聊天显示找不到该信息\r\n![image](https://github.com/user-attachments/assets/7ef85c5c-ed03-4c91-8f0b-0a67ab3d2709)\r\n![image](https://github.com/user-attachments/assets/ce34967f-5b5f-4416-b4ad-56e322e7efc0)\r\n\n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "lll-Dragon",
      "author_type": "User",
      "created_at": "2024-12-11T08:41:32Z",
      "updated_at": "2025-04-10T21:05:23Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2189/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2189",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2189",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:18.822152",
      "comments": [
        {
          "author": "lll-Dragon",
          "body": "![image](https://github.com/user-attachments/assets/e7614d70-3db2-4c75-af9c-0c90ac271e8f)\r\n",
          "created_at": "2024-12-11T09:10:11Z"
        },
        {
          "author": "Aries-ckt",
          "body": "check prompt log if there are some `贵州航天` knowledge context.",
          "created_at": "2024-12-11T11:11:15Z"
        },
        {
          "author": "lll-Dragon",
          "body": "但是问贵州航天资产负债率可以查到相关信息\r\n![image](https://github.com/user-attachments/assets/6496d5e2-7073-4dad-8230-69369647c28f)\r\n\r\n![image](https://github.com/user-attachments/assets/02920a20-d03f-40cc-8d17-a83fe71721d6)\r\n",
          "created_at": "2024-12-11T12:18:28Z"
        },
        {
          "author": "lll-Dragon",
          "body": "WARNING No relevant docs were retrieved using the relevance score threshold 0.3\r\n![image](https://github.com/user-attachments/assets/255b2f7e-b966-4ca6-8ece-6942e11be551)\r\n",
          "created_at": "2024-12-11T14:00:46Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-04-10T21:05:22Z"
        }
      ]
    },
    {
      "issue_number": 2190,
      "title": "[Doc][Module Name] workflow is empty",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n从dbgpts安装知识构建workflow和财报问答机器人workflow后，工作流内容为空\r\n![image](https://github.com/user-attachments/assets/2e674c46-3d73-456c-9c91-ccef89221077)\r\n\n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "lll-Dragon",
      "author_type": "User",
      "created_at": "2024-12-11T08:50:29Z",
      "updated_at": "2025-04-10T21:05:21Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2190/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2190",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2190",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:19.011300",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "what means workflow is empty?",
          "created_at": "2024-12-11T11:02:04Z"
        },
        {
          "author": "lll-Dragon",
          "body": "这两个工作流里面没有内容\r\n![image](https://github.com/user-attachments/assets/f3e424f0-ac8a-4e37-ac23-ad31ab340520)\r\n",
          "created_at": "2024-12-11T11:18:01Z"
        },
        {
          "author": "Aries-ckt",
          "body": "这个是由awel代码写的，还没有可视化组件，如果需要看代码可以去dbgpts里面看看源码",
          "created_at": "2024-12-11T15:53:52Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-04-10T21:05:20Z"
        }
      ]
    },
    {
      "issue_number": 2217,
      "title": "[Feature][GraphRAG] Improve GraphRAG Text2GQL Through FineTuned Model (Ollama/HuggingFace)",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n_No response_\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nMedium\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "fanzhidongyzby",
      "author_type": "User",
      "created_at": "2024-12-18T08:17:25Z",
      "updated_at": "2025-04-10T10:22:46Z",
      "closed_at": "2025-04-10T10:22:46Z",
      "labels": [
        "enhancement",
        "Waiting for reply",
        "GraphRAG"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2217/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2217",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2217",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:19.250800",
      "comments": []
    },
    {
      "issue_number": 2604,
      "title": "[Bug] [client api] Client packages cannot be imported",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [x] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nN/A\n\n### What happened\n\nRefer to the documentation to install the client package, but the client package is not actually imported\nActually, the dbgpt-core package is imported, If you manually import the dbgpt-client package, you will find that the dbgpt-client package depends on the dbgpt-serve package and dbgpt-serve is not uploaded\n![Image](https://github.com/user-attachments/assets/a739a645-74be-40bb-9caa-4fb1a25fe748)\n\n![Image](https://github.com/user-attachments/assets/3d549903-198a-4b69-83f5-f1600dc1fe6c)\n\n![Image](https://github.com/user-attachments/assets/21e3d704-842f-402c-9ea5-9e33c7f7924d)\n\n![Image](https://github.com/user-attachments/assets/018939c9-4cda-4ff2-a0f3-929d87ed4d06)\n\n\n### What you expected to happen\n\nThe dbgpt client package can be imported normally\n\n### How to reproduce\n\nCreate a separate project, import the client package according to the document, and execute the Chat API sample code\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "vnicers",
      "author_type": "User",
      "created_at": "2025-04-10T01:15:42Z",
      "updated_at": "2025-04-10T02:23:50Z",
      "closed_at": "2025-04-10T02:23:50Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2604/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2604",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2604",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:19.250824",
      "comments": []
    },
    {
      "issue_number": 2299,
      "title": "[Bug] [Module Name] Unable to open the awel and community pages.\"",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\ncuda\n\n### Models information\n\nqwen2.5\n\n### What happened\n\nWhen I open the AWEL or DBGPT community on the frontend page, I receive a \"Request error {'error': {'message': '', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\" notification, and the backend indicates a 401 error.\r\n![image](https://github.com/user-attachments/assets/cda79003-1626-4271-985d-90a55d64f3b4)\r\n![image](https://github.com/user-attachments/assets/62712279-baeb-4cf3-aba4-81763f4a87fd)\r\n\n\n### What you expected to happen\n\nopen the awel and community pages.\n\n### How to reproduce\n\nOpen the front-end page and click  AWEL Flow or DBGPT community page\r\n\r\n\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "liuyu970321",
      "author_type": "User",
      "created_at": "2025-01-12T10:28:13Z",
      "updated_at": "2025-04-10T01:35:03Z",
      "closed_at": "2025-01-16T02:13:06Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2299/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2299",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2299",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:19.250832",
      "comments": [
        {
          "author": "Yemeimei",
          "body": "#*******************************************************************#\r\n#**                         API_KEYS                              **#\r\n#*******************************************************************#\r\n# API_KEYS - The list of API keys that are allowed to access the API. Each of the below",
          "created_at": "2025-01-14T07:20:05Z"
        },
        {
          "author": "liuyu970321",
          "body": "> #_**# #** API_KEYS **# #**_#\r\n> \r\n> # API_KEYS - The list of API keys that are allowed to access the API. Each of the below are an option, separated by commas.\r\n> #API_KEYS=dbgpt <<<<<<<<<<<<尝试注释掉这个设置！\r\n\r\n非常感谢",
          "created_at": "2025-01-16T02:13:06Z"
        },
        {
          "author": "QGcPV7EBU58rclpM",
          "body": "非常感谢",
          "created_at": "2025-04-10T01:35:02Z"
        }
      ]
    },
    {
      "issue_number": 2576,
      "title": "[Bug] [ElasticStore] AttributeError: 'ElasticsearchStoreConfig' object has no attribute 'dict'",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [x] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nhave nothing to do with\n\n### Models information\n\nhave nothing to do with\n\n### What happened\n\n- When using Elasticsearch as the vector storage solution in the RAG module, the configuration reading for Elasticsearch failed. The error message is:  \n```bash  \nFile \"/app/DB-GPT/packages/dbgpt-ext/src/dbgpt_ext/storage/vector_store/elastic_store.py\", line 170, in __init__  \n    elasticsearch_vector_config = vector_store_config.dict()  \n                                  ^^^^^^^^^^^^^^^^^^^^^^^^  \nAttributeError: 'ElasticsearchStoreConfig' object has no attribute 'dict'  \n```\n\n-  After reviewing the code, it was found that the parent class [`BaseParameters`](https://github.com/eosphoros-ai/DB-GPT/blob/59e34e2d893b1f9fc8c522dd2e3d2a460eed3869/packages/dbgpt-core/src/dbgpt/util/parameter_utils.py#L81) of [`ElasticsearchStoreConfig`](https://github.com/eosphoros-ai/DB-GPT/blob/59e34e2d893b1f9fc8c522dd2e3d2a460eed3869/packages/dbgpt-ext/src/dbgpt_ext/storage/vector_store/elastic_store.py#L78) does not have a `dict()` function. Therefore, `to_dict()` should be used here instead.\n\n### What you expected to happen\n\nNormal reading configuration\n```toml\n[rag.storage]\n[rag.storage.vector]\ntype = \"elasticsearch\"\n```\n\n### How to reproduce\n\n- Set\n ```toml\n[rag.storage]\n[rag.storage.vector]\ntype = \"elasticsearch\"\n\n```\n\n- Start service\n\n- Add or update a data source, such as MySQL.\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "geebytes",
      "author_type": "User",
      "created_at": "2025-04-02T07:31:00Z",
      "updated_at": "2025-04-09T23:36:44Z",
      "closed_at": "2025-04-09T23:36:44Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2576/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2576",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2576",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:19.420440",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "thanks for your contribution, we will merge it when test successful.",
          "created_at": "2025-04-06T12:42:57Z"
        }
      ]
    },
    {
      "issue_number": 2186,
      "title": "[Bug] [Module Name] Bug title chat_data web page has  no data.",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [X] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU集群\n\n### Models information\n\ntext2vec-large-chinese\r\nqwen2.5-7b\n\n### What happened\n\n问题1：![a9559b8cd398df46b3d5c29f9b0501e](https://github.com/user-attachments/assets/1173fd1f-828f-4011-8e04-69ad50917294)\r\n![d19c86e46dec4f94244d18b51826bfc](https://github.com/user-attachments/assets/398c605f-ca6b-4164-ab49-85eac9a48546)\r\n，如图所示，查询数据库中的表名，后端的输出是正确的，但是页面部分没有输出查询结果。\r\n问题2：\r\n![2f2679a3a1f3a97db8aadd5887703f7](https://github.com/user-attachments/assets/73baa87c-5987-4fa9-9e9e-11bedaf08827)\r\n如图所示，查询某表的前3条数据报错。\r\n\n\n### What you expected to happen\n\n对于问题1：将\"direct response\"的输出是想要的结果，为何在前端输出“暂无数据”，如何解决？\r\n对于问题2：如何解决报错？\n\n### How to reproduce\n\n正常运行服务，选择数据对话和数据库对话，提出问题\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "w371803361",
      "author_type": "User",
      "created_at": "2024-12-10T08:51:47Z",
      "updated_at": "2025-04-09T21:05:06Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2186/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2186",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2186",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:19.622109",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "have a retry several times?",
          "created_at": "2024-12-10T15:49:21Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-04-09T21:05:06Z"
        }
      ]
    },
    {
      "issue_number": 2187,
      "title": "[Doc][Module Name] Financial Report SQL update select limit",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n如何把LIMIT 5去掉\r\n![image](https://github.com/user-attachments/assets/ece02507-743a-46ae-b561-b23c7b2608a4)\r\n\n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "lll-Dragon",
      "author_type": "User",
      "created_at": "2024-12-10T15:26:30Z",
      "updated_at": "2025-04-09T21:05:05Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2187/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2187",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2187",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:19.840737",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "in dbgpts github repo, `dbgpts/workflow/financial-robot-app/chat_indicator.py` ",
          "created_at": "2024-12-10T15:51:42Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-04-09T21:05:04Z"
        }
      ]
    },
    {
      "issue_number": 2602,
      "title": "为什么pip不用就是要用uv呢，出了个错误都不知道怎么调",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n_No response_\n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "zzzsudo",
      "author_type": "User",
      "created_at": "2025-04-09T07:57:22Z",
      "updated_at": "2025-04-09T08:14:27Z",
      "closed_at": "2025-04-09T08:14:27Z",
      "labels": [
        "documentation",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2602/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2602",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2602",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:20.053142",
      "comments": []
    },
    {
      "issue_number": 2540,
      "title": "[Bug] uv run dbgpt start webserver stoped when llama-cpp-python",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU\n\n### Models information\n\nglm-4-9b-chat\nbge-large-zh-v1.5\n\n### What happened\n\nI have installed llama-cpp-python==0.3.7,but  stoped here, why it didn`t continew?\n![Image](https://github.com/user-attachments/assets/934ac49a-bee5-44a9-82e0-2ae669b452be)\n\n### What you expected to happen\n\nuv run dbgpt start webserver --config configs/dbgpt-local-glm.toml --index-url=https://pypi.tuna.tsinghua.edu.cn/simple\n\n\nno other log get!\n\n### How to reproduce\n\n```\nuv sync --all-packages \\\n--extra \"base\" \\\n--extra \"proxy_openai\" \\\n--extra \"rag\" \\\n--extra \"storage_chromadb\" \\\n--extra \"dbgpts\" \\\n--index-url=https://pypi.tuna.tsinghua.edu.cn/simple\n```\n\n```\nuv run dbgpt start webserver --config configs/dbgpt-local-glm.toml --index-url=https://pypi.tuna.tsinghua.edu.cn/simple\n```\n\ndbgpt-local-glm.toml:\n```\n[system]\n# Load language from environment variable(It is set by the hook)\nlanguage = \"${env:DBGPT_LANG:-zh}\"\napi_keys = []\nencrypt_key = \"your_secret_key\"\n\n# Server Configurations\n[service.web]\nhost = \"0.0.0.0\"\nport = 5670\n\n[service.web.database]\ntype = \"sqlite\"\npath = \"pilot/meta_data/dbgpt.db\"\n\n[rag.storage]\n[rag.storage.vector]\ntype = \"chroma\"\npersist_path = \"pilot/data\"\n\n# Model Configurations\n[models]\n[[models.llms]]\nname = \"THUDM/glm-4-9b-chat\"\nprovider = \"hf\"\n# If not provided, the model will be downloaded from the Hugging Face model hub\n# uncomment the following line to specify the model path in the local file system\n# path = \"the-model-path-in-the-local-file-system\"\npath = \"models/THUDM/glm-4-9b-chat\"\n\n[[models.embeddings]]\nname = \"BAAI/bge-large-zh-v1.5\"\nprovider = \"hf\"\n# If not provided, the model will be downloaded from the Hugging Face model hub\n# uncomment the following line to specify the model path in the local file system\n# path = \"the-model-path-in-the-local-file-system\"\npath = \"models/BAAI/bge-large-zh-v1.5\"\n\n```\n\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "sankexin",
      "author_type": "User",
      "created_at": "2025-03-27T07:19:33Z",
      "updated_at": "2025-04-06T20:36:14Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2540/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2540",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2540",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:20.053164",
      "comments": [
        {
          "author": "sankexin",
          "body": "or ,How to set up to not use llama-cpp-python library ?",
          "created_at": "2025-03-27T08:51:39Z"
        },
        {
          "author": "fangyinc",
          "body": "If you execute the following sync command successfully, it should not be blocked during run.\n```bash\nuv sync --all-packages \\\n--extra \"base\" \\\n--extra \"proxy_openai\" \\\n--extra \"rag\" \\\n--extra \"storage_chromadb\" \\\n--extra \"dbgpts\" \\\n--index-url=https://pypi.tuna.tsinghua.edu.cn/simple\n```\n\n`uv run` w",
          "created_at": "2025-03-27T21:41:01Z"
        },
        {
          "author": "sankexin",
          "body": "> If you execute the following sync command successfully, it should not be blocked during run.\n> \n> uv sync --all-packages \\\n> --extra \"base\" \\\n> --extra \"proxy_openai\" \\\n> --extra \"rag\" \\\n> --extra \"storage_chromadb\" \\\n> --extra \"dbgpts\" \\\n> --index-url=https://pypi.tuna.tsinghua.edu.cn/simple\n> `u",
          "created_at": "2025-03-31T04:25:54Z"
        },
        {
          "author": "sankexin",
          "body": "solve by ：--index-url=https://mirrors.aliyun.com/pypi/simple ",
          "created_at": "2025-04-01T01:55:31Z"
        },
        {
          "author": "braveryhui",
          "body": "[tool.uv]\nindex-url = \"https://pypi.tuna.tsinghua.edu.cn/simple/\"\nmanaged = true\n#试了各种切换源的办法最后在项目 pyproject.toml  文件追加上uv的源可以了  \n#MacBook M2  0.7. 0  llama-cpp-python 一直装不上",
          "created_at": "2025-04-01T11:55:19Z"
        }
      ]
    },
    {
      "issue_number": 2178,
      "title": "[Doc][Module Name] Chat Excel the table showed too small",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nChat Excel生成的表格太小，能不能让生成的表格大一点。\r\n![image](https://github.com/user-attachments/assets/5babfab9-48cb-4537-a4a8-7811484dbf93)\r\n\n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "lll-Dragon",
      "author_type": "User",
      "created_at": "2024-12-04T08:45:03Z",
      "updated_at": "2025-04-05T21:04:53Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2178/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2178",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2178",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:20.239448",
      "comments": [
        {
          "author": "lll-Dragon",
          "body": "还有，Chat Excel分析出的数据有问题，与实际的Excel里的数据对不上，导致后面的查询会报错。上面是Chat Excel分析出的数据，下面是Excel里实际的数据。\r\n![image](https://github.com/user-attachments/assets/38f36502-a5c1-4948-be70-d89b16bead79)\r\n![image](https://github.com/user-attachments/assets/384d3756-8c23-426a-8b4f-26b0de12a6c1)\r\n\r\n",
          "created_at": "2024-12-04T09:17:35Z"
        },
        {
          "author": "lll-Dragon",
          "body": "![image](https://github.com/user-attachments/assets/44be9c70-d26f-4a17-951c-0062cf0277bd)\r\n![image](https://github.com/user-attachments/assets/e5226871-bc4b-4b99-9bed-ac05daf4f199)\r\n",
          "created_at": "2024-12-04T09:43:10Z"
        },
        {
          "author": "Aries-ckt",
          "body": "could you provide your excel data?",
          "created_at": "2024-12-05T15:29:22Z"
        },
        {
          "author": "lll-Dragon",
          "body": "![image](https://github.com/user-attachments/assets/80297954-8ee6-44cc-a13f-cef90eb416ee)\r\n",
          "created_at": "2024-12-06T02:18:20Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-04-05T21:04:52Z"
        }
      ]
    },
    {
      "issue_number": 2168,
      "title": "[Bug] [Knowledge Cli Command]Fail to delete the knowledge space using command caused by httprequest 'data':null.   ",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [X] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU: 4090 , Count:1\n\n### Models information\n\nLLM: Qwen2.5-14B-Instruct, Embedding:text2vec-large-chinese\n\n### What happened\n\nwhen I try delete knowledge space or name just created on command line like,\r\n\r\n` dbgpt knowledge delete --space_name testdbgpt_knowledge`\r\n\r\nbut, get response error Exception like,\r\n\r\n`Exception: Http request error, code: 400, message: {\"success\":false,\"err_code\":\"E0001\",\"err_msg\":\"body.desc:Input should be a valid string;\",\"data\":null}`\r\n\r\nI found that `dbgpt/app/knowledge/_cli/knowledge_client.py`\r\n\r\n\r\n```\r\ndef knowledge_delete(\r\n    api_address: str, space_name: str, doc_name: str, confirm: bool = False\r\n): \r\n    client = KnowledgeApiClient(api_address)\r\n    space = KnowledgeSpaceRequest()\r\n\r\n    space.name = space_name\r\n    space_list = client.space_list(KnowledgeSpaceRequest(name=space.name))\r\n    if not space_list:\r\n        raise Exception(f\"No knowledge space name {space_name}\")\r\n```\r\n\r\nwhen I adjust to assign `space.desc='DB-GPT Cli'` and sent request using the space parameter, deletion successed.\r\n\r\n\r\n\r\n\r\n\n\n### What you expected to happen\n\n```\r\n2024-12-01 13:20:13 nsscyk dbgpt.serve.core.schemas[1113687] ERROR validation_exception_handler catch RequestValidationError: success=False err_code='E0001' err_msg='body.desc:Input should be a valid string;' data=None\r\nINFO:     127.0.0.1:47498 - \"POST /knowledge/space/delete HTTP/1.1\" 400 Bad Request\r\n\r\n```\r\n\r\nwhen I adjust to assign `space.desc='DB-GPT Cli'`, deletion successed.\n\n### How to reproduce\n\n### Use dbgpt knowledge Command Line\r\n- dbgpt knowledge load --space_name testdbgpt_knowledge --vector_store_type Chroma --local_doc_path ~/test\r\n- dbgpt knowledge delete --space_name testdbgpt_knowledge\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "toralee",
      "author_type": "User",
      "created_at": "2024-12-01T05:54:51Z",
      "updated_at": "2025-04-04T21:05:03Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2168/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2168",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2168",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:20.447356",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "which dbgpt version you use?",
          "created_at": "2024-12-01T15:47:00Z"
        },
        {
          "author": "toralee",
          "body": "> which dbgpt version you use?\r\n\r\ndbgpt --version\r\n\r\ndbgpt, version 0.6.1",
          "created_at": "2024-12-02T01:13:25Z"
        },
        {
          "author": "toralee",
          "body": "> > which dbgpt version you use?\r\n> \r\n> dbgpt --version\r\n> \r\n> dbgpt, version 0.6.1\r\n\r\ndbgpt, version 0.6.2  was the same exception as like, \r\n\r\n`Exception: Http request error, code: 400, message: {\"success\":false,\"err_code\":\"E0001\",\"err_msg\":\"body.desc:Input should be a valid string;\",\"data\":null}\r",
          "created_at": "2024-12-05T02:09:27Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-04-04T21:05:02Z"
        }
      ]
    },
    {
      "issue_number": 2171,
      "title": "[Doc][Module Name]  Upload Knowledge pdf error.",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n创建知识库添加数据源时出错，ERROR document embedding, failed:地表水环境质 量标准.pdf, list index out of range in upsert.\n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "lll-Dragon",
      "author_type": "User",
      "created_at": "2024-12-02T02:57:14Z",
      "updated_at": "2025-04-04T21:05:02Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2171/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2171",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2171",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:20.688857",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "could you show the more error log ?",
          "created_at": "2024-12-02T15:52:38Z"
        },
        {
          "author": "lll-Dragon",
          "body": "\r\n![1733225485405](https://github.com/user-attachments/assets/eda06a15-0fb9-4b94-b3cc-13064195c823)\r\n\r\n",
          "created_at": "2024-12-03T11:32:24Z"
        },
        {
          "author": "lll-Dragon",
          "body": "![image](https://github.com/user-attachments/assets/3488484a-9436-43d5-9690-577d6b747ee7)\r\n",
          "created_at": "2024-12-04T07:30:57Z"
        },
        {
          "author": "Aries-ckt",
          "body": "replace the other pdf? the same problem?",
          "created_at": "2024-12-05T02:32:25Z"
        },
        {
          "author": "lll-Dragon",
          "body": "一共上传了4个pdf文件，只有1个失败，其他3个都成功了。\r\n![image](https://github.com/user-attachments/assets/65105b71-3cb2-46e9-95b8-a1f10bbd9011)\r\n",
          "created_at": "2024-12-05T06:36:54Z"
        }
      ]
    },
    {
      "issue_number": 2539,
      "title": "[Bug] v0.7版本 SQLserver能链接但无法查询数据对话，所有关联的原生应用与流程无法使用",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [x] Chat Data\n- [ ] Chat Excel\n- [x] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [x] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nTesla L20\n\n### Models information\n\nQwen2.5-14B-Instruct\n\n### What happened\n\nSQLserver能链接但无法查询数据对话，所有关联的原生应用与流程无法使用\n试过2019last和2008R2两个版本均无法查询数据与对话\n\n![Image](https://github.com/user-attachments/assets/ca36c0be-8010-4f91-ad00-adc88c1945f9)\n\n![Image](https://github.com/user-attachments/assets/b8b41a69-3d06-4a7e-b140-909991675b4a)\n\n### What you expected to happen\n\nSQLserver能链接且可以查询数据与对话\n\n### How to reproduce\n\n链接sqlserver与原生DB与流程对话，模型知识库无法回答\n\n### Additional context\n\n_No response_\n",
      "state": "open",
      "author": "EdwinOlders11",
      "author_type": "User",
      "created_at": "2025-03-27T06:27:05Z",
      "updated_at": "2025-04-03T09:29:22Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2539/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2539",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2539",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:20.891629",
      "comments": [
        {
          "author": "dobet",
          "body": "+1",
          "created_at": "2025-04-03T09:29:21Z"
        }
      ]
    },
    {
      "issue_number": 2585,
      "title": "[Bug] [Module Name] mcp 使用报错",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [x] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nlinux\n\n### Models information\n\ndeepseek\n\n### What happened\n\n![Image](https://github.com/user-attachments/assets/03ca3929-994f-4b75-b83c-313d464f040e)\nnpx -y supergateway --stdio \"uvx mcp-server-fetch\"\n[supergateway] Starting...\n[supergateway] Supergateway is supported by Supermachine (hosted MCPs) - https://supermachine.ai\n[supergateway]   - outputTransport: sse\n[supergateway]   - Headers: (none)\n[supergateway]   - port: 8000\n[supergateway]   - stdio: uvx mcp-server-fetch\n[supergateway]   - ssePath: /sse\n[supergateway]   - messagePath: /message\n[supergateway]   - CORS enabled: false\n[supergateway]   - Health endpoints: (none)\n[supergateway] Listening on port 8000\n[supergateway] SSE endpoint: http://localhost:8000/sse\n[supergateway] POST messages: http://localhost:8000/message\n[supergateway] Child stderr: error: unrecognized subcommand 'mcp-server-fetch'\n启动报错，按照文档中流程尝试mcp功能，启动mcp server报错\n\n### What you expected to happen\n\n请老师帮忙解决\n\n### How to reproduce\n\n直接测试\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "adogwangwang",
      "author_type": "User",
      "created_at": "2025-04-03T06:04:18Z",
      "updated_at": "2025-04-03T06:29:54Z",
      "closed_at": "2025-04-03T06:29:54Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2585/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2585",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2585",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:21.059660",
      "comments": []
    },
    {
      "issue_number": 2412,
      "title": "[Bug] [tugraph] 文档上传切片处理时失败",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice: GPU\nGPU: 1 ,24GB\n\n\n### Models information\n\nllm: glm-4-9b-chat  text2vec-large-chinese\nembeding: text2vex-large-chinese\n\n### What happened\n\ndbgpt 版本（0.6.3），知识库文档上传，生成图谱切片处理的时候， 状态一直是running， 后台tugraph日志显示‘Graph name cannot be empty’ 。 偶尔切片处理成功，多数在running状态或failed，几分钟后点击看图谱是有生成。\n\n另外重新执行文档同步的时候，图谱会重复生成内容，不会检查是否已生成过，但状态还是FAILED。\n\n\n\n\n### What you expected to happen\n\n图谱库显示的日志报错： \ngraph name cannot be empty\n\n### How to reproduce\n\n1. 新建知识库\n2. 上传文档  （选图谱方式保存）\n3. 切片处理 （默认）\n4. 结果FAILED\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "z1s8h5",
      "author_type": "User",
      "created_at": "2025-03-07T09:01:45Z",
      "updated_at": "2025-04-03T04:22:56Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2412/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2412",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2412",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:21.059680",
      "comments": [
        {
          "author": "fangyinc",
          "body": "@fanzhidongyzby ",
          "created_at": "2025-03-07T12:03:39Z"
        },
        {
          "author": "Appointat",
          "body": "You should name the graph name correctly, for example \"graph1\", \"graph2\", etc.\nCan you show some screenshots?",
          "created_at": "2025-03-09T08:03:35Z"
        },
        {
          "author": "Aries-ckt",
          "body": "the same issue ? https://github.com/eosphoros-ai/DB-GPT/issues/2417",
          "created_at": "2025-03-09T13:08:55Z"
        },
        {
          "author": "liguanghua315",
          "body": "Can the OP's graph be used with the latest version of Neo4j installed? I can't use versions 3. X and 4. X, which correspond to JDK9 and 11. The latest version is 5. X, which corresponds to 17, right,Cannot input Chinese, Chinese people pit Chinese people\n",
          "created_at": "2025-03-11T01:43:44Z"
        },
        {
          "author": "z1s8h5",
          "body": "> You should name the graph name correctly, for example \"graph1\", \"graph2\", etc. Can you show some screenshots?\nseems there is no place to name the graph name, it will auto create the graph after I upload the document. pls check the below screenshots for the failed status\n\n![Image](https://github.co",
          "created_at": "2025-03-13T01:18:13Z"
        }
      ]
    },
    {
      "issue_number": 2581,
      "title": "[Bug] [refresh_hub_by_git] Dbgpts hub source refresh Error!",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [x] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [x] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nQwen/Qwen2.5-Coder-32B-Instruct\n\n\n### What happened\n\n从社区Git仓库刷新，会报错Request error，不管挂不挂梯子都会报错：\n`2025-04-03 01:07:32 ce499a60bec6 dbgpt_serve.dbgpts.hub.api.endpoints[1] INFO source_refresh\n2025-04-03 01:07:32 ce499a60bec6 dbgpt_serve.dbgpts.hub.service.service[1] INFO refresh_hub_by_git start!\nNo repos found, installing default repos eosphoros/dbgpts from https://github.com/eosphoros-ai/dbgpts.git\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/app/packages/dbgpt-serve/src/dbgpt_serve/dbgpts/hub/api/endpoints.py\", line 187, in source_refresh\n    await blocking_func_to_async(\n  File \"/app/packages/dbgpt-serve/src/dbgpt_serve/core/__init__.py\", line 32, in blocking_func_to_async\n    return await _blocking_func_to_async(executor, func, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/util/executor_utils.py\", line 70, in blocking_func_to_async\n    return await loop.run_in_executor(executor, run_with_context)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/util/executor_utils.py\", line 67, in run_with_context\n    return ctx.run(partial(func, *args, **kwargs))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-serve/src/dbgpt_serve/dbgpts/hub/service/service.py\", line 139, in refresh_hub_from_git\n    _install_default_repos_if_no_repos()\n  File \"/app/packages/dbgpt-core/src/dbgpt/util/dbgpts/repo.py\", line 276, in _install_default_repos_if_no_repos\n    add_repo(_DEFAULT_REPO, repo_url)\n  File \"/app/packages/dbgpt-core/src/dbgpt/util/dbgpts/repo.py\", line 302, in add_repo\n    clone_repo(repo, repo_group_dir, repo_name, repo_url, branch)\n  File \"/app/packages/dbgpt-core/src/dbgpt/util/dbgpts/repo.py\", line 348, in clone_repo\n    process = subprocess.Popen(\n              ^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/subprocess.py\", line 1022, in __init__\n    self._execute_child(args, executable, preexec_fn, close_fds,\n  File \"/usr/lib/python3.11/subprocess.py\", line 1899, in _execute_child\n    raise child_exception_type(errno_num, err_msg, err_filename)\nFileNotFoundError: [Errno 2] No such file or directory: 'git'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.11/logging/__init__.py\", line 1110, in emit\n    msg = self.format(record)\n          ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/logging/__init__.py\", line 953, in format\n    return fmt.format(record)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/logging/__init__.py\", line 687, in format\n    record.message = record.getMessage()\n                     ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/logging/__init__.py\", line 377, in getMessage\n    msg = msg % self.args\n          ~~~~^~~~~~~~~~~\nTypeError: not all arguments converted during string formatting\nCall stack:\n  File \"/opt/.uv.venv/bin/dbgpt\", line 10, in <module>\n    sys.exit(main())\n  File \"/app/packages/dbgpt-core/src/dbgpt/cli/cli_scripts.py\", line 229, in main\n    return cli()\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/click/core.py\", line 1161, in __call__\n    return self.main(*args, **kwargs)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/click/core.py\", line 1082, in main\n    rv = self.invoke(ctx)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/click/core.py\", line 1697, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/click/core.py\", line 1697, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/click/core.py\", line 1443, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/click/core.py\", line 788, in invoke\n    return __callback(*args, **kwargs)\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/cli.py\", line 458, in wrapper\n    return func(*args, **kwargs)\n  File \"/app/packages/dbgpt-app/src/dbgpt_app/_cli.py\", line 25, in start_webserver\n    run_webserver(config)\n  File \"/app/packages/dbgpt-app/src/dbgpt_app/dbgpt_server.py\", line 254, in run_webserver\n    run_uvicorn(param.service.web)\n  File \"/app/packages/dbgpt-app/src/dbgpt_app/dbgpt_server.py\", line 211, in run_uvicorn\n    uvicorn.run(\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/uvicorn/main.py\", line 579, in run\n    server.run()\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/uvicorn/server.py\", line 66, in run\n    return asyncio.run(self.serve(sockets=sockets))\n  File \"/usr/lib/python3.11/asyncio/runners.py\", line 188, in run\n    return runner.run(main)\n  File \"/usr/lib/python3.11/asyncio/runners.py\", line 120, in run\n    return self._loop.run_until_complete(task)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 149, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    await app(scope, receive, sender)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/routing.py\", line 715, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/routing.py\", line 735, in app\n    await route.handle(scope, receive, send)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    await app(scope, receive, sender)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/routing.py\", line 73, in app\n    response = await f(request)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 301, in app\n    raw_response = await run_endpoint_function(\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    return await dependant.call(**values)\n  File \"/app/packages/dbgpt-serve/src/dbgpt_serve/dbgpts/hub/api/endpoints.py\", line 194, in source_refresh\n    logger.error(\"Dbgpts hub source refresh Error!\", e)\nMessage: 'Dbgpts hub source refresh Error!'\nArguments: (FileNotFoundError(2, 'No such file or directory'),)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/app/packages/dbgpt-serve/src/dbgpt_serve/dbgpts/hub/api/endpoints.py\", line 187, in source_refresh\n    await blocking_func_to_async(\n  File \"/app/packages/dbgpt-serve/src/dbgpt_serve/core/__init__.py\", line 32, in blocking_func_to_async\n    return await _blocking_func_to_async(executor, func, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/util/executor_utils.py\", line 70, in blocking_func_to_async\n    return await loop.run_in_executor(executor, run_with_context)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/util/executor_utils.py\", line 67, in run_with_context\n    return ctx.run(partial(func, *args, **kwargs))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-serve/src/dbgpt_serve/dbgpts/hub/service/service.py\", line 139, in refresh_hub_from_git\n    _install_default_repos_if_no_repos()\n  File \"/app/packages/dbgpt-core/src/dbgpt/util/dbgpts/repo.py\", line 276, in _install_default_repos_if_no_repos\n    add_repo(_DEFAULT_REPO, repo_url)\n  File \"/app/packages/dbgpt-core/src/dbgpt/util/dbgpts/repo.py\", line 302, in add_repo\n    clone_repo(repo, repo_group_dir, repo_name, repo_url, branch)\n  File \"/app/packages/dbgpt-core/src/dbgpt/util/dbgpts/repo.py\", line 348, in clone_repo\n    process = subprocess.Popen(\n              ^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/subprocess.py\", line 1022, in __init__\n    self._execute_child(args, executable, preexec_fn, close_fds,\n  File \"/usr/lib/python3.11/subprocess.py\", line 1899, in _execute_child\n    raise child_exception_type(errno_num, err_msg, err_filename)\nFileNotFoundError: [Errno 2] No such file or directory: 'git'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.11/logging/__init__.py\", line 1110, in emit\n    msg = self.format(record)\n          ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/logging/__init__.py\", line 953, in format\n    return fmt.format(record)\n           ^^^^^^^^^^^^^^^^^^\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/coloredlogs/__init__.py\", line 1140, in format\n    return logging.Formatter.format(self, record)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/logging/__init__.py\", line 687, in format\n    record.message = record.getMessage()\n                     ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/logging/__init__.py\", line 377, in getMessage\n    msg = msg % self.args\n          ~~~~^~~~~~~~~~~\nTypeError: not all arguments converted during string formatting\nCall stack:\n  File \"/opt/.uv.venv/bin/dbgpt\", line 10, in <module>\n    sys.exit(main())\n  File \"/app/packages/dbgpt-core/src/dbgpt/cli/cli_scripts.py\", line 229, in main\n    return cli()\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/click/core.py\", line 1161, in __call__\n    return self.main(*args, **kwargs)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/click/core.py\", line 1082, in main\n    rv = self.invoke(ctx)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/click/core.py\", line 1697, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/click/core.py\", line 1697, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/click/core.py\", line 1443, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/click/core.py\", line 788, in invoke\n    return __callback(*args, **kwargs)\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/cli.py\", line 458, in wrapper\n    return func(*args, **kwargs)\n  File \"/app/packages/dbgpt-app/src/dbgpt_app/_cli.py\", line 25, in start_webserver\n    run_webserver(config)\n  File \"/app/packages/dbgpt-app/src/dbgpt_app/dbgpt_server.py\", line 254, in run_webserver\n    run_uvicorn(param.service.web)\n  File \"/app/packages/dbgpt-app/src/dbgpt_app/dbgpt_server.py\", line 211, in run_uvicorn\n    uvicorn.run(\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/uvicorn/main.py\", line 579, in run\n    server.run()\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/uvicorn/server.py\", line 66, in run\n    return asyncio.run(self.serve(sockets=sockets))\n  File \"/usr/lib/python3.11/asyncio/runners.py\", line 188, in run\n    return runner.run(main)\n  File \"/usr/lib/python3.11/asyncio/runners.py\", line 120, in run\n    return self._loop.run_until_complete(task)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 149, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    await app(scope, receive, sender)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/routing.py\", line 715, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/routing.py\", line 735, in app\n    await route.handle(scope, receive, send)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    await app(scope, receive, sender)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/starlette/routing.py\", line 73, in app\n    response = await f(request)\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 301, in app\n    raw_response = await run_endpoint_function(\n  File \"//opt/.uv.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    return await dependant.call(**values)\n  File \"/app/packages/dbgpt-serve/src/dbgpt_serve/dbgpts/hub/api/endpoints.py\", line 194, in source_refresh\n    logger.error(\"Dbgpts hub source refresh Error!\", e)\nMessage: 'Dbgpts hub source refresh Error!'\nArguments: (FileNotFoundError(2, 'No such file or directory'),)`\n\n### What you expected to happen\n\n看不到社区DBGPTS\n\n### How to reproduce\n\n![Image](https://github.com/user-attachments/assets/f4e64906-47f8-4990-b93b-e9870d261dcf)\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "tianliangz76",
      "author_type": "User",
      "created_at": "2025-04-03T01:18:23Z",
      "updated_at": "2025-04-03T02:47:04Z",
      "closed_at": "2025-04-03T02:47:04Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2581/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2581",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2581",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:21.264732",
      "comments": []
    },
    {
      "issue_number": 2547,
      "title": "[Bug] [model] \"model not found\" when restart model",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nMacOS(x86)\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [x] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [x] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nthe original setting models, such as Qwen/Qwen2.5-Coder-32\n\n### What happened\n\n1.stop the original model\n2.start the model again\n \n\"model not found\" when restart model\n\n![Image](https://github.com/user-attachments/assets/4344eb4a-59cd-4a09-8fa6-e27c345ecb3f)\n\n### What you expected to happen\n\n\nthe model start successfully\n\n### How to reproduce\n\nI use docker-compose to start the server\n\n1.stop the original model\n2.start the model again\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "dailyer",
      "author_type": "User",
      "created_at": "2025-03-28T06:28:36Z",
      "updated_at": "2025-04-02T16:42:37Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2547/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2547",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2547",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:23.065629",
      "comments": [
        {
          "author": "fangyinc",
          "body": "Restarting the model you configured in the configuration file (you `xxx.toml`) on the model page is not supported",
          "created_at": "2025-04-02T16:42:37Z"
        }
      ]
    },
    {
      "issue_number": 2570,
      "title": "[Bug] [Web] Editing the app configuration, sometimes the bound resources will be lost",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nN/A\n\n### What happened\n\nQuickly updating the app configuration will randomly cause the bound resources to be lost\n![Image](https://github.com/user-attachments/assets/fd80f061-44e4-48ef-aede-0c3445a21cc4)\n\n### What you expected to happen\n\nWhen editing an application, the bound resources cannot be lost\n\n### How to reproduce\n\n1  Open the app update page and quickly tap the update button\n2, Open the app update page again, and all the bound resources will be lost\n\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "vnicers",
      "author_type": "User",
      "created_at": "2025-04-01T09:34:18Z",
      "updated_at": "2025-04-02T12:19:46Z",
      "closed_at": "2025-04-02T12:19:46Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2570/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2570",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2570",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:23.231828",
      "comments": [
        {
          "author": "vnicers",
          "body": "app编辑页面打开之后马上点击更新就会必现",
          "created_at": "2025-04-01T09:36:35Z"
        }
      ]
    },
    {
      "issue_number": 2578,
      "title": "[Bug] [Module Name] mulit-agent 遇到报错，找不到数据源",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [x] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nlinux\n\n### Models information\n\ndeepseek\n\n### What happened\n\n![Image](https://github.com/user-attachments/assets/490f1558-bb6d-430c-8e79-768ab16329b6)\n在如图所示配置multi agent后，进行问答会报错如下，是哪里配置的有问题吗？\nTraceback (most recent call last):\n  File \"/usr/lib/python3.11/logging/__init__.py\", line 1110, in emit\n    msg = self.format(record)\n          ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/logging/__init__.py\", line 953, in format\n    return fmt.format(record)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/coloredlogs/__init__.py\", line 1140, in format\n    return logging.Formatter.format(self, record)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/logging/__init__.py\", line 687, in format\n    record.message = record.getMessage()\n                     ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/logging/__init__.py\", line 377, in getMessage\n    msg = msg % self.args\n          ~~~~^~~~~~~~~~~\nTypeError: not all arguments converted during string formatting\nCall stack:\n  File \"/app/packages/dbgpt-app/src/dbgpt_app/dbgpt_server.py\", line 326, in <module>\n    run_webserver(_config_file)\n  File \"/app/packages/dbgpt-app/src/dbgpt_app/dbgpt_server.py\", line 254, in run_webserver\n    run_uvicorn(param.service.web)\n  File \"/app/packages/dbgpt-app/src/dbgpt_app/dbgpt_server.py\", line 211, in run_uvicorn\n    uvicorn.run(\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/uvicorn/main.py\", line 579, in run\n    server.run()\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/uvicorn/server.py\", line 66, in run\n    return asyncio.run(self.serve(sockets=sockets))\n  File \"/usr/lib/python3.11/asyncio/runners.py\", line 188, in run\n    return runner.run(main)\n  File \"/usr/lib/python3.11/asyncio/runners.py\", line 120, in run\n    return self._loop.run_until_complete(task)\n  File \"/app/packages/dbgpt-serve/src/dbgpt_serve/agent/agents/controller.py\", line 598, in agent_team_chat_new\n    logger.error(f\"chat abnormal termination！{str(e)}\", e)\nMessage: \"chat abnormal termination！Failed to build resource database:dbgpt_serve.agent.resource.datasource.DatasourceResource: DatasourceResource.resource_parameters_class.<locals>._DynDBParameters.__init__() missing 2 required positional arguments: 'name' and 'db_name'\"\nArguments: (ValueError(\"Failed to build resource database:dbgpt_serve.agent.resource.datasource.DatasourceResource: DatasourceResource.resource_parameters_class.<locals>._DynDBParameters.__init__() missing 2 required positional arguments: 'name' and 'db_name'\"),)\n\n\n### What you expected to happen\n\n修改bug，或者帮忙纠正配置问题，顺便想问选择动态是什么意思？资源name应该填什么？动态后也是报错\n\n### How to reproduce\n\n直接配置即可\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "adogwangwang",
      "author_type": "User",
      "created_at": "2025-04-02T08:51:52Z",
      "updated_at": "2025-04-02T09:01:07Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2578/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2578",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2578",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:23.398031",
      "comments": []
    },
    {
      "issue_number": 2575,
      "title": "生成图表建议采用HTML方式生成，实现在线直接点击编辑，修改数值或数据不需要的数据，在线变动这个图大小或行列。",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n生成图表建议采用HTML方式生成，实现在线直接点击编辑，修改数值或数据不需要的数据，在线变动这个图大小或行列。\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Scoop3o3",
      "author_type": "User",
      "created_at": "2025-04-02T07:07:12Z",
      "updated_at": "2025-04-02T07:07:12Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2575/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2575",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2575",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:23.398050",
      "comments": []
    },
    {
      "issue_number": 2512,
      "title": "是否能支持登陆认证，查数是个非常敏感的操作，急需有身份认证",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n_No response_\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "shanzhy",
      "author_type": "User",
      "created_at": "2025-03-24T03:41:53Z",
      "updated_at": "2025-04-02T06:19:10Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2512/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 1,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2512",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2512",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:23.398057",
      "comments": [
        {
          "author": "jackiezzq",
          "body": "+1",
          "created_at": "2025-03-25T09:23:44Z"
        },
        {
          "author": "shysnow",
          "body": "同样提两个权限问题：\n1、当前不区分用户，无法大批量使用，比如创建的应用程序多，或者聊天记录多时，很难找到属于自己创建的应用程序或历史聊天记录。\n2、当前应用程序或知识库发布，默认到应用市场，所有人可用，完全未考虑到数据权限隔离，后期有此方面的规划吗?比如分享到角色、或者某个组织机构。",
          "created_at": "2025-03-25T11:42:46Z"
        },
        {
          "author": "adogwangwang",
          "body": "+1 非常需要登录认证以及权限分层",
          "created_at": "2025-03-26T08:03:40Z"
        },
        {
          "author": "huanwang14",
          "body": "0.7.X能加上此功能吗？竟然还有系统不用登录，既然是做数据的，数据安全第一啊",
          "created_at": "2025-03-26T11:16:31Z"
        },
        {
          "author": "jx001-chen",
          "body": "确实急需用户和权限功能",
          "created_at": "2025-03-27T09:02:36Z"
        }
      ]
    },
    {
      "issue_number": 2562,
      "title": "[Bug]创建Agent ，进入会话提问，在加载Agent resource资源时报错。",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n本地笔记本电脑\n\n### Models information\n\nopen AI gpt 4o 代理\n\n### What happened\n\n创建single agent（关联了知识库和数据源），进入agent会话后，输入一个问题后，运行报错！ \n  File \"/home/jxlhxyp/work/yingzi-topsea-dataengineering-dbgpt/packages/dbgpt-core/src/dbgpt/agent/resource/manage.py\", line 287, in build_resource\n    Resource, self.build_resource_by_type(resource.type, resource)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jxlhxyp/work/yingzi-topsea-dataengineering-dbgpt/packages/dbgpt-core/src/dbgpt/agent/resource/manage.py\", line 262, in build_resource_by_type\n    raise ValueError(\nValueError: Failed to build resource knowledge:dbgpt_serve.agent.resource.knowledge.KnowledgeSpaceRetrieverResource: (psycopg2.errors.InvalidTextRepresentation) invalid input syntax for type integer: \"cook_info\"\nLINE 3: WHERE knowledge_space.id = 'cook_info' \n                                   ^\n\n[SQL: SELECT knowledge_space.id AS knowledge_space_id, knowledge_space.name AS knowledge_space_name, knowledge_space.vector_type AS knowledge_space_vector_type, knowledge_space.domain_type AS knowledge_space_domain_type, knowledge_space.\"desc\" AS knowledge_space_desc, knowledge_space.owner AS knowledge_space_owner, knowledge_space.context AS knowledge_space_context, knowledge_space.gmt_created AS knowledge_space_gmt_created, knowledge_space.gmt_modified AS knowledge_space_gmt_modified \nFROM knowledge_space \nWHERE knowledge_space.id = %(id_1)s \n LIMIT %(param_1)s]\n[parameters: {'id_1': 'cook_info', 'param_1': 1}]\n(Background on this error at: https://sqlalche.me/e/20/9h9h)\n\n其中'cook_info'是 knowledge_space表中的name字段。\n\n### What you expected to happen\n\n对话时，加载Agent资源，不应该报这个错误。\n\n### How to reproduce\n\n创建一个agent进行对话，即可复现！\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "jxlhxyp",
      "author_type": "User",
      "created_at": "2025-03-31T08:48:58Z",
      "updated_at": "2025-04-02T02:44:31Z",
      "closed_at": "2025-04-02T02:44:31Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 16,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2562/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2562",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2562",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:23.573369",
      "comments": [
        {
          "author": "jxlhxyp",
          "body": "补充信息，代码版本上周2左右，tag 0.7.0：\n\n![Image](https://github.com/user-attachments/assets/27d06b56-2e2e-4036-bbc5-4494f216916e)\n\n![Image](https://github.com/user-attachments/assets/3e629262-3021-4606-9f12-3f81fc0dd951)\n\n![Image](https://github.com/user-attachments/assets/54d5072c-904c-4383-a8fa-a729da3d5e15)\n\n",
          "created_at": "2025-03-31T09:13:42Z"
        },
        {
          "author": "Aries-ckt",
          "body": "single agent 选择的类型是？",
          "created_at": "2025-03-31T13:47:22Z"
        },
        {
          "author": "jxlhxyp",
          "body": "数据科学类型\r\n\r\n\r\n\r\n---原始邮件---\r\n发件人: ***@***.***&gt;\r\n发送时间: 2025年3月31日(周一) 晚上9:47\r\n收件人: ***@***.***&gt;;\r\n抄送: ***@***.******@***.***&gt;;\r\n主题: Re: [eosphoros-ai/DB-GPT] [Bug]创建Agent ，进入会话提问，在加载Agent resource资源时报错。 (Issue #2562)\r\n\r\n\r\n   \r\nsingle agent 选择的类型是？\r\n\r\n—\r\nReply to this email directly, view it on ",
          "created_at": "2025-03-31T14:11:34Z"
        },
        {
          "author": "Aries-ckt",
          "body": "看下你应用编辑页面呢？",
          "created_at": "2025-03-31T15:41:42Z"
        },
        {
          "author": "jxlhxyp",
          "body": "![Image](https://github.com/user-attachments/assets/14ee6970-ffc5-48b6-a090-469adb0b82c7)\n\n![Image](https://github.com/user-attachments/assets/5c4a3d63-f4f0-4f04-9a92-83d9f94b7a67)\n\n![Image](https://github.com/user-attachments/assets/9c5c761e-93ab-4c4c-a4b6-8e1db24894d8)",
          "created_at": "2025-04-01T01:21:35Z"
        }
      ]
    },
    {
      "issue_number": 2169,
      "title": "[Bug] [ChatKnowledge] document embedding failed'source'",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [X] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [X] Other\n\n### Device information\n\n(base) root@autodl-container-3ea342bd74-8563f1df:/usr/lib# nvidia-smi\r\nSun Dec  1 18:15:44 2024       \r\n+-----------------------------------------------------------------------------------------+\r\n| NVIDIA-SMI 550.54.14              Driver Version: 550.54.14      CUDA Version: 12.4     |\r\n|-----------------------------------------+------------------------+----------------------+\r\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n|                                         |                        |               MIG M. |\r\n|=========================================+========================+======================|\r\n|   0  NVIDIA GeForce RTX 3090        On  |   00000000:44:00.0 Off |                  N/A |\r\n|  0%   25C    P8             24W /  350W |    8804MiB /  24576MiB |      0%      Default |\r\n|                                         |                        |                  N/A |\r\n+-----------------------------------------+------------------------+----------------------+\r\n                                                                                         \r\n+-----------------------------------------------------------------------------------------+\r\n| Processes:                                                                              |\r\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\r\n|        ID   ID                                                               Usage      |\r\n|=========================================================================================|\n\n### Models information\n\nLLM:vicuna-7b-v1.5 Embedding model:text2vec-large-chinese\n\n### What happened\n\n上传pdf文档，时发生\r\n![图片](https://github.com/user-attachments/assets/4f7ebf49-5dd1-4715-b16e-a2014d249304)\r\n\n\n### What you expected to happen\n\nINFO:     111.41.138.94:0 - \"POST /knowledge/ai/arguments HTTP/1.1\" 200 OK\r\n2024-12-01 18:08:14 autodl-container-3ea342bd74-8563f1df dbgpt.app.knowledge.api[1646] INFO /document/list params: ai, doc_name=None doc_ids=None doc_type=None status=None page=1 page_size=18\r\nINFO:     111.41.138.94:0 - \"POST /knowledge/ai/document/list HTTP/1.1\" 200 OK\r\n2024-12-01 18:10:59 autodl-container-3ea342bd74-8563f1df dbgpt.app.knowledge.api[1646] INFO Received params: ai, doc_ids=[8] model_name=None pre_separator=None separators=None chunk_size=None chunk_overlap=None\r\ncurrent session:<sqlalchemy.orm.session.Session object at 0x7fb9c809b490>\r\n2024-12-01 18:10:59 autodl-container-3ea342bd74-8563f1df dbgpt.serve.rag.connector[1646] INFO VectorStore:<class 'dbgpt.storage.knowledge_graph.community_summary.CommunitySummaryKnowledgeGraph'>\r\n2024-12-01 18:10:59 autodl-container-3ea342bd74-8563f1df dbgpt.serve.rag.service.service[1646] INFO begin save document chunks, doc:Understanding AI Technology.pdf\r\n2024-12-01 18:10:59 autodl-container-3ea342bd74-8563f1df dbgpt.serve.rag.service.service[1646] INFO async doc persist sync, doc:Understanding AI Technology.pdf\r\nINFO:     111.41.138.94:0 - \"POST /knowledge/ai/document/sync HTTP/1.1\" 200 OK\r\n2024-12-01 18:11:00 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 0 extract text success\r\n2024-12-01 18:11:00 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 1 extract text success\r\n2024-12-01 18:11:00 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 2 extract text success\r\n2024-12-01 18:11:00 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 3 extract text success\r\n2024-12-01 18:11:00 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 4 extract text success\r\n2024-12-01 18:11:00 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 5 extract text success\r\n2024-12-01 18:11:01 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 6 extract text success\r\n2024-12-01 18:11:01 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 7 extract text success\r\n2024-12-01 18:11:01 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 8 extract text success\r\n2024-12-01 18:11:01 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 9 extract text success\r\n2024-12-01 18:11:01 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 10 extract text success\r\n2024-12-01 18:11:01 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 11 extract text success\r\n2024-12-01 18:11:01 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 12 extract text success\r\n2024-12-01 18:11:02 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 13 extract text success\r\n2024-12-01 18:11:02 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 14 extract text success\r\n2024-12-01 18:11:02 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 15 extract text success\r\n2024-12-01 18:11:03 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 16 extract text success\r\n2024-12-01 18:11:03 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 17 extract text success\r\n2024-12-01 18:11:03 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 18 extract text success\r\n2024-12-01 18:11:03 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 19 extract text success\r\n2024-12-01 18:11:03 autodl-container-3ea342bd74-8563f1df dbgpt.serve.rag.service.service[1646] ERROR document embedding, failed:Understanding AI Technology.pdf, 'source'\r\n![微信图片_20241201180406](https://github.com/user-attachments/assets/1c67cc0d-1028-4f62-a0fe-b82e0d2a5102)\r\n![Snipaste_2024-12-01_18-03-46](https://github.com/user-attachments/assets/fe161c98-3839-4134-8d59-6b1576b45195)\r\n\n\n### How to reproduce\n\nNFO:     111.41.138.94:0 - \"POST /knowledge/ai/document/sync HTTP/1.1\" 200 OK\r\n2024-12-01 18:11:00 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 0 extract text success\r\n2024-12-01 18:11:00 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 1 extract text success\r\n2024-12-01 18:11:00 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 2 extract text success\r\n2024-12-01 18:11:00 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 3 extract text success\r\n2024-12-01 18:11:00 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 4 extract text success\r\n2024-12-01 18:11:00 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 5 extract text success\r\n2024-12-01 18:11:01 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 6 extract text success\r\n2024-12-01 18:11:01 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 7 extract text success\r\n2024-12-01 18:11:01 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 8 extract text success\r\n2024-12-01 18:11:01 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 9 extract text success\r\n2024-12-01 18:11:01 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 10 extract text success\r\n2024-12-01 18:11:01 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 11 extract text success\r\n2024-12-01 18:11:01 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 12 extract text success\r\n2024-12-01 18:11:02 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 13 extract text success\r\n2024-12-01 18:11:02 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 14 extract text success\r\n2024-12-01 18:11:02 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 15 extract text success\r\n2024-12-01 18:11:03 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 16 extract text success\r\n2024-12-01 18:11:03 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 17 extract text success\r\n2024-12-01 18:11:03 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 18 extract text success\r\n2024-12-01 18:11:03 autodl-container-3ea342bd74-8563f1df dbgpt.component[1646] INFO /root/autodl-tmp/DB-GPT/pilot/data/ai/Understanding AI Technology.pdf page 19 extract text success\r\n2024-12-01 18:11:03 autodl-container-3ea342bd74-8563f1df dbgpt.serve.rag.service.service[1646] ERROR document embedding, failed:Understanding AI Technology.pdf, 'source'\r\n\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "sunnf",
      "author_type": "User",
      "created_at": "2024-12-01T10:16:10Z",
      "updated_at": "2025-04-01T21:05:11Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2169/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2169",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2169",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:23.810676",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "just pdf? try word docx or markdown?",
          "created_at": "2024-12-01T11:56:06Z"
        },
        {
          "author": "Aries-ckt",
          "body": "this pr fix the problem. https://github.com/eosphoros-ai/DB-GPT/pull/2170\r\npull the latest main branch and try again.\r\n",
          "created_at": "2024-12-02T14:05:42Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-04-01T21:05:10Z"
        }
      ]
    },
    {
      "issue_number": 2571,
      "title": "[Feature][Module Name] Feature title",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n建议在数据链接成功后，把数据库的表列出来，同时还可以加上表或字段的注释，方便AI精准查表。如附件所示\n\n![Image](https://github.com/user-attachments/assets/07c89f8e-6ea4-42c7-8899-10fa34e71679)\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Scoop3o3",
      "author_type": "User",
      "created_at": "2025-04-01T10:01:00Z",
      "updated_at": "2025-04-01T10:01:00Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2571/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2571",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2571",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:24.133394",
      "comments": []
    },
    {
      "issue_number": 2315,
      "title": "[Bug] 'ChatWithDbQA' object has no attribute 'database'",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [x] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\ncpu\n\n### Models information\n\nchatgpt\n\n### What happened\n\n我使用源码安装后添加了mysql数据库源，然后使用chat db对话，提示错误如下：'ChatWithDbQA' object has no attribute 'database'\n\n### What you expected to happen\n\n对话返回正常\n\n### How to reproduce\n\n1.源码+mysql部署；\n2.添加mysql数据源；\n3.开启chatdb会话；\n\n### Additional context\n\ndbgpt.app.openapi.api_v1.api_v1[10621] INFO get_chat_instance:conv_uid='8df6b052-d79b-11ef-a162-525400933cef' user_input='我有哪些数据库及表' user_name='001' chat_mode='chat_with_db_qa' app_code='chat_with_db_qa' temperature=0.5 max_new_tokens=2048 select_param='' model_name='chatgpt_proxyllm' incremental=False sys_code=None ext_info={}\nGet prompt template of scene_name: chat_with_db_qa with model_name: chatgpt_proxyllm, proxyllm_backend: None, language: en\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/data/dbgpt/DB-GPT/dbgpt/app/openapi/api_v1/api_v1.py\", line 538, in chat_completions\n    chat: BaseChat = await get_chat_instance(dialogue)\n  File \"/data/dbgpt/DB-GPT/dbgpt/app/openapi/api_v1/api_v1.py\", line 441, in get_chat_instance\n    chat: BaseChat = await blocking_func_to_async(\n  File \"/data/dbgpt/DB-GPT/dbgpt/util/executor_utils.py\", line 67, in blocking_func_to_async\n    return await loop.run_in_executor(executor, run_with_context)\n  File \"/usr/local/miniconda/envs/dbgpt_env/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/data/dbgpt/DB-GPT/dbgpt/util/executor_utils.py\", line 64, in run_with_context\n    return ctx.run(partial(func, *args, **kwargs))\n  File \"/data/dbgpt/DB-GPT/dbgpt/app/scene/chat_factory.py\", line 36, in get_implementation\n    implementation = cls(**kwargs)\n  File \"/data/dbgpt/DB-GPT/dbgpt/app/scene/chat_db/professional_qa/chat.py\", line 34, in __init__\n    if self.database.is_graph_type():\nAttributeError: 'ChatWithDbQA' object has no attribute 'database'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/miniconda/envs/dbgpt_env/lib/python3.10/logging/__init__.py\", line 1100, in emit\n    msg = self.format(record)\n  File \"/usr/local/miniconda/envs/dbgpt_env/lib/python3.10/logging/__init__.py\", line 943, in format\n    return fmt.format(record)\n  File \"/usr/local/miniconda/envs/dbgpt_env/lib/python3.10/logging/__init__.py\", line 678, in format\n    record.message = record.getMessage()\n  File \"/usr/local/miniconda/envs/dbgpt_env/lib/python3.10/logging/__init__.py\", line 368, in getMessage\n    msg = msg % self.args\nTypeError: not all arguments converted during string formatting\nCall stack:\n  File \"/data/dbgpt/DB-GPT/dbgpt/app/dbgpt_server.py\", line 289, in <module>\n    run_webserver()\n  File \"/data/dbgpt/DB-GPT/dbgpt/app/dbgpt_server.py\", line 285, in run_webserver\n    run_uvicorn(param)\n  File \"/data/dbgpt/DB-GPT/dbgpt/app/dbgpt_server.py\", line 245, in run_uvicorn\n    uvicorn.run(\n  File \"/usr/local/miniconda/envs/dbgpt_env/lib/python3.10/site-packages/uvicorn/main.py\", line 579, in run\n    server.run()\n  File \"/usr/local/miniconda/envs/dbgpt_env/lib/python3.10/site-packages/uvicorn/server.py\", line 66, in run\n    return asyncio.run(self.serve(sockets=sockets))\n  File \"/usr/local/miniconda/envs/dbgpt_env/lib/python3.10/asyncio/runners.py\", line 44, in run\n    return loop.run_until_complete(main)\n  File \"/usr/local/miniconda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/base.py\", line 149, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/usr/local/miniconda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/usr/local/miniconda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/usr/local/miniconda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/routing.py\", line 715, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/usr/local/miniconda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/routing.py\", line 735, in app\n    await route.handle(scope, receive, send)\n  File \"/usr/local/miniconda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"/usr/local/miniconda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/usr/local/miniconda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/usr/local/miniconda/envs/dbgpt_env/lib/python3.10/site-packages/starlette/routing.py\", line 73, in app\n    response = await f(request)\n  File \"/usr/local/miniconda/envs/dbgpt_env/lib/python3.10/site-packages/fastapi/routing.py\", line 301, in app\n    raw_response = await run_endpoint_function(\n  File \"/usr/local/miniconda/envs/dbgpt_env/lib/python3.10/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    return await dependant.call(**values)\n  File \"/data/dbgpt/DB-GPT/dbgpt/app/openapi/api_v1/api_v1.py\", line 553, in chat_completions\n    logger.exception(f\"Chat Exception!{dialogue}\", e)\nMessage: \"Chat Exception!conv_uid='8df6b052-d79b-11ef-a162-525400933cef' user_input='我有哪些数据库及表' user_name='001' chat_mode='chat_with_db_qa' app_code='chat_with_db_qa' temperature=0.5 max_new_tokens=2048 select_param='' model_name='chatgpt_proxyllm' incremental=False sys_code=None ext_info={}\"\nArguments: (AttributeError(\"'ChatWithDbQA' object has no attribute 'database'\"),)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/data/dbgpt/DB-GPT/dbgpt/app/openapi/api_v1/api_v1.py\", line 538, in chat_completions\n    chat: BaseChat = await get_chat_instance(dialogue)\n  File \"/data/dbgpt/DB-GPT/dbgpt/app/openapi/api_v1/api_v1.py\", line 441, in get_chat_instance\n    chat: BaseChat = await blocking_func_to_async(\n  File \"/data/dbgpt/DB-GPT/dbgpt/util/executor_utils.py\", line 67, in blocking_func_to_async\n    return await loop.run_in_executor(executor, run_with_context)\n  File \"/usr/local/miniconda/envs/dbgpt_env/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/data/dbgpt/DB-GPT/dbgpt/util/executor_utils.py\", line 64, in run_with_context\n    return ctx.run(partial(func, *args, **kwargs))\n  File \"/data/dbgpt/DB-GPT/dbgpt/app/scene/chat_factory.py\", line 36, in get_implementation\n    implementation = cls(**kwargs)\n  File \"/data/dbgpt/DB-GPT/dbgpt/app/scene/chat_db/professional_qa/chat.py\", line 34, in __init__\n    if self.database.is_graph_type():\nAttributeError: 'ChatWithDbQA' object has no attribute 'database'\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "duguwo",
      "author_type": "User",
      "created_at": "2025-01-21T02:12:11Z",
      "updated_at": "2025-04-01T08:22:23Z",
      "closed_at": "2025-01-22T01:05:03Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2315/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2315",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2315",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:24.133413",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "v0.6.3 dbgpt version?",
          "created_at": "2025-01-21T16:17:27Z"
        },
        {
          "author": "duguwo",
          "body": "> v0.6.3 dbgpt version?\n\nyes",
          "created_at": "2025-01-22T01:03:39Z"
        },
        {
          "author": "duguwo",
          "body": "问题已经解决，问题原因是在开启对话前，没有设置chatdb进行数据库设置",
          "created_at": "2025-01-22T01:05:00Z"
        }
      ]
    },
    {
      "issue_number": 2504,
      "title": "[Bug] [dbgpt-serve AWEL ] AWEL Agent's second trigger will default to selecting the last agent instead of running the entire stream",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nIt has nothing to do with this\n\n### Models information\n\nIt has nothing to do with this\n\n### What happened\n\nIt has nothing to do with this\n\n### What you expected to happen\n\n![Image](https://github.com/user-attachments/assets/0acec468-1af7-4790-a1b5-ecd004326cf5)\n\n工作流是官方的意图识别工作流 选择了 两个不同的agent【DataScientist、Summarizer】\n\n第一次会整体走流程、二次触发会默认选择上一次选择的agent 而不会走意图识别重新识别。\n\n### How to reproduce\n\n![Image](https://github.com/user-attachments/assets/0acec468-1af7-4790-a1b5-ecd004326cf5)\n\n工作流是官方的意图识别工作流 选择了 两个不同的agent【DataScientist、Summarizer】\n\n第一次会整体走流程、二次触发会默认选择上一次选择的agent 而不会走意图识别重新识别。\n\n### Additional context\n\n![Image](https://github.com/user-attachments/assets/21aac110-d60d-4639-acaf-c170ca80974c)\n\n![Image](https://github.com/user-attachments/assets/e996e423-996a-4a77-8240-4185d3b157d0)\n\n第一次问都好好的 追问后就默认会选择上一个agent类型。而不会走工作流。\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "15089677014",
      "author_type": "User",
      "created_at": "2025-03-21T11:41:06Z",
      "updated_at": "2025-04-01T06:27:01Z",
      "closed_at": "2025-04-01T06:27:01Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2504/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2504",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2504",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:24.349704",
      "comments": [
        {
          "author": "15089677014",
          "body": "第一次：'Intent Recognition Expert' - >  ''AppLauncher'' -> 指定的Agent(DataScientist、Summarizer)\n\n第二次： ''AppLauncher'' -> 指定的Agent(可能会选择默认的)\n\n<img width=\"1153\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/253ce387-0c72-4bba-a282-ed0daab1d732\" />",
          "created_at": "2025-03-22T05:18:50Z"
        },
        {
          "author": "15089677014",
          "body": "![Image](https://github.com/user-attachments/assets/f0a5fe4b-ba13-4fe5-8bdc-6378c3fcc559)\nagent 启动了ask_user",
          "created_at": "2025-03-24T10:58:18Z"
        },
        {
          "author": "15089677014",
          "body": "第一次：'Intent Recognition Expert' - >  ''AppLauncher'' -> 指定的Agent(DataScientist、Summarizer)\n\n第二次： ''AppLauncher'' -> 指定的Agent(可能会选择默认的)",
          "created_at": "2025-03-24T11:59:10Z"
        },
        {
          "author": "15089677014",
          "body": "![Image](https://github.com/user-attachments/assets/d6a79b05-ff2f-4739-9e73-1a088032ea0a)\n\n![Image](https://github.com/user-attachments/assets/0f4c0987-0667-4a36-a6e5-03628c11089b)\n\n可以修复这个问题 但是意图识别会导致没有知识库。并且最后展示的时候 虽然本身是DataScientist 但因为之前选择了 Summarizer 下一个问题就算是 DataScientist 还是不会展示sql结果",
          "created_at": "2025-03-26T09:30:06Z"
        }
      ]
    },
    {
      "issue_number": 2568,
      "title": "[Optimize][Web] pls optimize node_modules file size",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nAfter installing web dependencies with yarn, the size of the node_modules folder actually reaches 11GB, which takes up a lot of disk space\n![Image](https://github.com/user-attachments/assets/25a835f3-49ea-43d6-bf73-69896e1615c3)\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "vnicers",
      "author_type": "User",
      "created_at": "2025-04-01T03:28:39Z",
      "updated_at": "2025-04-01T03:29:00Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2568/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2568",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2568",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:24.615736",
      "comments": []
    },
    {
      "issue_number": 2553,
      "title": "[Bug] [dbgpt_client] Triggering the ‘’sync_document‘’ program causes the program to freeze",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n![Image](https://github.com/user-attachments/assets/7a042c6b-2fc2-422d-9833-908c8d4f3476)\n\n### Models information\n\nBoth local and remote are the same\n\nbge-m3\n\n### What happened\n\n使用\nfrom dbgpt_client.knowledge import sync_document\n\n\n### What you expected to happen\n\n使用\nfrom dbgpt_client.knowledge import sync_document\n方法会导致\ndbgpt_server.py 启动的程序 直接卡死\n\n已经定位到了这个位置\n![Image](https://github.com/user-attachments/assets/7394889f-e091-413d-9071-dffbbc462bce)\n\n如果web去触发同步是不会异常，只有代码触发会出现这个问题。\n\n这是我修改的代码：\nhttps://github.com/eosphoros-ai/DB-GPT/commit/b531f62895160add69dbaac2a19ed65641b5785b\n\n需要再启动的toml添加配置\n[agent.system_prompt.synchronous.'auto_update_zhibiao_table_structure']\ndata_type=\"mysql\"\ntable_name=\"table\"\nsql = \"SELECT * FROM table;\"\ndoc_name = \"indicator_result_table_structure.csv\"\ndatasource_id = \"1\"\nis_customize = 0\n\n\ndatasource_id 如果不使用绑定的数据库可以补全 数据库信息\ndb_pwd=xxxx\nf\"mysql+pymysql://{sync_info['db_user']}:{sync_info['db_pwd']}\"\n                     f\"@{sync_info['db_host']}:{sync_info['db_port']}/{sync_info['db_name']}\"\n                     f\"?{sync_info.get('ext_config', '')}\"\n\n### How to reproduce\n\n\n这是我修改的代码：\nhttps://github.com/eosphoros-ai/DB-GPT/commit/b531f62895160add69dbaac2a19ed65641b5785b\n\n需要再启动的toml添加配置\n[agent.system_prompt.synchronous.'auto_update_zhibiao_table_structure']\ndata_type=\"mysql\"\ntable_name=\"table\"\nsql = \"SELECT * FROM table;\"\ndoc_name = \"indicator_result_table_structure.csv\"\ndatasource_id = \"1\"\nis_customize = 0\n\n\ndatasource_id 如果不使用绑定的数据库可以补全 数据库信息\ndb_pwd=xxxx\nf\"mysql+pymysql://{sync_info['db_user']}:{sync_info['db_pwd']}\"\n                     f\"@{sync_info['db_host']}:{sync_info['db_port']}/{sync_info['db_name']}\"\n                     f\"?{sync_info.get('ext_config', '')}\"\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "15089677014",
      "author_type": "User",
      "created_at": "2025-03-29T12:40:04Z",
      "updated_at": "2025-04-01T01:44:33Z",
      "closed_at": "2025-04-01T01:42:31Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 15,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2553/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2553",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2553",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:24.615759",
      "comments": [
        {
          "author": "15089677014",
          "body": "@Aries-ckt  @fangyinc 作者，可以看看这个问题",
          "created_at": "2025-03-29T12:42:33Z"
        },
        {
          "author": "15089677014",
          "body": "from dbgpt_client.knowledge import sync_document\n\n本身是不可用的我抽了出来",
          "created_at": "2025-03-29T12:43:10Z"
        },
        {
          "author": "15089677014",
          "body": "这是我修改的代码：\nhttps://github.com/eosphoros-ai/DB-GPT/commit/b531f62895160add69dbaac2a19ed65641b5785b",
          "created_at": "2025-03-29T12:43:23Z"
        },
        {
          "author": "15089677014",
          "body": "packages/dbgpt-core/src/dbgpt/storage/base.py\n\n![Image](https://github.com/user-attachments/assets/36767e48-ad5f-436e-81eb-5efb14f874b1)\n\ntry下这个行 可以解决第一次触发问题 但第二次已然会卡死",
          "created_at": "2025-03-30T09:00:21Z"
        },
        {
          "author": "15089677014",
          "body": "<img width=\"676\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/7661a539-515b-49c3-a97f-afb826fbf6dc\" />\n\nweb 同步第四次也会卡死",
          "created_at": "2025-03-30T13:54:38Z"
        }
      ]
    },
    {
      "issue_number": 2525,
      "title": "What's the difference between DB-GPT and OpenSPG and KAG?",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nWhat's the difference between DB-GPT and OpenSPG and KAG?\n\nThey're all open-sourced by AntGroup and try to enhanced the current RAG performance.\n\nSo which one should I choose? I can't find any doc that elaborate it.\n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "ttchin",
      "author_type": "User",
      "created_at": "2025-03-25T11:57:15Z",
      "updated_at": "2025-03-31T13:49:48Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2525/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2525",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2525",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:24.840216",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "OpenSPG is an excellent KnowledgeGraph Framework, KAG is an excellent RAG framework based on OpenSPG.DB-GPT is data ai application framework.",
          "created_at": "2025-03-26T14:33:35Z"
        },
        {
          "author": "ttchin",
          "body": "> OpenSPG is an excellent KnowledgeGraph Framework, KAG is an excellent RAG framework based on OpenSPG.DB-GPT is data ai application framework.\n\nThanks for your kind reply. Do you mean DB-GPT has implemented RAG based on KAG or OpenSPG?\nOr DB-GPT has implemented its own RAG framework?",
          "created_at": "2025-03-28T09:18:01Z"
        },
        {
          "author": "Aries-ckt",
          "body": "not yet, but we can integrate their excellent ability.",
          "created_at": "2025-03-31T13:49:47Z"
        }
      ]
    },
    {
      "issue_number": 2564,
      "title": "[Feature][Module Name] Feature title",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n1、workflow 建议增加可以在创建工作流时选择 LLMClient。\n2、 大模板对话时，增加联网搜索功能\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Scoop3o3",
      "author_type": "User",
      "created_at": "2025-03-31T09:13:47Z",
      "updated_at": "2025-03-31T09:13:47Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2564/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2564",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2564",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:25.021585",
      "comments": []
    },
    {
      "issue_number": 2563,
      "title": "flow需要自定义 LLMClient",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nawel流程配置中希望支持特性，支持用户自选大语言模型客户端配置\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "fengsao",
      "author_type": "User",
      "created_at": "2025-03-31T09:12:13Z",
      "updated_at": "2025-03-31T09:12:13Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2563/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2563",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2563",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:25.021605",
      "comments": []
    },
    {
      "issue_number": 2557,
      "title": "[Bug] [dbgpt_client] Triggering the ‘’sync_document‘’ program causes the program to freeze #2553",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [x] Chat Data\n- [x] Chat Excel\n- [x] Chat DB\n- [x] Chat Knowledge\n- [x] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n<!-- Failed to upload \"image.png\" -->\n\n### Models information\n\nLLM:vicuna-13b-v1.5嵌入模型:text2vec-large-chinese\n\n### What happened\n\n使用\nfrom dbgpt_client.knowledge import sync_document\n\n### What you expected to happen\n\n使用\nfrom dbgpt_client.knowledge import sync_document\n方法会导致\ndbgpt_server.py 启动的程序 直接卡死\n\n已经定位到了这个位置\n\n<!-- Failed to upload \"image.png\" -->\n如果web去触发同步是不会异常，只有代码触发会出现这个问题。\n\n\n### How to reproduce\n\n这是我修改的代码：\nhttps://github.com/eosphoros-ai/DB-GPT/commit/b531f62895160add69dbaac2a19ed65641b5785b\n\n需要再启动的toml添加配置\n[agent.system_prompt.synchronous.'auto_update_zhibiao_table_structure']\ndata_type=\"mysql\"\ntable_name=\"table\"\nsql = \"SELECT * FROM table;\"\ndoc_name = \"indicator_result_table_structure.csv\"\ndatasource_id = \"1\"\nis_customize = 0\n\ndatasource_id 如果不使用绑定的数据库可以补全 数据库信息\ndb_pwd=xxxx\nf\"mysql+pymysql://{sync_info['db_user']}:{sync_info['db_pwd']}\"\nf\"@{sync_info['db_host']}:{sync_info['db_port']}/{sync_info['db_name']}\"\nf\"?{sync_info.get('ext_config', '')}\"\n\nAdditional context\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "xushishun",
      "author_type": "User",
      "created_at": "2025-03-31T01:46:08Z",
      "updated_at": "2025-03-31T03:59:45Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2557/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2557",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2557",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:25.021612",
      "comments": [
        {
          "author": "xushishun",
          "body": "1",
          "created_at": "2025-03-31T03:59:44Z"
        }
      ]
    },
    {
      "issue_number": 2554,
      "title": "[Bug] [model] VLLM chat count_token raise Not NotImplementedError",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [x] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice: GPU 4090\n\n### Models information\n\n[models]\n[[models.llms]]\nname = \"DeepSeek-R1-Distill-Qwen-1.5B\"\nprovider = \"vllm\"\n# If not provided, the model will be downloaded from the Hugging Face model hub\n# uncomment the following line to specify the model path in the local file system\n# path = \"the-model-path-in-the-local-file-system\"\npath = \"models/DeepSeek-R1-Distill-Qwen-1.5B\"\n# dtype = \"float32\"\n\n### What happened\n\nWhen use vllm inference local model, the chatNomal will raise a error at next  code\n```\n   async with worker_run_data.semaphore:\n                if worker_run_data.worker.support_async():\n                    return await worker_run_data.worker.async_count_token(prompt)\n                else:\n                    return await self.run_blocking_func(\n                        worker_run_data.worker.count_token, prompt\n                    )\n```\n\n### What you expected to happen\n\nFix this\n\n### How to reproduce\n\nUse vllm, chatNormal\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "csunny",
      "author_type": "User",
      "created_at": "2025-03-30T03:40:46Z",
      "updated_at": "2025-03-31T00:31:05Z",
      "closed_at": "2025-03-31T00:31:05Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2554/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2554",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2554",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:25.224742",
      "comments": []
    },
    {
      "issue_number": 2167,
      "title": "[Feature][Scene] how to set  parameter top_p in prompt.py ?",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\ni tried in  in prompt.py and dbgpt/app/scene/base.py , yet it's still top_p=None in logs\r\n![f0bf30a6aaa209d52ccb83c22a973a4e](https://github.com/user-attachments/assets/e276f786-6b38-4c81-a909-1dcdb3228d7a)\r\nwhat else should i do ? thank u \r\n\n\n### Use case\n\n![1221579f90d835e597fa24dfe1b16946](https://github.com/user-attachments/assets/32072352-7bcd-474a-99e8-c452174c535d)\r\n\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "chuangzhidan",
      "author_type": "User",
      "created_at": "2024-11-30T13:58:28Z",
      "updated_at": "2025-03-30T21:05:39Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2167/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2167",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2167",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:25.224763",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-03-30T21:05:39Z"
        }
      ]
    },
    {
      "issue_number": 2164,
      "title": "[Bug] [Module Name] Bug title cannot show chart",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [X] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU Count: 2 pcs\r\nMemory Size: 64 GB\r\nSystem: CentOS 7.6\n\n### Models information\n\ntongyi_proxyllm\n\n### What happened\n\n询问问题无法获得理想回答，无法查询数据库内容，并且正常绘制图表\n\n### What you expected to happen\n\n1.询问数据库内容时无法获得完整数据内容，测试库中包含23张表，但是询问模型结果一直答复为4张，更换其他数据库也是一样，只会回答四张表，但是表名又是对应库中确实存在的表。\r\n2.询问表内容，可以正常理解字段并给出SQL，但是无法执行SQL绘制出图表。\r\n![PixPin_2024-11-28_18-22-47](https://github.com/user-attachments/assets/d4267617-381d-4afc-8365-bff2ea23ef17)\r\n\n\n### How to reproduce\n\n按照 https://www.yuque.com/eosphoros/dbgpt-docs/vbs7kh3bnd27fsvz 文档中新建了一个应用\r\n![PixPin_2024-11-28_18-20-28](https://github.com/user-attachments/assets/3a485a43-43ae-4de9-a342-455644e6576a)\r\n按照此方式新建一个db应用进行询问。\n\n### Additional context\n\nV0.6.0版本 源码部署\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Dongxiaohaoo",
      "author_type": "User",
      "created_at": "2024-11-28T10:26:58Z",
      "updated_at": "2025-03-29T21:04:54Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2164/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2164",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2164",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:25.438865",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "if you want to show chart, you need the `ChatData` application, not the `ChatDB` application.",
          "created_at": "2024-11-28T12:59:04Z"
        },
        {
          "author": "Dongxiaohaoo",
          "body": "> if you want to show chart, you need the `ChatData` application, not the `ChatDB` application.\r\n\r\nGreat, it's working fine. But right now, it can only query a single table. I want to know if it can join other tables to query some data. For example, I have a department table and an employee table, w",
          "created_at": "2024-11-29T09:19:27Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-03-29T21:04:53Z"
        }
      ]
    },
    {
      "issue_number": 2549,
      "title": "[Bug] [Module Name]工作流发布为应用程序后多轮对话报错",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nOS: windows 11\nCPU: Intel(R) Core(TM) i5-1035G1 CPU @ 1.00GHz   1.19 GHz\n\n### Models information\n\nLLM: deepseek:32b\nembedding: bge-m3\n\n### What happened\n\nawel 工作流发布为应用程序后，多轮对话报错。\n![Image](https://github.com/user-attachments/assets/1d86e75a-db73-4b00-b286-47b5b91130a5)\n\n### What you expected to happen\n\n多轮对话正常\n\n### How to reproduce\n\n## 场景复现\n1. 基于 rag-chat-awel-flow-template-zh.json 模板导入创建 awel 工作流，关联已有知识库；\n\n![Image](https://github.com/user-attachments/assets/1d86e75a-db73-4b00-b286-47b5b91130a5)\n2. 创建应用程序，关联对应 awel 工作流；\n3. 点击应用程序对话，进行首次对话，对话返回正常；\n4. 继续输入进行第二次对话，对话刚开始正常流式返回，但最终存储报错。\n![Image](https://github.com/user-attachments/assets/d82c9c9d-7d0f-4ab3-8e34-c1d7cbc2f9bb)\n\n## 错误日志\n\ndbgpt.serve.core.schemas[33844] ERROR common_exception_handler catch Exception: success=False err_code='E0003' err_msg='(sqlite3.IntegrityError) UNIQUE constraint failed: chat_history_message.conv_uid, chat_history_message.index\\n[SQL: INSERT INTO chat_history_message (conv_uid, \"index\", round_index, message_detail, gmt_created, gmt_modified) VALUES (?, ?, ?, ?, ?, ?)]\\n[parameters: (\\'0617a74a-0bb4-11f0-86db-40ec9972c706\\', 0, 1, \\'{\"type\": \"human\", \"data\": {\"content\": \"焦点科技电话\", \"index\": 0, \"round_index\": 1, \"additional_kwargs\": {\"param_type\": \"DbGpts\", \"param_value\": \"6dd089bb-0af0-11f0-9099-40ec9972c706\", \"model_name\": \"\"}, \"example\": false}, \"index\": 0, \"round_index\": 1}\\', \\'2025-03-28 17:07:51.393739\\', \\'2025-03-28 17:07:51.393739\\')]\\n(Background on this error at: https://sqlalche.me/e/20/gkpj)' data=None\nERROR:    Exception in ASGI application\n\n### Additional context\n\n经分析插入`chat_history`记录时缺少`chat_mode`，而该字段设计为 `NOT NULL` ，导致保存记录失败。\n查看 `api/v1/chat/completions`接口已经带入了 `chat_mode: chat_agent` 。\n\ndebug 调用链路时发现， api_v1.py 中 chat_completions 调用 multi_agents.app_agent_chat() 遗漏的 `chat_mode`。\n\n![Image](https://github.com/user-attachments/assets/1b594190-2121-4824-8f66-a7027860168c)\n\n而 chat_mode 为 chat_flow 传递了该参数，所以直接通过工作流能正常进行多轮对话。 \n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "cumbersun",
      "author_type": "User",
      "created_at": "2025-03-28T09:42:03Z",
      "updated_at": "2025-03-29T09:36:14Z",
      "closed_at": "2025-03-29T09:36:14Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2549/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2549",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2549",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:25.646075",
      "comments": []
    },
    {
      "issue_number": 2378,
      "title": "[Bug] [Module Name] Bug title 我怀疑DB-GPT的开发人员估计已经离职了",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU 1\n\n### Models information\n\ndeepseek-r1:8b\nbge-e3\n\n### What happened\n\n1) 根据目录还有 .env.template 么\n2) 知识库的 ElasticSearch 一直不能用，是怎么想法呢，整个项目文件有关 es 的 host 都写死了，都不行;\n\n### What you expected to happen\n\n1) 根据目录还有 .env.template 么\n2) 知识库的 ElasticSearch 一直不能用，是怎么想法呢，整个项目文件有关 es 的 host 都写死了，都不行;\n\n### How to reproduce\n\n1) 根据目录还有 .env.template 么\n2) 知识库的 ElasticSearch 一直不能用，是怎么想法呢，整个项目文件有关 es 的 host 都写死了，都不行;\n\n### Additional context\n\n1) 根据目录还有 .env.template 么\n2) 知识库的 ElasticSearch 一直不能用，是怎么想法呢，整个项目文件有关 es 的 host 都写死了，都不行;\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "gloot",
      "author_type": "User",
      "created_at": "2025-02-28T17:59:51Z",
      "updated_at": "2025-03-29T02:40:40Z",
      "closed_at": "2025-03-01T01:44:53Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2378/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2378",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2378",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:25.646096",
      "comments": [
        {
          "author": "jjj201200",
          "body": "https://github.com/eosphoros-ai/DB-GPT/issues/2369",
          "created_at": "2025-02-28T22:11:28Z"
        },
        {
          "author": "Hec-gitHub",
          "body": "项目架构改动有点频繁，有种向Dify对齐的意思，就不能专注自身项目初衷",
          "created_at": "2025-03-01T01:04:13Z"
        },
        {
          "author": "fangyinc",
          "body": "Same #2362",
          "created_at": "2025-03-01T01:44:53Z"
        },
        {
          "author": "jackiemoo",
          "body": "> 项目架构改动有点频繁，有种向Dify对齐的意思，就不能专注自身项目初衷\n\n是的，很无语，打算弃坑了",
          "created_at": "2025-03-03T03:34:51Z"
        },
        {
          "author": "Aries-ckt",
          "body": "非常抱歉造成不好的体验，因为作为数据应用框架，我们需要保证配置尽量简单和核心功能尽可能的轻量化，所以才打算对v0.7.0版本进行模块化的重构，将额外的模块集成进行拆分，目前我们项目还没有打最新的版本tag，\n所以如果想要稳定版本，可以回退到v0.6.x版本，我们会在发布最新版本的时候尽可能保证功能的稳定。",
          "created_at": "2025-03-03T03:45:14Z"
        }
      ]
    },
    {
      "issue_number": 2161,
      "title": "[Bug] [Module Name] Page Database shows missing!",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n-\n\n### Models information\n\n-\n\n### What happened\n\n在前端界面配置了三个mysql数据库，只显示了一个，在chat data中可以正常使用三个。\r\n![image](https://github.com/user-attachments/assets/9fc1cd72-abd6-4d17-95e2-d1baf15a67fd)\r\n\n\n### What you expected to happen\n\n数据库信息正常显示\n\n### How to reproduce\n\n-\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "yuerf",
      "author_type": "User",
      "created_at": "2024-11-28T05:56:49Z",
      "updated_at": "2025-03-28T21:05:02Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2161/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2161",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2161",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:25.825909",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "it looks like your have only one mysql database ",
          "created_at": "2024-11-28T12:45:38Z"
        },
        {
          "author": "yuerf",
          "body": "其实是配置了两个数据库，chat data时可选\r\n![image](https://github.com/user-attachments/assets/2c48b834-21bc-401b-8804-385110b0c788)\r\n",
          "created_at": "2024-11-28T12:52:21Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-03-28T21:05:01Z"
        }
      ]
    },
    {
      "issue_number": 2545,
      "title": "Vector store chroma not supported",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [x] Chat Data\n- [ ] Chat Excel\n- [x] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [x] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice: CPU\n\n### Models information\n\nLLM: QwQ-32B\nEmbeddings: text2vec-large-chinese\n\n### What happened\n\n在配置数据库连接时会报向量数据库chroma不支持的错误信息。\ntoml配置如下：\n[system]\n# Load language from environment variable(It is set by the hook)\nlanguage = \"${env:DBGPT_LANG:-zh}\"\napi_keys = []\nencrypt_key = \"your_secret_key\"\n\n# Server Configurations\n[service.web]\nhost = \"0.0.0.0\"\nport = 5670\n\n[service.web.database]\ntype = \"sqlite\"\npath = \"pilot/meta_data/dbgpt.db\"\n[service.model.worker]\nhost = \"127.0.0.1\"\n\n[rag.storage]\n[rag.storage.vector]\ntype = \"chroma\"\npersist_path = \"pilot/data\"\n\n# Model Configurations\n[models]\n[[models.llms]]\n#name = \"deepseek-reasoner\"\n#name = \"deepseek-chat\"\nname = \"QwQ-32B\"\nprovider = \"proxy/deepseek\"\n#api_key = \"your_deepseek_api_key\"\napi_key = \"sk-xxx\"          #替换为自己的\napi_base = \"https://xxx\"   # 替换为自己的\n\n[[models.embeddings]]\nname = \"Jerry0/text2vec-large-chinese\"\nprovider = \"hf\"\n# If not provided, the model will be downloaded from the Hugging Face model hub\n# uncomment the following line to specify the model path in the local file system\n# path = \"the-model-path-in-the-local-file-system\"\npath = \"models/text2vec-large-chinese\"\n\n### What you expected to happen\n\n错误日志如下：\n2025-03-28 02:56:17 | INFO | dbgpt_ext.storage.vector_store.chroma_store | Check persist_dir: /app/pilot/data/Chinook_profile.vectordb\n2025-03-28 02:56:17 | INFO | dbgpt_serve.datasource.manages.connect_config_db | Result: <sqlalchemy.engine.cursor.CursorResult object at 0x7f7a0c085da0>\n2025-03-28 02:56:17 | INFO | dbgpt_serve.datasource.manages.connect_config_db | Result: <sqlalchemy.engine.cursor.CursorResult object at 0x7f7a0c085da0>\n2025-03-28 02:56:39 | WARNING | dbgpt_serve.datasource.service.db_summary_client | Chinook, mysql summary error!Vector store chroma not supported, detail: Traceback (most recent call last):\n  File \"/app/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/db_summary_client.py\", line 52, in db_summary_embedding\n    self.init_db_profile(db_summary_client, dbname)\n  File \"/app/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/db_summary_client.py\", line 105, in init_db_profile\n    self._get_vector_connector_by_db(dbname)\n  File \"/app/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/db_summary_client.py\", line 165, in _get_vector_connector_by_db\n    table_vector_connector = VectorStoreConnector.from_default(\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-serve/src/dbgpt_serve/rag/connector.py\", line 126, in from_default\n    return cls(real_vector_store_type, vector_store_config, system_app)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-serve/src/dbgpt_serve/rag/connector.py\", line 66, in __init__\n    raise Exception(f\"Vector store {vector_store_type} not supported\")\nException: Vector store chroma not supported\n\n2025-03-28 02:56:39 | ERROR | dbgpt_serve.core.schemas | common_exception_handler catch Exception: success=False err_code='E0003' err_msg='Vector store chroma not supported' data=None\n2025-03-28 02:56:39 | ERROR | dbgpt_serve.core.schemas | common_exception_handler catch Exception: success=False err_code='E0003' err_msg='Vector store chroma not supported' data=None\n\n### How to reproduce\n\n1.点击应用管理\n2.点击顶部的数据库\n3.选择MySQL\n4.点击Create\n5.填写数据库的连接参数\n6.点击提交，就会提示：Vector store chroma not supported\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "zhenglibing",
      "author_type": "User",
      "created_at": "2025-03-28T03:11:08Z",
      "updated_at": "2025-03-28T06:40:57Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2545/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2545",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2545",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:26.005231",
      "comments": [
        {
          "author": "fangyinc",
          "body": "Please try with image `eosphorosai/dbgpt-openai:latest`",
          "created_at": "2025-03-28T03:23:28Z"
        },
        {
          "author": "zhenglibing",
          "body": "I use  image eosphorosai/dbgpt-openai:latest，The docker container starting is error: ModuleNotFoundError: No module named 'sentence_transformers'. The details:\nINFO:     Uvicorn running on http://0.0.0.0:5670 (Press CTRL+C to quit)\n2025-03-28 06:23:10 14f6e17aef24 dbgpt.util.code.server[1] INFO Code",
          "created_at": "2025-03-28T06:40:55Z"
        }
      ]
    },
    {
      "issue_number": 1726,
      "title": "[Bug] [DB] KeyError: 'db_name'",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [X] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU: 36G\n\n### Models information\n\nLLM:tongyi\r\nEmbedding model:tongyi\n\n### What happened\n\nERROR:    Exception in ASGI application\r\n  + Exception Group Traceback (most recent call last):\r\n  |   File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/_utils.py\", line 87, in collapse_excgroups\r\n  |     yield\r\n  |   File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/base.py\", line 190, in __call__\r\n  |     async with anyio.create_task_group() as task_group:\r\n  |   File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 680, in __aexit__\r\n  |     raise BaseExceptionGroup(\r\n  | exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\r\n  +-+---------------- 1 ----------------\r\n    | Traceback (most recent call last):\r\n    |   File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 399, in run_asgi\r\n    |     result = await app(  # type: ignore[func-returns-value]\r\n    |   File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py\", line 70, in __call__\r\n    |     return await self.app(scope, receive, send)\r\n    |   File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/cors.py\", line 93, in __call__\r\n    |     await self.simple_response(scope, receive, send, request_headers=headers)\r\n    |   File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/cors.py\", line 148, in simple_response\r\n    |     await self.app(scope, receive, send)\r\n    |   File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/fastapi/applications.py\", line 1054, in __call__\r\n    |     await super().__call__(scope, receive, send)\r\n    |   File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/applications.py\", line 123, in __call__\r\n    |     await self.middleware_stack(scope, receive, send)\r\n    |   File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/errors.py\", line 186, in __call__\r\n    |     raise exc\r\n    |   File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/errors.py\", line 164, in __call__\r\n    |     await self.app(scope, receive, _send)\r\n    |   File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/base.py\", line 189, in __call__\r\n    |     with collapse_excgroups():\r\n    |   File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/contextlib.py\", line 153, in __exit__\r\n    |     self.gen.throw(typ, value, traceback)\r\n    |   File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/_utils.py\", line 93, in collapse_excgroups\r\n    |     raise exc\r\n    |   File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/base.py\", line 191, in __call__\r\n    |     response = await self.dispatch_func(request, call_next)\r\n    |   File \"/opt/soft/DB-GPT/dbgpt/util/tracer/tracer_middleware.py\", line 49, in dispatch\r\n    |     response = await call_next(request)\r\n    |   File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/base.py\", line 165, in call_next\r\n    |     raise app_exc\r\n    |   File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/base.py\", line 151, in coro\r\n    |     await self.app(scope, receive_or_disconnect, send_no_error)\r\n    |   File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/exceptions.py\", line 65, in __call__\r\n    |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\r\n    |   File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 64, in wrapped_app\r\n    |     raise exc\r\n    |   File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\r\n    |     await app(scope, receive, sender)\r\n    |   File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/routing.py\", line 756, in __call__\r\n    |     await self.middleware_stack(scope, receive, send)\r\n    |   File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/routing.py\", line 776, in app\r\n    |     await route.handle(scope, receive, send)\r\n    |   File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/routing.py\", line 297, in handle\r\n    |     await self.app(scope, receive, send)\r\n    |   File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/routing.py\", line 77, in app\r\n    |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\r\n    |   File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 64, in wrapped_app\r\n    |     raise exc\r\n    |   File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\r\n    |     await app(scope, receive, sender)\r\n    |   File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/routing.py\", line 72, in app\r\n    |     response = await func(request)\r\n    |   File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/fastapi/routing.py\", line 278, in app\r\n    |     raw_response = await run_endpoint_function(\r\n    |   File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/fastapi/routing.py\", line 191, in run_endpoint_function\r\n    |     return await dependant.call(**values)\r\n    |   File \"/opt/soft/DB-GPT/dbgpt/app/openapi/api_v1/editor/api_editor_v1.py\", line 95, in editor_sql_run\r\n    |     db_name = run_param[\"db_name\"]\r\n    | KeyError: 'db_name'\r\n    +------------------------------------\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 399, in run_asgi\r\n    result = await app(  # type: ignore[func-returns-value]\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py\", line 70, in __call__\r\n    return await self.app(scope, receive, send)\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/cors.py\", line 93, in __call__\r\n    await self.simple_response(scope, receive, send, request_headers=headers)\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/cors.py\", line 148, in simple_response\r\n    await self.app(scope, receive, send)\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/fastapi/applications.py\", line 1054, in __call__\r\n    await super().__call__(scope, receive, send)\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/applications.py\", line 123, in __call__\r\n    await self.middleware_stack(scope, receive, send)\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/errors.py\", line 186, in __call__\r\n    raise exc\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/errors.py\", line 164, in __call__\r\n    await self.app(scope, receive, _send)\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/base.py\", line 189, in __call__\r\n    with collapse_excgroups():\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/contextlib.py\", line 153, in __exit__\r\n    self.gen.throw(typ, value, traceback)\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/_utils.py\", line 93, in collapse_excgroups\r\n    raise exc\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/base.py\", line 191, in __call__\r\n    response = await self.dispatch_func(request, call_next)\r\n  File \"/opt/soft/DB-GPT/dbgpt/util/tracer/tracer_middleware.py\", line 49, in dispatch\r\n    response = await call_next(request)\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/base.py\", line 165, in call_next\r\n    raise app_exc\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/base.py\", line 151, in coro\r\n    await self.app(scope, receive_or_disconnect, send_no_error)\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/middleware/exceptions.py\", line 65, in __call__\r\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 64, in wrapped_app\r\n    raise exc\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\r\n    await app(scope, receive, sender)\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/routing.py\", line 756, in __call__\r\n    await self.middleware_stack(scope, receive, send)\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/routing.py\", line 776, in app\r\n    await route.handle(scope, receive, send)\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/routing.py\", line 297, in handle\r\n    await self.app(scope, receive, send)\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/routing.py\", line 77, in app\r\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 64, in wrapped_app\r\n    raise exc\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\r\n    await app(scope, receive, sender)\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/starlette/routing.py\", line 72, in app\r\n    response = await func(request)\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/fastapi/routing.py\", line 278, in app\r\n    raw_response = await run_endpoint_function(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/fastapi/routing.py\", line 191, in run_endpoint_function\r\n    return await dependant.call(**values)\r\n  File \"/opt/soft/DB-GPT/dbgpt/app/openapi/api_v1/editor/api_editor_v1.py\", line 95, in editor_sql_run\r\n    db_name = run_param[\"db_name\"]\r\nKeyError: 'db_name'\r\n![Snipaste_2024-07-16_09-31-47](https://github.com/user-attachments/assets/95f0377b-0ecc-4897-9e35-1faa65f7778a)\r\n![Snipaste_2024-07-16_09-32-20](https://github.com/user-attachments/assets/d80ae57c-f0ef-4c39-b5f3-df5639db9e55)\r\n\n\n### What you expected to happen\n\ni don't know....\n\n### How to reproduce\n\nuse tongyi.\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "sky1417168",
      "author_type": "User",
      "created_at": "2024-07-16T01:34:47Z",
      "updated_at": "2025-03-28T06:13:19Z",
      "closed_at": "2024-08-24T21:04:44Z",
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1726/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1726",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1726",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:26.189190",
      "comments": [
        {
          "author": "sky1417168",
          "body": "数据库里是有这个库的，所有的数据库，mysql，sqlite，starrocks连接都是正常，打开数据对话就显示错误",
          "created_at": "2024-07-16T03:03:49Z"
        },
        {
          "author": "dusens",
          "body": "你选择的对话是mysql数据库还报错么,另外你的 dbgpt版本是多少 可以升级下最新的试一下,我这边数据库对话都没问题我用的还是0.5.6版本",
          "created_at": "2024-07-18T04:52:34Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-08-17T21:04:36Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue bas been closed, because it has been marked as `stale` and there has been no activity for over 7 days.",
          "created_at": "2024-08-24T21:04:44Z"
        },
        {
          "author": "Carlycjl",
          "body": "> 你选择的对话是mysql数据库还报错么,另外你的 dbgpt版本是多少 可以升级下最新的试一下,我这边数据库对话都没问题我用的还是0.5.6版本\r\n\r\n请问你的数据库需要导入scheme吗？",
          "created_at": "2024-10-14T02:36:19Z"
        }
      ]
    },
    {
      "issue_number": 2546,
      "title": "[Doc][Module Name] dbgpt db migration 命令行问题",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n![Image](https://github.com/user-attachments/assets/5de4fd44-31e7-4287-9d5d-1c9c25ebde3e)\n\n这里面的-c 指的是什么文件？在什么位置？\n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "adogwangwang",
      "author_type": "User",
      "created_at": "2025-03-28T03:17:38Z",
      "updated_at": "2025-03-28T03:25:03Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2546/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2546",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2546",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:26.368599",
      "comments": [
        {
          "author": "fangyinc",
          "body": "Same as `dbgpt start webserver`, this configuration file is used to read the database configuration information",
          "created_at": "2025-03-28T03:25:02Z"
        }
      ]
    },
    {
      "issue_number": 2542,
      "title": "[Bug]在命令行执行dbgpt app install  ，在前端不会出现新安装的包",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [x] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [x] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nlinux\n\n### Models information\n\ndeepseek\n\n### What happened\n\n![Image](https://github.com/user-attachments/assets/0ce69bbb-296f-4304-819c-66c1736205d4)\n\n![Image](https://github.com/user-attachments/assets/40247425-e57c-406b-9035-9da4f6feab87)\n\ndbgpt app install summarizer-agent-example ...  安装remote list 中的包，显示安装成功后但是在前端还是没有显示\n\n### What you expected to happen\n\n请老师解答并解决\n\n### How to reproduce\n\n直接安装测试即可\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "adogwangwang",
      "author_type": "User",
      "created_at": "2025-03-27T08:38:48Z",
      "updated_at": "2025-03-28T02:53:35Z",
      "closed_at": "2025-03-27T21:31:21Z",
      "labels": [
        "question",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2542/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2542",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2542",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:26.550516",
      "comments": [
        {
          "author": "fangyinc",
          "body": "`summarizer-agent-example` is an agent app extension and will not be displayed on the AWEL flow page",
          "created_at": "2025-03-27T21:31:21Z"
        },
        {
          "author": "adogwangwang",
          "body": "> `summarizer-agent-example` is an agent app extension and will not be displayed on the AWEL flow page\n\nthen how to install all-in-one flow and make it appear in AWEL 工作流？",
          "created_at": "2025-03-28T02:53:34Z"
        }
      ]
    },
    {
      "issue_number": 2529,
      "title": "[Bug] [Module Name] Bug title  使用deepseek-r1时在think阶段前端没有渲染效果",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [x] Chat Data\n- [x] Chat Excel\n- [x] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\ndocker image\n\n### Models information\n\ndeepseek-r1\n\n### What happened\n\n![Image](https://github.com/user-attachments/assets/81a9fa78-d46e-4243-9afb-c76a38a23226)\n\n### What you expected to happen\n\n希望思考过程有渲染效果，而不是当做最终输出一样\n\n### How to reproduce\n\n连接deepseek-r1测试即可\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "adogwangwang",
      "author_type": "User",
      "created_at": "2025-03-26T08:40:38Z",
      "updated_at": "2025-03-28T02:44:29Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2529/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2529",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2529",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:26.766505",
      "comments": [
        {
          "author": "fangyinc",
          "body": "Where are you accessing `deepseek-r1` from? Please check your API , version 0.7.0 supports viewing thinking content in the web page.\nSee [more](http://docs.dbgpt.cn/blog/db-gpt-v070-release#2-integrated-deepseek-r1-inference-model)",
          "created_at": "2025-03-27T21:56:22Z"
        },
        {
          "author": "adogwangwang",
          "body": "> Where are you accessing `deepseek-r1` from? Please check your API , version 0.7.0 supports viewing thinking content in the web page. See [more](http://docs.dbgpt.cn/blog/db-gpt-v070-release#2-integrated-deepseek-r1-inference-model)\n\n华为910b部署的，是否不支持？",
          "created_at": "2025-03-28T02:44:29Z"
        }
      ]
    },
    {
      "issue_number": 2469,
      "title": "[Bug] [Chat DB] 配置TuGraph后，ChatDB 无应答显示'list_iterator' object is not subscriptable",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [x] Chat Data\n- [ ] Chat Excel\n- [x] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [x] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nQWen32B\n\n### What happened\n\n集成TuGraph后，引入模版图谱TheThreeBody_022F，进行ChatDB时报错：\n\n![Image](https://github.com/user-attachments/assets/2032232f-212c-464f-906b-189261404dfa)\n\n再进入到配置TuGraph界面，点击刷新，依然报错：\n\n![Image](https://github.com/user-attachments/assets/170ec650-443b-44e4-9fb5-a3b95531a890)\n\n### What you expected to happen\n\nnothing\n\n### How to reproduce\n\n1、添加TuGraph\n2、刷新TuGraph\n3、ChatDB选择该数据库，然后任意聊天\n\n### Additional context\n\n日志信息：\n2025-03-14 17:26:16 rocky9.0-2 dbgpt_serve.core.schemas[19397] ERROR common_exception_handler catch Exception: success=False err_code='E0003' err_msg=\"'list_iterator' object is not subscriptable\" data=None\nINFO:     10.36.196.238:62098 - \"POST /api/v2/serve/datasources/1/refresh HTTP/1.1\" 400 Bad Request\nERROR:    Exception in ASGI application\n  + Exception Group Traceback (most recent call last):\n  |   File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_utils.py\", line 77, in collapse_excgroups\n  |     yield\n  |   File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 186, in __call__\n  |     async with anyio.create_task_group() as task_group:\n  |   File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 767, in __aexit__\n  |     raise BaseExceptionGroup(\n  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 409, in run_asgi\n    |     result = await app(  # type: ignore[func-returns-value]\n    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n    |     return await self.app(scope, receive, send)\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    |     await self.simple_response(scope, receive, send, request_headers=headers)\n    |   File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    |     await self.app(scope, receive, send)\n    |   File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/fastapi/applications.py\", line 1054, in __call__\n    |     await super().__call__(scope, receive, send)\n    |   File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/applications.py\", line 113, in __call__\n    |     await self.middleware_stack(scope, receive, send)\n    |   File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 187, in __call__\n    |     raise exc\n    |   File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    |     await self.app(scope, receive, _send)\n    |   File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 185, in __call__\n    |     with collapse_excgroups():\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.11/contextlib.py\", line 158, in __exit__\n    |     self.gen.throw(typ, value, traceback)\n    |   File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_utils.py\", line 83, in collapse_excgroups\n    |     raise exc\n    |   File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 187, in __call__\n    |     response = await self.dispatch_func(request, call_next)\n    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/root/guopengye/DB-GPT/packages/dbgpt-core/src/dbgpt/util/tracer/tracer_middleware.py\", line 49, in dispatch\n    |     response = await call_next(request)\n    |                ^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 163, in call_next\n    |     raise app_exc\n    |   File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 149, in coro\n    |     await self.app(scope, receive_or_disconnect, send_no_error)\n    |   File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n    |   File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n    |     raise exc\n    |   File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 715, in __call__\n    |     await self.middleware_stack(scope, receive, send)\n    |   File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 735, in app\n    |     await route.handle(scope, receive, send)\n    |   File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 288, in handle\n    |     await self.app(scope, receive, send)\n    |   File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 76, in app\n    |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n    |   File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n    |     raise exc\n    |   File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 73, in app\n    |     response = await f(request)\n    |                ^^^^^^^^^^^^^^^^\n    |   File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 301, in app\n    |     raw_response = await run_endpoint_function(\n    |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    |     return await dependant.call(**values)\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/root/guopengye/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/api/endpoints.py\", line 259, in refresh_datasource\n    |     res = await blocking_func_to_async(\n    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/root/guopengye/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/core/__init__.py\", line 32, in blocking_func_to_async\n    |     return await _blocking_func_to_async(executor, func, *args, **kwargs)\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/root/guopengye/DB-GPT/packages/dbgpt-core/src/dbgpt/util/executor_utils.py\", line 70, in blocking_func_to_async\n    |     return await loop.run_in_executor(executor, run_with_context)\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n    |     result = self.fn(*self.args, **self.kwargs)\n    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/root/guopengye/DB-GPT/packages/dbgpt-core/src/dbgpt/util/executor_utils.py\", line 67, in run_with_context\n    |     return ctx.run(partial(func, *args, **kwargs))\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/root/guopengye/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/service.py\", line 310, in refresh\n    |     self._db_summary_client.db_summary_embedding(\n    |   File \"/root/guopengye/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/db_summary_client.py\", line 50, in db_summary_embedding\n    |     db_summary_client = self.create_summary_client(dbname, db_type)\n    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/root/guopengye/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/db_summary_client.py\", line 154, in create_summary_client\n    |     return GdbmsSummary(dbname, db_type)\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/root/guopengye/DB-GPT/packages/dbgpt-ext/src/dbgpt_ext/rag/summary/gdbms_db_summary.py\", line 48, in __init__\n    |     for table_name in tables[\"vertex_tables\"]\n    |                       ~~~~~~^^^^^^^^^^^^^^^^^\n    | TypeError: 'list_iterator' object is not subscriptable\n    +------------------------------------\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 409, in run_asgi\n    result = await app(  # type: ignore[func-returns-value]\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n    return await self.app(scope, receive, send)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    await self.simple_response(scope, receive, send, request_headers=headers)\n  File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    await self.app(scope, receive, send)\n  File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/fastapi/applications.py\", line 1054, in __call__\n    await super().__call__(scope, receive, send)\n  File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/applications.py\", line 113, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 187, in __call__\n    raise exc\n  File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    await self.app(scope, receive, _send)\n  File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 185, in __call__\n    with collapse_excgroups():\n  File \"/root/miniconda3/envs/dbgpt/lib/python3.11/contextlib.py\", line 158, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_utils.py\", line 83, in collapse_excgroups\n    raise exc\n  File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 187, in __call__\n    response = await self.dispatch_func(request, call_next)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/guopengye/DB-GPT/packages/dbgpt-core/src/dbgpt/util/tracer/tracer_middleware.py\", line 49, in dispatch\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 163, in call_next\n    raise app_exc\n  File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 149, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n    raise exc\n  File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 715, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 735, in app\n    await route.handle(scope, receive, send)\n  File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n    raise exc\n  File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 73, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 301, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/guopengye/DB-GPT/.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    return await dependant.call(**values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/guopengye/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/api/endpoints.py\", line 259, in refresh_datasource\n    res = await blocking_func_to_async(\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/guopengye/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/core/__init__.py\", line 32, in blocking_func_to_async\n    return await _blocking_func_to_async(executor, func, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/guopengye/DB-GPT/packages/dbgpt-core/src/dbgpt/util/executor_utils.py\", line 70, in blocking_func_to_async\n    return await loop.run_in_executor(executor, run_with_context)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/miniconda3/envs/dbgpt/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/guopengye/DB-GPT/packages/dbgpt-core/src/dbgpt/util/executor_utils.py\", line 67, in run_with_context\n    return ctx.run(partial(func, *args, **kwargs))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/guopengye/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/service.py\", line 310, in refresh\n    self._db_summary_client.db_summary_embedding(\n  File \"/root/guopengye/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/db_summary_client.py\", line 50, in db_summary_embedding\n    db_summary_client = self.create_summary_client(dbname, db_type)\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/guopengye/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/db_summary_client.py\", line 154, in create_summary_client\n    return GdbmsSummary(dbname, db_type)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/guopengye/DB-GPT/packages/dbgpt-ext/src/dbgpt_ext/rag/summary/gdbms_db_summary.py\", line 48, in __init__\n    for table_name in tables[\"vertex_tables\"]\n                      ~~~~~~^^^^^^^^^^^^^^^^^\nTypeError: 'list_iterator' object is not subscriptable\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "AlexanderGPY",
      "author_type": "User",
      "created_at": "2025-03-14T09:29:37Z",
      "updated_at": "2025-03-27T21:46:46Z",
      "closed_at": "2025-03-27T21:46:46Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2469/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2469",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2469",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:26.986836",
      "comments": []
    },
    {
      "issue_number": 2159,
      "title": "Module: ChatKnowledge",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n1. At present, the knowledge base creation supports the upload of PDF files, but it seems to not handle image-based PDF files, resulting in empty content after upload.\r\n\r\n2. It would be beneficial to enhance the knowledge base creation section to include support for image-based PDFs and image processing. This would allow for the handling of a greater variety of data types.\r\n\r\n1、目前知识库创建那边虽然支持pdf文件上传，但好像不支持图片类pdf文件的处理，上传后读取的内容为空。\r\n\r\n2、希望可以在创建知识库那块增加对图像类pdf和图像的处理，这样可以处理更多类型的数据。\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "virtual-sln",
      "author_type": "User",
      "created_at": "2024-11-27T06:31:08Z",
      "updated_at": "2025-03-27T21:05:24Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2159/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2159",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2159",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:26.986866",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "Thanks for your suggestion. now pdf loader support pdf extract json and pdf extract table, we will integrate OCR to solve the image info in the future.",
          "created_at": "2024-11-27T11:47:21Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-03-27T21:05:23Z"
        }
      ]
    },
    {
      "issue_number": 2528,
      "title": "When I run the service using Deepseek, an error occurs: “ValueError: Path /root/DB-GPT/models/bge-large-zh-v1.5 not found”",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\ndeepseek-reasoner\nbge-large-zh-v1.5\n\n### What happened\n\nError starting worker manager: model deepseek-reasoner@proxy/deepseek(192.168.1.223:5670) start successfully\n;model BAAI/bge-large-zh-v1.5@hf(192.168.1.223:5670) start failed, Traceback (most recent call last):\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/cluster/worker/manager.py\", line 631, in _start_worker\n    await self.run_blocking_func(\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/cluster/worker/manager.py\", line 146, in run_blocking_func\n    return await loop.run_in_executor(self.executor, func, *args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/cluster/worker/embedding_worker.py\", line 84, in start\n    self._embeddings_impl = self._adapter.load_from_params(self._model_params)\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/adapter/base.py\", line 829, in load_from_params\n    return model_adapter_cls.from_parameters(params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/rag/embedding/embeddings.py\", line 487, in from_parameters\n    return cls(\n           ^^^^\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/rag/embedding/embeddings.py\", line 468, in __init__\n    kwargs[\"client\"] = sentence_transformers.SentenceTransformer(\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py\", line 295, in __init__\n    raise ValueError(f\"Path {model_name_or_path} not found\")\nValueError: Path /root/DB-GPT/models/bge-large-zh-v1.5 not found\n\n\n### What you expected to happen\n\nrun successfully\n\n### How to reproduce\n\n1、uv sync --all-packages --extra \"base\" --extra \"proxy_openai\" --extra \"rag\" --extra \"storage_chromadb\" --extra \"dbgpts\" --extra \"hf\" --extra \"cpu\"\n2、Only modify \"api_key\"([models.llms]) in the \"dbgpt-proxy-deepseek.toml\"\n3、uv run dbgpt start webserver --config configs/dbgpt-proxy-deepseek.toml\n\n### Additional context\n\nI am using a proxy, but this error seems to be caused by a local search for bge-large-zh-v1.5\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "DuskBelievers",
      "author_type": "User",
      "created_at": "2025-03-26T07:16:23Z",
      "updated_at": "2025-03-27T10:41:41Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2528/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2528",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2528",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:27.175577",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "try figure out model path problem.",
          "created_at": "2025-03-26T14:31:32Z"
        },
        {
          "author": "Fangpeng-77",
          "body": "You should carefully check if there is a file named bge-large-zh-v1.5 under your /root/DB-GPT/models directory.",
          "created_at": "2025-03-26T15:44:52Z"
        },
        {
          "author": "DuskBelievers",
          "body": "@Fangpeng-77 @Aries-ckt \nI have found the reason: I did not annotate the 'path'. However, when I commented out 'path' and went to download the model from \"https://huggingface.co\", a new issue arose. The error message read: \"OSError: We couldn't connect to 'https://huggingface.co' to load this file, ",
          "created_at": "2025-03-27T02:19:23Z"
        },
        {
          "author": "Fangpeng-77",
          "body": "You can use this URL to download the model to your local machine and then place it in the \"models\" folder: \nURL 1 : https://huggingface.co/BAAI/bge-large-zh-v1.5\nURL 2 : https://modelscope.cn/models?name=bge-large-zh-v1.5&page=1",
          "created_at": "2025-03-27T10:41:39Z"
        }
      ]
    },
    {
      "issue_number": 1962,
      "title": "4卡A100 使用VLLM推理Qwen2-72B，报错(VllmWorkerProcess pid=10898) ERROR 09-04 17:23:44 multiproc_worker_utils.py:226] RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n4卡 A100  160g\n\n### Models information\n\ntext2vec-large-chinese\n\n### What happened\n\n4卡A100 使用VLLM推理Qwen2-72B，报错(VllmWorkerProcess pid=10898) ERROR 09-04 17:23:44 multiproc_worker_utils.py:226] RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n\n### What you expected to happen\n\n多卡推理出问题\n\n### How to reproduce\n\n1\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "TuDaCheng",
      "author_type": "User",
      "created_at": "2024-09-04T09:30:12Z",
      "updated_at": "2025-03-27T08:39:26Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1962/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1962",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1962",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:27.328954",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-02T21:04:43Z"
        },
        {
          "author": "329724814",
          "body": "你好朋友，我也碰到了一样的问题，请问你解决了吗",
          "created_at": "2025-03-27T08:39:25Z"
        }
      ]
    },
    {
      "issue_number": 2523,
      "title": "同名称的数据库没有办法创建",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n如果多个数据库同名，在创建一个数据连接之后，就没办法再创建同名的数据库了\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Eason-Shen",
      "author_type": "User",
      "created_at": "2025-03-25T07:59:08Z",
      "updated_at": "2025-03-27T02:59:08Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2523/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2523",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2523",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:27.535388",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "sorry about that, now does not support different database with same db name.",
          "created_at": "2025-03-26T14:34:37Z"
        },
        {
          "author": "Eason-Shen",
          "body": "> sorry about that, now does not support different database with same db name.\n\n请问后续有修改的计划吗？",
          "created_at": "2025-03-27T02:59:07Z"
        }
      ]
    },
    {
      "issue_number": 2537,
      "title": "[Bug] [Module Name] Bug title chat dashboard 功能editor中显示与preview中绘图结果不一致",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [x] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nlinux\n\n### Models information\n\ndeepseek-r1\n\n### What happened\n\n已合并#2530提交记录，解决save按钮报错的问题，进一步测试发现dashboard功能还存在以下问题：\n\n1. 在preview 和 editor 两个模式下查看同一title的结果，生成的图片不一致，在editor中生成的是对的，但是在preview中看到的图片驴唇不对马嘴，如图\n\n![Image](https://github.com/user-attachments/assets/5999bc57-bd68-4604-bc4b-2ff4ea072f12)\n\n![Image](https://github.com/user-attachments/assets/5922840a-fc23-49c7-a172-975e590dd4cd)\n图一和图二是分别在editor和preview当中，editor生成图片正确，但是到了preview当中出来的不一致。更多示例：\n\n![Image](https://github.com/user-attachments/assets/46b9efeb-5500-42c8-b4bb-4cc3f8d710fb)\n\n![Image](https://github.com/user-attachments/assets/2b2091af-3981-4a04-9827-70022d6c305d)\n也是同样的问题\n2. \n\n![Image](https://github.com/user-attachments/assets/7fd74562-a164-496e-a533-efcffd2ba817)\n\n![Image](https://github.com/user-attachments/assets/f43d483a-ee21-4f80-8b11-01e44d5f76cc)\n\n在editor模式下，run之后看到右侧的表格和图片显示不全，只有缩放网页到很小才能全部如画，建议右侧显示表格和图片一栏添加滚轮，并且中间sql和图标分割界限设置为可拖动形式以调整两栏大小。\n\n3. 通过测试一些绘图工具，感觉echarts的展示效果较好，各位老师可以考虑日后调整绘图形式。\n\n\n### What you expected to happen\n\n希望老师看到并解决以上问题，这些问题应该是在较早版本就已经发现过~ 谢谢各位老师在百忙之中解决！\n\n### How to reproduce\n\n直接问答即可\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "adogwangwang",
      "author_type": "User",
      "created_at": "2025-03-27T02:56:59Z",
      "updated_at": "2025-03-27T02:56:59Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2537/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2537",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2537",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:27.731483",
      "comments": []
    },
    {
      "issue_number": 2535,
      "title": "[Bug] [cluster] apiserver error",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nMacOS(x86)\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [x] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [x] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice\n\n### Models information\n\nLLM: deepseek-v3 or deepseek-r1\n\n### What happened\n\nModelOutput(content={'object': {'data': '`', 'format': 'text'}, 'type': 'text'}, error_code=0, incremental=False, model_context={'prompt_echo_len_char': -1, 'has_format_prompt': False, 'echo': False}, finish_reason=None, usage=None, metrics={'collect_index': 1, 'start_time_ms': 1742987132061, 'end_time_ms': 1742987135503, 'current_time_ms': 1742987135503, 'first_token_time_ms': None, 'first_completion_time_ms': 1742987135505, 'first_completion_tokens': None, 'prompt_tokens': None, 'completion_tokens': None, 'total_tokens': None, 'speed_per_second': None, 'current_gpu_infos': None, 'avg_gpu_infos': None})\n\n\nFile \"./packages/dbgpt-core/src/dbgpt/model/cluster/apiserver/api.py\", line 334, in chat_completion_stream_generator\n    decoded_unicode = model_output.text.replace(\"\\ufffd\", \"\")\n\n修复以上后又报以下：\n File \"./packages/dbgpt-core/src/dbgpt/model/cluster/apiserver/api.py\", line 656, in create_chat_completion\n    |     return await api_server.chat_completion_generate(\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"./packages/dbgpt-core/src/dbgpt/model/cluster/apiserver/api.py\", line 419, in chat_completion_generate\n    |     content=model_output.text,\n    |             ^^^^^^^^^^^^^^^^^\n\n### What you expected to happen\n\n1. ModelOutput content 由原来的str 类型切换成现在的 Union[MediaContent, List[MediaContent]]，并未在api server上做适配。\n\n### How to reproduce\n\n1.  dbgpt start controller --config configs/controller/dev.toml\n```toml\n[service.model.controller]\nhost = \"0.0.0.0\"\nport = 8080\n\n[service.model.controller.registry]\n[service.model.controller.registry.database]\ntype = \"mysql\"\nhost = \"${env:MYSQL_HOST:-xxxxx.com.cn}\"\nport = \"${env:MYSQL_PORT:-3337}\"\ndatabase = \"${env:MYSQL_DATABASE:-db-gpt}\"\nuser = \"${env:MYSQL_USER:-root}\"\npassword =\"${env:MYSQL_PASSWORD:}\"\n```\n\n2.  dbgpt start worker --config ./configs/proxy/dev.toml \n```toml\n[service.model.worker]\nworker_type = \"llm\"\nstandalone = \"True\"\ncontroller_addr = \"http://0.0.0.0:8080\"\n\n[models]\n[[models.llms]]\nname = \"${env:LLM_MODEL_NAME:-qwen-plus}\"\nprovider = \"${env:LLM_MODEL_PROVIDER:-proxy/tongyi}\"\napi_base = \"${env:DASHSCOPE_API_BASE:-https://prem.dashscope.aliyuncs.com/compatible-mode/v1}\"\napi_key = \"${env:DASHSCOPE_API_KEY:-sk-XXXXX}\"\n\n[[models.llms]]\nname = \"${env:LLM_MODEL_NAME:-qwen-max}\"\nprovider = \"${env:LLM_MODEL_PROVIDER:-proxy/tongyi}\"\napi_base = \"${env:DASHSCOPE_API_BASE:-https://prem.dashscope.aliyuncs.com/compatible-mode/v1}\"\napi_key = \"${env:DASHSCOPE_API_KEY:-sk-XXXXX}\"\n\n[[models.llms]]\nname = \"${env:LLM_MODEL_NAME:-tongyi/DeepSeek-V3}\"\nprovider = \"${env:LLM_MODEL_PROVIDER:-proxy/tongyi}\"\napi_base = \"${env:DASHSCOPE_API_BASE:-https://dashscope.aliyuncs.com/compatible-mode/v1}\"\napi_key = \"${env:DASHSCOPE_API_KEY:-sk-XXXXX}\"\nbackend = \"deepSeek-v3\"\n\n[[models.llms]]\nname = \"${env:LLM_MODEL_NAME:-tongyi/DeepSeek-R1}\"\nprovider = \"${env:LLM_MODEL_PROVIDER:-proxy/tongyi}\"\napi_base = \"${env:DASHSCOPE_API_BASE:-https://dashscope.aliyuncs.com/compatible-mode/v1}\"\napi_key = \"${env:DASHSCOPE_API_KEY:-sk-XXXXX}\"\nbackend = \"deepseek-r1\"\n\n[[models.embeddings]]\nname = \"${env:EMBEDDING_MODEL_NAME:-text-embedding-v3}\"\nprovider = \"${env:EMBEDDING_MODEL_PROVIDER:-proxy/tongyi}\"\napi_key = \"${env:DASHSCOPE_API_KEY:-sk-XXXXX}\"\n```\n3. dbgpt start apiserver --config configs/api/dev.toml\n4. api call\ncurl --location 'http://127.0.0.1:8100/api/v1/chat/completions' \\\n--header 'Content-Type: application/json' \\\n--header 'Authorization: Bearer xlc-aabbccdd' \\\n--data '{\n    \"model\": \"qianfan/deepseek-v3\",\n    \"messages\": [\n        {\n            \"role\": \"system\",\n            \"content\": \"You are a helpful assistant.\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"Runner \\n 什么是Runner？Runner是用来执行DAG中任务的类。当我们通过 task.call(call_data='\\''world'\\'') 调用任务时，我们正使用runner来执行任务。它会触发该任务的所有父任务，然后执行该任务。DefaultWorkflowRunner 在同一进程中运行您的任务。 RayWorkflowRunner 在 Ray 集群中运行您的任务（社区版本尚未实现）。此外，您还可以实现自己的运行器以在自己的环境中运行任务。\"\n        }\n    ],\n    \"stream\": true\n}'\n\n### Additional context\n\n.packages/dbgpt-core/src/dbgpt/model/cluster/worker/manager.py\n代码有变动，添加如果全是代理模型，可以一次启动多个，避免生产环境一个代理一个docker实例。\n\ndef run_worker_manager(\n    config_file: str,\n    app=None,\n    include_router: bool = True,\n    start_listener: Callable[[\"WorkerManager\"], None] = None,\n    **kwargs,\n):\n    global worker_manager\n    worker_params, deploy_model_params, sys_trace, sys_log = _parse_config(config_file)\n…………\n    def _start_deploy_model(start_model_params: BaseDeployModelParameters):\n        if isinstance(start_model_params, LLMDeployModelParameters):\n            _start_local_worker(\n                worker_manager,\n                worker_params,\n                start_model_params,\n            )\n        elif isinstance(start_model_params, EmbeddingDeployModelParameters):\n            worker_params.worker_type = WorkerType.TEXT2VEC\n            _start_local_worker(\n                worker_manager,\n                worker_params,\n                start_model_params,\n            )\n        elif isinstance(start_model_params, RerankerDeployModelParameters):\n            worker_params.worker_type = WorkerType.RERANKER\n            _start_local_worker(\n                worker_manager,\n                worker_params,\n                start_model_params,\n            )\n        else:\n            raise ValueError(f\"Unsupported deploy model params: {start_model_params}\")\n\n    if isinstance(deploy_model_params, list):\n        for model_params in deploy_model_params:\n            _start_deploy_model(model_params)\n    else:\n        _start_deploy_model(deploy_model_params)\n\n    worker_manager.after_start(start_listener)\n\n    if include_router:\n        app.include_router(router, prefix=\"/api\")\n\n……………………\n\n\n\ndef _parse_config(config_file: str):\n    from dbgpt.configs.model_config import ROOT_PATH\n    from dbgpt.model import scan_model_providers\n    from dbgpt.util.configure import ConfigurationManager\n\n    def config_handler(config_dict: Union[Dict[str, Any], List[Dict[str, Any]]]):\n        if isinstance(config_dict, list):\n            if not config_dict:\n                raise ValueError(\"Empty model config list\")\n\n            # 检查所有配置项的provider是否以proxy/开头\n            all_proxy = all(item.get('provider', '').find('proxy/') >=0 for item in config_dict)\n            if all_proxy:\n                return config_dict\n\n            if len(config_dict) > 1:\n                raise ValueError(\n                    \"Only one model config is supported when running worker in cluster \"\n                    \"mode\"\n                )\n            return config_dict[0]\n        else:\n            config_dict\n\n    scan_model_providers()\n\n    if not os.path.isabs(config_file) and not os.path.exists(config_file):\n        config_file = os.path.join(ROOT_PATH, config_file)\n\n    cfg = ConfigurationManager.from_file(config_file)\n    worker_params = cfg.parse_config(\n        ModelWorkerParameters, prefix=\"service.model.worker\", hook_section=\"hooks\"\n    )\n    worker_type = worker_params.worker_type\n    sys_trace: Optional[TracerParameters] = None\n    sys_log: Optional[LoggingParameters] = None\n    configs = []\n    if cfg.exists(\"models.llms\") and (\n        worker_type is None or worker_type == WorkerType.LLM\n    ):\n        llm_deploy_config = cfg.parse_config(\n            LLMDeployModelParameters,\n            prefix=\"models.llms\",\n            config_handler=config_handler,\n        )\n        if isinstance(llm_deploy_config, list):\n            configs.extend(llm_deploy_config)\n        else:\n            configs.append(llm_deploy_config)\n    if cfg.exists(\"models.embeddings\") and (\n        worker_type is None or worker_type == WorkerType.TEXT2VEC\n    ):\n        embeddings_deploy_config = cfg.parse_config(\n            EmbeddingDeployModelParameters,\n            prefix=\"models.embeddings\",\n            config_handler=config_handler,\n        )\n        if isinstance(embeddings_deploy_config, list):\n            configs.extend(embeddings_deploy_config)\n        else:\n            configs.append(embeddings_deploy_config)\n    if cfg.exists(\"models.rerankers\") and (\n        worker_type is None or worker_type == WorkerType.RERANKER\n    ):\n        rerank_deploy_config = cfg.parse_config(\n            RerankerDeployModelParameters,\n            prefix=\"models.rerankers\",\n            config_handler=config_handler,\n        )\n        if isinstance(rerank_deploy_config, list):\n            configs.extend(rerank_deploy_config)\n        else:\n            configs.append(rerank_deploy_config)\n    if worker_type:\n        configs = [config for config in configs if config.worker_type() == worker_type]\n    if not configs:\n        raise ValueError(\"No model config found\")\n    if len(configs) > 1:\n        if all(config.provider.startswith('proxy/') for config in configs):\n            print(\"全是代理模型配置\")\n        else:\n            raise ValueError(\n                \"Only one model config is supported when running worker in cluster mode\"\n            )\n\n    if cfg.exists(\"trace\"):\n        sys_trace = cfg.parse_config(TracerParameters, prefix=\"trace\")\n    if cfg.exists(\"log\"):\n        sys_log = cfg.parse_config(LoggingParameters, prefix=\"log\")\n    return worker_params, configs, sys_trace, sys_log\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "xydz",
      "author_type": "User",
      "created_at": "2025-03-27T01:29:44Z",
      "updated_at": "2025-03-27T01:29:44Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2535/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2535",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2535",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:27.731526",
      "comments": []
    },
    {
      "issue_number": 2154,
      "title": "[Doc][Module Name] Documentation bug or improvement",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n默认返回的结果数量限制为50，如何取消限制\n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "lll-Dragon",
      "author_type": "User",
      "created_at": "2024-11-25T14:02:44Z",
      "updated_at": "2025-03-26T21:05:03Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2154/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2154",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2154",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:27.731533",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "50 means?",
          "created_at": "2024-11-25T15:32:46Z"
        },
        {
          "author": "lll-Dragon",
          "body": "使用Chat Data查询数据库中表的信息时，只返回50条信息，SQL语句后面会默认加一句LIMIT 50，限制了返回的结果最多为50条。",
          "created_at": "2024-11-26T10:53:00Z"
        },
        {
          "author": "lll-Dragon",
          "body": "SELECT\r\n  *\r\nFROM\r\n  scores\r\nLIMIT\r\n  50;",
          "created_at": "2024-11-26T11:33:18Z"
        },
        {
          "author": "Aries-ckt",
          "body": "`dbgpt/app/scene/chat_db/auto_execute/chat.py`\r\n```\r\nself.top_k: int = 50\r\n```",
          "created_at": "2024-11-26T15:11:25Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-03-26T21:05:02Z"
        }
      ]
    },
    {
      "issue_number": 2524,
      "title": "[Feature][model cluster] dbgpt start worker support multi proxy model",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n使用 dbgpt start worker --config ./configs/proxy/dev.toml  一次只能启动一个模型， 希望一次可以启动多个代理模型。\n\n\n<file> dev.toml</file>\n\n[service.model.worker]\nworker_type = \"llm\"\ncontroller_addr = \"http://0.0.0.0:8080/\"\n\n[models]\n[[models.llms]]\nname = \"${env:LLM_MODEL_NAME:-qianfan/deepseek-v3}\"\nprovider = \"${env:LLM_MODEL_PROVIDER:-proxy/qianfan}\"\napi_key = \"${env:QIANFAN_API_BASE:-bce-v3/XXXXXX}\"\nbackend = \"deepseek-v3\"\n\n[[models.llms]]\nname = \"${env:LLM_MODEL_NAME:-qianfan/deepseek-r1}\"\nprovider = \"${env:LLM_MODEL_PROVIDER:-proxy/qianfan}\"\napi_key = \"${env:QIANFAN_API_BASE:-bce-v3/XXXXXX}\"\nbackend = \"deepseek-r1\"\nreasoning_model = \"True\"\n\n### Use case\n\n我希望可以将“proxy/” 开头的 多个 provider 部署一个容器中。提高生产环境容器的利用率。\nLLMDeployModelParameters\n\ndef config_handler(config_dict: Union[Dict[str, Any], List[Dict[str, Any]]]):\n    if isinstance(config_dict, list):\n        if not config_dict:\n            raise ValueError(\"Empty model config list\")\n        if len(config_dict) > 1:\n            raise ValueError(\n                \"Only one model config is supported when running worker in cluster \"\n                \"mode\"\n            )\n        return config_dict[0]\n    else:\n        config_dict\n\n### Related issues\n\n暂未发现。\n\n### Feature Priority\n\nMedium\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "xydz",
      "author_type": "User",
      "created_at": "2025-03-25T10:08:14Z",
      "updated_at": "2025-03-26T14:36:28Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2524/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2524",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2524",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:27.981175",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "@fangyinc , take a look.",
          "created_at": "2025-03-26T14:36:13Z"
        }
      ]
    },
    {
      "issue_number": 2530,
      "title": "[Bug] [Module Name] Bug title chat dashboard editor显示问题",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [x] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nlinux\n\n### Models information\n\ndeepseek-r1\n\n### What happened\n\n![Image](https://github.com/user-attachments/assets/b69d6da6-4e35-43b9-821c-6fd23fc9d564)\n\n![Image](https://github.com/user-attachments/assets/c7839e0e-03c8-4b50-8aaf-d67c6632cccc)\n图一可以看到当浏览器界面大小设置为100%时，进入editor之后是看不到下面执行的表格和图片的\n图二显示当我将页面缩放到比较小的时候，可以看到表格和图片，但是看到修改sql之后执行run，表格中的数据变化了，但是表头没有随之改变。\nrun旁边的save不知道是什么功能？但是点击报错\nTraceback (most recent call last):\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 409, in run_asgi\n    result = await app(  # type: ignore[func-returns-value]\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n    return await self.app(scope, receive, send)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    await self.simple_response(scope, receive, send, request_headers=headers)\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    await self.app(scope, receive, send)\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/fastapi/applications.py\", line 1054, in __call__\n    await super().__call__(scope, receive, send)\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/starlette/applications.py\", line 113, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 187, in __call__\n    raise exc\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    await self.app(scope, receive, _send)\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 185, in __call__\n    with collapse_excgroups():\n  File \"/usr/lib/python3.11/contextlib.py\", line 155, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/starlette/_utils.py\", line 83, in collapse_excgroups\n    raise exc\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 187, in __call__\n    response = await self.dispatch_func(request, call_next)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/util/tracer/tracer_middleware.py\", line 49, in dispatch\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 163, in call_next\n    raise app_exc\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 149, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n    raise exc\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/starlette/routing.py\", line 715, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/starlette/routing.py\", line 735, in app\n    await route.handle(scope, receive, send)\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/starlette/routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/starlette/routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n    raise exc\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/starlette/routing.py\", line 73, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 301, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    return await dependant.call(**values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-app/src/dbgpt_app/openapi/api_v1/editor/api_editor_v1.py\", line 323, in chart_editor_submit\n    history_mem = chat_history_fac.get_store_instance(chart_edit_context.con_uid)\n                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/.uv.venv/lib/python3.11/site-packages/pydantic/main.py\", line 891, in __getattr__\n    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')\nAttributeError: 'ChatChartEditContext' object has no attribute 'con_uid'\n\n\n### What you expected to happen\n\n请老师抽空回答~\n\n### How to reproduce\n\n直接进行 问答即可\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "adogwangwang",
      "author_type": "User",
      "created_at": "2025-03-26T08:54:22Z",
      "updated_at": "2025-03-26T14:03:36Z",
      "closed_at": "2025-03-26T14:03:35Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2530/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2530",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2530",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:28.192898",
      "comments": []
    },
    {
      "issue_number": 1094,
      "title": "[Bug] When modifying in. env_ After the EMBEDDING_MODEL parameter, error text2vec-large-chinese does not exist in simple_rag_embedding_example.py",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [X] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU\n\n### Models information\n\nLLM: codellama-13b-sql-sft\r\nEmbedding Model: bge-large-zh\n\n### What happened\n\nWhen I set the parameter EMBEDDING_MODEL=bge-large-zh, an error occurs when starting the service\r\n\r\n2024-01-19 17:51:44 172-16-10-163 dbgpt.app.initialization.embedding_component[5422] INFO Register local LocalEmbeddingFactory\r\n2024-01-19 17:51:44 172-16-10-163 dbgpt.model.cluster.worker.embedding_worker[5422] INFO [EmbeddingsModelWorker] Parameters of device is None, use cuda\r\n2024-01-19 17:51:44 172-16-10-163 dbgpt.app.initialization.embedding_component[5422] INFO \r\n\r\n=========================== EmbeddingModelParameters ===========================\r\n\r\nmodel_name: bge-large-zh\r\nmodel_path: /mnt/data/xiuzhu/models/bge-large-zh\r\ndevice: cuda\r\nnormalize_embeddings: None\r\n\r\n======================================================================\r\n\r\n\r\n/home/dtstack/miniconda3/envs/dbgpt_0.4.6/lib/python3.10/site-packages/langchain/embeddings/__init__.py:29: LangChainDeprecationWarning: Importing embeddings from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\r\n\r\n`from langchain_community.embeddings import HuggingFaceEmbeddings`.\r\n\r\nTo install langchain-community run `pip install -U langchain-community`.\r\n  warnings.warn(\r\n2024-01-19 17:51:47 172-16-10-163 sentence_transformers.SentenceTransformer[5422] INFO Load pretrained SentenceTransformer: /mnt/data/xiuzhu/models/bge-large-zh\r\n2024-01-19 17:51:50 172-16-10-163 dbgpt.component[5422] INFO Register component with name embedding_factory and instance: <dbgpt.app.initialization.embedding_component.LocalEmbeddingFactory object at 0x7fec997b48e0>\r\n2024-01-19 17:51:51 172-16-10-163 dbgpt.component[5422] INFO Register component with name dbgpt_model_cache_manager and instance: <dbgpt.storage.cache.manager.LocalCacheManager object at 0x7fec909c6800>\r\n2024-01-19 17:51:51 172-16-10-163 dbgpt.component[5422] INFO Register component with name dbgpt_awel_trigger_manager and instance: <dbgpt.core.awel.trigger.trigger_manager.DefaultTriggerManager object at 0x7fec909c6c50>\r\n2024-01-19 17:51:51 172-16-10-163 dbgpt.component[5422] INFO Register component with name dbgpt_awel_dag_manager and instance: <dbgpt.core.awel.dag.dag_manager.DAGManager object at 0x7fec909c4220>\r\n2024-01-19 17:51:51 172-16-10-163 dbgpt.core.awel.dag.loader[5422] INFO Importing /mnt/data/xiuzhu/DB-GPT/examples/awel/simple_rag_embedding_example.py\r\n2024-01-19 17:51:51 172-16-10-163 sentence_transformers.SentenceTransformer[5422] INFO Load pretrained SentenceTransformer: /mnt/data/xiuzhu/models/bge-large-zh\r\n2024-01-19 17:51:53 172-16-10-163 sentence_transformers.SentenceTransformer[5422] INFO Use pytorch device: cuda\r\n<class 'dbgpt.storage.vector_store.chroma_store.ChromaStore'>\r\n/home/dtstack/miniconda3/envs/dbgpt_0.4.6/lib/python3.10/site-packages/langchain/vectorstores/__init__.py:35: LangChainDeprecationWarning: Importing vector stores from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\r\n\r\n`from langchain_community.vectorstores import Chroma`.\r\n\r\nTo install langchain-community run `pip install -U langchain-community`.\r\n  warnings.warn(\r\n2024-01-19 17:51:54 172-16-10-163 chromadb.config[5422] DEBUG Starting component System\r\n2024-01-19 17:51:54 172-16-10-163 chromadb.config[5422] DEBUG Starting component Posthog\r\n2024-01-19 17:51:54 172-16-10-163 chromadb.config[5422] DEBUG Starting component SqliteDB\r\n2024-01-19 17:51:54 172-16-10-163 chromadb.config[5422] DEBUG Starting component LocalSegmentManager\r\n2024-01-19 17:51:54 172-16-10-163 chromadb.config[5422] DEBUG Starting component SegmentAPI\r\n2024-01-19 17:51:54 172-16-10-163 dbgpt.core.awel.dag.loader[5422] INFO Found dag DAG(dag_id=simple_sdk_rag_embedding_example) from mod <module 'unusual_prefix_5614104ab16cac672f036956b1e15e84848eaabc_simple_rag_embedding_example' from '/mnt/data/xiuzhu/DB-GPT/examples/awel/simple_rag_embedding_example.py'> and model file /mnt/data/xiuzhu/DB-GPT/examples/awel/simple_rag_embedding_example.py\r\n2024-01-19 17:51:54 172-16-10-163 dbgpt.core.awel.dag.loader[5422] INFO Importing /mnt/data/xiuzhu/DB-GPT/examples/awel/simple_rag_rewrite_example.py\r\n2024-01-19 17:51:55 172-16-10-163 dbgpt.core.awel.dag.loader[5422] INFO Found dag DAG(dag_id=dbgpt_awel_simple_rag_rewrite_example) from mod <module 'unusual_prefix_af430ba751d6890f0fb9dc8be6d40e6a4663f160_simple_rag_rewrite_example' from '/mnt/data/xiuzhu/DB-GPT/examples/awel/simple_rag_rewrite_example.py'> and model file /mnt/data/xiuzhu/DB-GPT/examples/awel/simple_rag_rewrite_example.py\r\n2024-01-19 17:51:55 172-16-10-163 dbgpt.core.awel.dag.loader[5422] INFO Importing /mnt/data/xiuzhu/DB-GPT/examples/awel/simple_rag_retriever_example.py\r\n2024-01-19 17:51:55 172-16-10-163 sentence_transformers.SentenceTransformer[5422] INFO Load pretrained SentenceTransformer: /mnt/data/xiuzhu/models/text2vec-large-chinese\r\n2024-01-19 17:51:55 172-16-10-163 dbgpt.core.awel.dag.loader[5422] ERROR Failed to import: /mnt/data/xiuzhu/DB-GPT/examples/awel/simple_rag_retriever_example.py, error message: Traceback (most recent call last):\r\n  File \"/mnt/data/xiuzhu/DB-GPT/dbgpt/core/awel/dag/loader.py\", line 86, in parse\r\n    loader.exec_module(new_module)\r\n  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n  File \"/mnt/data/xiuzhu/DB-GPT/examples/awel/simple_rag_retriever_example.py\", line 91, in <module>\r\n    vector_connector = _create_vector_connector()\r\n  File \"/mnt/data/xiuzhu/DB-GPT/examples/awel/simple_rag_retriever_example.py\", line 86, in _create_vector_connector\r\n    ).create(),\r\n  File \"/mnt/data/xiuzhu/DB-GPT/dbgpt/rag/embedding/embedding_factory.py\", line 48, in create\r\n    return HuggingFaceEmbeddings(**new_kwargs)\r\n  File \"/mnt/data/xiuzhu/DB-GPT/dbgpt/rag/embedding/embeddings.py\", line 91, in __init__\r\n    self.client = sentence_transformers.SentenceTransformer(\r\n  File \"/home/dtstack/miniconda3/envs/dbgpt_0.4.6/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py\", line 77, in __init__\r\n    raise ValueError(\"Path {} not found\".format(model_name_or_path))\r\nValueError: Path /mnt/data/xiuzhu/models/text2vec-large-chinese not found\r\n \n\n### What you expected to happen\n\nLoad the model text2vec-large-chinese by default in file  simple_rag_embedding_example.py、simple_rag_retriever_example.py、simple_rag_rewrite_example.py\n\n### How to reproduce\n\n1. set EMBEDDING_MODEL=bge-large-zh in .env\n\n### Additional context\n\nno \n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "xiuzhu9527",
      "author_type": "User",
      "created_at": "2024-01-19T14:48:56Z",
      "updated_at": "2025-03-26T14:00:11Z",
      "closed_at": "2024-01-20T11:48:50Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1094/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1094",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1094",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:28.192918",
      "comments": [
        {
          "author": "zhenglibing",
          "body": "我是通过docker容器部署的，也遇到同样的问题。还遇到缺少pymssql驱动的问题。\n",
          "created_at": "2025-03-26T14:00:10Z"
        }
      ]
    },
    {
      "issue_number": 2527,
      "title": "[Bug] [AWEL] 使用官方模板db_expert_assisant 创建的app 中调用 rag_url_knowledge_example创建的app的时候出错，不能显示结果",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [x] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n1\n\n### Models information\n\n\ndefault\n\n### What happened\n\n1. 多智能体意图识别工作流db_expert_assisant使用AgentGenerateContext作为上下文和最终输出\n与知识库问答工作流 rag_url_knowledge_example使用ModelOutput作为输出\n形成冲突，在意图识别到需要调用知识问答app之后，知识问答app执行并给出output，但output传递给多智能体工作流之后会产生报错\n2. 手动增加Modelouput转AgentGenerateContext的自定义算子之后，不再报错，知识库问答agent能正常调用并产生结果，但这个结果无法在多智能体对话中体现\n\n### What you expected to happen\n\n工作流正常运行，显示结果\n\n### How to reproduce\n\n使用问题中提到的两个awel模板创建构建应用并使用就会发生\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "tsq913",
      "author_type": "User",
      "created_at": "2025-03-26T03:46:34Z",
      "updated_at": "2025-03-26T09:21:50Z",
      "closed_at": "2025-03-26T09:21:50Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2527/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2527",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2527",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:28.371233",
      "comments": []
    },
    {
      "issue_number": 2145,
      "title": "[Bug] [Module Name] Bug title space add relation question error.",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [X] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [X] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\ngpu v100\n\n### Models information\n\nqwen2.5-72b\n\n### What happened\n\n当我对知识库中的一篇文档添加关联问题是报错，\r\n![image](https://github.com/user-attachments/assets/7bf59945-6cbd-4198-90d0-67f232c1e318)\r\n不知道这个报错是什么意思？请老师解答应该怎么解决？\n\n### What you expected to happen\n\n希望老师能够解答这个报错的意思，以及解决方案\n\n### How to reproduce\n\n上传文档到知识库，添加问题\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "adogwangwang",
      "author_type": "User",
      "created_at": "2024-11-21T08:17:55Z",
      "updated_at": "2025-03-25T21:05:08Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2145/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2145",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2145",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:28.371253",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "what's your `LOCAL_DB_TYPE` in your `.env`",
          "created_at": "2024-11-21T11:43:22Z"
        },
        {
          "author": "adogwangwang",
          "body": "> what's your `LOCAL_DB_TYPE` in your `.env`\r\n\r\nsqlite",
          "created_at": "2024-11-22T02:01:08Z"
        },
        {
          "author": "Aries-ckt",
          "body": "sorry about that, sqlite will reproduce the problem. we will fix it in next version\r\nIn the meantime you can switch `LOCAL_DB_TYPE`=mysql",
          "created_at": "2024-11-22T05:43:58Z"
        },
        {
          "author": "adogwangwang",
          "body": "> sorry about that, sqlite will reproduce the problem. we will fix it in next version In the meantime you can switch `LOCAL_DB_TYPE`=mysql\r\n\r\n好的，期待下一个版本~",
          "created_at": "2024-11-22T05:45:27Z"
        },
        {
          "author": "adogwangwang",
          "body": "> sorry about that, sqlite will reproduce the problem. we will fix it in next version In the meantime you can switch `LOCAL_DB_TYPE`=mysql\r\n\r\n老师您好，我试了mysql启动，还是同样的错误",
          "created_at": "2024-11-25T02:34:25Z"
        }
      ]
    },
    {
      "issue_number": 2505,
      "title": "[Bug] [Knowledge] Query: CALL db.vertexVectorKnnSearch('entity','_embedding', XXX使用, {top_k:None}) YIELD node WHERE node.distance < None RETURN node.id AS id;",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nProxy LLM\n\n### What happened\n\n创建完知识图谱后(Knowledge Graph)，与知识图谱对话时，返回错误。\n  File \"/dbgpt/rag/retriever/embedding.py\", line 267, in _similarity_search_with_score\n    return await self._index_store.asimilar_search_with_scores(\n  File \"/dbgpt/storage/knowledge_graph/knowledge_graph.py\", line 224, in asimilar_search_with_scores\n    subgraph = self._graph_store_adapter.explore_trigraph(\n  File \"/dbgpt/storage/knowledge_graph/community/tugraph_store_adapter.py\", line 672, in explore_trigraph\n    self.graph_store.conn.run(query=similarity_retrieval_query)\n  File \"/dbgpt/datasource/conn_tugraph.py\", line 127, in run\n    raise Exception(f\"Query execution failed: {e}\\nQuery: {query}\") from e\nException: Query execution failed: {code: CypherException} {message: Unknown variable: None}\nQuery: CALL db.vertexVectorKnnSearch('entity','_embedding', XXX使用, {top_k:None}) YIELD node WHERE node.distance < None RETURN node.id AS id;\n\n\n                similarity_retrieval_query = (\n                    \"CALL db.vertexVectorKnnSearch(\"\n                    f\"'{GraphElemType.ENTITY.value}','_embedding', {vector}, \"\n                    f\"{{top_k:{topk}}}) YIELD node \"\n                    f\"WHERE node.distance < {score_threshold} \"\n                    \"RETURN node.id AS id;\"\n                )\n手动将topk，score_threshold值固定，查询结果如下：\n  File \"/dbgpt/storage/knowledge_graph/knowledge_graph.py\", line 224, in asimilar_search_with_scores\n    subgraph = self._graph_store_adapter.explore_trigraph(\n  File \"/dbgpt/storage/knowledge_graph/community/tugraph_store_adapter.py\", line 674, in explore_trigraph\n    self.graph_store.conn.run(query=similarity_retrieval_query)\n  File \"/dbgpt/datasource/conn_tugraph.py\", line 127, in run\n    raise Exception(f\"Query execution failed: {e}\\nQuery: {query}\") from e\nException: Query execution failed: {code: CypherException} {message: Unknown variable: well}\nQuery: CALL db.vertexVectorKnnSearch('entity','_embedding', well, {top_k:5}) YIELD node WHERE node.distance < 0.3 RETURN node.id AS id;\n\n另外，登录TuGraph web端，可以正常查询上述知识库内容。\n\n### What you expected to happen\n\n正常返回查询结果\n\n### How to reproduce\n\n知识图谱对话时，返回错误。\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Hec-gitHub",
      "author_type": "User",
      "created_at": "2025-03-21T12:12:04Z",
      "updated_at": "2025-03-25T10:11:54Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2505/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2505",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2505",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:28.585695",
      "comments": [
        {
          "author": "Hec-gitHub",
          "body": "知识图谱创建成功了，使用view graph 也可以看到图谱与数据正常显示。\n另外，在TuGraph 客户端也看到了数据正常被创建，使用“entity”类型也可以正常查询数据。\n(properties:{\nname:\"API使用Key\",\nid:\"API使用Key\",\ndescription:null,\n_community_id:null,\n_embedding:null)。  \"_community_id\" 与 “_embedding” 的值都未创建。\n嵌入模型使用的是：m3e-large\n\n\n但是，使用Chat Knowledge 对话时，就会报查询错误。\n错误信息：\n  File \"/",
          "created_at": "2025-03-24T11:07:44Z"
        }
      ]
    },
    {
      "issue_number": 2521,
      "title": "[Bug] [ChatDB] Bot does not keep previous conversation in history. It can't continue a conversation and requires full context for response.",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [x] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nOpenAI Api\n\n### Models information\n\nLLM: GPT 4o\nEmbedding model: mini lm v6\n\n### What happened\n\nWhen asked a question w.r.t to the previous question the bot doesnt get the context.\n\n### What you expected to happen\n\nThe conversation should be natural, the bot should be able to access the previous conversation to answer the current questions.\n\n### How to reproduce\n\n1. Add a db to chat DB\n2. Ask a question\n3. Ask another question referring to the previous question as a continuation\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "kesavazt",
      "author_type": "User",
      "created_at": "2025-03-25T06:21:52Z",
      "updated_at": "2025-03-25T06:21:52Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2521/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2521",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2521",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:28.795267",
      "comments": []
    },
    {
      "issue_number": 2520,
      "title": "[Bug] [] After Added a new  SQLSERVER Connection successful, Terminal have some Failed Information.",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nQwen/Qwen2.5-Coder-32B-Instruct\nBAAI/bge-large-zh-v1.5\nBAAI/bge-reranker-v2-m3\n\n### What happened\n\nINFO:     127.0.0.1:52905 - \"POST /api/v2/serve/datasources/test-connection HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:52905 - \"POST /api/v2/serve/datasources HTTP/1.1\" 200 OK\n2025-03-25 13:20:38 PCSU dbgpt_serve.datasource.manages.connect_config_db[6004] INFO Result: <sqlalchemy.engine.cursor.CursorResult object at 0x0000022C533A7150>\nINFO:     127.0.0.1:52905 - \"GET /api/v2/serve/datasources HTTP/1.1\" 200 OK\n2025-03-25 13:20:38 PCSU dbgpt.datasource.rdbms.base[6004] ERROR Error in session scope: (pymssql.exceptions.OperationalError) (156, b\"Incorrect syntax near the keyword 'user'.DB-Lib error message 20018, severity 15:\\nGeneral SQL Server error: Check messages from the SQL Server\\n\")\n[SQL: SELECT user, host FROM mysql.user]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\n2025-03-25 13:20:38 PCSU dbgpt.datasource.rdbms.base[6004] ERROR Error in session scope: (pymssql.exceptions.ProgrammingError) (2812, b\"Could not find stored procedure 'SHOW'.DB-Lib error message 20018, severity 16:\\nGeneral SQL Server error: Check messages from the SQL Server\\n\")\n[SQL: SHOW GRANTS]\n(Background on this error at: https://sqlalche.me/e/20/f405)\n2025-03-25 13:20:38 PCSU dbgpt_serve.datasource.service.db_summary_client[6004] WARNING AIS2025, mssql summary error!(pymssql.exceptions.ProgrammingError) (2812, b\"Could not find stored procedure 'SHOW'.DB-Lib error message 20018, severity 16:\\nGeneral SQL Server error: Check messages from the SQL Server\\n\")\n[SQL: SHOW GRANTS]\n(Background on this error at: https://sqlalche.me/e/20/f405), detail: Traceback (most recent call last):\n  File \"src\\\\pymssql\\\\_pymssql.pyx\", line 447, in pymssql._pymssql.Cursor.execute\n  File \"src\\\\pymssql\\\\_mssql.pyx\", line 1125, in pymssql._mssql.MSSQLConnection.execute_query\n  File \"src\\\\pymssql\\\\_mssql.pyx\", line 1156, in pymssql._mssql.MSSQLConnection.execute_query\n  File \"src\\\\pymssql\\\\_mssql.pyx\", line 1289, in pymssql._mssql.MSSQLConnection.format_and_run_query\n  File \"src\\\\pymssql\\\\_mssql.pyx\", line 1855, in pymssql._mssql.check_cancel_and_raise\n  File \"src\\\\pymssql\\\\_mssql.pyx\", line 1901, in pymssql._mssql.raise_MSSQLDatabaseException\npymssql._mssql.MSSQLDatabaseException: (2812, b\"Could not find stored procedure 'SHOW'.DB-Lib error message 20018, severity 16:\\nGeneral SQL Server error: Check messages from the SQL Server\\n\")\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\DB-GPT\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1970, in _exec_single_context\n    self.dialect.do_execute(\n  File \"C:\\DB-GPT\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\default.py\", line 924, in do_execute\n    cursor.execute(statement, parameters)\n  File \"src\\\\pymssql\\\\_pymssql.pyx\", line 462, in pymssql._pymssql.Cursor.execute\npymssql.exceptions.ProgrammingError: (2812, b\"Could not find stored procedure 'SHOW'.DB-Lib error message 20018, severity 16:\\nGeneral SQL Server error: Check messages from the SQL Server\\n\")\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\DB-GPT\\packages\\dbgpt-serve\\src\\dbgpt_serve\\datasource\\service\\db_summary_client.py\", line 51, in db_summary_embedding\n    db_summary_client = self.create_summary_client(dbname, db_type)\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\DB-GPT\\packages\\dbgpt-serve\\src\\dbgpt_serve\\datasource\\service\\db_summary_client.py\", line 157, in create_summary_client\n    return RdbmsSummary(dbname, db_type)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\DB-GPT\\packages\\dbgpt-ext\\src\\dbgpt_ext\\rag\\summary\\rdbms_db_summary.py\", line 73, in __init__\n    grant=self.db.get_grants(),\n          ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\datasource\\rdbms\\base.py\", line 806, in get_grants\n    cursor = session.execute(text(\"SHOW GRANTS\"))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\DB-GPT\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\session.py\", line 2306, in execute\n    return self._execute_internal(\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\DB-GPT\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\session.py\", line 2200, in _execute_internal\n    result = conn.execute(\n             ^^^^^^^^^^^^^\n  File \"C:\\DB-GPT\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1421, in execute\n    return meth(\n           ^^^^^\n  File \"C:\\DB-GPT\\.venv\\Lib\\site-packages\\sqlalchemy\\sql\\elements.py\", line 514, in _execute_on_connection\n    return connection._execute_clauseelement(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\DB-GPT\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1643, in _execute_clauseelement\n    ret = self._execute_context(\n          ^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\DB-GPT\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1849, in _execute_context\n    return self._exec_single_context(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\DB-GPT\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1989, in _exec_single_context\n    self._handle_dbapi_exception(\n  File \"C:\\DB-GPT\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 2356, in _handle_dbapi_exception\n    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e\n  File \"C:\\DB-GPT\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1970, in _exec_single_context\n    self.dialect.do_execute(\n  File \"C:\\DB-GPT\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\default.py\", line 924, in do_execute\n    cursor.execute(statement, parameters)\n  File \"src\\\\pymssql\\\\_pymssql.pyx\", line 462, in pymssql._pymssql.Cursor.execute\nsqlalchemy.exc.ProgrammingError: (pymssql.exceptions.ProgrammingError) (2812, b\"Could not find stored procedure 'SHOW'.DB-Lib error message 20018, severity 16:\\nGeneral SQL Server error: Check messages from the SQL Server\\n\")   \n[SQL: SHOW GRANTS]\n(Background on this error at: https://sqlalche.me/e/20/f405)\n\n### What you expected to happen\n\nDon't show this error message\n\n### How to reproduce\n\nAdd A SQLSERVER Connection  and  click the refresh button.\n\n### Additional context\n\nBy the way, Another problem occured after add the SQL Connection\nWhen create app:\nerror: (sqlite3.IntegrityError) UNIQUE constraint failed: gpts_app.app_name [SQL: INSERT INTO gpts_app (app_code, app_name, icon, app_describe, language, team_mode, team_context, user_code, sys_code, published, param_need, created_at, updated_at, admins) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)] [parameters: ('ee93eefd-093b-11f0-80f4-48e7da102e06', 'test', None, 'test', 'zh', 'native_app', None, '001', None, 'false', None, '2025-03-25 09:30:29.339755', '2025-03-25 09:30:29.339755', None)] (Background on this error at: https://sqlalche.me/e/20/gkpj)\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "su1234121",
      "author_type": "User",
      "created_at": "2025-03-25T05:46:02Z",
      "updated_at": "2025-03-25T05:48:44Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2520/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2520",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2520",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:28.795286",
      "comments": [
        {
          "author": "su1234121",
          "body": "The problem mentioned in the  Additional context is occured after Creat A app And trying to creat Another One.",
          "created_at": "2025-03-25T05:48:43Z"
        }
      ]
    },
    {
      "issue_number": 1917,
      "title": "[Bug] [Module Name] Bug title \"Request error Rex Test connect Failure!No module named 'pymssql'\"",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [X] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nDB-GPT\\models\\Qwen-14B-Chat-Int4\r\n![error](https://github.com/user-attachments/assets/04b3ec01-f8c1-4964-a77a-6de82dc6b8b9)\r\n\n\n### What happened\n\nI configured the DB source as MS Sqlserver and save it got these errors.\r\n\r\nRequest error\r\nRex Test connect Failure!No module named 'pymssql'\n\n### What you expected to happen\n\nHow to fix it\n\n### How to reproduce\n\nJust try to add MS SQL as data source\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "zencorn",
      "author_type": "User",
      "created_at": "2024-08-29T09:42:20Z",
      "updated_at": "2025-03-24T22:48:30Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1917/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1917",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1917",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:28.969004",
      "comments": [
        {
          "author": "zencorn",
          "body": "Here are the error alert \r\n![msg](https://github.com/user-attachments/assets/07ebd070-a582-4a93-bff0-bbdaf6492b9d)\r\n",
          "created_at": "2024-08-29T09:48:15Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-12-27T21:04:42Z"
        },
        {
          "author": "zhaosting",
          "body": "try add pymssql use : uv pip install mssql \nneed in the vitural env ",
          "created_at": "2025-03-24T22:48:30Z"
        }
      ]
    },
    {
      "issue_number": 2514,
      "title": "Can CHAT DATA support the construction of a knowledge base with relational database table structure information",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nCan CHAT DATA support the construction of a knowledge base with relational database table structure information, and allow users to select the corresponding knowledge base during usage to improve the accuracy of Q&A? Currently, simply annotating table fields, I'm getting a very low accuracy rate in the Q&A process, and the fields are prone to errors. \n\n\n<img width=\"1109\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/a30a8d14-e5bd-4d6c-9157-2f9fe17c9af7\" />\n\n<img width=\"984\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/cdebd126-22e5-472f-b3b8-60a6320e5899\" />\n\nAs shown in the following pictures, Figure 1 is the result of my Q&A, and Figure 2 is the detailed list of fields in the relational table. Due to the lack of support from a knowledge base, the fields are often confused, which bothers me a lot. Could you provide a better solution? \n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "ganyu123456",
      "author_type": "User",
      "created_at": "2025-03-24T09:36:35Z",
      "updated_at": "2025-03-24T09:36:35Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2514/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2514",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2514",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:29.184906",
      "comments": []
    },
    {
      "issue_number": 2511,
      "title": "Does the configuration of the Embedding model support third - party tools, such as bge - m3? 2.",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nCurrently, Chat-Data is used for joint queries of multiple tables in the relational database. It is found that the existing functions still have some deficiencies in semantic understanding and transformation. Can it support the configuration of models like bge - m3? Looking forward to your reply. \n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "ganyu123456",
      "author_type": "User",
      "created_at": "2025-03-24T03:24:29Z",
      "updated_at": "2025-03-24T05:51:42Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2511/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2511",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2511",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:29.184920",
      "comments": [
        {
          "author": "fangyinc",
          "body": "Yes.  Just modify your config file:\n```toml\n[[models.embeddings]]\nname = \"BAAI/bge-m3\"\nprovider = \"hf\"\n# If not provided, the model will be downloaded from the Hugging Face model hub\n# uncomment the following line to specify the model path in the local file system\n# path = \"the-model-path-in-the-loc",
          "created_at": "2025-03-24T03:39:23Z"
        },
        {
          "author": "ganyu123456",
          "body": "> Yes. Just modify your config file:\n> \n> [[models.embeddings]]\n> name = \"BAAI/bge-m3\"\n> provider = \"hf\"\n> # If not provided, the model will be downloaded from the Hugging Face model hub\n> # uncomment the following line to specify the model path in the local file system\n> # path = \"the-model-path-in",
          "created_at": "2025-03-24T03:55:24Z"
        },
        {
          "author": "fangyinc",
          "body": "You can use your custom config file, please see [here](http://docs.dbgpt.cn/docs/next/installation/docker#deploy-with-gpu-local-model)",
          "created_at": "2025-03-24T04:32:45Z"
        },
        {
          "author": "ganyu123456",
          "body": "> You can use your custom config file, please see [here](http://docs.dbgpt.cn/docs/next/installation/docker#deploy-with-gpu-local-model)\n\nCould you please provide a contact method, such as a WeChat group or a DingTalk group? I'd like to have a friendly exchange. ",
          "created_at": "2025-03-24T05:51:40Z"
        }
      ]
    },
    {
      "issue_number": 2492,
      "title": "[Feature][code] 让DB-GPT 读取自己的代码存入 运行中的DB-GPT 查看BUG  自我修复BUG",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n[Feature][code] 让DB-GPT 读取自己的代码存入 运行中的DB-GPT 查看BUG  自我修复BUG\n1.给出URL地址 自动拉取项目地址  Linux 有个工具命令 tree  识别代码下面全部目录 存入DB-GPT\n2.根据目录信息 获取所有文件信息存入DB-GPT   如cat  README.MD  \n3.修改代码 根据聊天内容 截取markdrow 内容  以 开始\\`\\`\\` action  nvim   ... 代码内容 ...  \\`\\`\\` 结束   并结合Python 执行创建文件 安装配置neovim 比较复杂 建议使用 lazyvim 配置neovim  把使用文档 给它 DB-GPT 应该可以快速掌握 如需交互的  其它额外命令 用action cmd等等其它进行交互 操作\n4.git  把修改内容 填上 提交  提供github账号 提交\n5. 本地运行调试 根据docker 构建 查看日志 生成结果内容\n6. 查看github issues 自动创建任务 并解决 尝试修复\n\n### Use case\n\n1.给出URL地址 自动拉取项目地址  Linux 有个工具命令 tree  识别代码下面全部目录 存入DB-GPT\n如 查询全部` tree > 目录.txt`  限制目录层级（例如仅显示 2 层）  `tree -L 2 > 目录2.txt`  \n```\n\n.\n├── CODE_OF_CONDUCT\n├── CONTRIBUTING.md\n├── DISCKAIMER.md\n├── LICENSE\n├── MANIFEST.in\n├── Makefile\n├── README.ja.md\n├── README.md\n├── README.zh.md\n├── assets\n│   ├── DB-GPT.png\n│   ├── DB-GPT_zh.png\n│   ├── LOGO.png\n│   ├── RAG-IN-ACTION.jpg\n│   ├── dbgpt.png\n│   ├── ding.jpg\n│   ├── schema\n│   └── wechat.jpg\n├── configs\n│   ├── dbgpt-graphrag.toml\n│   ├── dbgpt-local-glm.toml\n│   ├── dbgpt-local-llama-cpp-server.toml\n│   ├── dbgpt-local-llama-cpp.toml\n│   ├── dbgpt-local-qwen.toml\n│   ├── dbgpt-local-vllm.toml\n│   ├── dbgpt-proxy-deepseek.toml\n│   ├── dbgpt-proxy-ollama.toml\n│   ├── dbgpt-proxy-openai.toml\n│   └── dbgpt-siliconflow.toml\n├── docker\n│   ├── allinone\n│   ├── base\n│   ├── build_all_images.sh\n│   ├── compose_examples\n│   ├── datasources\n│   └── examples\n├── docker-compose.yml\n├── docs\n│   ├── Dockerfile\n│   ├── Dockerfile-deploy\n│   ├── Dockerfile-deploy.dockerignore\n│   ├── README.md\n│   ├── babel.config.js\n│   ├── blog\n│   ├── docs\n│   ├── docusaurus.config.js\n│   ├── nginx\n│   ├── package-lock.json\n│   ├── package.json\n│   ├── patchs\n│   ├── sidebars.js\n│   ├── src\n│   ├── static\n│   ├── versions.json\n│   └── yarn.lock\n├── examples\n│   ├── __main__.py\n│   ├── agents\n│   ├── awel\n│   ├── client\n│   ├── rag\n│   ├── sdk\n│   └── test_files\n├── i18n\n│   ├── Makefile\n│   ├── README.md\n│   ├── README_zh.md\n│   ├── locales\n│   └── translate_util.py\n├── packages\n│   ├── dbgpt-accelerator\n│   ├── dbgpt-app\n│   ├── dbgpt-client\n│   ├── dbgpt-core\n│   ├── dbgpt-ext\n│   └── dbgpt-serve\n├── pilot\n│   └── meta_data\n├── pyproject.toml\n├── requirements\n│   ├── dev-requirements.txt\n│   └── lint-requirements.txt\n├── scripts\n│   ├── build_web_static.sh\n│   ├── examples\n│   ├── llama_cpp_install.sh\n│   ├── run_llm_benchmarks.sh\n│   └── setup_autodl_env.sh\n├── tests\n│   ├── __init__.py\n│   ├── intetration_tests\n│   └── unit_tests\n├── uv.lock\n├── web\n│   ├── README.md\n│   ├── app\n│   ├── client\n│   ├── components\n│   ├── genAntdCss.ts\n│   ├── global.d.ts\n│   ├── hooks\n│   ├── lib\n│   ├── locales\n│   ├── new-components\n│   ├── next.config.js\n│   ├── nprogress.css\n│   ├── package-lock.json\n│   ├── package.json\n│   ├── pages\n│   ├── postcss.config.js\n│   ├── public\n│   ├── styles\n│   ├── tailwind.config.js\n│   ├── tsconfig.json\n│   ├── types\n│   ├── utils\n│   └── yarn.lock\n├── 目录.txt\n\n54 directories, 66 files\n\n```\n\n2.根据目录信息 获取所有文件信息存入DB-GPT   如cat  README.MD  \n3.修改代码 根据聊天内容 截取markdrow 内容  以 开始\\`\\`\\` action  nvim   ... 代码内容 ...  \\`\\`\\` 结束   并结合Python 执行创建文件 安装配置neovim 比较复杂 建议使用 lazyvim 配置neovim  把使用文档 给它 DB-GPT 应该可以快速掌握 如需交互的  其它额外命令 用action cmd等等其它进行交互 操作\n4.git  把修改内容 填上 提交  提供github账号 提交\n5. 本地运行调试 根据docker 构建 查看日志 生成结果内容\n6. 查看github issues 自动创建任务 并解决 尝试修复\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "TomYule",
      "author_type": "User",
      "created_at": "2025-03-20T06:05:13Z",
      "updated_at": "2025-03-24T02:35:42Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2492/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2492",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2492",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:29.413729",
      "comments": [
        {
          "author": "fangyinc",
          "body": "感觉这个思路很有意思呀！也有实现的可能性，您对这块感兴趣么，有的话可以尝试一下然后提交到社区，有任何问题欢迎沟通。\n\nEn:\nThis approach seems very interesting! And it has potential for implementation. Are you interested in this area? If so, you could try it out and submit it to the community. Feel free to communicate if you have any questions.",
          "created_at": "2025-03-21T08:04:28Z"
        },
        {
          "author": "TomYule",
          "body": "> 感觉这个思路很有意思呀！也有实现的可能性，您对这块感兴趣么，有的话可以尝试一下然后提交到社区，有任何问题欢迎沟通。\n> \n> En: This approach seems very interesting! And it has potential for implementation. Are you interested in this area? If so, you could try it out and submit it to the community. Feel free to communicate if you have any questions.\n\n做好了 开源",
          "created_at": "2025-03-24T02:35:40Z"
        }
      ]
    },
    {
      "issue_number": 2143,
      "title": "[Doc][Module Name] Documentation bug or improvement The new prompt interface parameters have unclear meanings",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n![image](https://github.com/user-attachments/assets/2293cf6c-031d-48a2-8ead-e2d9443da20b)\r\n各位老师好，在使用prompt功能的时候遇到界面参数不清楚其含义的问题，比如截图中的dialect, display_type,response分别是什么含义以及应该怎么填写？ 以及 user_input与后面的用户输入有什么区别？请老师看到后可以解答下！感谢\n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "adogwangwang",
      "author_type": "User",
      "created_at": "2024-11-21T07:27:06Z",
      "updated_at": "2025-03-22T21:04:48Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2143/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2143",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2143",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:29.582863",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "- dialect: it means datasource dialog, such as `clickhouse`,`doris`, `mysql`\r\n- display_type: it means chat data chart display type , you can specify `response_line_chart` reference `vis_chart.py`\r\n- response: it means the json structure you expect the llm to output.",
          "created_at": "2024-11-21T12:04:44Z"
        },
        {
          "author": "adogwangwang",
          "body": "> * datasource dialog\r\n\r\n多谢老师，然后user_input和下面的用户输入有什么区别呢？",
          "created_at": "2024-11-22T02:03:38Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-03-22T21:04:47Z"
        }
      ]
    },
    {
      "issue_number": 2150,
      "title": "[Doc][Module Name] Documentation bug or improvement  how to use prompt module in native_app",
      "body": "### Search before asking\r\n\r\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\r\n\r\n\r\n### Description\r\n\r\n各位老师好，dbgpt-main版本中，我在使用prompt功能新增prompt模版之后，点开其他构建的应用时发现找不到选择prompt的位置，文档中也没有找到相关内容，请各位老师有时间可以解答下下~~比如在图中这个界面我应该如何调用已构建的prompt呢？\r\n![image](https://github.com/user-attachments/assets/f885da1a-5338-48a5-a5de-163de0e778ce)\r\n\r\n\r\n### Documentation Links\r\n\r\n_No response_\r\n\r\n### Are you willing to submit PR?\r\n\r\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "adogwangwang",
      "author_type": "User",
      "created_at": "2024-11-22T02:54:54Z",
      "updated_at": "2025-03-22T21:04:47Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2150/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2150",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2150",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:29.843363",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "sorry about that, now native app did not support prompt switch, we will fix that.\r\nnow you can create app with single agent and select `DataScientist`, and you can specify your prompt.\r\n![image](https://github.com/user-attachments/assets/544c071e-d104-4db1-b08c-dd0791d8bccf)\r\n![image](https://github",
          "created_at": "2024-11-22T04:41:00Z"
        },
        {
          "author": "adogwangwang",
          "body": "> sorry about that, now native app did not support prompt switch, we will fix that. now you can create app with single agent and select `DataScientist`, and you can specify your prompt. ![image](https://private-user-images.githubusercontent.com/13723926/388795273-544c071e-d104-4db1-b08c-dd0791d8bccf",
          "created_at": "2024-11-22T05:42:46Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-03-22T21:04:46Z"
        }
      ]
    },
    {
      "issue_number": 2482,
      "title": "[Bug] [tugraph]  tugraph import data occur error",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU\n\n### Models information\n\nolama\n\n### What happened\n\nINFO:     192.168.11.212:55748 - \"POST /knowledge/space/list HTTP/1.1\" 200 OK\nINFO:     192.168.11.212:55748 - \"GET /models/knowledge-graph.png HTTP/1.1\" 200 OK\nINFO:     192.168.11.212:55750 - \"GET /pictures/card_chat.png HTTP/1.1\" 200 OK\n/document/upload params: test001\ncurrent session:<sqlalchemy.orm.session.Session object at 0x7f1ed4340be0>\nINFO:     192.168.11.212:55793 - \"POST /knowledge/test001/document/upload HTTP/1.1\" 200 OK\n2025-03-18 07:15:37 687a6bfbb293 dbgpt_app.knowledge.api[1] INFO /document/chunkstrategies:\nINFO:     192.168.11.212:55793 - \"GET /knowledge/document/chunkstrategies HTTP/1.1\" 200 OK\n2025-03-18 07:15:40 687a6bfbb293 dbgpt_app.knowledge.api[1] INFO Received params: test001, [KnowledgeSyncRequest(doc_id=73, space_id=None, model_name=None, chunk_parameters=ChunkParameters(chunk_strategy='Automatic', text_splitter=None, splitter_type=<SplitterType.USER_DEFINE: 'user_define'>, chunk_size=512, chunk_overlap=50, separator='\\n', enable_merge=None))]\ncurrent session:<sqlalchemy.orm.session.Session object at 0x7f1edc64f340>\n2025-03-18 07:15:40 687a6bfbb293 dbgpt_serve.rag.connector[1] INFO VectorStore:<class 'dbgpt_ext.storage.knowledge_graph.knowledge_graph.BuiltinKnowledgeGraph'>\n2025-03-18 07:15:40 687a6bfbb293 dbgpt_app.knowledge.api[1] ERROR document sync batch error!\nTraceback (most recent call last):\n  File \"/app/packages/dbgpt-app/src/dbgpt_app/knowledge/api.py\", line 454, in batch_document_sync\n    doc_ids = await service.sync_document(requests=request)\n  File \"/app/packages/dbgpt-serve/src/dbgpt_serve/rag/service/service.py\", line 241, in sync_document\n    await self._sync_knowledge_document(space_id, doc, chunk_parameters)\n  File \"/app/packages/dbgpt-serve/src/dbgpt_serve/rag/service/service.py\", line 516, in _sync_knowledge_document\n    vector_store_connector = VectorStoreConnector(\n  File \"/app/packages/dbgpt-serve/src/dbgpt_serve/rag/connector.py\", line 82, in __init__\n    config_dict[key] = value\nTypeError: 'BuiltinKnowledgeGraphConfig' object does not support item assignment\nINFO:     192.168.11.212:55793 - \"POST /knowledge/test001/document/sync_batch HTTP/1.1\" 200 OK\n\n### What you expected to happen\n\nsee error\n\n### How to reproduce\n\nsee error\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "hiro110110",
      "author_type": "User",
      "created_at": "2025-03-18T08:17:26Z",
      "updated_at": "2025-03-22T12:56:28Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2482/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2482",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2482",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:30.080216",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "try http://docs.dbgpt.cn/docs/next/installation/integrations/graph_rag_install",
          "created_at": "2025-03-18T08:41:17Z"
        },
        {
          "author": "hiro110110",
          "body": "> try http://docs.dbgpt.cn/docs/next/installation/integrations/graph_rag_install\n\nno resolve",
          "created_at": "2025-03-22T12:56:27Z"
        }
      ]
    },
    {
      "issue_number": 2130,
      "title": "[Bug] [awel] ValueError: Create DAG AWELassi1 error, define_type: json, error: Unable to build resource instance，Input should be 'priority', 'auto' or 'default' [type=enum, input_value=None, input_type=NoneType",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU\n\n### Models information\n\nqwen2.5-7b\n\n### What happened\n\nWhen I create a workflow,the error occured. ValueError: Create DAG AWELassi1 error, define_type: json, error: Unable to build resource instance: resource_dbgpt.agent.core.plan.awel.agent_operator_resource.AWELAgentConfig_0, resource_cls: <class 'dbgpt.agent.core.plan.awel.agent_operator_resource.AWELAgentConfig'>, error: 1 validation error for AWELAgentConfig\n\n### What you expected to happen\n\nno bug\n\n### How to reproduce\n\ncreate the workflow\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "yugezheng",
      "author_type": "User",
      "created_at": "2024-11-16T09:09:42Z",
      "updated_at": "2025-03-21T21:04:56Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2130/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2130",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2130",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:30.354616",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "i haven't know what parameters you specify,  could you give the web screenshot, it looks like AWELAgentConfig parameter validation error.",
          "created_at": "2024-11-16T11:43:50Z"
        },
        {
          "author": "yugezheng",
          "body": "> i haven't know what parameters you specify, could you give the web screenshot, it looks like AWELAgentConfig parameter validation error.\r\n\r\n![image](https://github.com/user-attachments/assets/1ebbea32-9e7a-463a-b34d-1d525c91b548)\r\n",
          "created_at": "2024-11-18T07:29:17Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-03-21T21:04:55Z"
        }
      ]
    },
    {
      "issue_number": 2141,
      "title": "[Bug] [Module Name] Bug title delete knowledge space error.",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [X] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nqwen2.5-7b\r\ntext2vec-large-chinese\n\n### What happened\n\n![image](https://github.com/user-attachments/assets/066082c0-1063-4db1-a8cb-4129b4214558)\r\n我创建了一个知识图谱方式存储的知识库，删除的时候报错如图，请问如何解决？或者如何从后端删除该知识库？ 向量存储方式可以正常删除操作。\n\n### What you expected to happen\n\n不知道是否是缺少相关配置还是什么原因，希望能够得到解决的办法\n\n### How to reproduce\n\n按照文档下载部署DB-GPT后，正常运行创建一个知识图谱方式存储的知识库，然后就出现该报错\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "w371803361",
      "author_type": "User",
      "created_at": "2024-11-21T01:24:13Z",
      "updated_at": "2025-03-21T21:04:55Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2141/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2141",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2141",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:30.596148",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "it looks like vector_type you choose is `Full_Text` ?",
          "created_at": "2024-11-21T06:01:37Z"
        },
        {
          "author": "w371803361",
          "body": "\r\n\r\n![image](https://github.com/user-attachments/assets/7aa849c4-4ed3-4bee-8208-93da180f48ea)\r\n我当时选择的好像是“知识图谱”，现在想删除该知识库，但是一直报这个错误，不知道该如何解决，能否指导下。后台日志:\r\n2024-11-21 14:06:43 localhost1 elastic_transport.transport[232529] INFO HEAD http://localhost:9200/dbgpt_e6b58be8af95e79fa5e8af86e5ba93 [status:N/A",
          "created_at": "2024-11-21T06:07:22Z"
        },
        {
          "author": "w371803361",
          "body": "> 看起来您选择的vector_type是 ？`Full_Text`\r\n\r\n好像就是Full_Text，想请问我如何能够删除这个知识库？或者解决这个报错？",
          "created_at": "2024-11-21T06:17:28Z"
        },
        {
          "author": "Aries-ckt",
          "body": "如果你想用知识图谱应该是选第二个，你现在选的是全文是吗？",
          "created_at": "2024-11-21T06:23:38Z"
        },
        {
          "author": "w371803361",
          "body": "> 如果你想用知识图谱应该是选第二个，你现在选的是全文是吗？\r\n\r\n是的，现在选的是全文，想删除这个知识库",
          "created_at": "2024-11-21T06:25:37Z"
        }
      ]
    },
    {
      "issue_number": 2506,
      "title": "0.7版本啥时候发布？",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n_No response_\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "npumaster",
      "author_type": "User",
      "created_at": "2025-03-21T12:18:44Z",
      "updated_at": "2025-03-21T12:20:50Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2506/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2506",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2506",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:30.836369",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "可以main分支测测，准备发布了",
          "created_at": "2025-03-21T12:20:49Z"
        }
      ]
    },
    {
      "issue_number": 2503,
      "title": "[Bug] [Module Name] Bug title error when use tongyi as proxy embedding",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice:CPU\n\n### Models information\n\nEmbedding Model:text-embedding-v2@proxy/tongyi\n\n### What happened\n\nllm client class: <class 'dbgpt.model.proxy.llms.deepseek.DeepseekLLMClient'>\nINFO:     Uvicorn running on http://0.0.0.0:5670 (Press CTRL+C to quit)\n2025-03-21 16:44:30 iZ2ze6ul4clspwa0f0qhhaZ dbgpt.util.api_utils[1996] WARNING No healthy urls found, selecting randomly\nINFO:     127.0.0.1:35568 - \"POST /api/controller/models HTTP/1.1\" 200 OK\n2025-03-21 16:44:30 iZ2ze6ul4clspwa0f0qhhaZ dbgpt.model.cluster.worker.embedding_worker[1996] INFO Load embeddings model: text-embedding-v2\n2025-03-21 16:44:30 iZ2ze6ul4clspwa0f0qhhaZ dbgpt.model.cluster.worker.manager[1996] ERROR Error starting worker manager: model deepseek-reasoner@proxy/deepseek(192.168.1.194:5670) start successfully\n;model text-embedding-v2@proxy/tongyi(192.168.1.194:5670) start failed, Traceback (most recent call last):\n  File \"/home/DB-GPT/packages/dbgpt-ext/src/dbgpt_ext/rag/embeddings/tongyi.py\", line 74, in __init__\n    import dashscope  # type: ignore\n    ^^^^^^^^^^^^^^^^\nModuleNotFoundError: No module named 'dashscope'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/DB-GPT/packages/dbgpt-core/src/dbgpt/model/cluster/worker/manager.py\", line 631, in _start_worker\n    await self.run_blocking_func(\n  File \"/home/DB-GPT/packages/dbgpt-core/src/dbgpt/model/cluster/worker/manager.py\", line 146, in run_blocking_func\n    return await loop.run_in_executor(self.executor, func, *args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/DB-GPT/packages/dbgpt-core/src/dbgpt/model/cluster/worker/embedding_worker.py\", line 84, in start\n    self._embeddings_impl = self._adapter.load_from_params(self._model_params)\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/DB-GPT/packages/dbgpt-core/src/dbgpt/model/adapter/base.py\", line 829, in load_from_params\n    return model_adapter_cls.from_parameters(params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/DB-GPT/packages/dbgpt-ext/src/dbgpt_ext/rag/embeddings/tongyi.py\", line 94, in from_parameters\n    return cls(\n           ^^^^\n  File \"/home/DB-GPT/packages/dbgpt-ext/src/dbgpt_ext/rag/embeddings/tongyi.py\", line 76, in __init__\n    raise ValueError(\nValueError: Could not import python package: dashscope Please install dashscope by command `pip install dashscope\n\nINFO:     Shutting down\nINFO:     Waiting for application shutdown.\n\n### What you expected to happen\n\nsomething wrong when read config.toml\n\n### How to reproduce\n\n![Image](https://github.com/user-attachments/assets/1805d9fa-6efa-47ce-9ea4-1d03268dc273)\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "ZaneH1992",
      "author_type": "User",
      "created_at": "2025-03-21T08:54:59Z",
      "updated_at": "2025-03-21T08:59:01Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2503/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2503",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2503",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:31.062277",
      "comments": [
        {
          "author": "yyhhyyyyyy",
          "body": "Please use the following command to install the dependencies:\n\n```\nuv sync --all-packages --frozen --extra \"base\" --extra \"proxy_tongyi\" --extra \"rag\" --extra \"storage_chromadb\" --extra \"dbgpts\"\n```",
          "created_at": "2025-03-21T08:59:00Z"
        }
      ]
    },
    {
      "issue_number": 2474,
      "title": "[Feature][Module Name] 希望能集成MCP协议",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nRAG知识库查询结里最后最好能显示引用的附件名称，点击能打开查看，另外，系统能集成MCP协议调用外部资源就很强了\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "Scoop3o3",
      "author_type": "User",
      "created_at": "2025-03-17T00:49:14Z",
      "updated_at": "2025-03-21T08:07:22Z",
      "closed_at": "2025-03-21T08:07:21Z",
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2474/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2474",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2474",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:31.216865",
      "comments": [
        {
          "author": "fangyinc",
          "body": "This is already supported by #2497",
          "created_at": "2025-03-21T08:07:21Z"
        }
      ]
    },
    {
      "issue_number": 2495,
      "title": "[Bug] [Knowledge]  can't select all the knowledge bases items",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nLLM: proxy /QwQ 32B\n\n### What happened\n\nWhen creating an app, you can't select all the knowledge bases, and you can only see some of them, unless you restart the system\n\n### What you expected to happen\n\n view and select all the knowledge bases\n\n### How to reproduce\n\nI created two knowledge bases, but when I created the app, I couldn't select them all, and the second knowledge base couldn't be selected\n![Image](https://github.com/user-attachments/assets/005fdb78-2d52-48c2-8117-71b5b1862d68)\n\n![Image](https://github.com/user-attachments/assets/e8b82102-12f4-4926-a2a3-f6a87cffce16)\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "vnicers",
      "author_type": "User",
      "created_at": "2025-03-20T12:27:07Z",
      "updated_at": "2025-03-21T08:07:02Z",
      "closed_at": "2025-03-21T08:07:02Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2495/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2495",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2495",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:31.384066",
      "comments": [
        {
          "author": "vnicers",
          "body": "I debugged the code and found that it was put into the cache in the configuration, and when the knowledge base was added or deleted, although the data was fetched from the database resource_parameters_class each call, but the cache was not refreshed\n![Image](https://github.com/user-attachments/asset",
          "created_at": "2025-03-20T16:58:48Z"
        }
      ]
    },
    {
      "issue_number": 2496,
      "title": "[Feature][cache] 缓存的数据库结构支持包含字段的类型，和字段注释",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n现在的数据库结构缓存只包括所有表名称和含有的字段，只有支持包含字段的类型，和字段注释，才能在提供SQL的时候错误率降低。\n\n### Use case\n\n用户问题：查询用户表的年龄分布\n数据库上下文：\n- 表名: user\n- 字段: \n  id (INT, 主键)\n  name (VARCHAR(50), 用户姓名)\n  age (INT, 用户年龄)\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nHigh\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "2100663502",
      "author_type": "User",
      "created_at": "2025-03-21T02:53:06Z",
      "updated_at": "2025-03-21T02:53:06Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2496/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2496",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2496",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:31.559466",
      "comments": []
    },
    {
      "issue_number": 2425,
      "title": "[Bug] [Module Name] The embedding model configuration is not working",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice：CPU\n\n\n\n### Models information\n\nLLM：deepseek\nEmbedding model：text-embedding-v3\n\n### What happened\n\nI first added the remote embedding model text-embedding-v3 in the model management interface and successfully started it. Then, in the embedding model configuration interface of the knowledge base, I changed the model to text-embedding-v3. However, according to the backend logs, it is still calling the embedding model specified in the config file. \n\n\n### What you expected to happen\n\nThe expected result is that both vectorization processing and knowledge retrieval should use the embedding model configured in the interface.\n\n### How to reproduce\n\n1. Configure the embedding model as text2vec-large-chinese in the config file.\n2. Stop the text2vec-large-chinese model in the model management interface, then create a new remote text-embedding-v3 model.\n3. Create a new knowledge base and change the model in the embedding model configuration interface of the knowledge base to text-embedding-v3.\n4. Upload documents and start parsing. Upon observing the backend logs, it is found that the text2vec-large-chinese model is being called instead.\n\n![Image](https://github.com/user-attachments/assets/5190bd73-80de-4da4-8857-e31ddd10dc16)\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "bxfxf",
      "author_type": "User",
      "created_at": "2025-03-10T02:55:15Z",
      "updated_at": "2025-03-21T02:43:41Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2425/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2425",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2425",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:31.559485",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "```\n[[models.embeddings]]\nname = \"BAAI/bge-large-zh-v1.5\"\nprovider = \"hf\"\n# If not provided, the model will be downloaded from the Hugging Face model hub\n# uncomment the following line to specify the model path in the local file system\n# path = \"the-model-path-in-the-local-file-system\"\npath = \"/xxx/",
          "created_at": "2025-03-11T01:42:07Z"
        },
        {
          "author": "bxfxf",
          "body": "> ```\n> [[models.embeddings]]\n> name = \"BAAI/bge-large-zh-v1.5\"\n> provider = \"hf\"\n> # If not provided, the model will be downloaded from the Hugging Face model hub\n> # uncomment the following line to specify the model path in the local file system\n> # path = \"the-model-path-in-the-local-file-system\"",
          "created_at": "2025-03-11T09:28:56Z"
        },
        {
          "author": "dailyer",
          "body": "我使用docker compose ud -d 启动的最新版，也试过配置这个字段，没有效果",
          "created_at": "2025-03-21T02:43:39Z"
        }
      ]
    },
    {
      "issue_number": 2491,
      "title": "[Doc] 文档似乎没有跟着代码同步更新，现在文档有多处不能正常运行的地方",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n包括 UV 运行安装依赖等，全量安装时最后一行还有 \\ ，请帮忙同步更新和验证一遍语雀中使用到的命令是否正确，确保跟随命令能够完成基础的 demo 运行\n\n### Documentation Links\n\nhttps://www.yuque.com/eosphoros/dbgpt-docs/urh3fcx8tu0s9xmb\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "jamesliang1226",
      "author_type": "User",
      "created_at": "2025-03-20T02:47:01Z",
      "updated_at": "2025-03-20T02:47:01Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2491/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2491",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2491",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:31.750438",
      "comments": []
    },
    {
      "issue_number": 2135,
      "title": "where to get more about AWEL related document",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nAfter reading the AWEL related documents, I don't know how to create an AWEL workflow through web。could privode some scene to explain how to use\n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "zengweitju",
      "author_type": "User",
      "created_at": "2024-11-19T02:34:33Z",
      "updated_at": "2025-03-19T21:05:10Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2135/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2135",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2135",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:33.595787",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "Chinese awel agent tutorial: https://www.yuque.com/eosphoros/dbgpt-docs/ce6xrtx9xal0zm8m",
          "created_at": "2024-11-19T02:37:18Z"
        },
        {
          "author": "zengweitju",
          "body": "> Chinese awel agent tutorial: https://www.yuque.com/eosphoros/dbgpt-docs/ce6xrtx9xal0zm8m\r\n\r\nI am not a smart person. This document is not friendly to me. Many things are not explained clearly. I followed the document and got an error when saving.\r\n",
          "created_at": "2024-11-19T03:08:06Z"
        },
        {
          "author": "Aries-ckt",
          "body": "can you post your error log info?",
          "created_at": "2024-11-19T04:50:32Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-03-19T21:05:09Z"
        }
      ]
    },
    {
      "issue_number": 2476,
      "title": "[Bug] [MSSQL] Unable to connect to MSSQL SERVER 2012 and earlier versions.",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nQwen/Qwen2.5-Coder-32B-Instruct\nBAAI/bge-large-zh-v1.5\nBAAI/bge-reranker-v2-m3\n\n### What happened\n\nIF the SQLSERVER version is 2012 or even earlier,it will occur like this:\n连接失败: (20002, b'DB-Lib error message 20002, severity 9:\\nAdaptive Server connection failed (172.16.12.74)\\nDB-Lib error message 20002, severity 9:\\nAdaptive Server connection failed (172.16.12.74)\\n')\n\nThe total info:\n2025-03-17 14:42:46 PC-Asus-Su dbgpt_serve.datasource.manages.connector_manager[17187] ERROR Test connection Failure!(pymssql.exceptions.OperationalError) (20002, b'DB-Lib error message 20002, severity 9:\\nAdaptive Server connection failed (106.14.37.235)\\nDB-Lib error message 20002, severity 9:\\nAdaptive Server connection failed (106.14.37.235)\\n')\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\n2025-03-17 14:42:46 PC-Asus-Su dbgpt_serve.core.schemas[17187] ERROR common_exception_handler catch Exception: success=False err_code='E0003' err_msg=\"Test connection Failure!(pymssql.exceptions.OperationalError) (20002, b'DB-Lib error message 20002, severity 9:\\\\nAdaptive Server connection failed (106.14.37.235)\\\\nDB-Lib error message 20002, severity 9:\\\\nAdaptive Server connection failed (106.14.37.235)\\\\n')\\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\" data=None\nINFO:     127.0.0.1:53034 - \"POST /api/v2/serve/datasources/test-connection HTTP/1.1\" 400 Bad Request\nERROR:    Exception in ASGI application\n  + Exception Group Traceback (most recent call last):\n  |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_utils.py\", line 77, in collapse_excgroups\n  |     yield\n  |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 186, in __call__\n  |     async with anyio.create_task_group() as task_group:\n  |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 767, in __aexit__\n  |     raise BaseExceptionGroup(\n  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 409, in run_asgi\n    |     result = await app(  # type: ignore[func-returns-value]\n    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n    |     return await self.app(scope, receive, send)\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    |     await self.simple_response(scope, receive, send, request_headers=headers)\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    |     await self.app(scope, receive, send)\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/fastapi/applications.py\", line 1054, in __call__\n    |     await super().__call__(scope, receive, send)\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/applications.py\", line 113, in __call__\n    |     await self.middleware_stack(scope, receive, send)\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 187, in __call__\n    |     raise exc\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    |     await self.app(scope, receive, _send)\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 185, in __call__\n    |     with collapse_excgroups():\n    |   File \"/home/suc/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/contextlib.py\", line 158, in __exit__\n    |     self.gen.throw(typ, value, traceback)\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_utils.py\", line 83, in collapse_excgroups\n    |     raise exc\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 187, in __call__\n    |     response = await self.dispatch_func(request, call_next)\n    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/suc/DB-GPT/packages/dbgpt-core/src/dbgpt/util/tracer/tracer_middleware.py\", line 49, in dispatch\n    |     response = await call_next(request)\n    |                ^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 163, in call_next\n    |     raise app_exc\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 149, in coro\n    |     await self.app(scope, receive_or_disconnect, send_no_error)\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n    |     raise exc\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 715, in __call__\n    |     await self.middleware_stack(scope, receive, send)\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 735, in app\n    |     await route.handle(scope, receive, send)\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 288, in handle\n    |     await self.app(scope, receive, send)\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 76, in app\n    |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n    |     raise exc\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 73, in app\n    |     response = await f(request)\n    |                ^^^^^^^^^^^^^^^^\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 301, in app\n    |     raw_response = await run_endpoint_function(\n    |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    |     return await dependant.call(**values)\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/suc/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/api/endpoints.py\", line 233, in test_connection\n    |     res = await blocking_func_to_async(\n    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/suc/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/core/__init__.py\", line 32, in blocking_func_to_async\n    |     return await _blocking_func_to_async(executor, func, *args, **kwargs)\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/suc/DB-GPT/packages/dbgpt-core/src/dbgpt/util/executor_utils.py\", line 70, in blocking_func_to_async\n    |     return await loop.run_in_executor(executor, run_with_context)\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/suc/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n    |     result = self.fn(*self.args, **self.kwargs)\n    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/suc/DB-GPT/packages/dbgpt-core/src/dbgpt/util/executor_utils.py\", line 67, in run_with_context\n    |     return ctx.run(partial(func, *args, **kwargs))\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/suc/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/service.py\", line 290, in test_connection\n    |     return self.datasource_manager.test_connection(request)\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/suc/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/manages/connector_manager.py\", line 273, in test_connection\n    |     raise ValueError(f\"Test connection Failure!{str(e)}\")\n    | ValueError: Test connection Failure!(pymssql.exceptions.OperationalError) (20002, b'DB-Lib error message 20002, severity 9:\\nAdaptive Server connection failed (106.14.37.235)\\nDB-Lib error message 20002, severity 9:\\nAdaptive Server connection failed (106.14.37.235)\\n')\n    | (Background on this error at: https://sqlalche.me/e/20/e3q8)\n    +------------------------------------\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 409, in run_asgi\n    result = await app(  # type: ignore[func-returns-value]\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n    return await self.app(scope, receive, send)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    await self.simple_response(scope, receive, send, request_headers=headers)\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    await self.app(scope, receive, send)\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/fastapi/applications.py\", line 1054, in __call__\n    await super().__call__(scope, receive, send)\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/applications.py\", line 113, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 187, in __call__\n    raise exc\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    await self.app(scope, receive, _send)\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 185, in __call__\n    with collapse_excgroups():\n  File \"/home/suc/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/contextlib.py\", line 158, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_utils.py\", line 83, in collapse_excgroups\n    raise exc\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 187, in __call__\n    response = await self.dispatch_func(request, call_next)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/suc/DB-GPT/packages/dbgpt-core/src/dbgpt/util/tracer/tracer_middleware.py\", line 49, in dispatch\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 163, in call_next\n    raise app_exc\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 149, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n    raise exc\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 715, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 735, in app\n    await route.handle(scope, receive, send)\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n    raise exc\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 73, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 301, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    return await dependant.call(**values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/suc/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/api/endpoints.py\", line 233, in test_connection\n    res = await blocking_func_to_async(\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/suc/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/core/__init__.py\", line 32, in blocking_func_to_async\n    return await _blocking_func_to_async(executor, func, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/suc/DB-GPT/packages/dbgpt-core/src/dbgpt/util/executor_utils.py\", line 70, in blocking_func_to_async\n    return await loop.run_in_executor(executor, run_with_context)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/suc/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/suc/DB-GPT/packages/dbgpt-core/src/dbgpt/util/executor_utils.py\", line 67, in run_with_context\n    return ctx.run(partial(func, *args, **kwargs))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/suc/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/service.py\", line 290, in test_connection\n    return self.datasource_manager.test_connection(request)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/suc/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/manages/connector_manager.py\", line 273, in test_connection\n    raise ValueError(f\"Test connection Failure!{str(e)}\")\nValueError: Test connection Failure!(pymssql.exceptions.OperationalError) (20002, b'DB-Lib error message 20002, severity 9:\\nAdaptive Server connection failed (106.14.37.235)\\nDB-Lib error message 20002, severity 9:\\nAdaptive Server connection failed (106.14.37.235)\\n')\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\n2025-03-17 14:42:46 PC-Asus-Su dbgpt.datasource.rdbms.base[17187] INFO Closing RDBMS connector resources...\nException ignored in: <function BaseConnector.__del__ at 0x7f0e4e57ad40>\nTraceback (most recent call last):\n  File \"/home/suc/DB-GPT/packages/dbgpt-core/src/dbgpt/datasource/base.py\", line 274, in __del__\n    self.close()\n  File \"/home/suc/DB-GPT/packages/dbgpt-core/src/dbgpt/datasource/rdbms/base.py\", line 882, in close\n    for session in self._sessions:\n                   ^^^^^^^^^^^^^^\nAttributeError: 'MSSQLConnector' object has no attribute '_sessions'\n2025-03-17 15:20:57 PC-Asus-Su dbgpt_serve.datasource.manages.connector_manager[17187] ERROR Test connection Failure!(pymssql.exceptions.OperationalError) (20002, b'DB-Lib error message 20002, severity 9:\\nAdaptive Server connection failed (172.16.12.74)\\nDB-Lib error message 20002, severity 9:\\nAdaptive Server connection failed (172.16.12.74)\\n')\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\n2025-03-17 15:20:57 PC-Asus-Su dbgpt_serve.core.schemas[17187] ERROR common_exception_handler catch Exception: success=False err_code='E0003' err_msg=\"Test connection Failure!(pymssql.exceptions.OperationalError) (20002, b'DB-Lib error message 20002, severity 9:\\\\nAdaptive Server connection failed (172.16.12.74)\\\\nDB-Lib error message 20002, severity 9:\\\\nAdaptive Server connection failed (172.16.12.74)\\\\n')\\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\" data=None\nINFO:     127.0.0.1:60096 - \"POST /api/v2/serve/datasources/test-connection HTTP/1.1\" 400 Bad Request\nERROR:    Exception in ASGI application\n  + Exception Group Traceback (most recent call last):\n  |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_utils.py\", line 77, in collapse_excgroups\n  |     yield\n  |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 186, in __call__\n  |     async with anyio.create_task_group() as task_group:\n  |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 767, in __aexit__\n  |     raise BaseExceptionGroup(\n  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 409, in run_asgi\n    |     result = await app(  # type: ignore[func-returns-value]\n    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n    |     return await self.app(scope, receive, send)\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    |     await self.simple_response(scope, receive, send, request_headers=headers)\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    |     await self.app(scope, receive, send)\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/fastapi/applications.py\", line 1054, in __call__\n    |     await super().__call__(scope, receive, send)\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/applications.py\", line 113, in __call__\n    |     await self.middleware_stack(scope, receive, send)\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 187, in __call__\n    |     raise exc\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    |     await self.app(scope, receive, _send)\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 185, in __call__\n    |     with collapse_excgroups():\n    |   File \"/home/suc/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/contextlib.py\", line 158, in __exit__\n    |     self.gen.throw(typ, value, traceback)\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_utils.py\", line 83, in collapse_excgroups\n    |     raise exc\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 187, in __call__\n    |     response = await self.dispatch_func(request, call_next)\n    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/suc/DB-GPT/packages/dbgpt-core/src/dbgpt/util/tracer/tracer_middleware.py\", line 49, in dispatch\n    |     response = await call_next(request)\n    |                ^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 163, in call_next\n    |     raise app_exc\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 149, in coro\n    |     await self.app(scope, receive_or_disconnect, send_no_error)\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n    |     raise exc\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 715, in __call__\n    |     await self.middleware_stack(scope, receive, send)\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 735, in app\n    |     await route.handle(scope, receive, send)\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 288, in handle\n    |     await self.app(scope, receive, send)\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 76, in app\n    |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n    |     raise exc\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 73, in app\n    |     response = await f(request)\n    |                ^^^^^^^^^^^^^^^^\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 301, in app\n    |     raw_response = await run_endpoint_function(\n    |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    |     return await dependant.call(**values)\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/suc/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/api/endpoints.py\", line 233, in test_connection\n    |     res = await blocking_func_to_async(\n    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/suc/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/core/__init__.py\", line 32, in blocking_func_to_async\n    |     return await _blocking_func_to_async(executor, func, *args, **kwargs)\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/suc/DB-GPT/packages/dbgpt-core/src/dbgpt/util/executor_utils.py\", line 70, in blocking_func_to_async\n    |     return await loop.run_in_executor(executor, run_with_context)\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/suc/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n    |     result = self.fn(*self.args, **self.kwargs)\n    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/suc/DB-GPT/packages/dbgpt-core/src/dbgpt/util/executor_utils.py\", line 67, in run_with_context\n    |     return ctx.run(partial(func, *args, **kwargs))\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/suc/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/service.py\", line 290, in test_connection\n    |     bool: The test result\n    |        ^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/suc/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/manages/connector_manager.py\", line 273, in test_connection\n    |     raise ValueError(f\"Test connection Failure!{str(e)}\")\n    | ValueError: Test connection Failure!(pymssql.exceptions.OperationalError) (20002, b'DB-Lib error message 20002, severity 9:\\nAdaptive Server connection failed (172.16.12.74)\\nDB-Lib error message 20002, severity 9:\\nAdaptive Server connection failed (172.16.12.74)\\n')\n    | (Background on this error at: https://sqlalche.me/e/20/e3q8)\n    +------------------------------------\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 409, in run_asgi\n    result = await app(  # type: ignore[func-returns-value]\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n    return await self.app(scope, receive, send)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    await self.simple_response(scope, receive, send, request_headers=headers)\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    await self.app(scope, receive, send)\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/fastapi/applications.py\", line 1054, in __call__\n    await super().__call__(scope, receive, send)\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/applications.py\", line 113, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 187, in __call__\n    raise exc\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    await self.app(scope, receive, _send)\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 185, in __call__\n    with collapse_excgroups():\n  File \"/home/suc/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/contextlib.py\", line 158, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_utils.py\", line 83, in collapse_excgroups\n    raise exc\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 187, in __call__\n    response = await self.dispatch_func(request, call_next)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/suc/DB-GPT/packages/dbgpt-core/src/dbgpt/util/tracer/tracer_middleware.py\", line 49, in dispatch\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 163, in call_next\n    raise app_exc\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 149, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n    raise exc\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 715, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 735, in app\n    await route.handle(scope, receive, send)\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n    raise exc\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 73, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 301, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/suc/DB-GPT/.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    return await dependant.call(**values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/suc/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/api/endpoints.py\", line 233, in test_connection\n    res = await blocking_func_to_async(\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/suc/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/core/__init__.py\", line 32, in blocking_func_to_async\n    return await _blocking_func_to_async(executor, func, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/suc/DB-GPT/packages/dbgpt-core/src/dbgpt/util/executor_utils.py\", line 70, in blocking_func_to_async\n    return await loop.run_in_executor(executor, run_with_context)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/suc/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/suc/DB-GPT/packages/dbgpt-core/src/dbgpt/util/executor_utils.py\", line 67, in run_with_context\n    return ctx.run(partial(func, *args, **kwargs))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/suc/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/service.py\", line 290, in test_connection\n    bool: The test result\n       ^^^^^^^^^^^^^^^^^^^\n  File \"/home/suc/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/manages/connector_manager.py\", line 273, in test_connection\n    raise ValueError(f\"Test connection Failure!{str(e)}\")\nValueError: Test connection Failure!(pymssql.exceptions.OperationalError) (20002, b'DB-Lib error message 20002, severity 9:\\nAdaptive Server connection failed (172.16.12.74)\\nDB-Lib error message 20002, severity 9:\\nAdaptive Server connection failed (172.16.12.74)\\n')\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\n2025-03-17 15:21:00 PC-Asus-Su dbgpt.datasource.rdbms.base[17187] INFO Closing RDBMS connector resources...\nException ignored in: <function BaseConnector.__del__ at 0x7f0e4e57ad40>\nTraceback (most recent call last):\n  File \"/home/suc/DB-GPT/packages/dbgpt-core/src/dbgpt/datasource/base.py\", line 274, in __del__\n    self.close()\n  File \"/home/suc/DB-GPT/packages/dbgpt-core/src/dbgpt/datasource/rdbms/base.py\", line 882, in close\n    for session in self._sessions:\n                   ^^^^^^^^^^^^^^\nAttributeError: 'MSSQLConnector' object has no attribute '_sessions'\n\n\n### What you expected to happen\n\nconnect successfully.\nI have figure out the reason,due to the TDS_version,but don't  know how to fix this problem.\n\n![Image](https://github.com/user-attachments/assets/a6801981-7654-4087-8b12-2f41ce01057d)\nadd the tds_version = \"7.0\"\nfor more details at this blog https://zhuanlan.zhihu.com/p/5170716996\n\n### How to reproduce\n\nJust install a 2012 or earlier vesion and connect.\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "su1234121",
      "author_type": "User",
      "created_at": "2025-03-17T07:49:16Z",
      "updated_at": "2025-03-19T08:09:15Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2476/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2476",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2476",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:33.809008",
      "comments": [
        {
          "author": "su1234121",
          "body": "if the version is 2012 2008r2 2008 even earlier, add tds_version = \"7.0\" can solve this problem.",
          "created_at": "2025-03-17T07:51:03Z"
        },
        {
          "author": "donywud",
          "body": "> if the version is 2012 2008r2 2008 even earlier, add tds_version = \"7.0\" can solve this problem.\n\n是的，正解",
          "created_at": "2025-03-19T08:09:14Z"
        }
      ]
    },
    {
      "issue_number": 2487,
      "title": "[Bug] [Datasource] When MySQL is used as a data source, is changing the database name not allowed?",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [x] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [x] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nThat's not the issue here.\n\n### Models information\n\nThat's not the issue here.\n\n### What happened\n\nWhen I am doing,Database Management->Select MySQL->Modify DataBase Name, I get “there is no datasource name:test exists”.    \n\n### What you expected to happen\n\nIf the user is not allowed to modify the Database Name, the input box should be disabled.\n\n### How to reproduce\n\n1. Go to App Manage\n2. Click on Databse\n3. Select MySQL\n4. Click on edit\n5. Modify Database Name\n6. Get error \"there is no datasource name:test exists\"\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "geebytes",
      "author_type": "User",
      "created_at": "2025-03-19T06:43:45Z",
      "updated_at": "2025-03-19T06:43:45Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2487/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2487",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2487",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:33.997721",
      "comments": []
    },
    {
      "issue_number": 2483,
      "title": "[Feature] [core]用户管理系统和模型统计",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n系统貌似没有用户体系和模型统计体系，望早日提上日程\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "jx001-chen",
      "author_type": "User",
      "created_at": "2025-03-18T09:22:03Z",
      "updated_at": "2025-03-19T06:07:46Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2483/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2483",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2483",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:33.997743",
      "comments": [
        {
          "author": "hklb2025",
          "body": "支持，权限和用户管理还挺重要的，希望可以早日完善",
          "created_at": "2025-03-19T06:07:45Z"
        }
      ]
    },
    {
      "issue_number": 2484,
      "title": "[Bug] [Knowledge] The latest version of the code Chinese knowledge base name cannot be synchronized",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\n[models]\n[[models.llms]]\nname = \"Qwen/QwQ-32B\"\nprovider = \"proxy/siliconflow\"\n\n\n\n[[models.embeddings]]\nname = \"BAAI/bge-large-zh-v1.5\"\n\n\n[[models.rerankers]]\ntype = \"reranker\"\nname = \"BAAI/bge-reranker-v2-m3\"\n\n\n### What happened\n\nToday I pulled the latest code, If it is a knowledge base named in Chinese, it cannot be created and deleted\n\n![Image](https://github.com/user-attachments/assets/9e61b8cc-3956-443b-bacd-5439702d8261)\n\n### What you expected to happen\n\nThe name of the knowledge base of the current version of the code needs to be verified on the front-end and back-end\n\n1. Meet the Tugraph graph name rule of 1-20 characters and cannot start with a number\n2, Meet the Chroma Collection  name rules\n        \"(1) contains 3-63 characters, \"\n        \"(2) starts and ends with an alphanumeric character, \"\n        \"(3) otherwise contains only alphanumeric characters, underscores or hyphens (-), \"\n        \"(4) contains no two consecutive periods (..) and \"\n        \"(5) is not a valid IPv4 address, \"\n\n### How to reproduce\n\nCreate a new knowledge base named in Chinese, synchronize or delete it\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "vnicers",
      "author_type": "User",
      "created_at": "2025-03-18T09:35:08Z",
      "updated_at": "2025-03-19T05:42:36Z",
      "closed_at": "2025-03-19T05:42:36Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2484/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2484",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2484",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:34.189092",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "i will try to reproduce it.",
          "created_at": "2025-03-18T09:40:50Z"
        }
      ]
    },
    {
      "issue_number": 2118,
      "title": "[Bug] [agent] AWEL \"Knowledge Operator\" Enable Reordering Feature Exception",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice: GPU ;  Count: 1 - GPU Memory: 15G\n\n### Models information\n\nLLM: Qwen2-72b; Embedding model: bge-large-zh-v1.5; Rerank model: bge-reranker-large\n\n### What happened\n\nWhen I applied the knowledge operator(\"知识算子\") to set the rerank feature enabled, after saving the workflow, I returned to the workflow and found that the feature had reverted back to the default disabled state\n\n### What you expected to happen\n\n1. After repeatedly saving the test, verify that the related function indeed has an abnormality\r\n![企业微信截图_17309614672886](https://github.com/user-attachments/assets/8b7693e1-918e-4b42-b1b4-c0052be71f77)\r\n![Snipaste_2024-11-07_14-38-19](https://github.com/user-attachments/assets/0f06010a-8013-442a-8c98-c8b50d6377a1)\r\n\n\n### How to reproduce\n\n1. Go to AWEL\r\n2. Click on '知识算子'\r\n3. save with the rerank feature opened\r\n4. refresh and see the rerank feature error\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "dj-jack001",
      "author_type": "User",
      "created_at": "2024-11-07T06:42:27Z",
      "updated_at": "2025-03-18T21:05:09Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2118/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2118",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2118",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:34.390035",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "Sorry about that, can you show some error log?",
          "created_at": "2024-11-10T14:44:38Z"
        },
        {
          "author": "dj-jack001",
          "body": "> Sorry about that, can you show some error log?抱歉，你能展示一些错误日志吗？\r\n\r\nThis has no error log because it is not an error, but rather, after clicking the save button on the AWEL interface, the settings for rerank enabled are not saved normally",
          "created_at": "2024-11-12T01:08:34Z"
        },
        {
          "author": "Aries-ckt",
          "body": "can you show your all operator workflow,  I'll see if I can reproduce it.",
          "created_at": "2024-11-12T01:46:56Z"
        },
        {
          "author": "dj-jack001",
          "body": "> can you show your all operator workflow, I'll see if I can reproduce it.你能展示你的所有操作流程吗？我会看看是否能重现它。\r\n\r\nI use the official knowledge base example workflow",
          "created_at": "2024-11-18T06:52:50Z"
        },
        {
          "author": "dj-jack001",
          "body": "> can you show your all operator workflow, I'll see if I can reproduce it.你能展示你的所有操作流程吗？我会看看是否能重现它。\r\n\r\n![image](https://github.com/user-attachments/assets/24a494be-f5d9-40d4-88c3-f3c5de400420)\r\n",
          "created_at": "2024-11-18T06:53:54Z"
        }
      ]
    },
    {
      "issue_number": 2132,
      "title": "[Feature][Module Name] Multi-agent resource configuration",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n![image](https://github.com/user-attachments/assets/a5657114-5d54-4a04-9e82-a45b449de9d9)\r\n在多智能体自动规划模式下，目前采用的是将所有资源统一配置？这可能不是友好的方案，某些资源应当根据其特性，专门适配到特定的智能体，以实现更高效和精准的资源利用，即规划配置规划的资源、智能体配置智能体的资源\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "yuerf",
      "author_type": "User",
      "created_at": "2024-11-18T03:29:31Z",
      "updated_at": "2025-03-18T21:05:06Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2132/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2132",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2132",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:34.583785",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-03-18T21:05:05Z"
        }
      ]
    },
    {
      "issue_number": 2133,
      "title": "[Bug] [Module Name] AWEL  Resource Allocation",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n-\n\n### Models information\n\n-\n\n### What happened\n\n![image](https://github.com/user-attachments/assets/c37f3b55-e906-4074-973a-0a07a294e2ad)\r\n使用AWEL编排，配置了5个资源，其中一个database，四个knowledge，结果只配置成功了database，知识库内容没显示，目前仅支持配置一个资源？\n\n### What you expected to happen\n\n-\n\n### How to reproduce\n\n-\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "yuerf",
      "author_type": "User",
      "created_at": "2024-11-18T09:03:21Z",
      "updated_at": "2025-03-18T21:05:05Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2133/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2133",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2133",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:34.782647",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "sorry about that, now awel resource support only one resource. we will support multi resources soon.",
          "created_at": "2024-11-18T15:41:25Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-03-18T21:05:04Z"
        }
      ]
    },
    {
      "issue_number": 2451,
      "title": "[Bug] [Module Name] Bug title 向量数据库中的表查询报错时会返回全量数据库的表和字段，消耗大量token",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [x] Chat Data\n- [ ] Chat Excel\n- [x] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU 24*4\n\n### Models information\n\nLLM: qwen-max\n\n\n### What happened\n\n![Image](https://github.com/user-attachments/assets/6be6a446-d5a6-41e7-8ebb-b664a6bfc626)\n\n### What you expected to happen\n\n当遇到“db summary find error” 这个报错时，不应该返回全量的表和字段，会影响查询准确性，并且消耗大量token\n\n### How to reproduce\n\n1、使用checkData，问一些问题时，某些问题会触发此类现象\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "maoyongjun2025",
      "author_type": "User",
      "created_at": "2025-03-13T00:51:54Z",
      "updated_at": "2025-03-17T08:55:02Z",
      "closed_at": "2025-03-17T08:55:02Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2451/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2451",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2451",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:35.020036",
      "comments": []
    },
    {
      "issue_number": 2416,
      "title": "[Feature] [graphrag] s3 support",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n简单看了下项目，发现知识库对话的文件是存放在指定目录下的。如果文件特别多的话，似乎这样子处理不太好呀，有没有考虑接入s3 对象存储产品之类的。或者有什么方式处理这些文件嘛。\nLooking at the implementation, I see knowledge base conversations are stored as local files. This directory-based approach could become problematic at scale. Have you considered using object storage like Amazon S3/MinIO, or are there other file management strategies you're planning to adopt?\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "WhistleO",
      "author_type": "User",
      "created_at": "2025-03-07T18:35:21Z",
      "updated_at": "2025-03-17T08:55:02Z",
      "closed_at": "2025-03-17T08:55:02Z",
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2416/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2416",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2416",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:35.020056",
      "comments": [
        {
          "author": "fangyinc",
          "body": "@WhistleO \nYeah, DB-GPT has designed a set of abstract file operation interfaces and implemented storage for local file systems as well as a simple distributed file storage based on database metadata management. Essentially, it can also be easily integrated with third-party storage solutions like S3",
          "created_at": "2025-03-08T01:11:45Z"
        }
      ]
    },
    {
      "issue_number": 2475,
      "title": "[Bug] [ChatDB] MySQL表字段太多，日志显示表被截断",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [x] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [x] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU\nRTX 3090 \n2张卡，单卡24G\n\n### Models information\n\nLLM:ollama_proxy\n\n### What happened\n\n当我通过dbgpt连接到我本地的MySQL数据库后，进行ChatDB测试，发现查询结果质量很差，观察后台日志发现，出现了表被截断的显示，图例如下：\n\n![Image](https://github.com/user-attachments/assets/1c928bf6-89d0-467a-8324-7b4f2cb33b8e)\n\n### What you expected to happen\n\ndbgpt的预处理中能展示完整的数据库表结构给到大模型，而不是被截断的数据，这样会导致大模型回答质量非常差。请告诉我这是否是bug，如果是可以通过参数调整的，请告诉我调整的配置文件目录和名称以及配置值。\n\n### How to reproduce\n\n1.部署最新的dbgpt，连接好ollama代理；\n2.连接本地数据库（包含一些超过20个字段的表）\n3.进行chatDB问答\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "531128151",
      "author_type": "User",
      "created_at": "2025-03-17T02:33:18Z",
      "updated_at": "2025-03-17T08:55:01Z",
      "closed_at": "2025-03-17T08:55:01Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2475/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2475",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2475",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:35.202908",
      "comments": []
    },
    {
      "issue_number": 2468,
      "title": "[Bug] [dbgpt-ext] 配置向量库和向量模型后无法准确查询表结构信息",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [x] Chat Data\n- [ ] Chat Excel\n- [x] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice: CPU\n\n### Models information\n\nLLM: deepseek-r1-distill-qwen\nembeddings: bce-embedding-base_v1\nrag.storage.vector: Milvus\n\n### What happened\n\n配置向量数据库，通过Chat DB 查询表信息无法查询准确的字段信息。debug发现db_schema.py、milvus_store.py文件有几处问题可能导致无法获取到字段信息。\n\n![Image](https://github.com/user-attachments/assets/fa977794-4dd9-4890-84ee-e8a0bb53e510)\n\nChunk对象通过metadata属性是无法获取到separated字段的，需要通过chunk.metadata['props_fields'].get('separated')才能获取到。\n涉及到函数包括：_similarity_search、_deserialize_table_chunk、_retrieve_field \n\n![Image](https://github.com/user-attachments/assets/06ea1162-5cfb-456e-bcc3-5411f11cbcd5)\n\n![Image](https://github.com/user-attachments/assets/96547087-b104-4c25-8e07-bf106a419033)\n\n![Image](https://github.com/user-attachments/assets/eee3ad17-1fe1-47c0-b064-3a2dc0549b71)\n\n### What you expected to happen\n\ndb_schema.py 文件，涉及3处函数：\n\n\n```\n    def _similarity_search(\n        self, query, filters: Optional[MetadataFilters] = None\n    ) -> List[Chunk]:\n        \"\"\"Similar search.\"\"\"\n        table_chunks = self._table_vector_store_connector.similar_search_with_scores(\n            query, self._top_k, 0, filters\n        )\n\n        # Find all table chunks which are not separated\n        not_sep_chunks = [\n            chunk for chunk in table_chunks if not chunk.metadata.get(\"separated\")\n        ]\n        separated_chunks = [\n            chunk for chunk in table_chunks if chunk.metadata.get(\"separated\")\n        ]\n        if not separated_chunks:\n            return [self._deserialize_table_chunk(chunk) for chunk in not_sep_chunks]\n\n        # Create tasks list\n        # The fields of table is too large, and it has to be separated into chunks,\n        # so we need to retrieve fields of each table separately\n        tasks = [\n            lambda c=chunk: self._retrieve_field(c, query) for chunk in separated_chunks\n        ]\n        # Run tasks concurrently\n        separated_result = run_tasks(tasks, concurrency_limit=3)\n\n        # Combine and return results\n        return not_sep_chunks + separated_result\n```\n\n_similarity_search：函数判断向量数据库中存储元数据信息是否分片 通过separated 判断，0否，1是，如果是1需要查询存放字段信息的向量库的中字段collection。但是通过debug发现，chunk.metadata 中没有separated 属性，只有在chunk.metadata['props_field'].get('separated ') 才能获取到。\n\n ```\ndef _deserialize_table_chunk(self, chunk: Chunk) -> Chunk:\n        \"\"\"Deserialize table chunk.\"\"\"\n        db_summary_version = chunk.metadata.get(\"db_summary_version\")\n        if not db_summary_version:\n            return chunk\n        parts = chunk.content.split(self._separator)\n        table_part, field_part = parts[0].strip(), parts[1].strip()\n        table_detail = _parse_table_detail(table_part)\n        table_name = table_detail.get(\"table_name\")\n        table_comment = table_detail.get(\"table_comment\")\n        index_keys = table_detail.get(\"index_keys\")\n\n        table_name = table_name.strip() if table_name else table_name\n        table_comment = table_comment.strip() if table_comment else table_comment\n        index_keys = index_keys.strip() if index_keys else index_keys\n        if not table_name:\n            return chunk\n\n        create_statement = f\"CREATE TABLE `{table_name}`\\r\\n(\\r\\n    \"\n        create_statement += field_part\n        create_statement += \"\\r\\n)\"\n        if table_comment:\n            create_statement += f' COMMENT \"{table_comment}\"\\r\\n'\n        if index_keys:\n            create_statement += f\"Index keys: {index_keys}\"\n\n        chunk.content = create_statement\n        return chunk\n```\n\n_deserialize_table_chunk 中：db_summary_version = chunk.metadata.get(\"db_summary_version\") 获取db_summary_version 属性也是同样的问题，也是再 chunk.metadata['props_field'] 词典中。\n\n\n```\n    def _retrieve_field(self, table_chunk: Chunk, query) -> Chunk:\n        metadata = table_chunk.metadata\n        metadata[\"part\"] = \"field\"\n        filters = [MetadataFilter(key=k, value=v) for k, v in metadata.items()]\n        field_chunks = self._field_vector_store_connector.similar_search_with_scores(\n            query, self._top_k, 0, MetadataFilters(filters=filters)\n        )\n        field_contents = [chunk.content.strip() for chunk in field_chunks]\n        table_chunk.content += (\n            \"\\n\" + self._separator + \"\\n\" + self._column_separator.join(field_contents)\n        )\n        return self._deserialize_table_chunk(table_chunk)\n```\n_retrieve_field函数中：  filters = [MetadataFilter(key=k, value=v) for k, v in metadata.items()] 获取过滤条件，应该从metadata['props_field'] 词典中获取过滤属性，否则会报错。\n\n\nmilvus_store.py 文件中：\n\n  ```\n     def convert_metadata_filters(self, filters: MetadataFilters) -> str:\n        \"\"\"Convert filter to milvus filters.\n\n        Args:\n            - filters: metadata filters.\n        Returns:\n            - metadata_filters: metadata filters.\n        \"\"\"\n        metadata_filters = []\n        for metadata_filter in filters.filters:\n            if isinstance(metadata_filter.value, str):\n                expr = (\n                    f\"{self.props_field}['{metadata_filter.key}'] \"\n                    f\"{FilterOperator.EQ} '{metadata_filter.value}'\"\n                )\n                metadata_filters.append(expr)\n            elif isinstance(metadata_filter, List):\n                expr = (\n                    f\"{self.props_field}['{metadata_filter.key}'] \"\n                    f\"{FilterOperator.IN.value} {metadata_filter.value}\"\n                )\n                metadata_filters.append(expr)\n            else:\n                expr = (\n                    f\"{self.props_field}['{metadata_filter.key}'] \"\n                    f\"{FilterOperator.EQ} {str(metadata_filter.value)}\"\n                )\n                metadata_filters.append(expr)\n        if len(metadata_filters) > 1:\n            metadata_filter_expr = f\" {filters.condition} \".join(metadata_filters)\n        else:\n            metadata_filter_expr = metadata_filters[0]\n        return metadata_filter_expr\n```\n\nconvert_metadata_filters 函数中  f\"{FilterOperator.EQ} 获取操作符时，没有获取到枚举的值，经debug发现生成的过滤条件是 part FilterOperator.EQ 'field' 这种，最终导致报错。\n\n\n经把以上代码问题修复后，经测试可以查询出完整的表结构信息。\n\n### How to reproduce\n\n配置了向量数据库且配置了向量模型，再chat_db  chat_data中问某张表的表结构或字段信息时 都会出现这种问题。\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "380828801",
      "author_type": "User",
      "created_at": "2025-03-14T08:57:48Z",
      "updated_at": "2025-03-17T08:55:01Z",
      "closed_at": "2025-03-17T08:55:01Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2468/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2468",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2468",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:35.202930",
      "comments": [
        {
          "author": "AlexanderGPY",
          "body": "同问题加一，只是我没找到原因，感谢大佬解惑。",
          "created_at": "2025-03-14T09:13:43Z"
        },
        {
          "author": "Aries-ckt",
          "body": "what's your milvus version, i will reproduce what happened",
          "created_at": "2025-03-14T13:52:51Z"
        },
        {
          "author": "380828801",
          "body": "> what's your milvus version, i will reproduce what happened\n\nv2.5.2\n",
          "created_at": "2025-03-17T01:39:39Z"
        }
      ]
    },
    {
      "issue_number": 2458,
      "title": "[Bug] [Chat Knowledge] document/sync api error 'NoneType' object is not subscriptable",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nMacOS(M1, M2...)\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice： CPU\n\n### Models information\n\nembeddings model: text-embedding-v3 （通义）\n\n### What happened\n\n上下文为：\n- UI操作同步单个文件  /knowledge/TEST/document/sync\n\n日志：\nINFO:     127.0.0.1:52443 - \"POST /knowledge/TEST/document/sync HTTP/1.1\" 200 OK\n2025-03-13 17:26:21 .local dbgpt.storage.base[62266] INFO Loading 6 chunks in 1 groups with 1 threads.\n2025-03-13 17:27:31 .local dbgpt.model.cluster.worker.embedding_worker[62266] INFO Receive embeddings request, model: text-embedding-v3\n2025-03-13 17:28:29 .local dbgpt.model.cluster.worker.embedding_worker[62266] INFO Receive embeddings request, model: text-embedding-v3\n2025-03-13 17:28:57 .local dbgpt_serve.rag.service.service[62266] ERROR document embedding, failed:planning.md, 'NoneType' object is not subscriptable\n\n代码方法：\n@trace(\"async_doc_embedding\")\nasync def async_doc_embedding(\n    self, knowledge, chunk_parameters, vector_store_connector, doc, space\n):\n --- 引发异常代码\nchunk_docs = assembler.get_chunks()\ndoc.chunk_size = len(chunk_docs)\nvector_ids = await assembler.apersist(\n    max_chunks_once_load=max_chunks_once_load,\n    max_threads=max_threads,\n)\n\n调到 aload_document_with_limit\n最后执行MilvusStore 里的def init_schema_and_load(self, vector_name, documents) -> List[str]: 方法报的错误。\n\nif utility.has_collection(self.collection_name):\n    self.col = Collection(self.collection_name, using=self.alias)\n    self.fields = []\n    for x in self.col.schema.fields:\n        self.fields.append(x.name)\n        if x.auto_id:\n            self.fields.remove(x.name)\n        if x.is_primary:\n            self.primary_field = x.name\n        if (\n            x.dtype == DataType.FLOAT_VECTOR\n            or x.dtype == DataType.BINARY_VECTOR\n        ):\n            self.vector_field = x.name\n    return self._add_documents(texts, metadatas)\n\n### What you expected to happen\n\n async def aload_document_with_limit(\n        self, chunks: List[Chunk], max_chunks_once_load: int = 10, max_threads: int = 1\n    ) -> List[str]: \n………\n        import asyncio\n        results = await asyncio.gather(*tasks)\n…………\n异步报错。\n你可以上传 ./DB-GPT/docs/docs/agents/*.md\n\n### How to reproduce\n\n上传多个文件md文件（10个左右），其中有几个报错的情况。通过UI点同步。\n你可以上传 ./DB-GPT/docs/docs/agents/*.md\n\n### Additional context\n\n使用的\nMilvus version2.3.13\n       self.index_params = {\n            \"index_type\": \"IVF_FLAT\",\n            \"metric_type\": \"IP\", # 2.3 版本，只有ip和L2\n            \"params\": {\"nlist\": 8},\n        }\n\n        self.index_params_map = {\n            \"FLAT\": {\"params\": {\"nprobe\": 10}},\n            \"IVF_FLAT\": {\"params\": {\"nprobe\": 16}},\n            \"IVF_SQ8\": {\"params\": {\"nprobe\": 10}},\n            \"IVF_PQ\": {\"params\": {\"nprobe\": 10}},\n            \"HNSW\": {\"params\": {\"M\": 8, \"efConstruction\": 64}},\n            \"RHNSW_FLAT\": {\"params\": {\"ef\": 10}},\n            \"RHNSW_SQ\": {\"params\": {\"ef\": 10}},\n            \"RHNSW_PQ\": {\"params\": {\"ef\": 10}},\n            \"IVF_HNSW\": {\"params\": {\"nprobe\": 10, \"ef\": 10}},\n            \"ANNOY\": {\"params\": {\"search_k\": 10}},\n        }\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "xydz",
      "author_type": "User",
      "created_at": "2025-03-13T10:06:56Z",
      "updated_at": "2025-03-17T08:02:46Z",
      "closed_at": "2025-03-17T08:02:45Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2458/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2458",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2458",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:35.429616",
      "comments": [
        {
          "author": "xydz",
          "body": "self fix:\n1. <file>dbgpt-core/src/dbgpt/storage/base.py</file> \n async def aload_document_with_limit(\n        self, chunks: List[Chunk], max_chunks_once_load: int = 10, max_threads: int = 1\n    ) -> List[str]:\n        \"\"\"Load document in index database with specified limit.\n\n        Args:\n          ",
          "created_at": "2025-03-17T08:02:45Z"
        }
      ]
    },
    {
      "issue_number": 1179,
      "title": "[Bug] [deploy] Error starting worker manager: model tongyi_proxyllm@proxy(10.25.151.8:5001) start failed",
      "body": "### Search before asking\r\n\r\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\r\n\r\n\r\n### Operating system information\r\n\r\nWindows\r\n\r\n### Python version information\r\n\r\n>3.10.3\r\n\r\n### DB-GPT version\r\n\r\nmain\r\n\r\n### Related scenes\r\n\r\n- [X] Chat Data\r\n- [X] Chat Excel\r\n- [X] Chat DB\r\n- [ ] Chat Knowledge\r\n- [ ] Model Management\r\n- [ ] Dashboard\r\n- [ ] Plugins\r\n\r\n### Installation Information\r\n\r\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\r\n\r\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\r\n\r\n- [ ] AutoDL Image\r\n- [ ] Other\r\n\r\n### Device information\r\n\r\nDevice: CPU\r\n\r\n### Models information\r\n\r\nLLM: tongyi_proxyllm\r\nEMBEDDING_MODEL=text2vec\r\n\r\n### What happened\r\n\r\n启动服务时报错\r\n\r\nerror occurred when tried to start up the server\r\n\r\n### What you expected to happen\r\n\r\n- related context:\r\n``` txt\r\nINFO:     Uvicorn running on http://0.0.0.0:5001 (Press CTRL+C to quit)\r\n2024-02-21 20:35:42 DESKTOP-5JQT482 dbgpt.model.cluster.worker.manager[2256] **ERROR Error starting worker manager: model tongyi_proxyllm@proxy(10.25.151.8:5001) start failed,** \r\n2024-02-21 20:35:42 DESKTOP-5JQT482 dbgpt.model.cluster.worker.manager[2256] INFO Stop all workers\r\n2024-02-21 20:35:42 DESKTOP-5JQT482 dbgpt.model.cluster.worker.manager[2256] INFO Apply req: None, apply_func: <function LocalWorkerManager._stop_all_worker.<locals>._stop_worker at 0x00000208A4064CA0>\r\n2024-02-21 20:35:42 DESKTOP-5JQT482 dbgpt.model.cluster.worker.manager[2256] INFO Apply to all workers\r\n2024-02-21 20:35:48 DESKTOP-5JQT482 dbgpt.model.cluster.worker.manager[2256] WARNING Stop worker, ignored exception from deregister_func: \r\n2024-02-21 20:35:48 DESKTOP-5JQT482 dbgpt.model.cluster.worker.manager[2256] WARNING Stop worker, ignored exception from deregister_func: \r\n```\r\n\r\n- Here's the full log [dbgpt_webserver.log](https://github.com/eosphoros-ai/DB-GPT/files/14359615/dbgpt_webserver.log)\r\n\r\n### How to reproduce\r\n\r\nwhen run `python dbgpt/app/dbgpt_server.py`\r\n\r\n### Additional context\r\n\r\n_No response_\r\n\r\n### Are you willing to submit PR?\r\n\r\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "vxwong",
      "author_type": "User",
      "created_at": "2024-02-21T12:50:24Z",
      "updated_at": "2025-03-17T07:07:33Z",
      "closed_at": "2024-06-04T21:04:43Z",
      "labels": [
        "bug",
        "FAQ:Install",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1179/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1179",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1179",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:35.606582",
      "comments": [
        {
          "author": "fangyinc",
          "body": "Have you enabled global proxies on your system? Please turn off it and try again.",
          "created_at": "2024-02-22T06:38:40Z"
        },
        {
          "author": "vxwong",
          "body": "Thanks for the reply.\r\nYes I did have global proxies set by the company due to security issues.\r\nI'll try it later this weekend at home.",
          "created_at": "2024-02-27T08:03:32Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-03-28T21:05:15Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue bas been closed, because it has been marked as `stale` and there has been no activity for over 7 days.",
          "created_at": "2024-06-04T21:04:43Z"
        },
        {
          "author": "pc-mysql",
          "body": "maybe the port has been used，try to change ",
          "created_at": "2025-03-17T07:07:33Z"
        }
      ]
    },
    {
      "issue_number": 2052,
      "title": "[Bug]When running the project locally, the mysql query table structure is too long, causing the fields to be truncated characters truncated",
      "body": "\r\n... (1774 characters truncated) ... \r\n<img width=\"1060\" alt=\"image\" src=\"https://github.com/user-attachments/assets/b3253c7d-45ac-4690-94ce-677349a52bac\">\r\n<img width=\"818\" alt=\"image\" src=\"https://github.com/user-attachments/assets/08ed5122-ca4e-48cb-a7ff-c12ab95f7942\">\r\n",
      "state": "open",
      "author": "yongxingMa",
      "author_type": "User",
      "created_at": "2024-10-06T04:03:20Z",
      "updated_at": "2025-03-17T02:39:56Z",
      "closed_at": null,
      "labels": [
        "stale"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2052/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2052",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2052",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:35.808005",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "[#2035 ](https://github.com/eosphoros-ai/DB-GPT/pull/2035)\r\nwill fix your problem.",
          "created_at": "2024-10-07T14:59:17Z"
        },
        {
          "author": "Carlycjl",
          "body": "请问在使用text2sql功能的时候，添加了数据库后还需要有什么操作嘛？我这边想要查询，一直显示没有table structure。谢谢你！",
          "created_at": "2024-10-13T08:57:24Z"
        },
        {
          "author": "FOkvj",
          "body": "请问您是否使用了该代码[#2035](https://github.com/eosphoros-ai/DB-GPT/pull/2035)？如果用了，希望您能把报错日志贴一下",
          "created_at": "2024-10-22T15:32:47Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-02-19T21:04:50Z"
        },
        {
          "author": "531128151",
          "body": "哥们，你这个问题最后解决了吗？",
          "created_at": "2025-03-17T02:39:55Z"
        }
      ]
    },
    {
      "issue_number": 2473,
      "title": "[Doc]AWEL agent python demo",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n各位大佬，目前只有在页面拖拽配置agent的样例，但是实际工作中可能需要手动去写awel的python代码。能否提供一个具体的调用样例代码呢，例如从httptrigger开始，经过rag算子等，然后触发一个agent，这个agent再去操作一些经过rag检索出来的工作流程。还是目前agent只支持经过agnettrigger才能触发呢，前面能否添加例如rag之类的额外过程:)\n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "paul-yangmy",
      "author_type": "User",
      "created_at": "2025-03-16T15:32:07Z",
      "updated_at": "2025-03-16T15:32:07Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2473/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2473",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2473",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:36.010892",
      "comments": []
    },
    {
      "issue_number": 2126,
      "title": "[Bug] [Chat_Data] use stream model return json without data",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [X] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nx86_64\r\nNVIDIA GeForce GTX 1080\n\n### Models information\n\nLLM: iFlytekSpark-13B\r\nEmbedding model:text2vec-large-chinese\n\n### What happened\n\nWhen I call the streaming answer mode with the API, the answer result is only JSON characters, without data.\r\n![image](https://github.com/user-attachments/assets/b97dc96d-0c9a-4032-bd37-f2ededb1684d)\r\n\n\n### What you expected to happen\n\nReturn streaming output results, just like non streaming output.\r\n![image](https://github.com/user-attachments/assets/fffe9c25-b2fb-4497-a1f9-8ea0434946cb)\r\n\n\n### How to reproduce\n\n curl -X POST \"http://localhost:5670/api/v2/chat/completions\" \\\r\n    -H \"Authorization: Bearer dbgpt\" \\\r\n    -H \"accept: application/json\" \\\r\n    -H \"Content-Type: application/json\" \\\r\n    -d \"{\\\"messages\\\":\\\"Hello\\\",\\\"model\\\":\\\"chatgpt_proxyllm\\\", \\\"stream\\\": true}\"\r\n\n\n### Additional context\n\nnothing\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "sun-timer",
      "author_type": "User",
      "created_at": "2024-11-14T11:25:38Z",
      "updated_at": "2025-03-15T21:04:53Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2126/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2126",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2126",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:36.010912",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "```\r\ncurl -X POST \"http://localhost:5670/api/v2/chat/completions\"\r\n-H \"Authorization: Bearer dbgpt\"\r\n-H \"accept: application/json\"\r\n-H \"Content-Type: application/json\"\r\n-d \"{\"messages\":\"Hello\",\"model\":\"chatgpt_proxyllm\", \"stream\": true}\"\r\n```\r\nit is a normal chat, you can set your mode like \r\n```\r\nD",
          "created_at": "2024-11-14T15:38:28Z"
        },
        {
          "author": "sun-timer",
          "body": "thank u for answer. What I mean is that it returned an incorrect response, which is that the streaming output did not output the complete table at the end. I use Source Code Deployment, where shall I modify to fix it\r\n![image](https://github.com/user-attachments/assets/6d1c0fd0-ca53-4245-b0e8-6036a7",
          "created_at": "2024-11-15T01:54:07Z"
        },
        {
          "author": "Aries-ckt",
          "body": "it looks like web chat data app not correct , can you show the whole complete chat data screen shot? did you specify your db name?",
          "created_at": "2024-11-15T02:04:01Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-03-15T21:04:51Z"
        }
      ]
    },
    {
      "issue_number": 2470,
      "title": "[Bug] [ChatKnowledge] ElasticSearch没有按照预定义ids保存文档",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice: CPU\n\n### Models information\n\nLLM: deepseek-r1\n\n### What happened\n\nElasticSearch向量库按照自定义ids保存文档时，并没有将ids传入，保存时还是使用的随机ids，导致最终不能按照id删除文档（删除过后还是能够检索到）。主要是因为from langchain.vectorstores.elasticsearch import ElasticsearchStore这个类里面的问题，from_texts方法没有将ids传入add_texts方法中。\n\n![Image](https://github.com/user-attachments/assets/0ae3f4fa-71cb-4283-a750-3325dce1ed22)\n\n### What you expected to happen\n\n通过重写from_texts方法可以解决，把参数**kwargs加上\nelasticsearchStore.add_texts(\n            texts, metadatas=metadatas, bulk_kwargs=bulk_kwargs, **kwargs\n        )\n\n### How to reproduce\n\n通过上传文档，获取ids，然后删除过后，使用kibana查询该id还能查询到。\n如：GET /ik_1024_bge_15/_doc/d8846723-9fb5-4b09-b539-7e8557299497\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "fangyiwb",
      "author_type": "User",
      "created_at": "2025-03-14T09:41:42Z",
      "updated_at": "2025-03-14T09:42:32Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2470/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2470",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2470",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:36.199390",
      "comments": []
    },
    {
      "issue_number": 2433,
      "title": "改为显示数据库别名，方便业务使用",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n![Image](https://github.com/user-attachments/assets/f6e76fe4-de89-4bed-a798-1076903316bd)只能显示数据库名，不方便业务部门辨别该用哪个库\n\n### Use case\n\n![Image](https://github.com/user-attachments/assets/84adfab6-a1a3-4600-a0c1-b8236206cbb2)增加一行填写数据库别名，使得聊天选择数据库时显示为别名\n\n<!-- Failed to upload \"image.png\" -->\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Silenceang",
      "author_type": "User",
      "created_at": "2025-03-11T03:15:51Z",
      "updated_at": "2025-03-14T07:58:40Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2433/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2433",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2433",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:36.199410",
      "comments": [
        {
          "author": "Silenceang",
          "body": "![Image](https://github.com/user-attachments/assets/b4ad6336-e8c4-4943-a81c-1312fc04a651)使得聊天时选择数据库别名使用更方便",
          "created_at": "2025-03-11T03:17:38Z"
        },
        {
          "author": "Eason-Shen",
          "body": "而且不能创建同名的数据库连接，这也是个问题",
          "created_at": "2025-03-14T07:58:39Z"
        }
      ]
    },
    {
      "issue_number": 2447,
      "title": "[Bug] [Module Name] Bug title 无法删除数据源链接",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\ncpu\n\n### Models information\n\nproxy_ollama_proxy_backend=\"nomic-embed-text:latest\"\nPROXYLLM_BACKEND=\"qwen2:7b\"\n\n### What happened\n\n在数据库管理页面，删除之前录入的数据源时，后台报错，无法删除数据源。报错信息是这样的。\n`2025-03-12 16:01:19 DESKTOP-IGT118C dbgpt.serve.rag.connector[17808] ERROR delete vector name test1_profile failed: Collection langchain does not exist.\n2025-03-12 16:01:19 DESKTOP-IGT118C dbgpt.serve.core.schemas[17808] ERROR common_exception_handler catch Exception: success=False err_code='E0003' err_msg='delete name test1_profile failed' data=None\nINFO:     127.0.0.1:53633 - \"POST /api/v1/chat/db/delete?db_name=test1 HTTP/1.1\" 400 Bad Request\nERROR:    Exception in ASGI application\n  + Exception Group Traceback (most recent call last):\n  |   File \"D:\\python-3.10\\lib\\site-packages\\starlette\\_utils.py\", line 77, in collapse_excgroups\n  |     yield\n  |   File \"D:\\python-3.10\\lib\\site-packages\\starlette\\middleware\\base.py\", line 186, in __call__\n  |     async with anyio.create_task_group() as task_group:\n  |   File \"D:\\python-3.10\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 767, in __aexit__\n  |     raise BaseExceptionGroup(\n  | exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"D:\\python-3.10\\lib\\site-packages\\uvicorn\\protocols\\http\\httptools_impl.py\", line 409, in run_asgi\n    |     result = await app(  # type: ignore[func-returns-value]\n    |   File \"D:\\python-3.10\\lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 60, in __call__\n    |     return await self.app(scope, receive, send)\n    |   File \"D:\\python-3.10\\lib\\site-packages\\starlette\\middleware\\cors.py\", line 93, in __call__\n    |     await self.simple_response(scope, receive, send, request_headers=headers)\n    |   File \"D:\\python-3.10\\lib\\site-packages\\starlette\\middleware\\cors.py\", line 144, in simple_response\n    |     await self.app(scope, receive, send)\n    |   File \"D:\\python-3.10\\lib\\site-packages\\fastapi\\applications.py\", line 1054, in __call__\n    |     await super().__call__(scope, receive, send)\n    |   File \"D:\\python-3.10\\lib\\site-packages\\starlette\\applications.py\", line 113, in __call__\n    |     await self.middleware_stack(scope, receive, send)\n    |   File \"D:\\python-3.10\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 187, in __call__\n    |     raise exc\n    |   File \"D:\\python-3.10\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 165, in __call__\n    |     await self.app(scope, receive, _send)\n    |   File \"D:\\python-3.10\\lib\\site-packages\\starlette\\middleware\\base.py\", line 185, in __call__\n    |     with collapse_excgroups():\n    |   File \"D:\\python-3.10\\lib\\contextlib.py\", line 153, in __exit__\n    |     self.gen.throw(typ, value, traceback)\n    |   File \"D:\\python-3.10\\lib\\site-packages\\starlette\\_utils.py\", line 83, in collapse_excgroups\n    |     raise exc\n    |   File \"D:\\python-3.10\\lib\\site-packages\\starlette\\middleware\\base.py\", line 187, in __call__\n    |     response = await self.dispatch_func(request, call_next)\n    |   File \"d:\\db-gpt\\db-gpt-0.6.3\\dbgpt\\util\\tracer\\tracer_middleware.py\", line 49, in dispatch\n    |     response = await call_next(request)\n    |   File \"D:\\python-3.10\\lib\\site-packages\\starlette\\middleware\\base.py\", line 163, in call_next\n    |     raise app_exc\n    |   File \"D:\\python-3.10\\lib\\site-packages\\starlette\\middleware\\base.py\", line 149, in coro\n    |     await self.app(scope, receive_or_disconnect, send_no_error)\n    |   File \"D:\\python-3.10\\lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 62, in __call__\n    |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n    |   File \"D:\\python-3.10\\lib\\site-packages\\starlette\\_exception_handler.py\", line 62, in wrapped_app\n    |     raise exc\n    |   File \"D:\\python-3.10\\lib\\site-packages\\starlette\\_exception_handler.py\", line 51, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"D:\\python-3.10\\lib\\site-packages\\starlette\\routing.py\", line 715, in __call__\n    |     await self.middleware_stack(scope, receive, send)\n    |   File \"D:\\python-3.10\\lib\\site-packages\\starlette\\routing.py\", line 735, in app\n    |     await route.handle(scope, receive, send)\n    |   File \"D:\\python-3.10\\lib\\site-packages\\starlette\\routing.py\", line 288, in handle\n    |     await self.app(scope, receive, send)\n    |   File \"D:\\python-3.10\\lib\\site-packages\\starlette\\routing.py\", line 76, in app\n    |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n    |   File \"D:\\python-3.10\\lib\\site-packages\\starlette\\_exception_handler.py\", line 62, in wrapped_app\n    |     raise exc\n    |   File \"D:\\python-3.10\\lib\\site-packages\\starlette\\_exception_handler.py\", line 51, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"D:\\python-3.10\\lib\\site-packages\\starlette\\routing.py\", line 73, in app\n    |     response = await f(request)\n    |   File \"D:\\python-3.10\\lib\\site-packages\\fastapi\\routing.py\", line 301, in app\n    |     raw_response = await run_endpoint_function(\n    |   File \"D:\\python-3.10\\lib\\site-packages\\fastapi\\routing.py\", line 212, in run_endpoint_function\n    |     return await dependant.call(**values)\n    |   File \"d:\\db-gpt\\db-gpt-0.6.3\\dbgpt\\app\\openapi\\api_v1\\api_v1.py\", line 217, in db_connect_delete\n    |     CFG.local_db_manager.db_summary_client.delete_db_profile(db_name)\n    |   File \"d:\\db-gpt\\db-gpt-0.6.3\\dbgpt\\rag\\summary\\db_summary_client.py\", line 147, in delete_db_profile\n    |     table_vector_connector.delete_vector_name(table_vector_store_name)\n    |   File \"d:\\db-gpt\\db-gpt-0.6.3\\dbgpt\\serve\\rag\\connector.py\", line 229, in delete_vector_name\n    |     raise Exception(f\"delete name {vector_name} failed\")\n    | Exception: delete name test1_profile failed\n    +------------------------------------`\n\n### What you expected to happen\n\n关于chroma向量库的操作。有没有办法通过手动删除的方式，清空我之前的一些录入信息。\n\n### How to reproduce\n\n[dbgpt_webserver.log](https://github.com/user-attachments/files/19205846/dbgpt_webserver.log)\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "kyyz147",
      "author_type": "User",
      "created_at": "2025-03-12T08:07:28Z",
      "updated_at": "2025-03-14T06:43:46Z",
      "closed_at": "2025-03-14T06:43:46Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2447/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2447",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2447",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:36.789919",
      "comments": []
    },
    {
      "issue_number": 2422,
      "title": "[Bug] [Knowlege] delete knowledge space error",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\n[[models.llms]]\nname = \"Qwen/QwQ-32B\"\nprovider = \"proxy/siliconflow\"\n\n[[models.embeddings]]\nname = \"BAAI/bge-large-zh-v1.5\"\n\n### What happened\n\n![Image](https://github.com/user-attachments/assets/40d305bb-6c05-4643-a3e2-a54bdd57118e)\n\n![Image](https://github.com/user-attachments/assets/58011f1e-778d-423a-beeb-25c9c9d324b8)\n\n![Image](https://github.com/user-attachments/assets/9003ca4b-df0c-469f-8e0f-ab9676571583)\n\nknowledge space delete error ,log:\n`\n2025-03-10 00:21:22 tam dbgpt_ext.storage.vector_store.chroma_store[28020] INFO chroma vector_name:111 begin delete...\n2025-03-10 00:21:22 tam dbgpt_serve.rag.connector[28020] ERROR delete vector name 111 failed: Collection langchain does not exist.\n`\n\n\n### What you expected to happen\n\ndelete knowledge space success\n\n### How to reproduce\n\n1,  Create a space of vector storage type,  domain type is normal \n![Image](https://github.com/user-attachments/assets/e813322b-adb0-420f-8d99-c3137e160f0d)\n2,Fill in some test text for automatic slicing\n![Image](https://github.com/user-attachments/assets/2b5f4ece-fa90-460e-9046-a4d780bfc5cd)\n3, There are two kinds of errors, the first deletion log shows Error delete vector name demo failed, the other program is using this file, the process cannot access it, and then wait for a while and delete it again will prompt failure, the log shows ERROR delete vector name demo failed: Collection langchain does not exist.\n\n![Image](https://github.com/user-attachments/assets/0ded3da3-4f0e-41ce-aef0-b756fd9838fc)\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "vnicers",
      "author_type": "User",
      "created_at": "2025-03-09T16:38:27Z",
      "updated_at": "2025-03-14T06:43:45Z",
      "closed_at": "2025-03-14T06:43:45Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2422/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2422",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2422",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:36.789955",
      "comments": [
        {
          "author": "vnicers",
          "body": "Refresh the MySQL data source will also report the same error: delete vector name xxx failed: Collection langchain does not exist.",
          "created_at": "2025-03-10T02:24:16Z"
        },
        {
          "author": "vnicers",
          "body": "The probably reason is that the first deletion failed because the underlying file was occupied, but the collection was successfully deleted, and then when the user deleted it again, the collection no longer existed and an error was reported.",
          "created_at": "2025-03-10T04:49:49Z"
        }
      ]
    },
    {
      "issue_number": 2437,
      "title": "[Bug] [ChatExcel]execute \"SELECT comment, table_name, database_name FROM duckdb_tables() \" is empty",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [x] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [x] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nno\n\n### Models information\n\nno\n\n### What happened\n\n- When a table is registered via `register` in DuckDB, executing the query \"SELECT comment, table_name, database_name FROM duckdb_tables()\" returns an empty result.\n- Characteristics of Tables Registered via `register`:\n  - 1. **Temporary Nature**: Tables registered via `register` are session-level temporary tables. They are only valid within the current connection and are not persisted to disk.\n\n  - 2. **Metadata Storage**: These tables are not recorded in `duckdb_tables()`. Instead, they are stored in DuckDB's internal temporary directory.\n\nso,you can see https://github.com/eosphoros-ai/DB-GPT/blob/49ce86f2ce1f0f53c847f5dd4f82f3d4fa03bc42/packages/dbgpt-app/src/dbgpt_app/scene/chat_data/chat_excel/excel_reader.py#L174 and https://github.com/eosphoros-ai/DB-GPT/blob/49ce86f2ce1f0f53c847f5dd4f82f3d4fa03bc42/packages/dbgpt-app/src/dbgpt_app/scene/chat_data/chat_excel/excel_reader.py#L317 \nhttps://github.com/eosphoros-ai/DB-GPT/blob/49ce86f2ce1f0f53c847f5dd4f82f3d4fa03bc42/packages/dbgpt-app/src/dbgpt_app/scene/chat_data/chat_excel/excel_reader.py#L320\nhttps://github.com/eosphoros-ai/DB-GPT/blob/49ce86f2ce1f0f53c847f5dd4f82f3d4fa03bc42/packages/dbgpt-app/src/dbgpt_app/scene/chat_data/chat_excel/excel_reader.py#L321   Therefore, an `IndexError` may occur.\n\n\n```def get_create_table_sql(self, table_name: str) -> str:\n        sql = f\"\"\"SELECT comment, table_name, database_name FROM duckdb_tables() \\\n        where table_name = '{table_name}'\"\"\"\n\n        columns, datas = self.run(sql, table_name, transform=False)\n        table_comment = datas[0][0]\n```\n\n\n\n### What you expected to happen\n\nA condition should be added to determine whether `datas` is a non-empty array.\n\n### How to reproduce\n\n-  https://github.com/eosphoros-ai/DB-GPT/blob/49ce86f2ce1f0f53c847f5dd4f82f3d4fa03bc42/packages/dbgpt-app/src/dbgpt_app/scene/chat_data/chat_excel/excel_reader.py#L174\n\n- Init db by `read_from_df` and use `db.register(table_name, df)`\n\n- Verfiy\n\n```\nimport duckdb\nimport pandas as pd\n\n# Create a persistent table\nconn = duckdb.connect()\nconn.execute(\"CREATE TABLE persistent_table (id INTEGER)\")\n\n# Register a temporary table\ndf = pd.DataFrame({\"data\": [1, 2, 3]})\nconn.register(\"temp_table\", df)\n\n# Query duckdb_tables (does not include temp_table)\ntables = conn.execute(\"SELECT table_name FROM duckdb_tables()\").fetchall()\nprint(tables)  # Output: [('persistent_table',)]\n\n# Query SHOW TABLES (includes temp_table)\nshow_tables = conn.execute(\"SHOW TABLES\").fetchall()\nprint(show_tables)  # Output: ['persistent_table', 'temp_table']\n```\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "geebytes",
      "author_type": "User",
      "created_at": "2025-03-11T07:57:31Z",
      "updated_at": "2025-03-14T05:15:05Z",
      "closed_at": "2025-03-14T05:15:05Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2437/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2437",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2437",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:37.083070",
      "comments": [
        {
          "author": "fangyinc",
          "body": "Thank you for your feedback. This is indeed an issue, though currently only a few cases call `read_from_df` (situations where xls or DockDB cannot be read directly). Would you be interested in submitting a PR to fix this?",
          "created_at": "2025-03-11T15:49:41Z"
        }
      ]
    },
    {
      "issue_number": 2435,
      "title": "[Bug] [Plugins] ImportError: Please install chroma package first.",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [x] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice on CPU\n\n### Models information\n\ngpt-4o-mini\n\n### What happened\n\n\n在应用管理中，修改mysql数据库偶尔报错：ImportError: Please install chroma package first.\n删除mysql数据源必报错：ImportError: Please install chroma package first.\n\n![Image](https://github.com/user-attachments/assets/e5fdcdfd-2f9d-403d-8d25-2094c6f0d858)\n\n在点击确定时报错。\n\n\n\n### What you expected to happen\n\n成功增删数据库\n\n### How to reproduce\n\n1、复刻我的安装过程，即chromadb单独安装\n2、在应用程序中，添加新的mysql数据库，然后删除mysql数据库。\n\n### Additional context\n\n在安装新版本main分支的0.7.0时，使用如下指令安装：\nuv sync --all-packages --frozen \\\n--extra \"base\" \\\n--extra \"proxy_openai\" \\\n--extra \"rag\" \\\n--extra \"storage_chromadb\" \\\n--extra \"dbgpts\"\n报错：error: Distribution `onnxruntime==1.18.1 @ registry+https://pypi.tuna.tsinghua.edu.cn/simple` can't be installed because it doesn't have a source distribution or wheel for the current platform\n\nhint: You're on Linux (`manylinux_2_17_x86_64`), but `onnxruntime` (v1.18.1) only has wheels for the following platforms: `manylinux_2_27_aarch64`, `manylinux_2_27_x86_64`, `manylinux_2_28_aarch64`, `manylinux_2_28_x86_64`, `macosx_11_0_universal2`, `win32`, `win_amd64`\n\n**于是我咨询社区后去掉了--extra \"storage_chromadb\" \\ 这一行，安装成功！**\n\n随后再次进行chromadb安装\nuv pip install chroma\nuv pip install chromadb==0.6.3\n以及onnxruntime==1.16.3\n\n**这三个都安装成功了，而且也能成功启动0.7.0版本db-gpt**\n\n\n**从启动程序开始的日志如下：**\n2025-03-11 13:48:22 dwh-datadev-prod-yzbx-007178.dev.ljnode.com dbgpt.util.code.server[76021] INFO Code server is ready\nINFO:     10.36.196.238:51958 - \"GET /images/bg.png HTTP/1.1\" 404 Not Found\n2025-03-11 13:48:22 dwh-datadev-prod-yzbx-007178.dev.ljnode.com dbgpt_app.openapi.api_v1.api_v1[76021] INFO /controller/model/types\n2025-03-11 13:48:22 dwh-datadev-prod-yzbx-007178.dev.ljnode.com dbgpt.model.cluster.controller.controller[76021] INFO Get all instances with None, healthy_only: True\nINFO:     10.36.196.238:51958 - \"GET /api/v1/model/types HTTP/1.1\" 200 OK\n2025-03-11 13:48:23 dwh-datadev-prod-yzbx-007178.dev.ljnode.com dbgpt_serve.rag.connector[76021] INFO VectorStore:<class 'dbgpt_ext.storage.vector_store.chroma_store.ChromaStore'>\n2025-03-11 13:48:23 dwh-datadev-prod-yzbx-007178.dev.ljnode.com dbgpt_serve.rag.connector[76021] ERROR connect vector store failed: Please install chroma package first.\n2025-03-11 13:48:23 dwh-datadev-prod-yzbx-007178.dev.ljnode.com dbgpt_serve.datasource.service.db_summary_client[76021] WARNING mysql, mysql summary error!Please install chroma package first., detail: Traceback (most recent call last):\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-ext/src/dbgpt_ext/storage/vector_store/chroma_store.py\", line 85, in __init__\n    from chromadb import PersistentClient, Settings\nModuleNotFoundError: No module named 'chromadb'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/db_summary_client.py\", line 52, in db_summary_embedding\n    self.init_db_profile(db_summary_client, dbname)\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/db_summary_client.py\", line 105, in init_db_profile\n    self._get_vector_connector_by_db(dbname)\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/db_summary_client.py\", line 161, in _get_vector_connector_by_db\n    table_vector_connector = VectorStoreConnector.from_default(\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/rag/connector.py\", line 121, in from_default\n    return cls(real_vector_store_type, vector_store_config, system_app)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/rag/connector.py\", line 95, in __init__\n    raise e\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/rag/connector.py\", line 91, in __init__\n    client = self.connector_class(config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-ext/src/dbgpt_ext/storage/vector_store/chroma_store.py\", line 87, in __init__\n    raise ImportError(\"Please install chroma package first.\")\nImportError: Please install chroma package first.\n\n2025-03-11 13:48:23 dwh-datadev-prod-yzbx-007178.dev.ljnode.com dbgpt_serve.datasource.service.db_summary_client[76021] WARNING mysql, mysql summary error!Please install chroma package first., detail: Traceback (most recent call last):\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-ext/src/dbgpt_ext/storage/vector_store/chroma_store.py\", line 85, in __init__\n    from chromadb import PersistentClient, Settings\nModuleNotFoundError: No module named 'chromadb'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/db_summary_client.py\", line 87, in init_db_summary\n    self.db_summary_embedding(item[\"db_name\"], item[\"db_type\"])\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/db_summary_client.py\", line 52, in db_summary_embedding\n    self.init_db_profile(db_summary_client, dbname)\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/db_summary_client.py\", line 105, in init_db_profile\n    self._get_vector_connector_by_db(dbname)\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/db_summary_client.py\", line 161, in _get_vector_connector_by_db\n    table_vector_connector = VectorStoreConnector.from_default(\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/rag/connector.py\", line 121, in from_default\n    return cls(real_vector_store_type, vector_store_config, system_app)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/rag/connector.py\", line 95, in __init__\n    raise e\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/rag/connector.py\", line 91, in __init__\n    client = self.connector_class(config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-ext/src/dbgpt_ext/storage/vector_store/chroma_store.py\", line 87, in __init__\n    raise ImportError(\"Please install chroma package first.\")\nImportError: Please install chroma package first.\n\n2025-03-11 13:48:23 dwh-datadev-prod-yzbx-007178.dev.ljnode.com dbgpt.datasource.rdbms.base[76021] INFO Closing RDBMS connector resources...\n2025-03-11 13:48:23 dwh-datadev-prod-yzbx-007178.dev.ljnode.com dbgpt_serve.datasource.manages.connect_config_db[76021] INFO Result: <sqlalchemy.engine.cursor.CursorResult object at 0x7f4c32a5f690>\n2025-03-11 13:48:23 dwh-datadev-prod-yzbx-007178.dev.ljnode.com dbgpt_serve.rag.connector[76021] INFO VectorStore:<class 'dbgpt_ext.storage.vector_store.chroma_store.ChromaStore'>\n2025-03-11 13:48:23 dwh-datadev-prod-yzbx-007178.dev.ljnode.com dbgpt_serve.rag.connector[76021] ERROR connect vector store failed: Please install chroma package first.\n2025-03-11 13:48:23 dwh-datadev-prod-yzbx-007178.dev.ljnode.com dbgpt_serve.datasource.service.db_summary_client[76021] WARNING xiaoxin, mysql summary error!Pleaseinstall chroma package first., detail: Traceback (most recent call last):\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-ext/src/dbgpt_ext/storage/vector_store/chroma_store.py\", line 85, in __init__\n    from chromadb import PersistentClient, Settings\nModuleNotFoundError: No module named 'chromadb'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/db_summary_client.py\", line 52, in db_summary_embedding\n    self.init_db_profile(db_summary_client, dbname)\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/db_summary_client.py\", line 105, in init_db_profile\n    self._get_vector_connector_by_db(dbname)\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/db_summary_client.py\", line 161, in _get_vector_connector_by_db\n    table_vector_connector = VectorStoreConnector.from_default(\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/rag/connector.py\", line 121, in from_default\n    return cls(real_vector_store_type, vector_store_config, system_app)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/rag/connector.py\", line 95, in __init__\n    raise e\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/rag/connector.py\", line 91, in __init__\n    client = self.connector_class(config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-ext/src/dbgpt_ext/storage/vector_store/chroma_store.py\", line 87, in __init__\n    raise ImportError(\"Please install chroma package first.\")\nImportError: Please install chroma package first.\n\n2025-03-11 13:48:23 dwh-datadev-prod-yzbx-007178.dev.ljnode.com dbgpt_serve.datasource.service.db_summary_client[76021] WARNING xiaoxin, mysql summary error!Pleaseinstall chroma package first., detail: Traceback (most recent call last):\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-ext/src/dbgpt_ext/storage/vector_store/chroma_store.py\", line 85, in __init__\n    from chromadb import PersistentClient, Settings\nModuleNotFoundError: No module named 'chromadb'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/db_summary_client.py\", line 87, in init_db_summary\n    self.db_summary_embedding(item[\"db_name\"], item[\"db_type\"])\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/db_summary_client.py\", line 52, in db_summary_embedding\n    self.init_db_profile(db_summary_client, dbname)\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/db_summary_client.py\", line 105, in init_db_profile\n    self._get_vector_connector_by_db(dbname)\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/db_summary_client.py\", line 161, in _get_vector_connector_by_db\n    table_vector_connector = VectorStoreConnector.from_default(\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/rag/connector.py\", line 121, in from_default\n    return cls(real_vector_store_type, vector_store_config, system_app)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/rag/connector.py\", line 95, in __init__\n    raise e\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/rag/connector.py\", line 91, in __init__\n    client = self.connector_class(config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-ext/src/dbgpt_ext/storage/vector_store/chroma_store.py\", line 87, in __init__\n    raise ImportError(\"Please install chroma package first.\")\nImportError: Please install chroma package first.\n\n2025-03-11 13:48:23 dwh-datadev-prod-yzbx-007178.dev.ljnode.com dbgpt.datasource.rdbms.base[76021] INFO Closing RDBMS connector resources...\nINFO:     10.36.196.238:51958 - \"POST /api/v1/app/list?page=1&page_size=12 HTTP/1.1\" 200 OK\nINFO:     10.36.196.238:51958 - \"POST /api/v1/app/list?page=1&page_size=12 HTTP/1.1\" 200 OK\nINFO:     10.36.196.238:51958 - \"GET /api/v2/serve/datasources HTTP/1.1\" 200 OK\nINFO:     10.36.196.238:51958 - \"GET /api/v2/serve/datasource-types HTTP/1.1\" 200 OK\n2025-03-11 13:48:31 dwh-datadev-prod-yzbx-007178.dev.ljnode.com dbgpt_serve.rag.connector[76021] INFO VectorStore:<class 'dbgpt_ext.storage.vector_store.chroma_store.ChromaStore'>\n2025-03-11 13:48:31 dwh-datadev-prod-yzbx-007178.dev.ljnode.com dbgpt_serve.rag.connector[76021] ERROR connect vector store failed: Please install chroma package first.\n2025-03-11 13:48:31 dwh-datadev-prod-yzbx-007178.dev.ljnode.com dbgpt_serve.core.schemas[76021] ERROR common_exception_handler catch Exception: success=False err_code='E0003' err_msg='Please install chroma package first.' data=None\nINFO:     10.36.196.238:51958 - \"DELETE /api/v2/serve/datasources/1 HTTP/1.1\" 400 Bad Request\nERROR:    Exception in ASGI application\n  + Exception Group Traceback (most recent call last):\n  |   File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_utils.py\", line 77, in collapse_excgroups\n  |     yield\n  |   File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 186, in __call__\n  |     async with anyio.create_task_group() as task_group:\n  |   File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 767, in __aexit__\n  |     raise BaseExceptionGroup(\n  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n    |     result = await app(  # type: ignore[func-returns-value]\n    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n    |     return await self.app(scope, receive, send)\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    |     await self.simple_response(scope, receive, send, request_headers=headers)\n    |   File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    |     await self.app(scope, receive, send)\n    |   File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/fastapi/applications.py\", line 1054, in __call__\n    |     await super().__call__(scope, receive, send)\n    |   File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/applications.py\", line 113, in __call__\n    |     await self.middleware_stack(scope, receive, send)\n    |   File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 187, in __call__\n    |     raise exc\n    |   File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    |     await self.app(scope, receive, _send)\n    |   File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 185, in __call__\n    |     with collapse_excgroups():\n    |   File \"/home/guopengye001/miniconda3/envs/dbgpt_env3114/lib/python3.11/contextlib.py\", line 155, in __exit__\n    |     self.gen.throw(typ, value, traceback)\n    |   File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_utils.py\", line 83, in collapse_excgroups\n    |     raise exc\n    |   File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 187, in __call__\n    |     response = await self.dispatch_func(request, call_next)\n    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-core/src/dbgpt/util/tracer/tracer_middleware.py\", line 49, in dispatch\n    |     response = await call_next(request)\n    |                ^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 163, in call_next\n    |     raise app_exc\n    |   File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 149, in coro\n    |     await self.app(scope, receive_or_disconnect, send_no_error)\n    |   File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n    |   File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n    |     raise exc\n    |   File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 715, in __call__\n    |     await self.middleware_stack(scope, receive, send)\n    |   File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 735, in app\n    |     await route.handle(scope, receive, send)\n    |   File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 288, in handle\n    |     await self.app(scope, receive, send)\n    |   File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 76, in app\n    |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n    |   File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n    |     raise exc\n    |   File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 73, in app\n    |     response = await f(request)\n    |                ^^^^^^^^^^^^^^^^\n    |   File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 301, in app\n    |     raw_response = await run_endpoint_function(\n    |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    |     return await dependant.call(**values)\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/api/endpoints.py\", line 156, in delete\n    |     service.delete(datasource_id)\n    |   File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/service.py\", line 233, in delete\n    |     _vector_connector = VectorStoreConnector(\n    |                         ^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/rag/connector.py\", line 95, in __init__\n    |     raise e\n    |   File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/rag/connector.py\", line 91, in __init__\n    |     client = self.connector_class(config)\n    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |   File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-ext/src/dbgpt_ext/storage/vector_store/chroma_store.py\", line 87, in __init__\n    |     raise ImportError(\"Please install chroma package first.\")\n    | ImportError: Please install chroma package first.\n    +------------------------------------\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n    result = await app(  # type: ignore[func-returns-value]\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n    return await self.app(scope, receive, send)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    await self.simple_response(scope, receive, send, request_headers=headers)\n  File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    await self.app(scope, receive, send)\n  File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/fastapi/applications.py\", line 1054, in __call__\n    await super().__call__(scope, receive, send)\n  File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/applications.py\", line 113, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 187, in __call__\n    raise exc\n  File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    await self.app(scope, receive, _send)\n  File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 185, in __call__\n    with collapse_excgroups():\n  File \"/home/guopengye001/miniconda3/envs/dbgpt_env3114/lib/python3.11/contextlib.py\", line 155, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_utils.py\", line 83, in collapse_excgroups\n    raise exc\n  File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 187, in __call__\n    response = await self.dispatch_func(request, call_next)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-core/src/dbgpt/util/tracer/tracer_middleware.py\", line 49, in dispatch\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 163, in call_next\n    raise app_exc\n  File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/base.py\", line 149, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n    raise exc\n  File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 715, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 735, in app\n    await route.handle(scope, receive, send)\n  File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n    raise exc\n  File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 73, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 301, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/guopengye001/tech-research/DB-GPT/.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n    return await dependant.call(**values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/api/endpoints.py\", line 156, in delete\n    service.delete(datasource_id)\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/datasource/service/service.py\", line 233, in delete\n    _vector_connector = VectorStoreConnector(\n                        ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/rag/connector.py\", line 95, in __init__\n    raise e\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/rag/connector.py\", line 91, in __init__\n    client = self.connector_class(config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/guopengye001/tech-research/DB-GPT/packages/dbgpt-ext/src/dbgpt_ext/storage/vector_store/chroma_store.py\", line 87, in __init__\n    raise ImportError(\"Please install chroma package first.\")\nImportError: Please install chroma package first.\n\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "AlexanderGPY",
      "author_type": "User",
      "created_at": "2025-03-11T05:53:39Z",
      "updated_at": "2025-03-14T03:31:46Z",
      "closed_at": "2025-03-14T03:31:05Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2435/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2435",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2435",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:37.248408",
      "comments": [
        {
          "author": "fangyinc",
          "body": "Hi @AlexanderGPY. Please pull the latest main code and try again.",
          "created_at": "2025-03-11T21:17:28Z"
        },
        {
          "author": "AlexanderGPY",
          "body": "> Hi [@AlexanderGPY](https://github.com/AlexanderGPY). Please pull the latest main code and try again.\n仍然没有解决呢，chromadb都需要哪些依赖呢？我是不是少安装了一些。",
          "created_at": "2025-03-12T05:44:20Z"
        },
        {
          "author": "AlexanderGPY",
          "body": "升级了centos8，升级到glibc2.28以上就兼容了。",
          "created_at": "2025-03-14T03:31:45Z"
        }
      ]
    },
    {
      "issue_number": 2449,
      "title": "[Bug] [Module Name] 启用了接口API KEY之后，数据库管理和工作流配置界面报错",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\ndeepseek\n\n### What happened\n\n\n配置文件启用了接口API KEY之后，数据库管理和工作流配置界面报错\n\n{'error': {'message': '', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n\n### What you expected to happen\n\n不要报错\n\n### How to reproduce\n\n配置文件启用了接口API KEY之后，数据库管理和工作流配置界面报错\n\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "bxfxf",
      "author_type": "User",
      "created_at": "2025-03-12T09:04:42Z",
      "updated_at": "2025-03-14T03:02:54Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2449/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2449",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2449",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:37.462959",
      "comments": [
        {
          "author": "su1234121",
          "body": "Please remove your api_keys or set empty to api_keys in config file.\nhave a try like this\n```\n[system]\nlanguage = \"${env:DBGPT_LANG:-zh}\"\napi_keys = []\n```",
          "created_at": "2025-03-13T05:45:23Z"
        },
        {
          "author": "531128151",
          "body": "@su1234121 请问你回复的这个[system]相关的配置是在哪个文件配置的，烦请告知下，感谢",
          "created_at": "2025-03-14T01:48:15Z"
        },
        {
          "author": "su1234121",
          "body": "在你uv启动命令后的那个配置文件的头上",
          "created_at": "2025-03-14T01:53:35Z"
        },
        {
          "author": "bxfxf",
          "body": "> Please remove your api_keys or set empty to api_keys in config file. have a try like this\n> \n> ```\n> [system]\n> language = \"${env:DBGPT_LANG:-zh}\"\n> api_keys = []\n> ```\n\n就是要设置apikey哦，因为调接口要用，为了安全",
          "created_at": "2025-03-14T02:51:32Z"
        },
        {
          "author": "su1234121",
          "body": "#2430 可以看这里，应该是版本更新还没修复，给的临时处理办法是这样的，APIkey可以填到下面去",
          "created_at": "2025-03-14T03:02:53Z"
        }
      ]
    },
    {
      "issue_number": 2399,
      "title": "[Bug] [dbgpt core] KeyError: 'content'",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU\n\n### Models information\n\nLLM: qwen\n\n### What happened\n\n最新代码本地llm运行，创建多智能体应用，选择数据分析和报表智能体引用数据库资源，聊天对话报错。\nTraceback (most recent call last):\n  File \"/v7/DB-GPT/packages/dbgpt-core/src/dbgpt/agent/expand/actions/chart_action.py\", line 84, in run\n    view = await self.render_protocol.display(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/v7/DB-GPT/packages/dbgpt-core/src/dbgpt/vis/base.py\", line 50, in display\n    return self.sync_display(**kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/v7/DB-GPT/packages/dbgpt-core/src/dbgpt/vis/base.py\", line 44, in sync_display\n    self.sync_generate_param(**kwargs), default=serialize, ensure_ascii=False\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/v7/DB-GPT/packages/dbgpt-core/src/dbgpt/vis/base.py\", line 27, in sync_generate_param\n    return kwargs[\"content\"]\n           ~~~~~~^^^^^^^^^^^\nKeyError: 'content'\n\n### What you expected to happen\n\n 正常返回图表\n\n### How to reproduce\n\nuv run python packages/dbgpt-app/src/dbgpt_app/dbgpt_server.py --config configs/dbgpt-local-qwen.toml\n创建应用选择选择数据分析和报表应用，对话聊天。\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "loverainye",
      "author_type": "User",
      "created_at": "2025-03-05T07:47:21Z",
      "updated_at": "2025-03-14T01:18:23Z",
      "closed_at": "2025-03-14T01:18:23Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2399/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 1
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2399",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2399",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:37.675512",
      "comments": [
        {
          "author": "Dong09",
          "body": "the same problem +1",
          "created_at": "2025-03-07T08:25:06Z"
        },
        {
          "author": "Dong09",
          "body": "> the same problem +1\n\n![Image](https://github.com/user-attachments/assets/27ad329b-a875-4762-8876-c95f9638baed)",
          "created_at": "2025-03-07T09:07:08Z"
        },
        {
          "author": "fangyinc",
          "body": "@loverainye @Dong09 \nThanks for your feedback, we will fix it today.",
          "created_at": "2025-03-13T03:47:20Z"
        }
      ]
    },
    {
      "issue_number": 2448,
      "title": "[Bug] [工作流] 新增工作流无法保存",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [x] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nlinux\n\n### Models information\n\nopenai\n\n### What happened\n\n![Image](https://github.com/user-attachments/assets/b5fdb3a4-da9c-4c7c-a77d-346b62d654c8)\n\n![Image](https://github.com/user-attachments/assets/1eee0314-d6d5-4986-ac5e-36e939d28874)\n\n报空了\n\n### What you expected to happen\n\n报空指针\n\n### How to reproduce\n\n保存\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "lishidetainan",
      "author_type": "User",
      "created_at": "2025-03-12T08:19:26Z",
      "updated_at": "2025-03-14T01:18:22Z",
      "closed_at": "2025-03-14T01:18:22Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2448/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2448",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2448",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:37.908467",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "try `uv pip install fastapi==0.111.0`",
          "created_at": "2025-03-12T15:15:44Z"
        },
        {
          "author": "lishidetainan",
          "body": "> try `uv pip install fastapi==0.111.0`\n\n![Image](https://github.com/user-attachments/assets/ef7d661b-4193-41ce-9e0f-1a2e60670298) 安装的是高版本的应该是兼容的 实际问题是sys_app未初始化；\n\n![Image](https://github.com/user-attachments/assets/ac3dff19-ccfa-4424-a02d-0aa8a32056e7)",
          "created_at": "2025-03-13T01:43:19Z"
        },
        {
          "author": "Aries-ckt",
          "body": "it will be fixed soon.",
          "created_at": "2025-03-13T10:54:37Z"
        }
      ]
    },
    {
      "issue_number": 2444,
      "title": "[Bug] [Module Name] AWEL  “Create DAG hybrid_knowledge_process_workflow_zh error”",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n24\n\n### Models information\n\n1\n\n### What happened\n\ni want to use the Hybrid Knowledge Process Workflow，when i save ，it reported“ ERROR common_exception_handler catch Exception: success=False err_code='E0003' err_msg='Create DAG hybrid_knowledge_process_workflow_zh error, define_type: json, error: Resource resource_dbgpt.storage.vector_store.chroma_store.ChromaVectorConfig not registered.' data=None\n”\n\n![Image](https://github.com/user-attachments/assets/53a2fa3d-3732-4d43-8326-9739a1553c83)\n\n![Image](https://github.com/user-attachments/assets/213fe6cc-e1a6-4cd2-991c-d90a63b783cd)\n\n### What you expected to happen\n\nI'm missing some environment dependencies on the installation and what do I need to do about it\n\n### How to reproduce\n\n1\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "ghao123",
      "author_type": "User",
      "created_at": "2025-03-11T16:27:27Z",
      "updated_at": "2025-03-14T01:18:22Z",
      "closed_at": "2025-03-14T01:18:21Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2444/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2444",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2444",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:38.097136",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "sorry about that, i will check what happened",
          "created_at": "2025-03-13T10:53:59Z"
        }
      ]
    },
    {
      "issue_number": 2418,
      "title": "Unable to build operator task: operator_higher_order_knowledge_operator___$$___rag___$$___v1_0, operator_cls: <class 'dbgpt_app.operators.rag.HOKnowledgeOperator'>, error: 'NoneType' object has no attribute 'config'",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [x] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU:3080TI\nCPU:Architecture:            x86_64\n  CPU op-mode(s):        32-bit, 64-bit\n  Address sizes:         46 bits physical, 57 bits virtual\n  Byte Order:            Little Endian\nCPU(s):                  128\n  On-line CPU(s) list:   0-127\nVendor ID:               GenuineIntel\n  Model name:            Intel(R) Xeon(R) Platinum 8336C CPU @ 2.30GHz\n    CPU family:          6\n    Model:               106\n    Thread(s) per core:  2\n    Core(s) per socket:  32\n    Socket(s):           2\n    Stepping:            6\n    CPU max MHz:         3500.0000\n    CPU min MHz:         800.0000\n    BogoMIPS:            4600.00\n    Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 \n                         clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtsc\n                         p lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nons\n                         top_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est\n                          tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe p\n                         opcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowpref\n                         etch cpuid_fault epb cat_l3 invpcid_single ssbd mba ibrs ibpb stibp ibrs\n                         _enhanced tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adju\n                         st bmi1 avx2 smep bmi2 erms invpcid cqm rdt_a avx512f avx512dq rdseed ad\n                         x smap avx512ifma clflushopt clwb intel_pt avx512cd sha_ni avx512bw avx5\n                         12vl xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total \n                         cqm_mbm_local split_lock_detect wbnoinvd dtherm ida arat pln pts avx512v\n                         bmi umip pku ospke avx512_vbmi2 gfni vaes vpclmulqdq avx512_vnni avx512_\n                         bitalg tme avx512_vpopcntdq la57 rdpid fsrm md_clear pconfig flush_l1d a\n                         rch_capabilities\nVirtualization features: \n  Virtualization:        VT-x\nCaches (sum of all):     \n  L1d:                   3 MiB (64 instances)\n  L1i:                   2 MiB (64 instances)\n  L2:                    80 MiB (64 instances)\n  L3:                    108 MiB (2 instances)\nNUMA:                    \n  NUMA node(s):          2\n  NUMA node0 CPU(s):     0-31,64-95\n  NUMA node1 CPU(s):     32-63,96-127\nVulnerabilities:         \n  Gather data sampling:  Mitigation; Microcode\n  Itlb multihit:         Not affected\n  L1tf:                  Not affected\n  Mds:                   Not affected\n  Meltdown:              Not affected\n  Mmio stale data:       Mitigation; Clear CPU buffers; SMT vulnerable\n  Retbleed:              Not affected\n  Spec rstack overflow:  Not affected\n  Spec store bypass:     Mitigation; Speculative Store Bypass disabled via prctl and seccomp\n  Spectre v1:            Mitigation; usercopy/swapgs barriers and __user pointer sanitization\n  Spectre v2:            Mitigation; Enhanced IBRS; IBPB conditional; RSB filling; PBRSB-eIBRS SW\n                          sequence; BHI Syscall hardening, KVM SW loop\n  Srbds:                 Not affected\n  Tsx async abort:       Not affected\nroot@autodl-container-8964458727-765abc2d:~/DB-GPT# \n\n### Models information\n\ndeepseek-r1:1.5b\nbge-m3:latest\n\n### What happened\n\nWhen we create an AWEL workflow in the dbgpt web interface and save it, an error is reported:  Request error:  Unable to build operator task: operator_higher_order_knowledge_operator___$$___rag___$$___v1_0, operator_cls: <class 'dbgpt_app.operators.rag.HOKnowledgeOperator'>, error: 'NoneType' object has no attribute 'config'\n\n![Image](https://github.com/user-attachments/assets/3f1c76b3-21d5-4e16-af05-03620cf27d45)\n\n### What you expected to happen\n\nWe expect the created workflow files to be saved normally.\nWe think that the database or other necessary configuration may not be configured.\nWe have not configured the database\n![Image](https://github.com/user-attachments/assets/4a8435e4-ed41-484e-b3f9-d6575e90ab93)\n\nOur configuration is to use the official dbpgt-proxy-ollama.toml configuration directly \n\n：[system]\n# Load language from environment variable(It is set by the hook)\nlanguage = \"${env:DBGPT_LANG:-en}\"\napi_keys = []\nencrypt_key = \"your_secret_key\"\n# Server Configurations\n[service.web]\nhost = \"0.0.0.0\"\nport = 6006\n[service.web.database]\ntype = \"sqlite\"\npath = \"pilot/meta_data/dbgpt.db\"\n[rag.storage]\n[rag.storage.vector]\ntype = \"Chroma\"\npersist_path = \"pilot/data\"\n\n# Model Configurations\n[models]\n[[models.llms]]\nname = \"deepseek-r1:1.5b\"\nprovider = \"proxy/ollama\"\napi_base = \"http://localhost:11434\"\napi_key = \"\"\n\n[[models.embeddings]]\nname = \"bge-m3:latest\"\nprovider = \"proxy/ollama\"\napi_url = \"http://localhost:11434\"\napi_key = \"\"\n\n\n### How to reproduce\n\nCompletely follow the tutorial of user yyhhyy :\n1.git clone https://github.com/eosphoros-ai/DB-GPT.git\ncd DB-GPT\n\n2.uv sync --all-packages --frozen \\\n--extra \"base\" \\\n--extra \"proxy_openai\" \\\n--extra \"hf\" \\\n--extra \"llama_cpp\" \\\n--extra \"rag\" \\\n--extra \"storage_chromadb\" \\\n--extra \"dbgpts\" \\\n--extra \"quant_bnb\" \\\n\n3.uv run dbgpt start webserver --config configs/dbgpt-proxy-ollama.toml \n\n4.Visit localhost:5670. Enter application management, AWEL workflow, create workflow\n\n5. Create a basic dialogue llm workflow.Click Save\n![Image](https://github.com/user-attachments/assets/442f4df4-d416-49db-8f52-3bb1af40f80b)\n\n### Additional context\n\nWhen we create an AWEL workflow in the dbgpt web interface, an error will be reported after adding the LLM processing operation. Similarly, this error will also occur when calling the Demo in the dbgpts community.\n\n![Image](https://github.com/user-attachments/assets/6d7fead2-8b9e-47ca-ae69-a37e46ab57de)\n\n![Image](https://github.com/user-attachments/assets/6ec372e3-3a4f-405b-aca5-2bf8f00529e2)\n\n我们的启动配置如下：dbgpt-proxy-ollama.toml\n[system]\n# Load language from environment variable(It is set by the hook)\nlanguage = \"${env:DBGPT_LANG:-en}\"\napi_keys = []\nencrypt_key = \"your_secret_key\"\n\n# Server Configurations\n[service.web]\nhost = \"0.0.0.0\"\nport = 6006\n\n[service.web.database]\ntype = \"sqlite\"\npath = \"pilot/meta_data/dbgpt.db\"\n\n[rag.storage]\n[rag.storage.vector]\ntype = \"Chroma\"\npersist_path = \"pilot/data\"\n\n# Model Configurations\n[models]\n[[models.llms]]\nname = \"deepseek-r1:1.5b\"\nprovider = \"proxy/ollama\"\napi_base = \"http://localhost:11434\"\napi_key = \"\"\n\n[[models.embeddings]]\nname = \"bge-m3:latest\"\nprovider = \"proxy/ollama\"\napi_url = \"http://localhost:11434\"\napi_key = \"\"\n\n\n我们的完整报错日志如下:\n root@autodl-container-8964458727-765abc2d:~/DB-GPT# uv run dbgpt start webserver --config configs/dbgpt-proxy-ollama.toml \nApplicationConfig(hooks=[], system=SystemParameters(language='en', log_level='INFO', api_keys=[], encrypt_key='your_secret_key'), service=ServiceConfig(web=ServiceWebParameters(host='0.0.0.0', port=6006, light=False, controller_addr=None, database=SQLiteConnectorParameters(path='pilot/meta_data/dbgpt.db', check_same_thread=False, driver='sqlite'), model_storage=None, trace=None, log=None, disable_alembic_upgrade=False, db_ssl_verify=False, default_thread_pool_size=None, remote_embedding=False, remote_rerank=False, awel_dirs=None, new_web_ui=True, model_cache=ModelCacheParameters(enable_model_cache=True, storage_type='memory', max_memory_mb=256, persist_dir='model_cache'), embedding_model_max_seq_len=512), model=ModelServiceConfig(worker=ModelWorkerParameters(host='0.0.0.0', port=8001, daemon=False, log=LoggingParameters(level='INFO', file=None), trace=None, worker_type=None, worker_class=None, standalone=False, register=True, worker_register_host=None, controller_addr=None, send_heartbeat=True, heartbeat_interval=20), api=ModelControllerParameters(host='0.0.0.0', port=8000, daemon=False, log=LoggingParameters(level='INFO', file=None), trace=None, registry=None, heartbeat_interval_secs=20, heartbeat_timeout_secs=60), controller=ModelControllerParameters(host='0.0.0.0', port=8000, daemon=False, log=LoggingParameters(level='INFO', file=None), trace=None, registry=None, heartbeat_interval_secs=20, heartbeat_timeout_secs=60))), models=ModelsDeployParameters(default_llm='deepseek-r1:1.5b', default_embedding='bge-m3:latest', default_reranker=None, llms=[OllamaDeployModelParameters(name='deepseek-r1:1.5b', provider='proxy/ollama', verbose=False, concurrency=5, backend=None, prompt_template=None, context_length=None, reasoning_model=None, api_base='http://localhost:11434')], embeddings=[OllamaEmbeddingDeployModelParameters(name='bge-m3:latest', provider='proxy/ollama', verbose=False, concurrency=100, api_url='http://localhost:11434', backend=None)], rerankers=[]), serves=[], rag=RagParameters(chunk_size=500, chunk_overlap=50, similarity_top_k=10, similarity_score_threshold=0, query_rewrite=False, max_chunks_once_load=10, max_threads=1, rerank_top_k=3, storage=StorageConfig(vector={'type': 'Chroma', 'persist_path': 'pilot/data'}, graph=BuiltinKnowledgeGraphConfig(type='TuGraph', name='dbgpt_collection', embedding_fn=None, max_chunks_once_load=10, max_threads=1, llm_client=None, model_name=None), full_text=BuiltinKnowledgeGraphConfig(type='TuGraph', name='dbgpt_collection', embedding_fn=None, max_chunks_once_load=10, max_threads=1, llm_client=None, model_name=None)), graph_search_top_k=3, graph_community_summary_enabled=False), trace=TracerParameters(file=None, root_operation_name=None, exporter=None, otlp_endpoint=None, otlp_insecure=None, otlp_timeout=None, tracer_storage_cls=None), log=LoggingParameters(level='INFO', file=None))\n2025-03-08 11:10:03 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_unified_metadata_db_manager_factory and instance: <dbgpt.storage.metadata.db_factory.UnifiedDBManagerFactory object at 0x7f6b3169f3d0>\n2025-03-08 11:10:03 autodl-container-8964458727-765abc2d dbgpt.datasource.rdbms.base[8922] INFO Closing RDBMS connector resources...\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_thread_pool_default and instance: <dbgpt.util.executor_utils.DefaultExecutorFactory object at 0x7f6b2cc9d050>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_default_scheduler and instance: <dbgpt_app.initialization.scheduler.DefaultScheduler object at 0x7f6b2d025a50>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_model_controller and instance: <dbgpt.model.cluster.controller.controller.ModelControllerAdapter object at 0x7f6b52643910>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_connector_manager and instance: <dbgpt_serve.datasource.manages.connector_manager.ConnectorManager object at 0x7f6b2d8e8650>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_plugin_hub and instance: <dbgpt_serve.agent.hub.controller.ModulePlugin object at 0x7f6b2ca861d0>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_multi_agents and instance: <dbgpt_serve.agent.agents.controller.MultiAgents object at 0x7f6b2d04c490>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt_app.initialization.embedding_component[8922] INFO Register remote RemoteEmbeddingFactory\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name embedding_factory and instance: <dbgpt_app.initialization.embedding_component.RemoteEmbeddingFactory object at 0x7f6b2d314810>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_model_cache_manager and instance: <dbgpt.storage.cache.manager.LocalCacheManager object at 0x7f6b2d338b50>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_awel_trigger_manager and instance: <dbgpt.core.awel.trigger.trigger_manager.DefaultTriggerManager object at 0x7f6b2c96b850>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_awel_dag_manager and instance: <dbgpt.core.awel.dag.dag_manager.DAGManager object at 0x7f6b2d33a710>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_resource_manager and instance: <dbgpt.agent.resource.manage.ResourceManager object at 0x7f6b2d203350>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_agent_manager and instance: <dbgpt.agent.core.agent_manage.AgentManager object at 0x7f6b2ce676d0>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_app_editor_service and instance: <dbgpt_app.openapi.api_v1.editor.service.EditorService object at 0x7f6b2d169650>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_serve_prompt and instance: <dbgpt_serve.prompt.serve.Serve object at 0x7f6b2d17b190>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_serve_prompt_service and instance: <dbgpt_serve.prompt.service.service.Service object at 0x7f6b2c824890>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_serve_conversation and instance: <dbgpt_serve.conversation.serve.Serve object at 0x7f6b2c82df50>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_serve_conversation_service and instance: <dbgpt_serve.conversation.service.service.Service object at 0x7f6b2c84ac50>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_variables_provider and instance: <dbgpt.core.interface.variables.StorageVariablesProvider object at 0x7f6b2d1c49d0>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_serve_flow and instance: <dbgpt_serve.flow.serve.Serve object at 0x7f6b2d78de50>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_dbgpts_loader and instance: <dbgpt.util.dbgpts.loader.DBGPTsLoader object at 0x7f6b2d7e84d0>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_serve_flow_service and instance: <dbgpt_serve.flow.service.service.Service object at 0x7f6b2d2b1250>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_serve_flow_variables_service and instance: <dbgpt_serve.flow.service.variables_service.VariablesService object at 0x7f6b2d344490>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt.core.flow.flows and instance: <dbgpt_serve.flow.api.variables_provider.BuiltinFlowVariablesProvider object at 0x7f6b2cd12a10>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt.core.flow.nodes and instance: <dbgpt_serve.flow.api.variables_provider.BuiltinNodeVariablesProvider object at 0x7f6b2c972750>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt.core.variables and instance: <dbgpt_serve.flow.api.variables_provider.BuiltinAllVariablesProvider object at 0x7f6b2d8d9a90>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt.core.secrets and instance: <dbgpt_serve.flow.api.variables_provider.BuiltinAllSecretVariablesProvider object at 0x7f6b2c76ef10>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt.core.model.llms and instance: <dbgpt_serve.flow.api.variables_provider.BuiltinLLMVariablesProvider object at 0x7f6b2d1cd0d0>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt.core.model.embeddings and instance: <dbgpt_serve.flow.api.variables_provider.BuiltinEmbeddingsVariablesProvider object at 0x7f6b2d85f890>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt.core.datasources and instance: <dbgpt_serve.flow.api.variables_provider.BuiltinDatasourceVariablesProvider object at 0x7f6b2d0772d0>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt.core.agent.agents and instance: <dbgpt_serve.flow.api.variables_provider.BuiltinAgentsVariablesProvider object at 0x7f6b2d8e9050>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt.core.knowledge_spaces and instance: <dbgpt_serve.flow.api.variables_provider.BuiltinKnowledgeSpacesVariablesProvider object at 0x7f6b2d76d9d0>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_rag and instance: <dbgpt_serve.rag.serve.Serve object at 0x7f6b2c632550>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_rag_service and instance: <dbgpt_serve.rag.service.service.Service object at 0x7f6b2d2a9c10>\n2025-03-08 11:10:04 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_datasource and instance: <dbgpt_serve.datasource.serve.Serve object at 0x7f6b2c4a8190>\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_datasource_service and instance: <dbgpt_serve.datasource.service.service.Service object at 0x7f6b2c34ba50>\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_serve_feedback and instance: <dbgpt_serve.feedback.serve.Serve object at 0x7f6b2c5ef1d0>\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_serve_feedback_service and instance: <dbgpt_serve.feedback.service.service.Service object at 0x7f6b2c381390>\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_serve_dbgpts_hub and instance: <dbgpt_serve.dbgpts.hub.serve.Serve object at 0x7f6b2c382910>\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_serve_dbgpts_hub_service and instance: <dbgpt_serve.dbgpts.hub.service.service.Service object at 0x7f6b2c23a1d0>\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_serve_dbgpts_my and instance: <dbgpt_serve.dbgpts.my.serve.Serve object at 0x7f6b2c4a8350>\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_serve_dbgpts_my_service and instance: <dbgpt_serve.dbgpts.my.service.service.Service object at 0x7f6b2c0da990>\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_serve_file and instance: <dbgpt_serve.file.serve.Serve object at 0x7f6b2c24d050>\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_serve_file_service and instance: <dbgpt_serve.file.service.service.Service object at 0x7f6b2c175210>\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_serve_evaluate and instance: <dbgpt_serve.evaluate.serve.Serve object at 0x7f6b2c7774d0>\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_serve_evaluate_service and instance: <dbgpt_serve.evaluate.service.service.Service object at 0x7f6b275fa4d0>\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_serve_libro and instance: <dbgpt_serve.libro.serve.Serve object at 0x7f6b275faf90>\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_serve_libro_service and instance: <dbgpt_serve.libro.service.service.Service object at 0x7f6b27654f10>\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_serve_model and instance: <dbgpt_serve.model.serve.Serve object at 0x7f6b2c193a90>\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_serve_model_service and instance: <dbgpt_serve.model.service.service.Service object at 0x7f6b27698910>\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name base_dbgpt_component and instance: <dbgpt.util.code.server.CodeServer object at 0x7f6b2c189590>\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.util._db_migration_utils[8922] WARNING Initialize and upgrade database metadata with alembic, just run this in your development environment, if you deploy this in production environment, please run webserver with --disable_alembic_upgrade(`python dbgpt/app/dbgpt_server.py --disable_alembic_upgrade`).\nwe suggest you to use `dbgpt db migration` to initialize and upgrade database metadata with alembic, your can run `dbgpt db migration --help` to get more information.\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d alembic.runtime.migration[8922] INFO Context impl SQLiteImpl.\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d alembic.runtime.migration[8922] INFO Will assume non-transactional DDL.\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.util._db_migration_utils[8922] INFO Migration versions and their file paths:\n========================================Migration versions========================================\n\nc50f56fa37d7 (current): New migration (Path: /root/DB-GPT/pilot/meta_data/alembic/versions/c50f56fa37d7_new_migration.py)\n638eb1a5d9da : New migration (Path: /root/DB-GPT/pilot/meta_data/alembic/versions/638eb1a5d9da_new_migration.py)\nbb5411c9cd4a : New migration (Path: /root/DB-GPT/pilot/meta_data/alembic/versions/bb5411c9cd4a_new_migration.py)\na4dbf2b22030 : New migration (Path: /root/DB-GPT/pilot/meta_data/alembic/versions/a4dbf2b22030_new_migration.py)\ncb75f80de4b7 : New migration (Path: /root/DB-GPT/pilot/meta_data/alembic/versions/cb75f80de4b7_new_migration.py)\n85b6ea711d5c : New migration (Path: /root/DB-GPT/pilot/meta_data/alembic/versions/85b6ea711d5c_new_migration.py)\n509b50f6a81e : New migration (Path: /root/DB-GPT/pilot/meta_data/alembic/versions/509b50f6a81e_new_migration.py)\naa2870207033 : New migration (Path: /root/DB-GPT/pilot/meta_data/alembic/versions/aa2870207033_new_migration.py)\n6a342ca974ed : New migration (Path: /root/DB-GPT/pilot/meta_data/alembic/versions/6a342ca974ed_new_migration.py)\nfca0d51e0d62 : New migration (Path: /root/DB-GPT/pilot/meta_data/alembic/versions/fca0d51e0d62_new_migration.py)\n04c34a754722 : New migration (Path: /root/DB-GPT/pilot/meta_data/alembic/versions/04c34a754722_new_migration.py)\n==========================================================================================\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d alembic.runtime.migration[8922] INFO Context impl SQLiteImpl.\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d alembic.runtime.migration[8922] INFO Will assume non-transactional DDL.\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d alembic.runtime.migration[8922] INFO Context impl SQLiteImpl.\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d alembic.runtime.migration[8922] INFO Will assume non-transactional DDL.\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.util._db_migration_utils[8922] INFO alembic migration current revision: c50f56fa37d7, latest revision: c50f56fa37d7\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d alembic.runtime.migration[8922] INFO Context impl SQLiteImpl.\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d alembic.runtime.migration[8922] INFO Will assume non-transactional DDL.\n  Generating /root/DB-GPT/pilot/meta_data/alembic/versions/b905eac91837_new_migration.py ...  done\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d alembic.runtime.migration[8922] INFO Context impl SQLiteImpl.\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d alembic.runtime.migration[8922] INFO Will assume non-transactional DDL.\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d alembic.runtime.migration[8922] INFO Running upgrade c50f56fa37d7 -> b905eac91837, New migration\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt_app.dbgpt_server[8922] INFO Model Unified Deployment Mode, run all services in the same process\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.model.cluster.worker.manager[8922] INFO Register WorkerManager dbgpt_worker_manager_factory\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.component[8922] INFO Register component with name dbgpt_worker_manager_factory and instance: <dbgpt.model.cluster.worker.manager._DefaultWorkerManagerFactory object at 0x7f6b2c742310>\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.model.cluster.worker.manager[8922] INFO Worker params: \n\n=========================== ModelWorkerParameters ===========================\n\nhost: 0.0.0.0\nport: 6006\ndaemon: False\nlog: \n\n=========================== LoggingParameters ===========================\n\nlevel: INFO\nfile: None\n\n======================================================================\n\n\ntrace: None\nworker_type: None\nworker_class: None\nstandalone: True\nregister: True\nworker_register_host: None\ncontroller_addr: None\nsend_heartbeat: True\nheartbeat_interval: 20\n\n======================================================================\n\n\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.model.cluster.worker.manager[8922] INFO Run WorkerManager with standalone mode, controller_addr: http://127.0.0.1:6006\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.model.adapter.model_adapter[8922] INFO Current model deepseek-r1:1.5b use new adapter <_DynProxyLLMModelAdapter model_name=deepseek-r1:1.5b model_path=None>\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.model.cluster.worker.default_worker[8922] INFO model_name: deepseek-r1:1.5b, model_path: None, model_param_class: <class 'dbgpt.model.proxy.llms.ollama.OllamaDeployModelParameters'>\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.model.cluster.worker.manager[8922] INFO Init empty instances list for deepseek-r1:1.5b@llm\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.model.cluster.worker.manager[8922] INFO Start local embedding worker with embedding parameters\n\n\n=========================== ModelWorkerParameters ===========================\n\nhost: 0.0.0.0\nport: 8001\ndaemon: False\nlog: \n\n=========================== LoggingParameters ===========================\n\nlevel: ${env:DBGPT_LOG_LEVEL:-INFO}\nfile: None\n\n======================================================================\n\n\ntrace: None\nworker_type: text2vec\nworker_class: None\nstandalone: False\nregister: True\nworker_register_host: None\ncontroller_addr: None\nsend_heartbeat: True\nheartbeat_interval: 20\n\n======================================================================\n\n\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.model.cluster.worker.manager[8922] INFO Init empty instances list for bge-m3:latest@text2vec\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.util.api_utils[8922] WARNING Health check failed for http://127.0.0.1:6006, error: HTTPConnectionPool(host='127.0.0.1', port=6006): Max retries exceeded with url: /api/health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6b2c1a0290>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.util.dbgpts.loader[8922] INFO Found 1 dbgpts packages from /root/.dbgpts/packages/24f65127dcfc1f3fbc75981674fba4e4\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt_serve.flow.service.compat_service[8922] INFO Found compat file: 0.7.0, use latest: 0.7.0\nINFO:     Started server process [8922]\nINFO:     Waiting for application startup.\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.core.awel.dag.loader[8922] INFO Importing /root/DB-GPT/examples/awel/awel_flow_ui_components.py\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.core.awel.dag.loader[8922] INFO Importing /root/DB-GPT/examples/awel/data_analyst_assistant.py\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.core.awel.dag.loader[8922] INFO Found dag DAG(dag_id=dbgpt_awel_data_analyst_assistant) from mod <module 'unusual_prefix_fbe42a1bcade349cf20c126841b41352baabb778_data_analyst_assistant' from '/root/DB-GPT/examples/awel/data_analyst_assistant.py'> and model file /root/DB-GPT/examples/awel/data_analyst_assistant.py\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.core.awel.dag.loader[8922] INFO Importing /root/DB-GPT/examples/awel/simple_chat_dag_example.py\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.core.awel.dag.loader[8922] INFO Found dag DAG(dag_id=dbgpt_awel_simple_dag_example) from mod <module 'unusual_prefix_c12a4d777cfc9b9ac585d737997cf1e58f4f28fe_simple_chat_dag_example' from '/root/DB-GPT/examples/awel/simple_chat_dag_example.py'> and model file /root/DB-GPT/examples/awel/simple_chat_dag_example.py\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.core.awel.dag.loader[8922] INFO Importing /root/DB-GPT/examples/awel/simple_chat_history_example.py\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.core.awel.dag.loader[8922] INFO Found dag DAG(dag_id=dbgpt_awel_simple_chat_history) from mod <module 'unusual_prefix_27b694e572b127b1c0d3c0a2e4ef43e526e7bb5b_simple_chat_history_example' from '/root/DB-GPT/examples/awel/simple_chat_history_example.py'> and model file /root/DB-GPT/examples/awel/simple_chat_history_example.py\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.core.awel.dag.loader[8922] INFO Importing /root/DB-GPT/examples/awel/simple_dag_example.py\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.core.awel.dag.loader[8922] INFO Found dag DAG(dag_id=simple_dag_example) from mod <module 'unusual_prefix_48383d9597a7353e14e91a0bcb223cfb6fdc4690_simple_dag_example' from '/root/DB-GPT/examples/awel/simple_dag_example.py'> and model file /root/DB-GPT/examples/awel/simple_dag_example.py\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.core.awel.dag.loader[8922] INFO Importing /root/DB-GPT/examples/awel/simple_llm_client_example.py\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.core.awel.dag.loader[8922] INFO Found dag DAG(dag_id=dbgpt_awel_simple_llm_client_generate) from mod <module 'unusual_prefix_0b0fc919c1d88237260ad0cb95c4f84351ef6942_simple_llm_client_example' from '/root/DB-GPT/examples/awel/simple_llm_client_example.py'> and model file /root/DB-GPT/examples/awel/simple_llm_client_example.py\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.core.awel.dag.loader[8922] INFO Found dag DAG(dag_id=dbgpt_awel_simple_llm_client_count_token) from mod <module 'unusual_prefix_0b0fc919c1d88237260ad0cb95c4f84351ef6942_simple_llm_client_example' from '/root/DB-GPT/examples/awel/simple_llm_client_example.py'> and model file /root/DB-GPT/examples/awel/simple_llm_client_example.py\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.core.awel.dag.loader[8922] INFO Importing /root/DB-GPT/examples/awel/simple_nl_schema_sql_chart_example.py\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.core.awel.dag.loader[8922] ERROR Failed to import: /root/DB-GPT/examples/awel/simple_nl_schema_sql_chart_example.py, error message: Traceback (most recent call last):\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/core/awel/dag/loader.py\", line 91, in parse\n    loader.exec_module(new_module)\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"/root/DB-GPT/examples/awel/simple_nl_schema_sql_chart_example.py\", line 235, in <module>\n    llm = OpenAILLMClient()\n          ^^^^^^^^^^^^^^^^^\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/proxy/llms/chatgpt.py\", line 178, in __init__\n    _ = self.client.default_headers\n        ^^^^^^^^^^^\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/proxy/llms/chatgpt.py\", line 229, in client\n    self._api_type, self._client = _build_openai_client(\n                                   ^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/utils/chatgpt_utils.py\", line 103, in _build_openai_client\n    openai_params, api_type, api_version, api_azure_deployment = _initialize_openai_v1(\n                                                                 ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/utils/chatgpt_utils.py\", line 90, in _initialize_openai_v1\n    raise ValueError(\"api_key is required, please set OPENAI_API_KEY environment\")\nValueError: api_key is required, please set OPENAI_API_KEY environment\n\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.core.awel.dag.loader[8922] INFO Importing /root/DB-GPT/examples/awel/simple_rag_rewrite_example.py\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.core.awel.dag.loader[8922] ERROR Failed to import: /root/DB-GPT/examples/awel/simple_rag_rewrite_example.py, error message: Traceback (most recent call last):\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/core/awel/dag/loader.py\", line 91, in parse\n    loader.exec_module(new_module)\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"/root/DB-GPT/examples/awel/simple_rag_rewrite_example.py\", line 64, in <module>\n    rewrite_task = QueryRewriteOperator(llm_client=OpenAILLMClient(), nums=2)\n                                                   ^^^^^^^^^^^^^^^^^\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/proxy/llms/chatgpt.py\", line 178, in __init__\n    _ = self.client.default_headers\n        ^^^^^^^^^^^\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/proxy/llms/chatgpt.py\", line 229, in client\n    self._api_type, self._client = _build_openai_client(\n                                   ^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/utils/chatgpt_utils.py\", line 103, in _build_openai_client\n    openai_params, api_type, api_version, api_azure_deployment = _initialize_openai_v1(\n                                                                 ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/utils/chatgpt_utils.py\", line 90, in _initialize_openai_v1\n    raise ValueError(\"api_key is required, please set OPENAI_API_KEY environment\")\nValueError: api_key is required, please set OPENAI_API_KEY environment\n\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.core.awel.dag.loader[8922] INFO Importing /root/DB-GPT/examples/awel/simple_rag_summary_example.py\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.core.awel.dag.loader[8922] ERROR Failed to import: /root/DB-GPT/examples/awel/simple_rag_summary_example.py, error message: Traceback (most recent call last):\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/core/awel/dag/loader.py\", line 91, in parse\n    loader.exec_module(new_module)\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"/root/DB-GPT/examples/awel/simple_rag_summary_example.py\", line 65, in <module>\n    llm_client=OpenAILLMClient(), language=\"en\"\n               ^^^^^^^^^^^^^^^^^\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/proxy/llms/chatgpt.py\", line 178, in __init__\n    _ = self.client.default_headers\n        ^^^^^^^^^^^\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/proxy/llms/chatgpt.py\", line 229, in client\n    self._api_type, self._client = _build_openai_client(\n                                   ^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/utils/chatgpt_utils.py\", line 103, in _build_openai_client\n    openai_params, api_type, api_version, api_azure_deployment = _initialize_openai_v1(\n                                                                 ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/utils/chatgpt_utils.py\", line 90, in _initialize_openai_v1\n    raise ValueError(\"api_key is required, please set OPENAI_API_KEY environment\")\nValueError: api_key is required, please set OPENAI_API_KEY environment\n\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.trigger_manager[8922] INFO Register trigger HttpTrigger(node_id=66e941df-4c5d-42b9-a4e7-f169ea191049)\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.http_trigger[8922] INFO mount router function <function HttpTrigger._create_route_func.<locals>.create_route_function.<locals>.route_function at 0x7f6b1cbc3880>(AWEL_trigger_route__examples_data_analyst_copilot), endpoint: /examples/data_analyst/copilot, methods: ['POST']\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.http_trigger[8922] INFO Mount http trigger success, path: /api/v1/awel/trigger/examples/data_analyst/copilot\n2025-03-08 11:10:05 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.trigger_manager[8922] INFO Include router <fastapi.routing.APIRouter object at 0x7f6b2cb098d0> to prefix path /api/v1/awel/trigger\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.trigger_manager[8922] INFO Register trigger HttpTrigger(node_id=2bc8ffbe-92b6-4678-b608-d8362a4b4afd)\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.http_trigger[8922] INFO mount router function <function HttpTrigger._create_route_func.<locals>.create_route_function.<locals>.route_function at 0x7f6b1cc140e0>(AWEL_trigger_route__examples_simple_chat), endpoint: /examples/simple_chat, methods: ['POST']\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.http_trigger[8922] INFO Mount http trigger success, path: /api/v1/awel/trigger/examples/simple_chat\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.trigger_manager[8922] INFO Include router <fastapi.routing.APIRouter object at 0x7f6b2cb098d0> to prefix path /api/v1/awel/trigger\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.trigger_manager[8922] INFO Register trigger HttpTrigger(node_id=e091e371-1c0f-4cfc-8891-97605ea54d30)\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.http_trigger[8922] INFO mount router function <function HttpTrigger._create_route_func.<locals>.create_route_function.<locals>.route_function at 0x7f6b1cc14900>(AWEL_trigger_route__examples_simple_history_multi_round_chat_completions), endpoint: /examples/simple_history/multi_round/chat/completions, methods: ['POST']\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.http_trigger[8922] INFO Mount http trigger success, path: /api/v1/awel/trigger/examples/simple_history/multi_round/chat/completions\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.trigger_manager[8922] INFO Include router <fastapi.routing.APIRouter object at 0x7f6b2cb098d0> to prefix path /api/v1/awel/trigger\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.trigger_manager[8922] INFO Register trigger HttpTrigger(node_id=a378f17b-a91c-4a7f-bcc5-ce1399976b3a)\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.http_trigger[8922] INFO mount router function <function HttpTrigger._create_route_func.<locals>.create_route_function.<locals>.route_function_get at 0x7f6b1cc15800>(AWEL_trigger_route__examples_hello), endpoint: /examples/hello, methods: ['GET']\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.http_trigger[8922] INFO Mount http trigger success, path: /api/v1/awel/trigger/examples/hello\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.trigger_manager[8922] INFO Include router <fastapi.routing.APIRouter object at 0x7f6b2cb098d0> to prefix path /api/v1/awel/trigger\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.trigger_manager[8922] INFO Register trigger HttpTrigger(node_id=bdd4c1d8-a939-4ab0-ac56-4e19b1fd4c3f)\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.http_trigger[8922] INFO mount router function <function HttpTrigger._create_route_func.<locals>.create_route_function.<locals>.route_function at 0x7f6b1cc15d00>(AWEL_trigger_route__examples_simple_client_chat_completions), endpoint: /examples/simple_client/chat/completions, methods: ['POST']\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.http_trigger[8922] INFO Mount http trigger success, path: /api/v1/awel/trigger/examples/simple_client/chat/completions\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.trigger_manager[8922] INFO Include router <fastapi.routing.APIRouter object at 0x7f6b2cb098d0> to prefix path /api/v1/awel/trigger\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.trigger_manager[8922] INFO Register trigger HttpTrigger(node_id=e3c1848a-c066-4096-b41a-c478c2fa9018)\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.http_trigger[8922] INFO mount router function <function HttpTrigger._create_route_func.<locals>.create_route_function.<locals>.route_function at 0x7f6b1cc163e0>(AWEL_trigger_route__examples_simple_client_count_token), endpoint: /examples/simple_client/count_token, methods: ['POST']\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.http_trigger[8922] INFO Mount http trigger success, path: /api/v1/awel/trigger/examples/simple_client/count_token\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.trigger_manager[8922] INFO Include router <fastapi.routing.APIRouter object at 0x7f6b2cb098d0> to prefix path /api/v1/awel/trigger\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.trigger_manager[8922] INFO Register trigger CommonLLMHttpTrigger(node_id=d77eb9c0-b17a-4d8a-b0e9-0b007909ba5e, node_name=operator_common_llm_http_trigger___$$___trigger___$$___v1_0)\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.http_trigger[8922] INFO mount router function <function HttpTrigger._create_route_func.<locals>.create_route_function.<locals>.route_function at 0x7f6b1ca623e0>(AWEL_trigger_route__example_{dag_id}), endpoint: /example/{dag_id}, methods: ['POST']\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.http_trigger[8922] INFO Mount http trigger success, path: /api/v1/awel/trigger/example/flow_dag_test_e6f1365f-7593-49f4-b980-a97847181b2d\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.trigger_manager[8922] INFO Include router <fastapi.routing.APIRouter object at 0x7f6b2cb098d0> to prefix path /api/v1/awel/trigger\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt_serve.flow.service.service[8922] WARNING Unregister DAG(dbgpts_all_in_one_entrance_intent_detection_dag) error: Unregister DAG error, DAG ID dbgpts_all_in_one_entrance_intent_detection_dag does not exist\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.trigger_manager[8922] INFO Register trigger CommonLLMHttpTrigger(node_id=3c4dd107-dd88-420b-ab63-a87285bc182e)\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.http_trigger[8922] INFO mount router function <function HttpTrigger._create_route_func.<locals>.create_route_function.<locals>.route_function at 0x7f6b1cb171a0>(AWEL_trigger_route__dbgpts_all-in-one-entrance), endpoint: /dbgpts/all-in-one-entrance, methods: ['POST']\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.http_trigger[8922] INFO Mount http trigger success, path: /api/v1/awel/trigger/dbgpts/all-in-one-entrance\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.core.awel.trigger.trigger_manager[8922] INFO Include router <fastapi.routing.APIRouter object at 0x7f6b2cb098d0> to prefix path /api/v1/awel/trigger\nLibro Server start!\nstart libro exception！[Errno 2] No such file or directory: 'libro'\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.model.cluster.worker.manager[8922] INFO Begin start all worker, apply_req: None\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.model.cluster.worker.manager[8922] INFO Apply req: None, apply_func: <function LocalWorkerManager._start_all_worker.<locals>._start_worker at 0x7f6b1cb519e0>\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.model.cluster.worker.manager[8922] INFO Apply to all workers\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://0.0.0.0:6006 (Press CTRL+C to quit)\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.model.cluster.worker.default_worker[8922] INFO Begin load model, model params: \n\n=========================== OllamaDeployModelParameters ===========================\n\nname: deepseek-r1:1.5b\nprovider: proxy/ollama\nverbose: False\nconcurrency: 5\nbackend: None\nprompt_template: None\ncontext_length: None\nreasoning_model: None\napi_base: http://localhost:11434\n\n======================================================================\n\n\n2025-03-08 11:10:06 autodl-container-8964458727-765abc2d dbgpt.model.adapter.proxy_adapter[8922] INFO Load model from params: \n\n=========================== OllamaDeployModelParameters ===========================\n\nname: deepseek-r1:1.5b\nprovider: proxy/ollama\nverbose: False\nconcurrency: 5\nbackend: None\nprompt_template: None\ncontext_length: None\nreasoning_model: None\napi_base: http://localhost:11434\n\n======================================================================\n\nllm client class: <class 'dbgpt.model.proxy.llms.ollama.OllamaLLMClient'>\n2025-03-08 11:10:08 autodl-container-8964458727-765abc2d dbgpt.util.api_utils[8922] WARNING No healthy urls found, selecting randomly\nINFO:     127.0.0.1:38812 - \"POST /api/controller/models HTTP/1.1\" 200 OK\n2025-03-08 11:10:08 autodl-container-8964458727-765abc2d dbgpt.model.cluster.worker.embedding_worker[8922] INFO Load embeddings model: bge-m3:latest\n2025-03-08 11:10:10 autodl-container-8964458727-765abc2d dbgpt.util.api_utils[8922] WARNING No healthy urls found, selecting randomly\n2025-03-08 11:10:10 autodl-container-8964458727-765abc2d dbgpt.util.api_utils[8922] WARNING No healthy urls found, selecting randomly\nINFO:     127.0.0.1:38918 - \"POST /api/controller/models HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:34802 - \"POST /api/controller/models HTTP/1.1\" 200 OK\n2025-03-08 11:10:10 autodl-container-8964458727-765abc2d dbgpt.model.cluster.worker.manager[8922] INFO There has model storage, start the model from storage\nbegin run _add_app_startup_event\n2025-03-08 11:10:11 autodl-container-8964458727-765abc2d dbgpt.util.code.server[8922] INFO Code server is ready\nINFO:     127.0.0.1:34892 - \"GET /api/v2/serve/awel/flows?page=1&page_size=12 HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:34892 - \"GET /api/v2/serve/awel/flows/e6f1365f-7593-49f4-b980-a97847181b2d HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:34944 - \"GET /api/v2/serve/awel/variables/keys HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:34928 - \"GET /api/v2/serve/awel/nodes?tags=%7B%22order%22:%22higher-order%22%7D HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:34958 - \"GET /api/v2/serve/awel/flow/templates HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:40504 - \"PUT /api/v2/serve/awel/flows/e6f1365f-7593-49f4-b980-a97847181b2d HTTP/1.1\" 200 OK\n\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "Goldenringz",
      "author_type": "User",
      "created_at": "2025-03-08T03:35:32Z",
      "updated_at": "2025-03-14T01:18:22Z",
      "closed_at": "2025-03-14T01:18:22Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2418/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2418",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2418",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:38.289283",
      "comments": [
        {
          "author": "ghao123",
          "body": "same problem",
          "created_at": "2025-03-12T15:12:41Z"
        }
      ]
    },
    {
      "issue_number": 2114,
      "title": "[Bug] [examples] agents example export errors:  Type List cannot be instantiated; use list() instead",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [X] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\ncpu\n\n### Models information\n\nLLM: qwen1.5    embedding: nomic\n\n### What happened\n\nagents examples errors:  \r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\git_idea\\DB-GPT\\examples\\agents\\plugin_agent_dialogue_example.py\", line 64, in <module>\r\n    asyncio.run(main())\r\n  File \"C:\\ProgramData\\miniconda3\\envs\\dbgpt_env\\lib\\asyncio\\runners.py\", line 44, in run\r\n    return loop.run_until_complete(main)\r\n  File \"C:\\ProgramData\\miniconda3\\envs\\dbgpt_env\\lib\\asyncio\\base_events.py\", line 649, in run_until_complete\r\n    return future.result()\r\n  File \"D:\\git_idea\\DB-GPT\\examples\\agents\\plugin_agent_dialogue_example.py\", line 53, in main\r\n    await user_proxy.initiate_chat(\r\n  File \"D:\\git_idea\\DB-GPT\\dbgpt\\agent\\core\\base_agent.py\", line 651, in initiate_chat\r\n    await self.send(\r\n  File \"D:\\git_idea\\DB-GPT\\dbgpt\\agent\\core\\base_agent.py\", line 226, in send\r\n    await recipient.receive(\r\n  File \"D:\\git_idea\\DB-GPT\\dbgpt\\agent\\core\\base_agent.py\", line 263, in receive\r\n    await self._a_process_received_message(message, sender)\r\n  File \"D:\\git_idea\\DB-GPT\\dbgpt\\agent\\core\\base_agent.py\", line 770, in _a_process_received_message\r\n    valid = await self._a_append_message(message, None, sender)\r\n  File \"D:\\git_idea\\DB-GPT\\dbgpt\\agent\\core\\base_agent.py\", line 724, in _a_append_message\r\n    await self.memory.gpts_memory.append_message(\r\n  File \"D:\\git_idea\\DB-GPT\\dbgpt\\agent\\core\\memory\\gpts\\gpts_memory.py\", line 122, in append_message\r\n    self.messages_cache[conv_id].append(message)\r\n  File \"C:\\ProgramData\\miniconda3\\envs\\dbgpt_env\\lib\\typing.py\", line 955, in __call__\r\n    raise TypeError(f\"Type {self._name} cannot be instantiated; \"\r\nTypeError: Type List cannot be instantiated; use list() instead\n\n### What you expected to happen\n\n正常执行\n\n### How to reproduce\n\n执行 agents/下的examples\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "maco6096",
      "author_type": "User",
      "created_at": "2024-11-01T08:06:46Z",
      "updated_at": "2025-03-13T21:05:15Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2114/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2114",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2114",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:38.501255",
      "comments": [
        {
          "author": "cinjoseph",
          "body": "i got the same problem ， do you fix it？",
          "created_at": "2024-11-13T02:13:46Z"
        },
        {
          "author": "cinjoseph",
          "body": "try this.  modify agent memory code as below\r\n\r\n![image](https://github.com/user-attachments/assets/9023f536-007f-4913-978c-fde213f02e91)\r\n",
          "created_at": "2024-11-13T06:44:44Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-03-13T21:05:14Z"
        }
      ]
    },
    {
      "issue_number": 2123,
      "title": "[Doc]  how to support multiple embedding models  in different app scenes?",
      "body": "### Search before asking\r\n\r\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\r\n\r\n\r\n### Description\r\n\r\n i want to use different embedding models  in different  scenes, couldn't find it  how to do it in ref  doc ,  will u support this function in future？if not，could u tell me where i can change it if i want to  change code ?  thank u  :)\r\n\r\n### Documentation Links\r\n\r\n_No response_\r\n\r\n### Are you willing to submit PR?\r\n\r\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "chuangzhidan",
      "author_type": "User",
      "created_at": "2024-11-12T04:58:44Z",
      "updated_at": "2025-03-13T21:05:14Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2123/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2123",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2123",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:38.728289",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "good suggestion, now knowledge space serve support only one embedding model, we will support specifying different embedding models in the knowledge space soon.",
          "created_at": "2024-11-12T06:48:04Z"
        },
        {
          "author": "chuangzhidan",
          "body": "> good suggestion, now knowledge space serve support only one embedding model, we will support specifying different embedding models in the knowledge space soon.\r\n\r\nsupport different scenes such as  chat_bi / chat_data  /chat_knoledge?",
          "created_at": "2024-11-12T11:24:04Z"
        },
        {
          "author": "Aries-ckt",
          "body": "Currently, it is true that different applications in the embedding project can only use one embedding model.so we will consider to support different embedding model in the future.",
          "created_at": "2024-11-13T01:52:09Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-03-13T21:05:13Z"
        }
      ]
    },
    {
      "issue_number": 2125,
      "title": "[Doc][Module Name] Documentation bug or improvement",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n关于DB-GPT 启动 text2vec 服务，底层是否有对并发进行线程，当并发达到超过5 或者 6的时候显存就不再增加了\n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "luo7297605",
      "author_type": "User",
      "created_at": "2024-11-13T05:55:02Z",
      "updated_at": "2025-03-13T21:05:12Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2125/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2125",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2125",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:38.926305",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-03-13T21:05:11Z"
        }
      ]
    },
    {
      "issue_number": 2459,
      "title": "[Bug] [Module Name] Bug title 为什么一定要SILICONFLOW_API_KEY这个啊",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n![Image](https://github.com/user-attachments/assets/9a19c293-8e3d-46cb-8044-707337fd03b3)\n按照README配置了，为什么还要硅基流动的APIKEY呢，用本地自己启动的模型不行吗？\n\n### Models information\n\nopenai格式的模型，向量模型为本地\n\n### What happened\n\n上传excel文件，问答时候报错\n\n### What you expected to happen\n\n不清楚，感觉不应该出错才对\n\n### How to reproduce\n\n参考我上传的配置文件\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "xsun15",
      "author_type": "User",
      "created_at": "2025-03-13T10:10:52Z",
      "updated_at": "2025-03-13T15:27:00Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2459/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2459",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2459",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:39.360882",
      "comments": [
        {
          "author": "fangyinc",
          "body": "Please refer to the latest [document](http://docs.dbgpt.cn/docs/installation/docker) for deployment",
          "created_at": "2025-03-13T15:26:59Z"
        }
      ]
    },
    {
      "issue_number": 2460,
      "title": "[Bug] [Module Name] error when start rerank model",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [x] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nA30*2\n\n### Models information\n\nembedding：bge-large-zh\nrerank：bge-rerank-large\n\n### What happened\n\n模型管理中提交加载rerank模型报错：model start failed No worker instance found for the model bge-reranker-large worker type text2vec\n\n![Image](https://github.com/user-attachments/assets/9d4167e2-e710-483e-9cd3-6debfa8418b3)\n\n### What you expected to happen\n\n加载rerank模型\n\n### How to reproduce\n\n。\n\n### Additional context\n\n![Image](https://github.com/user-attachments/assets/d791ccdf-5a9e-41d6-9fdd-7f019626f5e4)\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "liuyu970321",
      "author_type": "User",
      "created_at": "2025-03-13T14:46:11Z",
      "updated_at": "2025-03-13T15:25:03Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2460/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2460",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2460",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:39.514669",
      "comments": [
        {
          "author": "fangyinc",
          "body": "Hi @liuyu970321, thanks for you feedback.\nSorry, I can't reproduce this problem, please provide more information (screenshots or background logs)",
          "created_at": "2025-03-13T15:24:08Z"
        }
      ]
    },
    {
      "issue_number": 2452,
      "title": "[Bug] [dbgpt-openai] docker-compose up run error",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [x] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU: 4C8G\n\n### Models information\n\nLLM: deepseek\nEmbeding: text2vec-large-chinese\n\n### What happened\n\nchange docker-compose.yml\n```\ncommand: dbgpt start webserver --config /app/configs/dbgpt-proxy-deepseek.toml\n```\nand change dbgpt-proxy-deepseek.toml, use local embedding model\n```\n[[models.embeddings]]\nname = \"text2vec-large-chinese\"\nprovider = \"hf\"\n# If not provided, the model will be downloaded from the Hugging Face model hub\n# uncomment the following line to specify the model path in the local file system\n# path = \"the-model-path-in-the-local-file-system\"\npath = \"/app/models/text2vec-large-chinese\"\n```\n\nthen, run docker-compose up -d, get an error\n```\n2025-03-13 03:03:08 b1f8e49b3eec dbgpt.model.cluster.worker.manager[1] ERROR Error starting worker manager: model deepseek-reasoner@proxy/deepseek(172.18.0.3:5670) start successfully\n;model text2vec-large-chinese@hf(172.18.0.3:5670) start failed, Traceback (most recent call last):\n  File \"/app/packages/dbgpt-core/src/dbgpt/rag/embedding/embeddings.py\", line 204, in __init__\n    import sentence_transformers\nModuleNotFoundError: No module named 'sentence_transformers'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/cluster/worker/manager.py\", line 631, in _start_worker\n    await self.run_blocking_func(\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/cluster/worker/manager.py\", line 146, in run_blocking_func\n    return await loop.run_in_executor(self.executor, func, *args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/cluster/worker/embedding_worker.py\", line 84, in start\n    self._embeddings_impl = self._adapter.load_from_params(self._model_params)\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/model/adapter/base.py\", line 829, in load_from_params\n    return model_adapter_cls.from_parameters(params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/rag/embedding/embeddings.py\", line 228, in from_parameters\n    return cls(\n           ^^^^\n  File \"/app/packages/dbgpt-core/src/dbgpt/rag/embedding/embeddings.py\", line 207, in __init__\n    raise ImportError(\nImportError: Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`.\n\n```\n\n\n### What you expected to happen\n\nrun success\n\n### How to reproduce\n\n.\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "dobet",
      "author_type": "User",
      "created_at": "2025-03-13T03:17:42Z",
      "updated_at": "2025-03-13T08:33:04Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2452/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2452",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2452",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:39.728803",
      "comments": [
        {
          "author": "dobet",
          "body": "sentence_transformers is not install by uv",
          "created_at": "2025-03-13T06:25:10Z"
        },
        {
          "author": "fangyinc",
          "body": "The docker`eosphorosai/dbgpt-openai` not support local model. Please try `eosphorosai/dbgpt`",
          "created_at": "2025-03-13T08:33:00Z"
        }
      ]
    },
    {
      "issue_number": 2426,
      "title": "[Bug] Chat历史清除，并不会真正的清除所有对话历史。",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nIt has nothing to do with this\n\n### Models information\n\nIt has nothing to do with this\n\n### What happened\n\nIt has nothing to do with this\n\n### What you expected to happen\n\nIt has nothing to do with this\n\n### How to reproduce\n\nIt has nothing to do with this\n\n### Additional context\n\n<img width=\"310\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/98273537-a976-4d8b-a66f-1a48d559f29c\" />\n\n<img width=\"383\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/4b5a414e-caa6-4df3-8501-8941baa8da69\" />\n\n问题复现很简单 我现在就是清除了历史 就是聊天窗口那个扫地的图表，后问同样的问题 虽然会展示图一 但只要刷新一下就会显示图二。所以这个清楚并不是真正的清除。如何修复或解决 真正的清除 我并不想要之前的聊天记录了。\n下述我附带我修改的过程。\n\n[20250310.xlsx](https://github.com/user-attachments/files/19155030/20250310.xlsx)\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "15089677014",
      "author_type": "User",
      "created_at": "2025-03-10T03:37:13Z",
      "updated_at": "2025-03-13T06:43:35Z",
      "closed_at": "2025-03-13T06:43:35Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2426/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2426",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2426",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:39.932189",
      "comments": [
        {
          "author": "15089677014",
          "body": "发现是因为 \n\n![Image](https://github.com/user-attachments/assets/e9309509-8e09-4933-8bbe-b2af77df45b9)\n的数据清扫功能只会清扫chat history 和 chat_history_message 不会清楚 gpts_messages 麻烦修复下",
          "created_at": "2025-03-10T07:48:19Z"
        },
        {
          "author": "15089677014",
          "body": "已修复\n\n<!-- Failed to upload \"image.png\" -->",
          "created_at": "2025-03-10T11:45:49Z"
        }
      ]
    },
    {
      "issue_number": 2453,
      "title": "[Bug] [Datasource] Unable to add starrocks data source",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [x] Chat Data\n- [ ] Chat Excel\n- [x] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\n[models]\n[[models.llms]]\nname = \"Qwen/QwQ-32B\"\nprovider = \"proxy/siliconflow\"\n\n[[models.embeddings]]\nname = \"BAAI/bge-large-zh-v1.5\"\nprovider = \"hf\"\n\n### What happened\n\nIn the data source module, click Add Starrocks Database, fill in the relevant connection configuration, and click Save to report an error: Test connection Failure!No module named 'dbgpt.datasource.rdbms.dialect'\n\n### What you expected to happen\n\nThe starrocks data source can be successfully added\n\n### How to reproduce\n\nIn the data source module, click Add Starrocks Database, fill in the relevant connection configuration, and click Save to report an error: Test connection Failure!No module named 'dbgpt.datasource.rdbms.dialect'\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "vnicers",
      "author_type": "User",
      "created_at": "2025-03-13T03:21:27Z",
      "updated_at": "2025-03-13T04:52:15Z",
      "closed_at": "2025-03-13T04:52:15Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2453/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2453",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2453",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:40.147939",
      "comments": []
    },
    {
      "issue_number": 2455,
      "title": "[Bug] [Workflow] change to version 0.6.2",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [x] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n4GPU-A10G\n\n### Models information\n\nQwQ-32B\n\n### What happened\n\nVersion 0.7 has too many bugs. I want to change to version 0.6.2. Do I just need to reinstall it in the environment? Do I need to re-download the previous source code?\n\n### What you expected to happen\n\nTell me what to do next\n\n### How to reproduce\n\nTell me what to do next\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "JasonJiang1208",
      "author_type": "User",
      "created_at": "2025-03-13T03:31:01Z",
      "updated_at": "2025-03-13T03:33:25Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2455/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2455",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2455",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:40.147959",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "```\n- git tag\n- git checkout v0.6.2\n- restart your dbgpt server\n```",
          "created_at": "2025-03-13T03:33:24Z"
        }
      ]
    },
    {
      "issue_number": 2454,
      "title": "[Bug] [Module Name] 编辑提示词时，输出结构无法回显",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [x] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [x] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU 24*4\n\n### Models information\n\nLLM: qwen-max\n\n### What happened\n\n编写完提示词后，再点击编辑进来时，提示词无法回显，输出结构\n\n![Image](https://github.com/user-attachments/assets/6c6b09eb-b77c-480c-a8ac-19a5f5214a7e)\n\n### What you expected to happen\n\n提示词回显输出结构\n\n### How to reproduce\n\n1、新建提示词保存\n2、编辑刚才新建后的提示词，可以看到 右边没有回显前面保存的输出结构\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "maoyongjun2025",
      "author_type": "User",
      "created_at": "2025-03-13T03:24:10Z",
      "updated_at": "2025-03-13T03:24:10Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2454/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2454",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2454",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:40.324139",
      "comments": []
    },
    {
      "issue_number": 2445,
      "title": "[Bug] [Module Name]  docker build 镜像时，dbgpt-acc-auto/pyproject.toml 提示licence文件不正确",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU  24*4\n\n### Models information\n\nLLM: qwen\n\n\n\n### What happened\n\ndocker build 镜像时，dbgpt-acc-auto/pyproject.toml  提示licence文件不正确。去掉了license = \"MIT\"之后才可以正常安装。\n\n![Image](https://github.com/user-attachments/assets/dcaf2839-cb43-4781-b14b-ccd7a3b644c8)\n\n\n\n\n### What you expected to happen\n\n000\n\n### How to reproduce\n\nbash docker/build_all_images.sh \\\n--base-image nvidia/cuda:11.8.0-runtime-ubuntu22.04 \\\n--pip-index-url https://pypi.tuna.tsinghua.edu.cn/simple \\\n--language zh\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "maoyongjun2025",
      "author_type": "User",
      "created_at": "2025-03-12T01:55:45Z",
      "updated_at": "2025-03-13T03:20:16Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2445/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2445",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2445",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:40.324152",
      "comments": []
    },
    {
      "issue_number": 2450,
      "title": "[Bug] [uv] pytorch能否不通过https://download.pytorch.org/whl/cp下载？",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\npytorch能否不通过网址下载？\n\n### Models information\n\nproxy/deepseek\n\n### What happened\n\n内网环境，无法连接到https://download.pytorch.org/whl/cpu\n\n### What you expected to happen\n\n能够通过其他方式下载pytorch\n\n### How to reproduce\n\n...\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "dobet",
      "author_type": "User",
      "created_at": "2025-03-12T14:49:36Z",
      "updated_at": "2025-03-13T01:47:11Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2450/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2450",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2450",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:40.324156",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "try use https://pypi.tuna.tsinghua.edu.cn/simple",
          "created_at": "2025-03-12T15:13:20Z"
        },
        {
          "author": "dobet",
          "body": "> try use https://pypi.tuna.tsinghua.edu.cn/simple\n\nuse this url, get error:\n```\nx No solution found when resolving dependencies for split (sys_platform == 'win32'):\n  `-> Because aiohttp was not found in the package registry and dbgpt depends on aiohttp==3.8.4, we can conclude that dbgpt's requirem",
          "created_at": "2025-03-13T01:47:10Z"
        }
      ]
    },
    {
      "issue_number": 2087,
      "title": "[Doc][Module Name] Communication implementation with GraphRAG",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n我 pdb 了 GraphRAG 相关源码。\r\n在  db-gpt 的实现里\r\n\r\n1. 会把  raw chunk 改写成一个 “基于图谱” 总结的 summary，并且把这个 summary 重新作为 chunk 提取 embedding\r\n2. 把 raw chunk 存到 sql\r\n\r\n检索期间用 summary_chunk。\r\n\r\n我的问题是，检索期间用 summary_chunk 还是用 raw_chunk，有客观精度 / 主观经验对比么？\n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "tpoisonooo",
      "author_type": "User",
      "created_at": "2024-10-22T11:15:12Z",
      "updated_at": "2025-03-12T21:05:11Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2087/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2087",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2087",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:40.488280",
      "comments": [
        {
          "author": "tpoisonooo",
          "body": "纯抬杠：如果是个文学类的知识库，满口之乎者也... 似乎是影响精度的。",
          "created_at": "2024-10-22T11:18:45Z"
        },
        {
          "author": "Appointat",
          "body": "Hi @tpoisonooo , could you please show me the code about it ? :\r\n\"\r\n会把 raw chunk 改写成一个 “基于图谱” 总结的 summary，并且把这个 summary 重新作为 chunk 提取 embedding\r\n把 raw chunk 存到 sql\r\n\"\r\n\r\nAnd the meaning that you mentioned \"检索期间用 summary_chunk 还是用 raw_chunk\" refers to the vector retrieval, or graph retrieval?\r\n\r\nthan",
          "created_at": "2024-10-27T17:39:20Z"
        },
        {
          "author": "adogwangwang",
          "body": "> Hi @tpoisonooo , could you please show me the code about it ? : \" 会把 raw chunk 改写成一个 “基于图谱” 总结的 summary，并且把这个 summary 重新作为 chunk 提取 embedding 把 raw chunk 存到 sql \"\r\n> \r\n> And the meaning that you mentioned \"检索期间用 summary_chunk 还是用 raw_chunk\" refers to the vector retrieval, or graph retrieval?\r\n> \r\n",
          "created_at": "2024-11-12T01:37:05Z"
        },
        {
          "author": "Appointat",
          "body": "> > Hi @tpoisonooo , could you please show me the code about it ? : \" 会把 raw chunk 改写成一个 “基于图谱” 总结的 summary，并且把这个 summary 重新作为 chunk 提取 embedding 把 raw chunk 存到 sql \"\r\n> > And the meaning that you mentioned \"检索期间用 summary_chunk 还是用 raw_chunk\" refers to the vector retrieval, or graph retrieval?\r\n> > ",
          "created_at": "2024-11-12T06:42:17Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-03-12T21:05:10Z"
        }
      ]
    },
    {
      "issue_number": 2122,
      "title": "[Bug] [Module Name] Bug title Graph is not normal，Appear in large numbers none header chunk",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [X] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n4gpu ,A6000\n\n### Models information\n\nllm:qwen2.5 72B \r\nBGE-M3\n\n### What happened\n\n生成的图谱不正常，出现大量none header chunk,检索问答时仅有极少数回答是正确的，大量的报错。\r\n![111](https://github.com/user-attachments/assets/371d25d9-f114-4143-be7b-18cb002105aa)\r\n\n\n### What you expected to happen\n\n不知道\n\n### How to reproduce\n\n导入同样的文件 \n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "su400",
      "author_type": "User",
      "created_at": "2024-11-10T13:19:19Z",
      "updated_at": "2025-03-12T21:05:07Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2122/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2122",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2122",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:40.674750",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "You can check your prompt log and check are there some graph nodes recalled by graph retrieve.\r\nNow graph retrieve process is \r\n\r\n1. keyword extract from query \r\n2. Accurately match graph nodes based on keywords and find node information associated with graph nodes.\r\n3. Assembling context to form pr",
          "created_at": "2024-11-10T14:43:25Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-03-12T21:05:06Z"
        }
      ]
    },
    {
      "issue_number": 2302,
      "title": "[Bug] [Module Name] delete database failed",
      "body": "### Search before asking\r\n\r\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\r\n\r\n\r\n### Operating system information\r\n\r\nWindows\r\n\r\n### Python version information\r\n\r\n>=3.11\r\n\r\n### DB-GPT version\r\n\r\nmain\r\n\r\n### Related scenes\r\n\r\n- [ ] Chat Data\r\n- [ ] Chat Excel\r\n- [ ] Chat DB\r\n- [ ] Chat Knowledge\r\n- [ ] Model Management\r\n- [ ] Dashboard\r\n- [ ] Plugins\r\n\r\n### Installation Information\r\n\r\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\r\n\r\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\r\n\r\n- [ ] AutoDL Image\r\n- [ ] Other\r\n\r\n### Device information\r\n\r\nwindows 11 家庭版\r\n\r\n### Models information\r\n\r\nollama\r\n\r\n### TuGraph config\r\nTUGRAPH_HOST=192.168.3.X\r\nTUGRAPH_PORT=7687\r\nTUGRAPH_USERNAME=admin\r\nTUGRAPH_PASSWORD=73@TuGraph\r\nTUGRAPH_VERTEX_TYPE=entity\r\nTUGRAPH_EDGE_TYPE=relation\r\nTUGRAPH_PLUGIN_NAMES=leiden\r\n\r\n### What happened\r\n\r\n2025-01-14 09:30:25 wendell dbgpt.serve.rag.connector[76776] INFO VectorStore:<class 'dbgpt.storage.vector_store.chroma_store.ChromaStore'>\r\n2025-01-14 09:30:25 wendell dbgpt.serve.rag.connector[76776] INFO VectorStore:<class 'dbgpt.storage.vector_store.chroma_store.ChromaStore'>\r\n2025-01-14 09:30:25 wendell dbgpt.storage.vector_store.chroma_store[76776] INFO Check persist_dir: d:\\project\\db-gpt\\pilot\\data\\case_1_student_manager_profile.vectordb\r\n2025-01-14 09:30:25 wendell dbgpt.storage.vector_store.chroma_store[76776] INFO chroma vector_name:case_1_student_manager_profile begin delete...\r\n2025-01-14 09:30:25 wendell dbgpt.serve.rag.connector[76776] ERROR delete vector name case_1_student_manager_profile failed: Collection langchain does not exist.\r\n2025-01-14 09:30:25 wendell dbgpt.serve.core.schemas[76776] ERROR common_exception_handler catch Exception: success=False err_code='E0003' err_msg='delete name case_1_student_manager_profile failed' data=None\r\nINFO:     127.0.0.1:55626 - \"POST /api/v1/chat/db/delete?db_name=case_1_student_manager HTTP/1.1\" 400 Bad Request\r\nERROR:    Exception in ASGI application\r\n  + Exception Group Traceback (most recent call last):\r\n  |   File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\_utils.py\", line 77, in collapse_excgroups\r\n  |     yield\r\n  |   File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\middleware\\base.py\", line 186, in __call__\r\n  |     async with anyio.create_task_group() as task_group:\r\n  |   File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 767, in __aexit__\r\n  |     raise BaseExceptionGroup(\r\n  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\r\n  +-+---------------- 1 ----------------\r\n    | Traceback (most recent call last):\r\n    |   File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\uvicorn\\protocols\\http\\httptools_impl.py\", line 409, in run_asgi\r\n    |     result = await app(  # type: ignore[func-returns-value]\r\n    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n    |   File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 60, in __call__\r\n    |     return await self.app(scope, receive, send)\r\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n    |   File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\middleware\\cors.py\", line 93, in __call__\r\n    |     await self.simple_response(scope, receive, send, request_headers=headers)\r\n    |   File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\middleware\\cors.py\", line 144, in simple_response\r\n    |     await self.app(scope, receive, send)\r\n    |   File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\fastapi\\applications.py\", line 1054, in __call__\r\n    |     await super().__call__(scope, receive, send)\r\n    |   File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\applications.py\", line 113, in __call__\r\n    |     await self.middleware_stack(scope, receive, send)\r\n    |   File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 187, in __call__\r\n    |     raise exc\r\n    |   File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 165, in __call__\r\n    |     await self.app(scope, receive, _send)\r\n    |   File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\middleware\\base.py\", line 185, in __call__\r\n    |     with collapse_excgroups():\r\n    |   File \"D:\\librarys\\envs\\db-gpt\\Lib\\contextlib.py\", line 158, in __exit__\r\n    |     self.gen.throw(typ, value, traceback)\r\n    |   File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\_utils.py\", line 83, in collapse_excgroups\r\n    |     raise exc\r\n    |   File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\middleware\\base.py\", line 187, in __call__\r\n    |     response = await self.dispatch_func(request, call_next)\r\n    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n    |   File \"d:\\project\\db-gpt\\dbgpt\\util\\tracer\\tracer_middleware.py\", line 49, in dispatch\r\n    |     response = await call_next(request)\r\n    |                ^^^^^^^^^^^^^^^^^^^^^^^^\r\n    |   File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\middleware\\base.py\", line 163, in call_next\r\n    |     raise app_exc\r\n    |   File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\middleware\\base.py\", line 149, in coro\r\n    |     await self.app(scope, receive_or_disconnect, send_no_error)\r\n    |   File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 62, in __call__\r\n    |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\r\n    |   File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 62, in wrapped_app\r\n    |     raise exc\r\n    |   File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 51, in wrapped_app\r\n    |     await app(scope, receive, sender)\r\n    |   File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\routing.py\", line 715, in __call__\r\n    |     await self.middleware_stack(scope, receive, send)\r\n    |   File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\routing.py\", line 735, in app\r\n    |     await route.handle(scope, receive, send)\r\n    |   File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\routing.py\", line 288, in handle\r\n    |     await self.app(scope, receive, send)\r\n    |   File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\routing.py\", line 76, in app\r\n    |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\r\n    |   File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 62, in wrapped_app\r\n    |     raise exc\r\n    |   File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 51, in wrapped_app\r\n    |     await app(scope, receive, sender)\r\n    |   File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\routing.py\", line 73, in app\r\n    |     response = await f(request)\r\n    |                ^^^^^^^^^^^^^^^^\r\n    |   File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\fastapi\\routing.py\", line 301, in app\r\n    |     raw_response = await run_endpoint_function(\r\n    |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n    |   File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\fastapi\\routing.py\", line 212, in run_endpoint_function\r\n    |     return await dependant.call(**values)\r\n    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n    |   File \"d:\\project\\db-gpt\\dbgpt\\app\\openapi\\api_v1\\api_v1.py\", line 217, in db_connect_delete\r\n    |     CFG.local_db_manager.db_summary_client.delete_db_profile(db_name)\r\n    |   File \"d:\\project\\db-gpt\\dbgpt\\rag\\summary\\db_summary_client.py\", line 147, in delete_db_profile\r\n    |     table_vector_connector.delete_vector_name(table_vector_store_name)\r\n    |   File \"d:\\project\\db-gpt\\dbgpt\\serve\\rag\\connector.py\", line 230, in delete_vector_name\r\n    |     raise Exception(f\"delete name {vector_name} failed\")\r\n    | Exception: delete name case_1_student_manager_profile failed\r\n    +------------------------------------\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\uvicorn\\protocols\\http\\httptools_impl.py\", line 409, in run_asgi\r\n    result = await app(  # type: ignore[func-returns-value]\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 60, in __call__\r\n    return await self.app(scope, receive, send)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\middleware\\cors.py\", line 93, in __call__\r\n    await self.simple_response(scope, receive, send, request_headers=headers)\r\n  File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\middleware\\cors.py\", line 144, in simple_response\r\n    await self.app(scope, receive, send)\r\n  File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\fastapi\\applications.py\", line 1054, in __call__\r\n    await super().__call__(scope, receive, send)\r\n  File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\applications.py\", line 113, in __call__\r\n    await self.middleware_stack(scope, receive, send)\r\n  File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 187, in __call__\r\n    raise exc\r\n  File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 165, in __call__\r\n    await self.app(scope, receive, _send)\r\n  File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\middleware\\base.py\", line 185, in __call__\r\n    with collapse_excgroups():\r\n  File \"D:\\librarys\\envs\\db-gpt\\Lib\\contextlib.py\", line 158, in __exit__\r\n    self.gen.throw(typ, value, traceback)\r\n  File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\_utils.py\", line 83, in collapse_excgroups\r\n    raise exc\r\n  File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\middleware\\base.py\", line 187, in __call__\r\n    response = await self.dispatch_func(request, call_next)\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"d:\\project\\db-gpt\\dbgpt\\util\\tracer\\tracer_middleware.py\", line 49, in dispatch\r\n    response = await call_next(request)\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\middleware\\base.py\", line 163, in call_next\r\n    raise app_exc\r\n  File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\middleware\\base.py\", line 149, in coro\r\n    await self.app(scope, receive_or_disconnect, send_no_error)\r\n  File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 62, in __call__\r\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\r\n  File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 62, in wrapped_app\r\n    raise exc\r\n  File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 51, in wrapped_app\r\n    await app(scope, receive, sender)\r\n  File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\routing.py\", line 715, in __call__\r\n    await self.middleware_stack(scope, receive, send)\r\n  File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\routing.py\", line 735, in app\r\n    await route.handle(scope, receive, send)\r\n  File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\routing.py\", line 288, in handle\r\n    await self.app(scope, receive, send)\r\n  File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\routing.py\", line 76, in app\r\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\r\n  File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 62, in wrapped_app\r\n    raise exc\r\n  File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 51, in wrapped_app\r\n    await app(scope, receive, sender)\r\n  File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\starlette\\routing.py\", line 73, in app\r\n    response = await f(request)\r\n               ^^^^^^^^^^^^^^^^\r\n  File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\fastapi\\routing.py\", line 301, in app\r\n    raw_response = await run_endpoint_function(\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\librarys\\envs\\db-gpt\\Lib\\site-packages\\fastapi\\routing.py\", line 212, in run_endpoint_function\r\n    return await dependant.call(**values)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"d:\\project\\db-gpt\\dbgpt\\app\\openapi\\api_v1\\api_v1.py\", line 217, in db_connect_delete\r\n    CFG.local_db_manager.db_summary_client.delete_db_profile(db_name)\r\n  File \"d:\\project\\db-gpt\\dbgpt\\rag\\summary\\db_summary_client.py\", line 147, in delete_db_profile\r\n    table_vector_connector.delete_vector_name(table_vector_store_name)\r\n  File \"d:\\project\\db-gpt\\dbgpt\\serve\\rag\\connector.py\", line 230, in delete_vector_name\r\n    raise Exception(f\"delete name {vector_name} failed\")\r\nException: delete name case_1_student_manager_profile failed\r\n\r\n### What you expected to happen\r\n\r\n![image](https://github.com/user-attachments/assets/9d765368-d6c6-4f88-9483-2abd383daf1a)\r\n\r\n\r\n### How to reproduce\r\n\r\n![image](https://github.com/user-attachments/assets/cbbe1916-a021-4d08-b7ca-c0b4a448bd63)\r\n\r\n\r\n### Additional context\r\n\r\n_No response_\r\n\r\n### Are you willing to submit PR?\r\n\r\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "LuWei6896",
      "author_type": "User",
      "created_at": "2025-01-14T02:43:22Z",
      "updated_at": "2025-03-12T06:53:20Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2302/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2302",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2302",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:40.852440",
      "comments": [
        {
          "author": "kyyz147",
          "body": "我也遇到了这个问题，这个问题需要怎么解决？删也删不掉，使用智能体的时候，还会默认查错误的数据源。",
          "created_at": "2025-03-12T06:53:19Z"
        }
      ]
    },
    {
      "issue_number": 2436,
      "title": "[Bug] [docker run] 使用docker命令启动镜像时，容器内报错",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.9\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [x] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU数量：2\n总显存：160G\n\n### Models information\n\ndocker run --ipc host --gpus all -d \\\n-p 5000:5000 \\\n-e LOCAL_DB_TYPE=sqlite \\\n-e LOCAL_DB_PATH=data/default_sqlite.db \\\n-e LLM_MODEL=vicuna-13b-v1.5 \\\n-e LANGUAGE=zh \\\n-v /data/models:/app/models \\\n--name dbgpt \\\neosphorosai/dbgpt\n\n### What happened\n\n使用网站https://www.yuque.com/eosphoros/dbgpt-docs/glf87qg4xxcyrp89的启动命令docker run --ipc host --gpus all -d \\\n-p 5000:5000 \\\n-e LOCAL_DB_TYPE=sqlite \\\n-e LOCAL_DB_PATH=data/default_sqlite.db \\\n-e LLM_MODEL=vicuna-13b-v1.5 \\\n-e LANGUAGE=zh \\\n-v /data/models:/app/models \\\n--name dbgpt \\\neosphorosai/dbgpt\n启动完容器之后，报错了，报错信息在附件里\n\n[error.txt](https://github.com/user-attachments/files/19178030/error.txt)\n\n\n### What you expected to happen\n\n正常启动\n\n### How to reproduce\n\n运行命令docker run --ipc host --gpus all -d \\\n-p 5000:5000 \\\n-e LOCAL_DB_TYPE=sqlite \\\n-e LOCAL_DB_PATH=data/default_sqlite.db \\\n-e LLM_MODEL=vicuna-13b-v1.5 \\\n-e LANGUAGE=zh \\\n-v /data/models:/app/models \\\n--name dbgpt \\\neosphorosai/dbgpt\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "Leeeeno",
      "author_type": "User",
      "created_at": "2025-03-11T07:35:19Z",
      "updated_at": "2025-03-12T02:31:50Z",
      "closed_at": "2025-03-12T02:31:50Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2436/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2436",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2436",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:41.041864",
      "comments": []
    },
    {
      "issue_number": 2429,
      "title": "[Bug] [StartUp] Cannot run proxy mode(siliconflow) on a computer with No NVIDIA graphics AND CUDA toolkit",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice CPU\n\n### Models information\n\nQwen/Qwen2.5-Coder-32B-Instruct\nBAAI/bge-large-zh-v1.5\nBAAI/bge-reranker-v2-m3\n\n### What happened\n\nStarting from version 243e981, there is an error message when starting up. Please refer to  #2396 for the error issue,  After the update to d5a2a0b, I was able to run the project normally and start it on a computer with NVIDIA graphics card and CUDA driver. The next day, due to debugging needs, I pulled the latest version (3bd75d8) on my laptop which is  lack of CUDA driver and graphics card on it, which was 3bd75d8 at the time. I thought it was this update that caused the startup problem to recur but have no idea to resolve it. Even today, it has been updated to 93eb3a7. The laptop has also pulled the latest version, but it still starts with an error. I realized that it may be due to the lack of CUDA driver and graphics card on the machine itself. However, this proxy mode startup method should not use CUDA, so I pulled the latest version again on a machine with graphics card for testing. After checking if it can start, I found that it is possible, so I discovered this issue: it will not start on machines without NVIDIA graphics cards and CUDA ToolKit.\nBy the way, the errors in related #2404 may be caused by the same reason。\n\n### What you expected to happen\n\nBased on my understanding of the project introduction video, it should be possible to start in full proxy mode on machines without CUDA or NVIDIA graphics cards\n\n### How to reproduce\n\njust find a laptop with no NVIDIA AND CUDA\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "su1234121",
      "author_type": "User",
      "created_at": "2025-03-10T08:36:46Z",
      "updated_at": "2025-03-12T02:31:49Z",
      "closed_at": "2025-03-12T02:31:49Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2429/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2429",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2429",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:41.041885",
      "comments": [
        {
          "author": "fangyinc",
          "body": "Hi, @su1234121 , thanks for your feedback. \nThank you very much for your attention to our changes.\nIn addition, what is the complete commans of your installation dependencies?\nBy the way, if you want to run Qwen/Qwen2.5-Coder-32B-Instruct using cpu, you can consider using `llama.cpp` to install",
          "created_at": "2025-03-10T09:52:06Z"
        },
        {
          "author": "su1234121",
          "body": "I have tried this two method.\nuv sync --all-packages --extra \"base\" --extra \"proxy_openai\" --extra \"rag\" --extra \"storage_chromadb\" --extra \"dbgpts\"  \nuv sync --all-packages --extra \"base\" --extra \"proxy_openai\" --extra \"rag\" --extra \"storage_chromadb\" --extra \"dbgpts\"  --extra \"hf\"\n\nthanks for you ",
          "created_at": "2025-03-10T10:04:46Z"
        },
        {
          "author": "fangyinc",
          "body": "> I have tried this two method. uv sync --all-packages --extra \"base\" --extra \"proxy_openai\" --extra \"rag\" --extra \"storage_chromadb\" --extra \"dbgpts\" uv sync --all-packages --extra \"base\" --extra \"proxy_openai\" --extra \"rag\" --extra \"storage_chromadb\" --extra \"dbgpts\" --extra \"hf\"\n> \n> thanks for y",
          "created_at": "2025-03-10T10:27:02Z"
        },
        {
          "author": "su1234121",
          "body": "I delete the file and re git clone and run it with: \nuv sync --all-packages --extra \"base\" --extra \"proxy_openai\" --extra \"rag\" --extra \"storage_chromadb\" --extra \"dbgpts\" \nuv run dbgpt start webserver --config configs/dbgpt-siliconflow.toml\n\nthen still get error:\n\n2025-03-10 21:27:37 localhost.loca",
          "created_at": "2025-03-10T13:29:41Z"
        },
        {
          "author": "su1234121",
          "body": "![Image](https://github.com/user-attachments/assets/320b4707-e51a-4c33-8885-739c65559e1a)\n\nBy the way ,I compared the successful startup progress and the failed one ,the black one is success. the progress is different from this step.",
          "created_at": "2025-03-11T01:14:16Z"
        }
      ]
    },
    {
      "issue_number": 2439,
      "title": "[Bug] [Module Name] chat/completions 流式响应报文问题",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nLLM：deepseek\n\n### What happened\n\n curl -X POST \"http://localhost:5670/api/v2/chat/completions\" \\\n    -H \"Authorization: Bearer XXX\" \\\n    -H \"accept: application/json\" \\\n    -H \"Content-Type: application/json\" \\\n    -d \"{\\\"messages\\\":\\\"Hello\\\",\\\"model\\\":\\\"deepseek_v3\\\", \\\"stream\\\": true}\"\n\n响应报文倒数第二条报文会显示一条完整的回答内容，不符合接口规范，前端显示会有问题，如下图\n![Image](https://github.com/user-attachments/assets/b63b93b0-5968-4b28-bdbd-23d969132ea2)\n\n### What you expected to happen\n\n倒数第二条报文不要显示完整的回答内容\n\n### How to reproduce\n\n curl -X POST \"http://localhost:5670/api/v2/chat/completions\" \\\n    -H \"Authorization: Bearer XXX\" \\\n    -H \"accept: application/json\" \\\n    -H \"Content-Type: application/json\" \\\n    -d \"{\\\"messages\\\":\\\"Hello\\\",\\\"model\\\":\\\"deepseek_v3\\\", \\\"stream\\\": true}\"\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "bxfxf",
      "author_type": "User",
      "created_at": "2025-03-11T10:57:34Z",
      "updated_at": "2025-03-12T00:40:42Z",
      "closed_at": "2025-03-12T00:40:42Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2439/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2439",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2439",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:41.278647",
      "comments": []
    },
    {
      "issue_number": 2440,
      "title": "[Bug] [GraphRag] Bug title 图谱切片与输入文本不符",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU Memory 24G\n\n### Models information\n\nLLM:DeepSeek-R1-Distill-Qwen-1.5B\nEmbedding：text2vec-large-chinese\n\n### What happened\n\n[[输入中文文本文件构建知识库，选择图谱类型存储，后台把prompt中的example示例当成了输入文件进行切片，导致出来的图谱十分混乱，与输入文本完全不符合；\n\n![Image](https://github.com/user-attachments/assets/923ffa85-98f8-4744-a8af-614a2fcc2c78)\n\n![Image](https://github.com/user-attachments/assets/0f242e35-3d2a-4c57-bd77-aacd2ef4f61a)\n\n### What you expected to happen\n\n解决这个混乱的问题\n\n### How to reproduce\n\n1\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "ghao123",
      "author_type": "User",
      "created_at": "2025-03-11T15:20:05Z",
      "updated_at": "2025-03-11T15:20:05Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2440/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2440",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2440",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:41.278670",
      "comments": []
    },
    {
      "issue_number": 2417,
      "title": "[Bug] [Module Name] Bug title 'BuiltinKnowledgeGraphConfig' object does not support item assignment",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU：1\nvram：24G\n\n### Models information\n\nLLM: DeepSeek-R1-Distill-Qwen-1.5B\nEmbedding： text2vec-large-chinese\n\n### What happened\n\n构建知识库时，选用 Vector Store形式存储知识库时，可正常切片，没有问题；\n选用Knowledge Graph时，切片报错“'BuiltinKnowledgeGraphConfig' object does not support item assignment”；\n\n### What you expected to happen\n\ndbgpt已更新至main最新版本\n\n### How to reproduce\n\n最新版本部署\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "ghao123",
      "author_type": "User",
      "created_at": "2025-03-08T02:56:17Z",
      "updated_at": "2025-03-11T11:05:30Z",
      "closed_at": "2025-03-11T11:05:30Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2417/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2417",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2417",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:41.278677",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "http://docs.dbgpt.cn/docs/next/installation/integrations/graph_rag_install\n```\nuv sync --all-packages --frozen \\\n--extra \"base\" \\\n--extra \"proxy_openai\" \\\n--extra \"rag\" \\\n--extra \"storage_chromadb\" \\\n--extra \"dbgpts\"\n--extra \"graph_rag\"\n```\n\n```\nuv run python packages/dbgpt-app/src/dbgpt_app/dbgpt_s",
          "created_at": "2025-03-09T13:07:28Z"
        }
      ]
    },
    {
      "issue_number": 2367,
      "title": "[Bug] [KnowledgeGraph] 长文本生成知识图谱时到最后网络会一直超时",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [x] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU：16G\n\n### Models information\n\nLLM：gpt-35-turbo【微软代理】\nembedding：DB-GPT/models/text2vec-large-chinese\n\n### What happened\n\n对于短文章，一万字左右，点击知识图谱-自动切片，可以顺利构造知识图片并进行召回，让ai回答问题；\n但是对于长文本【三体第一部】，首先是**自动切片不能用**，会显示报错：\nCheckErrorInfo.**: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 267142 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}，即令牌数超了，\n\n因此使用手动切片**chunk size**，每512token切一次，重叠50token，然后就开始处理，处理的过程中简单看了一下终端的输出，会经历切片、向量化等一系列操作，中间跳的太快看不清楚，最后出现一系列进度条\n2025-02-24 16:30:27 deqing-gpu-249 dbgpt.storage.vector_store.chroma_store[3847629] INFO ChromaStore similar search with scores\nBatches: 100%|███████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 20.40it/s]\n\n\n但是会有一些是进度0，然后就开始报\ndeqing-gpu-249 dbgpt.util.api_utils[3847629] WARNING Health check failed for http://127.0.0.1:5670, error: HTTPConnectionPool(host='127.0.0.1', port=5670): Read timed out. (read timeout=10)\n\n然后我估计是有些进度条一直是0且超时，然后程序就一直重复一直显示超时，搞到最后都不响应了\n\n### What you expected to happen\n\n有两类进度条好像都会弹出超时的提示，因为切片是并行逻辑，所以终端弹出的内容不是很按照顺序，比较混乱，另一类是\n2025-02-24 16:33:39 deqing-gpu-249 dbgpt.model.proxy.llms.chatgpt[3847629] INFO Send request to openai(1.61.1), payload: {'stream': True, 'model': 'gpt-35-turbo'}\n\n后面会显示进度条，然后也会报超时。\n然后我估计是有些进度条一直是0且超时，然后程序就一直重复一直显示超时，搞到最后都不响应了\n\n### How to reproduce\n\n复现用个超长文本不知道能不能复现，我可以提供一下我的样本\n\n[santi.md](https://github.com/user-attachments/files/18938601/santi.md)\n\n### Additional context\n\n哦对了，在这里面我还看见过一个问题，终端会显示：\nExpected `str` but got `datetime` with value `datetime.datetime(2025, 2, 24, 11, 10, 6, 371925)` - serialized value may not be as expected\n\n这个是什么原因，能怎么解决吗？一直有见到这个不是报错的报错\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "JUNK803",
      "author_type": "User",
      "created_at": "2025-02-24T09:13:13Z",
      "updated_at": "2025-03-11T07:48:48Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2367/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "fanzhidongyzby"
      ],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2367",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2367",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:41.450123",
      "comments": [
        {
          "author": "JUNK803",
          "body": "自己复现了一遍，这是最后的情况：\n![Image](https://github.com/user-attachments/assets/d1994373-272c-4a00-bf0e-f4d060a01c54)\n\n![Image](https://github.com/user-attachments/assets/6335e625-75cf-4b8b-bd67-f48a75e7f9c5)",
          "created_at": "2025-02-24T09:49:57Z"
        },
        {
          "author": "JUNK803",
          "body": "补充说一下我最新的测试，我将文本手动切割，token是10000，重叠100，这下就可以正常分割了，当然也会出现“read timeout=10”的情况，但是最终还是可以制成知识图谱，但是查看制作完的知识图谱会发现：内容不够丰富，且很多实体的名字叫“none_header_chunk”，可以看下图，最终也是咨询不了任何问题，会报错，报错信息看着像是因为检索的东西过多，以及文本过长？我对sql的东西不是很熟悉，看不是很懂。报错的终端信息也会贴在下面。麻烦各位前辈帮我分析一下，非常感谢\n\n![Image](https://github.com/user-attachments/assets/295",
          "created_at": "2025-02-25T01:47:04Z"
        },
        {
          "author": "fanzhidongyzby",
          "body": "none_header_chunk不用太在意，只是表示文本块。KNOWLEDGE_GRAPH_CHUNK_SEARCH_TOP_SIZE是用来控制单次召回的文本块的数量的，太大容易导致上下文溢出。你split的chunk size = 10k已经很大了，容易出现这样的问题。\n",
          "created_at": "2025-02-25T02:42:42Z"
        },
        {
          "author": "JUNK803",
          "body": "> none_header_chunk不用太在意，只是表示文本块。KNOWLEDGE_GRAPH_CHUNK_SEARCH_TOP_SIZE是用来控制单次召回的文本块的数量的，太大容易导致上下文溢出。你split的chunk size = 10k已经很大了，容易出现这样的问题。\n\n嗯嗯，明白了，非常感谢！所以chunk size不能太大，但是细分的太小的话也会不好！",
          "created_at": "2025-02-25T06:27:24Z"
        },
        {
          "author": "JUNK803",
          "body": "> none_header_chunk不用太在意，只是表示文本块。KNOWLEDGE_GRAPH_CHUNK_SEARCH_TOP_SIZE是用来控制单次召回的文本块的数量的，太大容易导致上下文溢出。你split的chunk size = 10k已经很大了，容易出现这样的问题。\n\n前辈您好，根据您的这个说法，我又进行了两次参数，第一次是用1000token进行分割，80token的文本重叠，第二次是用800token进行分割和70的文本重叠，好消息是都可以生成知识图谱，最终显示“Finished”。但是坏消息是依然不能正常进行对话，报错内容和之前10ktoken的一样，图片如下：\n难道800t",
          "created_at": "2025-02-25T08:29:15Z"
        }
      ]
    },
    {
      "issue_number": 2424,
      "title": "[Bug] Chroma document embedding errror -  unable to open database file",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n1\n\n### Models information\n\n1\n\n### What happened\n\n<img width=\"765\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/355cfee5-a40d-44ae-81c1-f54198e73cb4\" />\n同步知识库文档时报错 unable to open database file, 查看pilot/data这些文件路径都正常创建且权限正确，但在chroma还是报了document embedding errror. 每次出现这个问题后重启下dbgpt server就可解决，可过一段时间后又无法同步了\n\n### What you expected to happen\n\n1\n\n### How to reproduce\n\n1\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "paul-yangmy",
      "author_type": "User",
      "created_at": "2025-03-10T01:51:43Z",
      "updated_at": "2025-03-11T07:28:17Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2424/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2424",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2424",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:41.645023",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "version is v0.7.0?",
          "created_at": "2025-03-11T01:40:49Z"
        },
        {
          "author": "paul-yangmy",
          "body": "> version is v0.7.0?\n\n0.6.3",
          "created_at": "2025-03-11T07:28:16Z"
        }
      ]
    },
    {
      "issue_number": 2432,
      "title": "[Bug] [tugraph knowlege] Bug title 图谱知识库解析文档到一定阶段终端报错，图谱知识库提取失败。",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nMacOS(M1, M2...)\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice: GPU\nGPU: 1 ,24GB\n\n### Models information\n\nLLM：deep-seek API 接口\nenbeding：models/bge-large-zh-v1.5\n\n### What happened\n\n----\n\n请根据接下来[上下文]提供的信息，按照上述要求，抽取[文本]中的实体和关系数据。\n\n[上下文]:\nSection 1:\n入密码进行解密；如果在解密时间内解密失败，可再次解密。投标人应在开标当天及时关注本项目的情况，如遇问题，请拨打技术服务单位（国泰新点）电话：4009980000。\nSection 2:\n入密码进行解密；如果在解密时间内解密失败，可再次解密。投标人应在开标当天及时关注本项目的情况，如遇问题，请拨打技术服务单位（国泰新点）电话：4009980000。\nSection 3:\n标证通的，投标人应在解密时间内扫描二维码进行解密；使用CA证书的，投标人应在解密时间内插入CA锁，输入密码进行解密；如果在解密时间内解密失败，可再次解密。投标人应在开标当天及时关注本项目的情况，如遇问\nSection 4:\n标证通的，投标人应在解密时间内扫描二维码进行解密；使用CA证书的，投标人应在解密时间内插入CA锁，输入密码进行解密；如果在解密时间内解密失败，可再次解密。投标人应在开标当天及时关注本项目的情况，如遇问\nSection 5:\n解密等问题由投标人自行承担；投标人可在开标时间之后系统内观看开标过程，并进行文件解密，答疑澄清；使用标证通的，投标人应在解密时间内扫描二维码进行解密；使用CA证书的，投标人应在解密时间内插入CA锁，输\n\n[文本]:\n入密码进行解密；如果在解密时间内解密失败，可再次解密。投标人应在开标当天及时关注本项目的情况，如遇问题，请拨打技术服务单位（国泰新点）电话：4009980000。\n\n[结果]:\n\n\n\nasync generate stream output:\n\n2025-03-11 10:51:08 litaosmile-new-mac-2.local dbgpt.model.proxy.llms.chatgpt[34146] INFO Send request to openai, payload: {'stream': True, 'model': 'deepseek-reasoner'}\n\n messages:\n[{'role': 'user', 'content': '## 角色\\n你是一个知识图谱工程专家，非常擅长从文本中精确抽取知识图谱的实体（主体、客体）和关系，并能对实体和关系的含义做出恰当的总结性描述。\\n\\n## 技能\\n### 技能 1: 实体抽取\\n--请按照如下步骤抽取实体--\\n1. 准确地识别文本中的实体信息，一般是名词、代词等。\\n2. 准确地识别实体的修饰性描述，一般作为定语对实体特征做补充。\\n3. 对相同概念的实体（同义词、别称、代指），请合并为单一简洁的实体名，并合并它们的描述信息。\\n4. 对合并后的实体描述信息做简洁、恰当、连贯的总结。\\n\\n### 技能 2: 关系抽取\\n--请按照如下步骤抽取关系--\\n1. 准确地识别文本中实体之间的关联信息，一般是动词、代词等。\\n2. 准确地识别关系的修饰性描述，一般作为状语对关系特征做补充。\\n3. 对相同概念的关系（同义词、别称、代指），请合并为单一简洁的关系名，并合并它们的描述信息。\\n4. 对合并后的关系描述信息做简洁、恰当、连贯的总结。\\n\\n### 技能 3: 关联上下文\\n- 关联上下文来自与当前待抽取文本相关的前置段落内容，可以为知识抽取提供信息补充。\\n- 合理利用提供的上下文信息，知识抽取过程中出现的内容引用可能来自关联上下文。\\n- 不要对关联上下文的内容做知识抽取，而仅作为关联信息参考。\\n- 关联上下文是可选信息，可能为空。\\n\\n## 约束条件\\n- 如果文本已提供了图结构格式的数据，直接转换为输出格式返回，不要修改实体或ID名称。- 尽可能多的生成文本中提及的实体和关系信息，但不要随意创造不存在的实体和关系。\\n- 确保以第三人称书写，从客观角度描述实体名称、关系名称，以及他们的总结性描述。\\n- 尽可能多地使用关联上下文中的信息丰富实体和关系的内容，这非常重要。\\n- 如果实体或关系的总结描述为空，不提供总结描述信息，不要生成无关的描述信息。\\n- 如果提供的描述信息相互矛盾，请解决矛盾并提供一个单一、连贯的描述。\\n- 实体和关系的名称或者描述文本出现#和:字符时，使用_字符替换，其他字符不要修改。- 避免使用停用词和过于常见的词汇。\\n\\n## 输出格式\\nEntities:\\n(实体名#实体总结)\\n...\\n\\nRelationships:\\n(来源实体名#关系名#目标实体名#关系总结)\\n...\\n\\n## 参考案例--案例仅帮助你理解提示词的输入和输出格式，请不要在答案中使用它们。--\\n输入:\\n```\\n[上下文]:\\nSection 1:\\n菲尔・贾伯的大儿子叫雅各布・贾伯。\\nSection 2:\\n菲尔・贾伯的小儿子叫比尔・贾伯。\\n...\\n[文本]:\\n菲尔兹咖啡由菲尔・贾伯于1978年在加利福尼亚州伯克利创立。因其独特的混合咖啡而闻名，菲尔兹已扩展到美国多地。他的大儿子于2005年成为首席执行官，并带领公司实现了显著增长。\\n```\\n\\n输出:\\n```\\nEntities:\\n(菲尔・贾伯#菲尔兹咖啡创始人)\\n(菲尔兹咖啡#加利福尼亚州伯克利创立的咖啡品牌)\\n(雅各布・贾伯#菲尔・贾伯的大儿子)\\n(美国多地#菲尔兹咖啡的扩展地区)\\n\\nRelationships:\\n(菲尔・贾伯#创建#菲尔兹咖啡#1978年在加利福尼亚州伯克利创立)\\n(菲尔兹咖啡#位于#加利福尼亚州伯克利#菲尔兹咖啡的创立地点)\\n(菲尔・贾伯#拥有#雅各布・贾伯#菲尔・贾伯的大儿子)\\n(雅各布・贾伯#管理#菲尔兹咖啡#在2005年担任首席执行官)\\n(菲尔兹咖啡#扩展至#美国多地#菲尔兹咖啡的扩展范围)\\n```\\n\\n----\\n\\n请根据接下来[上下文]提供的信息，按照上述要求，抽取[文本]中的实体和关系数据。\\n\\n[上下文]:\\nSection 1:\\n入密码进行解密；如果在解密时间内解密失败，可再次解密。投标人应在开标当天及时关注本项目的情况，如遇问题，请拨打技术服务单位（国泰新点）电话：4009980000。\\nSection 2:\\n入密码进行解密；如果在解密时间内解密失败，可再次解密。投标人应在开标当天及时关注本项目的情况，如遇问题，请拨打技术服务单位（国泰新点）电话：4009980000。\\nSection 3:\\n标证通的，投标人应在解密时间内扫描二维码进行解密；使用CA证书的，投标人应在解密时间内插入CA锁，输入密码进行解密；如果在解密时间内解密失败，可再次解密。投标人应在开标当天及时关注本项目的情况，如遇问\\nSection 4:\\n标证通的，投标人应在解密时间内扫描二维码进行解密；使用CA证书的，投标人应在解密时间内插入CA锁，输入密码进行解密；如果在解密时间内解密失败，可再次解密。投标人应在开标当天及时关注本项目的情况，如遇问\\nSection 5:\\n解密等问题由投标人自行承担；投标人可在开标时间之后系统内观看开标过程，并进行文件解密，答疑澄清；使用标证通的，投标人应在解密时间内扫描二维码进行解密；使用CA证书的，投标人应在解密时间内插入CA锁，输\\n\\n[文本]:\\n入密码进行解密；如果在解密时间内解密失败，可再次解密。投标人应在开标当天及时关注本项目的情况，如遇问题，请拨打技术服务单位（国泰新点）电话：4009980000。\\n\\n[结果]:\\n\\n'}]\n2025-03-11 10:51:09 litaosmile-new-mac-2.local dbgpt_serve.rag.service.service[34146] ERROR document embedding, failed:湖南鸿昌电力工程建设有限责任公司历史投标数据.txt, Query execution failed: {code: InputError} {message: Plugin [_fma_leiden] does not exist.}\nQuery: CALL db.plugin.callPlugin('CPP','leiden','{\"leiden_val\":\"_community_id\"}',60.00,false)\n\n\n\n### What you expected to happen\n\nnothing\n\n### How to reproduce\n\n1.知识库，创建知识库，存储类型选择：knowledge Graph。\n2. 上传文件，选择默认\n3. 等待后台解析文档，存入tugraph\n4. 到后面阶段，页面显示失败。终端有报错：\n2025-03-11 10:51:09 litaosmile-new-mac-2.local dbgpt_serve.rag.service.service[34146] ERROR document embedding, failed:湖南鸿昌电力工程建设有限责任公司历史投标数据.txt, Query execution failed: {code: InputError} {message: Plugin [_fma_leiden] does not exist.}\nQuery: CALL db.plugin.callPlugin('CPP','leiden','{\"leiden_val\":\"_community_id\"}',60.00,false)\n\n### Additional context\n\nuv sync --all-packages --frozen \\\n--extra \"base\" \\\n--extra \"llama_cpp\" \\\n--extra \"rag\" \\\n--extra \"storage_chromadb\" \\\n--extra \"quant_bnb\" \\\n--extra \"dbgpts\" \\\n--link-mode=copy\n   Building llama-cpp-python==0.3.7\n\n  × Failed to build `llama-cpp-python==0.3.7`\n  ├─▶ The build backend returned an error\n  ╰─▶ Call to `scikit_build_core.build.build_wheel` failed (exit status: 1)\n\n      [stdout]\n      *** scikit-build-core 0.11.0 using CMake 3.31.6 (wheel)\n      *** Configuring CMake...\n      loading initial cache file /var/folders/ky/gt63mkt96_v4yqyvslmbzx0m0000gn/T/tmpkh4ca03k/build/CMakeInit.txt\n      -- The C compiler identification is AppleClang 12.0.0.12000031\n      -- The CXX compiler identification is AppleClang 12.0.0.12000031\n      -- Detecting C compiler ABI info\n      -- Detecting C compiler ABI info - done\n      -- Check for working C compiler: /Library/Developer/CommandLineTools/usr/bin/clang - skipped\n      -- Detecting C compile features\n      -- Detecting C compile features - done\n      -- Detecting CXX compiler ABI info\n      -- Detecting CXX compiler ABI info - done\n      -- Check for working CXX compiler: /Library/Developer/CommandLineTools/usr/bin/clang++ - skipped\n      -- Detecting CXX compile features\n      -- Detecting CXX compile features - done\n      -- Host architecture: arm64\n      -- Target architecture: arm64\n      -- Found Git: /usr/bin/git (found version \"2.24.3 (Apple Git-128)\")\n      -- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n      -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n      -- Found Threads: TRUE\n      -- Warning: ccache not found - consider installing it for faster compilation or disable this warning with\n      GGML_CCACHE=OFF\n      -- CMAKE_SYSTEM_PROCESSOR: arm64\n      -- Including CPU backend\n      -- Accelerate framework found\n      -- Could NOT find OpenMP_C (missing: OpenMP_C_FLAGS OpenMP_C_LIB_NAMES)\n      -- Could NOT find OpenMP_CXX (missing: OpenMP_CXX_FLAGS OpenMP_CXX_LIB_NAMES)\n      -- Could NOT find OpenMP (missing: OpenMP_C_FOUND OpenMP_CXX_FOUND)\n      -- ARM detected\n      -- Performing Test GGML_COMPILER_SUPPORTS_FP16_FORMAT_I3E\n      -- Performing Test GGML_COMPILER_SUPPORTS_FP16_FORMAT_I3E - Failed\n      -- ARM -mcpu not found, -mcpu=native will be used\n      -- Performing Test GGML_MACHINE_SUPPORTS_dotprod\n      -- Performing Test GGML_MACHINE_SUPPORTS_dotprod - Success\n      -- Performing Test GGML_MACHINE_SUPPORTS_i8mm\n      -- Performing Test GGML_MACHINE_SUPPORTS_i8mm - Failed\n      -- Performing Test GGML_MACHINE_SUPPORTS_sve\n      -- Performing Test GGML_MACHINE_SUPPORTS_sve - Failed\n      -- Adding CPU backend variant ggml-cpu: -mcpu=native+dotprod+noi8mm+nosve\n      -- Looking for dgemm_\n      -- Looking for dgemm_ - found\n      -- Found BLAS:\n      /Library/Developer/CommandLineTools/SDKs/MacOSX11.0.sdk/System/Library/Frameworks/Accelerate.framework\n      -- BLAS found, Libraries:\n      /Library/Developer/CommandLineTools/SDKs/MacOSX11.0.sdk/System/Library/Frameworks/Accelerate.framework\n      -- BLAS found, Includes:\n      -- Including BLAS backend\n      -- Metal framework found\n      -- The ASM compiler identification is AppleClang\n      -- Found assembler: /Library/Developer/CommandLineTools/usr/bin/clang\n      -- Including METAL backend\n      -- Configuring done (1.3s)\n      -- Generating done (0.0s)\n      -- Build files have been written to: /var/folders/ky/gt63mkt96_v4yqyvslmbzx0m0000gn/T/tmpkh4ca03k/build\n      *** Building project with Ninja...\n      Change Dir: '/var/folders/ky/gt63mkt96_v4yqyvslmbzx0m0000gn/T/tmpkh4ca03k/build'\n\n      Run Build Command(s): /Users/litao/.cache/uv/builds-v0/.tmpJwsFAf/bin/ninja -v\n      [1/66] /Library/Developer/CommandLineTools/usr/bin/clang++ -DACCELERATE_LAPACK_ILP64 -DACCELERATE_NEW_LAPACK\n      -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_ACCELERATE\n      -DGGML_USE_CPU_AARCH64 -DGGML_USE_LLAMAFILE -D_DARWIN_C_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/..\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/.\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/ggml-cpu\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/../include\n      -F/Library/Developer/CommandLineTools/SDKs/MacOSX11.0.sdk/System/Library/Frameworks -O3 -DNDEBUG\n      -std=gnu++17 -arch arm64 -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX11.0.sdk\n      -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic\n      -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return\n      -Wmissing-prototypes -Wextra-semi -mcpu=native+dotprod+noi8mm+nosve -MD -MT\n      vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-aarch64.cpp.o -MF\n      vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-aarch64.cpp.o.d -o\n      vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-aarch64.cpp.o -c\n      /Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/ggml-cpu/ggml-cpu-aarch64.cpp\n      FAILED: vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-aarch64.cpp.o\n      /Library/Developer/CommandLineTools/usr/bin/clang++ -DACCELERATE_LAPACK_ILP64 -DACCELERATE_NEW_LAPACK\n      -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_ACCELERATE\n      -DGGML_USE_CPU_AARCH64 -DGGML_USE_LLAMAFILE -D_DARWIN_C_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/..\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/.\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/ggml-cpu\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/../include\n      -F/Library/Developer/CommandLineTools/SDKs/MacOSX11.0.sdk/System/Library/Frameworks -O3 -DNDEBUG\n      -std=gnu++17 -arch arm64 -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX11.0.sdk\n      -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic\n      -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return\n      -Wmissing-prototypes -Wextra-semi -mcpu=native+dotprod+noi8mm+nosve -MD -MT\n      vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-aarch64.cpp.o -MF\n      vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-aarch64.cpp.o.d -o\n      vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-aarch64.cpp.o -c\n      /Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/ggml-cpu/ggml-cpu-aarch64.cpp\n      clang: error: the clang compiler does not support '-mcpu=native+dotprod+noi8mm+nosve'\n      [2/66] /Library/Developer/CommandLineTools/usr/bin/clang -DACCELERATE_LAPACK_ILP64 -DACCELERATE_NEW_LAPACK\n      -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_ACCELERATE\n      -DGGML_USE_CPU_AARCH64 -DGGML_USE_LLAMAFILE -D_DARWIN_C_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/..\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/.\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/ggml-cpu\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/../include\n      -F/Library/Developer/CommandLineTools/SDKs/MacOSX11.0.sdk/System/Library/Frameworks -O3 -DNDEBUG\n      -std=gnu11 -arch arm64 -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX11.0.sdk\n      -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int\n      -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function\n      -Wunreachable-code-break -Wunreachable-code-return -Wdouble-promotion -mcpu=native+dotprod+noi8mm+nosve\n      -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o\n      -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o.d\n      -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o -c\n      /Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/ggml-cpu/ggml-cpu.c\n      FAILED: vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o\n      /Library/Developer/CommandLineTools/usr/bin/clang -DACCELERATE_LAPACK_ILP64 -DACCELERATE_NEW_LAPACK\n      -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_ACCELERATE\n      -DGGML_USE_CPU_AARCH64 -DGGML_USE_LLAMAFILE -D_DARWIN_C_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/..\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/.\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/ggml-cpu\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/../include\n      -F/Library/Developer/CommandLineTools/SDKs/MacOSX11.0.sdk/System/Library/Frameworks -O3 -DNDEBUG\n      -std=gnu11 -arch arm64 -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX11.0.sdk\n      -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int\n      -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function\n      -Wunreachable-code-break -Wunreachable-code-return -Wdouble-promotion -mcpu=native+dotprod+noi8mm+nosve\n      -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o\n      -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o.d\n      -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o -c\n      /Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/ggml-cpu/ggml-cpu.c\n      clang: error: the clang compiler does not support '-mcpu=native+dotprod+noi8mm+nosve'\n      [3/66] /Library/Developer/CommandLineTools/usr/bin/clang++ -DACCELERATE_LAPACK_ILP64 -DACCELERATE_NEW_LAPACK\n      -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_ACCELERATE\n      -DGGML_USE_CPU_AARCH64 -DGGML_USE_LLAMAFILE -D_DARWIN_C_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/..\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/.\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/ggml-cpu\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/../include\n      -F/Library/Developer/CommandLineTools/SDKs/MacOSX11.0.sdk/System/Library/Frameworks -O3 -DNDEBUG\n      -std=gnu++17 -arch arm64 -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX11.0.sdk\n      -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic\n      -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return\n      -Wmissing-prototypes -Wextra-semi -mcpu=native+dotprod+noi8mm+nosve -MD -MT\n      vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o -MF\n      vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o.d -o\n      vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o -c\n      /Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/ggml-cpu/ggml-cpu.cpp\n      FAILED: vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o\n      /Library/Developer/CommandLineTools/usr/bin/clang++ -DACCELERATE_LAPACK_ILP64 -DACCELERATE_NEW_LAPACK\n      -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_ACCELERATE\n      -DGGML_USE_CPU_AARCH64 -DGGML_USE_LLAMAFILE -D_DARWIN_C_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/..\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/.\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/ggml-cpu\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/../include\n      -F/Library/Developer/CommandLineTools/SDKs/MacOSX11.0.sdk/System/Library/Frameworks -O3 -DNDEBUG\n      -std=gnu++17 -arch arm64 -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX11.0.sdk\n      -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic\n      -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return\n      -Wmissing-prototypes -Wextra-semi -mcpu=native+dotprod+noi8mm+nosve -MD -MT\n      vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o -MF\n      vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o.d -o\n      vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o -c\n      /Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/ggml-cpu/ggml-cpu.cpp\n      clang: error: the clang compiler does not support '-mcpu=native+dotprod+noi8mm+nosve'\n      [4/66] /Library/Developer/CommandLineTools/usr/bin/clang++ -DGGML_BUILD -DGGML_SCHED_MAX_COPIES=4\n      -DGGML_SHARED -D_DARWIN_C_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/.\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/../include\n      -O3 -DNDEBUG -std=gnu++17 -arch arm64 -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX11.0.sdk\n      -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual\n      -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes\n      -Wextra-semi -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o\n      -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o.d\n      -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o -c\n      /Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/ggml-threading.cpp\n      [5/66] /Library/Developer/CommandLineTools/usr/bin/clang -DGGML_BUILD -DGGML_SCHED_MAX_COPIES=4\n      -DGGML_SHARED -D_DARWIN_C_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/.\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/../include\n      -O3 -DNDEBUG -std=gnu11 -arch arm64 -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX11.0.sdk\n      -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes\n      -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic\n      -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return\n      -Wdouble-promotion -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o\n      -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o.d\n      -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o -c\n      /Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/ggml-alloc.c\n      [6/66] /Library/Developer/CommandLineTools/usr/bin/clang++ -DGGML_BUILD -DGGML_SCHED_MAX_COPIES=4\n      -DGGML_SHARED -D_DARWIN_C_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/.\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/../include\n      -O3 -DNDEBUG -std=gnu++17 -arch arm64 -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX11.0.sdk\n      -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual\n      -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes\n      -Wextra-semi -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o\n      -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o.d\n      -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o -c\n      /Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/ggml-opt.cpp\n      [7/66] /Library/Developer/CommandLineTools/usr/bin/clang++ -DGGML_BUILD -DGGML_SCHED_MAX_COPIES=4\n      -DGGML_SHARED -D_DARWIN_C_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/.\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/../include\n      -O3 -DNDEBUG -std=gnu++17 -arch arm64 -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX11.0.sdk\n      -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual\n      -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes\n      -Wextra-semi -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o\n      -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o.d\n      -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o -c\n      /Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/ggml-backend.cpp\n      [8/66] /Library/Developer/CommandLineTools/usr/bin/clang -DGGML_BUILD -DGGML_SCHED_MAX_COPIES=4\n      -DGGML_SHARED -D_DARWIN_C_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/.\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/../include\n      -O3 -DNDEBUG -std=gnu11 -arch arm64 -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX11.0.sdk\n      -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes\n      -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic\n      -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return\n      -Wdouble-promotion -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o\n      -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o.d\n      -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o -c\n      /Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/ggml.c\n      [9/66] /Library/Developer/CommandLineTools/usr/bin/clang++ -DGGML_BUILD -DGGML_SCHED_MAX_COPIES=4\n      -DGGML_SHARED -D_DARWIN_C_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/.\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/../include\n      -O3 -DNDEBUG -std=gnu++17 -arch arm64 -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX11.0.sdk\n      -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual\n      -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes\n      -Wextra-semi -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o\n      -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o.d\n      -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o -c\n      /Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/gguf.cpp\n      [10/66] /Library/Developer/CommandLineTools/usr/bin/clang -DGGML_BUILD -DGGML_SCHED_MAX_COPIES=4\n      -DGGML_SHARED -D_DARWIN_C_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/.\n      -I/Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/../include\n      -O3 -DNDEBUG -std=gnu11 -arch arm64 -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX11.0.sdk\n      -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes\n      -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic\n      -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return\n      -Wdouble-promotion -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o\n      -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o.d\n      -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o -c\n      /Users/litao/.cache/uv/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/88JFG40xqVBLk2fxDuWLz/src/vendor/llama.cpp/ggml/src/ggml-quants.c\n      ninja: build stopped: subcommand failed.\n\n\n      [stderr]\n      CMake Warning at vendor/llama.cpp/ggml/src/ggml-cpu/CMakeLists.txt:53 (message):\n        OpenMP not found\n      Call Stack (most recent call first):\n        vendor/llama.cpp/ggml/src/CMakeLists.txt:312 (ggml_add_cpu_backend_variant_impl)\n\n      \n      clang: error: the clang compiler does not support '-mcpu=native+dotprod+noi8mm+nosve'\n      CMake Warning at vendor/llama.cpp/ggml/src/ggml-cpu/CMakeLists.txt:151 (message):\n        Failed to get ARM features\n      Call Stack (most recent call first):\n        vendor/llama.cpp/ggml/src/CMakeLists.txt:312 (ggml_add_cpu_backend_variant_impl)\n\n      \n      CMake Warning at vendor/llama.cpp/ggml/CMakeLists.txt:285 (message):\n        GGML build version fixed at 1 likely due to a shallow clone.\n\n      \n      CMake Warning (dev) at CMakeLists.txt:13 (install):\n        Target llama has PUBLIC_HEADER files but no PUBLIC_HEADER DESTINATION.\n      Call Stack (most recent call first):\n        CMakeLists.txt:97 (llama_cpp_python_install_target)\n      This warning is for project developers.  Use -Wno-dev to suppress it.\n      \n      CMake Warning (dev) at CMakeLists.txt:21 (install):\n        Target llama has PUBLIC_HEADER files but no PUBLIC_HEADER DESTINATION.\n      Call Stack (most recent call first):\n        CMakeLists.txt:97 (llama_cpp_python_install_target)\n      This warning is for project developers.  Use -Wno-dev to suppress it.\n      \n      CMake Warning (dev) at CMakeLists.txt:13 (install):\n        Target ggml has PUBLIC_HEADER files but no PUBLIC_HEADER DESTINATION.\n      Call Stack (most recent call first):\n        CMakeLists.txt:98 (llama_cpp_python_install_target)\n      This warning is for project developers.  Use -Wno-dev to suppress it.\n      \n      CMake Warning (dev) at CMakeLists.txt:21 (install):\n        Target ggml has PUBLIC_HEADER files but no PUBLIC_HEADER DESTINATION.\n      Call Stack (most recent call first):\n        CMakeLists.txt:98 (llama_cpp_python_install_target)\n      This warning is for project developers.  Use -Wno-dev to suppress it.\n      \n\n      *** CMake build failed\n\n      hint: This usually indicates a problem with the package or the build environment.\n  help: `llama-cpp-python` (v0.3.7) was included because `dbgpt[llama-cpp]` (v0.7.0) depends on\n        `llama-cpp-python`\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "litaosmile",
      "author_type": "User",
      "created_at": "2025-03-11T03:08:24Z",
      "updated_at": "2025-03-11T03:08:24Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2432/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2432",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2432",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:41.908296",
      "comments": []
    },
    {
      "issue_number": 2431,
      "title": "[Bug] [Module Name] Bug title",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [x] Chat Data\n- [ ] Chat Excel\n- [x] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n正常\n\n### Models information\n\n正常\n\n### What happened\n\nhttps://mp.csdn.net/mp_blog/creation/editor/146154065\n\n### What you expected to happen\n\nhttps://mp.csdn.net/mp_blog/creation/editor/146154065\n\n### How to reproduce\n\nhttps://mp.csdn.net/mp_blog/creation/editor/146154065\n\n### Additional context\n\n现在AI这么火，知识库应用首当其冲，可是你们的知识库不是说做得多好，简直是一塌糊涂，不可用，还不如cherry studio和AnythingLLM，Char-DB本来是你们的强项，可是兼容性做得很差，我连接一个700表的mysql库，只能查到几张表，chardata应对大库也是无能为力，另外我们业务库是sql sqlser 2012的库、还有2016的版本的数据库添加都添加报错，虽说你们兼容很多库，却没有做相应的版本方言适配。知识图谱应用场景比较偏就算了，知识库不应该做成这样，尽管你们集成了很多功能，可是没有在一个功能上面深入，无论是知识库还是chat-db，都丢了，起大早赶晚集的感觉，另外在你们github项目地址问题的回复不可以尽量双语吗，中国人不吭中国人，我英语不是很好，还要花更多时间找问题看问题，我安装win10版本的DB-GPT耗时两天，到处报错，官方文档也不更新，人也找不到，\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "liguanghua315",
      "author_type": "User",
      "created_at": "2025-03-11T01:32:41Z",
      "updated_at": "2025-03-11T01:39:52Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2431/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2431",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2431",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:41.908316",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "非常抱歉影响你的体验，因为还不知道你的具体问题是什么，可以把你使用的版本信息，问题报错都贴在这里，目前我们是在准备v0.7.0的版本发布，如果你是main分支新拉的分支，安装部署可以参考:https://www.yuque.com/eosphoros/dbgpt-docs/nh6zd314859l38qa，英文的教程会全一些，参考: http://docs.dbgpt.cn/docs/next/overview",
          "created_at": "2025-03-11T01:39:07Z"
        }
      ]
    },
    {
      "issue_number": 2415,
      "title": "V0.6.3 DB-GPT连接SiliconCloud模型报错",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nMacOS(x86)\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [x] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n![Image](https://github.com/user-attachments/assets/1471ffee-d896-4c65-a8a1-68c763a4fe5d)\n\n### Models information\n.env文件如下：\n\nLLM_MODEL=siliconflow_proxyllm\nSILICONFLOW_MODEL_VERSION= Qwen/Qwen2.5-7B-Instruct\nSILICONFLOW_API_BASE=https://api.siliconflow.cn/v1\nSILICONFLOW_API_KEY={sk-}\n\nEMBEDDING_MODEL=proxy_http_openapi\nPROXY_HTTP_OPENAPI_PROXY_SERVER_URL=https://api.siliconflow.cn/v1/embeddings\nPROXY_HTTP_OPENAPI_PROXY_API_KEY={sk-}\nPROXY_HTTP_OPENAPI_PROXY_BACKEND=BAAI/bge-m3\n\nRERANK_MODEL=rerank_proxy_siliconflow\nRERANK_PROXY_SILICONFLOW_PROXY_SERVER_URL=https://api.siliconflow.cn/v1/rerank\nRERANK_PROXY_SILICONFLOW_PROXY_API_KEY={sk-}\nRERANK_PROXY_SILICONFLOW_PROXY_BACKEND=BAAI/bge-reranker-v2-m3\n\n\n\n\n### What happened\n\n![Image](https://github.com/user-attachments/assets/6b184d96-896c-4a1d-82a2-202e5d9234b2)\nopenai.AuthenticationError: Error code: 401 - Invalid token\n\n### What you expected to happen\n\n如何解决openai.AuthenticationError: Error code: 401 - Invalid token\n\n### How to reproduce\n\ndbgpt start webserver --port 5670\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "JacobCaiC",
      "author_type": "User",
      "created_at": "2025-03-07T11:10:17Z",
      "updated_at": "2025-03-10T09:42:37Z",
      "closed_at": "2025-03-10T09:42:37Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2415/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2415",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2415",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:42.150842",
      "comments": [
        {
          "author": "fangyinc",
          "body": "Please remove the curly braces on both sides. If my API Key is \"abc\", then it should be `SILICONFLOW_API_KEY=\"abc\"` and not `SILICONFLOW_API_KEY=\"{abc}\"`",
          "created_at": "2025-03-10T01:56:29Z"
        },
        {
          "author": "JacobCaiC",
          "body": "great，thanks",
          "created_at": "2025-03-10T09:42:25Z"
        }
      ]
    },
    {
      "issue_number": 2430,
      "title": "[Bug] [Module Name] AWEL workflow display error",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [x] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nQwen/Qwen2.5-Coder-32B-Instruct\nBAAI/bge-large-zh-v1.5\nBAAI/bge-reranker-v2-m3\n\n### What happened\n\nRequest error\n{'error': {'message': '', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n\nINFO:     172.16.12.74:63832 - \"GET /api/v2/serve/awel/flows?page=1&page_size=12 HTTP/1.1\" 401 Unauthorized\n\nwhen click AWEL workflow tab on 93eb3a7\n\n### What you expected to happen\n\ndisplay worlflow normaly.\n\n### How to reproduce\n\nclick the AWEL workflow TAB on latest version.\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "su1234121",
      "author_type": "User",
      "created_at": "2025-03-10T09:05:45Z",
      "updated_at": "2025-03-10T09:18:30Z",
      "closed_at": "2025-03-10T09:18:30Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2430/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2430",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2430",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:42.398461",
      "comments": [
        {
          "author": "fangyinc",
          "body": "Please remove your `api_keys` or set empty to `api_keys` in config file.\n```toml\n[system]\nlanguage = \"${env:DBGPT_LANG:-zh}\"\napi_keys = []\n```",
          "created_at": "2025-03-10T09:11:32Z"
        },
        {
          "author": "su1234121",
          "body": "Thanks very much",
          "created_at": "2025-03-10T09:18:21Z"
        }
      ]
    },
    {
      "issue_number": 2410,
      "title": "[Feature][ChatExcel] How to capture exceptions during SQL execution in Excel analysis and incorporate logic for LLM to regenerate SQL and retry?",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nIn ChatExcel, due to the complex data structures and types of the provided tables, the SQL statement initially generated by the LLM may not necessarily be valid or functional. Therefore, it is desirable to resubmit the exception information as part of the context to the LLM, prompting it to revise the SQL and retry. How should I proceed to implement this requirement?\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "geebytes",
      "author_type": "User",
      "created_at": "2025-03-07T08:20:58Z",
      "updated_at": "2025-03-10T04:53:18Z",
      "closed_at": "2025-03-10T03:37:33Z",
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2410/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2410",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2410",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:42.780763",
      "comments": [
        {
          "author": "fangyinc",
          "body": "I will fix it later. @geebytes ",
          "created_at": "2025-03-07T13:08:01Z"
        },
        {
          "author": "fangyinc",
          "body": "Hi, @geebytes . The previous code DB-GPT has some issues in this scenario, which we have fixed. If you are interested in catching and handling exceptions, you can modify it based on the latest code.",
          "created_at": "2025-03-10T04:01:14Z"
        },
        {
          "author": "geebytes",
          "body": "> Hi, [@geebytes](https://github.com/geebytes) . The previous code DB-GPT has some issues in this scenario, which we have fixed. If you are interested in catching and handling exceptions, you can modify it based on the latest code.\n\nthanks a lot for addressing the issues and sharing the updates!",
          "created_at": "2025-03-10T04:53:17Z"
        }
      ]
    },
    {
      "issue_number": 2427,
      "title": "[Feature][Module Name]  The knowledge base management interface supports config rerank model.",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nThe knowledge base management interface supports config rerank model.\n\n### Use case\n\n_No response_\n\n### Related issues\n\nhttps://github.com/eosphoros-ai/DB-GPT/issues/2425\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "bxfxf",
      "author_type": "User",
      "created_at": "2025-03-10T03:40:53Z",
      "updated_at": "2025-03-10T03:41:55Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2427/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2427",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2427",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:42.986360",
      "comments": []
    },
    {
      "issue_number": 2239,
      "title": "[Bug] [Module Name] Workflow context information is not ideal",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n24Gx4\n\n### Models information\n\nQwen2.5-32B\n\n### What happened\n\n上下文问题修复后，拉取分支部署，单app(单agent)，已有上下文能力， 但是工作流（智能体的对话记忆利）还是没有， 使用工作流时，第一论对话，通过意图识别出使用某个app进行回答，第二轮再询问时，第二轮对话不会根据第一论对话，从引用内容中找到相应的内容回答，如下图：\r\n![fac5af883cc37bb9b0e895c06c387e10a3833e6d50feda04837b7181d77cf477QzpcVXNlcnNcY2xhc3NcQXBwRGF0YVxSb2FtaW5nXERpbmdUYWxrXDc3Yzg5YmIzY2JhMzgzODc2MzM1X3YzXEltYWdlRmlsZXNcMTczNDkxNjA2NzkyM18wMzdCRTVDQS00RDk3LTRmNDctOTIzQS1EMDE4RTgzMTU5OTIucG5n](https://github.com/user-attachments/assets/9eb43073-b2a4-4ffa-a4b2-6f1c2cd9e2fe)\r\n\n\n### What you expected to happen\n\n实现多智能体之间的对话记忆，在意图识别后也能使上下文有效\n\n### How to reproduce\n\nAwel\r\n结构如下：\r\n![1734916108821_6EA0E3A2-104B-4119-8AA2-20D38328AC20](https://github.com/user-attachments/assets/4dfecbed-6e92-4d16-b1d3-e3f93427938d)\r\n建好后，进行对话，第一轮对话可以正确识别出意图，然后根据第一轮的对话继续进行第二轮对话。观察是否有利用上下文\r\n\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "classic325",
      "author_type": "User",
      "created_at": "2024-12-23T01:17:30Z",
      "updated_at": "2025-03-09T07:05:34Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2239/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2239",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2239",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:42.986383",
      "comments": [
        {
          "author": "classic325",
          "body": ".env配置t如下\r\n![1734915934705_2A1CD42A-698D-4224-8D06-ACEE5C307FB3](https://github.com/user-attachments/assets/9ab2c790-ce3e-4217-a884-9d4e5a1987b3)\r\n",
          "created_at": "2024-12-23T01:18:33Z"
        },
        {
          "author": "yhjun1026",
          "body": "从你截图的场景来看， 建议使用 单Agent + 多知识库绑定的方式去实现， 就可以支持历史对话上下文关联。  你使用了较为复杂的意图分类多分支Agent 流程，这里也有两种模式，流程控制 和模型控制的 多轮交互。  流程控制： 自行控制下轮对话用户交互，消息在一个convid下 自己去当起回话取上轮消息。  模型控制： 每次重新进行识别意图，意图识别的时候可以获取到上轮对话的问答内容。  另外 可以自行对总结摘要Prompt 进行修复覆盖，提升效果。  ",
          "created_at": "2024-12-23T04:02:30Z"
        },
        {
          "author": "classic325",
          "body": "> 从你截图的场景来看， 建议使用 单Agent + 多知识库绑定的方式去实现， 就可以支持历史对话上下文关联。 你使用了较为复杂的意图分类多分支Agent 流程，这里也有两种模式，流程控制 和模型控制的 多轮交互。 流程控制： 自行控制下轮对话用户交互，消息在一个convid下 自己去当起回话取上轮消息。 模型控制： 每次重新进行识别意图，意图识别的时候可以获取到上轮对话的问答内容。 另外 可以自行对总结摘要Prompt 进行修复覆盖，提升效果。\r\n\r\n如何实现以上的两种模式呢？？是否有相关文档",
          "created_at": "2024-12-23T05:09:00Z"
        },
        {
          "author": "yhjun1026",
          "body": "> > 从你截图的场景来看， 建议使用 单Agent + 多知识库绑定的方式去实现， 就可以支持历史对话上下文关联。 你使用了较为复杂的意图分类多分支Agent 流程，这里也有两种模式，流程控制 和模型控制的 多轮交互。 流程控制： 自行控制下轮对话用户交互，消息在一个convid下 自己去当起回话取上轮消息。 模型控制： 每次重新进行识别意图，意图识别的时候可以获取到上轮对话的问答内容。 另外 可以自行对总结摘要Prompt 进行修复覆盖，提升效果。\r\n> \r\n> 如何实现以上的两种模式呢？？是否有相关文档\r\n\r\n流程控制模式： Agent 的Action里有用户交互的地方 需要设置返回Ac",
          "created_at": "2024-12-23T05:39:15Z"
        },
        {
          "author": "yhjun1026",
          "body": "> > > 从你截图的场景来看， 建议使用 单Agent + 多知识库绑定的方式去实现， 就可以支持历史对话上下文关联。 你使用了较为复杂的意图分类多分支Agent 流程，这里也有两种模式，流程控制 和模型控制的 多轮交互。 流程控制： 自行控制下轮对话用户交互，消息在一个convid下 自己去当起回话取上轮消息。 模型控制： 每次重新进行识别意图，意图识别的时候可以获取到上轮对话的问答内容。 另外 可以自行对总结摘要Prompt 进行修复覆盖，提升效果。\r\n> > \r\n> > \r\n> > 如何实现以上的两种模式呢？？是否有相关文档\r\n> \r\n> 流程控制模式： Agent 的Action里有",
          "created_at": "2024-12-23T05:40:46Z"
        }
      ]
    },
    {
      "issue_number": 2115,
      "title": "There is no v0.6.1 tag image in Docker Hub",
      "body": null,
      "state": "open",
      "author": "Valdanitooooo",
      "author_type": "User",
      "created_at": "2024-11-04T07:57:28Z",
      "updated_at": "2025-03-08T21:04:35Z",
      "closed_at": null,
      "labels": [
        "stale"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2115/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2115",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2115",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:43.178320",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "we will update soon.",
          "created_at": "2024-11-08T16:32:51Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-03-08T21:04:35Z"
        }
      ]
    },
    {
      "issue_number": 2408,
      "title": "[Bug] [Knowledge Client API] The response returned by creating a space is the primary key and cannot be converted to a space model",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nLLM: proxy siliconflow \n\n### What happened\n\nWhen I run the examples/client/knowledge_crud_example.py sample code, I get the following error:\n`python examples/client/knowledge_crud_example.py \n{'success': True, 'err_code': None, 'err_msg': None, 'data': 2}\nTraceback (most recent call last):\n  File \"/mnt/d/workspace/backend/highjet/DB-GPT-ALL/DB-GPT-v0.7.0/packages/dbgpt-client/src/dbgpt_client/knowledge.py\", line 29, in create_space\n    return SpaceModel(**result[\"data\"])\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: dbgpt_client.schema.SpaceModel() argument after ** must be a mapping, not int\n\nDuring handling of the above exception, another exception occurred:`\n\n\n\n### What you expected to happen\n\nin dbgpt_client knowledge.py create_space method\n`  try:\n        res = await client.put(\"/knowledge/spaces\", model_to_dict(space_model))\n        result: Result = res.json()\n        if result[\"success\"]:\n            print(result) // **result.data is space id**  \n            return SpaceModel(**result[\"data\"])\n        else:\n            raise ClientException(status=result[\"err_code\"], reason=result)\n    except Exception as e:\n        raise ClientException(f\"Failed to update space: {e}\")\n`\n\n### How to reproduce\n\nrun   examples/client/knowledge_crud_example.py sample code \n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "vnicers",
      "author_type": "User",
      "created_at": "2025-03-07T03:29:19Z",
      "updated_at": "2025-03-07T07:36:31Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2408/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2408",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2408",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:43.377802",
      "comments": [
        {
          "author": "vnicers",
          "body": "After debug the code, it was found that the problem was here\n![Image](https://github.com/user-attachments/assets/c2d8a825-a8bc-4573-92c8-759f549792a9)\n",
          "created_at": "2025-03-07T07:36:31Z"
        }
      ]
    },
    {
      "issue_number": 2407,
      "title": "[Bug] [Knowledge] document sync batch error 'BuiltinKnowledgeGraphConfig' object has no attribute 'get'",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nIt has nothing to do with this\n\n### Models information\n\nIt has nothing to do with this\n\n### What happened\n\nIt has nothing to do with this\n\n### What you expected to happen\n\nIt has nothing to do with this\n\n### How to reproduce\n\nIt has nothing to do with this\n\n### Additional context\n\nIt has nothing to do with this\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "15089677014",
      "author_type": "User",
      "created_at": "2025-03-06T09:11:13Z",
      "updated_at": "2025-03-06T12:12:51Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2407/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2407",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2407",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:43.564454",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "what's your space type vector or graph?",
          "created_at": "2025-03-06T09:12:43Z"
        },
        {
          "author": "fangyinc",
          "body": "Please latest main branch.",
          "created_at": "2025-03-06T12:12:50Z"
        }
      ]
    },
    {
      "issue_number": 2396,
      "title": "[Bug] [Module Name] Startup failed when uv run dbgpt start webserver --config configs/dbgpt-siliconflow.toml",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nhave not startup\n\n### What happened\n\nuv run dbgpt start webserver --config configs/dbgpt-siliconflow.toml\nTraceback (most recent call last):\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/torch/__init__.py\", line 300, in _load_global_deps\n    ctypes.CDLL(global_deps_lib_path, mode=ctypes.RTLD_GLOBAL)\n  File \"/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/ctypes/__init__.py\", line 376, in __init__\n    self._handle = _dlopen(self._name, mode)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^\nOSError: libcudart.so.12: cannot open shared object file: No such file or directory\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/root/DB-GPT/.venv/bin/dbgpt\", line 10, in <module>\n    sys.exit(main())\n             ^^^^^^\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/cli/cli_scripts.py\", line 227, in main\n    return cli()\n           ^^^^^\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/click/core.py\", line 1161, in __call__\n    return self.main(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/click/core.py\", line 1082, in main\n    rv = self.invoke(ctx)\n         ^^^^^^^^^^^^^^^^\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/click/core.py\", line 1697, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/click/core.py\", line 1697, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/click/core.py\", line 1443, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/click/core.py\", line 788, in invoke\n    return __callback(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/cli.py\", line 458, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/DB-GPT/packages/dbgpt-app/src/dbgpt_app/_cli.py\", line 25, in start_webserver\n    run_webserver(config)\n  File \"/root/DB-GPT/packages/dbgpt-app/src/dbgpt_app/dbgpt_server.py\", line 222, in run_webserver\n    param = load_config(config_file)\n            ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/DB-GPT/packages/dbgpt-app/src/dbgpt_app/dbgpt_server.py\", line 292, in load_config\n    scan_configs()\n  File \"/root/DB-GPT/packages/dbgpt-app/src/dbgpt_app/dbgpt_server.py\", line 267, in scan_configs\n    scan_model_providers()\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/__init__.py\", line 66, in scan_model_providers\n    scanner.scan_and_register(embedding_config)\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/util/module_utils.py\", line 239, in scan_and_register\n    module = importlib.import_module(config.module_path)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/rag/embedding/__init__.py\", line 8, in <module>\n    from .embeddings import (  # noqa: F401\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/rag/embedding/embeddings.py\", line 34, in <module>\n    import transformers\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/transformers/__init__.py\", line 26, in <module>\n    from . import dependency_versions_check\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/transformers/dependency_versions_check.py\", line 16, in <module>\n    from .utils.versions import require_version, require_version_core\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/transformers/utils/__init__.py\", line 27, in <module>\n    from .chat_template_utils import DocstringParsingException, TypeHintParsingException, get_json_schema\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/transformers/utils/chat_template_utils.py\", line 40, in <module>\n    from torch import Tensor\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/torch/__init__.py\", line 366, in <module>\n    _load_global_deps()\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/torch/__init__.py\", line 324, in _load_global_deps\n    _preload_cuda_deps(lib_folder, lib_name)\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/torch/__init__.py\", line 284, in _preload_cuda_deps\n    raise ValueError(f\"{lib_name} not found in the system path {sys.path}\")\nValueError: libcublas.so.*[0-9] not found in the system path ['/root/DB-GPT/.venv/bin', '/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python311.zip', '/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11', '/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/lib-dynload', '/root/DB-GPT/.venv/lib/python3.11/site-packages', '/root/DB-GPT/packages/dbgpt-core/src', '/root/DB-GPT/packages/dbgpt-app/src', '/root/DB-GPT/packages/dbgpt-client/src', '/root/DB-GPT/packages/dbgpt-ext/src', '/root/DB-GPT/packages/dbgpt-serve/src', '/root/DB-GPT/packages/dbgpt-app', '/root/DB-GPT/packages/dbgpt-app']\n\n### What you expected to happen\n\nstartup success!\n\n### How to reproduce\n\n今早拉取的main分支，使用硅基流动API启动时报错\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "su1234121",
      "author_type": "User",
      "created_at": "2025-03-05T02:16:18Z",
      "updated_at": "2025-03-06T09:37:01Z",
      "closed_at": "2025-03-05T05:33:04Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 14,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2396/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2396",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2396",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:43.747169",
      "comments": [
        {
          "author": "fangyinc",
          "body": "Hi, @su1234121. Think you for your feedback.\nPlease provide your full `uv sync` command.",
          "created_at": "2025-03-05T02:59:14Z"
        },
        {
          "author": "su1234121",
          "body": "> Hi, [@su1234121](https://github.com/su1234121). Think you for your feedback. Please provide your full `uv sync` command.\n\nuv sync --all-packages\n--extra \"base\"\n--extra \"proxy_openai\"\n--extra \"rag\"\n--extra \"storage_chromadb\"\n--extra \"dbgpts\" \\",
          "created_at": "2025-03-05T03:05:37Z"
        },
        {
          "author": "su1234121",
          "body": "如最后的报错原因所示：ValueError: libcublas.so.[0-9] not found in the system path，\n我的电脑有nvidia显卡，装了Cuda 驱动后 问题已经不见了，但是按照我的理解 代理模式应该不会需要显卡和驱动支持才对",
          "created_at": "2025-03-05T03:12:07Z"
        },
        {
          "author": "su1234121",
          "body": "还是会报错，只是报错信息变短了\n uv run dbgpt start webserver --config configs/dbgpt-siliconflow.toml\nTraceback (most recent call last):\n  File \"/root/DB-GPT/.venv/bin/dbgpt\", line 10, in <module>\n    sys.exit(main())\n             ^^^^^^\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/cli/cli_scripts.py\", line 2",
          "created_at": "2025-03-05T03:15:28Z"
        },
        {
          "author": "fangyinc",
          "body": "> 还是会报错，只是报错信息变短了 uv run dbgpt start webserver --config configs/dbgpt-siliconflow.toml Traceback (most recent call last): File \"/root/DB-GPT/.venv/bin/dbgpt\", line 10, in sys.exit(main()) ^^^^^^ File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/cli/cli_scripts.py\", line 227, in main return cli() ^^^^",
          "created_at": "2025-03-05T03:43:11Z"
        }
      ]
    },
    {
      "issue_number": 2406,
      "title": "[Bug] [Konwledge] konwledge create_document error",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nhave nothing to do with\n\n### Models information\n\nhave nothing to do with\n\n### What happened\n\nhave nothing to do with\n\n### What you expected to happen\n\nhave nothing to do with\n\n### How to reproduce\n\nhave nothing to do with\n\n### Additional context\n\n执行以下代码遇到了报错\n\n\"\"\"Client: Simple Knowledge CRUD example.\n\nThis example demonstrates how to use the dbgpt client to create, get, update, and\ndelete knowledge spaces and documents.\n\nExample:\n    .. code-block:: python\n\n        DBGPT_API_KEY = \"dbgpt\"\n        client = Client(api_key=DBGPT_API_KEY)\n        # 1. Create a space\n        res = await create_space(\n            client,\n            SpaceModel(\n                name=\"test_space\",\n                vector_type=\"Chroma\",\n                desc=\"for client space\",\n                owner=\"dbgpt\",\n            ),\n        )\n        # 2. Update a space\n        res = await update_space(\n            client,\n            SpaceModel(\n                name=\"test_space\",\n                vector_type=\"Chroma\",\n                desc=\"for client space333\",\n                owner=\"dbgpt\",\n            ),\n        )\n        # 3. Delete a space\n        res = await delete_space(client, space_id=\"37\")\n        # 4. Get a space\n        res = await get_space(client, space_id=\"5\")\n        # 5. List all spaces\n        res = await list_space(client)\n        # 6. Create a document\n        res = await create_document(\n            client,\n            DocumentModel(\n                space_id=\"5\",\n                doc_name=\"test_doc\",\n                doc_type=\"TEXT\",\n                doc_content=\"test content\",\n                doc_source=\"\",\n            ),\n        )\n        # 7. Sync a document\n        res = await sync_document(\n            client,\n            sync_model=SyncModel(\n                doc_id=\"153\",\n                space_id=\"40\",\n                model_name=\"text2vec\",\n                chunk_parameters=ChunkParameters(chunk_strategy=\"Automatic\"),\n            ),\n        )\n        # 8. Get a document\n        res = await get_document(client, \"52\")\n        # 9. List all documents\n        res = await list_document(client)\n        # 10. Delete a document\n        res = await delete_document(client, \"150\")\n\"\"\"\n\nimport asyncio\n\nfrom dbgpt_client import Client\nfrom dbgpt_client.knowledge import *\nfrom dbgpt_client.schema import SpaceModelNow\nfrom fastapi import File, UploadFile\n\nasync def main():\n    # initialize client\n    DBGPT_API_KEY = \"dbgpt\"\n    client = Client(api_key=DBGPT_API_KEY)\n    try:\n        # res = await create_space(\n        #     client,\n        #     SpaceModelNow(\n        #         name=\"test_space_1\",\n        #         vector_type=\"Chroma\",\n        #         desc=\"for client space desc\",\n        #         owner=\"dbgpt\",\n        #     ),\n        # )\n        # print(res)\n\n        # # list all spaces\n        # res = await list_space(client)\n        # print(res)\n\n        # get space\n        # res = await get_space(client, space_id='5')\n\n        # create space\n        # res = await create_space(client, SpaceModel(name=\"test_space\", vector_type=\"Chroma\", desc=\"for client space\", owner=\"dbgpt\"))\n\n        # update space\n        # res = await update_space(client, SpaceModelNow(name=\"test_space_1\", vector_type=\"Chroma\", desc=\"for client space444\", owner=\"dbgpt\"))\n\n        # delete space\n        # res = await delete_space(client, space_id='31')\n        # print(res)\n\n        # list all documents\n        # res = await list_document(client)\n        # print(res)\n\n        # get document\n        # res = await get_document(client, \"52\")\n\n        # delete document\n        # res = await delete_document(client, \"150\")\n\n        # create document\n        from dbgpt._private.pydantic import Field\n        res = await create_document(\n            client,\n            DocumentModel(\n                id=1,\n                space_id=\"1\",\n                body={\n                    Field(\"space_id\", description=\"body name\"): Field('1', description=\"body name\"),\n                    Field(\"doc_type\", description=\"body name\"): Field('TEXT', description=\"body name\"),\n                    Field(\"doc_name\", description=\"body name\"): Field('test_doc', description=\"body name\")\n                },\n                doc_name=\"test_doc\",\n                doc_type=\"TEXT\",\n                content=\"test content\",\n                doc_file=UploadFile(\n                    file=open('C:\\\\Users\\\\12073\\\\Desktop\\\\新建 文本文档 (3).txt', 'rb'),\n                    filename=\"knowledge.txt\"\n                ),\n                doc_source=\"local\"\n            )\n        )\n\n        # doc_file=(\n        #     '知识表', open('C:\\\\Users\\\\12073\\\\Desktop\\\\新建 文本文档 (3).txt', 'rb')),\n        # )\n        # sync document\n        # res = await sync_document(client, sync_model=SyncModel(doc_id=\"157\", space_id=\"49\", model_name=\"text2vec\", chunk_parameters=ChunkParameters(chunk_strategy=\"Automatic\")))\n    finally:\n        await client.aclose()  # 异步关闭\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n\n\n\nC:\\WWW\\DB-GPT-v0.7.0\\.venv\\Scripts\\python.exe C:\\WWW\\DB-GPT-v0.7.0\\examples\\client\\knowledge_crud_example.py \nTraceback (most recent call last):\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\examples\\client\\knowledge_crud_example.py\", line 68, in <module>\n    from dbgpt_client import Client\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\packages\\dbgpt-client\\src\\dbgpt_client\\__init__.py\", line 3, in <module>\n    from .client import Client, ClientException  # noqa: F401\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\packages\\dbgpt-client\\src\\dbgpt_client\\client.py\", line 14, in <module>\n    from .schema import ChatCompletionRequestBody\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\packages\\dbgpt-client\\src\\dbgpt_client\\schema.py\", line 265, in <module>\n    class DocumentModel(BaseModel):\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_model_construction.py\", line 224, in __new__\n    complete_model_class(\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_model_construction.py\", line 602, in complete_model_class\n    schema = cls.__get_pydantic_core_schema__(cls, handler)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\.venv\\Lib\\site-packages\\pydantic\\main.py\", line 702, in __get_pydantic_core_schema__\n    return handler(source)\n           ^^^^^^^^^^^^^^^\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_schema_generation_shared.py\", line 84, in __call__\n    schema = self._handler(source_type)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py\", line 610, in generate_schema\n    schema = self._generate_schema_inner(obj)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py\", line 879, in _generate_schema_inner\n    return self._model_schema(obj)\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py\", line 691, in _model_schema\n    {k: self._generate_md_field_schema(k, v, decorators) for k, v in fields.items()},\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py\", line 691, in <dictcomp>\n    {k: self._generate_md_field_schema(k, v, decorators) for k, v in fields.items()},\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py\", line 1071, in _generate_md_field_schema\n    common_field = self._common_field_schema(name, field_info, decorators)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py\", line 1263, in _common_field_schema\n    schema = self._apply_annotations(\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py\", line 2056, in _apply_annotations\n    schema = get_inner_schema(source_type)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_schema_generation_shared.py\", line 84, in __call__\n    schema = self._handler(source_type)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py\", line 2037, in inner_handler\n    schema = self._generate_schema_inner(obj)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py\", line 884, in _generate_schema_inner\n    return self.match_type(obj)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py\", line 986, in match_type\n    return self._match_generic_type(obj, origin)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py\", line 1014, in _match_generic_type\n    return self._union_schema(obj)\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py\", line 1325, in _union_schema\n    choices.append(self.generate_schema(arg))\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py\", line 610, in generate_schema\n    schema = self._generate_schema_inner(obj)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py\", line 884, in _generate_schema_inner\n    return self.match_type(obj)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py\", line 986, in match_type\n    return self._match_generic_type(obj, origin)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py\", line 1024, in _match_generic_type\n    return self._dict_schema(*self._get_first_two_args_or_any(obj))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py\", line 370, in _dict_schema\n    return core_schema.dict_schema(self.generate_schema(keys_type), self.generate_schema(values_type))\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py\", line 610, in generate_schema\n    schema = self._generate_schema_inner(obj)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py\", line 884, in _generate_schema_inner\n    return self.match_type(obj)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py\", line 975, in match_type\n    return self._call_schema(obj)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py\", line 1818, in _call_schema\n    type_hints = _typing_extra.get_function_type_hints(function, globalns=globalns, localns=localns)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_typing_extra.py\", line 730, in get_function_type_hints\n    type_hints[name] = eval_type_backport(value, globalns, localns, type_params)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_typing_extra.py\", line 609, in eval_type_backport\n    return _eval_type_backport(value, globalns, localns, type_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_typing_extra.py\", line 633, in _eval_type_backport\n    return _eval_type(value, globalns, localns, type_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\WWW\\DB-GPT-v0.7.0\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_typing_extra.py\", line 667, in _eval_type\n    return typing._eval_type(  # type: ignore\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\12073\\AppData\\Roaming\\uv\\python\\cpython-3.11.11-windows-x86_64-none\\Lib\\typing.py\", line 395, in _eval_type\n    return t._evaluate(globalns, localns, recursive_guard)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\12073\\AppData\\Roaming\\uv\\python\\cpython-3.11.11-windows-x86_64-none\\Lib\\typing.py\", line 905, in _evaluate\n    eval(self.__forward_code__, globalns, localns),\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 1, in <module>\nNameError: name 'Callable' is not defined. Did you mean: 'callable'?\n\n进程已结束，退出代码为 1\n\n需要先修复的文件\n\nC:\\WWW\\DB-GPT-v0.7.0\\packages\\dbgpt-client\\src\\dbgpt_client\\schema.py  \n\"\"\"this module contains the schemas for the dbgpt client.\"\"\"\n\nimport json\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Union\n\nfrom fastapi import File, UploadFile\n\nfrom dbgpt._private.pydantic import BaseModel, ConfigDict, Field\nfrom dbgpt_ext.rag.chunk_manager import ChunkParameters\n\n\nclass ChatCompletionRequestBody(BaseModel):\n    \"\"\"ChatCompletion LLM http request body.\"\"\"\n\n    model: str = Field(\n        ..., description=\"The model name\", examples=[\"gpt-3.5-turbo\", \"proxyllm\"]\n    )\n    messages: Union[str, List[str]] = Field(\n        ..., description=\"User input messages\", examples=[\"Hello\", \"How are you?\"]\n    )\n    stream: bool = Field(default=True, description=\"Whether return stream\")\n\n    temperature: Optional[float] = Field(\n        default=None,\n        description=\"What sampling temperature to use, between 0 and 2. Higher values \"\n        \"like 0.8 will make the output more random, \"\n        \"while lower values like 0.2 will \"\n        \"make it more focused and deterministic.\",\n    )\n    max_new_tokens: Optional[int] = Field(\n        default=None,\n        description=\"The maximum number of tokens that can be generated in the chat \"\n        \"completion.\",\n    )\n    conv_uid: Optional[str] = Field(\n        default=None, description=\"The conversation id of the model inference\"\n    )\n    span_id: Optional[str] = Field(\n        default=None, description=\"The span id of the model inference\"\n    )\n    chat_mode: Optional[str] = Field(\n        default=\"chat_normal\",\n        description=\"The chat mode\",\n        examples=[\"chat_awel_flow\", \"chat_normal\"],\n    )\n    chat_param: Optional[str] = Field(\n        default=None,\n        description=\"The chat param of chat mode\",\n    )\n    user_name: Optional[str] = Field(\n        default=None, description=\"The user name of the model inference\"\n    )\n    sys_code: Optional[str] = Field(\n        default=None, description=\"The system code of the model inference\"\n    )\n    incremental: bool = Field(\n        default=True,\n        description=\"Used to control whether the content is returned incrementally \"\n        \"or in full each time. \"\n        \"If this parameter is not provided, the default is full return.\",\n    )\n    enable_vis: bool = Field(\n        default=True, description=\"response content whether to output vis label\"\n    )\n\n\nclass ChatMode(Enum):\n    \"\"\"Chat mode.\"\"\"\n\n    CHAT_NORMAL = \"chat_normal\"\n    CHAT_APP = \"chat_app\"\n    CHAT_AWEL_FLOW = \"chat_flow\"\n    CHAT_KNOWLEDGE = \"chat_knowledge\"\n    CHAT_DATA = \"chat_data\"\n\n\nclass AWELTeamModel(BaseModel):\n    \"\"\"AWEL team model.\"\"\"\n\n    dag_id: str = Field(\n        ...,\n        description=\"The unique id of dag\",\n        examples=[\"flow_dag_testflow_66d8e9d6-f32e-4540-a5bd-ea0648145d0e\"],\n    )\n    uid: str = Field(\n        default=None,\n        description=\"The unique id of flow\",\n        examples=[\"66d8e9d6-f32e-4540-a5bd-ea0648145d0e\"],\n    )\n    name: Optional[str] = Field(\n        default=None,\n        description=\"The name of dag\",\n    )\n    label: Optional[str] = Field(\n        default=None,\n        description=\"The label of dag\",\n    )\n    version: Optional[str] = Field(\n        default=None,\n        description=\"The version of dag\",\n    )\n    description: Optional[str] = Field(\n        default=None,\n        description=\"The description of dag\",\n    )\n    editable: bool = Field(\n        default=False,\n        description=\"is the dag is editable\",\n        examples=[True, False],\n    )\n    state: Optional[str] = Field(\n        default=None,\n        description=\"The state of dag\",\n    )\n    user_name: Optional[str] = Field(\n        default=None,\n        description=\"The owner of current dag\",\n    )\n    sys_code: Optional[str] = Field(\n        default=None,\n        description=\"The system code of current dag\",\n    )\n    flow_category: Optional[str] = Field(\n        default=\"common\",\n        description=\"The flow category of current dag\",\n    )\n\n\nclass AgentResourceType(Enum):\n    \"\"\"Agent resource type.\"\"\"\n\n    DB = \"database\"\n    Knowledge = \"knowledge\"\n    Internet = \"internet\"\n    Plugin = \"plugin\"\n    TextFile = \"text_file\"\n    ExcelFile = \"excel_file\"\n    ImageFile = \"image_file\"\n    AWELFlow = \"awel_flow\"\n\n\nclass AgentResourceModel(BaseModel):\n    \"\"\"Agent resource model.\"\"\"\n\n    type: str\n    name: str\n    value: str\n    is_dynamic: bool = (\n        False  # Is the current resource predefined or dynamically passed in?\n    )\n\n    @staticmethod\n    def from_dict(d: Dict[str, Any]):\n        \"\"\"From dict.\"\"\"\n        if d is None:\n            return None\n        return AgentResourceModel(\n            type=d.get(\"type\"),\n            name=d.get(\"name\"),\n            introduce=d.get(\"introduce\"),\n            value=d.get(\"value\", None),\n            is_dynamic=d.get(\"is_dynamic\", False),\n        )\n\n    @staticmethod\n    def from_json_list_str(d: Optional[str]):\n        \"\"\"From json list str.\"\"\"\n        if d is None:\n            return None\n        try:\n            json_array = json.loads(d)\n        except Exception as e:\n            raise ValueError(f\"Illegal AgentResource json string！{d},{e}\")\n        return [AgentResourceModel.from_dict(item) for item in json_array]\n\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"To dict.\"\"\"\n        temp = self.dict()\n        for field, value in temp.items():\n            if isinstance(value, Enum):\n                temp[field] = value.value\n        return temp\n\n\nclass AppDetailModel(BaseModel):\n    \"\"\"App detail model.\"\"\"\n\n    app_code: Optional[str] = Field(None, description=\"app code\")\n    app_name: Optional[str] = Field(None, description=\"app name\")\n    agent_name: Optional[str] = Field(None, description=\"agent name\")\n    node_id: Optional[str] = Field(None, description=\"node id\")\n    resources: Optional[list[AgentResourceModel]] = Field(None, description=\"resources\")\n    prompt_template: Optional[str] = Field(None, description=\"prompt template\")\n    llm_strategy: Optional[str] = Field(None, description=\"llm strategy\")\n    llm_strategy_value: Optional[str] = Field(None, description=\"llm strategy value\")\n    created_at: datetime = datetime.now()\n    updated_at: datetime = datetime.now()\n\n\nclass AppModel(BaseModel):\n    \"\"\"App model.\"\"\"\n\n    app_code: Optional[str] = Field(None, title=\"app code\")\n    app_name: Optional[str] = Field(None, title=\"app name\")\n    app_describe: Optional[str] = Field(None, title=\"app describe\")\n    team_mode: Optional[str] = Field(None, title=\"team mode\")\n    language: Optional[str] = Field(\"en\", title=\"language\")\n    team_context: Optional[Union[str, dict]] = Field(None, title=\"team context\")\n    user_code: Optional[str] = Field(None, title=\"user code\")\n    sys_code: Optional[str] = Field(None, title=\"sys code\")\n    is_collected: Optional[str] = Field(None, title=\"is collected\")\n    icon: Optional[str] = Field(None, title=\"icon\")\n    created_at: datetime = datetime.now()\n    updated_at: datetime = datetime.now()\n    details: List[AppDetailModel] = Field([], title=\"app details\")\n\n\nclass SpaceModel(BaseModel):\n    \"\"\"Space model.\"\"\"\n\n    id: Optional[int] = Field(\n        default=None,\n        description=\"space id\",\n    )\n    name: Optional[str] = Field(\n        default=None,\n        description=\"knowledge space name\",\n    )\n    vector_type: Optional[str] = Field(\n        default=None,\n        description=\"vector type\",\n    )\n    desc: Optional[str] = Field(\n        default=None,\n        description=\"space description\",\n    )\n    owner: Optional[str] = Field(\n        default=None,\n        description=\"space owner\",\n    )\n    context: Optional[str] = Field(\n        default=None,\n        description=\"space argument context\",\n    )\n\nclass SpaceModelNow(SpaceModel):\n    domain_type: Optional[str] = Field(\n        default='Normal',\n        description=\"space argument domain_type\",\n    )\n\n    user_ids: Optional[str] = Field(\n        default=None,\n        description=\"space argument user_ids\",\n    )\n\n    user_id: Optional[str] = Field(\n        default=None,\n        description=\"space argument user_id\",\n    )\n\n\nclass DocumentModel(BaseModel):\n    \"\"\"Document model.\"\"\"\n\n    id: int = Field(None, description=\"The doc id\")\n    body: Optional[dict[Field, Field]] = Field(None, description=\"body name\")\n\n    doc_name: str = Field(None, description=\"doc name\")\n    \"\"\"doc_type: document type\"\"\"\n    doc_type: str = Field(None, description=\"The doc type\")\n    \"\"\"content: description\"\"\"\n    content: str = Field(None, description=\"content\")\n    \"\"\"doc file\"\"\"\n    doc_file: UploadFile = Field(File(None), description=\"doc file\")\n    \"\"\"doc_source: doc source\"\"\"\n    doc_source: str = Field(None, description=\"doc source\")\n    \"\"\"doc_source: doc source\"\"\"\n    space_id: str = Field(None, description=\"space_id\")\n\n\nclass SyncModel(BaseModel):\n    \"\"\"Sync model.\"\"\"\n\n    model_config = ConfigDict(protected_namespaces=())\n\n    \"\"\"doc_id: doc id\"\"\"\n    doc_id: str = Field(None, description=\"The doc id\")\n\n    \"\"\"space id\"\"\"\n    space_id: str = Field(None, description=\"The space id\")\n\n    \"\"\"model_name: model name\"\"\"\n    model_name: Optional[str] = Field(None, description=\"model name\")\n\n    \"\"\"chunk_parameters: chunk parameters\n    \"\"\"\n    chunk_parameters: ChunkParameters = Field(None, description=\"chunk parameters\")\n\n\nclass DatasourceModel(BaseModel):\n    \"\"\"Datasource model.\"\"\"\n\n    id: Optional[int] = Field(None, description=\"The datasource id\")\n    db_type: str = Field(..., description=\"Database type, e.g. sqlite, mysql, etc.\")\n    db_name: str = Field(..., description=\"Database name.\")\n    db_path: str = Field(\"\", description=\"File path for file-based database.\")\n    db_host: str = Field(\"\", description=\"Database host.\")\n    db_port: int = Field(0, description=\"Database port.\")\n    db_user: str = Field(\"\", description=\"Database user.\")\n    db_pwd: str = Field(\"\", description=\"Database password.\")\n    comment: str = Field(\"\", description=\"Comment for the database.\")\n\n\nC:\\WWW\\DB-GPT-v0.7.0\\packages\\dbgpt-client\\src\\dbgpt_client\\knowledge.py\n\"\"\"Knowledge API client.\"\"\"\n\nimport json\nfrom typing import List\n\nfrom dbgpt._private.pydantic import model_to_dict, model_to_json\nfrom dbgpt.core.schema.api import Result\n\nfrom .client import Client, ClientException\nfrom .schema import DocumentModel, SpaceModelNow, SyncModel\n\n\nasync def create_space(client: Client, space_model: SpaceModelNow) -> SpaceModelNow:\n    \"\"\"Create a new space.\n\n    Args:\n        client (Client): The dbgpt client.\n        space_model (SpaceModelNow): The space model.\n    Returns:\n        SpaceModelNow: The space model.\n    Raises:\n        ClientException: If the request failed.\n    \"\"\"\n    try:\n        res = await client.post(\"/knowledge/spaces\", model_to_dict(space_model))\n        result: Result = res.json()\n        if result[\"success\"]:\n            return SpaceModelNow(**result[\"data\"])\n        else:\n            raise ClientException(status=result[\"err_code\"], reason=result)\n    except Exception as e:\n        raise ClientException(f\"Failed to create space: {e}\")\n\n\nasync def update_space(client: Client, space_model: SpaceModelNow) -> SpaceModelNow:\n    \"\"\"Update a document.\n\n    Args:\n        client (Client): The dbgpt client.\n        space_model (SpaceModelNow): The space model.\n    Returns:\n        SpaceModelNow: The space model.\n    Raises:\n        ClientException: If the request failed.\n    \"\"\"\n    try:\n        res = await client.put(\"/knowledge/spaces\", model_to_dict(space_model))\n        result: Result = res.json()\n        if result[\"success\"]:\n            print(result)\n            return SpaceModelNow(**result[\"data\"])\n        else:\n            raise ClientException(status=result[\"err_code\"], reason=result)\n    except Exception as e:\n        raise ClientException(f\"Failed to update space: {e}\")\n\n\nasync def delete_space(client: Client, space_id: str) -> SpaceModelNow:\n    \"\"\"Delete a space.\n\n    Args:\n        client (Client): The dbgpt client.\n        space_id (str): The space id.\n    Returns:\n        SpaceModelNow: The space model.\n    Raises:\n        ClientException: If the request failed.\n    \"\"\"\n    try:\n        res = await client.delete(\"/knowledge/spaces/\" + space_id)\n        result: Result = res.json()\n        if result[\"success\"]:\n            return SpaceModelNow(**result[\"data\"])\n        else:\n            raise ClientException(status=result[\"err_code\"], reason=result)\n    except Exception as e:\n        raise ClientException(f\"Failed to delete space: {e}\")\n\n\nasync def get_space(client: Client, space_id: str) -> SpaceModelNow:\n    \"\"\"Get a document.\n\n    Args:\n        client (Client): The dbgpt client.\n        space_id (str): The space id.\n    Returns:\n        SpaceModelNow: The space model.\n    Raises:\n        ClientException: If the request failed.\n    \"\"\"\n    try:\n        res = await client.get(\"/knowledge/spaces/\" + space_id)\n        result: Result = res.json()\n        if result[\"success\"]:\n            return SpaceModelNow(**result[\"data\"])\n        else:\n            raise ClientException(status=result[\"err_code\"], reason=result)\n    except Exception as e:\n        raise ClientException(f\"Failed to get space: {e}\")\n\n\nasync def list_space(client: Client) -> List[SpaceModelNow]:\n    \"\"\"List spaces.\n\n    Args:\n        client (Client): The dbgpt client.\n    Returns:\n        List[SpaceModelNow]: The list of space models.\n    Raises:\n        ClientException: If the request failed.\n    \"\"\"\n    try:\n        res = await client.get(\"/knowledge/spaces\")\n        result: Result = res.json()\n        if result[\"success\"]:\n            return [SpaceModelNow(**space) for space in result[\"data\"][\"items\"]]\n        else:\n            raise ClientException(status=result[\"err_code\"], reason=result)\n    except Exception as e:\n        raise ClientException(f\"Failed to list spaces: {e}\")\n\n\nasync def create_document(client: Client, doc_model: DocumentModel) -> DocumentModel:\n    \"\"\"Create a new document.\n\n    Args:\n        client (Client): The dbgpt client.\n        doc_model (SpaceModelNow): The document model.\n\n    \"\"\"\n    try:\n        res = await client.post_param(\"/knowledge/documents\", model_to_dict(doc_model))\n        result: Result = res.json()\n        if result[\"success\"]:\n            return DocumentModel(**result[\"data\"])\n        else:\n            raise ClientException(status=result[\"err_code\"], reason=result)\n    except Exception as e:\n        raise ClientException(f\"Failed to create document: {e}\")\n\n\nasync def delete_document(client: Client, document_id: str) -> DocumentModel:\n    \"\"\"Delete a document.\n\n    Args:\n        client (Client): The dbgpt client.\n        document_id (str): The document id.\n    Returns:\n        DocumentModel: The document model.\n    Raises:\n        ClientException: If the request failed.\n    \"\"\"\n    try:\n        res = await client.delete(\"/knowledge/documents/\" + document_id)\n        result: Result = res.json()\n        if result[\"success\"]:\n            return DocumentModel(**result[\"data\"])\n        else:\n            raise ClientException(status=result[\"err_code\"], reason=result)\n    except Exception as e:\n        raise ClientException(f\"Failed to delete document: {e}\")\n\n\nasync def get_document(client: Client, document_id: str) -> DocumentModel:\n    \"\"\"Get a document.\n\n    Args:\n        client (Client): The dbgpt client.\n        document_id (str): The document id.\n    Returns:\n        DocumentModel: The document model.\n    Raises:\n        ClientException: If the request failed.\n    \"\"\"\n    try:\n        res = await client.get(\"/knowledge/documents/\" + document_id)\n        result: Result = res.json()\n        if result[\"success\"]:\n            return DocumentModel(**result[\"data\"])\n        else:\n            raise ClientException(status=result[\"err_code\"], reason=result)\n    except Exception as e:\n        raise ClientException(f\"Failed to get document: {e}\")\n\n\nasync def list_document(client: Client) -> List[DocumentModel]:\n    \"\"\"List documents.\n\n    Args:\n        client (Client): The dbgpt client.\n    \"\"\"\n    try:\n        res = await client.get(\"/knowledge/documents\")\n        result: Result = res.json()\n        if result[\"success\"]:\n            return [DocumentModel(**document) for document in result[\"data\"][\"items\"]]\n        else:\n            raise ClientException(status=result[\"err_code\"], reason=result)\n    except Exception as e:\n        raise ClientException(f\"Failed to list documents: {e}\")\n\n\nasync def sync_document(client: Client, sync_model: SyncModel) -> List:\n    \"\"\"Sync document.\n\n    Args:\n        client (Client): The dbgpt client.\n        sync_model (SyncModel): The sync model.\n    Returns:\n        List: The list of document ids.\n    Raises:\n        ClientException: If the request failed.\n    \"\"\"\n    try:\n        res = await client.post(\n            \"/knowledge/documents/sync\", [json.loads(model_to_json(sync_model))]\n        )\n        result: Result = res.json()\n        if result[\"success\"]:\n            return result[\"data\"]\n        else:\n            raise ClientException(status=result[\"err_code\"], reason=result)\n    except Exception as e:\n        raise ClientException(f\"Failed to list documents: {e}\")\n\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "15089677014",
      "author_type": "User",
      "created_at": "2025-03-06T08:18:54Z",
      "updated_at": "2025-03-06T08:18:54Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2406/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2406",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2406",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:43.953780",
      "comments": []
    },
    {
      "issue_number": 2400,
      "title": "[Bug] [Module Name] 在知识库界面点击向量类型的知识库时,右上角报错",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [x] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nBAAI/bge-large-zh-v1.5\nBAAI/bge-reranker-v2-m3\nQwen/Qwen2.5-72B-Instruct-128K\n\n### What happened\n\n点击删除KnowledgeGraph类型的知识库时，右上角报错：space delete error 'BuiltinKnowledgeGraphConfig' object does not support item assignment\n但是后台界面显示没有额外异常信息，知识库没有正常删除\n2025-03-05 17:03:53 DESKTOP-0RMTJO2 dbgpt_serve.rag.connector[6108] INFO VectorStore:<class 'dbgpt_ext.storage.knowledge_graph.knowledge_graph.BuiltinKnowledgeGraph'>\nINFO:     172.16.12.74:52738 - \"POST /knowledge/space/delete HTTP/1.1\" 200 OK\n/space/list params:\nINFO:     172.16.12.74:52738 - \"POST /knowledge/space/list HTTP/1.1\" 200 OK\n\n### What you expected to happen\n\n正常删除知识库\n\n### How to reproduce\n\n创建一个空的KnowledgeGraph类型的知识库，然后点击删除\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "su1234121",
      "author_type": "User",
      "created_at": "2025-03-05T09:05:34Z",
      "updated_at": "2025-03-06T07:16:09Z",
      "closed_at": "2025-03-06T07:16:09Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2400/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2400",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2400",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:43.953813",
      "comments": []
    },
    {
      "issue_number": 2403,
      "title": "[Bug] [Module Name] Startup failed when uv run dbgpt start webserver --config configs/dbgpt-proxy-deepseek.toml",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\n[models]\n[[models.llms]]\nname = \"deepseek-reasoner\"\n# name = \"deepseek-chat\"\nprovider = \"proxy/deepseek\"\napi_key = \"*****\"\n\n[[models.embeddings]]\nname = \"BAAI/bge-large-zh-v1.5\"\nprovider = \"hf\"\n# If not provided, the model will be downloaded from the Hugging Face model hub\n# uncomment the following line to specify the model path in the local file system\n# path = \"the-model-path-in-the-local-file-system\"\npath = \"/data/models/bge-large-zh-v1.5\"\n\n\n### What happened\n\nError starting worker manager: model deepseek-reasoner@proxy/deepseek(192.168.1.223:5670) start failed, Traceback (most recent call last):\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/torch/__init__.py\", line 300, in _load_global_deps\n    ctypes.CDLL(global_deps_lib_path, mode=ctypes.RTLD_GLOBAL)\n  File \"/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/ctypes/__init__.py\", line 376, in __init__\n    self._handle = _dlopen(self._name, mode)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^\nOSError: libcudart.so.12: cannot open shared object file: No such file or directory\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/cluster/worker/manager.py\", line 631, in _start_worker\n    await self.run_blocking_func(\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/cluster/worker/manager.py\", line 146, in run_blocking_func\n    return await loop.run_in_executor(self.executor, func, *args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/cluster/worker/default_worker.py\", line 102, in start\n    _try_import_torch()\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/cluster/worker/default_worker.py\", line 626, in _try_import_torch\n    import torch\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/torch/__init__.py\", line 366, in <module>\n    _load_global_deps()\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/torch/__init__.py\", line 324, in _load_global_deps\n    _preload_cuda_deps(lib_folder, lib_name)\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/torch/__init__.py\", line 284, in _preload_cuda_deps\n    raise ValueError(f\"{lib_name} not found in the system path {sys.path}\")\nValueError: libcublas.so.*[0-9] not found in the system path ['.', '.', '.', '.', '/root/DB-GPT/.venv/bin', '/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python311.zip', '/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11', '/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/lib-dynload', '/root/DB-GPT/.venv/lib/python3.11/site-packages', '/root/DB-GPT/packages/dbgpt-core/src', '/root/DB-GPT/packages/dbgpt-app/src', '/root/DB-GPT/packages/dbgpt-client/src', '/root/DB-GPT/packages/dbgpt-ext/src', '/root/DB-GPT/packages/dbgpt-serve/src', '/root/DB-GPT/packages/dbgpt-app', '/root/DB-GPT/packages/dbgpt-app']\n\n;model BAAI/bge-large-zh-v1.5@hf(192.168.1.223:5670) start failed, Traceback (most recent call last):\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/torch/__init__.py\", line 300, in _load_global_deps\n    ctypes.CDLL(global_deps_lib_path, mode=ctypes.RTLD_GLOBAL)\n  File \"/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/ctypes/__init__.py\", line 376, in __init__\n    self._handle = _dlopen(self._name, mode)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^\nOSError: libcudart.so.12: cannot open shared object file: No such file or directory\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/cluster/worker/manager.py\", line 631, in _start_worker\n    await self.run_blocking_func(\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/cluster/worker/manager.py\", line 146, in run_blocking_func\n    return await loop.run_in_executor(self.executor, func, *args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/cluster/worker/embedding_worker.py\", line 84, in start\n    self._embeddings_impl = self._adapter.load_from_params(self._model_params)\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/adapter/base.py\", line 829, in load_from_params\n    return model_adapter_cls.from_parameters(params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/rag/embedding/embeddings.py\", line 487, in from_parameters\n    return cls(\n           ^^^^\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/rag/embedding/embeddings.py\", line 460, in __init__\n    import sentence_transformers\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/sentence_transformers/__init__.py\", line 9, in <module>\n    from sentence_transformers.backend import (\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/sentence_transformers/backend.py\", line 11, in <module>\n    from sentence_transformers.util import disable_datasets_caching, is_datasets_available\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/sentence_transformers/util.py\", line 17, in <module>\n    import torch\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/torch/__init__.py\", line 366, in <module>\n    _load_global_deps()\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/torch/__init__.py\", line 324, in _load_global_deps\n    _preload_cuda_deps(lib_folder, lib_name)\n  File \"/root/DB-GPT/.venv/lib/python3.11/site-packages/torch/__init__.py\", line 284, in _preload_cuda_deps\n    raise ValueError(f\"{lib_name} not found in the system path {sys.path}\")\nValueError: libcublas.so.*[0-9] not found in the system path ['.', '.', '.', '.', '/root/DB-GPT/.venv/bin', '/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python311.zip', '/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11', '/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/lib-dynload', '/root/DB-GPT/.venv/lib/python3.11/site-packages', '/root/DB-GPT/packages/dbgpt-core/src', '/root/DB-GPT/packages/dbgpt-app/src', '/root/DB-GPT/packages/dbgpt-client/src', '/root/DB-GPT/packages/dbgpt-ext/src', '/root/DB-GPT/packages/dbgpt-serve/src', '/root/DB-GPT/packages/dbgpt-app', '/root/DB-GPT/packages/dbgpt-app']\n\n\n### What you expected to happen\n\nstartup success!\n\n### How to reproduce\n\ngit clone https://github.com/eosphoros-ai/DB-GPT.git\nuv sync --all-packages --extra \"base\" --extra \"proxy_openai\" --extra \"rag\" --extra \"storage_chromadb\" --extra \"dbgpts\" --extra \"hf\"\nuv run dbgpt start webserver --config configs/dbgpt-proxy-deepseek.toml\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "DuskBelievers",
      "author_type": "User",
      "created_at": "2025-03-06T07:07:52Z",
      "updated_at": "2025-03-06T07:11:34Z",
      "closed_at": "2025-03-06T07:11:34Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2403/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2403",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2403",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:43.953824",
      "comments": []
    },
    {
      "issue_number": 2402,
      "title": "[Bug] [Module Name] TuGraphConnector's create_graph function does not raise exception when failed to create new graph",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nMacOS(M1, M2...)\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nLLM:-gpt-4o\nEmbddingModel:-text-embedding-3-small\n\n### What happened\n\nTuGraphConnector's create_graph function does not raise exception when failed to create new graph, exception is raised when trying to create graph schema.\n\n### What you expected to happen\n\nraise exception when failed to create new graph\n\n### How to reproduce\n\n1. create graphs in TuGraphDB until can not allocate more memory\n2. create new community summary knowledge graph.\n\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "SonglinLyu",
      "author_type": "User",
      "created_at": "2025-03-06T06:57:13Z",
      "updated_at": "2025-03-06T06:57:13Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2402/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2402",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2402",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:43.953832",
      "comments": []
    },
    {
      "issue_number": 2312,
      "title": "[Feature][GraphRAG] Use config to store all configuration parameters.",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nThe CommunitySummary class only uses config to store default configuration parameters, but uses os.environ to get configuration parameters from .env. Parameters from .env should also be stored in config.\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "SonglinLyu",
      "author_type": "User",
      "created_at": "2025-01-20T09:50:12Z",
      "updated_at": "2025-03-05T19:09:14Z",
      "closed_at": "2025-03-05T19:09:14Z",
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2312/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 1,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2312",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2312",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:45.680976",
      "comments": []
    },
    {
      "issue_number": 2304,
      "title": "[Bug] [Module Name] Failed to execute chat_with_db_execute using the Doris database!",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [X] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nNVIDIA  P100\r\n\n\n### Models information\n\nollama depoy qwen:14b\n\n### What happened\n\n1. 无法查询Doris数据库\r\n![img_v3_02ih_531223bc-5601-4994-880f-0444781e95cg](https://github.com/user-attachments/assets/dcc3777f-e991-4c68-89fc-54b3ae102018)\r\n但是添加成功了\r\n![img_v3_02ih_cc952396-a524-4219-82de-b8e79852cb9g](https://github.com/user-attachments/assets/ec4752e7-96fa-4911-b9d0-c93113be9385)\r\n然后点击其它聊天窗口后再回来，发现有回复了，但是回复的内容答非所问\r\n![img_v3_02ih_11db3cf2-24bf-4f56-af47-6f3fce2a6cdg](https://github.com/user-attachments/assets/29e8ce85-3eab-4adc-83d0-7bc5cfa003f9)\r\n\r\n2.在查询Doris数据库时，控制台输出了结果（源码执行），但是前端界面没有输出\r\n![img_v3_02ih_2477a737-01f6-41d0-b6a0-2a8c0dbfe7dg](https://github.com/user-attachments/assets/1d86c96d-dbf7-41b6-b8cb-3ae9a4dee7a7)\r\n3. 查询Doris数据库表时大模型会返回一堆莫名其妙的回答\r\n![img_v3_02ih_0c968a96-9316-4bb3-b484-8bfec4b2958g](https://github.com/user-attachments/assets/de1e77e6-5b73-44f3-898a-f6fbdbf96fe1)\r\n以上问题只出现在Doris数据库查询时。\r\n我的Doris版本是2.1.1，我看23年12月份有个人提了issue说他在2.0上面测试成功了：https://github.com/eosphoros-ai/DB-GPT/pull/902\r\n所以，是框架的问题还是Doris版本的问题。大模型我单独测试了，可以生成正确的Doris的sql语句\n\n### What you expected to happen\n\nnone\n\n### How to reproduce\n\nnone\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "LuWei6896",
      "author_type": "User",
      "created_at": "2025-01-14T10:11:35Z",
      "updated_at": "2025-03-05T11:14:24Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2304/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2304",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2304",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:45.681003",
      "comments": [
        {
          "author": "QingShuo-agent",
          "body": "I have same problem, what is your final solution？\nPlease tell me, thanks.\n@LuWei6896 @csunny @Aries-ckt \n",
          "created_at": "2025-03-05T11:14:23Z"
        }
      ]
    },
    {
      "issue_number": 2398,
      "title": "[Bug] [Module Name] Bug title",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU\n\n### Models information\n\n Not installed\n\n### What happened\n\ngit clone https://github.com/eosphoros-ai/DB-GPT.git\nuv sync --all-packages --frozen --extra \"base\" --extra \"llama_cpp\" --extra \"rag\" --extra \"storage_chromadb\" --extra \"quant_bnb\" --extra \"dbgpts\"\n x Failed to build `llama-cpp-python==0.3.7`\n  |-> The build backend returned an error\n  `-> Call to `scikit_build_core.build.build_wheel` failed (exit code: 1)\n\n      [stdout]\n      *** scikit-build-core 0.11.0 using CMake 3.31.6 (wheel)\n      *** Configuring CMake...\n      loading initial cache file C:\\Users\\ykw\\AppData\\Local\\Temp\\tmpdneoplkx\\build\\CMakeInit.txt\n      -- Building for: Visual Studio 17 2022\n      -- Selecting Windows SDK version 10.0.22621.0 to target Windows 10.0.26100.\n      -- The C compiler identification is MSVC 19.43.34808.0\n      -- The CXX compiler identification is MSVC 19.43.34808.0\n      -- Detecting C compiler ABI info\n      -- Detecting C compiler ABI info - done\n      -- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual\n      Studio/2022/BuildTools/VC/Tools/MSVC/14.43.34808/bin/Hostx64/x64/cl.exe - skipped\n      -- Detecting C compile features\n      -- Detecting C compile features - done\n      -- Detecting CXX compiler ABI info\n      -- Detecting CXX compiler ABI info - done\n      -- Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual\n      Studio/2022/BuildTools/VC/Tools/MSVC/14.43.34808/bin/Hostx64/x64/cl.exe - skipped\n      -- Detecting CXX compile features\n      -- Detecting CXX compile features - done\n      -- Found Git: C:/Users/ykw/.conda/envs/py10/Library/mingw64/bin/git.exe (found version \"2.48.1.windows.1\")\n      -- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n      -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed\n      -- Looking for pthread_create in pthreads\n      -- Looking for pthread_create in pthreads - not found\n      -- Looking for pthread_create in pthread\n      -- Looking for pthread_create in pthread - not found\n      -- Found Threads: TRUE\n      -- Warning: ccache not found - consider installing it for faster compilation or disable this warning with\n      GGML_CCACHE=OFF\n      -- CMAKE_SYSTEM_PROCESSOR: AMD64\n      -- CMAKE_GENERATOR_PLATFORM: x64\n      -- Including CPU backend\n      -- Found OpenMP_C: -openmp (found version \"2.0\")\n      -- Found OpenMP_CXX: -openmp (found version \"2.0\")\n      -- Found OpenMP: TRUE (found version \"2.0\")\n      -- x86 detected\n      -- Performing Test HAS_AVX_1\n      -- Performing Test HAS_AVX_1 - Success\n      -- Performing Test HAS_AVX2_1\n      -- Performing Test HAS_AVX2_1 - Success\n      -- Performing Test HAS_FMA_1\n      -- Performing Test HAS_FMA_1 - Success\n      -- Performing Test HAS_AVX512_1\n      -- Performing Test HAS_AVX512_1 - Failed\n      -- Performing Test HAS_AVX512_2\n      -- Performing Test HAS_AVX512_2 - Failed\n      -- Adding CPU backend variant ggml-cpu: /arch:AVX2 GGML_AVX2;GGML_FMA;GGML_F16C\n      -- Configuring done (10.8s)\n      -- Generating done (0.5s)\n      -- Build files have been written to: C:/Users/ykw/AppData/Local/Temp/tmpdneoplkx/build\n      *** Building project with Visual Studio 17 2022...\n      Change Dir: 'C:/Users/ykw/AppData/Local/Temp/tmpdneoplkx/build'\n\n      Run Build Command(s): \"C:/Program Files (x86)/Microsoft Visual\n      Studio/2022/BuildTools/MSBuild/Current/Bin/amd64/MSBuild.exe\" ALL_BUILD.vcxproj /p:Configuration=Release\n      /p:Platform=x64 /p:VisualStudioVersion=17.0 /v:n\n      适用于 .NET Framework MSBuild 版本 17.13.15+18b3035f6\n      生成启动时间为 2025/3/5 9:39:48。\n\n      节点 1 上的项目“C:\\Users\\ykw\\AppData\\Local\\Temp\\tmpdneoplkx\\build\\ALL_BUILD.vcxproj”(默认目标)。\n      项目“C:\\Users\\ykw\\AppData\\Local\\Temp\\tmpdneoplkx\\build\\ALL_BUILD.vcxproj”(1)正在节点 1\n      上生成“C:\\Users\\ykw\\AppData\\Local\\Temp\\tmpdneoplkx\\build\\ZERO_CHECK.vcxproj”(2) (默认目标)。\n      PrepareForBuild:\n        正在创建目录“x64\\Release\\ZERO_CHECK\\”。\n      C:\\Program Files (x86)\\Microsoft Visual\n      Studio\\2022\\BuildTools\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppBuild.targets(544,5):\n      warning MSB8029: 中间目录或输出目录无法驻留在临时目录下，因为这可能会导致增量生成出现问题。\n      [C:\\Users\\ykw\\AppData\\Local\\Temp\\tmpdneoplkx\\build\\ZERO_CHECK.vcxproj]\n        已启用结构化输出。编译器诊断的格式设置将反映错误层次结构。有关详细信息，请参阅\n      https://aka.ms/cpp/structured-output。\n        正在创建目录“x64\\Release\\ZERO_CHECK\\ZERO_CHECK.tlog\\”。\n      InitializeBuildStatus:\n        正在创建“x64\\Release\\ZERO_CHECK\\ZERO_CHECK.tlog\\unsuccessfulbuild”，因为已指定“AlwaysCreate”。\n        正在对“x64\\Release\\ZERO_CHECK\\ZERO_CHECK.tlog\\unsuccessfulbuild”执行 Touch 任务。\n      CustomBuild:\n        1>Checking Build System\n      FinalizeBuildStatus:\n        正在删除文件“x64\\Release\\ZERO_CHECK\\ZERO_CHECK.tlog\\unsuccessfulbuild”。\n        正在对“x64\\Release\\ZERO_CHECK\\ZERO_CHECK.tlog\\ZERO_CHECK.lastbuildstate”执行 Touch 任务。\n      已完成生成项目“C:\\Users\\ykw\\AppData\\Local\\Temp\\tmpdneoplkx\\build\\ZERO_CHECK.vcxproj”(默认目标)的操作。\n      项目“C:\\Users\\ykw\\AppData\\Local\\Temp\\tmpdneoplkx\\build\\ALL_BUILD.vcxproj”(1)正在节点 1\n      上生成“C:\\Users\\ykw\\AppData\\Local\\Temp\\tmpdneoplkx\\build\\vendor\\llama.cpp\\common\\build_info.vcxproj”(3)\n      (默认目标)。\n      PrepareForBuild:\n        正在创建目录“build_info.dir\\Release\\”。\n      C:\\Program Files (x86)\\Microsoft Visual\n      Studio\\2022\\BuildTools\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppBuild.targets(544,5):\n      warning MSB8029: 中间目录或输出目录无法驻留在临时目录下，因为这可能会导致增量生成出现问题。\n      [C:\\Users\\ykw\\AppData\\Local\\Temp\\tmpdneoplkx\\build\\vendor\\llama.cpp\\common\\build_info.vcxproj]\n        已启用结构化输出。编译器诊断的格式设置将反映错误层次结构。有关详细信息，请参阅\n      https://aka.ms/cpp/structured-output。\n        正在创建目录“build_info.dir\\Release\\build_info.tlog\\”。\n      InitializeBuildStatus:\n        正在创建“build_info.dir\\Release\\build_info.tlog\\unsuccessfulbuild”，因为已指定“AlwaysCreate”。\n        正在对“build_info.dir\\Release\\build_info.tlog\\unsuccessfulbuild”执行 Touch 任务。\n      CustomBuild:\n        Generating build details from Git\n        -- Found Git: C:/Users/ykw/.conda/envs/py10/Library/mingw64/bin/git.exe (found version \"2.48.1.windows.1\")\n        Building Custom Rule\n      C:/Users/ykw/AppData/Local/uv/cache/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/AR55sO-navzM1gEVXdFzF/src/vendor/llama.cpp/common/CMakeLists.txt\n      ClCompile:\n        C:\\Program Files (x86)\\Microsoft Visual\n      Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.43.34808\\bin\\HostX64\\x64\\CL.exe /c /nologo /W1 /WX- /diagnostics:column\n      /O2 /Ob2 /D _MBCS /D WIN32 /D _WINDOWS /D NDEBUG /D _CRT_SECURE_NO_WARNINGS /D \"CMAKE_INTDIR=\\\"Release\\\"\"\n      /EHsc /MD /GS /fp:precise /Zc:wchar_t /Zc:forScope /Zc:inline /Fo\"build_info.dir\\Release\\\\\"\n      /Fd\"build_info.dir\\Release\\build_info.pdb\" /external:W1 /Gd /TP /errorReport:queue  /utf-8 /bigobj\n      \"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\common\\build-info.cpp\"\n        build-info.cpp\n      Lib:\n        C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.43.34808\\bin\\HostX64\\x64\\Lib.exe\n      /OUT:\"build_info.dir\\Release\\build_info.lib\" /NOLOGO /MACHINE:X64  /machine:x64\n      \"build_info.dir\\Release\\build-info.obj\"\n        build_info.vcxproj ->\n      C:\\Users\\ykw\\AppData\\Local\\Temp\\tmpdneoplkx\\build\\vendor\\llama.cpp\\common\\build_info.dir\\Release\\build_info.lib\n      FinalizeBuildStatus:\n        正在删除文件“build_info.dir\\Release\\build_info.tlog\\unsuccessfulbuild”。\n        正在对“build_info.dir\\Release\\build_info.tlog\\build_info.lastbuildstate”执行 Touch 任务。\n      已完成生成项目“C:\\Users\\ykw\\AppData\\Local\\Temp\\tmpdneoplkx\\build\\vendor\\llama.cpp\\common\\build_info.vcxproj”(默认 目标)的操作。\n      项目“C:\\Users\\ykw\\AppData\\Local\\Temp\\tmpdneoplkx\\build\\ALL_BUILD.vcxproj”(1)正在节点 1\n      上生成“C:\\Users\\ykw\\AppData\\Local\\Temp\\tmpdneoplkx\\build\\vendor\\llama.cpp\\examples\\llava\\llava.vcxproj”(4)\n      (默认目标)。\n      项目“C:\\Users\\ykw\\AppData\\Local\\Temp\\tmpdneoplkx\\build\\vendor\\llama.cpp\\examples\\llava\\llava.vcxproj”(4)正在节点\n      1 上生成“C:\\Users\\ykw\\AppData\\Local\\Temp\\tmpdneoplkx\\build\\vendor\\llama.cpp\\ggml\\src\\ggml.vcxproj”(5)\n      (默认目标)。\n      项目“C:\\Users\\ykw\\AppData\\Local\\Temp\\tmpdneoplkx\\build\\vendor\\llama.cpp\\ggml\\src\\ggml.vcxproj”(5)正在节点\n      1 上生成“C:\\Users\\ykw\\AppData\\Local\\Temp\\tmpdneoplkx\\build\\vendor\\llama.cpp\\ggml\\src\\ggml-base.vcxproj”(6)\n      (默认目标)。\n      PrepareForBuild:\n        正在创建目录“ggml-base.dir\\Release\\”。\n      C:\\Program Files (x86)\\Microsoft Visual\n      Studio\\2022\\BuildTools\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppBuild.targets(544,5):\n      warning MSB8029: 中间目录或输出目录无法驻留在临时目录下，因为这可能会导致增量生成出现问题。\n      [C:\\Users\\ykw\\AppData\\Local\\Temp\\tmpdneoplkx\\build\\vendor\\llama.cpp\\ggml\\src\\ggml-base.vcxproj]\n        已启用结构化输出。编译器诊断的格式设置将反映错误层次结构。有关详细信息，请参阅\n      https://aka.ms/cpp/structured-output。\n        正在创建目录“C:\\Users\\ykw\\AppData\\Local\\Temp\\tmpdneoplkx\\build\\bin\\Release\\”。\n        正在创建目录“ggml-base.dir\\Release\\ggml-base.tlog\\”。\n      InitializeBuildStatus:\n        正在创建“ggml-base.dir\\Release\\ggml-base.tlog\\unsuccessfulbuild”，因为已指定“AlwaysCreate”。\n        正在对“ggml-base.dir\\Release\\ggml-base.tlog\\unsuccessfulbuild”执行 Touch 任务。\n      CustomBuild:\n        Building Custom Rule\n      C:/Users/ykw/AppData/Local/uv/cache/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/AR55sO-navzM1gEVXdFzF/src/vendor/llama.cpp/ggml/src/CMakeLists.txt\n      ClCompile:\n        C:\\Program Files (x86)\\Microsoft Visual\n      Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.43.34808\\bin\\HostX64\\x64\\CL.exe /c\n      /I\"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\.\"\n      /I\"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\..\\include\"\n      /nologo /W1 /WX- /diagnostics:column /O2 /Ob2 /D _WINDLL /D _MBCS /D WIN32 /D _WINDOWS /D\n      NDEBUG /D GGML_BUILD /D GGML_SHARED /D _CRT_SECURE_NO_WARNINGS /D GGML_SCHED_MAX_COPIES=4\n      /D _XOPEN_SOURCE=600 /D \"CMAKE_INTDIR=\\\"Release\\\"\" /D ggml_base_EXPORTS /EHsc /MD /GS\n      /fp:precise /Zc:wchar_t /Zc:forScope /Zc:inline /std:c11 /Fo\"ggml-base.dir\\Release\\\\\"\n      /Fd\"ggml-base.dir\\Release\\vc143.pdb\" /external:W1 /Gd /TC /errorReport:queue  /utf-8 /bigobj\n      \"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\ggml.c\"\n      \"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\ggml-alloc.c\"\n      \"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\ggml-quants.c\"\n        ggml.c\n        ggml-alloc.c\n        ggml-quants.c\n      C:\\Program Files (x86)\\Windows Kits\\10\\Include\\10.0.22621.0\\ucrt\\assert.h(21,9): warning C4005: “static_assert”:\n      宏重定义 [C:\\Users\\ykw\\AppData\\Local\\Temp\\tmpdneoplkx\\build\\vendor\\llama.cpp\\ggml\\src\\ggml-base.vcxproj]\n        (编译源文件“../../../../../../../uv/cache/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/AR55sO-navzM1gEVXdFzF/src/vendor/llama.cpp/ggml/src/ggml-quants.c”)\n\n      C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\ggml-common.h(79,9):\n            参见“static_assert”的前一个定义\n\n        正在生成代码...\n        C:\\Program Files (x86)\\Microsoft Visual\n      Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.43.34808\\bin\\HostX64\\x64\\CL.exe /c\n      /I\"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\.\"\n      /I\"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\..\\include\"\n      /nologo /W1 /WX- /diagnostics:column /O2 /Ob2 /D _WINDLL /D _MBCS /D WIN32 /D _WINDOWS /D\n      NDEBUG /D GGML_BUILD /D GGML_SHARED /D _CRT_SECURE_NO_WARNINGS /D GGML_SCHED_MAX_COPIES=4\n      /D _XOPEN_SOURCE=600 /D \"CMAKE_INTDIR=\\\"Release\\\"\" /D ggml_base_EXPORTS /EHsc /MD /GS\n      /fp:precise /Zc:wchar_t /Zc:forScope /Zc:inline /std:c++17 /Fo\"ggml-base.dir\\Release\\\\\"\n      /Fd\"ggml-base.dir\\Release\\vc143.pdb\" /external:W1 /Gd /TP /errorReport:queue  /utf-8 /bigobj\n      \"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\ggml-backend.cpp\"\n      \"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\ggml-opt.cpp\"\n      \"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\ggml-threading.cpp\"\n      \"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\gguf.cpp\"\n        ggml-backend.cpp\n        ggml-opt.cpp\n        ggml-threading.cpp\n        gguf.cpp\n        正在生成代码...\n      MakeDirsForLink:\n        正在创建目录“C:\\Users\\ykw\\AppData\\Local\\Temp\\tmpdneoplkx\\build\\vendor\\llama.cpp\\ggml\\src\\Release\\”。\n      Link:\n        C:\\Program Files (x86)\\Microsoft Visual\n      Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.43.34808\\bin\\HostX64\\x64\\link.exe /ERRORREPORT:QUEUE\n      /OUT:\"C:\\Users\\ykw\\AppData\\Local\\Temp\\tmpdneoplkx\\build\\bin\\Release\\ggml-base.dll\" /INCREMENTAL:NO\n      /NOLOGO kernel32.lib user32.lib gdi32.lib winspool.lib shell32.lib ole32.lib oleaut32.lib\n      uuid.lib comdlg32.lib advapi32.lib /MANIFEST /MANIFESTUAC:\"level='asInvoker' uiAccess='false'\"\n      /manifest:embed /PDB:\"C:/Users/ykw/AppData/Local/Temp/tmpdneoplkx/build/bin/Release/ggml-base.pdb\"\n      /SUBSYSTEM:CONSOLE /TLBID:1 /DYNAMICBASE /NXCOMPAT\n      /IMPLIB:\"C:/Users/ykw/AppData/Local/Temp/tmpdneoplkx/build/vendor/llama.cpp/ggml/src/Release/ggml-base.lib\"\n      /MACHINE:X64  /machine:x64 /DLL \"ggml-base.dir\\Release\\ggml.obj\"\n        \"ggml-base.dir\\Release\\ggml-alloc.obj\"\n        \"ggml-base.dir\\Release\\ggml-backend.obj\"\n        \"ggml-base.dir\\Release\\ggml-opt.obj\"\n        \"ggml-base.dir\\Release\\ggml-threading.obj\"\n        \"ggml-base.dir\\Release\\ggml-quants.obj\"\n        \"ggml-base.dir\\Release\\gguf.obj\"\n          正在创建库 C:/Users/ykw/AppData/Local/Temp/tmpdneoplkx/build/vendor/llama.cpp/ggml/src/Release/ggml-base.lib\n      和对象 C:/Users/ykw/AppData/Local/Temp/tmpdneoplkx/build/vendor/llama.cpp/ggml/src/Release/ggml-base.exp\n        ggml-base.vcxproj -> C:\\Users\\ykw\\AppData\\Local\\Temp\\tmpdneoplkx\\build\\bin\\Release\\ggml-base.dll\n      FinalizeBuildStatus:\n        正在删除文件“ggml-base.dir\\Release\\ggml-base.tlog\\unsuccessfulbuild”。\n        正在对“ggml-base.dir\\Release\\ggml-base.tlog\\ggml-base.lastbuildstate”执行 Touch 任务。\n      已完成生成项目“C:\\Users\\ykw\\AppData\\Local\\Temp\\tmpdneoplkx\\build\\vendor\\llama.cpp\\ggml\\src\\ggml-base.vcxproj”(默认目标)的操作。\n      项目“C:\\Users\\ykw\\AppData\\Local\\Temp\\tmpdneoplkx\\build\\vendor\\llama.cpp\\ggml\\src\\ggml.vcxproj”(5)正在节点\n      1 上生成“C:\\Users\\ykw\\AppData\\Local\\Temp\\tmpdneoplkx\\build\\vendor\\llama.cpp\\ggml\\src\\ggml-cpu.vcxproj”(7)\n      (默认目标)。\n      PrepareForBuild:\n        正在创建目录“ggml-cpu.dir\\Release\\”。\n      C:\\Program Files (x86)\\Microsoft Visual\n      Studio\\2022\\BuildTools\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppBuild.targets(544,5):\n      warning MSB8029: 中间目录或输出目录无法驻留在临时目录下，因为这可能会导致增量生成出现问题。\n      [C:\\Users\\ykw\\AppData\\Local\\Temp\\tmpdneoplkx\\build\\vendor\\llama.cpp\\ggml\\src\\ggml-cpu.vcxproj]\n        已启用结构化输出。编译器诊断的格式设置将反映错误层次结构。有关详细信息，请参阅\n      https://aka.ms/cpp/structured-output。\n        正在创建目录“ggml-cpu.dir\\Release\\ggml-cpu.tlog\\”。\n      InitializeBuildStatus:\n        正在创建“ggml-cpu.dir\\Release\\ggml-cpu.tlog\\unsuccessfulbuild”，因为已指定“AlwaysCreate”。\n        正在对“ggml-cpu.dir\\Release\\ggml-cpu.tlog\\unsuccessfulbuild”执行 Touch 任务。\n      CustomBuild:\n        Building Custom Rule\n      C:/Users/ykw/AppData/Local/uv/cache/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/AR55sO-navzM1gEVXdFzF/src/vendor/llama.cpp/ggml/src/CMakeLists.txt\n      MakeDirsForCl:\n        正在创建目录“C:\\Users\\ykw\\AppData\\Local\\Temp\\tmpdneoplkx\\build\\vendor\\llama.cpp\\ggml\\src\\ggml-cpu.dir\\Release\\ggml-cpu”。\n      ClCompile:\n        C:\\Program Files (x86)\\Microsoft Visual\n      Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.43.34808\\bin\\HostX64\\x64\\CL.exe /c\n      /I\"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\..\"\n      /I\"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\.\"\n      /I\"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\ggml-cpu\"\n      /I\"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\..\\include\"\n      /nologo /W1 /WX- /diagnostics:column /O2 /Ob2 /D _WINDLL /D _MBCS /D WIN32 /D _WINDOWS /D NDEBUG /D\n      GGML_BACKEND_BUILD /D GGML_BACKEND_SHARED /D GGML_USE_OPENMP /D GGML_USE_LLAMAFILE /D GGML_USE_CPU_AARCH64 /D\n      GGML_AVX2 /D GGML_FMA /D GGML_F16C /D _CRT_SECURE_NO_WARNINGS /D GGML_SCHED_MAX_COPIES=4 /D _XOPEN_SOURCE=600\n      /D GGML_SHARED /D \"CMAKE_INTDIR=\\\"Release\\\"\" /D ggml_cpu_EXPORTS /EHsc /MD /GS /arch:AVX2 /fp:precise\n      /Zc:wchar_t /Zc:forScope /Zc:inline /openmp /std:c11 /Fo\"ggml-cpu.dir\\Release\\/ggml-cpu/ggml-cpu.c.obj\"\n      /Fd\"ggml-cpu.dir\\Release\\vc143.pdb\" /external:W1 /Gd /TC /errorReport:queue  /utf-8 /bigobj\n      \"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\ggml-cpu\\ggml-cpu.c\"\n        ggml-cpu.c\n        C:\\Program Files (x86)\\Microsoft Visual\n      Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.43.34808\\bin\\HostX64\\x64\\CL.exe /c\n      /I\"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\..\"\n      /I\"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\.\"\n      /I\"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\ggml-cpu\"\n      /I\"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\..\\include\"\n      /nologo /W1 /WX- /diagnostics:column /O2 /Ob2 /D _WINDLL /D _MBCS /D WIN32 /D _WINDOWS /D NDEBUG /D\n      GGML_BACKEND_BUILD /D GGML_BACKEND_SHARED /D GGML_USE_OPENMP /D GGML_USE_LLAMAFILE /D GGML_USE_CPU_AARCH64 /D\n      GGML_AVX2 /D GGML_FMA /D GGML_F16C /D _CRT_SECURE_NO_WARNINGS /D GGML_SCHED_MAX_COPIES=4 /D _XOPEN_SOURCE=600\n      /D GGML_SHARED /D \"CMAKE_INTDIR=\\\"Release\\\"\" /D ggml_cpu_EXPORTS /EHsc /MD /GS /arch:AVX2 /fp:precise\n      /Zc:wchar_t /Zc:forScope /Zc:inline /openmp /std:c++17 /Fo\"ggml-cpu.dir\\Release\\/ggml-cpu/ggml-cpu.cpp.obj\"\n      /Fd\"ggml-cpu.dir\\Release\\vc143.pdb\" /external:W1 /Gd /TP /errorReport:queue  /utf-8 /bigobj\n      \"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\ggml-cpu\\ggml-cpu.cpp\"\n        ggml-cpu.cpp\n        C:\\Program Files (x86)\\Microsoft Visual\n      Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.43.34808\\bin\\HostX64\\x64\\CL.exe /c\n      /I\"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\..\"\n      /I\"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\.\"\n      /I\"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\ggml-cpu\"\n      /I\"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\..\\include\"\n      /nologo /W1 /WX- /diagnostics:column /O2 /Ob2 /D _WINDLL /D _MBCS /D WIN32 /D _WINDOWS /D NDEBUG /D\n      GGML_BACKEND_BUILD /D GGML_BACKEND_SHARED /D GGML_USE_OPENMP /D GGML_USE_LLAMAFILE /D GGML_USE_CPU_AARCH64\n      /D GGML_AVX2 /D GGML_FMA /D GGML_F16C /D _CRT_SECURE_NO_WARNINGS /D GGML_SCHED_MAX_COPIES=4 /D\n      _XOPEN_SOURCE=600 /D GGML_SHARED /D \"CMAKE_INTDIR=\\\"Release\\\"\" /D ggml_cpu_EXPORTS /EHsc /MD /GS\n      /arch:AVX2 /fp:precise /Zc:wchar_t /Zc:forScope /Zc:inline /openmp /std:c++17 /Fo\"ggml-cpu.dir\\Release\\\\\"\n      /Fd\"ggml-cpu.dir\\Release\\vc143.pdb\" /external:W1 /Gd /TP /errorReport:queue  /utf-8 /bigobj\n      \"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\ggml-cpu\\ggml-cpu-aarch64.cpp\"\n      \"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\ggml-cpu\\ggml-cpu-hbm.cpp\"\n      \"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\ggml-cpu\\ggml-cpu-traits.cpp\"\n      \"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\ggml-cpu\\amx\\amx.cpp\"\n      \"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\ggml-cpu\\amx\\mmq.cpp\"\n      \"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\ggml-cpu\\llamafile\\sgemm.cpp\"\n        ggml-cpu-aarch64.cpp\n        ggml-cpu-hbm.cpp\n        ggml-cpu-traits.cpp\n        amx.cpp\n        mmq.cpp\n        sgemm.cpp\n        正在生成代码...\n        C:\\Program Files (x86)\\Microsoft Visual\n      Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.43.34808\\bin\\HostX64\\x64\\CL.exe /c\n      /I\"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\..\"\n      /I\"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\.\"\n      /I\"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\ggml-cpu\"\n      /I\"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\..\\include\"\n      /nologo /W1 /WX- /diagnostics:column /O2 /Ob2 /D _WINDLL /D _MBCS /D WIN32 /D _WINDOWS /D NDEBUG /D\n      GGML_BACKEND_BUILD /D GGML_BACKEND_SHARED /D GGML_USE_OPENMP /D GGML_USE_LLAMAFILE /D GGML_USE_CPU_AARCH64\n      /D GGML_AVX2 /D GGML_FMA /D GGML_F16C /D _CRT_SECURE_NO_WARNINGS /D GGML_SCHED_MAX_COPIES=4 /D\n      _XOPEN_SOURCE=600 /D GGML_SHARED /D \"CMAKE_INTDIR=\\\"Release\\\"\" /D ggml_cpu_EXPORTS /EHsc /MD /GS\n      /arch:AVX2 /fp:precise /Zc:wchar_t /Zc:forScope /Zc:inline /openmp /std:c11 /Fo\"ggml-cpu.dir\\Release\\\\\"\n      /Fd\"ggml-cpu.dir\\Release\\vc143.pdb\" /external:W1 /Gd /TC /errorReport:queue  /utf-8 /bigobj\n      \"C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\ggml-cpu\\ggml-cpu-quants.c\"\n        ggml-cpu-quants.c\n      C:\\Program Files (x86)\\Windows Kits\\10\\Include\\10.0.22621.0\\ucrt\\assert.h(21,9): warning C4005: “static_assert”:\n      宏重定义 [C:\\Users\\ykw\\AppData\\Local\\Temp\\tmpdneoplkx\\build\\vendor\\llama.cpp\\ggml\\src\\ggml-cpu.vcxproj]\n        (编译源文件“../../../../../../../uv/cache/sdists-v8/index/46901b1a4cb2cba0/llama-cpp-python/0.3.7/AR55sO-navzM1gEVXdFzF/src/vendor/llama.cpp/ggml/src/ggml-cpu/ggml-cpu-quants.c”)\n\n      C:\\Users\\ykw\\AppData\\Local\\uv\\cache\\sdists-v8\\index\\46901b1a4cb2cba0\\llama-cpp-python\\0.3.7\\AR55sO-navzM1gEVXdFzF\\src\\vendor\\llama.cpp\\ggml\\src\\ggml-common.h(79,9):\n            参见“static_assert”的前一个定义\n\n          16 个警告\n          5 个错误\n\n      已用时间 00:01:01.95\n\n\n      [stderr]\n      2025-03-05 09:39:37,237 - scikit_build_core - WARNING - Can't find a Python library, got libdir=None,\n      ldlibrary=None, multiarch=None, masd=None\n      CMake Warning at vendor/llama.cpp/ggml/CMakeLists.txt:285 (message):\n        GGML build version fixed at 1 likely due to a shallow clone.\n\n\n      CMake Warning (dev) at CMakeLists.txt:13 (install):\n        Target llama has PUBLIC_HEADER files but no PUBLIC_HEADER DESTINATION.\n      Call Stack (most recent call first):\n        CMakeLists.txt:97 (llama_cpp_python_install_target)\n      This warning is for project developers.  Use -Wno-dev to suppress it.\n\n      CMake Warning (dev) at CMakeLists.txt:21 (install):\n        Target llama has PUBLIC_HEADER files but no PUBLIC_HEADER DESTINATION.\n      Call Stack (most recent call first):\n        CMakeLists.txt:97 (llama_cpp_python_install_target)\n      This warning is for project developers.  Use -Wno-dev to suppress it.\n\n      CMake Warning (dev) at CMakeLists.txt:13 (install):\n        Target ggml has PUBLIC_HEADER files but no PUBLIC_HEADER DESTINATION.\n      Call Stack (most recent call first):\n        CMakeLists.txt:98 (llama_cpp_python_install_target)\n      This warning is for project developers.  Use -Wno-dev to suppress it.\n\n      CMake Warning (dev) at CMakeLists.txt:21 (install):\n        Target ggml has PUBLIC_HEADER files but no PUBLIC_HEADER DESTINATION.\n      Call Stack (most recent call first):\n        CMakeLists.txt:98 (llama_cpp_python_install_target)\n      This warning is for project developers.  Use -Wno-dev to suppress it.\n\n\n      *** CMake build failed\n\n      hint: This usually indicates a problem with the package or the build environment.\n  help: `llama-cpp-python` (v0.3.7) was included because `dbgpt[llama-cpp]` (v0.7.0) depends on `llama-cpp-python`\n\n\n### What you expected to happen\n\n      *** CMake build failed\n\n      hint: This usually indicates a problem with the package or the build environment.\n  help: `llama-cpp-python` (v0.3.7) was included because `dbgpt[llama-cpp]` (v0.7.0) depends on `llama-cpp-python`\n(py10) PS D:\\Installpackage\\DB-GPT>\n\n(py10) PS D:\\Installpackage\\DB-GPT>\n(py10) PS D:\\Installpackage\\DB-GPT> uv sync --all-packages --frozen --extra \"base\" --extra \"llama_cpp\" --extra \"rag\" --extra \"storage_chromadb\" --extra \"quant_bnb\" --extra \"dbgpts\"\n\n### How to reproduce\n\ngit clone https://github.com/eosphoros-ai/DB-GPT.git\ncd DB-GPT\nuv sync --all-packages --frozen --extra \"base\" --extra \"llama_cpp\" --extra \"rag\" --extra \"storage_chromadb\" --extra \"quant_bnb\" --extra \"dbgpts\"\n\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "yu154",
      "author_type": "User",
      "created_at": "2025-03-05T04:29:45Z",
      "updated_at": "2025-03-05T06:28:33Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2398/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2398",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2398",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:45.862294",
      "comments": [
        {
          "author": "fangyinc",
          "body": "@yu154  See [here](https://github.com/abetlen/llama-cpp-python/issues/1368)\n\nOr, you can try [llama-cpp-server](https://github.com/eosphoros-ai/DB-GPT/blob/main/configs/dbgpt-local-llama-cpp-server.toml)",
          "created_at": "2025-03-05T06:28:33Z"
        }
      ]
    },
    {
      "issue_number": 2096,
      "title": "[Bug] [web] Dynamic imports cannot be executed on the chat page in my compiled web project",
      "body": "### Search before asking\r\n\r\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\r\n\r\n\r\n### Operating system information\r\n\r\nLinux\r\n\r\n### Python version information\r\n\r\n>=3.11\r\n\r\n### DB-GPT version\r\n\r\nmain\r\n\r\n### Related scenes\r\n\r\n- [ ] Chat Data\r\n- [ ] Chat Excel\r\n- [ ] Chat DB\r\n- [X] Chat Knowledge\r\n- [ ] Model Management\r\n- [ ] Dashboard\r\n- [ ] Plugins\r\n\r\n### Installation Information\r\n\r\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\r\n\r\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\r\n\r\n- [ ] AutoDL Image\r\n- [ ] Other\r\n\r\n### Device information\r\n\r\nPersonal Computer\r\nDeepin 20.9\r\n\r\n### Models information\r\n\r\nNothing todo with models.\r\n\r\n### What happened\r\n\r\nI just downloaded 0.6.1 release.\r\nI run:\r\ncnpm install \r\ncnmp run compile\r\ncp -rf out/* ../dbgpt/app/static/web\r\n\r\n**I found that the chat page can not display correctly. The chat history messages did not show on the page.**\r\n![image](https://github.com/user-attachments/assets/b1b61ffa-502f-40ce-bfb3-16aa348195a1)\r\n\r\n**Then I did some debug work. I modified the following code(in web/new-components/chat/ChatContentContainer.tsx):**\r\n```\r\nimport ChatHeader from '@/new-components/chat/header/ChatHeader';\r\nimport dynamic from 'next/dynamic';\r\nimport React, { forwardRef, useEffect, useImperativeHandle, useRef, useState } from 'react';\r\n\r\nconst ChatCompletion = dynamic(() => import('@/new-components/chat/content/ChatCompletion'), { ssr: false });\r\n```\r\n\r\n\r\n\r\n**into:**\r\n```\r\n/* eslint-disable */\r\nimport ChatHeader from '@/new-components/chat/header/ChatHeader';\r\nimport dynamic from 'next/dynamic';\r\nimport React, { forwardRef, useEffect, useImperativeHandle, useRef, useState } from 'react';\r\n\r\nconst ChatCompletion = dynamic(() => import('@/new-components/chat/content/ChatCompletion'), {\r\n  ssr: false,\r\n  loading: () => <div>Loading ChatCompletion...</div>,\r\n  error: error => {\r\n    console.error('Failed to load ChatCompletion:', error);\r\n    return <div>Error loading ChatCompletion</div>;\r\n  },\r\n  load: () => {\r\n    console.log('ChatCompletion has been successfully loaded');\r\n  },\r\n});\r\n```\r\n\r\n**Then the page looks as follows:**\r\n![image](https://github.com/user-attachments/assets/8e702bf3-57b1-4460-ba9e-a8654b8ffb82)\r\n\r\n\r\n**It seems that there's something wrong with the dynamic import. What should I do?**\r\n\r\n\r\n\r\n\r\n### What you expected to happen\r\n\r\ndymaic import @/new-components/chat/content/ChatCompletion\r\n\r\n### How to reproduce\r\n\r\ndownloaded 0.6.1 release.\r\ncnpm install \r\ncnmp run compile\r\ncp -rf out/* ../dbgpt/app/static/web\r\n\r\n### Additional context\r\n\r\n**I found that if I use 'yarn' instead of 'cnpm', everything works fine.**\r\n\r\n### Are you willing to submit PR?\r\n\r\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "tiefan",
      "author_type": "User",
      "created_at": "2024-10-24T02:50:29Z",
      "updated_at": "2025-03-04T21:04:58Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2096/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2096",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2096",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:46.039273",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-02-21T21:04:44Z"
        },
        {
          "author": "Ge-Lshui",
          "body": "hello bro, I encountered the same problem, but using `yarn` still had the same effect. Do you remember what version of yarn you have",
          "created_at": "2025-03-04T15:15:53Z"
        }
      ]
    },
    {
      "issue_number": 2391,
      "title": "[Bug] [Module Name] Failed to build resource database:dbgpt_serve.agent.resource.datasource.DatasourceResource",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nBAAI/bge-large-zh-v1.5\nBAAI/bge-reranker-v2-m3\nQwen/Qwen2.5-Coder-32B-Instruct\n\n### What happened\n\n2025-03-04 16:15:55 DESKTOP-0RMTJO2 dbgpt_serve.agent.agents.controller[35536] INFO last conversation status:{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x7f1f0c7ad120>, 'user_goal': '分析当前有多少个资产使用组织', 'team_mode': 'single_agent', 'conv_id': '0a33f5a8-f8d0-11ef-bc66-00e070dcd821_1', 'max_auto_reply_round': 0, 'user_code': '001', 'created_at': datetime.datetime(2025, 3, 4, 8, 9, 49, 530425), 'id': 1, 'gpts_name': 'de69d19a-f8cf-11ef-bc66-00e070dcd821', 'state': 'failed', 'auto_reply_count': 0, 'sys_code': None, 'updated_at': datetime.datetime(2025, 3, 4, 8, 9, 49, 542185)}\nINFO:     172.16.12.74:61825 - \"POST /api/v1/chat/completions HTTP/1.1\" 200 OK\n2025-03-04 16:15:55 DESKTOP-0RMTJO2 dbgpt_serve.datasource.manages.connect_config_db[35536] INFO Result: <sqlalchemy.engine.cursor.CursorResult object at 0x7f1f0c778ee0>\n2025-03-04 16:15:55 DESKTOP-0RMTJO2 dbgpt.agent.resource.manage[35536] WARNING Failed to build resource database:dbgpt_serve.agent.resource.datasource.DatasourceResource: DBResource.__init__() got an unexpected keyword argument 'system_app'\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/agent/resource/manage.py\", line 215, in build_resource_by_type\n    resource_inst = single_item.resource_cls(**param_dict)\n  File \"/root/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/agent/resource/datasource.py\", line 128, in __init__\n    super().__init__(name, connector=conn, db_name=db_name, **kwargs)\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/agent/resource/database.py\", line 164, in __init__\n    super().__init__(\nTypeError: DBResource.__init__() got an unexpected keyword argument 'system_app'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/root/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/agent/agents/controller.py\", line 513, in agent_team_chat_new\n    depend_resource = rm.build_resource(record.resources, version=\"v1\")\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/agent/resource/manage.py\", line 244, in build_resource\n    resource_inst = self.build_resource_by_type(\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/agent/resource/manage.py\", line 219, in build_resource_by_type\n    raise ValueError(\nValueError: Failed to build resource database:dbgpt_serve.agent.resource.datasource.DatasourceResource: DBResource.__init__() got an unexpected keyword argument 'system_app'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/logging/__init__.py\", line 1100, in emit\n    msg = self.format(record)\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/logging/__init__.py\", line 943, in format\n    return fmt.format(record)\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/logging/__init__.py\", line 678, in format\n    record.message = record.getMessage()\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/logging/__init__.py\", line 368, in getMessage\n    msg = msg % self.args\nTypeError: not all arguments converted during string formatting\nCall stack:\n  File \"/root/DB-GPT/.venv/bin/dbgpt\", line 10, in <module>\n    sys.exit(main())\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/cli/cli_scripts.py\", line 227, in main\n    return cli()\n  File \"/root/DB-GPT/.venv/lib/python3.10/site-packages/click/core.py\", line 1161, in __call__\n    return self.main(*args, **kwargs)\n  File \"/root/DB-GPT/.venv/lib/python3.10/site-packages/click/core.py\", line 1082, in main\n    rv = self.invoke(ctx)\n  File \"/root/DB-GPT/.venv/lib/python3.10/site-packages/click/core.py\", line 1697, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"/root/DB-GPT/.venv/lib/python3.10/site-packages/click/core.py\", line 1697, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"/root/DB-GPT/.venv/lib/python3.10/site-packages/click/core.py\", line 1443, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"/root/DB-GPT/.venv/lib/python3.10/site-packages/click/core.py\", line 788, in invoke\n    return __callback(*args, **kwargs)\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/cli.py\", line 458, in wrapper\n    return func(*args, **kwargs)\n  File \"/root/DB-GPT/packages/dbgpt-app/src/dbgpt_app/_cli.py\", line 25, in start_webserver\n    run_webserver(config)\n  File \"/root/DB-GPT/packages/dbgpt-app/src/dbgpt_app/dbgpt_server.py\", line 255, in run_webserver\n    run_uvicorn(param.service.web)\n  File \"/root/DB-GPT/packages/dbgpt-app/src/dbgpt_app/dbgpt_server.py\", line 212, in run_uvicorn\n    uvicorn.run(\n  File \"/root/DB-GPT/.venv/lib/python3.10/site-packages/uvicorn/main.py\", line 579, in run\n    server.run()\n  File \"/root/DB-GPT/.venv/lib/python3.10/site-packages/uvicorn/server.py\", line 66, in run\n    return asyncio.run(self.serve(sockets=sockets))\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/asyncio/runners.py\", line 44, in run\n    return loop.run_until_complete(main)\n  File \"/root/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/agent/agents/controller.py\", line 595, in agent_team_chat_new\n    logger.error(f\"chat abnormal termination！{str(e)}\", e)\nMessage: \"chat abnormal termination！Failed to build resource database:dbgpt_serve.agent.resource.datasource.DatasourceResource: DBResource.__init__() got an unexpected keyword argument 'system_app'\"\nArguments: (ValueError(\"Failed to build resource database:dbgpt_serve.agent.resource.datasource.DatasourceResource: DBResource.__init__() got an unexpected keyword argument 'system_app'\"),)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/agent/resource/manage.py\", line 215, in build_resource_by_type\n    resource_inst = single_item.resource_cls(**param_dict)\n  File \"/root/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/agent/resource/datasource.py\", line 128, in __init__\n    super().__init__(name, connector=conn, db_name=db_name, **kwargs)\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/agent/resource/database.py\", line 164, in __init__\n    super().__init__(\nTypeError: DBResource.__init__() got an unexpected keyword argument 'system_app'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/root/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/agent/agents/controller.py\", line 513, in agent_team_chat_new\n    depend_resource = rm.build_resource(record.resources, version=\"v1\")\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/agent/resource/manage.py\", line 244, in build_resource\n    resource_inst = self.build_resource_by_type(\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/agent/resource/manage.py\", line 219, in build_resource_by_type\n    raise ValueError(\nValueError: Failed to build resource database:dbgpt_serve.agent.resource.datasource.DatasourceResource: DBResource.__init__() got an unexpected keyword argument 'system_app'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/logging/__init__.py\", line 1100, in emit\n    msg = self.format(record)\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/logging/__init__.py\", line 943, in format\n    return fmt.format(record)\n  File \"/root/DB-GPT/.venv/lib/python3.10/site-packages/coloredlogs/__init__.py\", line 1140, in format\n    return logging.Formatter.format(self, record)\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/logging/__init__.py\", line 678, in format\n    record.message = record.getMessage()\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/logging/__init__.py\", line 368, in getMessage\n    msg = msg % self.args\nTypeError: not all arguments converted during string formatting\nCall stack:\n  File \"/root/DB-GPT/.venv/bin/dbgpt\", line 10, in <module>\n    sys.exit(main())\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/cli/cli_scripts.py\", line 227, in main\n    return cli()\n  File \"/root/DB-GPT/.venv/lib/python3.10/site-packages/click/core.py\", line 1161, in __call__\n    return self.main(*args, **kwargs)\n  File \"/root/DB-GPT/.venv/lib/python3.10/site-packages/click/core.py\", line 1082, in main\n    rv = self.invoke(ctx)\n  File \"/root/DB-GPT/.venv/lib/python3.10/site-packages/click/core.py\", line 1697, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"/root/DB-GPT/.venv/lib/python3.10/site-packages/click/core.py\", line 1697, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"/root/DB-GPT/.venv/lib/python3.10/site-packages/click/core.py\", line 1443, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"/root/DB-GPT/.venv/lib/python3.10/site-packages/click/core.py\", line 788, in invoke\n    return __callback(*args, **kwargs)\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/cli.py\", line 458, in wrapper\n    return func(*args, **kwargs)\n  File \"/root/DB-GPT/packages/dbgpt-app/src/dbgpt_app/_cli.py\", line 25, in start_webserver\n    run_webserver(config)\n  File \"/root/DB-GPT/packages/dbgpt-app/src/dbgpt_app/dbgpt_server.py\", line 255, in run_webserver\n    run_uvicorn(param.service.web)\n  File \"/root/DB-GPT/packages/dbgpt-app/src/dbgpt_app/dbgpt_server.py\", line 212, in run_uvicorn\n    uvicorn.run(\n  File \"/root/DB-GPT/.venv/lib/python3.10/site-packages/uvicorn/main.py\", line 579, in run\n    server.run()\n  File \"/root/DB-GPT/.venv/lib/python3.10/site-packages/uvicorn/server.py\", line 66, in run\n    return asyncio.run(self.serve(sockets=sockets))\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/asyncio/runners.py\", line 44, in run\n    return loop.run_until_complete(main)\n  File \"/root/DB-GPT/packages/dbgpt-serve/src/dbgpt_serve/agent/agents/controller.py\", line 595, in agent_team_chat_new\n    logger.error(f\"chat abnormal termination！{str(e)}\", e)\nMessage: \"chat abnormal termination！Failed to build resource database:dbgpt_serve.agent.resource.datasource.DatasourceResource: DBResource.__init__() got an unexpected keyword argument 'system_app'\"\n\n### What you expected to happen\n\nrepare\n\n### How to reproduce\n\ni dont know\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "su1234121",
      "author_type": "User",
      "created_at": "2025-03-04T08:31:00Z",
      "updated_at": "2025-03-04T14:32:34Z",
      "closed_at": "2025-03-04T14:32:34Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2391/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2391",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2391",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:46.272334",
      "comments": []
    },
    {
      "issue_number": 2384,
      "title": "[Bug] [Module Name] Failed to import sth when startup",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nBAAI/bge-large-zh-v1.5\nBAAI/bge-reranker-v2-m3\nQwen/Qwen2.5-Coder-32B-Instruct\n\n### What happened\n\n1、Failed to import: /root/DB-GPT/examples/awel/simple_nl_schema_sql_chart_example.py, error message: Traceback (most recent call last):\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/core/awel/dag/loader.py\", line 91, in parse\n    loader.exec_module(new_module)\n  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"/root/DB-GPT/examples/awel/simple_nl_schema_sql_chart_example.py\", line 235, in <module>\n    llm = OpenAILLMClient()\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/proxy/llms/chatgpt.py\", line 188, in __init__\n    _ = self.client.default_headers\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/proxy/llms/chatgpt.py\", line 252, in client\n    self._api_type, self._client = _build_openai_client(\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/utils/chatgpt_utils.py\", line 139, in _build_openai_client\n    openai_params, api_type, api_version, api_azure_deployment = _initialize_openai_v1(\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/utils/chatgpt_utils.py\", line 90, in _initialize_openai_v1\n    raise ValueError(\"api_key is required, please set OPENAI_API_KEY environment\")\nValueError: api_key is required, please set OPENAI_API_KEY environment\n\n2、Failed to import: /root/DB-GPT/examples/awel/simple_rag_rewrite_example.py, error message: Traceback (most recent call last):\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/core/awel/dag/loader.py\", line 91, in parse\n    loader.exec_module(new_module)\n  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"/root/DB-GPT/examples/awel/simple_rag_rewrite_example.py\", line 64, in <module>\n    rewrite_task = QueryRewriteOperator(llm_client=OpenAILLMClient(), nums=2)\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/proxy/llms/chatgpt.py\", line 188, in __init__\n    _ = self.client.default_headers\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/proxy/llms/chatgpt.py\", line 252, in client\n    self._api_type, self._client = _build_openai_client(\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/utils/chatgpt_utils.py\", line 139, in _build_openai_client\n    openai_params, api_type, api_version, api_azure_deployment = _initialize_openai_v1(\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/utils/chatgpt_utils.py\", line 90, in _initialize_openai_v1\n    raise ValueError(\"api_key is required, please set OPENAI_API_KEY environment\")\nValueError: api_key is required, please set OPENAI_API_KEY environment\n\n3、Failed to import: /root/DB-GPT/examples/awel/simple_rag_summary_example.py, error message: Traceback (most recent call last):\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/core/awel/dag/loader.py\", line 91, in parse\n    loader.exec_module(new_module)\n  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"/root/DB-GPT/examples/awel/simple_rag_summary_example.py\", line 65, in <module>\n    llm_client=OpenAILLMClient(), language=\"en\"\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/proxy/llms/chatgpt.py\", line 188, in __init__\n    _ = self.client.default_headers\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/proxy/llms/chatgpt.py\", line 252, in client\n    self._api_type, self._client = _build_openai_client(\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/utils/chatgpt_utils.py\", line 139, in _build_openai_client\n    openai_params, api_type, api_version, api_azure_deployment = _initialize_openai_v1(\n  File \"/root/DB-GPT/packages/dbgpt-core/src/dbgpt/model/utils/chatgpt_utils.py\", line 90, in _initialize_openai_v1\n    raise ValueError(\"api_key is required, please set OPENAI_API_KEY environment\")\nValueError: api_key is required, please set OPENAI_API_KEY environment\n\n### What you expected to happen\n\nI'm not sure whether it's have any influence for Using\n\n### How to reproduce\n\nI'm not sure whether it's have any influence for Using\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "su1234121",
      "author_type": "User",
      "created_at": "2025-03-03T07:59:37Z",
      "updated_at": "2025-03-04T08:35:51Z",
      "closed_at": "2025-03-04T08:35:51Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2384/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2384",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2384",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:46.272356",
      "comments": [
        {
          "author": "fangyinc",
          "body": "You can ignore this problem, it is a mistake in the example and we will fix it later.",
          "created_at": "2025-03-03T15:08:09Z"
        }
      ]
    },
    {
      "issue_number": 2372,
      "title": "How to upload a large knowledge graph",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU\n\n### Models information\n\nQWEN2.5-14B\n\n### What happened\n\nI failed to upload a large .md file（600m） to build a knowledge graph\n\n### What you expected to happen\n\nupload a large knowledge graph\n\n### How to reproduce\n\nupload a large knowledge graph\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "liuyu970321",
      "author_type": "User",
      "created_at": "2025-02-27T02:16:36Z",
      "updated_at": "2025-03-03T15:40:23Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2372/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2372",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2372",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:46.435704",
      "comments": [
        {
          "author": "liuyu970321",
          "body": "使用\\examples\\rag\\graph_rag_example.py，将其中graphrag-mini.md直接替换就可以吗，有没有其他注意事项，期待回复。 ",
          "created_at": "2025-02-27T02:18:37Z"
        },
        {
          "author": "Aries-ckt",
          "body": "you can reference http://docs.dbgpt.cn/docs/next/installation/integrations/graph_rag_install",
          "created_at": "2025-03-03T15:40:22Z"
        }
      ]
    },
    {
      "issue_number": 2387,
      "title": "[Feature][Module: model] support Module: XiYanSQL-QwenCoder",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nCould you consider supporting the [XiYanSQL-QwenCoder](https://github.com/XGenerationLab/XiYanSQL-QwenCoder) model.\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "scott-wong",
      "author_type": "User",
      "created_at": "2025-03-03T09:01:37Z",
      "updated_at": "2025-03-03T15:06:33Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2387/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2387",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2387",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:46.600186",
      "comments": [
        {
          "author": "fangyinc",
          "body": "Great suggestion, we will consider supporting it in the future.\nIf you are interested, you are very welcome to submit a PR.",
          "created_at": "2025-03-03T15:06:32Z"
        }
      ]
    },
    {
      "issue_number": 2376,
      "title": "the Source Code Deployment in the document is failed",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nAfter pulling the latest code, the Source Code Deployment in the document is failed. The document seems to have not been updated for a long time, and the code directory does not correspond to it.\n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "yaohongfenglove",
      "author_type": "User",
      "created_at": "2025-02-28T09:01:06Z",
      "updated_at": "2025-03-03T10:07:05Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2376/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2376",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2376",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:46.772636",
      "comments": [
        {
          "author": "othniel251917",
          "body": "![Image](https://github.com/user-attachments/assets/69c9e45f-8eb1-4401-855d-6b74fad5fe7b)\n我发现了同样的问题，按照文档根本没有办法进行下去，同时钉钉群还满了，也没有办法找到任何相关的社区",
          "created_at": "2025-03-02T02:49:53Z"
        },
        {
          "author": "su1234121",
          "body": "http://docs.dbgpt.cn/docs/next/quickstart，参见这个文档， Starting from version 0.7.0, DB-GPT uses uv for environment and package management, providing faster and more stable dependency management.",
          "created_at": "2025-03-03T07:19:02Z"
        },
        {
          "author": "johnjob",
          "body": "Using CPython 3.11.7 interpreter at: /opt/anaconda3/bin/python3.11\nCreating virtual environment at: .venv\nerror: Distribution `onnxruntime==1.18.1 @ registry+https://pypi.tuna.tsinghua.edu.cn/simple` can't be installed because it doesn't have a source distribution or wheel for the current platform\n\n",
          "created_at": "2025-03-03T10:07:04Z"
        }
      ]
    },
    {
      "issue_number": 2377,
      "title": "[Bug] [StartUp Failed]  Getting requirements to build editable did not run successfully.",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice：CPU\n\n### Models information\n\nQwen2.5-14B-Instruct\n\n### What happened\n\n Installing build dependencies ... done\n  Checking if build backend supports build_editable ... done\n  Getting requirements to build editable ... error\n  error: subprocess-exited-with-error\n\n  × Getting requirements to build editable did not run successfully.\n  │ exit code: 1\n  ╰─> [14 lines of output]\n      error: Multiple top-level packages discovered in a flat-layout: ['web', 'i18n', 'pilot', 'assets', 'docker', 'configs', 'packages'].\n\n### What you expected to happen\n\nStartUp Failed and have no solution\n\n### How to reproduce\n\nStartUp successful\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "su1234121",
      "author_type": "User",
      "created_at": "2025-02-28T10:02:21Z",
      "updated_at": "2025-03-03T07:17:15Z",
      "closed_at": "2025-03-03T07:17:15Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2377/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2377",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2377",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:46.935159",
      "comments": [
        {
          "author": "pc-mysql",
          "body": "#2362 has solution\n",
          "created_at": "2025-03-01T17:06:37Z"
        }
      ]
    },
    {
      "issue_number": 2379,
      "title": "[Bug] loss more modules in 0.7.0",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\nPython 3.12.1\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU: 12th Gen Intel(R) Core(TM) i9-12900KF   3.20 GHz\nGPU: NVIDIA GeForce GTX 4090 24G\n\n### Models information\n\nLLM: qwen2.5\n\n### What happened\n\n$ uv run dbgpt start webserver --config configs/dbgpt-local-glm.toml\nTraceback (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"D:\\DB-GPT\\.venv\\Scripts\\dbgpt.exe\\__main__.py\", line 10, in <module>\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\cli\\cli_scripts.py\", line 227, in main\n    return cli()\n           ^^^^^\n  File \"D:\\DB-GPT\\.venv\\Lib\\site-packages\\click\\core.py\", line 1161, in __call__\n    return self.main(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\.venv\\Lib\\site-packages\\click\\core.py\", line 1082, in main\n    rv = self.invoke(ctx)\n         ^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\.venv\\Lib\\site-packages\\click\\core.py\", line 1697, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\.venv\\Lib\\site-packages\\click\\core.py\", line 1697, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\.venv\\Lib\\site-packages\\click\\core.py\", line 1443, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\.venv\\Lib\\site-packages\\click\\core.py\", line 788, in invoke\n    return __callback(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\model\\cli.py\", line 458, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\DB-GPT\\packages\\dbgpt-app\\src\\dbgpt_app\\_cli.py\", line 23, in start_webserver\n    from dbgpt_app.dbgpt_server import run_webserver\n  File \"D:\\DB-GPT\\packages\\dbgpt-app\\src\\dbgpt_app\\dbgpt_server.py\", line 28, in <module>\n    from dbgpt_app.base import (\n  File \"D:\\DB-GPT\\packages\\dbgpt-app\\src\\dbgpt_app\\base.py\", line 14, in <module>\n    from dbgpt.datasource.rdbms.base import RDBMSConnector, RDBMSDatasourceParameters\n  File \"D:\\DB-GPT\\packages\\dbgpt-core\\src\\dbgpt\\datasource\\rdbms\\base.py\", line 26, in <module>\n    import sqlalchemy\nModuleNotFoundError: No module named 'sqlalchemy'\n\n\n### What you expected to happen\n\nrun web server\n\n### How to reproduce\n\nrun\n```bash\nuv sync --all-packages --frozen \\\n--extra \"rag\" \\\n--extra \"storage_chromadb\" \\\n--extra \"hf\" \\\n--extra \"quant_bnb\" \\\n--extra \"dbgpts\"\n```\nrun \n```\nuv run dbgpt start webserver --config configs/dbgpt-local-glm.toml\n```\n\n### Additional context\n\nWhen I installed `sqlalchemy` using `uv`, I encountered a missing `sqlparse` error. After manually installing `sqlparse` and rerunning the command:  `uv run dbgpt start webserver --config configs/dbgpt-local-glm.toml`\n\nI still get errors about other missing modules. e.g.,pympler\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "jjj201200",
      "author_type": "User",
      "created_at": "2025-02-28T23:08:33Z",
      "updated_at": "2025-03-03T05:30:31Z",
      "closed_at": "2025-03-03T05:30:30Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2379/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2379",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2379",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:47.100547",
      "comments": [
        {
          "author": "jjj201200",
          "body": "When i add pympler, then:\n```\n$ uv run dbgpt start webserver --config configs/dbgpt-local-glm.toml\nTraceback (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"D:\\DB-GPT0.7.0\\.venv\\Scripts\\dbgpt.exe\\__main__.py\", ",
          "created_at": "2025-03-01T00:09:03Z"
        },
        {
          "author": "jjj201200",
          "body": "```\nDF2023@DF-2023 MINGW64 /d/DB-GPT0.7.0 (main)\n$ uv add shortuuid\nResolved 499 packages in 12.61s\n░░░░░░░░░░░░░░░░░░░░ [0/1] Installing wheels...                                warning: Failed to hardlink files; falling back to full copy. This may lead to degraded performance.\n         If the cach",
          "created_at": "2025-03-01T00:16:35Z"
        },
        {
          "author": "JerryLuo5799",
          "body": "I got same issue 😭\nI tried to deploy via source code base on Win11 + Anaconda, and also base on Win11 + WSL2 + Unbutu24\n\n",
          "created_at": "2025-03-03T01:35:14Z"
        },
        {
          "author": "othniel251917",
          "body": "win11+Anaconda+uv这个我也失败了(在Claude3.7的帮助下也无法跑起来)\nwin11+wsl2+unbutu+rust+Anaconda+6.1版本我倒是把依赖都下载好了，但是docker打包仍然有问题，",
          "created_at": "2025-03-03T02:48:03Z"
        },
        {
          "author": "fangyinc",
          "body": "I'm sorry for this. \nPlease pull the latest main branch codes and run:\n```bash\nuv sync --all-packages --frozen \\\n--extra \"base\" \\\n--extra \"hf\" \\ \n--extra \"dbgpts\" \\\n--extra \"rag\" \\\n--extra \"storage_chromadb\" \\\n--extra \"dbgpts\"\n```",
          "created_at": "2025-03-03T03:43:27Z"
        }
      ]
    },
    {
      "issue_number": 2362,
      "title": "[Bug] [Module Name] install from source pip install error",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nrk3588 cpu\narm64 ubuntu 20.04\n\n### Models information\n\nhave not install success\n\n### What happened\n\npip install error\n\n### What you expected to happen\n\nquickly\n\n### How to reproduce\n\ninstall from source \n pip install ...            watch the png\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Anbingsong",
      "author_type": "User",
      "created_at": "2025-02-24T01:45:07Z",
      "updated_at": "2025-03-01T01:44:10Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2362/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2362",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2362",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:47.337150",
      "comments": [
        {
          "author": "Anbingsong",
          "body": "![Image](https://github.com/user-attachments/assets/5e3cf402-348b-415c-8425-b337e982c6aa)",
          "created_at": "2025-02-24T01:46:11Z"
        },
        {
          "author": "swit1983",
          "body": "遇到一样的问题怎么解决啊？",
          "created_at": "2025-02-24T07:21:20Z"
        },
        {
          "author": "fangyinc",
          "body": "DB-GPT will use a new installation method starting from 0.7.0. For details, please see:  http://docs.dbgpt.cn/docs/next/quickstart",
          "created_at": "2025-02-24T08:41:29Z"
        },
        {
          "author": "swit1983",
          "body": "@fangyinc ollama 本地部署的 deepseek应该怎么修改配置文件",
          "created_at": "2025-02-25T02:08:04Z"
        },
        {
          "author": "Anbingsong",
          "body": "does it support arm64 linux cpu?",
          "created_at": "2025-02-26T06:56:45Z"
        }
      ]
    },
    {
      "issue_number": 2158,
      "title": "[Bug] [Module Name] ChatData error，Can not find sql in response",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [X] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU集群\n\n### Models information\n\ntext2vec-large-chinese\r\nqwen2.5-7b  \n\n### What happened\n\n对话数据时，无法显示结果，报错如图：\r\n![Uploading 60ff40dee757c878fb0a754a73ca448.png…]()\r\n报错日志：2024-11-27 10:35:20 localhost1 dbgpt.app.scene.chat_db.auto_execute.out_parser[113762] ERROR json load failed:{ \"thoughts\": \"用户想要查询表‘2023集团volte自忙时2月质差’中的前十条信息。根据提供的表结构定义，可以直接从该表中选择前10条记录。\", \"sql\": \"SELECT * FROM \"2023集团volte自忙时2月质差 \" LIMIT 10;\", \"display_type\": \"response_table\" } do_action:SqlAction(sql='', thoughts='{ \"thoughts\": \"用户想要查询表‘2023集团volte自忙时2月质差’中的前十条信息。根据提供的表结构定义，可以直接从该表中选择前10条记录。\", \"sql\": \"SELECT * FROM \"2023集团volte自忙时2月质差 \" LIMIT 10;\", \"display_type\": \"response_table\" }', display='') 2024-11-27 10:35:20 localhost1 dbgpt.app.scene.chat_db.auto_execute.out_parser[113762] ERROR parse_view_response error!Can not find sql in response 2024-11-27 10:35:20 localhost1 dbgpt.util.retry[113762] ERROR Attempt 1 of 1 failed with error: AppActionException, Generate view content failed\n\n### What you expected to happen\n\n如何呈现如文档实例中显示的样子？\r\n![image](https://github.com/user-attachments/assets/e928b7b8-f39e-4e2e-948f-a35249df77d7)\r\n\n\n### How to reproduce\n\n添加数据库，输入：查询XXX表前2条数据\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "w371803361",
      "author_type": "User",
      "created_at": "2024-11-27T03:36:35Z",
      "updated_at": "2025-03-01T01:24:52Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2158/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2158",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2158",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:47.517533",
      "comments": [
        {
          "author": "w371803361",
          "body": "![60ff40dee757c878fb0a754a73ca448](https://github.com/user-attachments/assets/586fefc5-5885-4135-86be-1a6b631a1a32)\r\n报错如图",
          "created_at": "2024-11-27T03:37:22Z"
        },
        {
          "author": "Dongxiaohaoo",
          "body": "同样遇到相似的问题，只会回答SQL不会绘制表格和图形，似乎无法查询数据库内容",
          "created_at": "2024-11-27T11:09:16Z"
        },
        {
          "author": "Aries-ckt",
          "body": "this pr will solve your problem. you can try. https://github.com/eosphoros-ai/DB-GPT/pull/2152",
          "created_at": "2024-11-27T11:43:17Z"
        },
        {
          "author": "w371803361",
          "body": "> 这个 PR 将解决您的问题。你可以试试。[排名 #2152](https://github.com/eosphoros-ai/DB-GPT/pull/2152)\r\n\r\n![image](https://github.com/user-attachments/assets/5ea8b4c8-4738-4a3d-a1b7-7857a8d729cd)\r\n尝试了上述方法，修改了out_parser.py和prompt.py代码，chat_db的回答仍然如图所示，并未给出具体数据库中的表名称，还是回答一些和问题关系不大的通用语句，请问还有其它解决办法吗？",
          "created_at": "2024-12-10T08:44:49Z"
        },
        {
          "author": "roymax",
          "body": "我增加一行数据类型定义，可以解决这个问题\n\n`sql = thoughts = display = resp =\"\"`\n\n<img width=\"1304\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/ec7081a4-4e21-4aba-b65d-e9864a43f01f\" />",
          "created_at": "2025-02-13T08:31:04Z"
        }
      ]
    },
    {
      "issue_number": 2109,
      "title": "[Bug] When the document imported into the knowledge base exceeds 10,000 words, a Python exception terminal appears, but there is no error in DEBUG mode.",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [X] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n/\n\n### Models information\n\nXinference的embediing模型，zhipu_proxyllm模型\n\n### What happened\n\n/\n\n### What you expected to happen\n\n![image](https://github.com/user-attachments/assets/a0d826a4-470f-4add-962a-c7d49ef3c8ea)\r\n最后的输出日志为：2024-10-30 20:01:05 ZHY-PC chromadb.config[29572] DEBUG Starting component PersistentLocalHnswSegment\n\n### How to reproduce\n\n/\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "fryng",
      "author_type": "User",
      "created_at": "2024-10-30T12:05:59Z",
      "updated_at": "2025-02-28T21:04:49Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2109/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2109",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2109",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:47.712651",
      "comments": [
        {
          "author": "fryng",
          "body": "通过断点调试，判断是chromadb版本问题，换了几个版本后，还是没有解决，通过windows事件查看器发现是MSVCP140.dll出现问题，前往下载最新的VC_redist.exe安装解决问题https://learn.microsoft.com/da-dk/cpp/windows/latest-supported-vc-redist?view=msvc-170\r\n![image](https://github.com/user-attachments/assets/cb38250e-0fda-4560-b16e-1bc4267e868b)\r\n",
          "created_at": "2024-10-31T05:24:18Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-02-28T21:04:48Z"
        }
      ]
    },
    {
      "issue_number": 2352,
      "title": "[Bug] [Module Name] Bug title deepseek 报错 ypeError: AsyncClient.__init__() got an unexpected keyword argument 'proxies'",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\ncpu\n\n### Models information\n\ndeepseek_proxyllm\n\n### What happened\n\n dbgpt.model.cluster.worker.default_worker[31692] ERROR Model inference error, detail: Traceback (most recent call last):\n  File \"d:\\项目\\db-gpt-0.6.2_statics\\dbgpt\\model\\cluster\\worker\\default_worker.py\", line 248, in async_generate_stream\n    async for output in generate_stream_func(\n  File \"d:\\项目\\db-gpt-0.6.2_statics\\dbgpt\\model\\proxy\\llms\\deepseek.py\", line 32, in deepseek_generate_stream\n    async for r in client.generate_stream(request):\n  File \"d:\\项目\\db-gpt-0.6.2_statics\\dbgpt\\model\\proxy\\llms\\chatgpt.py\", line 233, in generate_stream\n    async for r in self.generate_stream_v1(messages, payload):\n  File \"d:\\项目\\db-gpt-0.6.2_statics\\dbgpt\\model\\proxy\\llms\\chatgpt.py\", line 261, in generate_stream_v1\n    chat_completion = await self.client.chat.completions.create(\n  File \"d:\\项目\\db-gpt-0.6.2_statics\\dbgpt\\model\\proxy\\llms\\chatgpt.py\", line 164, in client\n    self._api_type, self._client = _build_openai_client(\n  File \"d:\\项目\\db-gpt-0.6.2_statics\\dbgpt\\model\\utils\\chatgpt_utils.py\", line 156, in _build_openai_client\n    **openai_params, http_client=httpx.AsyncClient(proxies=init_params.proxies)\nTypeError: AsyncClient.__init__() got an unexpected keyword argument 'proxies'\n\n### What you expected to happen\n\n。。。\n\n### How to reproduce\n\n。。。\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "LHT2019",
      "author_type": "User",
      "created_at": "2025-02-17T08:19:29Z",
      "updated_at": "2025-02-28T08:41:09Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2352/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2352",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2352",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:47.966732",
      "comments": [
        {
          "author": "nameless0704",
          "body": "same",
          "created_at": "2025-02-24T07:14:15Z"
        },
        {
          "author": "CH0918",
          "body": "Same, how do you solve this? bro",
          "created_at": "2025-02-24T10:04:05Z"
        },
        {
          "author": "caicongyang",
          "body": "same",
          "created_at": "2025-02-27T03:19:14Z"
        },
        {
          "author": "hero851815",
          "body": "@LHT2019 \nMy solution step:\n1. Upgrade httpx to 0.28.0. (Probably, it is not necessary)\n2. Modify _build_openai_client from '/dbgpt/model/utils/chatgpt_utils.py'.\n3. Restart db-gpt.\n\n<img width=\"1030\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/1a2931f7-6e6a-4733-88c1-91dd9e9625a0\" /",
          "created_at": "2025-02-28T08:37:34Z"
        }
      ]
    },
    {
      "issue_number": 2374,
      "title": "[Feature]如何调用局域网内部署的deepseek",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n_No response_\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "jarrywong",
      "author_type": "User",
      "created_at": "2025-02-27T08:58:29Z",
      "updated_at": "2025-02-28T06:22:30Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2374/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2374",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2374",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:48.153624",
      "comments": [
        {
          "author": "dkasa",
          "body": "看你用什么方式部署的，如用ollama，你就选 llm 的 proxy/ollama 配置对应11434地址",
          "created_at": "2025-02-28T06:22:29Z"
        }
      ]
    },
    {
      "issue_number": 2329,
      "title": "[Bug] [Module Name] web compile error: Failed to collect page data for /knowledge/graph",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n-\n\n### Models information\n\n-\n\n### What happened\n\n![Image](https://github.com/user-attachments/assets/bba01413-bcf3-45a7-a411-021f62d3fb73)\n前端小白，拉取main分支代码，根据操作文档步骤编译前端代码报错，是有没更新的代码吗？\n\n### What you expected to happen\n\n前端正常编译成功\n\n### How to reproduce\n\n-\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "yuerf",
      "author_type": "User",
      "created_at": "2025-02-06T07:48:21Z",
      "updated_at": "2025-02-28T02:38:17Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2329/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2329",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2329",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:48.383419",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "try `npm install d3-color@2.0.0`",
          "created_at": "2025-02-07T05:18:25Z"
        },
        {
          "author": "etcxy",
          "body": "> npm install d3-color@2.0.0\n\nstill error",
          "created_at": "2025-02-28T02:38:16Z"
        }
      ]
    },
    {
      "issue_number": 2104,
      "title": "[Bug]  _context_join_fn() missing 1 required positional argument: 'chunks'",
      "body": "### Search before asking\r\n\r\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\r\n\r\n\r\n### Operating system information\r\n\r\nLinux\r\n\r\n### Python version information\r\n\r\n>=3.11\r\n\r\n### DB-GPT version\r\n\r\nmain\r\n\r\n### Related scenes\r\n\r\n- [ ] Chat Data\r\n- [ ] Chat Excel\r\n- [ ] Chat DB\r\n- [ ] Chat Knowledge\r\n- [ ] Model Management\r\n- [ ] Dashboard\r\n- [ ] Plugins\r\n\r\n### Installation Information\r\n\r\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\r\n\r\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\r\n\r\n- [ ] AutoDL Image\r\n- [X] Other\r\n\r\n### Device information\r\n\r\nDevice CPU\r\n\r\n### Models information\r\n\r\nLLM: Proxy Ollama: qwen:0.5b\r\nEmbedding: Proxy Ollama: nomic-embed-text\r\n\r\n### What happened\r\n\r\nI run [simple_rag_retriever_example.py](https://github.com/eosphoros-ai/DB-GPT/blob/main/examples/rag/simple_rag_embedding_example.py)\r\n\r\nIt raise a error \r\n```bash\r\nnal Server Error\r\nERROR:    Exception in ASGI application\r\nTraceback (most recent call last):\r\n  File \"/media/manhdt4/sda1/miniconda3/envs/dbgpt/lib/python3.10/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 401, in run_asgi\r\n    result = await app(  # type: ignore[func-returns-value]\r\n  File \"/media/manhdt4/sda1/miniconda3/envs/dbgpt/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\r\n    return await self.app(scope, receive, send)\r\n  File \"/media/manhdt4/sda1/miniconda3/envs/dbgpt/lib/python3.10/site-packages/fastapi/applications.py\", line 1054, in __call__\r\n    await super().__call__(scope, receive, send)\r\n  File \"/media/manhdt4/sda1/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/applications.py\", line 113, in __call__\r\n    await self.middleware_stack(scope, receive, send)\r\n  File \"/media/manhdt4/sda1/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/errors.py\", line 187, in __call__\r\n    raise exc\r\n  File \"/media/manhdt4/sda1/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/errors.py\", line 165, in __call__\r\n    await self.app(scope, receive, _send)\r\n  File \"/media/manhdt4/sda1/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\r\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\r\n  File \"/media/manhdt4/sda1/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\r\n    raise exc\r\n  File \"/media/manhdt4/sda1/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\r\n    await app(scope, receive, sender)\r\n  File \"/media/manhdt4/sda1/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/routing.py\", line 715, in __call__\r\n    await self.middleware_stack(scope, receive, send)\r\n  File \"/media/manhdt4/sda1/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/routing.py\", line 735, in app\r\n    await route.handle(scope, receive, send)\r\n  File \"/media/manhdt4/sda1/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/routing.py\", line 288, in handle\r\n    await self.app(scope, receive, send)\r\n  File \"/media/manhdt4/sda1/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/routing.py\", line 76, in app\r\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\r\n  File \"/media/manhdt4/sda1/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\r\n    raise exc\r\n  File \"/media/manhdt4/sda1/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\r\n    await app(scope, receive, sender)\r\n  File \"/media/manhdt4/sda1/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/routing.py\", line 73, in app\r\n    response = await f(request)\r\n  File \"/media/manhdt4/sda1/miniconda3/envs/dbgpt/lib/python3.10/site-packages/fastapi/routing.py\", line 301, in app\r\n    raw_response = await run_endpoint_function(\r\n  File \"/media/manhdt4/sda1/miniconda3/envs/dbgpt/lib/python3.10/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\r\n    return await dependant.call(**values)\r\n  File \"/media/manhdt4/sda1/db-gpt/DB-GPT/dbgpt/core/awel/trigger/http_trigger.py\", line 676, in route_function\r\n    return await _trigger_dag_func(body)\r\n  File \"/media/manhdt4/sda1/db-gpt/DB-GPT/dbgpt/core/awel/trigger/http_trigger.py\", line 607, in _trigger_dag_func\r\n    return await _trigger_dag(\r\n  File \"/media/manhdt4/sda1/db-gpt/DB-GPT/dbgpt/core/awel/trigger/http_trigger.py\", line 729, in _trigger_dag\r\n    return await end_node.call(call_data=body)\r\n  File \"/media/manhdt4/sda1/db-gpt/DB-GPT/dbgpt/core/awel/operators/base.py\", line 283, in call\r\n    out_ctx = await self._runner.execute_workflow(\r\n  File \"/media/manhdt4/sda1/db-gpt/DB-GPT/dbgpt/core/awel/runner/local_runner.py\", line 114, in execute_workflow\r\n    await self._execute_node(\r\n  File \"/media/manhdt4/sda1/db-gpt/DB-GPT/dbgpt/core/awel/runner/local_runner.py\", line 143, in _execute_node\r\n    await self._execute_node(\r\n  File \"/media/manhdt4/sda1/db-gpt/DB-GPT/dbgpt/core/awel/runner/local_runner.py\", line 143, in _execute_node\r\n    await self._execute_node(\r\n  File \"/media/manhdt4/sda1/db-gpt/DB-GPT/dbgpt/core/awel/runner/local_runner.py\", line 143, in _execute_node\r\n    await self._execute_node(\r\n  [Previous line repeated 1 more time]\r\n  File \"/media/manhdt4/sda1/db-gpt/DB-GPT/dbgpt/core/awel/runner/local_runner.py\", line 213, in _execute_node\r\n    raise e\r\n  File \"/media/manhdt4/sda1/db-gpt/DB-GPT/dbgpt/core/awel/runner/local_runner.py\", line 192, in _execute_node\r\n    await node._run(dag_ctx, task_ctx.log_id)\r\n  File \"/media/manhdt4/sda1/db-gpt/DB-GPT/dbgpt/core/awel/operators/base.py\", line 248, in _run\r\n    return await self._do_run(dag_ctx)\r\n  File \"/media/manhdt4/sda1/db-gpt/DB-GPT/dbgpt/core/awel/operators/common_operator.py\", line 62, in _do_run\r\n    input_ctx: InputContext = await curr_task_ctx.task_input.map_all(\r\n  File \"/media/manhdt4/sda1/db-gpt/DB-GPT/dbgpt/core/awel/task/task_impl.py\", line 580, in map_all\r\n    map_res = map_func(*outputs)\r\nTypeError: _context_join_fn() missing 1 required positional argument: 'chunks'\r\n```\r\n\r\n### What you expected to happen\r\n\r\nHow can I fix that?\r\n\r\n### How to reproduce\r\n\r\n1. `python examples/rag/simple_rag_retriever_example.py`\r\n2. call from postman\r\n```\r\ncurl --location 'http://localhost:5555/api/v1/awel/trigger/examples/rag/retrieve' \\\r\n--header 'Content-Type: application/json' \\\r\n--data '{ \r\n    \"query\": \"what is awel talk about?\"\r\n}'\r\n```\r\n\r\n### Additional context\r\n\r\n_No response_\r\n\r\n### Are you willing to submit PR?\r\n\r\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "david101-hunter",
      "author_type": "User",
      "created_at": "2024-10-29T06:42:36Z",
      "updated_at": "2025-02-27T21:05:13Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2104/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2104",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2104",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:48.615892",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-02-27T21:05:12Z"
        }
      ]
    },
    {
      "issue_number": 2318,
      "title": "[Feature][GraphRAG] adapt local fine-tuned LLM for text2gql translation.",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n_No response_\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "SonglinLyu",
      "author_type": "User",
      "created_at": "2025-01-22T06:40:43Z",
      "updated_at": "2025-02-27T13:56:21Z",
      "closed_at": "2025-02-27T13:56:20Z",
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2318/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2318",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2318",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:48.882138",
      "comments": []
    },
    {
      "issue_number": 2163,
      "title": "[Bug] [Module Name] sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: gpts_app",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU Count:1 24G\n\n### Models information\n\nLLM_MODEL=glm-4-9b-chat\r\n\n\n### What happened\n\n本地部署报错：\r\nTraceback (most recent call last):\r\n  File \"/home/ec2-user/workdir/DB-GPT/dbgpt/serve/agent/db/gpts_app.py\", line 1233, in init_native_apps\r\n    gpts_dao.remove_native_app(chat_excel_app.app_code)\r\n  File \"/home/ec2-user/workdir/DB-GPT/dbgpt/serve/agent/db/gpts_app.py\", line 834, in remove_native_app\r\n    app_qry.delete()\r\n  File \"/opt/conda/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py\", line 3161, in delete\r\n    result: CursorResult[Any] = self.session.execute(\r\n  File \"/opt/conda/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py\", line 2306, in execute\r\n    return self._execute_internal(\r\n  File \"/opt/conda/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py\", line 2191, in _execute_internal\r\n    result: Result[Any] = compile_state_cls.orm_execute_statement(\r\n  File \"/opt/conda/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/orm/bulk_persistence.py\", line 1946, in orm_execute_statement\r\n    return super().orm_execute_statement(\r\n  File \"/opt/conda/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/orm/context.py\", line 293, in orm_execute_statement\r\n    result = conn.execute(\r\n  File \"/opt/conda/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1421, in execute\r\n    return meth(\r\n  File \"/opt/conda/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py\", line 514, in _execute_on_connection\r\n    return connection._execute_clauseelement(\r\n  File \"/opt/conda/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1643, in _execute_clauseelement\r\n    ret = self._execute_context(\r\n  File \"/opt/conda/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1849, in _execute_context\r\n    return self._exec_single_context(\r\n  File \"/opt/conda/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1989, in _exec_single_context\r\n    self._handle_dbapi_exception(\r\n  File \"/opt/conda/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 2356, in _handle_dbapi_exception\r\n    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e\r\n  File \"/opt/conda/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1970, in _exec_single_context\r\n    self.dialect.do_execute(\r\n  File \"/opt/conda/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py\", line 924, in do_execute\r\n    cursor.execute(statement, parameters)\r\nsqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: gpts_app\r\n[SQL: DELETE FROM gpts_app WHERE gpts_app.team_mode = ? AND gpts_app.app_code = ?]\r\n[parameters: ('native_app', 'chat_excel')]\r\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\r\n2024-11-28 08:47:07 ip-172-31-32-169.ec2.internal dbgpt.app.initialization.embedding_component[10507] INFO Register local LocalEmbeddingFactory\r\n2024-11-28 08:47:07 ip-172-31-32-169.ec2.internal dbgpt.model.adapter.embeddings_loader[10507] INFO [EmbeddingsModelWorker] Parameters of device is None, use cuda\r\n2024-11-28 08:47:07 ip-172-31-32-169.ec2.internal dbgpt.app.initialization.embedding_component[10507] INFO\n\n### What you expected to happen\n\nsuccess\n\n### How to reproduce\n\nhttp://docs.dbgpt.cn/docs/quickstart/\r\n按照文档顺序执行，sqlite3数据库\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "clarkzhanghao",
      "author_type": "User",
      "created_at": "2024-11-28T08:51:57Z",
      "updated_at": "2025-02-27T03:16:18Z",
      "closed_at": "2025-01-09T07:36:25Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2163/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2163",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2163",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:48.882159",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "check your database schema with `dbgpt.sql`",
          "created_at": "2024-11-28T12:46:27Z"
        },
        {
          "author": "tyy360142420",
          "body": "![屏幕截图 2024-11-30 195417](https://github.com/user-attachments/assets/93fbdcb7-5019-4950-87f0-aa5a5fbb669f)\r\nHi, i also met this problem. And my container could not start. I don't know how to solve this error.\r\nI pull the image from dockerhub.",
          "created_at": "2024-11-30T12:05:20Z"
        },
        {
          "author": "Aries-ckt",
          "body": "How did you deploy start dbgpt server? docker or source code?",
          "created_at": "2024-12-08T16:06:49Z"
        },
        {
          "author": "LuWei6896",
          "body": "同样的问题!!!!!",
          "created_at": "2025-01-06T07:04:05Z"
        },
        {
          "author": "MrJs133",
          "body": "I also met this problem after deploying follow the doc https://www.yuque.com/eosphoros/dbgpt-docs/ew0kf1plm0bru2ga",
          "created_at": "2025-02-11T06:42:35Z"
        }
      ]
    },
    {
      "issue_number": 2369,
      "title": "[Doc][Module Name] install documention problem",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n首先文档中说\n`cp .env.template  .env`\n\n![Image](https://github.com/user-attachments/assets/7cd623f0-026d-4bdb-bdda-27b73b944693)\nenv.template在哪？\n\n第二个问题文档中说\n`python dbgpt/app/dbgpt_server.py`\n\n![Image](https://github.com/user-attachments/assets/922860b2-6b65-4c4b-8e8e-21501ecd898f)\ndbgpt在哪？\n\n\n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "skinny0604",
      "author_type": "User",
      "created_at": "2025-02-25T02:46:49Z",
      "updated_at": "2025-02-25T16:08:02Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2369/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2369",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2369",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:49.066098",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "we now prepare v0.7.0 version, reference http://docs.dbgpt.cn/docs/next/quickstart",
          "created_at": "2025-02-25T16:03:19Z"
        },
        {
          "author": "Aries-ckt",
          "body": "Chinese tutorial is below v0.7.0, you can also install v0.6.3\n```\ngit tag\ngit checkout tags/v0.6.3\n```",
          "created_at": "2025-02-25T16:06:55Z"
        }
      ]
    },
    {
      "issue_number": 2280,
      "title": "[Bug] [Module Name] Bug title ",
      "body": "### Search before asking\r\n\r\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\r\n\r\n\r\n### Operating system information\r\n\r\nLinux\r\n\r\n### Python version information\r\n\r\n3.10\r\n\r\n### DB-GPT version\r\n\r\nmain\r\n\r\n### Related scenes\r\n\r\n- [ ] Chat Data\r\n- [ ] Chat Excel\r\n- [ ] Chat DB\r\n- [ ] Chat Knowledge\r\n- [ ] Model Management\r\n- [X] Dashboard\r\n- [ ] Plugins\r\n\r\n### Installation Information\r\n\r\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\r\n\r\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\r\n\r\n- [ ] AutoDL Image\r\n- [ ] Other\r\n\r\n### Device information\r\n\r\nCPU: i9 14900KF\r\nGPU: RTX-4090D 24G \r\n\r\n\r\n### Models information\r\n\r\nLLM_MODEL=chatgpt_proxyllm\r\n\r\n### What happened\r\n\r\nI followed the http://docs.dbgpt.cn/docs/quickstart document to build the DB-GPT environment, but when I executed `python dbgpt/app/dbgpt_server.py`, I got the following error，:\r\n```\r\ndbgpt.core.awel.dag.dag_manager.DAGManager object at 0x7fdffa1b4310>\r\nTraceback (most recent call last):\r\n  File \"/home/hygx/anaconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1970, in _exec_single_context\r\n    self.dialect.do_execute(\r\n  File \"/home/hygx/anaconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py\", line 924, in do_execute\r\n    cursor.execute(statement, parameters)\r\nsqlite3.OperationalError: no such table: gpts_app_collection\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/hygx/code/DB-GPT/dbgpt/app/dbgpt_server.py\", line 289, in <module>\r\n    run_webserver()\r\n  File \"/home/hygx/code/DB-GPT/dbgpt/app/dbgpt_server.py\", line 275, in run_webserver\r\n    param = initialize_app(param)\r\n  File \"/home/hygx/code/DB-GPT/dbgpt/app/dbgpt_server.py\", line 171, in initialize_app\r\n    initialize_components(\r\n  File \"/home/hygx/code/DB-GPT/dbgpt/app/component_configs.py\", line 58, in initialize_components\r\n    _initialize_resource_manager(system_app)\r\n  File \"/home/hygx/code/DB-GPT/dbgpt/app/component_configs.py\", line 109, in _initialize_resource_manager\r\n    from dbgpt.agent.resource.app import AppResource\r\n  File \"/home/hygx/code/DB-GPT/dbgpt/agent/resource/app.py\", line 28, in <module>\r\n    class AppResourceParameters(ResourceParameters):\r\n  File \"/home/hygx/code/DB-GPT/dbgpt/agent/resource/app.py\", line 34, in AppResourceParameters\r\n    \"valid_values\": _get_app_list(),\r\n  File \"/home/hygx/code/DB-GPT/dbgpt/agent/resource/app.py\", line 15, in _get_app_list\r\n    apps = get_app_manager().get_dbgpts()\r\n  File \"/home/hygx/code/DB-GPT/dbgpt/serve/agent/agents/app_agent_manage.py\", line 57, in get_dbgpts\r\n    apps = self.gpts_app.app_list(\r\n  File \"/home/hygx/code/DB-GPT/dbgpt/serve/agent/db/gpts_app.py\", line 584, in app_list\r\n    gpts_collections = collection_dao.list(\r\n  File \"/home/hygx/code/DB-GPT/dbgpt/serve/agent/db/gpts_app.py\", line 531, in list\r\n    res = app_qry.all()\r\n  File \"/home/hygx/anaconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py\", line 2673, in all\r\n    return self._iter().all()  # type: ignore\r\n  File \"/home/hygx/anaconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py\", line 2827, in _iter\r\n    result: Union[ScalarResult[_T], Result[_T]] = self.session.execute(\r\n  File \"/home/hygx/anaconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py\", line 2306, in execute\r\n    return self._execute_internal(\r\n  File \"/home/hygx/anaconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py\", line 2191, in _execute_internal\r\n    result: Result[Any] = compile_state_cls.orm_execute_statement(\r\n  File \"/home/hygx/anaconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/orm/context.py\", line 293, in orm_execute_statement\r\n    result = conn.execute(\r\n  File \"/home/hygx/anaconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1421, in execute\r\n    return meth(\r\n  File \"/home/hygx/anaconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py\", line 514, in _execute_on_connection\r\n    return connection._execute_clauseelement(\r\n  File \"/home/hygx/anaconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1643, in _execute_clauseelement\r\n    ret = self._execute_context(\r\n  File \"/home/hygx/anaconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1849, in _execute_context\r\n    return self._exec_single_context(\r\n  File \"/home/hygx/anaconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1989, in _exec_single_context\r\n    self._handle_dbapi_exception(\r\n  File \"/home/hygx/anaconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 2356, in _handle_dbapi_exception\r\n    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e\r\n  File \"/home/hygx/anaconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1970, in _exec_single_context\r\n    self.dialect.do_execute(\r\n  File \"/home/hygx/anaconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py\", line 924, in do_execute\r\n    cursor.execute(statement, parameters)\r\nsqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: gpts_app_collection\r\n[SQL: SELECT gpts_app_collection.id AS gpts_app_collection_id, gpts_app_collection.app_code AS gpts_app_collection_app_code, gpts_app_collection.user_code AS gpts_app_collection_user_code, gpts_app_collection.sys_code AS gpts_app_collection_sys_code, gpts_app_collection.created_at AS gpts_app_collection_created_at, gpts_app_collection.updated_at AS gpts_app_collection_updated_at\r\nFROM gpts_app_collection]\r\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\r\n```\r\n\r\nI saw a similar problem in the issue https://github.com/eosphoros-ai/DB-GPT/issues/1800 , but his LOCAL_DB_TYPE is different from mine. My LOCAL_DB_TYPE is sqlite. How should I deal with this problem?\r\n\r\n### What you expected to happen\r\n\r\nDB-GPT is operating normally\r\n\r\n### How to reproduce\r\n\r\njust follow the doc : http://docs.dbgpt.cn/docs/quickstart\r\n\r\n### Additional context\r\n\r\n_No response_\r\n\r\n### Are you willing to submit PR?\r\n\r\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "JV-X",
      "author_type": "User",
      "created_at": "2025-01-06T10:19:01Z",
      "updated_at": "2025-02-25T14:18:17Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2280/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2280",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2280",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:49.243975",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "Hi, thanks for your feedback. It’s weird, so now you can check your SQLite schema with dbgpt.sql, create table gpts_app_collection manually ",
          "created_at": "2025-01-06T16:14:55Z"
        },
        {
          "author": "SKKKKYLAR",
          "body": "### I'm` having the same issue, how should I resolve it? Additionally, are these settings still effective even though they are commented out?\r\n\r\nLOCAL_DB_TYPE=sqlite\r\nThe following are all comments.\r\n\r\n# ## MYSQL database \r\n# LOCAL_DB_TYPE=mysql\r\n# LOCAL_DB_USER=root\r\n# LOCAL_DB_PASSWORD={your_passw",
          "created_at": "2025-01-07T03:20:26Z"
        },
        {
          "author": "JV-X",
          "body": "> ### I'm` having the same issue, how should I resolve it? Additionally, are these settings still effective even though they are commented out?\r\n> LOCAL_DB_TYPE=sqlite The following are all comments.\r\n> \r\n> # ## MYSQL database\r\n> # LOCAL_DB_TYPE=mysql\r\n> # LOCAL_DB_USER=root\r\n> # LOCAL_DB_PASSWORD={",
          "created_at": "2025-01-07T06:49:01Z"
        },
        {
          "author": "Aries-ckt",
          "body": "yeah, `local_db_type=mysql` will require you execute `dbgpt.sql` manually.",
          "created_at": "2025-01-07T15:14:44Z"
        },
        {
          "author": "tuxtorres",
          "body": "用docker部署，遇到了相同的问题，请问如何解决？no such table: gpts_app_collection",
          "created_at": "2025-02-13T08:39:21Z"
        }
      ]
    },
    {
      "issue_number": 2346,
      "title": "[Bug] [Chat Excel] The Chinese form file will be displayed in UTF8 encoding, and the plain text will not be displayed.",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [x] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nnone\n\n### Models information\n\nNone\n\n### What happened\n\n在使用Chat Excel过程中，表格文件中文会以utf8编码显示，不显示明文\n\n### What you expected to happen\n\n应该显示明文\n\n### How to reproduce\n\n在处理json时使用ensure_ascii参数确保中文显示明文\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "HyperForce",
      "author_type": "User",
      "created_at": "2025-02-12T17:37:38Z",
      "updated_at": "2025-02-25T07:17:52Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2346/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2346",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2346",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:49.444713",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "can you give the bad case excel so we can reproduce.",
          "created_at": "2025-02-16T15:04:37Z"
        },
        {
          "author": "HyperForce",
          "body": "> can you give the bad case excel so we can reproduce.\n\n指标,2024,2023,2022,2021,2020,2019,2018,2017,2016,2015,2014,2013,2012,2011,2010,2009,2008,2007,2006,2005\n国民总收入(亿元),,1283680.3,1223706.8,1165816.8,1026751.9,1003108.4,931972.5,846292.7,757492,699224.5,656600,598838.4,546259.7,491160.2,417488.1,353",
          "created_at": "2025-02-25T07:16:38Z"
        },
        {
          "author": "HyperForce",
          "body": "> > can you give the bad case excel so we can reproduce.\n> \n> 指标,2024,2023,2022,2021,2020,2019,2018,2017,2016,2015,2014,2013,2012,2011,2010,2009,2008,2007,2006,2005 国民总收入(亿元),,1283680.3,1223706.8,1165816.8,1026751.9,1003108.4,931972.5,846292.7,757492,699224.5,656600,598838.4,546259.7,491160.2,417488",
          "created_at": "2025-02-25T07:17:51Z"
        }
      ]
    },
    {
      "issue_number": 2347,
      "title": "[Bug] [Chat Excel] When the table column name is purely numeric, the execution of the SQL statement will fail.",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [x] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nnone\n\n### Models information\n\nNone\n\n### What happened\n\n在使用Chat Excel过程中，若表格列名为纯数字时，会导致sql语句执行失败\n\n### What you expected to happen\n\n建议为表格列名加上前缀，以避免纯数字情况\n\n### How to reproduce\n\n建议为表格列名加上前缀，以避免纯数字情况\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "HyperForce",
      "author_type": "User",
      "created_at": "2025-02-12T17:39:39Z",
      "updated_at": "2025-02-25T07:17:41Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2347/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2347",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2347",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:49.631128",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "can you show your excel data?",
          "created_at": "2025-02-16T15:02:06Z"
        },
        {
          "author": "HyperForce",
          "body": "> can you show your excel data?\n\n指标,2024,2023,2022,2021,2020,2019,2018,2017,2016,2015,2014,2013,2012,2011,2010,2009,2008,2007,2006,2005\n国民总收入(亿元),,1283680.3,1223706.8,1165816.8,1026751.9,1003108.4,931972.5,846292.7,757492,699224.5,656600,598838.4,546259.7,491160.2,417488.1,353938.8,326302.7,274791.4",
          "created_at": "2025-02-25T07:16:09Z"
        },
        {
          "author": "HyperForce",
          "body": "> > can you show your excel data?\n> \n> 指标,2024,2023,2022,2021,2020,2019,2018,2017,2016,2015,2014,2013,2012,2011,2010,2009,2008,2007,2006,2005 国民总收入(亿元),,1283680.3,1223706.8,1165816.8,1026751.9,1003108.4,931972.5,846292.7,757492,699224.5,656600,598838.4,546259.7,491160.2,417488.1,353938.8,326302.7,27",
          "created_at": "2025-02-25T07:17:39Z"
        }
      ]
    },
    {
      "issue_number": 2153,
      "title": "[Bug] [Module Name] Bug title 0.6.2 can not open libro web interface",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [X] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [X] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nv100\n\n### Models information\n\nqwen2.5\n\n### What happened\n\n0.6.2版本新libro界面无法打开，安装了all_in_one_entrance，点进去前端无法显示，\r\n![image](https://github.com/user-attachments/assets/72a7a874-f6c3-474b-aea2-e6f7c246d508)\r\n![image](https://github.com/user-attachments/assets/2031072b-6599-4b69-ae6f-abaf113aae4e)\r\n![image](https://github.com/user-attachments/assets/92c03551-b04f-48b5-be4e-ebd231bfed75)\r\n\n\n### What you expected to happen\n\n如何操作可以打开notebook界面？\n\n### How to reproduce\n\n直接安装点击\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "adogwangwang",
      "author_type": "User",
      "created_at": "2024-11-25T07:12:45Z",
      "updated_at": "2025-02-24T09:48:50Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2153/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2153",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2153",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:49.819742",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "it's weird, try a new conda environment?",
          "created_at": "2024-11-25T15:48:20Z"
        },
        {
          "author": "Eason-Shen",
          "body": "请问这个问题解决了吗？我遇到了一样的问题",
          "created_at": "2025-02-24T09:48:47Z"
        }
      ]
    },
    {
      "issue_number": 2366,
      "title": "[Bug] [Module Name] Bug title Elasticsearch connection address error",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\n<v0.3.7\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [x] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU count 1\n\n### Models information\n\nLLM: Qwen2.5-1.5B-Instruct\nEmbedding model: text2vec-large-chinese\n\n### What happened\n\nElasticsearch connection address error\nThe es address has been modified, but the error message is still localhost。\nAfter reading the source code, the address written as' es' in the source code is 127.0.0.1\n\n![Image](https://github.com/user-attachments/assets/5b1c6cda-afce-4b6c-8928-a8040086c7a5)\n\n![Image](https://github.com/user-attachments/assets/a0271d22-e2cb-4abc-8f37-a392bf3da82b)\n\n### What you expected to happen\n\nes connect success\n\n\n\n### How to reproduce\n\nDocker image startup, creating a full-text knowledge base, uploading files and slicing them\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "zhanxin01",
      "author_type": "User",
      "created_at": "2025-02-24T08:40:40Z",
      "updated_at": "2025-02-24T08:40:40Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2366/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2366",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2366",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:50.017475",
      "comments": []
    },
    {
      "issue_number": 2364,
      "title": "[Feature][DATE CONNECTION] Kerberos authentication requirements",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nWe need kerberos authentication for using Hive and Spark locally. Will we consider adding code related to kerberos authentication in future versions？\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "clickyouxu",
      "author_type": "User",
      "created_at": "2025-02-24T07:09:05Z",
      "updated_at": "2025-02-24T07:30:14Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2364/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2364",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2364",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:50.017496",
      "comments": []
    },
    {
      "issue_number": 2184,
      "title": "[Bug] [Module Name] (sqlite3.OperationalError) no such table: gpts_app ",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [X] Chat Data\n- [X] Chat Excel\n- [X] Chat DB\n- [X] Chat Knowledge\n- [X] Model Management\n- [X] Dashboard\n- [X] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU:24G\n\n### Models information\n\nLLM_MODEL=Qwen2.5-7B-Instruct\r\nEMBEDDING_MODEL=text2vec\n\n### What happened\n\nwhen start the services： python dbgpt/app/dbgpt_server.py，and the errors is :\r\n\r\n2024-12-08 13:07:22 autodl-container-14944f8a6a-6239cd36 dbgpt.serve.agent.db.gpts_app[114373] ERROR create chat_knowledge_app error: (sqlite3.OperationalError) no such table: gpts_app\r\n[SQL: DELETE FROM gpts_app WHERE gpts_app.team_mode = ? AND gpts_app.app_code = ?]\r\n[parameters: ('native_app', 'chat_knowledge')]\r\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\r\nTraceback (most recent call last):\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1970, in _exec_single_context\r\n    self.dialect.do_execute(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py\", line 924, in do_execute\r\n    cursor.execute(statement, parameters)\r\nsqlite3.OperationalError: no such table: gpts_app\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/root/autodl-tmp/DB-GPT/dbgpt/serve/agent/db/gpts_app.py\", line 1121, in init_native_apps\r\n    gpts_dao.remove_native_app(chat_knowledge_app.app_code)\r\n  File \"/root/autodl-tmp/DB-GPT/dbgpt/serve/agent/db/gpts_app.py\", line 834, in remove_native_app\r\n    app_qry.delete()\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py\", line 3161, in delete\r\n    result: CursorResult[Any] = self.session.execute(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py\", line 2306, in execute\r\n    return self._execute_internal(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py\", line 2191, in _execute_internal\r\n    result: Result[Any] = compile_state_cls.orm_execute_statement(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/orm/bulk_persistence.py\", line 1946, in orm_execute_statement\r\n    return super().orm_execute_statement(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/orm/context.py\", line 293, in orm_execute_statement\r\n    result = conn.execute(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1421, in execute\r\n    return meth(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py\", line 514, in _execute_on_connection\r\n    return connection._execute_clauseelement(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1643, in _execute_clauseelement\r\n    ret = self._execute_context(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1849, in _execute_context\r\n    return self._exec_single_context(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1989, in _exec_single_context\r\n    self._handle_dbapi_exception(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 2356, in _handle_dbapi_exception\r\n    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1970, in _exec_single_context\r\n    self.dialect.do_execute(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py\", line 924, in do_execute\r\n    cursor.execute(statement, parameters)\r\nsqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: gpts_app\r\n[SQL: DELETE FROM gpts_app WHERE gpts_app.team_mode = ? AND gpts_app.app_code = ?]\r\n[parameters: ('native_app', 'chat_knowledge')]\r\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\r\n2024-12-08 13:07:22 autodl-container-14944f8a6a-6239cd36 dbgpt.serve.agent.db.gpts_app[114373] ERROR create chat_normal_app error: (sqlite3.OperationalError) no such table: gpts_app\r\n[SQL: DELETE FROM gpts_app WHERE gpts_app.team_mode = ? AND gpts_app.app_code = ?]\r\n[parameters: ('native_app', 'chat_normal')]\r\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\r\nTraceback (most recent call last):\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1970, in _exec_single_context\r\n    self.dialect.do_execute(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py\", line 924, in do_execute\r\n    cursor.execute(statement, parameters)\r\nsqlite3.OperationalError: no such table: gpts_app\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/root/autodl-tmp/DB-GPT/dbgpt/serve/agent/db/gpts_app.py\", line 1142, in init_native_apps\r\n    gpts_dao.remove_native_app(chat_normal_app.app_code)\r\n  File \"/root/autodl-tmp/DB-GPT/dbgpt/serve/agent/db/gpts_app.py\", line 834, in remove_native_app\r\n    app_qry.delete()\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py\", line 3161, in delete\r\n    result: CursorResult[Any] = self.session.execute(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py\", line 2306, in execute\r\n    return self._execute_internal(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py\", line 2191, in _execute_internal\r\n    result: Result[Any] = compile_state_cls.orm_execute_statement(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/orm/bulk_persistence.py\", line 1946, in orm_execute_statement\r\n    return super().orm_execute_statement(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/orm/context.py\", line 293, in orm_execute_statement\r\n    result = conn.execute(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1421, in execute\r\n    return meth(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py\", line 514, in _execute_on_connection\r\n    return connection._execute_clauseelement(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1643, in _execute_clauseelement\r\n    ret = self._execute_context(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1849, in _execute_context\r\n    return self._exec_single_context(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1989, in _exec_single_context\r\n    self._handle_dbapi_exception(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 2356, in _handle_dbapi_exception\r\n    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1970, in _exec_single_context\r\n    self.dialect.do_execute(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py\", line 924, in do_execute\r\n    cursor.execute(statement, parameters)\r\nsqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: gpts_app\r\n[SQL: DELETE FROM gpts_app WHERE gpts_app.team_mode = ? AND gpts_app.app_code = ?]\r\n[parameters: ('native_app', 'chat_normal')]\r\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\r\n2024-12-08 13:07:22 autodl-container-14944f8a6a-6239cd36 dbgpt.serve.agent.db.gpts_app[114373] ERROR create chat_with_db_qa_app error: (sqlite3.OperationalError) no such table: gpts_app\r\n[SQL: DELETE FROM gpts_app WHERE gpts_app.team_mode = ? AND gpts_app.app_code = ?]\r\n[parameters: ('native_app', 'chat_with_db_qa')]\r\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\r\nTraceback (most recent call last):\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1970, in _exec_single_context\r\n    self.dialect.do_execute(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py\", line 924, in do_execute\r\n    cursor.execute(statement, parameters)\r\nsqlite3.OperationalError: no such table: gpts_app\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/root/autodl-tmp/DB-GPT/dbgpt/serve/agent/db/gpts_app.py\", line 1164, in init_native_apps\r\n    gpts_dao.remove_native_app(chat_with_db_qa_app.app_code)\r\n  File \"/root/autodl-tmp/DB-GPT/dbgpt/serve/agent/db/gpts_app.py\", line 834, in remove_native_app\r\n    app_qry.delete()\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py\", line 3161, in delete\r\n    result: CursorResult[Any] = self.session.execute(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py\", line 2306, in execute\r\n    return self._execute_internal(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py\", line 2191, in _execute_internal\r\n    result: Result[Any] = compile_state_cls.orm_execute_statement(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/orm/bulk_persistence.py\", line 1946, in orm_execute_statement\r\n    return super().orm_execute_statement(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/orm/context.py\", line 293, in orm_execute_statement\r\n    result = conn.execute(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1421, in execute\r\n    return meth(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py\", line 514, in _execute_on_connection\r\n    return connection._execute_clauseelement(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1643, in _execute_clauseelement\r\n    ret = self._execute_context(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1849, in _execute_context\r\n    return self._exec_single_context(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1989, in _exec_single_context\r\n    self._handle_dbapi_exception(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 2356, in _handle_dbapi_exception\r\n    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1970, in _exec_single_context\r\n    self.dialect.do_execute(\r\n  File \"/root/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py\", line 924, in do_execute\r\n    cursor.execute(statement, parameters)\r\nsqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: gpts_app\r\n[SQL: DELETE FROM gpts_app WHERE gpts_app.team_mode = ? AND gpts_app.app_code = ?]\r\n[parameters: ('native_app', 'chat_with_db_qa')]\r\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\r\n\r\n\n\n### What you expected to happen\n\nthe services can started\n\n### How to reproduce\n\nstart the services:python dbgpt/app/dbgpt_server.py\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "chenyb868",
      "author_type": "User",
      "created_at": "2024-12-08T05:16:56Z",
      "updated_at": "2025-02-24T07:24:18Z",
      "closed_at": "2025-01-09T07:36:25Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 18,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2184/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2184",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2184",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:50.017502",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "\r\nHow did you deploy start dbgpt server? docker or source code?\r\n",
          "created_at": "2024-12-08T16:07:02Z"
        },
        {
          "author": "chenyb868",
          "body": "> How did you deploy start dbgpt server? docker or source code?\r\n\r\nby source code",
          "created_at": "2024-12-08T16:18:31Z"
        },
        {
          "author": "Aries-ckt",
          "body": "If you in a hurry you can check your database schema with dbgpt.sql\r\n",
          "created_at": "2024-12-08T16:23:44Z"
        },
        {
          "author": "chenyb868",
          "body": "> If you in a hurry you can check your database schema with dbgpt.sql\r\n\r\nhow to check the database schema with dbgpt.sql? run the dbgpt.sql?and how to run the dbgpt.sql?",
          "created_at": "2024-12-08T16:26:32Z"
        },
        {
          "author": "Aries-ckt",
          "body": "Connect your database through SQLite command, we storage SQLite dbgpt database file  in DB-GPT/pilot/metadata",
          "created_at": "2024-12-08T16:31:01Z"
        }
      ]
    },
    {
      "issue_number": 2363,
      "title": "[Feature][chat]  Can support for multi-turn conversations be added?",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nIt is hoped that a \"multi-turn conversation\" switch option can be added to the dialogue, and the corresponding API should also include a \"multi-turn conversation\" field.\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "bxfxf",
      "author_type": "User",
      "created_at": "2025-02-24T03:08:32Z",
      "updated_at": "2025-02-24T03:08:32Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2363/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2363",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2363",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:50.205271",
      "comments": []
    },
    {
      "issue_number": 2351,
      "title": "[Bug] [agent] 多智能体应用无法正常返回",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU Count:1\nGPU Memory:48G\n\n### Models information\n\nLLM: Qwen2.5-32B-Int4\nEmbedding: Bge-m3\n\n### What happened\n\n多智能体无法正常返回结果，后台错误附图：\n\n![Image](https://github.com/user-attachments/assets/c3ca860e-865a-425e-8487-ebc604b75188)\n\n### What you expected to happen\n\n![Image](https://github.com/user-attachments/assets/b1973c45-2475-45d2-897b-5911d497e7b3)\n\n### How to reproduce\n\n1.创建2个知识库，一个company，一个expert\n\n![Image](https://github.com/user-attachments/assets/b620c6cf-abc0-492a-a859-28791b6dcb73)\n\n![Image](https://github.com/user-attachments/assets/7d21e2c8-0693-4db0-8f02-797c08bd8264)\n2.创建2个single agent，分别绑定知识库\n\n![Image](https://github.com/user-attachments/assets/50b84fad-7d81-401b-ac06-ab73e01f84a8)\n\n![Image](https://github.com/user-attachments/assets/e8048994-eb56-4326-a8d5-4ccb41698605)\n3.创建父agent，绑定前2个子agent作为资源\n\n![Image](https://github.com/user-attachments/assets/db4c0e8f-d690-4b8d-b8cd-ad7596347e16)\n4.测试对话\n\n![Image](https://github.com/user-attachments/assets/72f5eb75-f3a4-4405-8b53-b4c3a7bbf098)\n\n### Additional context\n\n从plan分析，逻辑没问题，但最后没有返回\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "sliontc",
      "author_type": "User",
      "created_at": "2025-02-15T03:06:54Z",
      "updated_at": "2025-02-24T01:25:53Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2351/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2351",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2351",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:50.205312",
      "comments": [
        {
          "author": "sliontc",
          "body": "这是部分真实数据\n\n![Image](https://github.com/user-attachments/assets/a9a1db19-8f92-4c46-803c-616b65ffbd89)",
          "created_at": "2025-02-16T04:17:23Z"
        },
        {
          "author": "Aries-ckt",
          "body": "we need excel format, not image.",
          "created_at": "2025-02-16T15:05:48Z"
        },
        {
          "author": "sliontc",
          "body": "> we need excel format, not image.\n\n[expert.xlsx](https://github.com/user-attachments/files/18845045/expert.xlsx)",
          "created_at": "2025-02-18T12:21:34Z"
        },
        {
          "author": "cinjoseph",
          "body": "yes there is a bug on app starter。I will fix this bug on 0.7.0",
          "created_at": "2025-02-24T01:25:38Z"
        }
      ]
    },
    {
      "issue_number": 2099,
      "title": "[Feature][helm-chart] Create helm chart",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nif nobody is working on it already, i can build one\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "ayushin",
      "author_type": "User",
      "created_at": "2024-10-26T00:13:13Z",
      "updated_at": "2025-02-23T21:04:49Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2099/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2099",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2099",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:50.413219",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-02-23T21:04:47Z"
        }
      ]
    },
    {
      "issue_number": 2360,
      "title": "[Bug] [Module Name] Bug title",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [x] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nMacbook  M2  \n浏览器  谷歌  safari和火狐都是这样的 \n\n### Models information\n\n调用的代理模型硅机流动\n\n### What happened\n\n![Image](https://github.com/user-attachments/assets/c9463815-1cdb-4a23-8cc0-ee84e2360e04) 01右侧文档按钮挡住了loading的状态按钮 02- 当返回的表格多了一个文本框没了没办法再次输入\n\n### What you expected to happen\n\n修复\n\n### How to reproduce\n\n返回表格多的情况下\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "braveryhui",
      "author_type": "User",
      "created_at": "2025-02-23T08:54:03Z",
      "updated_at": "2025-02-23T08:54:03Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2360/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2360",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2360",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:50.636586",
      "comments": []
    },
    {
      "issue_number": 1058,
      "title": "[FAQ][install]:  Install  autoawq timeout",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU：nvidia A10，linux：Ubuntu 20.04.6 LTS\n\n### Models information\n\nvicuna-7b-1.5\n\n### What happened\n\n安装环境时出错\n\n### What you expected to happen\n\n(base) root@localhost:/llm/DB-GPT# pip install -e \".[default]\"\r\nLooking in indexes: https://pypi.douban.com/simple/\r\nObtaining file:///llm/DB-GPT\r\n  Preparing metadata (setup.py) ... done\r\nCollecting autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.1.7/autoawq-0.1.7+cu118-cp39-cp39-linux_x86_64.whl\r\n  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /casper-hansen/AutoAWQ/releases/download/v0.1.7/autoawq-0.1.7+cu118-cp39-cp39-linux_x86_64.whl\r\n  WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f38192685b0>, 'Connection to github.com timed out. (connect timeout=15)')': /casper-hansen/AutoAWQ/releases/download/v0.1.7/autoawq-0.1.7+cu118-cp39-cp39-linux_x86_64.whl\r\n  WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f3819268760>, 'Connection to github.com timed out. (connect timeout=15)')': /casper-hansen/AutoAWQ/releases/download/v0.1.7/autoawq-0.1.7+cu118-cp39-cp39-linux_x86_64.whl\r\n  WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /casper-hansen/AutoAWQ/releases/download/v0.1.7/autoawq-0.1.7+cu118-cp39-cp39-linux_x86_64.whl\r\n  WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f3819268ac0>, 'Connection to github.com timed out. (connect timeout=15)')': /casper-hansen/AutoAWQ/releases/download/v0.1.7/autoawq-0.1.7+cu118-cp39-cp39-linux_x86_64.whl\r\nERROR: Could not install packages due to an OSError: HTTPSConnectionPool(host='github.com', port=443): Max retries exceeded with url: /casper-hansen/AutoAWQ/releases/download/v0.1.7/autoawq-0.1.7+cu118-cp39-cp39-linux_x86_64.whl (Caused by ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f3819268bb0>, 'Connection to github.com timed out. (connect timeout=15)'))\r\n\r\n\n\n### How to reproduce\n\nnull\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "GLY-123",
      "author_type": "User",
      "created_at": "2024-01-10T03:14:44Z",
      "updated_at": "2025-02-23T01:59:00Z",
      "closed_at": "2024-01-31T08:24:40Z",
      "labels": [
        "FAQ:Install"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1058/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1058",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1058",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:50.636605",
      "comments": [
        {
          "author": "fangyinc",
          "body": "You can install DB-GPT without quantization with commands :\r\n```bash\r\npip install -e \".[framework]\"\r\npip install -e \".[knowledge]\"\r\npip install -e \".[torch]\"\r\npip install -e \".[cache]\"\r\n```\r\ninstead of the original  `pip install -e \".[default]\"`",
          "created_at": "2024-01-10T04:35:21Z"
        },
        {
          "author": "gqchen-dz",
          "body": "another way:\r\nvim ~./DB-GPT/set.py\r\nthen find :\r\n------------------------------------------------------------------------------------------------------------------------\r\nautoawq_url = _build_wheels(\r\n            \"autoawq\",\r\n            \"0.1.7\",\r\n            base_url_func=lambda v, x, y: f\"https://h",
          "created_at": "2024-01-11T06:50:23Z"
        },
        {
          "author": "GLY-123",
          "body": "> You can install DB-GPT without quantization with commands :\r\n> \r\n> ```shell\r\n> pip install -e \".[framework]\"\r\n> pip install -e \".[knowledge]\"\r\n> pip install -e \".[torch]\"\r\n> pip install -e \".[cache]\"\r\n> ```\r\n> \r\n> instead of the original `pip install -e \".[default]\"`\r\n\r\n运行pip install -e \".[torch]\"",
          "created_at": "2024-01-31T08:26:21Z"
        },
        {
          "author": "wansongying",
          "body": "> ## another way:\r\n> vim ~./DB-GPT/set.py\r\n> then find :\r\n> ## autoawq_url = _build_wheels(\r\n> \"autoawq\",\r\n> \"0.1.7\",\r\n> base_url_func=lambda v, x, y: f\"[https://hub.nuaa.cf/casper-hansen/AutoAWQ/releases/download/v{v}](https://hub.nuaa.cf/casper-hansen/AutoAWQ/releases/download/v%7Bv%7D)\",\r\n> suppo",
          "created_at": "2024-03-07T07:45:06Z"
        },
        {
          "author": "Robert-Lau",
          "body": "> > You can install DB-GPT without quantization with commands :\r\n> > ```shell\r\n> > pip install -e \".[framework]\"\r\n> > pip install -e \".[knowledge]\"\r\n> > pip install -e \".[torch]\"\r\n> > pip install -e \".[cache]\"\r\n> > ```\r\n> > \r\n> > \r\n> >     \r\n> >       \r\n> >     \r\n> > \r\n> >       \r\n> >     \r\n> > \r\n> ",
          "created_at": "2024-03-25T09:14:55Z"
        }
      ]
    },
    {
      "issue_number": 2080,
      "title": "[Bug] [Module Name] click \"Start Conversation\" on the knowledge base, and the select_param parameter is missing, causing an exception.",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [X] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nubuntu 20.04  chrome\r\n硬件信息不涉及\n\n### Models information\n\n不涉及\n\n### What happened\n\n## STEP1\r\n我已经创建了一个 GraphRAG 的知识库\r\n\r\n![image](https://github.com/user-attachments/assets/17f58374-4273-42bd-b5e4-381bf01be3c0)\r\n\r\n## STEP2\r\n点击开始对话，前端传递的 select_param 为空\r\n\r\n![image](https://github.com/user-attachments/assets/4a7eef65-905b-472d-9e2c-887f7f7790f3)\r\n\r\n## STEP3\r\n这个空导致 chat 找不到知识库， 这里取不到 ： `dialogue.select_param`\r\n![image](https://github.com/user-attachments/assets/19272458-b935-4b1d-b87f-de19afc6bbc4)\r\n\r\n## 当前\r\n看起来只能临时 hack 一把继续跑下去先\r\n\n\n### What you expected to happen\n\n功能正常 chat\n\n### How to reproduce\n\n遵循教程执行即可\n\n### Additional context\n\n我对前端不熟，无法帮你们修\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "tpoisonooo",
      "author_type": "User",
      "created_at": "2024-10-18T07:07:44Z",
      "updated_at": "2025-02-22T21:05:20Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2080/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2080",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2080",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:50.861343",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-02-22T21:05:19Z"
        }
      ]
    },
    {
      "issue_number": 2088,
      "title": "[Feature][ChatData]The ability to interactively specify one or more tables for a query before a data session",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n数据对话当中目前没办法通过前端页面交互的形式去选择对应的数据表或者数据集，这样导致如果同一个库当中存在多个表名较为类似的表时，就需要在对话时指定查询的表名以及关联关系，对开发来说还行，但是业务感觉基本没法用，是否考虑增加这块儿\n\n### Use case\n\n数据对话当中目前没办法通过前端页面交互的形式去选择对应的数据表或者数据集，这样导致如果同一个库当中存在多个表名较为类似的表时，就需要在对话时指定查询的表名以及关联关系，对开发来说还行，但是业务感觉基本没法用，是否考虑增加这块儿\n\n### Related issues\n\n无\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "517739",
      "author_type": "User",
      "created_at": "2024-10-22T12:35:17Z",
      "updated_at": "2025-02-22T21:05:19Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2088/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2088",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2088",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:51.075943",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-02-22T21:05:18Z"
        }
      ]
    },
    {
      "issue_number": 2089,
      "title": "[Feature][ChatData] According to the generated SQL statement, visual operations can be realized without filtering the statements, especially the part after where, and can be run",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n根据生成的SQL语句可以实现可视化的操作不分筛选的语句，特别是where后面的部分，并且可以运行，如下图这样\r\n![CKUWR%5D )GQ3UDT4LG}YKQ](https://github.com/user-attachments/assets/a084cf8e-729a-4ce0-b823-1bf0a1881be1)\r\n\n\n### Use case\n\n根据生成的SQL语句可以实现可视化的操作不分筛选的语句，特别是where后面的部分，并且可以运行，\n\n### Related issues\n\n无\n\n### Feature Priority\n\nHigh\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "517739",
      "author_type": "User",
      "created_at": "2024-10-22T12:47:14Z",
      "updated_at": "2025-02-22T21:05:18Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2089/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2089",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2089",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:51.265590",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-02-22T21:05:17Z"
        }
      ]
    },
    {
      "issue_number": 2090,
      "title": "[Bug] [Module Name] Bug title Error when uploading files to the graph knowledge base",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [X] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [X] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\ngpu v100\n\n### Models information\n\nqwen2.5 72b \r\nbge m3\r\nbge reranker\n\n### What happened\n\n我使用的是dbgpt 0.5.10版本, 当我上传文件到图知识库时发生报错{code: CypherException} {message: CypherException: visit(...) failed at src/cypher/arithmetic/ast_expr_evaluator.cpp:480}  ，通过debug发现问题出现在app\\dbgpt\\storage\\graph_store\\factory.py文件中的return store_cls(config) 这一句，不知道是什么原因，请大佬们帮忙解答！ 试过txt和md格式文档，都会报错\r\n![image](https://github.com/user-attachments/assets/866999e9-e922-4722-974b-2fa530263aae)\r\n\n\n### What you expected to happen\n\n希望老师们能够帮我找到原因，并解决，然后想问图知识库支持的是什么格式的文件来上传？\n\n### How to reproduce\n\n1. 构建图知识库\r\n2. 上传txt或md文件\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "adogwangwang",
      "author_type": "User",
      "created_at": "2024-10-23T02:58:18Z",
      "updated_at": "2025-02-22T21:05:17Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2090/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2090",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2090",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:51.517914",
      "comments": [
        {
          "author": "adogwangwang",
          "body": "document sync batch error {code: CypherException} {message: CypherException: visit(...) failed at src/cypher/arithmetic/ast_expr_evaluator.cpp:480}  完整报错是这样",
          "created_at": "2024-10-23T03:30:50Z"
        },
        {
          "author": "Aries-ckt",
          "body": "> document sync batch error {code: CypherException} {message: CypherException: visit(...) failed at src/cypher/arithmetic/ast_expr_evaluator.cpp:480} 完整报错是这样\r\n\r\nhi,\r\ncould you show your `.env` Graph setting or try DB-GPT `v0.6.1`",
          "created_at": "2024-10-24T02:02:52Z"
        },
        {
          "author": "Appointat",
          "body": "@adogwangwang Hi, it seems like you have the same issue with https://github.com/eosphoros-ai/DB-GPT/pull/2079#event-14756354567. \r\nThe good news it, we fixed it in v0.6.1. Therefore, please update db-gpt, and then update your env according to the .env.template, thank you.",
          "created_at": "2024-10-24T02:06:22Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-02-22T21:05:16Z"
        }
      ]
    },
    {
      "issue_number": 2092,
      "title": "【bug】excel_reader.py Functions in the middle can cause some unexpected results or performance issues.",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [X] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nexcel_reader.py中is_chinese函数  会导致一些非预期的结果或者性能问题\r\n \r\n\n\n### Models information\n\nexcel_reader.py中is_chinese函数 问题见附件\r\n<img width=\"875\" alt=\"lQLPKH7upOxgsG_NAZnNBtawKDCHR9EY8pgG_58nLAgGAA_1750_409\" src=\"https://github.com/user-attachments/assets/92c9f3a8-e5d2-4a43-89c5-4d6726fdd08a\">\r\n\r\n修改建议：\r\n1、如果只是想快速检查 BMP 中的常用汉字，并且接受可能的限制， 可以稍作修改以提高效率（避免在找到第一个汉字后仍然遍历整个字符串）\r\n2、之前代码存在一个潜在问题，这种字符比较方式可能不太符合 Unicode 编码的标准判断方式，而且\"鿿\"这个字符在 Unicode 编码中的位置比较靠后，可能会导致一些非预期的结果或者性能问题\r\n\n\n### What happened\n\nexcel_reader.py中is_chinese函数 问题见附件\r\n<img width=\"875\" alt=\"lQLPKH7upOxgsG_NAZnNBtawKDCHR9EY8pgG_58nLAgGAA_1750_409\" src=\"https://github.com/user-attachments/assets/92c9f3a8-e5d2-4a43-89c5-4d6726fdd08a\">\r\n\r\n修改建议：\r\n1、如果只是想快速检查 BMP 中的常用汉字，并且接受可能的限制， 可以稍作修改以提高效率（避免在找到第一个汉字后仍然遍历整个字符串）\r\n2、之前代码存在一个潜在问题，这种字符比较方式可能不太符合 Unicode 编码的标准判断方式，而且\"鿿\"这个字符在 Unicode 编码中的位置比较靠后，可能会导致一些非预期的结果或者性能问题\r\n\n\n### What you expected to happen\n\nexcel_reader.py中is_chinese函数 问题见附件\r\n<img width=\"875\" alt=\"lQLPKH7upOxgsG_NAZnNBtawKDCHR9EY8pgG_58nLAgGAA_1750_409\" src=\"https://github.com/user-attachments/assets/92c9f3a8-e5d2-4a43-89c5-4d6726fdd08a\">\r\n\r\n修改建议：\r\n1、如果只是想快速检查 BMP 中的常用汉字，并且接受可能的限制， 可以稍作修改以提高效率（避免在找到第一个汉字后仍然遍历整个字符串）\r\n2、之前代码存在一个潜在问题，这种字符比较方式可能不太符合 Unicode 编码的标准判断方式，而且\"鿿\"这个字符在 Unicode 编码中的位置比较靠后，可能会导致一些非预期的结果或者性能问题\r\n\n\n### How to reproduce\n\nexcel_reader.py中is_chinese函数  会导致一些非预期的结果或者性能问题\n\n### Additional context\n\nexcel_reader.py中is_chinese函数 问题见附件\r\n<img width=\"875\" alt=\"lQLPKH7upOxgsG_NAZnNBtawKDCHR9EY8pgG_58nLAgGAA_1750_409\" src=\"https://github.com/user-attachments/assets/92c9f3a8-e5d2-4a43-89c5-4d6726fdd08a\">\r\n\r\n修改建议：\r\n1、如果只是想快速检查 BMP 中的常用汉字，并且接受可能的限制， 可以稍作修改以提高效率（避免在找到第一个汉字后仍然遍历整个字符串）\r\n2、之前代码存在一个潜在问题，这种字符比较方式可能不太符合 Unicode 编码的标准判断方式，而且\"鿿\"这个字符在 Unicode 编码中的位置比较靠后，可能会导致一些非预期的结果或者性能问题\r\n\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "fengdezhen666",
      "author_type": "User",
      "created_at": "2024-10-23T07:20:39Z",
      "updated_at": "2025-02-22T21:05:16Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2092/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2092",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2092",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:51.756519",
      "comments": [
        {
          "author": "fengdezhen666",
          "body": "【PR】\r\nhttps://github.com/fdzgithub/DB-GPT/blob/main/dbgpt/app/scene/chat_data/chat_excel/excel_reader.py",
          "created_at": "2024-10-23T07:30:23Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-02-22T21:05:14Z"
        }
      ]
    },
    {
      "issue_number": 2094,
      "title": "[Bug][GraphRAG]Generate  Graph, the result is not normal",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n![image](https://github.com/user-attachments/assets/8ece84e7-35f1-4271-a5d0-b05129fc1b6b)\r\n\r\n上传了一个pdf 生成知识图谱是这样的\n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "harrisHxy",
      "author_type": "User",
      "created_at": "2024-10-23T10:27:30Z",
      "updated_at": "2025-02-21T21:04:47Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2094/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2094",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2094",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:51.963430",
      "comments": [
        {
          "author": "Appointat",
          "body": "Can you retry it? and what version of dbgpt you are using?",
          "created_at": "2024-10-24T10:15:27Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-02-21T21:04:46Z"
        }
      ]
    },
    {
      "issue_number": 1037,
      "title": " ERROR model response parase faild！Can't new LLMCacheValueData object, output is None",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n配置质谱ai的proxy，\r\n保证只是代理是可以运行的，但是在咱们这个环境中，就一直失败；\r\n\r\n ERROR model response parase faild！Can't new LLMCacheValueData object, output is None\r\n\n\n### Documentation Links\n\n配置质谱ai的proxy，\r\n保证只是代理是可以运行的，但是在咱们这个环境中，就一直失败；\r\n\r\n ERROR model response parase faild！Can't new LLMCacheValueData object, output is None\r\n\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "wentixiaogege",
      "author_type": "User",
      "created_at": "2024-01-05T10:11:38Z",
      "updated_at": "2025-02-20T08:38:05Z",
      "closed_at": "2024-02-16T21:04:26Z",
      "labels": [
        "documentation",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1037/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1037",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1037",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:52.131450",
      "comments": [
        {
          "author": "wentixiaogege",
          "body": "使用调用zhipu.py 单独执行是可以跑出数据的；\r\n![image](https://github.com/eosphoros-ai/DB-GPT/assets/8437905/5b840b60-20fa-46b3-8c1b-b0c1b96ee1bf)\r\n",
          "created_at": "2024-01-05T10:13:16Z"
        },
        {
          "author": "wentixiaogege",
          "body": "model generate_stream params:\r\n{'model': 'zhipu_proxyllm', 'prompt': 'You are a data analysis expert. ###system:\\nThe following is part of the data of the user file mart_coo_adm_128766\r\n456.xlsx. Please learn to understand the structure and content of the data and output the parsing results as requi",
          "created_at": "2024-01-09T08:24:49Z"
        },
        {
          "author": "wentixiaogege",
          "body": "上面是全部的日志，zhipuai配置应该是没错的。",
          "created_at": "2024-01-09T08:25:24Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-02-08T21:04:43Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue bas been closed, because it has been marked as `stale` and there has been no activity for over 7 days.",
          "created_at": "2024-02-16T21:04:25Z"
        }
      ]
    },
    {
      "issue_number": 2262,
      "title": "[Bug] [ModelCache] Win11 Pycharm start dbgpt_server error.",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [X] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [X] Other\n\n### Device information\n\nCPU Avx2\n\n### Models information\n\ntongyi qwen-max\n\n### What happened\n\npycharm run或者debug，执行到_initialize_model_cache(system_app, param.port)，触发windows 内存访问异常，终止执行。\r\n在terminal中使用python命令执行则正常。\n\n### What you expected to happen\n\nmodel_cache导致内存访问异常，是否是pycharm跟这段代码有冲突\n\n### How to reproduce\n\n在pycharm 2024.2.5或者2024.2.3中执行dbgpt_server.py就会触发该问题\n\n### Additional context\n\n按照官方手册里安装miniconda环境\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "ffly1985",
      "author_type": "User",
      "created_at": "2024-12-31T08:08:35Z",
      "updated_at": "2025-02-19T12:32:53Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2262/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2262",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2262",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:52.349410",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "can you give the error log? and show your embedding model and llm model.",
          "created_at": "2025-01-01T15:01:29Z"
        },
        {
          "author": "luxiang0412",
          "body": "好像在`.env`添加`MODEL_CACHE_STORAGE_TYPE=memory`就可以了。",
          "created_at": "2025-02-19T12:32:51Z"
        }
      ]
    },
    {
      "issue_number": 2112,
      "title": "[Bug] [ <class 'dbgpt.agent.core.plan.awel.agent_operator.AWELAgentOperator'] Client chat flow error, AttributeError: 'CommonLLMHttpRequestBody' object has no attribute 'already_failed'",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [X] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nWINDOWS11,DOCKER-COMPOSE都出现这个问题\n\n### Models information\n\n/\n\n### What happened\n\ndb-gpt-webserver-1  | 2024-11-01 02:44:38 140ce76a8a9e dbgpt.core.awel.runner.local_runner[1] INFO Run operator <class 'dbgpt.agent.core.plan.awel.agent_operator.AWELAgentOperator'>(e2726bca-7c47-4588-beea-63e7f8f105e0) error, error message: Traceback (most recent call last):\r\ndb-gpt-webserver-1  |   File \"/app/dbgpt/core/awel/runner/local_runner.py\", line 192, in _execute_node\r\ndb-gpt-webserver-1  |     await node._run(dag_ctx, task_ctx.log_id)\r\ndb-gpt-webserver-1  |   File \"/app/dbgpt/core/awel/operators/base.py\", line 248, in _run\r\ndb-gpt-webserver-1  |     return await self._do_run(dag_ctx)\r\ndb-gpt-webserver-1  |   File \"/app/dbgpt/core/awel/operators/common_operator.py\", line 190, in _do_run\r\ndb-gpt-webserver-1  |     input_ctx: InputContext = await curr_task_ctx.task_input.map(map_function)\r\ndb-gpt-webserver-1  |   File \"/app/dbgpt/core/awel/task/task_impl.py\", line 538, in map\r\ndb-gpt-webserver-1  |     new_outputs, results = await self._apply_func(map_func)\r\ndb-gpt-webserver-1  |   File \"/app/dbgpt/core/awel/task/task_impl.py\", line 533, in _apply_func\r\ndb-gpt-webserver-1  |     results = await asyncio.gather(*map_tasks)\r\ndb-gpt-webserver-1  |   File \"/app/dbgpt/core/awel/task/task_impl.py\", line 126, in map\r\ndb-gpt-webserver-1  |     out = await self._apply_func(map_func)\r\ndb-gpt-webserver-1  |   File \"/app/dbgpt/core/awel/task/task_impl.py\", line 112, in _apply_func\r\ndb-gpt-webserver-1  |     out = await func(self._data)\r\ndb-gpt-webserver-1  |   File \"/app/dbgpt/agent/core/plan/awel/agent_operator.py\", line 178, in map\r\ndb-gpt-webserver-1  |     if input_value.already_failed:\r\ndb-gpt-webserver-1  |   File \"/usr/local/lib/python3.10/dist-packages/pydantic/main.py\", line 853, in __getattr__\r\ndb-gpt-webserver-1  |     raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')\r\ndb-gpt-webserver-1  | AttributeError: 'CommonLLMHttpRequestBody' object has no attribute 'already_failed'\n\n### What you expected to happen\n\n/\n\n### How to reproduce\n\n请求代码如下\r\nfrom dbgpt.client import Client\r\nfrom dbgpt.client.flow import list_flow\r\nimport asyncio\r\nDBGPT_API_KEY = \"dbgpt\"\r\n\r\nclient = Client(api_key=DBGPT_API_KEY, version=\"v2\")\r\n\r\n\r\n# async def get_flow_list():\r\n#     res = await list_flow(client=client)\r\n#     return res\r\n\r\n# res = asyncio.run(get_flow_list())\r\n\r\n# for r in res:\r\n#     print(r.name)\r\n#     print(r.uid)\r\n\r\nasync def awel_flow_web_info_search():\r\n    async for data in client.chat_stream(\r\n        messages=\"今天的天气情况?\",\r\n        model=\"zhipu_proxyllm\", \r\n        chat_mode=\"chat_flow\", \r\n        chat_param=\"e777dd16-8295-4406-ba80-d14e1dfa4dfb\"\r\n    ):\r\n        print(data) \r\n\r\nasyncio.run(awel_flow_web_info_search())\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "fryng",
      "author_type": "User",
      "created_at": "2024-11-01T02:50:20Z",
      "updated_at": "2025-02-18T12:38:16Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2112/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2112",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2112",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:52.529425",
      "comments": [
        {
          "author": "kenny1109",
          "body": "过了一个月，这个问题没有项目成员来回复，这个项目是要停更了吗？",
          "created_at": "2024-12-13T06:24:47Z"
        },
        {
          "author": "huangzz",
          "body": "感觉问题很多，确实回复看起来有点问题\r\n",
          "created_at": "2024-12-15T11:20:35Z"
        },
        {
          "author": "wjyrun",
          "body": "在AWEL工作流中测试对话会有这个问题，新建一个应用程序，将该AWEL工作流集成进去再测试就可以了",
          "created_at": "2024-12-25T07:18:57Z"
        },
        {
          "author": "2u0ta0",
          "body": "> 在AWEL工作流中测试对话会有这个问题，新建一个应用程序，将该AWEL工作流集成进去再测试就可以了\n\nit works, thanks",
          "created_at": "2025-02-05T07:25:58Z"
        },
        {
          "author": "sliontc",
          "body": "我放到应用里后，出现下面的错误：\nFailed to build resource knowledge:dbgpt.serve.agent.resource.knowledge.KnowledgeSpaceRetrieverResource: 'NoneType' object has no attribute 'name\n\n> > 在AWEL工作流中测试对话会有这个问题，新建一个应用程序，将该AWEL工作流集成进去再测试就可以了\n> \n> it works, thanks\n\n",
          "created_at": "2025-02-18T12:38:14Z"
        }
      ]
    },
    {
      "issue_number": 2353,
      "title": "[Bug] 和知识库沟通复杂问题，可以看到正确的召回，但是回答错乱",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nMacOS(x86)\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nApple mac mini m4 16G\n\n### Models information\n\nLLM: ollama deepseek-r1:8b\nembedding model: ollama bge-m3:latest\n\n### What happened\n\n从日志看，它似乎进行了多轮和大模型互动，但是最终采纳了一个毫无关系的结果\n\n### What you expected to happen\n\n[日志.txt](https://github.com/user-attachments/files/18843598/default.txt)\n\n![Image](https://github.com/user-attachments/assets/e885f49c-718f-4a69-a65e-53acd4866983)\n\n### How to reproduce\n\n我是建立了一个300多个txt文件的知识库，多次交流 复杂问题后，就出现了。比如问：主人公认识哪些女性\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "daiyu536",
      "author_type": "User",
      "created_at": "2025-02-18T11:03:41Z",
      "updated_at": "2025-02-18T11:45:59Z",
      "closed_at": "2025-02-18T11:45:39Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2353/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2353",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2353",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:52.724184",
      "comments": [
        {
          "author": "daiyu536",
          "body": "最大迭代数的设定问题",
          "created_at": "2025-02-18T11:45:58Z"
        }
      ]
    },
    {
      "issue_number": 1126,
      "title": "[Bug]  dbgpt start error, No module named 'dbgpt'",
      "body": "### Search before asking\r\n\r\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\r\n\r\n\r\n### Operating system information\r\n\r\nLinux\r\n\r\n### Python version information\r\n\r\n<3.9\r\n\r\n### DB-GPT version\r\n\r\nmain\r\n\r\n### Related scenes\r\n\r\n- [ ] Chat Data\r\n- [ ] Chat Excel\r\n- [ ] Chat DB\r\n- [ ] Chat Knowledge\r\n- [ ] Model Management\r\n- [ ] Dashboard\r\n- [ ] Plugins\r\n\r\n### Installation Information\r\n\r\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\r\n\r\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\r\n\r\n- [ ] AutoDL Image\r\n- [ ] Other\r\n\r\n### Device information\r\n\r\nGPU1\r\n\r\n### Models information\r\n\r\nLLM\r\n\r\n### What happened\r\n环境配置时出错\r\n![image](https://github.com/eosphoros-ai/DB-GPT/assets/101547157/5fd4e4f5-0765-4160-bbff-93a998f82588)\r\n\r\n启动时两种方法均报错\r\n![image](https://github.com/eosphoros-ai/DB-GPT/assets/101547157/83a652fe-a01e-4ed4-80ed-7bc245e3b55b)\r\n\r\n\r\n### What you expected to happen\r\n\r\n请问怎么解决\r\n\r\n### How to reproduce\r\n\r\n*\r\n\r\n### Additional context\r\n\r\n_No response_\r\n\r\n### Are you willing to submit PR?\r\n\r\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "CharlieZZss",
      "author_type": "User",
      "created_at": "2024-01-28T11:17:54Z",
      "updated_at": "2025-02-17T05:11:47Z",
      "closed_at": "2024-01-29T05:46:38Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1126/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1126",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1126",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:52.895557",
      "comments": [
        {
          "author": "paul-yangmy",
          "body": "你没配置conda环境吧\r\n",
          "created_at": "2024-01-29T01:09:25Z"
        },
        {
          "author": "fangyinc",
          "body": "Please refer to this [AutoDL image](https://www.codewithgpu.com/i/eosphoros-ai/DB-GPT/dbgpt)",
          "created_at": "2024-01-29T02:44:58Z"
        },
        {
          "author": "caoyl2015",
          "body": "> Please refer to this [AutoDL image](https://www.codewithgpu.com/i/eosphoros-ai/DB-GPT/dbgpt)\r\n\r\nhello, I have the same error,  but my env is simple python3.10 and install the dependency ( BY the way, I run the 0.4.4 version is OK) ",
          "created_at": "2024-02-02T06:04:20Z"
        },
        {
          "author": "asd5800090",
          "body": "> > Please refer to this [AutoDL image](https://www.codewithgpu.com/i/eosphoros-ai/DB-GPT/dbgpt)\r\n> \r\n> hello, I have the same error, but my env is simple python3.10 and install the dependency ( BY the way, I run the 0.4.4 version is OK)\r\n\r\nuninstall the old version ，pull the latest source and reins",
          "created_at": "2024-03-26T02:13:57Z"
        },
        {
          "author": "alexmtd",
          "body": "ModuleNotFoundError: No module named 'dbgpt'\r\n怎么解决？\r\n<img width=\"745\" alt=\"截屏2024-08-11 19 34 43\" src=\"https://github.com/user-attachments/assets/35d9cb5e-d151-4a8b-bcce-23fb64b24702\">\r\n",
          "created_at": "2024-08-11T11:35:37Z"
        }
      ]
    },
    {
      "issue_number": 2053,
      "title": "[Bug] [Module Name] Bug title v0.6.0 deploy error. setuptools.command.test",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU：24G\n\n### Models information\n\nLLM_MODEL=glm-4-9b-chat\n\n### What happened\n\npython 安装报错，具体的错误信息如下，安装过程中，matplotlib一直找不到合适的版本\r\nPreparing metadata (setup.py) ... error\r\n  error: subprocess-exited-with-error\r\n  \r\n  × python setup.py egg_info did not run successfully.\r\n  │ exit code: 1\r\n  ╰─> [60 lines of output]\r\n      /tmp/pip-install-u3iwfl2e/matplotlib_498b668ccc8947ea9526de450efe5145/setup.py:33: SetuptoolsDeprecationWarning: The test command is disabled and references to it are deprecated.\r\n      !!\r\n      \r\n              ********************************************************************************\r\n              Please remove any references to `setuptools.command.test` in all supported versions of the affected package.\r\n      \r\n              By 2024-Nov-15, you need to update your project and remove deprecated calls\r\n              or your builds will no longer be supported.\r\n              ********************************************************************************\r\n      \r\n      !!\r\n        from setuptools.command.test import test as TestCommand\r\n      Traceback (most recent call last):\r\n        File \"<string>\", line 2, in <module>\r\n        File \"<pip-setuptools-caller>\", line 34, in <module>\r\n        File \"/tmp/pip-install-u3iwfl2e/matplotlib_498b668ccc8947ea9526de450efe5145/setup.py\", line 225, in <module>\r\n          msg = pkg.install_help_msg()\r\n        File \"/tmp/pip-install-u3iwfl2e/matplotlib_498b668ccc8947ea9526de450efe5145/setupext.py\", line 650, in install_help_msg\r\n          release = platform.linux_distribution()[0].lower()\r\n      AttributeError: module 'platform' has no attribute 'linux_distribution'\r\n      ============================================================================\r\n      Edit setup.cfg to change the build options\r\n      \r\n      BUILDING MATPLOTLIB\r\n                  matplotlib: yes [3.0.3]\r\n                      python: yes [3.10.15 (main, Oct  3 2024, 07:27:34) [GCC\r\n                              11.2.0]]\r\n                    platform: yes [linux]\r\n      \r\n      REQUIRED DEPENDENCIES AND EXTENSIONS\r\n                       numpy: yes [not found. pip may install it below.]\r\n            install_requires: yes [handled by setuptools]\r\n                      libagg: yes [pkg-config information for 'libagg' could not\r\n                              be found. Using local copy.]\r\n                    freetype: no  [The C/C++ header for freetype2 (ft2build.h)\r\n                              could not be found.  You may need to install the\r\n                              development package.]\r\n                         png: yes [version 1.6.37]\r\n                       qhull: yes [pkg-config information for 'libqhull' could not\r\n                              be found. Using local copy.]\r\n      \r\n      OPTIONAL SUBPACKAGES\r\n                 sample_data: yes [installing]\r\n                    toolkits: yes [installing]\r\n                       tests: no  [skipping due to configuration]\r\n              toolkits_tests: no  [skipping due to configuration]\r\n      \r\n      OPTIONAL BACKEND EXTENSIONS\r\n                         agg: yes [installing]\r\n                       tkagg: yes [installing; run-time loading from Python Tcl /\r\n                              Tk]\r\n                      macosx: no  [Mac OS-X only]\r\n                   windowing: no  [Microsoft Windows only]\r\n      \r\n      OPTIONAL PACKAGE DATA\r\n                        dlls: no  [skipping due to configuration]\r\n      \r\n      ============================================================================\r\n                              * The following required packages can not be built:\r\n                              * freetype\r\n      [end of output]\r\n  \r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\nerror: metadata-generation-failed\r\n\r\n× Encountered error while generating package metadata.\r\n╰─> See above for output.\r\n\r\nnote: This is an issue with the package mentioned above, not pip.\r\nhint: See above for details.\n\n### What you expected to happen\n\n1、正常来说，参照官方文档执行后，可正常部署，不会报任何错误；\r\n2、一开始使用python=3.10的虚拟环境，尝试过采用python=3.11的虚拟环境，仍然报同样的错误\n\n### How to reproduce\n\npython >= 3.10\r\nconda create -n dbgpt_env python=3.10\r\nconda activate dbgpt_env\r\n\r\n# it will take some minutes\r\npip install -e \".[default]\"\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "chenyb868",
      "author_type": "User",
      "created_at": "2024-10-07T05:07:52Z",
      "updated_at": "2025-02-14T21:05:05Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2053/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2053",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2053",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:53.129481",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "Cento os?\r\ntry\r\n```\r\npip install --use-pep517 fschat\r\n```",
          "created_at": "2024-10-07T14:57:24Z"
        },
        {
          "author": "chenyb868",
          "body": "> Cento os? try\r\n> \r\n> ```\r\n> pip install --use-pep517 fschat\r\n> ```\r\n\r\nthe os is Ubuntu 22.04.1.   have tried the command \"pip install --use-pep517 fschat\",but the problem still exists.",
          "created_at": "2024-10-07T16:28:53Z"
        },
        {
          "author": "Jay-zjms",
          "body": "I also encountered the same problem, and my system information is as follows:\r\nLinux version 3.10.0-1160.119.1.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-44) (GCC) )\r\n\r\n“pip install --use-pep517 fschat”  has no effect\r\n\r\nAccording to the log informatio",
          "created_at": "2024-10-08T05:46:20Z"
        },
        {
          "author": "mikck",
          "body": "I also met the same problem. Is there any progress.",
          "created_at": "2024-10-11T01:18:18Z"
        },
        {
          "author": "472027909",
          "body": "I also met the same problem. Is there any progress.",
          "created_at": "2024-10-11T08:59:46Z"
        }
      ]
    },
    {
      "issue_number": 2076,
      "title": "[Doc][Module Name] docker build error",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n```\r\n┌──(kali㉿kali)-[~/DB-GPT]\r\n└─$ bash docker/build_all_images.shbash docker/build_all_images.sh \\\r\n--base-image nvidia/cuda:11.8.0-runtime-ubuntu22.04 \\\r\n--pip-index-url https://pypi.tuna.tsinghua.edu.cn/simple \\\r\n--language zh\r\n                                                                                                                                                                                                                   \r\n┌──(kali㉿kali)-[~/DB-GPT]\r\n└─$ \r\n                                                                                                                                                                                                                   \r\n┌──(kali㉿kali)-[~/DB-GPT]\r\n└─$ bash docker/build_all_images.sh \\\r\n--base-image nvidia/cuda:11.8.0-runtime-ubuntu22.04 \\\r\n--pip-index-url https://pypi.tuna.tsinghua.edu.cn/simple \\\r\n--language zh\r\nBegin build docker image, base image: nvidia/cuda:11.8.0-runtime-ubuntu22.04, target image name: eosphorosai/dbgpt\r\n[+] Building 396.0s (11/14)                                                                                                                                                                         docker:default\r\n => [internal] load build definition from Dockerfile                                                                                                                                                          0.0s\r\n => => transferring dockerfile: 2.41kB                                                                                                                                                                        0.0s \r\n => [internal] load metadata for docker.io/nvidia/cuda:11.8.0-runtime-ubuntu22.04                                                                                                                             6.0s \r\n => [internal] load .dockerignore                                                                                                                                                                             0.0s\r\n => => transferring context: 220B                                                                                                                                                                             0.0s \r\n => [ 1/10] FROM docker.io/nvidia/cuda:11.8.0-runtime-ubuntu22.04@sha256:eaaccb3528ceca110601131434ab467e41d694a41e8c9bf280fb27ac18fcb29b                                                                   189.6s \r\n => => resolve docker.io/nvidia/cuda:11.8.0-runtime-ubuntu22.04@sha256:eaaccb3528ceca110601131434ab467e41d694a41e8c9bf280fb27ac18fcb29b                                                                       0.0s\r\n => => sha256:eaaccb3528ceca110601131434ab467e41d694a41e8c9bf280fb27ac18fcb29b 743B / 743B                                                                                                                    0.0s \r\n => => sha256:7c8e5ee1e8531f0d19f8d7e78c5b7efa9c455697fa96e62f083f361d6842e452 2.21kB / 2.21kB                                                                                                                0.0s \r\n => => sha256:d8fb74ecc8b26b5fae3ced43455e67e1f42dbc6a7b24102884fa038537da7f67 12.02kB / 12.02kB                                                                                                              0.0s \r\n => => sha256:5e3b7ee7738140e8f4608c3945b6e1ed4f9fb75db53a04e19ba0a6661e7cc4fe 4.62MB / 4.62MB                                                                                                                7.1s \r\n => => sha256:5bd037f007fdda13ae5a5f43a199d6677db1f9059c2980c84726e3a43fab169a 56.23MB / 56.23MB                                                                                                              8.2s\r\n => => sha256:4cda774ad2ecef28c9a1cd97594f7199071c83769f91c5d109eb1cb6770ecdff 188B / 188B                                                                                                                    1.8s\r\n => => sha256:775f22adee620daec0db645bad7027db4c1ecf22520412e1b2466fc73d54d19b 6.88kB / 6.88kB                                                                                                                2.5s\r\n => => sha256:263fc748118f7937f811e3e9c9355318db07dd2dd1dccc370dadaa7d0b5ed692 1.38GB / 1.38GB                                                                                                              102.0s\r\n => => extracting sha256:5e3b7ee7738140e8f4608c3945b6e1ed4f9fb75db53a04e19ba0a6661e7cc4fe                                                                                                                     4.0s\r\n => => sha256:16c36d0187d03bd0de84d870ded86c45fabd78f4bfdb2ed90177e5fc4dd33d11 63.70kB / 63.70kB                                                                                                              7.9s\r\n => => sha256:e7a56570655c990ecc804c77873efc83f9a6c31064e3e8a5dc02430213f2d74c 1.69kB / 1.69kB                                                                                                                8.5s\r\n => => sha256:507fc9045cbad45c1c4ca554a6453fe0a1c9ae74667db0612fec7475256d5c23 1.52kB / 1.52kB                                                                                                                8.8s\r\n => => extracting sha256:5bd037f007fdda13ae5a5f43a199d6677db1f9059c2980c84726e3a43fab169a                                                                                                                    16.9s\r\n => => extracting sha256:4cda774ad2ecef28c9a1cd97594f7199071c83769f91c5d109eb1cb6770ecdff                                                                                                                     0.0s\r\n => => extracting sha256:775f22adee620daec0db645bad7027db4c1ecf22520412e1b2466fc73d54d19b                                                                                                                     0.0s\r\n => => extracting sha256:263fc748118f7937f811e3e9c9355318db07dd2dd1dccc370dadaa7d0b5ed692                                                                                                                    87.0s\r\n => => extracting sha256:16c36d0187d03bd0de84d870ded86c45fabd78f4bfdb2ed90177e5fc4dd33d11                                                                                                                     0.0s \r\n => => extracting sha256:e7a56570655c990ecc804c77873efc83f9a6c31064e3e8a5dc02430213f2d74c                                                                                                                     0.0s \r\n => => extracting sha256:507fc9045cbad45c1c4ca554a6453fe0a1c9ae74667db0612fec7475256d5c23                                                                                                                     0.0s \r\n => [internal] load build context                                                                                                                                                                            26.4s \r\n => => transferring context: 330.82MB                                                                                                                                                                        26.4s \r\n => [ 2/10] RUN apt-get update && DEBIAN_FRONTEND=noninteractive apt-get install -y git python3 pip     wget sqlite3 tzdata libpq-dev default-libmysqlclient-dev     && apt-get clean                       128.2s \r\n => [ 3/10] RUN mkdir -p /app                                                                                                                                                                                 0.7s \r\n => [ 4/10] COPY ./setup.py /app/setup.py                                                                                                                                                                     0.1s \r\n => [ 5/10] COPY ./README.md /app/README.md                                                                                                                                                                   0.1s \r\n => [ 6/10] WORKDIR /app                                                                                                                                                                                      0.1s \r\n => ERROR [ 7/10] RUN pip3 install --upgrade pip -i https://pypi.tuna.tsinghua.edu.cn/simple     && pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple \".[default]\"     && pip3 install -i https://py  71.0s \r\n------                                                                                                                                                                                                             \r\n > [ 7/10] RUN pip3 install --upgrade pip -i https://pypi.tuna.tsinghua.edu.cn/simple     && pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple \".[default]\"     && pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple \".[openai]\":                                                                                                                                                                                       \r\n1.830 Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple                                                                                                                                                 \r\n1.830 Requirement already satisfied: pip in /usr/lib/python3/dist-packages (22.0.2)                                                                                                                                \r\n6.829 Collecting pip                                                                                                                                                                                               \r\n8.239   Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d4/55/90db48d85f7689ec6f81c0db0622d704306c5284850383c090e6c7195a5c/pip-24.2-py3-none-any.whl (1.8 MB)\r\n70.62      ━━━━━━━━━━━━━━━━━━━╸                     0.9/1.8 MB 11.0 kB/s eta 0:01:24\r\n70.65 ERROR: Exception:\r\n70.65 Traceback (most recent call last):\r\n70.65   File \"/usr/lib/python3/dist-packages/pip/_vendor/urllib3/response.py\", line 438, in _error_catcher\r\n70.65     yield\r\n70.65   File \"/usr/lib/python3/dist-packages/pip/_vendor/urllib3/response.py\", line 519, in read\r\n70.65     data = self._fp.read(amt) if not fp_closed else b\"\"\r\n70.65   File \"/usr/lib/python3/dist-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 90, in read\r\n70.65     data = self.__fp.read(amt)\r\n70.65   File \"/usr/lib/python3.10/http/client.py\", line 466, in read\r\n70.65     s = self.fp.read(amt)\r\n70.65   File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\r\n70.65     return self._sock.recv_into(b)\r\n70.65   File \"/usr/lib/python3.10/ssl.py\", line 1303, in recv_into\r\n70.65     return self.read(nbytes, buffer)\r\n70.65   File \"/usr/lib/python3.10/ssl.py\", line 1159, in read\r\n70.65     return self._sslobj.read(len, buffer)\r\n70.65 TimeoutError: The read operation timed out\r\n70.65 \r\n70.65 During handling of the above exception, another exception occurred:\r\n70.65 \r\n70.65 Traceback (most recent call last):\r\n70.65   File \"/usr/lib/python3/dist-packages/pip/_internal/cli/base_command.py\", line 165, in exc_logging_wrapper\r\n70.65     status = run_func(*args)\r\n70.65   File \"/usr/lib/python3/dist-packages/pip/_internal/cli/req_command.py\", line 205, in wrapper\r\n70.65     return func(self, options, args)\r\n70.65   File \"/usr/lib/python3/dist-packages/pip/_internal/commands/install.py\", line 339, in run\r\n70.65     requirement_set = resolver.resolve(\r\n70.65   File \"/usr/lib/python3/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 94, in resolve\r\n70.65     result = self._result = resolver.resolve(\r\n70.65   File \"/usr/lib/python3/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 481, in resolve\r\n70.65     state = resolution.resolve(requirements, max_rounds=max_rounds)\r\n70.65   File \"/usr/lib/python3/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 348, in resolve\r\n70.65     self._add_to_criteria(self.state.criteria, r, parent=None)\r\n70.65   File \"/usr/lib/python3/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 172, in _add_to_criteria\r\n70.65     if not criterion.candidates:\r\n70.65   File \"/usr/lib/python3/dist-packages/pip/_vendor/resolvelib/structs.py\", line 151, in __bool__\r\n70.65     return bool(self._sequence)\r\n70.65   File \"/usr/lib/python3/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 155, in __bool__\r\n70.65     return any(self)\r\n70.65   File \"/usr/lib/python3/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 143, in <genexpr>\r\n70.65     return (c for c in iterator if id(c) not in self._incompatible_ids)\r\n70.65   File \"/usr/lib/python3/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 97, in _iter_built_with_inserted\r\n70.65     candidate = func()\r\n70.65   File \"/usr/lib/python3/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 215, in _make_candidate_from_link\r\n70.65     self._link_candidate_cache[link] = LinkCandidate(\r\n70.65   File \"/usr/lib/python3/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 288, in __init__\r\n70.65     super().__init__(\r\n70.65   File \"/usr/lib/python3/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 158, in __init__\r\n70.65     self.dist = self._prepare()\r\n70.65   File \"/usr/lib/python3/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 227, in _prepare\r\n70.65     dist = self._prepare_distribution()\r\n70.65   File \"/usr/lib/python3/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 299, in _prepare_distribution\r\n70.65     return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\r\n70.65   File \"/usr/lib/python3/dist-packages/pip/_internal/operations/prepare.py\", line 487, in prepare_linked_requirement\r\n70.65     return self._prepare_linked_requirement(req, parallel_builds)\r\n70.65   File \"/usr/lib/python3/dist-packages/pip/_internal/operations/prepare.py\", line 532, in _prepare_linked_requirement\r\n70.65     local_file = unpack_url(\r\n70.65   File \"/usr/lib/python3/dist-packages/pip/_internal/operations/prepare.py\", line 214, in unpack_url\r\n70.65     file = get_http_url(\r\n70.65   File \"/usr/lib/python3/dist-packages/pip/_internal/operations/prepare.py\", line 94, in get_http_url\r\n70.65     from_path, content_type = download(link, temp_dir.path)\r\n70.65   File \"/usr/lib/python3/dist-packages/pip/_internal/network/download.py\", line 146, in __call__\r\n70.65     for chunk in chunks:\r\n70.65   File \"/usr/lib/python3/dist-packages/pip/_internal/cli/progress_bars.py\", line 304, in _rich_progress_bar\r\n70.65     for chunk in iterable:\r\n70.65   File \"/usr/lib/python3/dist-packages/pip/_internal/network/utils.py\", line 63, in response_chunks\r\n70.65     for chunk in response.raw.stream(\r\n70.65   File \"/usr/lib/python3/dist-packages/pip/_vendor/urllib3/response.py\", line 576, in stream\r\n70.65     data = self.read(amt=amt, decode_content=decode_content)\r\n70.65   File \"/usr/lib/python3/dist-packages/pip/_vendor/urllib3/response.py\", line 512, in read\r\n70.65     with self._error_catcher():\r\n70.65   File \"/usr/lib/python3.10/contextlib.py\", line 153, in __exit__\r\n70.65     self.gen.throw(typ, value, traceback)\r\n70.65   File \"/usr/lib/python3/dist-packages/pip/_vendor/urllib3/response.py\", line 443, in _error_catcher\r\n70.65     raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\r\n70.65 pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='pypi.tuna.tsinghua.edu.cn', port=443): Read timed out.\r\n------\r\n\r\n 2 warnings found (use docker --debug to expand):\r\n - UndefinedVar: Usage of undefined variable '$PYTHONPATH' (line 65)                                                                                                                                               \r\n - LegacyKeyValueFormat: \"ENV key=value\" should be used instead of legacy \"ENV key value\" format (line 65)\r\nDockerfile:32\r\n--------------------\r\n  31 |     \r\n  32 | >>> RUN pip3 install --upgrade pip -i $PIP_INDEX_URL \\\r\n  33 | >>>     && pip3 install -i $PIP_INDEX_URL \".[$DB_GPT_INSTALL_MODEL]\" \\\r\n  34 | >>>     # install openai for proxyllm\r\n  35 | >>>     && pip3 install -i $PIP_INDEX_URL \".[openai]\"\r\n  36 |     \r\n--------------------\r\nERROR: failed to solve: process \"/bin/sh -c pip3 install --upgrade pip -i $PIP_INDEX_URL     && pip3 install -i $PIP_INDEX_URL \\\".[$DB_GPT_INSTALL_MODEL]\\\"     && pip3 install -i $PIP_INDEX_URL \\\".[openai]\\\"\" did not complete successfully: exit code: 2\r\nError: build base image failed\r\n\r\n```\r\nHow can I fix it\n\n### Documentation Links\n\nhttp://docs.dbgpt.cn/docs/installation/docker#docker-image-preparation\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "NgocKhanhC311",
      "author_type": "User",
      "created_at": "2024-10-17T17:41:29Z",
      "updated_at": "2025-02-14T21:05:01Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2076/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2076",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2076",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:53.420574",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-02-14T21:04:59Z"
        }
      ]
    },
    {
      "issue_number": 2233,
      "title": "[Bug] [Module Name] After the intent is recognized, call the AppLauncher to answer the question and an error is reported",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n24GX4\n\n### Models information\n\nQwen2.5-32B\n\n### What happened\n\n上下文修复后，在调用awel工作流时，进行到AppLauncher时，后台报错：\r\n2024-12-20 18:22:44 amax dbgpt.agent.core.base_agent[3672381] ERROR Generate reply exception!\r\nTraceback (most recent call last):\r\n  File \"/home/xinrui24/DB-GPT/dbgpt/agent/core/base_agent.py\", line 375, in generate_reply\r\n    thinking_messages, resource_info = await self._load_thinking_messages(\r\nTypeError: StartAppAssistantAgent._load_thinking_messages() got an unexpected keyword argument 'historical_dialogues'\r\n![image](https://github.com/user-attachments/assets/f186fb93-4001-4399-bd60-e2cc84929512)\r\n前端一直卡着不动\r\n![image](https://github.com/user-attachments/assets/41acd5b7-4cfe-4b86-8578-7e43db1ae237)\r\n\n\n### What you expected to happen\n\n意图识别后，调用对应领域的app进行工作\n\n### How to reproduce\n\n搭建包含意图识别的工作流，提问就好\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "classic325",
      "author_type": "User",
      "created_at": "2024-12-20T10:29:13Z",
      "updated_at": "2025-02-14T08:45:10Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2233/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2233",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2233",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:53.680127",
      "comments": [
        {
          "author": "classic325",
          "body": "awel\r\n![image](https://github.com/user-attachments/assets/35d52887-9fb9-4493-875b-f75e3924c561)\r\n",
          "created_at": "2024-12-20T10:35:33Z"
        },
        {
          "author": "fangyinc",
          "body": "@yhjun1026 \r\n",
          "created_at": "2024-12-20T10:40:05Z"
        },
        {
          "author": "classic325",
          "body": "修后有个同类型的报错\r\n![1734692859002_415CCEAB-4F36-4482-B5C6-0504CFA15A85](https://github.com/user-attachments/assets/dc931376-37e2-4e34-ab87-aa0d6a3cd924)\r\n\r\n",
          "created_at": "2024-12-20T11:10:52Z"
        },
        {
          "author": "mxli441",
          "body": "![Image](https://github.com/user-attachments/assets/028b5474-7c9a-4fe1-a8d9-1bfbcd939365)\n我也遇到了同样的错误\n\n========================已解决================================\n处理如下：\n修改dbgpt/serve/agent/agents/expand/app_start_assisant_agent.py\n添加此行代码，可解决问题\nhistorical_dialogues: Optional[List[AgentMessage]] = None",
          "created_at": "2025-02-14T02:10:09Z"
        }
      ]
    },
    {
      "issue_number": 2064,
      "title": "[Bug] [ChatKnowledge]When Chat with GraphRAG, use milvus error.",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [X] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU  4090 一张，24G\n\n### Models information\n\nLLM：本地GLM4\n\n### What happened\n\n若用缺省向量库，工作正常，但切换到milvus时，报错。提示错是不能自动建collection错\n\n### What you expected to happen\n\n从ERROR来看，应该是没有自动创建 milvus collection\n\n### How to reproduce\n\n.env 切换至milvus，创建知识库，选知识图谱，上传一个文件就能看到。\n\n### Additional context\n\nMYSQL, MILVUS, TUGRAPH都跑起来，本地LLM\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "leichangqing",
      "author_type": "User",
      "created_at": "2024-10-14T02:21:37Z",
      "updated_at": "2025-02-13T21:04:53Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2064/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2064",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2064",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:53.909985",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "could you show some error log?",
          "created_at": "2024-10-16T15:49:02Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-02-13T21:04:51Z"
        }
      ]
    },
    {
      "issue_number": 2066,
      "title": "Windows11 can not found freetype and png",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\n<v0.3.7\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nwindows11   \n\n### Models information\n\nno\n\n### What happened\n\n* The following required packages can not be built:\r\n                              * freetype, png\r\n                              * Please check http://gnuwin32.sourceforge.net/packa\r\n                              * ges/freetype.htm for instructions to install\r\n                              * freetype\r\n                              * Please check http://gnuwin32.sourceforge.net/packa\r\n                              * ges/libpng.htm for instructions to install png\n\n### What you expected to happen\n\n![image](https://github.com/user-attachments/assets/27a76087-fc8d-47ee-aedd-8eaf08aa6794)\r\n\n\n### How to reproduce\n\npip install -e \".[default]\"\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Xlinlin",
      "author_type": "User",
      "created_at": "2024-10-14T02:42:12Z",
      "updated_at": "2025-02-13T21:04:52Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2066/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2066",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2066",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:54.177880",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-02-13T21:04:49Z"
        }
      ]
    },
    {
      "issue_number": 2067,
      "title": "[Bug] Chat Data hive ERROR!(pyhive.exc.OperationalError)...cannot recognize input near \"2024-10-11\"','",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [X] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [X] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU:1\r\nGPU Memorry:24G\n\n### Models information\n\nLLM:CHATGLM4_9B\r\nembedding model:M3E\n\n### What happened\n\nChat Data用hive数据库对话报错但生成的sql查询语句是正确的：\r\n<img width=\"943\" alt=\"企业微信截图_17287145958956\" src=\"https://github.com/user-attachments/assets/c4563621-b0a7-420e-8a52-f1262864c93c\">\r\n\n\n### What you expected to happen\n\n可正常与数据库交互\n\n### How to reproduce\n\n1、docker-compose部署\r\n2、新建hive数据库连接，但连接会报错Password should be set if and only if in LDAP or CUSTOM mode\r\n3、修改conn_hive.py如下图，添加auth=\"custom\":\r\n<img width=\"605\" alt=\"企业微信截图_1728714328492\" src=\"https://github.com/user-attachments/assets/3df21f26-496e-4730-8e96-2251b1e310fd\">\r\n4、hive数据库连接创建成功\r\n5、chat data与Hive数据库对话，报错但生成的sql查询语句是正确的：\r\n<img width=\"943\" alt=\"企业微信截图_17287145958956\" src=\"https://github.com/user-attachments/assets/1b59cba2-eb79-4b0e-954f-568a739f61d4\">\r\n\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Sloane9511",
      "author_type": "User",
      "created_at": "2024-10-15T02:19:10Z",
      "updated_at": "2025-02-13T21:04:50Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2067/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2067",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2067",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:54.390744",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-02-13T21:04:48Z"
        }
      ]
    },
    {
      "issue_number": 2071,
      "title": "[Doc][Module Name] Can't access http://docs.dbgpt.cn/",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nI can't access http://docs.dbgpt.cn/ to build. Can you help me?\n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "NgocKhanhC311",
      "author_type": "User",
      "created_at": "2024-10-16T03:32:10Z",
      "updated_at": "2025-02-13T21:04:48Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2071/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2071",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2071",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:54.623953",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "your network problem?",
          "created_at": "2024-10-16T15:45:12Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-02-13T21:04:47Z"
        }
      ]
    },
    {
      "issue_number": 2344,
      "title": "[Bug] [ChatKnowledge] Error found when chat with knowledge.",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU Count: 1\nGPU Memory: 48G\n\n### Models information\n\nLLM:chatgpt_proxyllm\nEmbeddings:bge-m3\nReranker:bge-reranker-v2-m3\n\n### What happened\n\n1.Build the knowledge successfully.\n2.chat with the knowledge.\n3.error found:\n2025-02-11 21:48:30 star-Super-Server dbgpt.serve.agent.app.controller[2824352] INFO app_detail:chat_knowledge,chat_knowledge\nINFO:     10.11.219.162:37870 - \"GET /api/v1/app/info?chat_scene=chat_knowledge&app_code=chat_knowledge HTTP/1.1\" 200 OK\nINFO:     10.11.219.162:37842 - \"GET /api/v1/chat/dialogue/messages/history?con_uid=e0c23f9c-e87e-11ef-925c-7cc2554a6c19 HTTP/1.1\" 200 OK\nINFO:     10.11.219.162:37858 - \"GET /api/v1/chat/dialogue/list HTTP/1.1\" 200 OK\nINFO:     10.11.219.162:37870 - \"POST /api/v1/chat/mode/params/list?chat_mode=chat_knowledge HTTP/1.1\" 200 OK\n2025-02-11 21:48:41 star-Super-Server dbgpt.app.openapi.api_v1.api_v1[2824352] INFO chat_completions:chat_knowledge,专家信息库,chatgpt_proxyllm, timestamp=1739281721064\n2025-02-11 21:48:41 star-Super-Server dbgpt.app.openapi.api_v1.api_v1[2824352] INFO get_chat_instance:conv_uid='e0c23f9c-e87e-11ef-925c-7cc2554a6c19' user_input='hi' user_name='001' chat_mode='chat_knowledge' app_code='chat_knowledge' temperature=0.5 max_new_tokens=2048 select_param='专家信息库' model_name='chatgpt_proxyllm' incremental=False sys_code=None ext_info={}\nGet prompt template of scene_name: chat_knowledge with model_name: chatgpt_proxyllm, proxyllm_backend: None, language: en\n2025-02-11 21:48:41 star-Super-Server dbgpt.serve.rag.connector[2824352] INFO VectorStore:<class 'dbgpt.storage.vector_store.chroma_store.ChromaStore'>\ncurrent session:<sqlalchemy.orm.session.Session object at 0x76b056dab760>\nINFO:     10.11.219.162:60226 - \"POST /api/v1/chat/completions HTTP/1.1\" 200 OK\n2025-02-11 21:48:41 star-Super-Server dbgpt.storage.vector_store.chroma_store[2824352] INFO ChromaStore similar search with scores\n2025-02-11 21:48:41 star-Super-Server dbgpt.serve.core.schemas[2824352] ERROR common_exception_handler catch Exception: success=False err_code='E0003' err_msg='Cannot find results in the response' data=None\nERROR:    Exception in ASGI application\n  + Exception Group Traceback (most recent call last):\n  |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/base.py\", line 188, in __call__\n  |     await response(scope, wrapped_receive, send)\n  |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/base.py\", line 222, in __call__\n  |     async for chunk in self.body_iterator:\n  |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/base.py\", line 179, in body_stream\n  |     raise app_exc\n  |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/base.py\", line 149, in coro\n  |     await self.app(scope, receive_or_disconnect, send_no_error)\n  |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n  |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n  |     raise exc\n  |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n  |     await app(scope, receive, sender)\n  |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/routing.py\", line 715, in __call__\n  |     await self.middleware_stack(scope, receive, send)\n  |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/routing.py\", line 735, in app\n  |     await route.handle(scope, receive, send)\n  |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/routing.py\", line 288, in handle\n  |     await self.app(scope, receive, send)\n  |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/routing.py\", line 76, in app\n  |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n  |     raise exc\n  |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n  |     await app(scope, receive, sender)\n  |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/routing.py\", line 74, in app\n  |     await response(scope, receive, send)\n  |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/responses.py\", line 250, in __call__\n  |     async with anyio.create_task_group() as task_group:\n  |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 767, in __aexit__\n  |     raise BaseExceptionGroup(\n  | exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 409, in run_asgi\n    |     result = await app(  # type: ignore[func-returns-value]\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n    |     return await self.app(scope, receive, send)\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    |     await self.simple_response(scope, receive, send, request_headers=headers)\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    |     await self.app(scope, receive, send)\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/fastapi/applications.py\", line 1054, in __call__\n    |     await super().__call__(scope, receive, send)\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/applications.py\", line 113, in __call__\n    |     await self.middleware_stack(scope, receive, send)\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/errors.py\", line 187, in __call__\n    |     raise exc\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    |     await self.app(scope, receive, _send)\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/base.py\", line 185, in __call__\n    |     with collapse_excgroups():\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/contextlib.py\", line 153, in __exit__\n    |     self.gen.throw(typ, value, traceback)\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/_utils.py\", line 83, in collapse_excgroups\n    |     raise exc\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/responses.py\", line 253, in wrap\n    |     await func()\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/responses.py\", line 242, in stream_response\n    |     async for chunk in self.body_iterator:\n    |   File \"/home/star/dev/DB-GPT/dbgpt/app/openapi/api_v1/api_v1.py\", line 673, in stream_generator\n    |     async for chunk in chat.stream_call():\n    |   File \"/home/star/dev/DB-GPT/dbgpt/app/scene/chat_knowledge/v1/chat.py\", line 116, in stream_call\n    |     async for output in super().stream_call():\n    |   File \"/home/star/dev/DB-GPT/dbgpt/app/scene/base_chat.py\", line 276, in stream_call\n    |     payload = await self._build_model_request()\n    |   File \"/home/star/dev/DB-GPT/dbgpt/app/scene/base_chat.py\", line 208, in _build_model_request\n    |     input_values = await self.generate_input_values()\n    |   File \"/home/star/dev/DB-GPT/dbgpt/util/tracer/tracer_impl.py\", line 217, in async_wrapper\n    |     return await func(*args, **kwargs)\n    |   File \"/home/star/dev/DB-GPT/dbgpt/app/scene/chat_knowledge/v1/chat.py\", line 157, in generate_input_values\n    |     candidates_with_scores = await run_async_tasks(tasks=tasks, concurrency_limit=1)\n    |   File \"/home/star/dev/DB-GPT/dbgpt/util/chat_util.py\", line 47, in run_async_tasks\n    |     return await _gather()\n    |   File \"/home/star/dev/DB-GPT/dbgpt/util/chat_util.py\", line 40, in _gather\n    |     return await asyncio.gather(\n    |   File \"/home/star/dev/DB-GPT/dbgpt/util/chat_util.py\", line 37, in _execute_task\n    |     return await task\n    |   File \"/home/star/dev/DB-GPT/dbgpt/app/scene/chat_knowledge/v1/chat.py\", line 260, in execute_similar_search\n    |     return await self._space_retriever.aretrieve_with_scores(\n    |   File \"/home/star/dev/DB-GPT/dbgpt/rag/retriever/base.py\", line 100, in aretrieve_with_scores\n    |     return await self._aretrieve_with_score(query, score_threshold, filters)\n    |   File \"/home/star/dev/DB-GPT/dbgpt/serve/rag/retriever/knowledge_space.py\", line 158, in _aretrieve_with_score\n    |     return await self._retriever_chain.aretrieve_with_scores(\n    |   File \"/home/star/dev/DB-GPT/dbgpt/rag/retriever/base.py\", line 100, in aretrieve_with_scores\n    |     return await self._aretrieve_with_score(query, score_threshold, filters)\n    |   File \"/home/star/dev/DB-GPT/dbgpt/serve/rag/retriever/retriever_chain.py\", line 90, in _aretrieve_with_score\n    |     candidates_with_scores = await retriever.aretrieve_with_scores(\n    |   File \"/home/star/dev/DB-GPT/dbgpt/rag/retriever/base.py\", line 100, in aretrieve_with_scores\n    |     return await self._aretrieve_with_score(query, score_threshold, filters)\n    |   File \"/home/star/dev/DB-GPT/dbgpt/rag/retriever/embedding.py\", line 224, in _aretrieve_with_score\n    |     new_candidates_with_score = await self._rerank.arank(\n    |   File \"/home/star/dev/DB-GPT/dbgpt/rag/retriever/rerank.py\", line 312, in arank\n    |     rank_scores = await self._model.apredict(query, contents)\n    |   File \"/home/star/dev/DB-GPT/dbgpt/rag/embedding/rerank.py\", line 164, in apredict\n    |     return self._parse_results(response_data)\n    |   File \"/home/star/dev/DB-GPT/dbgpt/rag/embedding/rerank.py\", line 121, in _parse_results\n    |     raise RuntimeError(\"Cannot find results in the response\")\n    | RuntimeError: Cannot find results in the response\n    +------------------------------------\n\nDuring handling of the above exception, another exception occurred:\n\n  + Exception Group Traceback (most recent call last):\n  |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/_utils.py\", line 77, in collapse_excgroups\n  |     yield\n  |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/base.py\", line 186, in __call__\n  |     async with anyio.create_task_group() as task_group:\n  |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 767, in __aexit__\n  |     raise BaseExceptionGroup(\n  | exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n  +-+---------------- 1 ----------------\n    | Traceback (most recent call last):\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/responses.py\", line 257, in __call__\n    |     await wrap(partial(self.listen_for_disconnect, receive))\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/responses.py\", line 253, in wrap\n    |     await func()\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/responses.py\", line 230, in listen_for_disconnect\n    |     message = await receive()\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/base.py\", line 118, in receive_or_disconnect\n    |     async with anyio.create_task_group() as task_group:\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 771, in __aexit__\n    |     raise exc_val\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/base.py\", line 126, in receive_or_disconnect\n    |     message = await wrap(wrapped_receive)\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/base.py\", line 121, in wrap\n    |     result = await func()\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/base.py\", line 51, in wrapped_receive\n    |     msg = await self.receive()\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 563, in receive\n    |     await self.message_event.wait()\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/asyncio/locks.py\", line 214, in wait\n    |     await fut\n    | asyncio.exceptions.CancelledError: Cancelled by cancel scope 76b05c53ffd0\n    | \n    | During handling of the above exception, another exception occurred:\n    | \n    | Exception Group Traceback (most recent call last):\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/base.py\", line 188, in __call__\n    |     await response(scope, wrapped_receive, send)\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/base.py\", line 222, in __call__\n    |     async for chunk in self.body_iterator:\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/base.py\", line 179, in body_stream\n    |     raise app_exc\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/base.py\", line 149, in coro\n    |     await self.app(scope, receive_or_disconnect, send_no_error)\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n    |     raise exc\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/routing.py\", line 715, in __call__\n    |     await self.middleware_stack(scope, receive, send)\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/routing.py\", line 735, in app\n    |     await route.handle(scope, receive, send)\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/routing.py\", line 288, in handle\n    |     await self.app(scope, receive, send)\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/routing.py\", line 76, in app\n    |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n    |     raise exc\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n    |     await app(scope, receive, sender)\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/routing.py\", line 74, in app\n    |     await response(scope, receive, send)\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/responses.py\", line 250, in __call__\n    |     async with anyio.create_task_group() as task_group:\n    |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 767, in __aexit__\n    |     raise BaseExceptionGroup(\n    | exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n    +-+---------------- 1 ----------------\n      | Traceback (most recent call last):\n      |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 409, in run_asgi\n      |     result = await app(  # type: ignore[func-returns-value]\n      |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n      |     return await self.app(scope, receive, send)\n      |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n      |     await self.simple_response(scope, receive, send, request_headers=headers)\n      |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n      |     await self.app(scope, receive, send)\n      |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/fastapi/applications.py\", line 1054, in __call__\n      |     await super().__call__(scope, receive, send)\n      |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/applications.py\", line 113, in __call__\n      |     await self.middleware_stack(scope, receive, send)\n      |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/errors.py\", line 187, in __call__\n      |     raise exc\n      |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n      |     await self.app(scope, receive, _send)\n      |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/base.py\", line 185, in __call__\n      |     with collapse_excgroups():\n      |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/contextlib.py\", line 153, in __exit__\n      |     self.gen.throw(typ, value, traceback)\n      |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/_utils.py\", line 83, in collapse_excgroups\n      |     raise exc\n      |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/responses.py\", line 253, in wrap\n      |     await func()\n      |   File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/responses.py\", line 242, in stream_response\n      |     async for chunk in self.body_iterator:\n      |   File \"/home/star/dev/DB-GPT/dbgpt/app/openapi/api_v1/api_v1.py\", line 673, in stream_generator\n      |     async for chunk in chat.stream_call():\n      |   File \"/home/star/dev/DB-GPT/dbgpt/app/scene/chat_knowledge/v1/chat.py\", line 116, in stream_call\n      |     async for output in super().stream_call():\n      |   File \"/home/star/dev/DB-GPT/dbgpt/app/scene/base_chat.py\", line 276, in stream_call\n      |     payload = await self._build_model_request()\n      |   File \"/home/star/dev/DB-GPT/dbgpt/app/scene/base_chat.py\", line 208, in _build_model_request\n      |     input_values = await self.generate_input_values()\n      |   File \"/home/star/dev/DB-GPT/dbgpt/util/tracer/tracer_impl.py\", line 217, in async_wrapper\n      |     return await func(*args, **kwargs)\n      |   File \"/home/star/dev/DB-GPT/dbgpt/app/scene/chat_knowledge/v1/chat.py\", line 157, in generate_input_values\n      |     candidates_with_scores = await run_async_tasks(tasks=tasks, concurrency_limit=1)\n      |   File \"/home/star/dev/DB-GPT/dbgpt/util/chat_util.py\", line 47, in run_async_tasks\n      |     return await _gather()\n      |   File \"/home/star/dev/DB-GPT/dbgpt/util/chat_util.py\", line 40, in _gather\n      |     return await asyncio.gather(\n      |   File \"/home/star/dev/DB-GPT/dbgpt/util/chat_util.py\", line 37, in _execute_task\n      |     return await task\n      |   File \"/home/star/dev/DB-GPT/dbgpt/app/scene/chat_knowledge/v1/chat.py\", line 260, in execute_similar_search\n      |     return await self._space_retriever.aretrieve_with_scores(\n      |   File \"/home/star/dev/DB-GPT/dbgpt/rag/retriever/base.py\", line 100, in aretrieve_with_scores\n      |     return await self._aretrieve_with_score(query, score_threshold, filters)\n      |   File \"/home/star/dev/DB-GPT/dbgpt/serve/rag/retriever/knowledge_space.py\", line 158, in _aretrieve_with_score\n      |     return await self._retriever_chain.aretrieve_with_scores(\n      |   File \"/home/star/dev/DB-GPT/dbgpt/rag/retriever/base.py\", line 100, in aretrieve_with_scores\n      |     return await self._aretrieve_with_score(query, score_threshold, filters)\n      |   File \"/home/star/dev/DB-GPT/dbgpt/serve/rag/retriever/retriever_chain.py\", line 90, in _aretrieve_with_score\n      |     candidates_with_scores = await retriever.aretrieve_with_scores(\n      |   File \"/home/star/dev/DB-GPT/dbgpt/rag/retriever/base.py\", line 100, in aretrieve_with_scores\n      |     return await self._aretrieve_with_score(query, score_threshold, filters)\n      |   File \"/home/star/dev/DB-GPT/dbgpt/rag/retriever/embedding.py\", line 224, in _aretrieve_with_score\n      |     new_candidates_with_score = await self._rerank.arank(\n      |   File \"/home/star/dev/DB-GPT/dbgpt/rag/retriever/rerank.py\", line 312, in arank\n      |     rank_scores = await self._model.apredict(query, contents)\n      |   File \"/home/star/dev/DB-GPT/dbgpt/rag/embedding/rerank.py\", line 164, in apredict\n      |     return self._parse_results(response_data)\n      |   File \"/home/star/dev/DB-GPT/dbgpt/rag/embedding/rerank.py\", line 121, in _parse_results\n      |     raise RuntimeError(\"Cannot find results in the response\")\n      | RuntimeError: Cannot find results in the response\n      +------------------------------------\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 409, in run_asgi\n    result = await app(  # type: ignore[func-returns-value]\n  File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n    return await self.app(scope, receive, send)\n  File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n    await self.simple_response(scope, receive, send, request_headers=headers)\n  File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n    await self.app(scope, receive, send)\n  File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/fastapi/applications.py\", line 1054, in __call__\n    await super().__call__(scope, receive, send)\n  File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/applications.py\", line 113, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/errors.py\", line 187, in __call__\n    raise exc\n  File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    await self.app(scope, receive, _send)\n  File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/middleware/base.py\", line 185, in __call__\n    with collapse_excgroups():\n  File \"/root/miniconda3/envs/dbgpt/lib/python3.10/contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/_utils.py\", line 83, in collapse_excgroups\n    raise exc\n  File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/responses.py\", line 253, in wrap\n    await func()\n  File \"/root/miniconda3/envs/dbgpt/lib/python3.10/site-packages/starlette/responses.py\", line 242, in stream_response\n    async for chunk in self.body_iterator:\n  File \"/home/star/dev/DB-GPT/dbgpt/app/openapi/api_v1/api_v1.py\", line 673, in stream_generator\n    async for chunk in chat.stream_call():\n  File \"/home/star/dev/DB-GPT/dbgpt/app/scene/chat_knowledge/v1/chat.py\", line 116, in stream_call\n    async for output in super().stream_call():\n  File \"/home/star/dev/DB-GPT/dbgpt/app/scene/base_chat.py\", line 276, in stream_call\n    payload = await self._build_model_request()\n  File \"/home/star/dev/DB-GPT/dbgpt/app/scene/base_chat.py\", line 208, in _build_model_request\n    input_values = await self.generate_input_values()\n  File \"/home/star/dev/DB-GPT/dbgpt/util/tracer/tracer_impl.py\", line 217, in async_wrapper\n    return await func(*args, **kwargs)\n  File \"/home/star/dev/DB-GPT/dbgpt/app/scene/chat_knowledge/v1/chat.py\", line 157, in generate_input_values\n    candidates_with_scores = await run_async_tasks(tasks=tasks, concurrency_limit=1)\n  File \"/home/star/dev/DB-GPT/dbgpt/util/chat_util.py\", line 47, in run_async_tasks\n    return await _gather()\n  File \"/home/star/dev/DB-GPT/dbgpt/util/chat_util.py\", line 40, in _gather\n    return await asyncio.gather(\n  File \"/home/star/dev/DB-GPT/dbgpt/util/chat_util.py\", line 37, in _execute_task\n    return await task\n  File \"/home/star/dev/DB-GPT/dbgpt/app/scene/chat_knowledge/v1/chat.py\", line 260, in execute_similar_search\n    return await self._space_retriever.aretrieve_with_scores(\n  File \"/home/star/dev/DB-GPT/dbgpt/rag/retriever/base.py\", line 100, in aretrieve_with_scores\n    return await self._aretrieve_with_score(query, score_threshold, filters)\n  File \"/home/star/dev/DB-GPT/dbgpt/serve/rag/retriever/knowledge_space.py\", line 158, in _aretrieve_with_score\n    return await self._retriever_chain.aretrieve_with_scores(\n  File \"/home/star/dev/DB-GPT/dbgpt/rag/retriever/base.py\", line 100, in aretrieve_with_scores\n    return await self._aretrieve_with_score(query, score_threshold, filters)\n  File \"/home/star/dev/DB-GPT/dbgpt/serve/rag/retriever/retriever_chain.py\", line 90, in _aretrieve_with_score\n    candidates_with_scores = await retriever.aretrieve_with_scores(\n  File \"/home/star/dev/DB-GPT/dbgpt/rag/retriever/base.py\", line 100, in aretrieve_with_scores\n    return await self._aretrieve_with_score(query, score_threshold, filters)\n  File \"/home/star/dev/DB-GPT/dbgpt/rag/retriever/embedding.py\", line 224, in _aretrieve_with_score\n    new_candidates_with_score = await self._rerank.arank(\n  File \"/home/star/dev/DB-GPT/dbgpt/rag/retriever/rerank.py\", line 312, in arank\n    rank_scores = await self._model.apredict(query, contents)\n  File \"/home/star/dev/DB-GPT/dbgpt/rag/embedding/rerank.py\", line 164, in apredict\n    return self._parse_results(response_data)\n  File \"/home/star/dev/DB-GPT/dbgpt/rag/embedding/rerank.py\", line 121, in _parse_results\n    raise RuntimeError(\"Cannot find results in the response\")\nRuntimeError: Cannot find results in the response\n\n### What you expected to happen\n\nIt should return something.\n\n### How to reproduce\n\n1.Build the knowledge successfully.\n2.chat with the knowledge.\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "sliontc",
      "author_type": "User",
      "created_at": "2025-02-11T13:53:23Z",
      "updated_at": "2025-02-13T14:44:02Z",
      "closed_at": "2025-02-13T14:44:02Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2344/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2344",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2344",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:54.856533",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "try check here chunks is empty or chunks is filtered by score in chroma_store.py.\n```python\n    def similar_search_with_scores(\n        self, text, topk, score_threshold, filters: Optional[MetadataFilters] = None\n    ) -> List[Chunk]:\n        \"\"\"Search similar documents with scores.\n\n        Chroma ",
          "created_at": "2025-02-11T15:03:26Z"
        }
      ]
    },
    {
      "issue_number": 2243,
      "title": "[Feature][AWEL] Add chatDB  AWEL Workflow Template",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n希望官方可以提供一些chatDB相关的工作流模板，最好辅助前期查询参数优化调整的环节加入工作流中，比如查询条件中部分筛选条件在无法精确得知的前提下，可以去知识库中识别出用户意图的条件，对查询问题作出调整后，在生成sql\n\n### Use case\n\n 当前使用工作流大多是RAG类模板，没有数据库查询相结合的工作流FLOW模板，希望官方可以尽快更新些案例，感谢各位大佬们\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nHigh\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "uniquecdmx",
      "author_type": "User",
      "created_at": "2024-12-23T09:23:10Z",
      "updated_at": "2025-02-13T01:33:11Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2243/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2243",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2243",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:55.024889",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "Thanks, it will be implement soon.",
          "created_at": "2024-12-23T10:05:31Z"
        },
        {
          "author": "jackiemoo",
          "body": "强烈支持、建议",
          "created_at": "2025-01-02T01:21:53Z"
        },
        {
          "author": "duguwo",
          "body": "> ### Search before asking\n> * [x]  I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n> \n> ### Description\n> 希望官方可以提供一些chatDB相关的工作流模板，最好辅助前期查询参数优化调整的环节加入工作流中，比如查询条件中部分筛选条件在无法精确得知的前提下，可以去知识库中识别出用户意图的条件，对查询问题作出调整后，在生成sq",
          "created_at": "2025-02-13T01:33:10Z"
        }
      ]
    },
    {
      "issue_number": 2069,
      "title": "[Bug]chat excel cannot found where to upload file",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [X] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [X] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nEmbedding modeling: text2vec-large-chinese\n\n### What happened\n\n使用eosphorosai/dbgpt:latest镜像启动\r\n镜像的启动命令如下：\r\ndocker run  -d -p 3306:3306 -p 5670:5670 -e LLM_MODEL=proxyllm -e PROXY_API_KEY=$PROXY_API_KEY -e PROXY_SERVER_URL=$PROXY_SERVER_URL  -e LANGUAGE=zh -v /media/vdc/demo/DB-GPT-0.6.0/models/text2vec-large-chinese:/app/models/text2vec-large-chinese --name dbgpt eosphorosai/dbgpt\r\n\r\n然后在web门户创建chat excel应用，进入应用对话，没有找到和[http://docs.dbgpt.cn/docs/application/apps/chat_excel里面描述的上传excel的按钮！](http://docs.dbgpt.cn/docs/application/apps/chat_excel%E9%87%8C%E9%9D%A2%E6%8F%8F%E8%BF%B0%E7%9A%84%E4%B8%8A%E4%BC%A0excel%E7%9A%84%E6%8C%89%E9%92%AE%EF%BC%81)\r\n\r\n![image](https://github.com/user-attachments/assets/654b7275-e430-4c24-ba88-f4024f287523)\r\n\r\n![image](https://github.com/user-attachments/assets/9a511615-0edb-4ff4-9457-d3c150495fed)\r\n\r\n\n\n### What you expected to happen\n\n能提供上传excel文档的地方\n\n### How to reproduce\n\n使用上面镜像启动就能复现\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "jicanghaixb",
      "author_type": "User",
      "created_at": "2024-10-15T08:11:24Z",
      "updated_at": "2025-02-12T08:21:40Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2069/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2069",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2069",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:55.197728",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "![image](https://github.com/user-attachments/assets/c3a0e580-47b8-4638-8c5d-dbb95abb0a28)\r\n",
          "created_at": "2024-10-16T15:43:46Z"
        },
        {
          "author": "jicanghaixb",
          "body": "我用的是proxyllm，你这个界面我怎么找不到？是从哪个地方进去的？\r\n在下面这个chat excel应用里面点击里面的chat按钮\r\n![image](https://github.com/user-attachments/assets/ff6e064f-3381-4876-b501-f893ecb9dbbe)\r\n我这边显示的是下面这个界面，没有看到你上面的那个界面\r\n![image](https://github.com/user-attachments/assets/bcdd39f3-52f6-47aa-8dfb-ab82759c120c)\r\n",
          "created_at": "2024-10-17T07:02:10Z"
        },
        {
          "author": "xiaoranchenwai",
          "body": "> 我用的是proxyllm，你这个界面我怎么找不到？是从哪个地方进去的？ 在下面这个chat excel应用里面点击里面的chat按钮 ![image](https://private-user-images.githubusercontent.com/25758705/377348245-ff6e064f-3381-4876-b501-f893ecb9dbbe.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSI",
          "created_at": "2024-10-17T10:01:01Z"
        },
        {
          "author": "lg836",
          "body": "docker是0.6，在ubuntu上，EDGE浏览器，不显示上传按钮，你用Windows电脑访问，就没问题。",
          "created_at": "2024-10-27T01:53:09Z"
        },
        {
          "author": "jicanghaixb",
          "body": "这个UI不兼容linux的浏览器？我也是在linux上使用chrome访问，不显示上传按钮？",
          "created_at": "2024-10-28T01:05:07Z"
        }
      ]
    },
    {
      "issue_number": 2062,
      "title": "[Doc][Module Name] Documentation bug or improvement",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nWhen using the text2sql function, the doc doesn't say what should I do after adding the database. I want to query in natural language and get some result from my mysql database. But it keeps showing that there is no table structure. \n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Carlycjl",
      "author_type": "User",
      "created_at": "2024-10-13T09:01:51Z",
      "updated_at": "2025-02-11T21:04:56Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2062/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2062",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2062",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:55.402648",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "could you show some related logs?",
          "created_at": "2024-10-14T02:11:42Z"
        },
        {
          "author": "Carlycjl",
          "body": "> could you show some related logs?\r\n![1728877662231](https://github.com/user-attachments/assets/ab87469f-39b7-4318-a81b-4dac618e6201)\r\nI have already connected to mysql.\r\n![1728877769401](https://github.com/user-attachments/assets/e6029cce-52a8-438c-b61a-f09ad9a17335)\r\n![1728877873058](https://gith",
          "created_at": "2024-10-14T03:52:10Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-02-11T21:04:53Z"
        }
      ]
    },
    {
      "issue_number": 2063,
      "title": "[Feature]user/tenant isolation",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n租户数据无法隔离\n\n### Use case\n\n租户数据无法隔离\n\n### Related issues\n\n租户数据无法隔离\n\n### Feature Priority\n\nHigh\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "fengdezhen666",
      "author_type": "User",
      "created_at": "2024-10-14T01:18:11Z",
      "updated_at": "2025-02-11T21:04:54Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2063/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2063",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2063",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:55.598363",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "We have reserved sys_code and user_code, and need to implement user/tenant isolation by ourselves",
          "created_at": "2024-10-14T01:56:19Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-02-11T21:04:52Z"
        }
      ]
    },
    {
      "issue_number": 2343,
      "title": "[Bug] DBchat功能 设置了mysql连接 但是提问时不进行前置数据库结构查询",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [x] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [x] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n使用的是 智普glm4模型 \n模型配置如下\n\nLLM_MODEL=zhipu_proxyllm\nPROXY_SERVER_URL=https://open.bigmodel.cn/api/paas/v4/chat/completions\nZHIPU_MODEL_VERSION=glm-4-plus\nZHIPU_PROXY_API_KEY=xxx\nPROXY_API_KEY=xxx\n\nEMBEDDING_MODEL=proxy_ollama\nproxy_ollama_proxy_server_url=http://192.168.2.92:11434 \nproxy_ollama_proxy_backend=bge-m3:latest\n\n![Image](https://github.com/user-attachments/assets/9f158f49-7d85-42d8-8528-4eb2f048061e)\n\n![Image](https://github.com/user-attachments/assets/3b09f273-cb0f-49e9-9a4f-c5230c58220a)\n\n### Models information\n\nLLM_MODEL=zhipu_proxyllm\nPROXY_SERVER_URL=https://open.bigmodel.cn/api/paas/v4/chat/completions\nZHIPU_MODEL_VERSION=glm-4-plus\nZHIPU_PROXY_API_KEY=xxx\nPROXY_API_KEY=xxx\n\nEMBEDDING_MODEL=proxy_ollama\nproxy_ollama_proxy_server_url=http://192.168.2.92:11434/\nproxy_ollama_proxy_backend=bge-m3:latest\n\n### What happened\n\n正常情况应该是我提问后 会去查询对应数据库的表结构数据 然后将表结构数据返回作为提交给模型的一部分提问参数进行提问的 根据截图直接跳过了查询结构这一个过程 导致无法正常进行对话过程\n\n### What you expected to happen\n\n希望可以解答一下我是否有哪些配置是错误的\n\n### How to reproduce\n\n就正常启动 然后配置对应的数据库 而且的我数据库与db-gpt是同一个数据库实例 所以不存在网络问题 而且在添加db时如果有网络问题也会报错提示的  我试了添加几个其他的数据库也不能正常使用\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "newShiJ",
      "author_type": "User",
      "created_at": "2025-02-11T08:06:15Z",
      "updated_at": "2025-02-11T08:22:23Z",
      "closed_at": "2025-02-11T08:22:23Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2343/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2343",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2343",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:55.779184",
      "comments": []
    },
    {
      "issue_number": 2059,
      "title": "[Bug] [Module Name] Bug title ",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [X] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n-GPU Count：2 -GPU Memory：22G\n\n### Models information\n\nLLM：zhipu_proxyllm Embedding model:text2vec-large-chinese\n\n### What happened\n\n2024-10-11 16:20:30 gpu-172-16-19-208 dbgpt.serve.core.schemas[17241] ERROR common_exception_handler catch Exception: success=False err_code='E0003' err_msg='(pymysql.err.OperationalError) (1054, \"Unknown column \\'(\\' in \\'field list\\'\")\\n[SQL: \\n                select concat(table_name, \"(\" , group_concat(column_name), \")\")\\n                as schema_info from information_schema.COLUMNS where\\n                table_schema=\"hy_dw_test\" group by TABLE_NAME;\\n            ]\\n(Background on this error at: https://sqlalche.me/e/20/e3q8)' data=None\r\nERROR:    Exception in ASGI application\r\nTraceback (most recent call last):\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1970, in _exec_single_context\r\n    self.dialect.do_execute(\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py\", line 924, in do_execute\r\n    cursor.execute(statement, parameters)\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/pymysql/cursors.py\", line 153, in execute\r\n    result = self._query(query)\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/pymysql/cursors.py\", line 322, in _query\r\n    conn.query(q)\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/pymysql/connections.py\", line 563, in query\r\n    self._affected_rows = self._read_query_result(unbuffered=unbuffered)\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/pymysql/connections.py\", line 825, in _read_query_result\r\n    result.read()\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/pymysql/connections.py\", line 1199, in read\r\n    first_packet = self.connection._read_packet()\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/pymysql/connections.py\", line 775, in _read_packet\r\n    packet.raise_for_error()\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/pymysql/protocol.py\", line 219, in raise_for_error\r\n    err.raise_mysql_exception(self._data)\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/pymysql/err.py\", line 150, in raise_mysql_exception\r\n    raise errorclass(errno, errval)\r\npymysql.err.OperationalError: (1054, \"Unknown column '(' in 'field list'\")\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 399, in run_asgi\r\n    result = await app(  # type: ignore[func-returns-value]\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py\", line 70, in __call__\r\n    return await self.app(scope, receive, send)\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/starlette/middleware/cors.py\", line 93, in __call__\r\n    await self.simple_response(scope, receive, send, request_headers=headers)\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/starlette/middleware/cors.py\", line 148, in simple_response\r\n    await self.app(scope, receive, send)\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/fastapi/applications.py\", line 1054, in __call__\r\n    await super().__call__(scope, receive, send)\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/starlette/applications.py\", line 123, in __call__\r\n    await self.middleware_stack(scope, receive, send)\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/starlette/middleware/errors.py\", line 186, in __call__\r\n    raise exc\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/starlette/middleware/errors.py\", line 164, in __call__\r\n    await self.app(scope, receive, _send)\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/starlette/middleware/base.py\", line 189, in __call__\r\n    with collapse_excgroups():\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/contextlib.py\", line 153, in __exit__\r\n    self.gen.throw(typ, value, traceback)\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/starlette/_utils.py\", line 93, in collapse_excgroups\r\n    raise exc\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/starlette/responses.py\", line 261, in wrap\r\n    await func()\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/starlette/responses.py\", line 250, in stream_response\r\n    async for chunk in self.body_iterator:\r\n  File \"/home/gqa/zhp/DB-GPT6.10/DB-GPT/dbgpt/app/openapi/api_v1/api_v1.py\", line 649, in no_stream_generator\r\n    msg = await chat.nostream_call()\r\n  File \"/home/gqa/zhp/DB-GPT6.10/DB-GPT/dbgpt/app/scene/base_chat.py\", line 304, in nostream_call\r\n    payload = await self._build_model_request()\r\n  File \"/home/gqa/zhp/DB-GPT6.10/DB-GPT/dbgpt/app/scene/base_chat.py\", line 208, in _build_model_request\r\n    input_values = await self.generate_input_values()\r\n  File \"/home/gqa/zhp/DB-GPT6.10/DB-GPT/dbgpt/util/tracer/tracer_impl.py\", line 217, in async_wrapper\r\n    return await func(*args, **kwargs)\r\n  File \"/home/gqa/zhp/DB-GPT6.10/DB-GPT/dbgpt/app/scene/chat_dashboard/chat.py\", line 78, in generate_input_values\r\n    \"table_info\": self.database.table_simple_info(),\r\n  File \"/home/gqa/zhp/DB-GPT6.10/DB-GPT/dbgpt/datasource/rdbms/base.py\", line 177, in table_simple_info\r\n    cursor = self.session.execute(text(_sql))\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py\", line 2306, in execute\r\n    return self._execute_internal(\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py\", line 2200, in _execute_internal\r\n    result = conn.execute(\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1421, in execute\r\n    return meth(\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py\", line 514, in _execute_on_connection\r\n    return connection._execute_clauseelement(\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1643, in _execute_clauseelement\r\n    ret = self._execute_context(\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1849, in _execute_context\r\n    return self._exec_single_context(\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1989, in _exec_single_context\r\n    self._handle_dbapi_exception(\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 2356, in _handle_dbapi_exception\r\n    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1970, in _exec_single_context\r\n    self.dialect.do_execute(\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py\", line 924, in do_execute\r\n    cursor.execute(statement, parameters)\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/pymysql/cursors.py\", line 153, in execute\r\n    result = self._query(query)\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/pymysql/cursors.py\", line 322, in _query\r\n    conn.query(q)\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/pymysql/connections.py\", line 563, in query\r\n    self._affected_rows = self._read_query_result(unbuffered=unbuffered)\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/pymysql/connections.py\", line 825, in _read_query_result\r\n    result.read()\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/pymysql/connections.py\", line 1199, in read\r\n    first_packet = self.connection._read_packet()\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/pymysql/connections.py\", line 775, in _read_packet\r\n    packet.raise_for_error()\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/pymysql/protocol.py\", line 219, in raise_for_error\r\n    err.raise_mysql_exception(self._data)\r\n  File \"/DATA/anaconda3/envs/zhp_env/lib/python3.10/site-packages/pymysql/err.py\", line 150, in raise_mysql_exception\r\n    raise errorclass(errno, errval)\r\nsqlalchemy.exc.OperationalError: (pymysql.err.OperationalError) (1054, \"Unknown column '(' in 'field list'\")\r\n[SQL: \r\n                select concat(table_name, \"(\" , group_concat(column_name), \")\")\r\n                as schema_info from information_schema.COLUMNS where\r\n                table_schema=\"hy_dw_test\" group by TABLE_NAME;\r\n            ]\r\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\n\n### What you expected to happen\n\n运行成功\n\n### How to reproduce\n\nSee Error\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "DocKris",
      "author_type": "User",
      "created_at": "2024-10-11T08:28:14Z",
      "updated_at": "2025-02-08T21:05:02Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2059/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2059",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2059",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:55.779206",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-02-08T21:05:01Z"
        }
      ]
    },
    {
      "issue_number": 2331,
      "title": "[bug]Install Financial Report v0.5.10 Error",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\devpinstall\\anaconda3\\envs\\dbgpt_env\\lib\\site-packages\\uvicorn\\protocols\\http\\httptools_impl.py\", line 419, in run_asgi\n    result = await app(  # type: ignore[func-returns-value]\n  File \"D:\\devpinstall\\anaconda3\\envs\\dbgpt_env\\lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 78, in __call__\n    return await self.app(scope, receive, send)\n  File \"D:\\devpinstall\\anaconda3\\envs\\dbgpt_env\\lib\\site-packages\\starlette\\middleware\\cors.py\", line 93, in __call__\n    await self.simple_response(scope, receive, send, request_headers=headers)\n  File \"D:\\devpinstall\\anaconda3\\envs\\dbgpt_env\\lib\\site-packages\\starlette\\middleware\\cors.py\", line 148, in simple_response\n    await self.app(scope, receive, send)\n  File \"D:\\devpinstall\\anaconda3\\envs\\dbgpt_env\\lib\\site-packages\\fastapi\\applications.py\", line 1054, in __call__\n    await super().__call__(scope, receive, send)\n  File \"D:\\devpinstall\\anaconda3\\envs\\dbgpt_env\\lib\\site-packages\\starlette\\applications.py\", line 123, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"D:\\devpinstall\\anaconda3\\envs\\dbgpt_env\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 186, in __call__\n    raise exc\n  File \"D:\\devpinstall\\anaconda3\\envs\\dbgpt_env\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 164, in __call__\n    await self.app(scope, receive, _send)\n  File \"D:\\devpinstall\\anaconda3\\envs\\dbgpt_env\\lib\\site-packages\\starlette\\middleware\\base.py\", line 189, in __call__\n    with collapse_excgroups():\n  File \"D:\\devpinstall\\anaconda3\\envs\\dbgpt_env\\lib\\contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"D:\\devpinstall\\anaconda3\\envs\\dbgpt_env\\lib\\site-packages\\starlette\\_utils.py\", line 89, in collapse_excgroups\n    raise exc\n  File \"D:\\devpinstall\\anaconda3\\envs\\dbgpt_env\\lib\\site-packages\\starlette\\responses.py\", line 261, in wrap\n    await func()\n  File \"D:\\devpinstall\\anaconda3\\envs\\dbgpt_env\\lib\\site-packages\\starlette\\responses.py\", line 250, in stream_response\n    async for chunk in self.body_iterator:\n  File \"F:\\pyproject\\DB-GPT\\dbgpt\\app\\openapi\\api_v1\\api_v1.py\", line 933, in chat_with_domain_flow\n    raise ValueError(f\"Cant find the DAG for domain type {domain_type}\")\nValueError: Cant find the DAG for domain type FinancialReport\n\n### Use case\n\n当按照0.5.10 搭建财报分析助手后，进行对话时出现上述异常\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "gezongyang",
      "author_type": "User",
      "created_at": "2025-02-07T02:46:04Z",
      "updated_at": "2025-02-08T03:33:51Z",
      "closed_at": "2025-02-08T03:33:51Z",
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2331/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2331",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2331",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:56.005029",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "try install follow https://www.yuque.com/eosphoros/dbgpt-docs/fwy03x9ygqtbsuno",
          "created_at": "2025-02-07T09:56:33Z"
        },
        {
          "author": "gezongyang",
          "body": "> try install follow https://www.yuque.com/eosphoros/dbgpt-docs/fwy03x9ygqtbsuno\n您好，按照上述操作后，还是报这个错\n\n",
          "created_at": "2025-02-07T10:00:55Z"
        },
        {
          "author": "Aries-ckt",
          "body": "看下awel界面是否安装成功了？\n",
          "created_at": "2025-02-07T10:02:59Z"
        },
        {
          "author": "gezongyang",
          "body": "> 看下awel界面是否安装成功了？\n这两个awel流 financial-report-knowledge-factory 和financial-robot-app都安装成功的，当domain_type为FinancialReport的知识库访问时会出现此异常",
          "created_at": "2025-02-07T10:15:39Z"
        },
        {
          "author": "gezongyang",
          "body": "我搭一套新环境看看是否还有此问题",
          "created_at": "2025-02-07T10:18:15Z"
        }
      ]
    },
    {
      "issue_number": 2050,
      "title": "[Bug] does the latest version remove the editing mode in the dialogue model? Can I keep the editing mode?",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [X] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [X] Other\n\n### Device information\n\n[Bug] 请问最新的版本是把对话模型中的编辑模式去掉了吗？ 现在哪个图标很像是编辑，但是点击是复制的功能，请问可以保留编辑模式吗？\n\n### Models information\n\n[Bug] 请问最新的版本是把对话模型中的编辑模式去掉了吗？ 现在哪个图标很像是编辑，但是点击是复制的功能，请问可以保留编辑模式吗？\n\n### What happened\n\n[Bug] 请问最新的版本是把对话模型中的编辑模式去掉了吗？ 现在哪个图标很像是编辑，但是点击是复制的功能，请问可以保留编辑模式吗？\n\n### What you expected to happen\n\n[Bug] 请问最新的版本是把对话模型中的编辑模式去掉了吗？ 现在哪个图标很像是编辑，但是点击是复制的功能，请问可以保留编辑模式吗？\n\n### How to reproduce\n\n[Bug] 请问最新的版本是把对话模型中的编辑模式去掉了吗？ 现在哪个图标很像是编辑，但是点击是复制的功能，请问可以保留编辑模式吗？\n\n### Additional context\n\n[Bug] 请问最新的版本是把对话模型中的编辑模式去掉了吗？ 现在哪个图标很像是编辑，但是点击是复制的功能，请问可以保留编辑模式吗？\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "ChainSong",
      "author_type": "User",
      "created_at": "2024-09-29T11:07:54Z",
      "updated_at": "2025-02-07T21:04:43Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2050/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2050",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2050",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:56.195201",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "could you show the screen shot in your env?",
          "created_at": "2024-10-07T15:01:11Z"
        },
        {
          "author": "ChainSong",
          "body": "Thanks for your reply, I used the old UI interface and found the function I needed. But I have other questions. I have edited the new sql and saved it. Will I use my edited sql to query and feedback the results when I ask the same question next time?",
          "created_at": "2024-10-10T10:07:56Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-02-07T21:04:41Z"
        }
      ]
    },
    {
      "issue_number": 2058,
      "title": "[Bug] [AWEL workflow] Using AWEL workflow created by Prompt, some results are not fully displayed when you output them.",
      "body": "### Search before asking\r\n\r\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\r\n\r\n\r\n### Operating system information\r\n\r\nLinux\r\n\r\n### Python version information\r\n\r\n3.10\r\n\r\n### DB-GPT version\r\n\r\nmain\r\n\r\n### Related scenes\r\n\r\n- [ ] Chat Data\r\n- [ ] Chat Excel\r\n- [ ] Chat DB\r\n- [ ] Chat Knowledge\r\n- [ ] Model Management\r\n- [ ] Dashboard\r\n- [ ] Plugins\r\n\r\n### Installation Information\r\n\r\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\r\n\r\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\r\n\r\n- [ ] AutoDL Image\r\n- [ ] Other\r\n\r\n### Device information\r\n\r\nDevice:CPU\r\n\r\n### Models information\r\n\r\nLLM:Proxy LLM\r\n\r\n### What happened\r\n\r\nUsing AWEL workflow created by Prompt, some results are not fully displayed when you output them.\r\nAWEL workflow:\r\n![image](https://github.com/user-attachments/assets/f6b8b5d6-3c67-4b81-99c0-305161c20260)\r\n\r\nCreateApp:\r\n![image](https://github.com/user-attachments/assets/92a8e15b-5118-4827-b7e5-bdb4dc25c190)\r\n\r\nChat App:\r\n![image](https://github.com/user-attachments/assets/9fefbd1d-6187-4a50-9d68-d659aab18c84)\r\n\r\nServer log:\r\nfull stream output:\r\n好的，我会为你生成一个完整的JSP文件示例，该文件包含一个用户登录表单，表单中有用户名和密码字段以及一个提交按钮，并使用CSS进行样式设计。\r\n\r\n### 创建JSP文件\r\n\r\n首先，创建一个名为 `login.jsp` 的JSP文件。\r\n\r\n```jsp\r\n<!-- filename: login.jsp -->\r\n<%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %>\r\n<!DOCTYPE html>\r\n<html lang=\"en\">\r\n<head>\r\n    <meta charset=\"UTF-8\">\r\n    <title>Login Page</title>\r\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"css/styles.css\">\r\n</head>\r\n<body>\r\n    <div class=\"login-container\">\r\n        <h2>Login</h2>\r\n        <form action=\"loginServlet\" method=\"post\">\r\n            <div class=\"form-group\">\r\n                <label for=\"username\">Username:</label>\r\n                <input type=\"text\" id=\"username\" name=\"username\" required>\r\n            </div>\r\n            <div class=\"form-group\">\r\n                <label for=\"password\">Password:</label>\r\n                <input type=\"password\" id=\"password\" name=\"password\" required>\r\n            </div>\r\n            <div class=\"form-group\">\r\n                <button type=\"submit\">Login</button>\r\n            </div>\r\n        </form>\r\n    </div>\r\n</body>\r\n</html>\r\n```\r\n\r\n### 创建CSS文件\r\n\r\n接下来，创建一个名为 `styles.css` 的CSS文件，用于样式设计。\r\n\r\n```css\r\n/* filename: styles.css */\r\nbody {\r\n    font-family: Arial, sans-serif;\r\n    background-color: #f4f4f4;\r\n    display: flex;\r\n    justify-content: center;\r\n    align-items: center;\r\n    height: 100vh;\r\n    margin: 0;\r\n}\r\n\r\n.login-container {\r\n    background-color: #fff;\r\n    padding: 20px;\r\n    border-radius: 5px;\r\n    box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);\r\n    width: 300px;\r\n    text-align: center;\r\n}\r\n\r\nh2 {\r\n    margin-bottom: 20px;\r\n}\r\n\r\n.form-group {\r\n    margin-bottom: 15px;\r\n    text-align: left;\r\n}\r\n\r\nlabel {\r\n    display: block;\r\n    margin-bottom: 5px;\r\n}\r\n\r\ninput[type=\"text\"],\r\ninput[type=\"password\"] {\r\n    width: 100%;\r\n    padding: 8px;\r\n    box-sizing: border-box;\r\n}\r\n\r\nbutton {\r\n    width: 100%;\r\n    padding: 10px;\r\n    background-color: #007bff;\r\n    border: none;\r\n    color: white;\r\n    border-radius: 5px;\r\n    cursor: pointer;\r\n}\r\n\r\nbutton:hover {\r\n    background-color: #0056b3;\r\n}\r\n```\r\n\r\n### 部署和运行\r\n\r\n将 `login.jsp` 和 `styles.css` 文件放置在你的Web应用程序的适当目录中（例如，JSP文件放在 `webapp` 目录下，CSS文件放在 `webapp/css` 目录下）。然后启动你的Web服务器（如Tomcat），访问 `login.jsp` 页面。\r\n\r\n### 访问页面\r\n\r\n在浏览器中访问 `http://localhost:8080/yourapp/login.jsp`，你将看到一个经过样式设计的登录页面，包含用户名和密码字段以及提交按钮。\r\n\r\n这个示例展示了如何使用JSP和CSS来创建一个简单的登录页面。如果你有更多具体的需求或需要进一步的定制，请告诉我。\r\n\r\nmodel generate_stream params:\r\n{'model': 'gpt4o', 'messages': [ModelMessage(role='human', content='You are a AI Code Assistant. xxxxxxx \\n\\n用户输入: 使用jsp写一个登录页面\\n'}\r\nun_stream ai response:  访问页面\r\n\r\n在浏览器中访问 `http://localhost:8080/yourapp/login.jsp`，你将看到一个经过样式设计的登录页面，包含用户名和密码字段以及提交按钮。\r\n\r\n这个示例展示了如何使用JSP和CSS来创建一个简单的登录页面。如果你有更多具体的需求或需要进一步的定制，请告诉我。\r\n\r\n--------------------------------------------------------------------------------\r\nTom (to User)-[gpt4o]:\r\n\r\n\"访问页面\\n\\n在浏览器中访问 `http://localhost:8080/yourapp/login.jsp`，你将看到一个经过样式设计的登录页面，包含用户名和密码字段以及提交按钮。\\n\\n这个示例展示了如何使用JSP和CSS来创建一个简单的登录页面。如果你有更多具体的需求或需要进一步的定制，请告诉我。\"\r\n>>>>>>>>Tom Review info: \r\nPass(None)\r\n>>>>>>>>Tom Action report: \r\nexecution succeeded,\r\n访问页面\r\n\r\n在浏览器中访问 `http://localhost:8080/yourapp/login.jsp`，你将看到一个经过样式设计的登录页面，包含用户名和密码字段以及提交按钮。\r\n\r\n这个示例展示了如何使用JSP和CSS来创建一个简单的登录页面。如果你有更多具体的需求或需要进一步的定制，请告诉我。\r\n\r\n--------------------------------------------------------------------------------\r\n2024-10-10 12:14:53 dbgpt.serve.agent.agents.controller[1731959] INFO save agent chat info！044cd85f-86be-11ef-bd83-42b90711c055\r\n2024-10-10 12:15:17 dbgpt.serve.agent.app.controller[1731959] INFO app_detail:chat_normal,None\r\n\r\nThrough the log output information, the page display information is incomplete.\r\nThe page shows only the final results of the answers, not all of them.\r\n\r\n\r\n\r\n### What you expected to happen\r\n\r\nShow all answers.\r\n\r\n### How to reproduce\r\n\r\nNone\r\n\r\n### Additional context\r\n\r\nNone\r\n\r\n### Are you willing to submit PR?\r\n\r\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Hec-gitHub",
      "author_type": "User",
      "created_at": "2024-10-10T05:53:53Z",
      "updated_at": "2025-02-07T21:04:42Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2058/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2058",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2058",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:56.409023",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-02-07T21:04:40Z"
        }
      ]
    },
    {
      "issue_number": 2287,
      "title": " Check database migration status failed, you can see the error and solutions above",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [X] Other\n\n### Device information\n\n123213\n\n### Models information\n\n ERROR | dbgpt.util._db_migration_utils | Failed to check database migration status: Check database migration status failed, you can see the error and solutions above\r\nTraceback (most recent call last):\r\n  File \"D:\\xnhj\\DB-GPT-main\\dbgpt\\app\\dbgpt_server.py\", line 289, in <module>\r\n    run_webserver()\r\n  File \"D:\\xnhj\\DB-GPT-main\\dbgpt\\app\\dbgpt_server.py\", line 275, in run_webserver\r\n    param = initialize_app(param)\r\n  File \"D:\\xnhj\\DB-GPT-main\\dbgpt\\app\\dbgpt_server.py\", line 182, in initialize_app\r\n    _migration_db_storage(param)\r\n  File \"d:\\xnhj\\db-gpt-main\\dbgpt\\app\\base.py\", line 86, in _migration_db_storage\r\n    _ddl_init_and_upgrade(default_meta_data_path, param.disable_alembic_upgrade)\r\n  File \"d:\\xnhj\\db-gpt-main\\dbgpt\\util\\_db_migration_utils.py\", line 353, in _ddl_init_and_upgrade\r\n    _check_database_migration_status(alembic_cfg, db.engine)\r\n  File \"d:\\xnhj\\db-gpt-main\\dbgpt\\util\\_db_migration_utils.py\", line 278, in _check_database_migration_status\r\n    raise Exception(\r\nException: Check database migration status failed, you can see the error and solutions above\n\n### What happened\n\n11112312\n\n### What you expected to happen\n\n112312\n\n### How to reproduce\n\n121321\n\n### Additional context\n\n怎么解决这个问题？\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "sy960923",
      "author_type": "User",
      "created_at": "2025-01-08T07:53:48Z",
      "updated_at": "2025-02-07T06:36:31Z",
      "closed_at": "2025-01-09T07:36:25Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 12,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2287/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2287",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2287",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:56.614937",
      "comments": [
        {
          "author": "sy960923",
          "body": "而且运行还报错2025-01-08 16:49:09 | INFO | alembic.runtime.migration | Context impl SQLiteImpl.\r\n2025-01-08 16:49:09 | INFO | alembic.runtime.migration | Will assume non-transactional DDL.\r\n2025-01-08 16:49:09 | INFO | alembic.runtime.migration | Running upgrade a51b1150a7fe -> c66dd2c293d4, New migration\r",
          "created_at": "2025-01-08T09:00:40Z"
        },
        {
          "author": "fangyinc",
          "body": "Hi @sy960923 \r\ncan you try  [Q9: alembic.util.exc.CommandError: Target database is not up to date](http://docs.dbgpt.cn/docs/faq/install#q9-alembicutilexccommanderror-target-database-is-not-up-to-date) ?",
          "created_at": "2025-01-08T09:43:28Z"
        },
        {
          "author": "sy960923",
          "body": "> Hi @sy960923 can you try [Q9: alembic.util.exc.CommandError: Target database is not up to date](http://docs.dbgpt.cn/docs/faq/install#q9-alembicutilexccommanderror-target-database-is-not-up-to-date) ?\r\npython dbgpt/app/dbgpt_server.py --disable_alembic_upgrade我使用这个命令运行起来了，excel对话 他是自己创建数据库表了嘛？\r\n\r\n",
          "created_at": "2025-01-08T09:50:03Z"
        },
        {
          "author": "fangyinc",
          "body": "Hi, @sy960923.\r\n\r\nStep 1,  try fix migration error according to [Q9: alembic.util.exc.CommandError: Target database is not up to date](http://docs.dbgpt.cn/docs/faq/install#q9-alembicutilexccommanderror-target-database-is-not-up-to-date)\r\n\r\nStep2, start your DB-GPT webserver by command `dbgpt start ",
          "created_at": "2025-01-08T09:58:39Z"
        },
        {
          "author": "sy960923",
          "body": "> Hi, @sy960923.\r\n> \r\n> Step 1, try fix migration error according to [Q9: alembic.util.exc.CommandError: Target database is not up to date](http://docs.dbgpt.cn/docs/faq/install#q9-alembicutilexccommanderror-target-database-is-not-up-to-date)\r\n> \r\n> Step2, start your DB-GPT webserver by command `dbg",
          "created_at": "2025-01-08T10:02:20Z"
        }
      ]
    },
    {
      "issue_number": 2049,
      "title": " When will the model on autodl be updated?",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nautodl 上原有的在对话模型=> 编辑模式下面run & save 都不能用\n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "ChainSong",
      "author_type": "User",
      "created_at": "2024-09-29T07:40:40Z",
      "updated_at": "2025-02-04T21:04:50Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2049/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2049",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2049",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:56.809193",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-02-04T21:04:48Z"
        }
      ]
    },
    {
      "issue_number": 2046,
      "title": "[Feature]support for importing knowledge graph from tu-graph to knowledge base",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n请问，是否能够反向支持从tu-graph导入知识图到知识库？\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "RyanFlying",
      "author_type": "User",
      "created_at": "2024-09-27T09:15:00Z",
      "updated_at": "2025-01-27T21:04:49Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2046/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2046",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2046",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:56.985635",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "hi, @RyanFlying ,Good Suggestion, we will consider into it.",
          "created_at": "2024-09-29T01:36:32Z"
        },
        {
          "author": "RyanFlying",
          "body": "> hi, @RyanFlying ,Good Suggestion, we will consider into it.\r\n\r\n能否拉我到微信群，我看你们的微信群二维码过期了",
          "created_at": "2024-09-29T01:39:22Z"
        },
        {
          "author": "Aries-ckt",
          "body": "sure,  \r\n![image](https://github.com/user-attachments/assets/46255969-6e07-458a-844c-c692a100a4a5)\r\n",
          "created_at": "2024-09-29T02:27:15Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-27T21:04:48Z"
        }
      ]
    },
    {
      "issue_number": 2047,
      "title": "[Feature]Support connection to Oracle",
      "body": null,
      "state": "open",
      "author": "Panda-Panda-new",
      "author_type": "User",
      "created_at": "2024-09-27T10:04:15Z",
      "updated_at": "2025-01-27T21:04:48Z",
      "closed_at": null,
      "labels": [
        "stale"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2047/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2047",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2047",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:57.203705",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "hi, @panda4444ssdfs , test at the pr https://github.com/eosphoros-ai/DB-GPT/pull/1628",
          "created_at": "2024-09-29T01:35:46Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-27T21:04:46Z"
        }
      ]
    },
    {
      "issue_number": 2326,
      "title": "[Feature][Module Name] Tugraph conn auth when graph project exists",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n大佬们，在使用图数据库中，因为安全考虑，不能直接给用户admin账号，而tugraph的鉴权是必须先admin账号创建图项目后把这个图项目分配给用户后用户才能使用，用户没有权限去新建一个项目。因此在使用过程中，往往是已经有了图库后再连接dbgpt使用的，而目前dbgpt的逻辑是先创建这个项目空间 :)\n我修改的话在tugraph_store_adapter.py中执行conn.create_graph先做了次is_exist判断，希望大佬能实现这个功能 \n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "paul-yangmy",
      "author_type": "User",
      "created_at": "2025-01-26T02:43:01Z",
      "updated_at": "2025-01-26T02:48:40Z",
      "closed_at": "2025-01-26T02:48:40Z",
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2326/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2326",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2326",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:59.212584",
      "comments": []
    },
    {
      "issue_number": 2036,
      "title": "[Doc][OPENAI]嵌入模型和总结模型都是openai api，源码部署运行脚本时，说缺model_path，但是没有，咋填？文档没有提示，写None也没用",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n嵌入模型和总结模型都是openai api，源码部署运行脚本时，说缺model_path，但是没有，咋填？文档没有提示，写None也没用\r\n![image](https://github.com/user-attachments/assets/0d2821a3-f9f5-47b4-bd54-00c94a2fb19e)\r\n\n\n### Documentation Links\n\nhttps://docs.dbgpt.site/docs/faq/install\r\n\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "CatyWong10086",
      "author_type": "User",
      "created_at": "2024-09-22T13:25:17Z",
      "updated_at": "2025-01-25T21:04:41Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2036/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2036",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2036",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:59.212615",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "embedding model use openai\r\n```\r\n#EMBEDDING_MODEL=proxy_openai\r\n#proxy_openai_proxy_server_url=http://xxx/api/openai/v1\r\n#proxy_openai_proxy_api_key=sk-xx\r\n#proxy_openai_proxy_backend=text-embedding-ada-002\r\n```\r\n\r\nllm service use openai\r\n```\r\nPROXY_API_KEY=sk-xxx\r\nPROXY_SERVER_URL=http://xxx/api/op",
          "created_at": "2024-09-25T01:46:07Z"
        },
        {
          "author": "ychuest",
          "body": "> 嵌入模型使用 openai\r\n> \r\n> ```\r\n> #EMBEDDING_MODEL=proxy_openai\r\n> #proxy_openai_proxy_server_url=http://xxx/api/openai/v1\r\n> #proxy_openai_proxy_api_key=sk-xx\r\n> #proxy_openai_proxy_backend=text-embedding-ada-002\r\n> ```\r\n> \r\n> llm 服务使用 openai\r\n> \r\n> ```\r\n> PROXY_API_KEY=sk-xxx\r\n> PROXY_SERVER_URL=http:",
          "created_at": "2024-09-27T06:38:32Z"
        },
        {
          "author": "riverhell",
          "body": "LLM_MODEL=proxyllm\r\nPROXY_SERVER_URL=http://172.16.15.242:8000/v1/chat/completions\r\nPROXYLLM_BACKEND=qwen2_5-14b-instruct",
          "created_at": "2024-09-27T07:32:54Z"
        },
        {
          "author": "ychuest",
          "body": "> LLM_MODEL=proxyllm PROXY_SERVER_URL=http://172.16.15.242:8000/v1/chat/completions PROXYLLM_BACKEND=qwen2_5-14b-instruct\r\n\r\n谢谢你，已解决！",
          "created_at": "2024-09-27T08:16:02Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-25T21:04:40Z"
        }
      ]
    },
    {
      "issue_number": 2045,
      "title": "[Bug] [Web Module]Pull the latest web code, no changes, compiles directly, an error occurs.",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice:CPU\n\n### Models information\n\nLLM:Proxy LLM\n\n### What happened\n\nThe following error occurred while compiling a web project using yarn compile :\r\nSyntaxError: Unexpected token { in JSON at position 887504\r\n    at JSON.parse (<anonymous>)\r\n    at patchIncorrectLockfile (/data/git/DB-GPT/web/node_modules/next/dist/lib/patch-incorrect-lockfile.js:93:33)\r\n- warn Compiled with warnings\r\n\r\n./node_modules/@antv/g2/esm/transform/sample.js\r\nAttempted import error: 'medianIndex' is not exported from 'd3-array' (imported as 'medianIndex').\r\nThis error has already been submitted to [Issse](https://github.com/antvis/G2/issues/6479) under item [antvis/G2].\n\n### What you expected to happen\n\nCompilation ended normally.\n\n### How to reproduce\n\n1. Pull the latest web code.\r\n2. cd web Project Directory\r\n3. Execute \"yarn install\"\r\n4. Execute \"yarn compile\"\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Hec-gitHub",
      "author_type": "User",
      "created_at": "2024-09-27T01:54:46Z",
      "updated_at": "2025-01-25T21:04:39Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2045/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2045",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2045",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:59.389421",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-25T21:04:38Z"
        }
      ]
    },
    {
      "issue_number": 1222,
      "title": "[Bug] [Milvus] collection name can only contain numbers, letters and underscores: invalid parameter",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [X] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nNone\n\n### Models information\n\nNone\n\n### What happened\n\nRPC error: [has_collection], <MilvusException: (code=5, message=Invalid collection name: milvus_测试. collection name can only contain numbers, letters and underscores: invalid parameter)>, <Time:{'RPC start': '2024-03-01 09:51:03.496826', 'RPC error': '2024-03-01 09:51:03.524910'}>\r\n\r\n\n\n### What you expected to happen\n\nFix this\n\n### How to reproduce\n\nWhen the space name is Mixed languages， this error will occur. such as   `milvus_测试`\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "csunny",
      "author_type": "User",
      "created_at": "2024-03-01T01:56:56Z",
      "updated_at": "2025-01-25T17:23:47Z",
      "closed_at": "2024-06-10T21:05:31Z",
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1222/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "Aries-ckt"
      ],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1222",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1222",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:59.588254",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-03-31T21:04:30Z"
        },
        {
          "author": "paul-yangmy",
          "body": "+1 能否在前端加个判定呢，the first character of a collection name must be an underscore or letter: invalid parameter",
          "created_at": "2024-04-10T07:03:33Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-06-03T21:05:05Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue bas been closed, because it has been marked as `stale` and there has been no activity for over 7 days.",
          "created_at": "2024-06-10T21:05:30Z"
        },
        {
          "author": "eigen2017",
          "body": "+1。有大量数据要迁到milvus，这个限制导致了左右数据很难对齐",
          "created_at": "2024-08-13T10:00:16Z"
        }
      ]
    },
    {
      "issue_number": 2043,
      "title": "[Bug] [connection] If it runs for a long time, there is a problem that the connection pool leaks and causes inaccessibility.",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [X] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\ncpu: 16c 32g\n\n### Models information\n\ndefault\n\n### What happened\n\n1. 使用 get_raw_session 时， 大部分使用没有主动释放session, 导致连接池长时间占用\r\n2. RDBMSConnector 类使用 self.session 或者 self._db_sessions 时，未进行主动释放， 导致连接被长时间占用\n\n### What you expected to happen\n\n使用上述两个方法时， 是否需要主动释放session， 或者使用上下文 with来关联session， 避免造成session资源的浪费或泄露\n\n### How to reproduce\n\n1. 将系统连接池变小\r\n - LOCAL_DB_POOL_SIZE=2\r\n - LOCAL_DB_POOL_OVERFLOW=0\r\n 2. 将数据库连接时连接池变小进行测试\r\n   - \r\n![image](https://github.com/user-attachments/assets/42946c5b-49f8-4f2c-9284-eb8c2caa1e2e)\r\n\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Andy1i",
      "author_type": "User",
      "created_at": "2024-09-24T10:13:18Z",
      "updated_at": "2025-01-24T21:04:54Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2043/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2043",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2043",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:39:59.769232",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-24T21:04:53Z"
        }
      ]
    },
    {
      "issue_number": 1143,
      "title": "[Bug] [Proxy] Gemini proxy error",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [X] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU Memory:16Gx4\n\n### Models information\n\ngemini_proxyllm\n\n### What happened\n\n代理模型执行时报错\n\n### What you expected to happen\n\n2024-02-02 15:53:32 jranlin-WUJIE14-PRO dbgpt.model.proxy.llms.gemini[60609] INFO [调试gemini_proxyllm]class gemini_generate_stream:<dbgpt.model.proxy.llms.proxy_model.ProxyModel object at 0x7fc38700d3c0>\r\nModel: <dbgpt.model.proxy.llms.proxy_model.ProxyModel object at 0x7fc38700d3c0>, model_params: \r\n\r\n=========================== ProxyModelParameters ===========================\r\n\r\nmodel_name: gemini_proxyllm\r\nmodel_path: gemini_proxyllm\r\nproxy_server_url: https://generativelanguage.googleapis.com/v1beta/models/gemini-pro\r\nproxy_api_key: {******}\r\nproxy_api_base: None\r\nproxy_api_app_id: None\r\nproxy_api_secret: None\r\nproxy_api_type: None\r\nproxy_api_version: None\r\nhttp_proxy: None\r\nproxyllm_backend: gemini-pro\r\nmodel_type: proxy\r\ndevice: cpu\r\nprompt_template: None\r\nmax_context_size: 4096\r\nllm_client_class: None\r\n\r\n======================================================================\r\n\r\n\r\n2024-02-02 15:53:32 jranlin-WUJIE14-PRO dbgpt.model.proxy.llms.gemini[60609] INFO [调试gemini_proxyllm]class sync_generate_stream:ModelRequest(model='gemini-pro', messages=[ModelMessage(role='human', content='你是一个有用的 AI 助手。\\n你好', round_index=0)], temperature=0.6, max_new_tokens=1024, stop=None, stop_token_ids=None, context_len=None, echo=False, span_id=None, context=ModelRequestContext(stream=True, cache_enable=False, user_name=None, sys_code=None, conv_uid=None, span_id=None, chat_mode=None, extra={}, request_id=None))\r\n\r\n\r\nfull stream output:\r\n\r\n\r\nmodel generate_stream params:\r\n{'model': 'gemini_proxyllm', 'messages': [ModelMessage(role='human', content='你是一个有用的 AI 助手。\\n你好', round_index=0)], 'temperature': 0.6, 'max_new_tokens': 1024, 'echo': False, 'span_id': 'eb72d66d-6730-4937-bd0c-df3b9122b8c5:5444b4b0-d20f-4e05-a0c7-4db23667f6cf', 'context': {'stream': True, 'cache_enable': False, 'user_name': None, 'sys_code': None, 'conv_uid': None, 'span_id': 'eb72d66d-6730-4937-bd0c-df3b9122b8c5:b964381e-64f6-4fc9-ad16-e4d737d622e6', 'chat_mode': 'chat_normal', 'extra': {}, 'request_id': None}, 'convert_to_compatible_format': False, 'string_prompt': 'human: 你是一个有用的 AI 助手。\\n你好'}\r\nTraceback (most recent call last):\r\n  File \"/media/jranlin/8E6FAD7176696DCF/Documents/DB-GPT/dbgpt/app/scene/base_chat.py\", line 302, in stream_call\r\n    self.current_message.add_ai_message(msg)\r\nUnboundLocalError: local variable 'msg' referenced before assignment\r\n\r\n2024-02-02 15:54:28 jranlin-WUJIE14-PRO dbgpt.app.scene.base_chat[60609] ERROR model response parse failed！local variable 'msg' referenced before assignment\r\nINFO:     127.0.0.1:53100 - \"GET /api/v1/chat/dialogue/list HTTP/1.1\" 200 OK\r\n\n\n### How to reproduce\n\nLLM_MODEL=gemini_proxyllm\r\nGEMINI_PROXY_API_KEY={your_api_key}\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "linjingran01",
      "author_type": "User",
      "created_at": "2024-02-02T08:12:55Z",
      "updated_at": "2025-01-24T01:09:32Z",
      "closed_at": "2024-07-30T21:05:07Z",
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 14,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1143/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1143",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1143",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:00.024234",
      "comments": [
        {
          "author": "fangyinc",
          "body": "@linjingran01 你好，看不出具体的错误原因，网络连接可以么？\r\n",
          "created_at": "2024-02-04T06:30:08Z"
        },
        {
          "author": "Derek8863",
          "body": "大佬，请问这个问题解决了吗，我也遇到同样的问题了，用的是chatgpt3.5的接口",
          "created_at": "2024-02-20T11:20:11Z"
        },
        {
          "author": "alexlovy",
          "body": "大佬，请问这个问题解决了吗，我也遇到同样的问题了，用的是chatgpt3.5的接口",
          "created_at": "2024-03-15T02:06:53Z"
        },
        {
          "author": "alexlovy",
          "body": "> @linjingran01 你好，看不出具体的错误原因，网络连接可以么？\r\n\r\n代码报错了，在DB-GPT/dbgpt/app/scene/base_chat.py的302行，self.current_message.add_ai_message(msg)，这一句报错的，我也遇到一样的问题，但是不知道怎么解决。",
          "created_at": "2024-03-15T02:09:20Z"
        },
        {
          "author": "xjw00654",
          "body": "@fangyinc 应该是代理失效了。\r\n全局查了一下，大概是在启动controller的时候选择取消代理导致的。实际在这里设置no_proxy=127.0.0.1,localhost就没问题了。\r\nhttps://github.com/eosphoros-ai/DB-GPT/blob/main/dbgpt/model/cluster/worker/manager.py#L842-L845",
          "created_at": "2024-03-27T00:51:33Z"
        }
      ]
    },
    {
      "issue_number": 2041,
      "title": "BUG[Model]:restart dbgpt server, llm model management service disappeared",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [X] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n笔记本电脑\n\n### Models information\n\nGPT-4\n\n### What happened\n\n应用管理--模型管理--创建模型新增成功后无法再对话页面下拉框选择；重启DB-GPT后新增的模型数据丢失\n\n### What you expected to happen\n\nBUG: 应用管理--模型管理--创建模型新增成功后无法再对话页面下拉框选择；重启DB-GPT后新增的模型数据丢失\n\n### How to reproduce\n\nBUG: 应用管理--模型管理--创建模型新增成功后无法再对话页面下拉框选择；重启DB-GPT后新增的模型数据丢失\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "fengdezhen666",
      "author_type": "User",
      "created_at": "2024-09-24T03:20:04Z",
      "updated_at": "2025-01-23T21:04:59Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2041/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2041",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2041",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:00.269177",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "hi, @fdzgithub , sorry about that, now dbgpt model metadata storage in memory, we have not persist in any datasource, we will fix that soon. ",
          "created_at": "2024-09-24T09:22:02Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-23T21:04:59Z"
        }
      ]
    },
    {
      "issue_number": 1939,
      "title": "[Bug] [Module Name] Bug titles，web page Application error: a client-side exception has occurred (see the browser console for more information).",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [X] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\ncpu\r\n\n\n### Models information\n\nzhipuapi\n\n### What happened\n\nApplication error: a client-side exception has occurred (see the browser console for more information).\n\n### What you expected to happen\n\n正常对话\n\n### How to reproduce\n\n添加数据源后，点击chadata 出现该错误\n\n### Additional context\n\nApplication error: a client-side exception has occurred (see the browser console for more information).\r\n![image](https://github.com/user-attachments/assets/69fa5b4a-e94e-4518-a16f-6c8cfc2df0da)\r\n\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "Viserion-nlper",
      "author_type": "User",
      "created_at": "2024-09-02T05:32:10Z",
      "updated_at": "2025-01-22T08:57:33Z",
      "closed_at": "2024-09-12T03:55:35Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1939/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1939",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1939",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:00.529299",
      "comments": [
        {
          "author": "Silecne666",
          "body": "应该是新版本升级的bug，用的之前的版本，可以正常运行，重新拉取了新的代码后，就会出现这个问题",
          "created_at": "2024-09-02T06:03:41Z"
        },
        {
          "author": "kuschzzp",
          "body": "同样的问题，本地启动的，点击 【应用管理】里面【Chat Knowledge\r\n的 开始对话】就报错：`Application error: a client-side exception has occurred (see the browser console for more information).`\r\n\r\n",
          "created_at": "2024-09-02T08:18:53Z"
        },
        {
          "author": "Viserion-nlper",
          "body": "请问该问题解决了吗 ？是否是react前端问题？",
          "created_at": "2024-09-03T03:31:26Z"
        },
        {
          "author": "Aries-ckt",
          "body": "pull the latest version.",
          "created_at": "2024-09-12T03:55:09Z"
        },
        {
          "author": "2u0ta0",
          "body": "Same problem，latest pull",
          "created_at": "2025-01-22T08:57:32Z"
        }
      ]
    },
    {
      "issue_number": 2195,
      "title": "[Feature][GraphRAG] Enhance GraphRAG search by `Text2GQL` model",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n_No response_\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nHigh\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "fanzhidongyzby",
      "author_type": "User",
      "created_at": "2024-12-12T08:44:16Z",
      "updated_at": "2025-01-22T08:30:18Z",
      "closed_at": "2025-01-22T08:30:18Z",
      "labels": [
        "enhancement",
        "Waiting for reply",
        "GraphRAG"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2195/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2195",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2195",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:00.909110",
      "comments": []
    },
    {
      "issue_number": 1970,
      "title": "[Feature][ALL MODULES] BigQuery with struct compatibility",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nsource: bigquery\r\nadd: table with struct\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nHigh\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "johnfelipe",
      "author_type": "User",
      "created_at": "2024-09-04T13:54:45Z",
      "updated_at": "2025-01-21T21:04:54Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1970/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1970",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1970",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:00.909134",
      "comments": [
        {
          "author": "johnfelipe",
          "body": "Hi team \r\nAny progress about BQ tables with struct?",
          "created_at": "2024-09-10T15:47:05Z"
        },
        {
          "author": "johnfelipe",
          "body": "??",
          "created_at": "2024-09-23T06:50:49Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-21T21:04:52Z"
        }
      ]
    },
    {
      "issue_number": 2022,
      "title": "[Bug] [GraphRAG] GraphRAG chat shut down.",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [X] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [X] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGTX 3060 \n\n### Models information\n\ndefault embedding \n\n### What happened\n\n当我建立完知识图谱以后，只要Chat Knowledge没服务就崩溃\r\n\r\n1、知识图谱确认已建立\r\n2、确认chat llm正常，chat Knowledge就立刻崩溃\r\n\r\n2024-09-14 18:31:04 2024-09-14 10:31:04 7ba7ee03bbb8 dbgpt.rag.transformer.llm_extractor[1] INFO Using model proxyllm to extract\r\n2024-09-14 18:31:04 2024-09-14 10:31:04 7ba7ee03bbb8 dbgpt.model.adapter.base[1] INFO Message version is v2\r\n2024-09-14 18:31:04 2024-09-14 10:31:04 7ba7ee03bbb8 dbgpt.model.cluster.worker.default_worker[1] INFO current generate stream function is asynchronous stream function\r\n2024-09-14 18:31:04 2024-09-14 10:31:04 7ba7ee03bbb8 dbgpt.model.proxy.llms.chatgpt[1] INFO Send request to openai(1.44.1), payload: {'stream': True, 'model': 'THUDM/glm-4-9b-chat'}\r\n2024-09-14 18:31:04 \r\n2024-09-14 18:31:04  messages:\r\n2024-09-14 18:31:04 [{'role': 'user', 'content': \"A question is provided below. Given the question, extract up to keywords from the text. Focus on extracting the keywords that we can use to best lookup answers to the question.\\nGenerate as more as possible synonyms or alias of the keywords considering possible cases of capitalization, pluralization, common expressions, etc.\\nAvoid stopwords.\\nProvide the keywords and synonyms in comma-separated format.Formatted keywords and synonyms text should be separated by a semicolon.\\n---------------------\\nExample:\\nText: Alice is Bob's mother.\\nKeywords:\\nAlice,mother,Bob;mummy\\nText: Philz is a coffee shop founded in Berkeley in 1982.\\nKeywords:\\nPhilz,coffee shop,Berkeley,1982;coffee bar,coffee house\\n---------------------\\nText: 卫宁\\nKeywords:\\n\"}]\r\n2024-09-14 18:31:09 2024-09-14 10:31:09 7ba7ee03bbb8 openai._base_client[1] INFO Retrying request to /chat/completions in 0.867724 seconds\r\n2024-09-14 18:31:15 2024-09-14 10:31:15 7ba7ee03bbb8 openai._base_client[1] INFO Retrying request to /chat/completions in 1.713854 seconds\r\n2024-09-14 18:31:17 llm_adapter: <OpenAIProxyLLMModelAdapter model_name=proxyllm model_path=chatgpt_proxyllm>\r\n2024-09-14 18:31:17 \r\n2024-09-14 18:31:17 model prompt: \r\n2024-09-14 18:31:17 \r\n2024-09-14 18:31:17 human: A question is provided below. Given the question, extract up to keywords from the text. Focus on extracting the keywords that we can use to best lookup answers to the question.\r\n2024-09-14 18:31:17 Generate as more as possible synonyms or alias of the keywords considering possible cases of capitalization, pluralization, common expressions, etc.\r\n2024-09-14 18:31:17 Avoid stopwords.\r\n2024-09-14 18:31:17 Provide the keywords and synonyms in comma-separated format.Formatted keywords and synonyms text should be separated by a semicolon.\r\n2024-09-14 18:31:17 ---------------------\r\n2024-09-14 18:31:17 Example:\r\n2024-09-14 18:31:17 Text: Alice is Bob's mother.\r\n2024-09-14 18:31:17 Keywords:\r\n2024-09-14 18:31:17 Alice,mother,Bob;mummy\r\n2024-09-14 18:31:17 Text: Philz is a coffee shop founded in Berkeley in 1982.\r\n2024-09-14 18:31:17 Keywords:\r\n2024-09-14 18:31:17 Philz,coffee shop,Berkeley,1982;coffee bar,coffee house\r\n2024-09-14 18:31:17 ---------------------\r\n2024-09-14 18:31:17 Text: 卫宁\r\n2024-09-14 18:31:17 Keywords:\r\n2024-09-14 18:31:17 \r\n2024-09-14 18:31:17 \r\n2024-09-14 18:31:17 async stream output:\r\n2024-09-14 18:31:17 \r\n2024-09-14 18:31:17 \r\n2024-09-14 18:31:17 2024-09-14 10:31:17 7ba7ee03bbb8 dbgpt.model.cluster.worker.default_worker[1] INFO is_first_generate, usage: None\r\n2024-09-14 18:31:17 Keywords: 卫宁;Weining\r\n2024-09-14 18:31:17 \r\n2024-09-14 18:31:17 Synonyms:\r\n2024-09-14 18:31:28 2024-09-14 10:31:28 7ba7ee03bbb8 dbgpt.util.api_utils[1] WARNING Health check failed for http://127.0.0.1:5670, error: HTTPConnectionPool(host='127.0.0.1', port=5670): Read timed out. (read timeout=10)\r\n2024-09-14 18:31:43 2024-09-14 10:31:43 7ba7ee03bbb8 dbgpt.util.api_utils[1] WARNING Health check failed for http://127.0.0.1:5670, error: HTTPConnectionPool(host='127.0.0.1', port=5670): Read timed out. (read timeout=10)\r\n2024-09-14 18:31:58 2024-09-14 10:31:58 7ba7ee03bbb8 dbgpt.util.api_utils[1] WARNING Health check failed for http://127.0.0.1:5670, error: HTTPConnectionPool(host='127.0.0.1', port=5670): Read timed out. (read timeout=10)\r\n2024-09-14 18:32:13 2024-09-14 10:32:13 7ba7ee03bbb8 dbgpt.util.api_utils[1] WARNING Health check failed for http://127.0.0.1:5670, error: HTTPConnectionPool(host='127.0.0.1', port=5670): Read timed out. (read timeout=10)\r\n2024-09-14 18:32:28 2024-09-14 10:32:28 7ba7ee03bbb8 dbgpt.util.api_utils[1] WARNING Health check failed for http://127.0.0.1:5670, error: HTTPConnectionPool(host='127.0.0.1', port=5670): Read timed out. (read timeout=10)\r\n2024-09-14 18:32:43 2024-09-14 10:32:43 7ba7ee03bbb8 dbgpt.util.api_utils[1] WARNING Health check failed for http://127.0.0.1:5670, error: HTTPConnectionPool(host='127.0.0.1', port=5670): Read timed out. (read timeout=10)\r\n2024-09-14 18:32:58 2024-09-14 10:32:58 7ba7ee03bbb8 dbgpt.util.api_utils[1] WARNING Health check failed for http://127.0.0.1:5670, error: HTTPConnectionPool(host='127.0.0.1', port=5670): Read timed out. (read timeout=10)\r\n2024-09-14 18:33:13 2024-09-14 10:33:13 7ba7ee03bbb8 dbgpt.util.api_utils[1] WARNING Health check failed for http://127.0.0.1:5670, error: HTTPConnectionPool(host='127.0.0.1', port=5670): Read timed out. (read timeout=10)\r\n2024-09-14 18:33:28 2024-09-14 10:33:28 7ba7ee03bbb8 dbgpt.util.api_utils[1] WARNING Health check failed for http://127.0.0.1:5670, error: HTTPConnectionPool(host='127.0.0.1', port=5670): Read timed out. (read timeout=10)\r\n2024-09-14 18:33:43 2024-09-14 10:33:43 7ba7ee03bbb8 dbgpt.util.api_utils[1] WARNING Health check failed for http://127.0.0.1:5670, error: HTTPConnectionPool(host='127.0.0.1', port=5670): Read timed out. (read timeout=10)\r\n2024-09-14 18:33:58 2024-09-14 10:33:58 7ba7ee03bbb8 dbgpt.util.api_utils[1] WARNING Health check failed for http://127.0.0.1:5670, error: HTTPConnectionPool(host='127.0.0.1', port=5670): Read timed out. (read timeout=10)\r\n2024-09-14 18:34:13 2024-09-14 10:34:13 7ba7ee03bbb8 dbgpt.util.api_utils[1] WARNING Health check failed for http://127.0.0.1:5670, error: HTTPConnectionPool(host='127.0.0.1', port=5670): Read timed out. (read timeout=10)\r\n\n\n### What you expected to happen\n\n正常回答\n\n### How to reproduce\n\n当我建立完知识图谱以后，只要Chat Knowledge没服务就崩溃\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "AppleJunJiang",
      "author_type": "User",
      "created_at": "2024-09-14T10:54:27Z",
      "updated_at": "2025-01-19T21:04:43Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2022/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2022",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2022",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:01.097006",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "it looks like your llm service problem.",
          "created_at": "2024-09-16T14:26:10Z"
        },
        {
          "author": "AppleJunJiang",
          "body": "My model service is functioning normally, and chat with LLM is also working fine. However, the service crashes when chatting with knowledge. Additionally, an LLM returning an exception should not cause the entire app to crash.",
          "created_at": "2024-09-18T13:42:36Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-19T21:04:43Z"
        }
      ]
    },
    {
      "issue_number": 2029,
      "title": "[Bug][web]batch upload problem.",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n在知识库上传多个文档时，上传文件后点击切片处理，提示以下消息：Please select chunk strategy for ...\r\n![4dfd33dabfb6f4957e5e43abaedca78](https://github.com/user-attachments/assets/454bd553-2c75-482e-9c55-a78a84026166)\r\n\n\n### Use case\n\n希望每个文档默认是自动切片，不必手动展开每个节点选择\n\n### Related issues\n\n无\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "yyyt2020",
      "author_type": "User",
      "created_at": "2024-09-19T01:37:15Z",
      "updated_at": "2025-01-18T21:05:15Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2029/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "Aries-ckt"
      ],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2029",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2029",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:01.305208",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "sorry about that , it looks like web problem, we will fix that soon.",
          "created_at": "2024-09-19T02:00:28Z"
        },
        {
          "author": "ygbingo",
          "body": "其实把下面的都展开就可以了，看起来是不展开不会默认填参数信息",
          "created_at": "2024-09-20T06:30:55Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-18T21:05:14Z"
        }
      ]
    },
    {
      "issue_number": 2034,
      "title": "local code generate slowly",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nHi, I deployed dbgpt on my own computer and loaded a local model Qwen2 0.5B, it reasoned very fast in dbgpt, I asked questions and it answered them very fast, however I'm in pycharm, and I'm getting it to work by writing code like.\r\n\r\nfrom transformers import pipeline\r\n\r\nmessages = [\r\n    {“role”: “user”, “content”: “Who are you?”}, ]\r\n]\r\npipe = pipeline(“text-generation”, model=“Qwen/Qwen2-0.5B”)\r\npipe(messages)\r\n\r\nIt's reasoning very slowly, although I'm sure cuda is being used to speed it up.\r\nI don't understand why this is the case, and I'd like to achieve very fast reasoning locally as well\r\n\r\n\r\n\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "yx1405585468",
      "author_type": "User",
      "created_at": "2024-09-20T10:00:53Z",
      "updated_at": "2025-01-18T21:05:14Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2034/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2034",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2034",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:01.532948",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-18T21:05:12Z"
        }
      ]
    },
    {
      "issue_number": 2032,
      "title": "[Bug] [Module Name] vLLM Start Qwen2.5-32B-Instruct Error",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [X] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [X] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU A800\n\n### Models information\n\nLLM: Qwen2.5-32B-Instruct\n\n### What happened\n\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/dbgpt\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/app/dbgpt/cli/cli_scripts.py\", line 219, in main\r\n    return cli()\r\n  File \"/usr/local/lib/python3.10/site-packages/click/core.py\", line 1157, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.10/site-packages/click/core.py\", line 1078, in main\r\n    rv = self.invoke(ctx)\r\n  File \"/usr/local/lib/python3.10/site-packages/click/core.py\", line 1688, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"/usr/local/lib/python3.10/site-packages/click/core.py\", line 1686, in invoke\r\n    sub_ctx = cmd.make_context(cmd_name, args, parent=ctx)\r\n  File \"/usr/local/lib/python3.10/site-packages/click/core.py\", line 943, in make_context\r\n    self.parse_args(ctx, args)\r\n  File \"/usr/local/lib/python3.10/site-packages/click/core.py\", line 1404, in parse_args\r\n    parser = self.make_parser(ctx)\r\n  File \"/usr/local/lib/python3.10/site-packages/click/core.py\", line 1315, in make_parser\r\n    for param in self.get_params(ctx):\r\n  File \"/app/dbgpt/util/parameter_utils.py\", line 866, in get_params\r\n    dynamic_params = EnvArgumentParser._create_raw_click_option(\r\n  File \"/app/dbgpt/util/parameter_utils.py\", line 464, in _create_raw_click_option\r\n    combined_fields = _merge_dataclass_types(\r\n  File \"/app/dbgpt/util/parameter_utils.py\", line 588, in _merge_dataclass_types\r\n    _types = _dynamic_factory()\r\n  File \"/app/dbgpt/model/cli.py\", line 413, in _model_dynamic_factory\r\n    param_class = _dynamic_model_parser()\r\n  File \"/app/dbgpt/model/adapter/model_adapter.py\", line 159, in _dynamic_model_parser\r\n    param_class = llm_adapter.model_param_class()\r\n  File \"/app/dbgpt/model/adapter/vllm_adapter.py\", line 58, in model_param_class\r\n    return _build_parameter_class(descs)\r\n  File \"/app/dbgpt/util/parameter_utils.py\", line 667, in _build_parameter_class\r\n    result_class = dataclass(new_class)  # type: ignore\r\n  File \"/usr/local/lib/python3.10/dataclasses.py\", line 1185, in dataclass\r\n    return wrap(cls)\r\n  File \"/usr/local/lib/python3.10/dataclasses.py\", line 1176, in wrap\r\n    return _process_class(cls, init, repr, eq, order, unsafe_hash,\r\n  File \"/usr/local/lib/python3.10/dataclasses.py\", line 956, in _process_class\r\n    cls_fields.append(_get_field(cls, name, type, kw_only))\r\n  File \"/usr/local/lib/python3.10/dataclasses.py\", line 813, in _get_field\r\n    raise ValueError(f'mutable default {type(f.default)} for field '\r\nValueError: mutable default <class 'list'> for field ignore_patterns is not allowed: use default_factory\n\n### What you expected to happen\n\n    def model_param_class(self, model_type: str = None) -> BaseModelParameters:\r\n        import argparse\r\n\r\n        from vllm.engine.arg_utils import AsyncEngineArgs\r\n\r\n        parser = argparse.ArgumentParser()\r\n        parser = AsyncEngineArgs.add_cli_args(parser)\r\n        parser.add_argument(\"--model_name\", type=str, help=\"model name\")\r\n        parser.add_argument(\r\n            \"--model_path\",\r\n            type=str,\r\n            help=\"local model path of the huggingface model to use\",\r\n        )\r\n        parser.add_argument(\"--model_type\", type=str, help=\"model type\")\r\n        # parser.add_argument(\"--device\", type=str, default=None, help=\"device\")\r\n        # TODO parse prompt templete from `model_name` and `model_path`\r\n        parser.add_argument(\r\n            \"--prompt_template\",\r\n            type=str,\r\n            default=None,\r\n            help=\"Prompt template. If None, the prompt template is automatically determined from model path\",\r\n        )\r\n\r\n        descs = _extract_parameter_details(\r\n            parser,\r\n            \"dbgpt.model.parameter.VLLMModelParameters\",\r\n            skip_names=[\"model\"],\r\n            overwrite_default_values={\"trust_remote_code\": True},\r\n        )\r\n        return _build_parameter_class(descs)\r\n        \r\n        \r\n        dbgpt.model.parameter.VLLMModelParameters not find\n\n### How to reproduce\n\n#!/bin/bash\r\ndbgpt start worker \\\r\n      --model_type vllm \\\r\n      --model_name qwen2.5-32b-instruct \\\r\n      --model_path /app/models/Qwen2.5-32B-Instruct \\\r\n      --port 8005 \\\r\n      --gpu_memory_utilization 0.92 \\\r\n      --max_model_len 4096 \\\r\n      --controller_addr http://10.28.92.172:8000\n\n### Additional context\n\nsource version 0.5.10\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "xydz",
      "author_type": "User",
      "created_at": "2024-09-19T11:28:59Z",
      "updated_at": "2025-01-17T21:04:52Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2032/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2032",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2032",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:01.747698",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-17T21:04:50Z"
        }
      ]
    },
    {
      "issue_number": 2021,
      "title": "[Doc][Module Name] How to check the version of dbgpt",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nHow to check the version of dbgpt\n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "darius-gs",
      "author_type": "User",
      "created_at": "2024-09-14T08:09:36Z",
      "updated_at": "2025-01-16T21:04:58Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2021/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2021",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2021",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:01.978328",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "http://docs.dbgpt.cn/docs/overview/\r\n![image](https://github.com/user-attachments/assets/327046b4-481d-4d5d-9325-369f81f3be29)\r\n",
          "created_at": "2024-09-16T14:29:08Z"
        },
        {
          "author": "darius-gs",
          "body": "> http://docs.dbgpt.cn/docs/overview/ ![image](https://private-user-images.githubusercontent.com/13723926/367798602-327046b4-481d-4d5d-9325-369f81f3be29.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mj",
          "created_at": "2024-09-18T02:30:21Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-16T21:04:56Z"
        }
      ]
    },
    {
      "issue_number": 2011,
      "title": "[Feature][Module Name] ApiServer Support tools_call and function call ",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n开源glm-4-9b-chat 或闭源 openai 等多模型已具备tools_call或function call 能力，可否在ApiServer上提供支持\n\n### Use case\n\n通过集群部署的方便业务开次开发。\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nHigh\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "xydz",
      "author_type": "User",
      "created_at": "2024-09-11T11:51:21Z",
      "updated_at": "2025-01-16T21:04:58Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2011/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2011",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2011",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:02.181777",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "thanks your suggestion, we will consider it next version.",
          "created_at": "2024-09-13T15:21:27Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-11T21:04:44Z"
        },
        {
          "author": "lkp0000",
          "body": "I also need the 'function call' function",
          "created_at": "2025-01-16T10:46:56Z"
        }
      ]
    },
    {
      "issue_number": 1142,
      "title": "[Bug] [Knowledge] can not delete knowledge space",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [X] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice : GPU\r\nGPU Count : 3\r\nGPU Memory : 24G per GPU\n\n### Models information\n\nLLM : zhipu_proxyllm\r\nEmbedding Model : text2vec-large-chinese\n\n### What happened\n\n无法正常删除知识库。删除的时候显示文件繁忙，通过终端查看对应的文件正在被DB-GPT服务占用。\r\n![捕获2](https://github.com/eosphoros-ai/DB-GPT/assets/51395086/8893bec8-9ab7-429c-b276-855f58cc4a41)\r\n![捕获1](https://github.com/eosphoros-ai/DB-GPT/assets/51395086/b2e4207d-749a-403e-a317-ac1b5e2a7677)\r\n![捕获](https://github.com/eosphoros-ai/DB-GPT/assets/51395086/0fbd0a00-6809-4cc9-b16e-905bf1b8d957)\r\n\n\n### What you expected to happen\n\n对应的文件通过终端查看显示正在被 python dbgpt/app/dbgpt_server.py 占用。\n\n### How to reproduce\n\n1. 创建知识库\r\n2. 添加知识源\r\n3. 删除刚刚创建的知识库\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "ForgivenF",
      "author_type": "User",
      "created_at": "2024-02-02T06:05:39Z",
      "updated_at": "2025-01-15T07:31:36Z",
      "closed_at": "2024-03-17T21:04:59Z",
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1142/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1142",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1142",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:02.400764",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "check is there are another dbgpt process?\r\n`ps -ef | grep dbgpt`",
          "created_at": "2024-02-04T03:22:16Z"
        },
        {
          "author": "Dd88664185",
          "body": "> 检查是否有其他 DBGPT 进程？ `ps -ef | grep dbgpt`\r\n\r\n我也是这个问题，目前进程只有当前运行这个。我从pilot/data中删掉xxx.vectordb知识库和文件后。页面点击删除按钮，无法删除。并且在pilot/data中删掉的xxx.vectordb知识库又复现了。\r\n![image](https://github.com/eosphoros-ai/DB-GPT/assets/90893026/5bc3b34e-d030-4686-a132-c93203670f4a)\r\n",
          "created_at": "2024-02-05T03:00:21Z"
        },
        {
          "author": "Aries-ckt",
          "body": "restart your server? and create another space and check if there still have that question.",
          "created_at": "2024-02-08T03:06:07Z"
        },
        {
          "author": "Dd88664185",
          "body": "> 重新启动服务器？并创建另一个空间并检查是否还有该问题。\r\n我重新拉了一下代码 并且创建的都是引文的知识库空间 删除后还是有这个问题，\r\n![无标题](https://github.com/eosphoros-ai/DB-GPT/assets/90893026/4b42c018-22a7-4582-8d7e-8b6bb2ace59b)\r\n<img width=\"904\" alt=\"微信图片_20240209091342\" src=\"https://github.com/eosphoros-ai/DB-GPT/assets/90893026/dd0cdbcb-837b-4423-b05f-0a",
          "created_at": "2024-02-09T01:14:11Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-03-10T21:04:41Z"
        }
      ]
    },
    {
      "issue_number": 2272,
      "title": "[Bug] [llm-worker] model create with dashboard unhealty when llm-worker restart",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [X] Chat Data\n- [X] Chat Excel\n- [X] Chat DB\n- [X] Chat Knowledge\n- [X] Model Management\n- [X] Dashboard\n- [X] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [X] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nLLM:chatgpt_proxyllm\n\n### What happened\n\nI create a model  \"4o-last\"with chatgt in the dashboard,but when i restart the llm-worker,the new model changed unhealthy,\r\nI don't know which config can fix it\r\n\r\n![screenshot-4olast](https://github.com/user-attachments/assets/e42a09bd-c7ef-4a6a-9386-b74ba490afef)\r\nafter llm-worker restart\r\n![screenshot-unhealthy](https://github.com/user-attachments/assets/f90c4486-0e11-4e62-b2ee-fb3422b6a7c1)\r\n\r\n(base) ubuntu@new-test:~/gt/DB-GPT$ docker compose exec controller dbgpt model list\r\nWARN[0000] /home/ubuntu/gt/DB-GPT/docker-compose.yml: `version` is obsolete\r\n+------------------+------------+------------+------+---------+---------+-----------------+---------------------+\r\n|    Model Name    | Model Type |    Host    | Port | Healthy | Enabled | Prompt Template |    Last Heartbeat   |\r\n+------------------+------------+------------+------+---------+---------+-----------------+---------------------+\r\n| chatgpt_proxyllm |    llm     | llm-worker | 8001 |   True  |   True  |                 | 2025-01-03T08:52:56 |\r\n|  WorkerManager   |  service   | llm-worker | 8001 |   True  |   True  |                 | 2025-01-03T08:53:07 |\r\n|     4o-last      |    llm     | llm-worker | 8001 |   True  |   True  |                 | 2025-01-03T08:53:18 |\r\n+------------------+------------+------------+------+---------+---------+-----------------+---------------------+\r\n(base) ubuntu@new-test:~/gt/DB-GPT$ docker compose stop llm-worker\r\nWARN[0000] /home/ubuntu/gt/DB-GPT/docker-compose.yml: `version` is obsolete\r\n[+] Stopping 1/1\r\n ✔ Container db-gpt-llm-worker-1  Stopped                                                                                                                               2.0s\r\n(base) ubuntu@new-test:~/gt/DB-GPT$ docker compose start llm-worker\r\nWARN[0000] /home/ubuntu/gt/DB-GPT/docker-compose.yml: `version` is obsolete\r\n[+] Running 1/1\r\n ✔ Container db-gpt-llm-worker-1  Started                                                                                                                               0.3s\r\n(base) ubuntu@new-test:~/gt/DB-GPT$ docker compose exec controller dbgpt model list\r\nWARN[0000] /home/ubuntu/gt/DB-GPT/docker-compose.yml: `version` is obsolete\r\n+------------------+------------+------------+------+---------+---------+-----------------+---------------------+\r\n|    Model Name    | Model Type |    Host    | Port | Healthy | Enabled | Prompt Template |    Last Heartbeat   |\r\n+------------------+------------+------------+------+---------+---------+-----------------+---------------------+\r\n| chatgpt_proxyllm |    llm     | llm-worker | 8001 |   True  |   True  |                 | 2025-01-03T08:53:45 |\r\n|  WorkerManager   |  service   | llm-worker | 8001 |   True  |   True  |                 | 2025-01-03T08:53:45 |\r\n|     4o-last      |    llm     | llm-worker | 8001 |  False  |   True  |                 | 2025-01-03T08:53:18 |\r\n+------------------+------------+------------+------+---------+---------+-----------------+---------------------+\n\n### What you expected to happen\n\nthe llm-worker logs only register chatgpt_proxyllm@llm,it's not get all register model from controller\n\n### How to reproduce\n\n...\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "zxlzhd",
      "author_type": "User",
      "created_at": "2025-01-03T08:58:27Z",
      "updated_at": "2025-01-15T07:13:00Z",
      "closed_at": "2025-01-15T07:13:00Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2272/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2272",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2272",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:02.609673",
      "comments": [
        {
          "author": "zxlzhd",
          "body": "it's  my controller and llm-worker config，\r\ni want know how to register the model in  table `dbgpt_cluster_registry_instance`\r\n  controller:\r\n    image: eosphorosai/dbgpt:latest\r\n    command: dbgpt start controller --host 0.0.0.0 --port 8000\r\n    ports:\r\n      - \"18000:8000\"  # 映射到18000\r\n    environ",
          "created_at": "2025-01-03T09:09:36Z"
        },
        {
          "author": "Aries-ckt",
          "body": "@fangyinc please take a look.",
          "created_at": "2025-01-05T14:38:05Z"
        },
        {
          "author": "zxlzhd",
          "body": "好吧，仔细读了源代码跟语雀上的文档之后，我了解了，后台配置的模型不支持持久化。",
          "created_at": "2025-01-15T07:13:00Z"
        }
      ]
    },
    {
      "issue_number": 2258,
      "title": "[Bug] [Module Name] Bug title dbgpt_server.py: error: the following arguments are required: --model_path",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [X] Chat Data\n- [X] Chat Excel\n- [X] Chat DB\n- [X] Chat Knowledge\n- [X] Model Management\n- [X] Dashboard\n- [X] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU:24G\n\n### Models information\n\nLLM_MODEL=Qwen2.5-7B-Instruct\r\nEMBEDDING_MODEL=text2vec\n\n### What happened\n\nwhen start the services(python dbgpt/app/dbgpt_server.py)，it is error as follows:\r\nModel Unified Deployment Mode!\r\n2024-12-28 00:01:58 autodl-container-07ff4facf2-71e1d84d dbgpt.model.cluster.worker.manager[7854] INFO Register WorkerManager dbgpt_worker_manager_factory\r\n2024-12-28 00:01:58 autodl-container-07ff4facf2-71e1d84d dbgpt.component[7854] INFO Register component with name dbgpt_worker_manager_factory and instance: <dbgpt.model.cluster.worker.manager._DefaultWorkerManagerFactory object at 0x7f123296b550>\r\nusage: dbgpt_server.py [-h] [--model_name MODEL_NAME] --model_path MODEL_PATH [--host HOST] [--port PORT] [--daemon] [--log_level {FATAL,ERROR,WARNING,WARNING,INFO,DEBUG,NOTSET}] [--log_file LOG_FILE] [--tracer_file TRACER_FILE]\r\n                       [--tracer_to_open_telemetry] [--otel_exporter_otlp_traces_endpoint OTEL_EXPORTER_OTLP_TRACES_ENDPOINT] [--otel_exporter_otlp_traces_insecure] [--otel_exporter_otlp_traces_certificate OTEL_EXPORTER_OTLP_TRACES_CERTIFICATE]\r\n                       [--otel_exporter_otlp_traces_headers OTEL_EXPORTER_OTLP_TRACES_HEADERS] [--otel_exporter_otlp_traces_timeout OTEL_EXPORTER_OTLP_TRACES_TIMEOUT] [--otel_exporter_otlp_traces_compression OTEL_EXPORTER_OTLP_TRACES_COMPRESSION]\r\n                       [--worker_type {llm,text2vec}] [--model_alias MODEL_ALIAS] [--worker_class WORKER_CLASS] [--model_type MODEL_TYPE] [--limit_model_concurrency LIMIT_MODEL_CONCURRENCY] [--standalone] [--register]\r\n                       [--worker_register_host WORKER_REGISTER_HOST] [--controller_addr CONTROLLER_ADDR] [--send_heartbeat] [--heartbeat_interval HEARTBEAT_INTERVAL] [--tracer_storage_cls TRACER_STORAGE_CLS]\r\ndbgpt_server.py: error: the following arguments are required: --model_path\r\n\n\n### What you expected to happen\n\nthe services can started\n\n### How to reproduce\n\nstart the services:python dbgpt/app/dbgpt_server.py\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "chenyb868",
      "author_type": "User",
      "created_at": "2024-12-27T16:10:02Z",
      "updated_at": "2025-01-15T01:36:49Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2258/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2258",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2258",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:02.794478",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "you start dbgpt server with auto-dl images?",
          "created_at": "2024-12-29T11:26:37Z"
        },
        {
          "author": "zhangyichen534",
          "body": "我也有这样的问题，我是使用docker-compose启动的\r\n\r\n> 您使用自动 dl 图像启动 dbgpt 服务器吗？\r\n\r\n",
          "created_at": "2025-01-07T07:10:44Z"
        },
        {
          "author": "weideliti",
          "body": "源码部署的，报这个错",
          "created_at": "2025-01-15T01:36:48Z"
        }
      ]
    },
    {
      "issue_number": 2016,
      "title": "[Bug] [connection] Added Database Source list are blank",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [X] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n8 CPU\r\n32G MEM\r\nDBGPT:v0.6.0\n\n### Models information\n\nGPT4\n\n### What happened\n\nThe database was added successfully, but the admin page is blank.\r\n![image](https://github.com/user-attachments/assets/a349c2d9-1d19-456f-adae-ba23424b0011)\r\n\r\nBut it can be selected during dialog:\r\n![image](https://github.com/user-attachments/assets/e41bfa2d-0d14-4e14-9e19-b74bdfd5e83f)\r\n\n\n### What you expected to happen\n\nadd  database source  can be edit  and managed \n\n### How to reproduce\n\ncan not solve\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "escblue",
      "author_type": "User",
      "created_at": "2024-09-13T09:19:39Z",
      "updated_at": "2025-01-14T21:04:53Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2016/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2016",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2016",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:03.019921",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "refresh didn't work? you can check the `connect_config` table exist the datasource. ",
          "created_at": "2024-09-13T15:20:34Z"
        },
        {
          "author": "escblue",
          "body": "![image](https://github.com/user-attachments/assets/3c0b7884-5930-4281-9c6e-7d54cab5990a)\r\nyes exist the record in connect_config",
          "created_at": "2024-09-16T06:10:45Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-14T21:04:52Z"
        }
      ]
    },
    {
      "issue_number": 2196,
      "title": "[Feature][GraphRAG] Enhance GraphRAG search by vector index",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n_No response_\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nHigh\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "fanzhidongyzby",
      "author_type": "User",
      "created_at": "2024-12-12T08:46:53Z",
      "updated_at": "2025-01-14T04:39:02Z",
      "closed_at": "2025-01-14T04:39:02Z",
      "labels": [
        "enhancement",
        "Waiting for reply",
        "GraphRAG"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2196/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2196",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2196",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:03.325626",
      "comments": []
    },
    {
      "issue_number": 2295,
      "title": "请问支持多业务构建图知识库以及业务隔离吗？",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n_No response_\n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "cwqJim2023",
      "author_type": "User",
      "created_at": "2025-01-10T07:57:01Z",
      "updated_at": "2025-01-13T07:50:25Z",
      "closed_at": "2025-01-13T07:50:25Z",
      "labels": [
        "documentation",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2295/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2295",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2295",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:03.325643",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "你好，目前暂时不会考虑去做用户和业务隔离，我们数据库表结构预留了user_code和sys_code字段，帮助社区用户做业务和用户隔离。",
          "created_at": "2025-01-10T16:22:51Z"
        }
      ]
    },
    {
      "issue_number": 1648,
      "title": "[Doc][ChatKnowledge]  Does the knowledge base support background batch import?",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n我在老版本的issue里面看到似乎存在以下方法：\r\n1.将个人知识文件或者文件夹放入pilot/datasets目录中\r\n...\r\n3.在tools目录执行知识入库脚本（）\r\n如果是选择默认知识库，不需要指定 --vector_name, 默认default\r\npython tools/knowledge_init.py\r\n如果选择新增知识库，在界面上新增知识库输入你的知识库名,\r\npython tools/knowledge_init.py --vector_name = yourname\r\n--vector_name: vector_name default_value:default\r\n就可以根据你的知识库进行问答\r\n\r\n但是新版本没有在文档里发现相关方法，文件也已经删除了，请问有其他办法可以从后台导入多个文件吗，文件数量比较多。\n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "S0uLHun43r",
      "author_type": "User",
      "created_at": "2024-06-20T02:50:14Z",
      "updated_at": "2025-01-13T07:13:18Z",
      "closed_at": "2024-07-28T21:06:05Z",
      "labels": [
        "documentation",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1648/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1648",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1648",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:03.501397",
      "comments": [
        {
          "author": "S0uLHun43r",
          "body": "使用如下方法进行导入，出现以下报错：\r\ndbgpt knowledge load --space_name 'test' --local_doc_path /data/DB-GPT-main/pilot/datasets/ --vector_store_type Chroma\r\nid=None name='test' vector_type='Chroma' desc='DB-GPT cli' owner='DB-GPT'\r\nTraceback (most recent call last):\r\n  File \"/usr/local/python3/bin/dbgpt\", line 8, in",
          "created_at": "2024-06-20T08:19:53Z"
        },
        {
          "author": "Aries-ckt",
          "body": "sorry about that , we will support knowledge client upload directory  soon.",
          "created_at": "2024-06-20T15:52:15Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-07-20T21:04:37Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue bas been closed, because it has been marked as `stale` and there has been no activity for over 7 days.",
          "created_at": "2024-07-28T21:06:04Z"
        },
        {
          "author": "Nick-Happy",
          "body": "> ### Search before asking\r\n> * [x]  I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\r\n> \r\n> ### Description\r\n> 我在老版本的issue里面看到似乎存在以下方法： 1.将个人知识文件或者文件夹放入pilot/datasets目录中 ... 3.在tools目录执行知识入库脚本（） 如果是选择默认知识库，不需要指定 --v",
          "created_at": "2025-01-09T08:54:50Z"
        }
      ]
    },
    {
      "issue_number": 1993,
      "title": "[Agent开发案例文档错误] [Agent模块] ",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [X] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nnone\n\n### Models information\n\nnone\n\n### What happened\n\n\r\n![image](https://github.com/user-attachments/assets/4b7c39b5-cde2-4adb-b0c6-d121faea5ed2)\r\n在按照语雀文档进行Agent开发的时候，报了两个错误：\r\n1、使用类型提示时，不能直接实例化类型本身（如 List），而应该使用类型提示的工厂函数\r\n![image](https://github.com/user-attachments/assets/7978ee27-2716-445b-8fc6-ee314ba42dff)\r\n![image](https://github.com/user-attachments/assets/a4aa9d4c-317a-4bee-a738-5376b61bf554)\r\n2、queue为none，错误调用put方法。\r\n![image](https://github.com/user-attachments/assets/2a85229c-b4bb-4128-86e4-9bcbf36c0c17)\r\n\n\n### What you expected to happen\n\nnone\n\n### How to reproduce\n\nnone\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Viserion-nlper",
      "author_type": "User",
      "created_at": "2024-09-10T06:19:59Z",
      "updated_at": "2025-01-12T21:04:44Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1993/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1993",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1993",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:03.693682",
      "comments": [
        {
          "author": "FenGDJIAO",
          "body": "在agent bind之前加一步操作\r\nagent_memory.gpts_memory.init(conv_id=\"test1234\")\r\ndemo就可以跑通，不过在agent对话中，发现agent没有记忆住上下文。\r\n",
          "created_at": "2024-09-14T07:33:10Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-12T21:04:42Z"
        }
      ]
    },
    {
      "issue_number": 2015,
      "title": "[Bug][Agent]Chat with Agent，Failed to allocate model service,No model service available!!",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nLLM_MODEL=chatgpt_proxyllm\r\nEMBEDDING_MODEL=text2vec\n\n### What happened\n\n![image](https://github.com/user-attachments/assets/3bc04091-e0ab-4937-bab1-2f3d008ddd5a)\r\n如图，在Agent对话中，一直报：Error:The answer is not output in the required format.\n\n### What you expected to happen\n\ni don't know\n\n### How to reproduce\n\nxx\n\n### Additional context\n\nxx\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "15074852943",
      "author_type": "User",
      "created_at": "2024-09-13T08:27:44Z",
      "updated_at": "2025-01-12T21:04:42Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2015/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2015",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2015",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:03.901658",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "could you show the dbgpt server error log?",
          "created_at": "2024-09-13T15:22:19Z"
        },
        {
          "author": "15074852943",
          "body": "> could you show the dbgpt server error log?\r\n日志如下：\r\n![image](https://github.com/user-attachments/assets/4efae04f-f727-4525-84aa-8ded7fbfd967)\r\n\r\n",
          "created_at": "2024-09-14T01:37:39Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-12T21:04:40Z"
        }
      ]
    },
    {
      "issue_number": 932,
      "title": "[Bug] [text2vec-large-chinese LLM启动报错] safetensors_rust.SafetensorError: Error while deserializing header: HeaderTooLarge",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU: 4C\r\nmem: 8G \n\n### Models information\n\nEMBEDDING_MODEL=text2vec\r\n\n\n### What happened\n\n<img width=\"619\" alt=\"111111111111\" src=\"https://github.com/eosphoros-ai/DB-GPT/assets/76768331/5d1b5ade-7124-4547-a0b5-bb5f4cc32702\">\r\n启动的时候直接报错：\r\nsafetensors_rust.SafetensorError: Error while deserializing header: HeaderTooLarge\n\n### What you expected to happen\n\n加载text2vec-large-chinese出现问题\n\n### How to reproduce\n\nDB-GPT-0.4.3 源码安装使用text2vec-large-chinese启动就能复现\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "xinge-1",
      "author_type": "User",
      "created_at": "2023-12-13T10:07:09Z",
      "updated_at": "2025-01-12T07:18:34Z",
      "closed_at": "2024-01-19T21:04:40Z",
      "labels": [
        "FAQ:Install",
        "stale"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/932/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/932",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/932",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:04.132530",
      "comments": [
        {
          "author": "fangyinc",
          "body": "Same  #314",
          "created_at": "2023-12-13T10:17:57Z"
        },
        {
          "author": "codychau",
          "body": "![image](https://github.com/eosphoros-ai/DB-GPT/assets/22789452/d84123d2-a4bc-4940-9e8a-63b8d49c90d1)问题出在这里：File \"DB-GPT/dbgpt/app/dbgpt_server.py\", line 142，默认的env文件加载一个内嵌的文本向量模型，这个模型自己拉取之前要先装git-lfs，其次如果下载太慢就会无法下载到模型，建议用国内社区提供的text2vec或者m3e的模型文件，替换models文件夹下的文件",
          "created_at": "2023-12-13T11:30:20Z"
        },
        {
          "author": "codychau",
          "body": "## 以M3E-large模型为例，安装步骤\r\n\r\n1. 确保系统环境有安装git和git-lfs；\r\n2. 下载模型到代码下的models目录内（建议检查文件大小，需超过1.7GB）。\r\n3. 编辑.env文件，找到“EMBEDDING MODEL m3e-large”，把注释解开，找到同名设置项加上注释，保存（见图1-1）。\r\n4. 按照官方的文档设置好LLM模型后就可以使用启动服务的命令启动了。\r\n\r\n图1-1:\r\n![image](https://github.com/eosphoros-ai/DB-GPT/assets/22789452/eb846427-cda2-4634-ba1a",
          "created_at": "2023-12-13T11:41:58Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-01-12T21:04:31Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue bas been closed, because it has been marked as `stale` and there has been no activity for over 7 days.",
          "created_at": "2024-01-19T21:04:40Z"
        }
      ]
    },
    {
      "issue_number": 1958,
      "title": "The use for DB-GPT、Open-SPG、TuGraph",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n网上可查的文档指出包含DB-GPT、Open-SPG、TuGraph三个部分，在使用中发现Open-SPG可参与的部分只有schema建模和tugraph的查询，实际schema建模是被代码写死的，即使20240828提交的代码也只是对entity中的字段进行了一部分补充，对图的查询更是无法参与进去，那么对Open-SPG的应用是我理解不到位，还是当前适配不够深，有没有后续的计划呢？\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nHigh\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "hiro110110",
      "author_type": "User",
      "created_at": "2024-09-04T03:25:29Z",
      "updated_at": "2025-01-11T21:04:50Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1958/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1958",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1958",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:04.329366",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "hi @hiro110110 , thanks for your suggestion, Open-SPG we provide the interface but not implement the code. we hope the developer will join us to implement that\r\n```python\r\nclass OpenSPG(KnowledgeGraphBase):\r\n    \"\"\"OpenSPG class.\"\"\"\r\n\r\n    # todo: add OpenSPG implementation\r\n\r\n    def __init__(self,",
          "created_at": "2024-09-13T15:26:13Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-11T21:04:49Z"
        }
      ]
    },
    {
      "issue_number": 1967,
      "title": "[Bug] [chat data、chat dashboard]chat data ，chat dashboard cannot choose database list",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [X] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [X] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n接口调用大模型与embedding模型\n\n### Models information\n\nglm4\n\n### What happened\n\nchatdata没有办法选择数据库，chatdashboard没有数据库选择列表。如图\r\n![image](https://github.com/user-attachments/assets/0abddde9-17ee-493d-86f9-86ef5b06b6fd)\r\n![image](https://github.com/user-attachments/assets/cad06f75-17b9-4338-9ffc-f1488df423da)\r\n\n\n### What you expected to happen\n\n希望能解决以上两个问题\n\n### How to reproduce\n\n正常启动即可\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "MachineSkywalker",
      "author_type": "User",
      "created_at": "2024-09-04T12:40:22Z",
      "updated_at": "2025-01-11T21:04:48Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 5,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1967/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1967",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1967",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:04.550452",
      "comments": [
        {
          "author": "lyingspring",
          "body": "我也碰到同样的问题，请问有解决吗？\r\n",
          "created_at": "2024-09-04T16:35:38Z"
        },
        {
          "author": "MachineSkywalker",
          "body": "> 我也遇到了同样的问题，请问有解决吗？\r\n\r\n还没有呢，如果您解决了，可以和我说下解决办法吗",
          "created_at": "2024-09-05T14:49:25Z"
        },
        {
          "author": "shanmu-raoyunfei",
          "body": "Same problem, and keeps getting stuck in \"save\" when adding database",
          "created_at": "2024-09-07T15:02:58Z"
        },
        {
          "author": "ygbingo",
          "body": "没遇到这个问题，可以从以下几个方面尝试解决：\r\n1. 检查应用管理的数据库中添加成功\r\n2. 执行assets/schema/upgrade/v0_6_0中的upgrade_*.sql脚本",
          "created_at": "2024-09-12T01:28:21Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-11T21:04:47Z"
        }
      ]
    },
    {
      "issue_number": 2009,
      "title": "[Bug] [Module Name] Bug title log error --- Logging error --- Traceback (most recent call last):   File \"E:\\Anaconda\\envs\\dbgpt060\\lib\\logging\\__init__.py\", line 1103, in emit     stream.write(msg + self.terminator) UnicodeEncodeError: 'gbk' codec can't encode character '\\u30fb' in position 1301: illegal multibyte sequence",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [X] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nWindows\n\n### Models information\n\nxx\n\n### What happened\n\n![image](https://github.com/user-attachments/assets/406302da-67db-4335-a4ba-aa407c8326ee)\r\nSometimes errors may occur when constructing or retrieving graphs based on community summaries. How to modify it?\n\n### What you expected to happen\n\nxx\n\n### How to reproduce\n\nxx\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Storm0921",
      "author_type": "User",
      "created_at": "2024-09-11T10:44:15Z",
      "updated_at": "2025-01-11T21:04:47Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2009/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2009",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2009",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:04.735976",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "maybe it's the window os problem.",
          "created_at": "2024-09-13T15:34:18Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-11T21:04:45Z"
        }
      ]
    },
    {
      "issue_number": 2014,
      "title": "[Bug] [Module Name] Unable to get data from TuGraph",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU 32g\n\n### Models information\n\nDefault models\n\n### What happened\n\nUnable to get data from 7687connection.\r\n![image](https://github.com/user-attachments/assets/d53fd413-2547-4892-8f5a-f9e3572876a3)\r\n\n\n### What you expected to happen\n\nI hope the knowledge data is successfuly generated.\n\n### How to reproduce\n\n1.Use docker to start TuGRAPH\r\n2.use main branch of dbgpt,use default configuration\n\n### Additional context\n\n### TuGraph config\r\nTUGRAPH_HOST=127.0.0.1\r\nTUGRAPH_PORT=7687\r\nTUGRAPH_USERNAME=admin\r\nTUGRAPH_PASSWORD=73@TuGraph\r\nTUGRAPH_VERTEX_TYPE=entity\r\nTUGRAPH_EDGE_TYPE=relation\r\nTUGRAPH_PLUGIN_NAMES=leiden\r\n\r\n\r\n**Dokcer ps result:**\r\n7b6b02441901   tugraph/tugraph-runtime-centos7:4.0.1   \"/bin/bash\"   34 minutes ago   Up 34 minutes   0.0.0.0:7001->7001/tcp, :::7001->7001/tcp, 0.0.0.0:7070->7070/tcp, :::7070->7070/tcp, 0.0.0.0:7687->7687/tcp, :::7687->7687/tcp, 0.0.0.0:8003->8003/tcp, :::8003->8003/tcp, 0.0.0.0:8888-8889->8888-8889/tcp, :::8888-8889->8888-8889/tcp, 0.0.0.0:9090->9090/tcp, :::9090->9090/tcp   tugraph_demo\r\n\r\n**Tugraph is successfully started.**\r\n![image](https://github.com/user-attachments/assets/6a7a1e45-2fee-460c-bb5c-7e776b6eb7ec)\r\n\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "worstkid92",
      "author_type": "User",
      "created_at": "2024-09-12T06:23:32Z",
      "updated_at": "2025-01-11T21:04:44Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2014/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2014",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2014",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:04.932001",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-10T21:04:47Z"
        }
      ]
    },
    {
      "issue_number": 2284,
      "title": "[Bug] [Module Name] ZHIPU proxyllm doesn't work ",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [X] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice：CPU\n\n### Models information\n\nLLM: zhipuai\r\nEmbedding model:m3e-base\r\n\r\nmodel_name: zhipu_proxyllm\r\nmodel_path: zhipu_proxyllm\r\nproxy_server_url: https://open.bigmodel.cn/api/paas/v4/\r\nproxy_api_key: 4******j\r\nproxy_api_base: None\r\nproxy_api_app_id: None\r\nproxy_api_secret: None\r\nproxy_api_type: None\r\nproxy_api_version: None\r\nhttp_proxy: http://xx:8080\r\nhttps_proxy: http://xxx:8080\r\nproxyllm_backend: glm-4\r\nmodel_type: proxy\r\ndevice: cpu\r\nprompt_template: None\r\nmax_context_size: 4096\r\nllm_client_class: None\r\n\n\n### What happened\n\n在对话中，无法获取响应影响，后台日志如下：\r\n\r\n`2025-01-08 10:17:24 xx dbgpt.model.cluster.worker.default_worker[2458899] INFO current generate stream function is synchronous generate stream function\r\nllm_adapter: <ZhipuProxyLLMModelAdapter model_name=zhipu_proxyllm model_path=zhipu_proxyllm>\r\n\r\nmodel prompt:\r\n\r\nhuman: 你是一个有用的 AI 助手。\r\n你好啊\r\n\r\ngenerate stream output:\r\n\r\nModel: <dbgpt.model.proxy.llms.proxy_model.ProxyModel object at 0x152999aaa530>, model_params:\r\n\r\n=========================== ProxyModelParameters ===========================\r\n\r\nmodel_name: zhipu_proxyllm\r\nmodel_path: zhipu_proxyllm\r\nproxy_server_url: https://open.bigmodel.cn/api/paas/v4/\r\nproxy_api_key: 4******j\r\nproxy_api_base: None\r\nproxy_api_app_id: None\r\nproxy_api_secret: None\r\nproxy_api_type: None\r\nproxy_api_version: None\r\nhttp_proxy: http://192.168.48.101:8080\r\nhttps_proxy: http://192.168.48.101:8080\r\nproxyllm_backend: glm-4\r\nmodel_type: proxy\r\ndevice: cpu\r\nprompt_template: None\r\nmax_context_size: 4096\r\nllm_client_class: None\r\n\r\n======================================================================\r\n\r\n2025-01-08 10:17:24 xx zhipuai.api_resource.chat.completions[2458899] DEBUG temperature:0.5, top_p:NOT_GIVEN\r\n2025-01-08 10:17:24 xx zhipuai.api_resource.chat.completions[2458899] DEBUG temperature:0.5, top_p:NOT_GIVEN\r\nurl 22: https://open.bigmodel.cn/api/paas/v4/chat/completions\r\njson_data 22: {'model': 'glm-4', 'temperature': 0.5, 'messages': [{'role': 'user', 'content': '你是一个有用的 AI 助手。\\n你好啊'}], 'response_format': None}\r\nrequest 11 : <Request('POST', 'https://open.bigmodel.cn/api/paas/v4/chat/completions')>\r\n2025-01-08 10:17:24 xx httpcore.connection[2458899] DEBUG connect_tcp.started host='open.bigmodel.cn' port=443 local_address=None timeout=8.0 socket_options=None\r\n2025-01-08 10:17:26 xx schedule[2458899] DEBUG Running job Job(interval=5, unit=seconds, do=load_dag_from_dbgpts, args=(), kwargs={})\r\n2025-01-08 10:17:29 xx dbgpt.util.api_utils[2458899] DEBUG Checking health for http://127.0.0.1:5670\r\n2025-01-08 10:17:29 xx urllib3.connectionpool[2458899] DEBUG Starting new HTTP connection (1): 127.0.0.1:5670\r\n2025-01-08 10:17:29 xx urllib3.connectionpool[2458899] DEBUG http://127.0.0.1:5670 \"GET /api/health HTTP/1.1\" 200 15\r\n2025-01-08 10:17:29 xx dbgpt.util.api_utils[2458899] DEBUG Healthy urls: ['http://127.0.0.1:5670']\r\n2025-01-08 10:17:29 xx schedule[2458899] DEBUG Running job Job(interval=5, unit=seconds, do=load_package, args=(), kwargs={})\r\n2025-01-08 10:17:31 xx schedule[2458899] DEBUG Running job Job(interval=5, unit=seconds, do=load_dag_from_dbgpts, args=(), kwargs={})\r\n2025-01-08 10:17:32 xx httpcore.connection[2458899] DEBUG connect_tcp.failed exception=ConnectTimeout(TimeoutError('timed out'))\r\n2025-01-08 10:17:32 xx zhipuai.core._http_client[2458899] DEBUG Encountered httpx.TimeoutException\r\nTraceback (most recent call last):\r\n  File \"/mwbase/appsystems/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\r\n    yield\r\n  File \"/mwbase/appsystems/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/httpx/_transports/default.py\", line 236, in handle_request\r\n    resp = self._pool.handle_request(req)\r\n  File \"/mwbase/appsystems/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py\", line 256, in handle_request\r\n    raise exc from None\r\n  File \"/mwbase/appsystems/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py\", line 236, in handle_request\r\n    response = connection.handle_request(\r\n  File \"/mwbase/appsystems/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/httpcore/_sync/connection.py\", line 101, in handle_request\r\n    raise exc\r\n  File \"/mwbase/appsystems/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/httpcore/_sync/connection.py\", line 78, in handle_request\r\n    stream = self._connect(request)\r\n  File \"/mwbase/appsystems/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/httpcore/_sync/connection.py\", line 124, in _connect\r\n    stream = self._network_backend.connect_tcp(**kwargs)\r\n  File \"/mwbase/appsystems/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/httpcore/_backends/sync.py\", line 207, in connect_tcp\r\n    with map_exceptions(exc_map):\r\n  File \"/mwbase/appsystems/miniconda3/envs/dbgpt_env/lib/python3.10/contextlib.py\", line 153, in __exit__\r\n    self.gen.throw(typ, value, traceback)\r\n  File \"/mwbase/appsystems/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\r\n    raise to_exc(exc) from exc\r\nhttpcore.ConnectTimeout: timed out\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/mwbase/appsystems/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/zhipuai/core/_http_client.py\", line 526, in _request\r\n    response = self._client.send(\r\n  File \"/mwbase/appsystems/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/httpx/_client.py\", line 926, in send\r\n    response = self._send_handling_auth(\r\n  File \"/mwbase/appsystems/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\r\n    response = self._send_handling_redirects(\r\n  File \"/mwbase/appsystems/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\r\n    response = self._send_single_request(request)\r\n  File \"/mwbase/appsystems/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/httpx/_client.py\", line 1027, in _send_single_request\r\n    response = transport.handle_request(request)\r\n  File \"/mwbase/appsystems/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/httpx/_transports/default.py\", line 235, in handle_request\r\n    with map_httpcore_exceptions():\r\n  File \"/mwbase/appsystems/miniconda3/envs/dbgpt_env/lib/python3.10/contextlib.py\", line 153, in __exit__\r\n    self.gen.throw(typ, value, traceback)\r\n  File \"/mwbase/appsystems/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\r\n    raise mapped_exc(message) from exc\r\nhttpx.ConnectTimeout: timed out\r\n`\r\n\r\n但是我直接跑zhipiai官方的案例是可以跑通的，这里说明网络是没问题的\r\n\r\n`(dbgpt_env) [user@xx DB-GPT]$ cat zhipuai_test.py\r\nfrom zhipuai import ZhipuAI\r\nclient = ZhipuAI(api_key=\"4***j\") # 填写您自己的APIKey\r\nresponse = client.chat.completions.create(\r\n    model=\"glm-4\",  # 填写需要调用的模型编码\r\n    messages=[\r\n        {\"role\": \"system\", \"content\": \"你是一个乐于解答各种问题的助手，你的任务是为用户提供专业、准确、有见地的建议。\"},\r\n        {\"role\": \"user\", \"content\": \"农夫需要把狼、羊和白菜都带过河，但每次只能带一样物品，而且狼和羊不能单独相处，羊和白菜也不能单独相处，问农夫该如何过河。\"}\r\n    ],\r\n)\r\nprint(response.choices[0].message)\r\n(dbgpt_env) [user@xx DB-GPT]$ python zhipuai_test.py\r\nCompletionMessage(content='这个问题是一个经典的逻辑谜题，解决方法如下：\\n\\n1. **第一步**：农夫先带羊过河。\\n   - 左岸：狼、白菜\\n   - 右岸：羊\\n\\n2. **第二步**：农夫返回左岸。\\n   - 左岸：狼、白菜\\n   - 右岸：羊\\n\\n3. **第三步**：农夫带狼过河。\\n   - 左岸：白菜\\n   - 右岸：羊、狼\\n\\n4. **第四步**：农夫把羊带回左岸。\\n   - 左岸：羊、白菜\\n   - 右岸：狼\\n\\n5. **第五步**：农夫带白菜过河。\\n   - 左岸：羊\\n   - 右岸：狼、白菜\\n\\n6. **第六步**：农夫返回左岸。\\n   - 左岸：羊\\n   - 右岸：狼、白菜\\n\\n7. **第七步**：农夫最后带羊过河。\\n   - 左岸：无\\n   - 右岸：羊、狼、白菜\\n\\n通过以上步骤，农夫成功地把狼、羊和白菜都带过了河，且在任何时候都没有让狼和羊、羊和白菜单独相处。\\n\\n希望这个解答对你有帮助！如果有其他问题，也欢迎继续提问。', role='assistant', tool_calls=None)`\n\n### What you expected to happen\n\n1、已经确认网络是没有问题的\r\n2、确定主机上能跑通zhipuai的官方示例\r\n3、zhipiai版本：2.1.5.20250106\r\n\n\n### How to reproduce\n\n当前配置：\r\n(dbgpt_env) [user@xx DB-GPT]$ grep -E \"LLM_MODEL|PROXY_SERVER_URL|API_KEY|ZHIPU_\" .env |grep -v \"^#\"\r\nLLM_MODEL=zhipu_proxyllm\r\nPROXY_SERVER_URL=https://open.bigmodel.cn/api/paas/v4/\r\nZHIPU_MODEL_VERSION=glm-4\r\nZHIPU_PROXY_API_KEY=4****j\r\n\r\n\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "songfaxian",
      "author_type": "User",
      "created_at": "2025-01-08T03:02:39Z",
      "updated_at": "2025-01-10T08:02:59Z",
      "closed_at": "2025-01-10T08:02:59Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2284/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2284",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2284",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:05.120903",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "try\r\n```\r\nLLM_MODEL=zhipu_proxyllm\r\nPROXYLLM_BACKEND=glm-4\r\nZHIPU_MODEL_VERSION=glm-4\r\nZHIPU_PROXY_API_KEY={yout_api_key}\r\nPROXY_SERVER_URL=http://127:0.0.1\r\n```",
          "created_at": "2025-01-08T12:06:45Z"
        },
        {
          "author": "songfaxian",
          "body": "config：\r\n`(dbgpt_env) [user@xx DB-GPT]$ grep -E \"^LLM_MODEL|^PROXYLLM_BACKEND|^ZHIPU_|^PROXY_SERVER_URL\" .env\r\nLLM_MODEL=zhipu_proxyllm\r\nPROXYLLM_BACKEND=glm-4\r\nPROXY_SERVER_URL=http://127:0.0.1\r\nZHIPU_MODEL_VERSION=glm-4\r\nZHIPU_PROXY_API_KEY=4*****j\r\n`\r\n\r\nStill no, the error is as follows：\r\n`Traceb",
          "created_at": "2025-01-09T09:03:05Z"
        },
        {
          "author": "Aries-ckt",
          "body": "try make sure your config and network is work and you can debug in this file.\r\n```\r\nDB-GPT/dbgpt/model/proxy/llms/zhipu.py\r\n```",
          "created_at": "2025-01-09T09:17:52Z"
        },
        {
          "author": "songfaxian",
          "body": "修改zhipu.py文件之后，问题解决了，完整代码如下：\r\n\r\n`import os\r\nfrom concurrent.futures import Executor\r\nfrom typing import Iterator, Optional\r\nimport httpx\r\n\r\nfrom dbgpt.core import MessageConverter, ModelOutput, ModelRequest\r\nfrom dbgpt.model.parameter import ProxyModelParameters\r\nfrom dbgpt.model.proxy.base import P",
          "created_at": "2025-01-10T08:02:59Z"
        }
      ]
    },
    {
      "issue_number": 2288,
      "title": "[Bug] [util] json_utils.find_json_objects bug",
      "body": "### Search before asking\r\n\r\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\r\n\r\n\r\n### Operating system information\r\n\r\nMacOS(x86)\r\n\r\n### Python version information\r\n\r\n>=3.11\r\n\r\n### DB-GPT version\r\n\r\nmain\r\n\r\n### Related scenes\r\n\r\n- [ ] Chat Data\r\n- [ ] Chat Excel\r\n- [ ] Chat DB\r\n- [ ] Chat Knowledge\r\n- [ ] Model Management\r\n- [ ] Dashboard\r\n- [ ] Plugins\r\n\r\n### Installation Information\r\n\r\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\r\n\r\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\r\n\r\n- [ ] AutoDL Image\r\n- [ ] Other\r\n\r\n### Device information\r\n\r\n*\r\n\r\n### Models information\r\n\r\n*\r\n\r\n### What happened\r\n\r\nI found an issue when I use AutoPlaner agent to generate a plan. The issue is  that `function.json_utils.find_json_objects` can not handle text likes:\r\n```\r\n\"\"\"\r\n        ```json\r\n\r\n          {\r\n            \"serial_number\": \"1\",\r\n            \"agent\": \"CodeOptimizer\",\r\n            \"content\": \"```json\r\nselect * \r\nfrom table\r\nwhere column = 'value'\r\n``` optimize the code above.\",\r\n            \"rely\": \"\"\r\n          }\r\n        ```\r\n        \"\"\"\r\n```\r\n\r\n### What you expected to happen\r\n\r\n`\\n` is not correctly replaced by `\\\\n`\r\n\r\n### How to reproduce\r\n\r\nrun test bellow:\r\n```python\r\nimport pytest\r\n\r\nfrom dbgpt.util.json_utils import find_json_objects\r\n\r\n# 定义参数化测试数据\r\ntest_data = [\r\n    (\r\n        \"\"\"\r\n        ```json\r\n\r\n          {\r\n            \"serial_number\": \"1\",\r\n            \"agent\": \"CodeOptimizer\",\r\n            \"content\": \"```json\r\nselect * \r\nfrom table\r\nwhere column = 'value'\r\n``` optimize the code above.\",\r\n            \"rely\": \"\"\r\n          }\r\n        ```\r\n        \"\"\",\r\n        [\r\n            {\r\n                \"serial_number\": \"1\",\r\n                \"agent\": \"CodeOptimizer\",\r\n                \"content\": \"```json\\nselect * \\nfrom table\\nwhere column = 'value'\\n``` optimize the code above.\",\r\n                \"rely\": \"\",\r\n            }\r\n        ],\r\n        \"Test case with nested code block\",\r\n    ),\r\n    (\r\n        \"\"\"\r\n        {\r\n            \"key\": \"value\"\r\n        }\r\n        \"\"\",\r\n        [{\"key\": \"value\"}],\r\n        \"Test case with simple JSON\",\r\n    ),\r\n    (\r\n        \"\"\"\r\n        {\r\n            \"key1\": \"value1\"\r\n        }\r\n        {\r\n            \"key2\": \"value2\"\r\n        }\r\n        \"\"\",\r\n        [{\"key1\": \"value1\"}, {\"key2\": \"value2\"}],\r\n        \"Test case with multiple JSON objects\",\r\n    ),\r\n    (\"\", [], \"Test case with empty input\"),\r\n    (\"This is not a JSON string\", [], \"Test case with non-JSON input\"),\r\n]\r\n\r\n# 参数化测试函数\r\n@pytest.mark.parametrize(\"text, expected, description\", test_data)\r\ndef test_find_json_objects(text, expected, description):\r\n    result = find_json_objects(text)\r\n    assert (\r\n        result == expected\r\n    ), f\"Test failed: {description}\\nExpected: {expected}\\nGot: {result}\"\r\n\r\n```\r\n\r\n\r\n### Additional context\r\n\r\n_No response_\r\n\r\n### Are you willing to submit PR?\r\n\r\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "FOkvj",
      "author_type": "User",
      "created_at": "2025-01-08T11:10:20Z",
      "updated_at": "2025-01-10T02:32:14Z",
      "closed_at": "2025-01-10T02:32:14Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2288/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2288",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2288",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:05.354082",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "Thanks for your contribution.",
          "created_at": "2025-01-10T02:32:11Z"
        }
      ]
    },
    {
      "issue_number": 2005,
      "title": "[Bug] [pymssql] Adaptive Server is unavailable or does not exist",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [X] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU memory 16 GB\n\n### Models information\n\nLLM:tongyi_proxyllm\r\nEMBEDDING_MODEL=text2vec\n\n### What happened\n\n![image](https://github.com/user-attachments/assets/d6ed66b8-d0be-4a76-b77c-00c0fa624ddd)\r\n\n\n### What you expected to happen\n\nin my side, I've tried in Python both 3.12 and 3.10, also facing the issue.\r\nin my environment, I tried it by below code, it works fine, but in DB-GPT side, it cannot work when i tried to create the MSSQL datasource under application manage model.\r\n\r\ntry:\r\n    # 建立连接\r\n    connection = pymssql.connect(server=server, user=username, password=password, database=database)\r\n    \r\n    # 创建游标\r\n    cursor = connection.cursor()\r\n    \r\n    # 执行简单的查询以测试连接\r\n    cursor.execute('SELECT @@VERSION')  # 查询 SQL Server 版本\r\n    row = cursor.fetchone()  # 获取一行结果\r\n    print('SQL Server Version:', row[0])  # 打印版本信息\r\n    \r\n    # 关闭游标和连接\r\n    cursor.close()\r\n    connection.close()\r\n    \r\nexcept pymssql.Error as e:\r\n    print(\"Error while connecting to SQL Server:\", e)\r\n\n\n### How to reproduce\n\n![image](https://github.com/user-attachments/assets/9bc6299c-cf52-4863-8b54-4e3f097933ae)\r\n\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "DekieCheng",
      "author_type": "User",
      "created_at": "2024-09-11T08:37:34Z",
      "updated_at": "2025-01-09T21:04:47Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2005/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2005",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2005",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:05.551524",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-09T21:04:46Z"
        }
      ]
    },
    {
      "issue_number": 2255,
      "title": "[Bug] [examples] fix agents & awel examples ",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nMacOS M1\n\n### Models information\n\nLLM: Siliconflow,  Qwen/Qwen2.5-Coder-32B-Instruct \n\n### What happened\n\nSome examples can't run successfully, needs to fix with latest code.\n\n### What you expected to happen\n\nTo fix the agents and `awel` example and add a GitHub workflow for automatic runs, follow these steps:\r\n\r\n```\r\nname: Run Examples\r\n\r\non:\r\n  push: \r\n    branches:\r\n      - fix_examples\r\n    pull_request:\r\n      branches:\r\n      - fix_examples\r\n\r\njobs:\r\n  run-examples:\r\n    runs-on: ubuntu-latest\r\n\r\n    steps:\r\n    - name: Checkout repository\r\n      uses: actions/checkout@v2\r\n\r\n    - name: Set up Python \r\n      uses: actions/setup-python@v3\r\n      with:\r\n        python-version: '3.10'\r\n      \r\n    - name: Install dependencies\r\n      run: |\r\n        python -m venv venv\r\n        source venv/bin/activate\r\n        pip install -e \".[default]\" \r\n\r\n    - name: Run Examples\r\n      run: |\r\n        source venv/bin/activate\r\n        python -m examples\r\n\r\n      env:\r\n        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\r\n        OPEN_API_BASE: ${{ secrets.OPENAI_API_BASE }}\r\n      \r\n\r\n```\r\n\r\n\n\n### How to reproduce\n\nNone\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "csunny",
      "author_type": "User",
      "created_at": "2024-12-27T09:56:15Z",
      "updated_at": "2025-01-09T12:01:38Z",
      "closed_at": "2025-01-09T12:01:38Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2255/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2255",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2255",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:05.768175",
      "comments": []
    },
    {
      "issue_number": 1950,
      "title": "[Doc][Agents/Quick Start] Documentation improvement: How to set the LLMClient initial params when using local model?",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nHow to set the LLMClient initial params when using local model? The default code example for OpenAILLMClient uses \"OPENAI_API_BASE\"、\"OPENAI_API_KEY\" environment variable.\n\n### Documentation Links\n\nhttps://www.yuque.com/eosphoros/dbgpt-docs/nfwfycuu024fn648\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "riverhell",
      "author_type": "User",
      "created_at": "2024-09-03T10:04:20Z",
      "updated_at": "2025-01-08T21:04:49Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1950/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1950",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1950",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:05.768195",
      "comments": [
        {
          "author": "riverhell",
          "body": "Solve it ! https://github.com/eosphoros-ai/DB-GPT/issues/1604#issuecomment-2151499049",
          "created_at": "2024-09-10T09:37:20Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-08T21:04:48Z"
        }
      ]
    },
    {
      "issue_number": 1998,
      "title": "[Bug] run cpu get error",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\non cpu\n\n### Models information\n\ndeploy on cpu\n\n### What happened\n\npip install python package and run project on cpu.but i get error \" RuntimeError: \"LayerNormKernelImpl\" not implemented for 'Half'\"  cpu not surport float16.please give me advice to solve this question.thank. \r\nmodel: local chatglm-6b   and semantic model:bge-m3\r\n\n\n### What you expected to happen\n\npip install python package and run project on cpu.but i get error \" RuntimeError: \"LayerNormKernelImpl\" not implemented for 'Half'\"  cpu not surport float16.please give me advice to solve this question.thank. \r\nmodel: local chatglm-6b   and semantic model:bge-m3\r\n\n\n### How to reproduce\n\npip install python package and run project on cpu.but i get error \" RuntimeError: \"LayerNormKernelImpl\" not implemented for 'Half'\"  cpu not surport float16.please give me advice to solve this question.thank. \r\nmodel: local chatglm-6b   and semantic model:bge-m3\r\n\n\n### Additional context\n\npip install python package and run project on cpu.but i get error \" RuntimeError: \"LayerNormKernelImpl\" not implemented for 'Half'\"  cpu not surport float16.please give me advice to solve this question.thank. \r\nmodel: local chatglm-6b   and semantic model:bge-m3\r\n\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "citePerson",
      "author_type": "User",
      "created_at": "2024-09-10T10:55:04Z",
      "updated_at": "2025-01-08T21:04:46Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1998/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1998",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1998",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:05.960729",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-08T21:04:45Z"
        }
      ]
    },
    {
      "issue_number": 2242,
      "title": "[Bug]Knowledge graph preview error report",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nMacOS(M1, M2...)\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [X] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nmacos\n\n### Models information\n\ntext2vec\n\n### What happened\n\nThe atlas can be sliced normally but an error is reported when previewing the knowledge atlas.\r\n\r\n\r\n![1734920037990](https://github.com/user-attachments/assets/b31e1da8-39e3-4f9a-a007-2c97e98814e7)\r\n\n\n### What you expected to happen\n\nThe atlas can be sliced normally but an error is reported when previewing the knowledge atlas.\r\n\r\n\r\n![1734920037990](https://github.com/user-attachments/assets/b31e1da8-39e3-4f9a-a007-2c97e98814e7)\r\n\n\n### How to reproduce\n\nThe atlas can be sliced normally but an error is reported when previewing the knowledge atlas.\r\n\r\n\r\n![1734920037990](https://github.com/user-attachments/assets/b31e1da8-39e3-4f9a-a007-2c97e98814e7)\r\n\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "zzll22",
      "author_type": "User",
      "created_at": "2024-12-23T02:17:58Z",
      "updated_at": "2025-01-08T05:22:39Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 8,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2242/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2242",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2242",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:06.159946",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "it looks like leiden plugin error, how do you  install your leiden plugin?",
          "created_at": "2024-12-23T07:10:25Z"
        },
        {
          "author": "zzll22",
          "body": "@Aries-ckt docker run -d -p 7070:7070  -p 7687:7687 --name tugraph tugraph/tugraph-runtime-centos7:latest lgraph_server -d run --enable_plugin true",
          "created_at": "2024-12-23T09:32:18Z"
        },
        {
          "author": "zzll22",
          "body": "![Picture](https://github.com/user-attachments/assets/637f856a-fe3d-4da0-9b1f-07e758b206c4)\r\nThe leiden plug-in for neo4j failed, and then it seemed that the entire binary so was printed out, and the command line interface was stuck because of this.",
          "created_at": "2024-12-23T09:43:30Z"
        },
        {
          "author": "zzll22",
          "body": "https://www.53ai.com/news/OpenSourceLLM/2024121937049.html\r\nEncountered the same problem",
          "created_at": "2024-12-23T09:43:58Z"
        },
        {
          "author": "zzll22",
          "body": "@Aries-ckt How did you solve it?",
          "created_at": "2024-12-23T09:44:38Z"
        }
      ]
    },
    {
      "issue_number": 1875,
      "title": "单智能体聊天，回复的答案会被后面的内容覆盖，导致输出的内容不完整",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\ncpu\n\n### Models information\n\ndeepseek\n\n### What happened\n\n![image](https://github.com/user-attachments/assets/a2555cf5-cbe7-4ade-aa0c-ebce76b4dfa3)\r\n自定义单智能体应用，答案输出只保留最后内容输出\r\n\n\n### What you expected to happen\n\n完整的答案内容\n\n### How to reproduce\n\n创建单智能体应用，聊天\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "huicewang",
      "author_type": "User",
      "created_at": "2024-08-23T03:59:42Z",
      "updated_at": "2025-01-07T21:04:54Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1875/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1875",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1875",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:06.414077",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "yeah, it's a prompt problem, you can define your prompt by yourself\r\n![image](https://github.com/user-attachments/assets/a4170d6e-2d04-4885-976d-709422bd8f6a)\r\n",
          "created_at": "2024-09-09T12:32:39Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-07T21:04:52Z"
        }
      ]
    },
    {
      "issue_number": 2142,
      "title": "[Bug] [Module Name] Bug title LLM test using prompt page does not get complete results",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [X] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [X] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU V100\n\n### Models information\n\nLLM： qwen2.5-72b\n\n### What happened\n\n1. 当我使用prompt时，输入，点击LLM测试之后，发现后台会输入一个很完整的回答，但是在prompt界面当中只能看到第一句，很奇怪，请教各位老师是什么原因？结果如图，黑色是我后台输出的一部分，远比LLM OUT呈现的内容多的多\r\n![image](https://github.com/user-attachments/assets/ea11b105-efaa-49ce-9d69-3756abe39a2a)\r\n![image](https://github.com/user-attachments/assets/4392b73c-1adc-4ff2-ba70-fdca0610fe3d)\r\n\r\n2. 请问在prompt界面中右下角的输出验证是什么意思？点击之后会在LLM OUT中出现红色的提示，‘当前场景没有找到可用的Prompt模版，chat_with_db_qa‘\n\n### What you expected to happen\n\n请老师解答我这两个问题\n\n### How to reproduce\n\n连接数据库执行即可\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "adogwangwang",
      "author_type": "User",
      "created_at": "2024-11-21T07:22:19Z",
      "updated_at": "2025-01-06T03:24:47Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2142/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2142",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2142",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:06.705838",
      "comments": [
        {
          "author": "Sloane9511",
          "body": "我也遇到了这个问题，有解决吗请问",
          "created_at": "2025-01-06T03:24:45Z"
        }
      ]
    },
    {
      "issue_number": 1966,
      "title": "[Bug] [ChatDashboard] Error 'ChatChartEditContext' object has no attribute 'con_uid'. Did you mean: 'conv_uid'?",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [X] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU,3060\n\n### Models information\n\nLLM: WENXIN\r\nEMBEDDED: text2vec-large-chinese\n\n### What happened\n\nI setup a database by sqlite3 and get the connect with dbgpt.\r\n![1725448510301](https://github.com/user-attachments/assets/43d3ba79-a0db-4299-9ff8-b8a355762e0d)\r\nwhen i start to make the conversition. like: analysis the data. the gpt response me with a SQL however it isn't work. So i change the sql in editor and click the save button. I'm sure the sql i change works will in sqliteStudio. however, i get error in background：\r\n![1725448705539](https://github.com/user-attachments/assets/787fed0a-57e1-40a9-bb64-fadaabce9458)\r\ni didn't change the source code and according to the error message it seams that there are two fileds with the similar name.\r\nplease help to have a check, thanks.\n\n### What you expected to happen\n\nthe error message in backgournd shows: 'ChatChartEditContext' object has no attribute 'con_uid'. Did you mean: 'conv_uid'?\r\nand that means there are two fields with the similar name . and there is no response after all actions.\n\n### How to reproduce\n\n1. go to dashboard chat.\r\n2. analysis the data use your own database.\r\n3. try to let the gpt generate a SQL and make sure the sql can not excute.\r\n4. make change according to the SQL and make sure it is excutable.\r\n5. paste the sql from database to editor page and click the save button.\r\n6. then you will see the errro message in background.\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "fluentlymos",
      "author_type": "User",
      "created_at": "2024-09-04T11:23:54Z",
      "updated_at": "2025-01-03T21:04:51Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1966/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1966",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1966",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:07.221918",
      "comments": [
        {
          "author": "fluentlymos",
          "body": "i made one more update for this issue since seems i find something related:\r\nin api_editor_v1: used :chart_edit_context.con_uid\r\n![1725537788447](https://github.com/user-attachments/assets/8b58125d-ce1b-42da-b91b-e2525fef6c10)\r\nhowever, the type: chart_edit_context:ChatChartEditContext didn't have t",
          "created_at": "2024-09-05T12:09:09Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-03T21:04:50Z"
        }
      ]
    },
    {
      "issue_number": 1980,
      "title": "[Feature][Module Name] DB-GPT support text to cypher",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nDB-GPT support text to cypher，call graph database query\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nHigh\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Wang-Jun-Chao",
      "author_type": "User",
      "created_at": "2024-09-05T00:14:14Z",
      "updated_at": "2025-01-03T21:04:50Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1980/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1980",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1980",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:07.465924",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-03T21:04:49Z"
        }
      ]
    },
    {
      "issue_number": 2261,
      "title": "[Bug] [Module Name] it will re-summary dbschema when restart dbgpt server",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [X] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [X] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\ncpu\n\n### Models information\n\nLLM:chat-gpt\n\n### What happened\n\n使用mysql做存储，每次重启服务之后gpts_app表数据都会初始化，导致之前后台配置的信息丢失，这个有配置项可以控制吗，\r\n源码启动或者docker compose都是一样的\n\n### What you expected to happen\n\n使用mysql做存储，每次重启服务之后gpts_app表数据都会初始化，导致之前后台配置的信息丢失，这个有配置项可以控制吗，\r\n源码启动或者docker compose都是一样的\n\n### How to reproduce\n\n使用mysql做存储，每次重启服务之后gpts_app表数据都会初始化，导致之前后台配置的信息丢失，这个有配置项可以控制吗，\r\n源码启动或者docker compose都是一样的\n\n### Additional context\n\n使用mysql做存储，每次重启服务之后gpts_app表数据都会初始化，导致之前后台配置的信息丢失，这个有配置项可以控制吗，\r\n源码启动或者docker compose都是一样的\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "zxlzhd",
      "author_type": "User",
      "created_at": "2024-12-31T07:14:18Z",
      "updated_at": "2025-01-03T09:07:15Z",
      "closed_at": "2025-01-03T09:07:14Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2261/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2261",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2261",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:07.710124",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "hi, when restart dbgpt_server, the db schema summery only initialization once.\r\nyou can check in `db_summary_client.py`\r\n```python\r\n        if not table_vector_connector.vector_name_exists():\r\n            from dbgpt.rag.assembler.db_schema import DBSchemaAssembler\r\n\r\n            chunk_parameters = C",
          "created_at": "2025-01-01T15:04:32Z"
        },
        {
          "author": "zxlzhd",
          "body": "Thank you for your reply. However, my issue is not with re-summarizing the dbschema. Instead, after restarting, the table data is being reset. For example, the data in the gpts_app table is cleared each time and initialized with demo data. It appears that this is handled by the gpts_dao.init_native_",
          "created_at": "2025-01-02T03:48:06Z"
        },
        {
          "author": "zxlzhd",
          "body": "I know, the re init app is the demo,if create new app will not init",
          "created_at": "2025-01-03T09:07:15Z"
        }
      ]
    },
    {
      "issue_number": 1957,
      "title": "[Bug] [Module Name] Bug title ",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [X] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU\n\n### Models information\n\nLLM: QWEN2-max\n\n### What happened\n\n在应用界面，能够成功连接MySQL数据库，但是在ChatDB或者自定义应用时，显示“暂无数据”。\r\n![lQLPJyDiIYN7Jb_NAuvNBHGwYPaNyMPC76EGwFJYaTqAAQ_1137_747](https://github.com/user-attachments/assets/75f3221b-1520-4fab-9016-8cb2e2a0b44d)\r\n![lQLPJxpf7-6a2P_NAT3NA0yw1VztY-wirPgGwFVN9b4WAA_844_317](https://github.com/user-attachments/assets/8709ae15-941b-481b-a7ac-f299e0fa2c78)\r\n\n\n### What you expected to happen\n\n已按照文档，在连接MySQL数据库时，运行相应版本的.sql文件。但是在界面中仍然无法查询到数据。\n\n### How to reproduce\n\n1. 在界面连接MySQL数据库\r\n2. 进入ChatDB应用，开始对话\r\n3. 选择参数 -> 暂无数据。\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "JackyMeow",
      "author_type": "User",
      "created_at": "2024-09-04T03:14:25Z",
      "updated_at": "2025-01-02T21:04:47Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1957/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1957",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1957",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:07.893785",
      "comments": [
        {
          "author": "csunny",
          "body": "@JackyMeow Thank for your pr, we have fixed this at #1953 ",
          "created_at": "2024-09-04T08:43:05Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-02T21:04:46Z"
        }
      ]
    },
    {
      "issue_number": 1959,
      "title": "[Bug] [Module Name] Bug title 0.6.0版本问题很多",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [X] Chat Data\n- [X] Chat Excel\n- [X] Chat DB\n- [X] Chat Knowledge\n- [X] Model Management\n- [X] Dashboard\n- [X] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\ncpu\n\n### Models information\n\nzhipuLLM\n\n### What happened\n\n在创建知识库的时候，没有create知识库，就进行了连接导致出错。\r\n另外tugraph的配置.env不会读取，会默认读取73@graph设定的这个字段。\r\n![image](https://github.com/user-attachments/assets/21720cd6-b800-442b-b9e8-21b7b20478c0)\r\n![1725429833015](https://github.com/user-attachments/assets/33522c05-0c87-4e5b-bb6d-785e9b7ab497)\r\n\n\n### What you expected to happen\n\n在创建知识库的时候，没有create知识库，就进行了连接导致出错。\r\n另外tugraph的配置.env不会读取，会默认读取73@graph设定的这个字段。\r\n![image](https://github.com/user-attachments/assets/21720cd6-b800-442b-b9e8-21b7b20478c0)\r\n![1725429833015](https://github.com/user-attachments/assets/33522c05-0c87-4e5b-bb6d-785e9b7ab497)\r\n\n\n### How to reproduce\n\n在创建知识库的时候，没有create知识库，就进行了连接导致出错。\r\n另外tugraph的配置.env不会读取，会默认读取73@graph设定的这个字段。\r\n![image](https://github.com/user-attachments/assets/21720cd6-b800-442b-b9e8-21b7b20478c0)\r\n![1725429833015](https://github.com/user-attachments/assets/33522c05-0c87-4e5b-bb6d-785e9b7ab497)\r\n\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Viserion-nlper",
      "author_type": "User",
      "created_at": "2024-09-04T06:04:09Z",
      "updated_at": "2025-01-02T21:04:45Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1959/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1959",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1959",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:08.098662",
      "comments": [
        {
          "author": "dkasa",
          "body": "一样问题\r\n![docker-compose部署](https://github.com/user-attachments/assets/f66fe0a0-ea7b-4ff4-a983-8cacaec839dd)\r\n",
          "created_at": "2024-09-04T08:43:39Z"
        },
        {
          "author": "KingSkyLi",
          "body": "您好：\r\nTuGraph的启动方式：加 --enable_plugin true\r\n启动方式如下：\r\ndocker run -d -p 7070:7070  -p 7687:7687 -p 9090:9090 --name tugraph_demo reg.docker.alibaba-inc.com/fma/tugraph-runtime-centos7:latest lgraph_server -d run --enable_plugin true",
          "created_at": "2024-09-04T10:31:40Z"
        },
        {
          "author": "Viserion-nlper",
          "body": "该docker镜像pull的链接是多少哈 我拉一下\r\n",
          "created_at": "2024-09-04T10:38:02Z"
        },
        {
          "author": "Viserion-nlper",
          "body": "![image](https://github.com/user-attachments/assets/a2d7cc91-695a-4295-8555-d50cd8b30f49)\r\n",
          "created_at": "2024-09-04T10:40:11Z"
        },
        {
          "author": "Viserion-nlper",
          "body": "@KingSkyLi \r\n",
          "created_at": "2024-09-04T10:40:19Z"
        }
      ]
    },
    {
      "issue_number": 2040,
      "title": "[Bug] [Agent]  self.actions.append(action(language=self.language)) TypeError: SummaryAction.__init__() got an unexpected keyword argument 'language'",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [X] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\ngpu\n\n### Models information\n\nyi:9b\n\n### What happened\n\nwhen I custom agent like doc: https://www.yuque.com/eosphoros/dbgpt-docs/de03l1n9kkg661wi#,  I use \"dbgpt new app -t agent --definition_type python -n test_agent2\" create agent in my local reposity, then I use \"dbgpt app install -r local/dbgpts test_agent2\" to install this agent. then i got this problem\n\n### What you expected to happen\n\ninstall the agent to project\n\n### How to reproduce\n\n1.dbgpt new app -t agent --definition_type python -n test_agent2\r\n2.dbgpt app install -r local/dbgpts test_agent2\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "long135",
      "author_type": "User",
      "created_at": "2024-09-24T03:14:43Z",
      "updated_at": "2025-01-02T11:21:09Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2040/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2040",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2040",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:08.301671",
      "comments": [
        {
          "author": "long135",
          "body": "this is my agent in local reposity\r\n<img width=\"216\" alt=\"Snipaste_2024-09-24_11-18-39\" src=\"https://github.com/user-attachments/assets/35d77c6f-e9b3-452f-8fc3-2c8f87f6b3b4\">\r\n\r\n",
          "created_at": "2024-09-24T03:19:35Z"
        },
        {
          "author": "long135",
          "body": "![图片](https://github.com/user-attachments/assets/5803401d-abdd-4438-88e6-8a554c3e64c4)\r\n",
          "created_at": "2024-09-24T03:22:28Z"
        },
        {
          "author": "IamWWT",
          "body": "I encountered this issue as well, but it happened after I installed the community dbgpts application. Moreover, some community applications are not working properly, for instance, after intent recognition, appLaunch cannot actually open the application.",
          "created_at": "2024-10-12T08:50:07Z"
        },
        {
          "author": "Bowie666",
          "body": "> I encountered this issue as well, but it happened after I installed the community dbgpts application. Moreover, some community applications are not working properly, for instance, after intent recognition, appLaunch cannot actually open the application.\r\n\r\n@IamWWT  Me too, I also got an error afte",
          "created_at": "2025-01-02T07:46:12Z"
        },
        {
          "author": "chaoStart",
          "body": "Me too, I also got an error after installing the dbgpts application.how did you solve it?",
          "created_at": "2025-01-02T11:07:33Z"
        }
      ]
    },
    {
      "issue_number": 1886,
      "title": "[Bug] [Module Name] 无法运行 缺少 fastapi",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [X] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n  File \"F:\\aimodels\\DB-GPT\\dbgpt\\app\\dbgpt_server.py\", line 6, in <module>\r\n    from fastapi import FastAPI\r\nModuleNotFoundError: No module named 'fastapi'\n\n### Models information\n\n  File \"F:\\aimodels\\DB-GPT\\dbgpt\\app\\dbgpt_server.py\", line 6, in <module>\r\n    from fastapi import FastAPI\r\nModuleNotFoundError: No module named 'fastapi'\n\n### What happened\n\n  File \"F:\\aimodels\\DB-GPT\\dbgpt\\app\\dbgpt_server.py\", line 6, in <module>\r\n    from fastapi import FastAPI\r\nModuleNotFoundError: No module named 'fastapi'\n\n### What you expected to happen\n\n  File \"F:\\aimodels\\DB-GPT\\dbgpt\\app\\dbgpt_server.py\", line 6, in <module>\r\n    from fastapi import FastAPI\r\nModuleNotFoundError: No module named 'fastapi'\n\n### How to reproduce\n\n  File \"F:\\aimodels\\DB-GPT\\dbgpt\\app\\dbgpt_server.py\", line 6, in <module>\r\n    from fastapi import FastAPI\r\nModuleNotFoundError: No module named 'fastapi'\n\n### Additional context\n\n  File \"F:\\aimodels\\DB-GPT\\dbgpt\\app\\dbgpt_server.py\", line 6, in <module>\r\n    from fastapi import FastAPI\r\nModuleNotFoundError: No module named 'fastapi'\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "icetech233",
      "author_type": "User",
      "created_at": "2024-08-26T06:34:07Z",
      "updated_at": "2025-01-02T02:26:11Z",
      "closed_at": "2024-08-28T09:33:41Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1886/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1886",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1886",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:08.476561",
      "comments": [
        {
          "author": "fujunsfzh",
          "body": "@icetech233 遇到了同样的问题：No module named 'fastapi'，请教您那怎么解决的",
          "created_at": "2025-01-02T02:26:09Z"
        }
      ]
    },
    {
      "issue_number": 1929,
      "title": "[Doc][Module Name] dbgpt新版本会在大会上发布吗",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\ndbgpt新版本会在大会上发布吗\n\n### Documentation Links\n\ndbgpt新版本会在大会上发布吗\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Viserion-nlper",
      "author_type": "User",
      "created_at": "2024-08-30T04:30:14Z",
      "updated_at": "2025-01-01T21:05:12Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1929/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1929",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1929",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:08.658662",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "是的，到时候有个展台演示。",
          "created_at": "2024-08-31T12:49:13Z"
        },
        {
          "author": "Viserion-nlper",
          "body": "在哪个区域呢 我们想过去学习下",
          "created_at": "2024-09-02T01:47:17Z"
        },
        {
          "author": "Viserion-nlper",
          "body": "@Aries-ckt ",
          "created_at": "2024-09-03T03:31:50Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-01T21:05:10Z"
        }
      ]
    },
    {
      "issue_number": 1947,
      "title": "[Bug] [ChatData]  In the SQL editor, updates to sql or comments cannot be saved and run ",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [X] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice：CPU\n\n### Models information\n\nLLM：tongyi_proxyllm\r\nEmbedding Model：text2vec-large-chinese\n\n### What happened\n\nExecute manually edited SQL statements normally.\r\n\n\n### What you expected to happen\n\nThe edited SQL and comments can be executed and saved normally\n\n### How to reproduce\n\nstep1：In chat data, the normal input requirements will generate the corresponding SQL and chart\r\nstep2：through editing, enter the SQL editor, modify the SQL or comments in the SQL editor, and then click Save or Run, the result will report an error\r\nError interface：api/v1/sql/editor/submit and api/v1/editor/sql/run\r\nCause of error：Interface missing parameter，new_sql and new_speak are missing.The cause of the error should be an error occurred when the front-end was cutting the modified parameter\r\neg：\r\napi/v1/sql/editor/submit\r\nError request parameters：\r\n```\r\nconv_round: 1\r\nconv_uid: \"e4a9fc39-69b8-11ef-baef-e0be0372346e\"\r\ndb_name: \"dbgpt_test\"\r\nnew_speak: \"\"\r\nold_speak: \"首先，需要从transaction_order表中查询出每个用户的订单数量。然后，根据订单数量对用户进行排序。最后，使用柱状图展示结果。\"\r\nold_sql: \"SELECT u.name, COUNT(*) as order_count FROM transaction_order t JOIN user u ON t.user_id = u.id GROUP BY u.id ORDER BY order_count DESC\"\r\n```\r\nNormal request parameters\r\n\r\n```\r\nconv_round: 1\r\nconv_uid: \"e4a9fc39-69b8-11ef-baef-e0be0372346e\"\r\ndb_name: \"dbgpt_test\"\r\nnew_speak: \"首先，需要从transaction_order表中查询出每个用户的订单数量。然后，根据订单数量对用户进行排序。最后，使用柱状图展示结果。111\"\r\nnew_sql: \"SELECT u.name, COUNT(*) as order_count FROM transaction_order t JOIN user u ON t.user_id = u.id GROUP BY u.id ORDER BY order_count DESC\"\r\nold_speak: \"首先，需要从transaction_order表中查询出每个用户的订单数量。然后，根据订单数量对用户进行排序。最后，使用柱状图展示结果。\"\r\nold_sql: \"SELECT u.name, COUNT(*) as order_count FROM transaction_order t JOIN user u ON t.user_id = u.id GROUP BY u.id ORDER BY order_count DESC\"\r\n```\r\n\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "Silecne666",
      "author_type": "User",
      "created_at": "2024-09-03T06:50:05Z",
      "updated_at": "2025-01-01T21:05:10Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1947/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1947",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1947",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:08.856888",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-01T21:05:09Z"
        }
      ]
    },
    {
      "issue_number": 1949,
      "title": "[Bug] [Chat Knowledge] [SERVER_ERROR]InvalidParameter",
      "body": "### Search before asking\r\n\r\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\r\n\r\n\r\n### Operating system information\r\n\r\nLinux\r\n\r\n### Python version information\r\n\r\n>=3.11\r\n\r\n### DB-GPT version\r\n\r\nmain\r\n\r\n### Related scenes\r\n\r\n- [ ] Chat Data\r\n- [ ] Chat Excel\r\n- [ ] Chat DB\r\n- [X] Chat Knowledge\r\n- [ ] Model Management\r\n- [ ] Dashboard\r\n- [ ] Plugins\r\n\r\n### Installation Information\r\n\r\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\r\n\r\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\r\n\r\n- [ ] AutoDL Image\r\n- [ ] Other\r\n\r\n### Device information\r\n\r\n4090 24G\r\n\r\n\r\n### Models information\r\n\r\ntongyi_proxyllm\r\nEmbedding: text2vec-large-chinese\r\n\r\n### What happened\r\n\r\n**DB-GPT版本：0.5.10**\r\n当根据教程创建知识库后，数据为docker/examples/fin_report/pdf下的文档\r\n在知识库对话界面：\r\n输入：浙江海翔药业股份有限公司资产负债率\r\n回复正常\r\n当输入：浙江海翔药业股份有限公司资产构成重大变动情况 时\r\n回复异常：\r\n**[SERVER_ERROR]InvalidParameter:<400> InternalError.Algo.InvalidParameter: Range of input length should be [1, 6000]**\r\n\r\n后台报错如下：\r\n`stream output:\r\n\r\nInvalidParameter:<400> InternalError.Algo.InvalidParameter: Range of input length should be [1, 6000]2024-09-03 17:11:39 hadoop-222 dbgpt.model.cluster.worker.default_worker[3760654] INFO is_first_generate, usage: None\r\n2024-09-03 17:11:39 hadoop-222 asyncio[3760654] ERROR Task exception was never retrieved\r\nfuture: <Task finished name='Task-6768' coro=<<async_generator_athrow without __name__>()> exception=RuntimeError('DAG context not found with event loop task id 139836486165760, task_name: Task-6768')>\r\nTraceback (most recent call last):\r\n  File \"/stang_llm/DB-GPT-0.5.10/dbgpt/core/awel/util/chat_util.py\", line 81, in safe_chat_stream_with_dag_task\r\n    yield output\r\nGeneratorExit\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/stang_llm/DB-GPT-0.5.10/dbgpt/core/awel/util/chat_util.py\", line 89, in safe_chat_stream_with_dag_task\r\n    await task.dag._after_dag_end(task.current_event_loop_task_id)\r\n  File \"/JjtGPT/stang_llm/DB-GPT-0.5.10/dbgpt/core/awel/dag/base.py\", line 751, in _after_dag_end\r\n    raise RuntimeError(\r\nRuntimeError: DAG context not found with event loop task id 139836486165760, task_name: Task-6768\r\n`\r\n![image](https://github.com/user-attachments/assets/aac7a22f-08f9-45d5-b97f-cb6dd780d810)\r\n\r\n\r\n### What you expected to happen\r\n\r\npass\r\n\r\n### How to reproduce\r\n\r\npass\r\n\r\n### Additional context\r\n\r\n_No response_\r\n\r\n### Are you willing to submit PR?\r\n\r\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "yungongzi",
      "author_type": "User",
      "created_at": "2024-09-03T09:34:49Z",
      "updated_at": "2025-01-01T21:05:08Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1949/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1949",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1949",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:09.077379",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2025-01-01T21:05:08Z"
        }
      ]
    },
    {
      "issue_number": 2231,
      "title": "[Feature] Use Gitee AI  Model API ？",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n这里是 Gitee AI 平台，隶属于开源中国项目。我们目前正在积极拓展合作伙伴。据我们了解，DB-GPT 可以集成到我们的 Serverless API 应用中，并且为您提供详细的集成配置指南。我们认为，通过合作，我们可以提升知名度并共同提升用户的 AI 使用体验。\r\n\r\n这是对应的对接文档:\r\nhttps://ai.gitee.com/docs/openapi/serverless\r\n也可以用openai兼容的方式接入:\r\nhttps://ai.gitee.com/docs/openapi/v1\r\n\r\n---------------\r\n\r\n[我们希望与贵公司产品确认合作意向。如果您对合作感兴趣，可以添加我的微信。]\r\n![产品合作伙伴-马建仓小助手](https://github.com/user-attachments/assets/1778e897-9627-4ece-a740-32f19906df06)\r\n\r\n\r\n合作权益包括：\r\n\r\n产业合作伙伴展示墙：https://ai.gitee.com/partner\r\n专业 1v1 技术支持\r\n\r\n期待您的回复！\n\n### Use case\n\n接入Gitee AI提供的API，达成产品级合作\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "pittosporum1",
      "author_type": "User",
      "created_at": "2024-12-20T08:22:49Z",
      "updated_at": "2024-12-31T11:24:25Z",
      "closed_at": "2024-12-31T11:24:25Z",
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2231/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2231",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2231",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:09.302759",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "非常感谢，这个合作能一起共建吗？\r\nbtw, https://ai.gitee.com/partner 这个页面没内容呢",
          "created_at": "2024-12-20T10:33:43Z"
        }
      ]
    },
    {
      "issue_number": 1918,
      "title": "[Feature][Module Name] Feature title Maybe combine with Ollama is the best way to run it as business level",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nCurrently, in real-world scenarios, the Ollama-hosted modeling scheme is more robust and convenient, as the Ollama-hosted model responds better without GPUs. However, the current modeling scheme is very complex, prone to exceptions, and after startup, the response is much slower than the response of the running model in Ollama.\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "zencorn",
      "author_type": "User",
      "created_at": "2024-08-29T10:05:26Z",
      "updated_at": "2024-12-27T21:04:42Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1918/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1918",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1918",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:09.494979",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-12-27T21:04:41Z"
        }
      ]
    },
    {
      "issue_number": 1791,
      "title": "[Bug] [prompt] ChatDB and others do not use prompts in the process of interacting with the database. Data analysis after using comments in the database table is not accurate.",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nMacOS(M1, M2...)\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [X] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [X] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n使用的openai，本机是mac probook m1 16g\n\n### Models information\n\ngpt3.5\n\n### What happened\n\n数据不准\r\n<img width=\"1036\" alt=\"9327102fb72377f4d94f2c5a9dea9c6\" src=\"https://github.com/user-attachments/assets/b09076d1-361d-42a6-9ff2-f78f20e245bc\">\r\n\r\n\n\n### What you expected to happen\n\n1、本项目使用prompt到底有没有效果，目测是没有效果的，他的工作原理设计之初是如何运作的\r\n2、如何让跟数据库表交互更有准确性，难道只是给数据库表字段设置comment，有没有详细的文案引导使用者\r\n3、我们需要企业级应用，准确性要求会高点\n\n### How to reproduce\n\n希望创作者提供下如何让跟数据库交互更准确的方法，小白可能有些地方不太明白\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "liukun084",
      "author_type": "User",
      "created_at": "2024-08-08T02:11:27Z",
      "updated_at": "2024-12-26T21:05:05Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1791/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1791",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1791",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:09.681127",
      "comments": [
        {
          "author": "liukun084",
          "body": "需要如何解？？",
          "created_at": "2024-08-12T01:57:43Z"
        },
        {
          "author": "liukun084",
          "body": "能解不能解决这个",
          "created_at": "2024-08-28T12:04:54Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-12-26T21:05:04Z"
        }
      ]
    },
    {
      "issue_number": 2249,
      "title": "[Bug] [EmbeddingModelParameters ] When I start dbgpt, it will automatically terminate without an error",
      "body": "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice: CPU\n\n### Models information\n\nLLM: tongyi_proxyllm Embedding model: text2vec-large-chinese\n\n### What happened\n\nWhen I run the command: $ python dbgpt/app/dbgpt_server.py\r\nThe previous ones were all very smooth, but after running to here:\r\n=========================== EmbeddingModelParameters ===========================\r\n\r\nmodel_name: text2vec\r\nmodel_path: f:\\桌面\\dbgpt\\db-gpt\\models\\text2vec-large-chinese\r\ndevice: cpu\r\nnormalize_embeddings: None\r\nrerank: False\r\nmax_length: None\r\n\r\n======================================================================\r\n\r\n\r\n2024-12-24 16:40:55 LAPTOP-SLEAVUQ2 sentence_transformers.SentenceTransformer[21704] INFO Load pretrained SentenceTransformer: f:\\桌面\\dbgpt\\db-gpt\\models\\text2vec-large-chinese\r\n2024-12-24 16:40:55 LAPTOP-SLEAVUQ2 sentence_transformers.SentenceTransformer[21704] WARNING No sentence-transformers model found with name f:\\桌面\\dbgpt\\db-gpt\\models\\text2vec-large-chinese. Creating a new one with mean pooling.\r\n2024-12-24 16:40:55 LAPTOP-SLEAVUQ2 dbgpt.component[21704] INFO Register component with name embedding_factory and instance: <dbgpt.app.initialization.embedding_component.LocalEmbeddingFactory object at 0x0000018A3EC9F650>\r\n\r\nthe program automatically exited without any error information.\n\n### What you expected to happen\n\nThe program is working properly and then I can access  “http://localhost:5670”\n\n### How to reproduce\n\nAccording to the source code installation part of the official documentation, proceed until the last step:\r\n $ python dbgpt/app/dbgpt_server.py\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "Levent-z",
      "author_type": "User",
      "created_at": "2024-12-25T07:40:57Z",
      "updated_at": "2024-12-26T08:51:15Z",
      "closed_at": "2024-12-26T08:51:14Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2249/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2249",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2249",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:09.887695",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "it will reproduce every time?",
          "created_at": "2024-12-26T08:39:34Z"
        },
        {
          "author": "Levent-z",
          "body": "> it will reproduce every time?\r\n\r\nI don't know. I deleted the project file, and then re-git clone there is no exception, the program is able to run normally. Thank you for your attention!",
          "created_at": "2024-12-26T08:51:14Z"
        }
      ]
    },
    {
      "issue_number": 2236,
      "title": "[Bug] [Model] Bug title RuntimeError: Unexpected error from cudaGetDeviceCount()",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [X] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU count:1，GPU Memory 24G\n\n### Models information\n\nLLM: qwen2.5-7b-instruct\r\nEMBEDDING_MODEL: m3e-base\n\n### What happened\n\n**I deployed the dbgpt project through a Docker container. It can run normally without loading the local model using vllm. \r\nHowever, if MODEL_TYPE is set to vllm (vllm dependency package has been installed), it will fail to run.** \r\nThe error message is as follows:\r\nERROR Error starting worker manager: model qwen2.5-7b-instruct@vllm(172.21.0.3:5670) start failed, Traceback (most recent call last):\r\n2024-12-19 17:34:32   File \"/app/dbgpt/model/cluster/worker/manager.py\", line 507, in _start_worker\r\n2024-12-19 17:34:32     await self.run_blocking_func(\r\n2024-12-19 17:34:32   File \"/app/dbgpt/model/cluster/worker/manager.py\", line 105, in run_blocking_func\r\n2024-12-19 17:34:32     return await loop.run_in_executor(self.executor, func, *args)\r\n2024-12-19 17:34:32   File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\r\n2024-12-19 17:34:32     result = self.fn(*self.args, **self.kwargs)\r\n2024-12-19 17:34:32   File \"/app/dbgpt/model/cluster/worker/default_worker.py\", line 116, in start\r\n2024-12-19 17:34:32     self.model, self.tokenizer = self.ml.loader_with_params(\r\n2024-12-19 17:34:32   File \"/app/dbgpt/model/adapter/loader.py\", line 132, in loader_with_params\r\n2024-12-19 17:34:32     return llm_adapter.load_from_params(model_params)\r\n2024-12-19 17:34:32   File \"/app/dbgpt/model/adapter/vllm_adapter.py\", line 78, in load_from_params\r\n2024-12-19 17:34:32     engine = AsyncLLMEngine.from_engine_args(engine_args)\r\n2024-12-19 17:34:32   File \"/usr/local/lib/python3.10/dist-packages/vllm/engine/async_llm_engine.py\", line 395, in from_engine_args\r\n2024-12-19 17:34:32     engine = cls(\r\n2024-12-19 17:34:32   File \"/usr/local/lib/python3.10/dist-packages/vllm/engine/async_llm_engine.py\", line 349, in __init__\r\n2024-12-19 17:34:32     self.engine = self._init_engine(*args, **kwargs)\r\n2024-12-19 17:34:32   File \"/usr/local/lib/python3.10/dist-packages/vllm/engine/async_llm_engine.py\", line 470, in _init_engine\r\n2024-12-19 17:34:32     return engine_class(*args, **kwargs)\r\n2024-12-19 17:34:32   File \"/usr/local/lib/python3.10/dist-packages/vllm/engine/llm_engine.py\", line 223, in __init__\r\n2024-12-19 17:34:32     self.model_executor = executor_class(\r\n2024-12-19 17:34:32   File \"/usr/local/lib/python3.10/dist-packages/vllm/executor/executor_base.py\", line 41, in __init__\r\n2024-12-19 17:34:32     self._init_executor()\r\n2024-12-19 17:34:32   File \"/usr/local/lib/python3.10/dist-packages/vllm/executor/gpu_executor.py\", line 22, in _init_executor\r\n2024-12-19 17:34:32     self.driver_worker = self._create_worker()\r\n2024-12-19 17:34:32   File \"/usr/local/lib/python3.10/dist-packages/vllm/executor/gpu_executor.py\", line 67, in _create_worker\r\n2024-12-19 17:34:32     wrapper.init_worker(**self._get_worker_kwargs(local_rank, rank,\r\n2024-12-19 17:34:32   File \"/usr/local/lib/python3.10/dist-packages/vllm/worker/worker_base.py\", line 134, in init_worker\r\n2024-12-19 17:34:32     self.worker = worker_class(*args, **kwargs)\r\n2024-12-19 17:34:32   File \"/usr/local/lib/python3.10/dist-packages/vllm/worker/worker.py\", line 74, in __init__\r\n2024-12-19 17:34:32     self.model_runner = ModelRunnerClass(\r\n2024-12-19 17:34:32   File \"/usr/local/lib/python3.10/dist-packages/vllm/worker/model_runner.py\", line 118, in __init__\r\n2024-12-19 17:34:32     self.attn_backend = get_attn_backend(\r\n2024-12-19 17:34:32   File \"/usr/local/lib/python3.10/dist-packages/vllm/attention/selector.py\", line 42, in get_attn_backend\r\n2024-12-19 17:34:32     backend = which_attn_to_use(num_heads, head_size, num_kv_heads,\r\n2024-12-19 17:34:32   File \"/usr/local/lib/python3.10/dist-packages/vllm/attention/selector.py\", line 117, in which_attn_to_use\r\n2024-12-19 17:34:32     if torch.cuda.get_device_capability()[0] < 8:\r\n2024-12-19 17:34:32   File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 430, in get_device_capability\r\n2024-12-19 17:34:32     prop = get_device_properties(device)\r\n2024-12-19 17:34:32   File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 444, in get_device_properties\r\n2024-12-19 17:34:32     _lazy_init()  # will define _get_device_properties\r\n2024-12-19 17:34:32   File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 293, in _lazy_init\r\n2024-12-19 17:34:32     torch._C._cuda_init()\r\n**2024-12-19 17:34:32 RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 500: named symbol not found**\r\n\r\n**If I start the project directly by command in WSL, even if MODEL_TYPE is set to the vllm type, the project can still be started and run normally.**\n\n### What you expected to happen\n\nI hope to be able to use vllm to load large models in Docker containers.\n\n### How to reproduce\n\nRun the project in a Docker container and set MODEL_TYPE to vllm. The version of vllm I use is 0.5.0.\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "xuxl2024",
      "author_type": "User",
      "created_at": "2024-12-20T15:01:32Z",
      "updated_at": "2024-12-26T06:25:51Z",
      "closed_at": "2024-12-26T06:25:51Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2236/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2236",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2236",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:10.069470",
      "comments": [
        {
          "author": "xuxl2024",
          "body": "排查了一下，在docker容器中运行，模型启动始终用的是cpu，而不是gpu；但是在wsl中用python dbgpt_server.py来运行程序，使用的就是gpu，搞不清楚为什么docker容器中启动无法使用到gpu\r\n\r\n",
          "created_at": "2024-12-25T02:59:41Z"
        }
      ]
    },
    {
      "issue_number": 2031,
      "title": "[Bug]ERROR document embedding, failed",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [X] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU内存：28G\n\n### Models information\n\n模型文件如图\r\n![image](https://github.com/user-attachments/assets/1ff92cb5-a079-4f4f-8c47-292517f735e1)\r\n\n\n### What happened\n\n上传文件到知识库中，知识库创建成功，但是文本切分失败\r\n\n\n### What you expected to happen\n\n输入embedding模型后切分数据\r\n![1](https://github.com/user-attachments/assets/23af1947-9f84-4c01-894d-8e5e0f21ab42)\r\n\r\n\r\n\n\n### How to reproduce\n\n1. 进入Knowledge页面，创建向量库，配置如图所示\r\n![2](https://github.com/user-attachments/assets/64d05b96-ae77-410c-b3f0-a022657643fd)\r\n2. 点击文档上传文档\r\n3. 选择自动切分\r\n4. 此时是可以自动切分的\r\n5. 删除新建的WHF_CS6,重复1-3步，出现bug\n\n### Additional context\n\n2024-09-19 15:45:10 localhost.localdomain dbgpt.serve.rag.service.service[13996] ERROR document embedding, failed:招待费用管理规定B1.docx, Collection 06b18bfd-57a0-4417-9e42-dc722c39d03d does not exist.\r\n/document/list params: WHF_CS6, doc_name=None doc_ids=[138] doc_type=None status=None page=1 page_size=20\r\ncurrent session:<sqlalchemy.orm.session.Session object at 0x7fd35d0a8580>\r\nINFO:     218.201.98.56:58293 - \"POST /knowledge/WHF_CS6/document/list HTTP/1.1\" 200 OK\r\n![1](https://github.com/user-attachments/assets/6f9d34c6-8a8d-4469-8b90-fd158afc4a8c)\r\n\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "2y2y2",
      "author_type": "User",
      "created_at": "2024-09-19T07:57:03Z",
      "updated_at": "2024-12-26T06:16:51Z",
      "closed_at": "2024-09-20T01:41:54Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2031/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2031",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2031",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:10.285830",
      "comments": [
        {
          "author": "Levent-z",
          "body": "我也遇到了一样的报错，请问您解决了吗",
          "created_at": "2024-12-26T06:16:50Z"
        }
      ]
    },
    {
      "issue_number": 1147,
      "title": "[Bug] [Model] When the input exceeds a certain length, the model inference freezes when using QWen-72B-Chat.",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [X] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nL40s  1T mem 8卡， 单卡现存 48G\n\n### Models information\n\nQWen-72B-Chat\n\n### What happened\n\n【篇一】小学生感人的故事作文300字\r\n　　在生活中发生很多让我感动的事，其中最感动的事是一次买气球那一天，我和姐姐妈妈上街书店看书买书，我走在步行街伤忽然发现了一个卖气球的车，旁边没有大人，只有一个小男孩，他可能是帮大人照看生意的，那车上的气球五彩缤纷，每种颜色的气球上拴着一根白线，我看见那漂亮的气球就喊妈妈带我买，在我的纠缠之下妈妈给了我10元钱，我拿着钱向车走去，小男孩看我来了就打招呼着，我问：“一个气球多少钱”，小男孩回答：“5角钱，你要多少个。”\r\n　　感人的故事我说：“要四个，给我红、黄。蓝、紫色的气球。”我一边说一边递上钱，小男孩麻利的解开红、黄、蓝、紫色的气球的递给我并把钱接了过去，我看见小男孩找钱时的表情就知道，他没有零钱找给我。他抬起头虎山着聪慧的大眼睛低声说：“零钱在我爸爸身上，现在找不开，你先拿着4个气球，6元钱我待会给你模拟先去好吧！”我握着四个气球，跟妈妈和姐姐去了新华书店，经过了长达2个小时的翻阅，我恋恋不舍地走出了书店，经过这么长的时间天都快黑了，我早就把这件事给忘了，突然一个下小男孩跑来说：“小姐姐这是你的6元钱，对不起”，他一边说一边把钱塞在我的手里，接着转身跑远了。我紧紧地攥着还带余温的6元钱，一股暖流传上心头，我被他的行为深深地感动着：多么守信用的小男孩啊！\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n输入这段话， 模型推理直接卡死， 使用 QWen  官方 vllm 推理没有这个问题\n\n### What you expected to happen\n\n卡死\n\n### How to reproduce\n\n【篇一】小学生感人的故事作文300字\r\n　　在生活中发生很多让我感动的事，其中最感动的事是一次买气球那一天，我和姐姐妈妈上街书店看书买书，我走在步行街伤忽然发现了一个卖气球的车，旁边没有大人，只有一个小男孩，他可能是帮大人照看生意的，那车上的气球五彩缤纷，每种颜色的气球上拴着一根白线，我看见那漂亮的气球就喊妈妈带我买，在我的纠缠之下妈妈给了我10元钱，我拿着钱向车走去，小男孩看我来了就打招呼着，我问：“一个气球多少钱”，小男孩回答：“5角钱，你要多少个。”\r\n　　感人的故事我说：“要四个，给我红、黄。蓝、紫色的气球。”我一边说一边递上钱，小男孩麻利的解开红、黄、蓝、紫色的气球的递给我并把钱接了过去，我看见小男孩找钱时的表情就知道，他没有零钱找给我。他抬起头虎山着聪慧的大眼睛低声说：“零钱在我爸爸身上，现在找不开，你先拿着4个气球，6元钱我待会给你模拟先去好吧！”我握着四个气球，跟妈妈和姐姐去了新华书店，经过了长达2个小时的翻阅，我恋恋不舍地走出了书店，经过这么长的时间天都快黑了，我早就把这件事给忘了，突然一个下小男孩跑来说：“小姐姐这是你的6元钱，对不起”，他一边说一边把钱塞在我的手里，接着转身跑远了。我紧紧地攥着还带余温的6元钱，一股暖流传上心头，我被他的行为深深地感动着：多么守信用的小男孩啊！\r\n\r\n\r\n\r\n输出超长字符， 直接卡死。 怀疑没有停止符\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "yangyongguang",
      "author_type": "User",
      "created_at": "2024-02-04T09:49:21Z",
      "updated_at": "2024-12-25T21:04:48Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 16,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1147/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1147",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1147",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:10.489700",
      "comments": [
        {
          "author": "yangyongguang",
          "body": "使用本地一次性运行多个模型，不会卡死。 如果用服务的形式启动， 文字过长就会挂死。一直卡着",
          "created_at": "2024-02-06T03:33:30Z"
        },
        {
          "author": "yangyongguang",
          "body": "有人帮忙解决一下这个问题么",
          "created_at": "2024-02-06T03:33:40Z"
        },
        {
          "author": "Aries-ckt",
          "body": "how did you start Qwen service?",
          "created_at": "2024-02-06T10:52:55Z"
        },
        {
          "author": "yangyongguang",
          "body": "您的邮件我已经收到了  我会及时的阅读 谢谢",
          "created_at": "2024-02-06T10:53:16Z"
        },
        {
          "author": "yangyongguang",
          "body": "CUDA_VISIBLE_DEVICES=4,5,6,7 dbgpt start worker --model_name Qwen-72B-Chat --model_path xxxxxx --model_type vllm --controller_addr http://localhost:8000 --gpu_memory_utilization 0.85\r\n@Aries-ckt  run this command， thinks",
          "created_at": "2024-02-07T02:55:00Z"
        }
      ]
    },
    {
      "issue_number": 1781,
      "title": "[Doc][Agnet] The return value of tool in agent is used directly.",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n大佬们，在自定义agent运行后怎么直接获得输出值呀，发现由大模型去管控整体流程时会有时候入参不对，例如我设置的变量名为query但它执行时传入parmas1之类的，很不准确，想要直接使用这个tool的返回值去硬编程为下一个tool的输入。其次有时候它会拼接成一个\"https://api.example.com/{tool_name}\"这样的地址去访问，编写一个request执行，请问这块逻辑是什么呀\n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "paul-yangmy",
      "author_type": "User",
      "created_at": "2024-08-06T08:47:37Z",
      "updated_at": "2024-12-25T21:04:47Z",
      "closed_at": null,
      "labels": [
        "documentation",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1781/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1781",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1781",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:10.724239",
      "comments": [
        {
          "author": "paul-yangmy",
          "body": "额，拼接成 这样去访问，但我的tool只是一个信息提取\r\n<img width=\"585\" alt=\"4545e7c8e019986fd4dba214dd13351\" src=\"https://github.com/user-attachments/assets/76977ffa-8fdf-4ab3-b981-d199b6a35a45\">\r\n",
          "created_at": "2024-08-06T08:49:16Z"
        },
        {
          "author": "paul-yangmy",
          "body": "hello~我现在从task memory中提取tools过程结果agent_memory.message_memory.get_by_conv_id，因为我们使用glm4时发现tool调用有时候会无法正确获得想要的结果（大模型问题），这时候如果中断了会导致整个agent都失败了:(",
          "created_at": "2024-08-26T01:27:21Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-12-24T21:04:48Z"
        },
        {
          "author": "paul-yangmy",
          "body": "anyone help ",
          "created_at": "2024-12-25T01:11:46Z"
        }
      ]
    },
    {
      "issue_number": 1893,
      "title": "无法识别doris的表注释",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [X] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nnull\n\n### Models information\n\nqianwen-max\n\n### What happened\n\n无法识别doris的表注释\n\n### What you expected to happen\n\nnull\n\n### How to reproduce\n\nnull\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "WangLL98",
      "author_type": "User",
      "created_at": "2024-08-27T01:39:41Z",
      "updated_at": "2024-12-25T21:04:46Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1893/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1893",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1893",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:10.911994",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-12-25T21:04:45Z"
        }
      ]
    },
    {
      "issue_number": 1590,
      "title": "Can you consider supporting the domestic database Dameng?",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n随着国产化要求越来越高，MySQL、Oracle、MongoDB这些都不能使用，是否计划支持国产数据库，比如达梦数据库（DMDB）\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nHigh\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "riverhell",
      "author_type": "User",
      "created_at": "2024-05-30T10:44:15Z",
      "updated_at": "2024-12-24T21:04:53Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1590/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1590",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1590",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:11.136862",
      "comments": [
        {
          "author": "Mrxiexianzhao",
          "body": "我也想问下能不能支持达梦数据库",
          "created_at": "2024-05-31T06:24:02Z"
        },
        {
          "author": "riverhell",
          "body": "@Mrxiexianzhao 自己写得了，反正有 dmPython 可以连接达梦",
          "created_at": "2024-05-31T10:00:48Z"
        },
        {
          "author": "Mrxiexianzhao",
          "body": " 您的邮件已收到，我会尽快回复的，祝你愉快！",
          "created_at": "2024-05-31T10:01:18Z"
        },
        {
          "author": "Aries-ckt",
          "body": "@Mrxiexianzhao , we provide `BaseConnect`you can implement methods with dm database.refer the `conn_clickhouse.py`",
          "created_at": "2024-06-01T15:37:43Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-07-01T21:04:46Z"
        }
      ]
    },
    {
      "issue_number": 1866,
      "title": "[Bug] [Module Name] Excellent UI transformation! However, after configuring the database, I am unable to select the corresponding database resources when constructing the application.",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n-\n\n### Models information\n\nLLM: glm-4-9b-caht\n\n### What happened\n\n配置了数据库资源但是构造应用时无法选择？同时配置mysql不同数据库时只显示一个是什么原因？\r\n![image](https://github.com/user-attachments/assets/851d4d50-1c77-4dcf-9cee-118ea49ac910)\r\n![Uploading image.png…]()\r\n\n\n### What you expected to happen\n\n-\n\n### How to reproduce\n\n-\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "yuerf",
      "author_type": "User",
      "created_at": "2024-08-22T08:17:33Z",
      "updated_at": "2024-12-24T21:04:47Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1866/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1866",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1866",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:11.390539",
      "comments": [
        {
          "author": "huicewang",
          "body": "遇到同样的问题\r\n![image](https://github.com/user-attachments/assets/d72aac5e-7359-4123-ad3a-4d249d1a64f6)\r\n![image](https://github.com/user-attachments/assets/570b0223-5e63-405a-8853-e86cbbe2c520)\r\n",
          "created_at": "2024-08-22T11:05:15Z"
        },
        {
          "author": "huangxuejie1994",
          "body": "遇到同样的问题，绑定了postgresql数据库，单独从首页进到Chat Data时，无法选择对应的数据库源。只有从数据库绑定界面，点击已绑定的数据库聊天按钮，才能跳转到有绑定数据库的聊天界面。请问这个怎么解决",
          "created_at": "2024-08-26T13:15:21Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-12-24T21:04:47Z"
        }
      ]
    },
    {
      "issue_number": 1867,
      "title": "[Bug] [API] get /knowledge/space/config HTTP/1.1 404 not Found",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [X] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU：14700\r\nRAM：64GB\r\nGPU：Nvidia 4060*4\n\n### Models information\n\nin saas api：deepseek\n\n### What happened\n\n特定情况下，知识库配置的config无法被使用，错误信息为\r\n![image](https://github.com/user-attachments/assets/334b0ad8-788a-4f65-89bc-8ebc38b1865d)\r\n其实我刚知道应该如何排错。我的debug过程并没有指向它，Jaeger中也没有看到非常明显的错误报警。无从下手\n\n### What you expected to happen\n\n![image](https://github.com/user-attachments/assets/02ebdf7f-7792-45d5-b1d3-f0db8ff9d400)\r\n![image](https://github.com/user-attachments/assets/fded6e07-e980-4a71-8a9f-f8b5dd098878)\r\n很抱歉，我没有思路。有可能是加载过程出了问题，在mlivus切换过程中。\n\n### How to reproduce\n\n我印象中，我是将 VECTOR_STORE_TYPE = Chroma 改为 milvus，之后就发生了这个报错\r\n我没有更准确的猜测和预期。当我切换为Chroma，这个问题依然存在。我的版本为最新\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "shaoqing404",
      "author_type": "User",
      "created_at": "2024-08-22T13:14:46Z",
      "updated_at": "2024-12-24T21:04:46Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1867/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1867",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1867",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:11.666495",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "what's your DB-GPT version?",
          "created_at": "2024-08-24T16:02:01Z"
        },
        {
          "author": "shaoqing404",
          "body": "> what's your DB-GPT version?\r\n\r\n0.5.1",
          "created_at": "2024-08-26T12:00:50Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-12-24T21:04:45Z"
        }
      ]
    },
    {
      "issue_number": 2246,
      "title": "[Bug] [ChatDB] too many values to unpack",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [X] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\ntongyi\n\n### What happened\n\n```\r\nmodel generate_stream params:\r\n2024-12-24 09:53:35 auto-db-gpt-pre-46975-55d97555df-cd95s dbgpt.core.awel.runner.local_runner[12] INFO Run operator <class 'dbgpt.core.interface.output_parser.SQLOutputParser'>(a18e658c-819c-4149-a338-29f308615efb) error, error message: Traceback (most recent call last):\r\n  File \"/a-one/app/dbgpt/core/awel/runner/local_runner.py\", line 192, in _execute_node\r\n    await node._run(dag_ctx, task_ctx.log_id)\r\n  File \"/a-one/app/dbgpt/core/awel/operators/base.py\", line 248, in _run\r\n    return await self._do_run(dag_ctx)\r\n  File \"/a-one/app/dbgpt/core/awel/operators/common_operator.py\", line 190, in _do_run\r\n    input_ctx: InputContext = await curr_task_ctx.task_input.map(map_function)\r\n  File \"/a-one/app/dbgpt/core/awel/task/task_impl.py\", line 538, in map\r\n    new_outputs, results = await self._apply_func(map_func)\r\n  File \"/a-one/app/dbgpt/core/awel/task/task_impl.py\", line 533, in _apply_func\r\n    results = await asyncio.gather(*map_tasks)\r\n  File \"/a-one/app/dbgpt/core/awel/task/task_impl.py\", line 126, in map\r\n    out = await self._apply_func(map_func)\r\n  File \"/a-one/app/dbgpt/core/awel/task/task_impl.py\", line 112, in _apply_func\r\n    out = await func(self._data)\r\n  File \"/a-one/app/dbgpt/core/interface/output_parser.py\", line 283, in map\r\n    return self.parse_model_nostream_resp(input_value, \"#####################\")\r\n  File \"/a-one/app/dbgpt/core/interface/output_parser.py\", line 337, in parse_model_nostream_resp\r\n    clean_str = super().parse_prompt_response(model_out_text)\r\n  File \"/a-one/app/dbgpt/core/interface/output_parser.py\", line 224, in parse_prompt_response\r\n    _, cleaned_output = cleaned_output.split(\"```json\")\r\nValueError: too many values to unpack (expected 2)\r\n```\n\n### What you expected to happen\n\nno error\n\n### How to reproduce\n\nAfter modifying the prompt, it may be reproducible.\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "dixingxing0",
      "author_type": "User",
      "created_at": "2024-12-24T03:41:38Z",
      "updated_at": "2024-12-24T03:44:09Z",
      "closed_at": "2024-12-24T03:44:08Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2246/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2246",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2246",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:11.885862",
      "comments": []
    },
    {
      "issue_number": 1718,
      "title": "Can I perform searches on multiple knowledge bases at the same time?",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n_No response_\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "kevinsummer219",
      "author_type": "User",
      "created_at": "2024-07-12T07:13:29Z",
      "updated_at": "2024-12-23T21:05:02Z",
      "closed_at": "2024-12-23T21:05:00Z",
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1718/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1718",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1718",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:11.885883",
      "comments": [
        {
          "author": "kevinsummer219",
          "body": "eg：SPACE_NAME={\"知识库一\"，\"知识库二\"}\r\n\\\"chat_mode\\\": \\\"chat_knowledge\\\", \\\"chat_param\\\": \\\"$SPACE_NAME\\\"\r\n\r\nThe request will fail, how can I search multiple knowledge bases?Thanks",
          "created_at": "2024-07-12T07:17:19Z"
        },
        {
          "author": "Aries-ckt",
          "body": "@kevinsummer219 , you mean multi knowledge spaces storage in different storage type, maybe vector or graph, or full text?",
          "created_at": "2024-07-14T12:43:18Z"
        },
        {
          "author": "xuzhuang1996",
          "body": "> @kevinsummer219 , you mean multi knowledge spaces storage in different storage type, maybe vector or graph, or full text?\r\n\r\nyes, how can I do this in AWEL,for example:\r\nI hava two index_store: graph_store and vector_store",
          "created_at": "2024-07-17T08:14:08Z"
        },
        {
          "author": "whm233",
          "body": "多创建几个知识库不就行了，在应用中添加多个知识库的资源",
          "created_at": "2024-08-14T07:45:02Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-09-23T21:04:53Z"
        }
      ]
    },
    {
      "issue_number": 1752,
      "title": "[Bug] [Chat Data] When changing the parameter \"PROMPT_NEED_STREAM_OUT\" to True，but this module can't achieve streamout",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nMacOS(M1, M2...)\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [X] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU: M1\n\n### Models information\n\nLLM:glm-4 Embedding model:text2vec-large-chinese\n\n### What happened\n\nThe prompt. py file PROMPT_NEED_STREAM_OUT in chat_db defaults to False. I hope that the chat data module will also implement streaming output like other modules. When PROMPT_NEED_STREAM_OUT = True, a bug will occur in the page output.\n\n### What you expected to happen\n\nWhen PROMPT_NEED_STREAM_OUT = True, the chat db will achieve streamout. Stream text first and then display table, or display table first and then stream text.\n\n### How to reproduce\n\nIn chat db, When PROMPT_NEED_STREAM_OUT = True, the bug occur.\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "ZZZYYYLL",
      "author_type": "User",
      "created_at": "2024-07-29T01:18:34Z",
      "updated_at": "2024-12-23T21:04:59Z",
      "closed_at": "2024-12-23T21:04:59Z",
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1752/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1752",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1752",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:12.121106",
      "comments": [
        {
          "author": "Jiweipy",
          "body": "Has the problem been solved? \r\nI set PROMPT_NEED_STREAM_OUT = True in the dbgpt/app/scene/chat_db/auto_execute/prompt.py file. The front-end page did not have the effect of streaming output.\r\n",
          "created_at": "2024-08-12T07:03:04Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-09-23T21:04:52Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue bas been closed, because it has been marked as `stale` and there has been no activity for over 7 days.",
          "created_at": "2024-12-23T21:04:59Z"
        }
      ]
    },
    {
      "issue_number": 1774,
      "title": "[Bug] [GraphRAG]  I created a knowledge graph, but am I unable to answer questions in chat?",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [X] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [X] Other\n\n### Device information\n\n本地\n\n### Models information\n\nLLM：通义千问，emding：text2vec-large-chinese\n\n### What happened\n\n我成功构建了知识图谱，但是在chat时候总是找不到\r\n![知识库](https://github.com/user-attachments/assets/3f3cf565-8598-4ab6-86b8-b934ea6955fa)\r\n![提问](https://github.com/user-attachments/assets/0f77baac-3698-40df-addc-c386fb6c776c)\r\n\n\n### What you expected to happen\n\n能够正常查询到知识图谱中的内容\n\n### How to reproduce\n\n能够正常查询到知识图谱中的内容\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "techflag",
      "author_type": "User",
      "created_at": "2024-08-03T02:34:33Z",
      "updated_at": "2024-12-23T21:04:58Z",
      "closed_at": "2024-12-23T21:04:58Z",
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1774/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1774",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1774",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:12.388131",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "Can you show some log here or debug at `knowledge_graph.py`\r\n```python\r\n    async def asimilar_search_with_scores(\r\n        self,\r\n        text,\r\n        topk,\r\n        score_threshold: float,\r\n        filters: Optional[MetadataFilters] = None,\r\n    ) -> List[Chunk]:\r\n        \"\"\"Search neighbours on",
          "created_at": "2024-08-05T15:02:26Z"
        },
        {
          "author": "Jacknolfskin",
          "body": "同样的问题",
          "created_at": "2024-08-23T09:09:48Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-09-23T21:04:50Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue bas been closed, because it has been marked as `stale` and there has been no activity for over 7 days.",
          "created_at": "2024-12-23T21:04:58Z"
        }
      ]
    },
    {
      "issue_number": 1864,
      "title": "[Bug]Baichuan api call problem",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [X] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [X] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU—1  V100-32G\n\n### Models information\n\nLLM:bc_proxyllm  Embedding model:text2vec-large-chinese\n\n### What happened\n\n2024-08-22 10:25:25 autodl-container-62da1183fa-c59ccf99 dbgpt.model.cluster.worker.default_worker[2274] ERROR Model inference error, detail: Traceback (most recent call last):\r\n  File \"/root/DB-GPT/dbgpt/model/cluster/worker/default_worker.py\", line 150, in generate_stream\r\n    ) = self._prepare_generate_stream(\r\n  File \"/root/DB-GPT/dbgpt/model/cluster/worker/default_worker.py\", line 303, in _prepare_generate_stream\r\n    generate_stream_func = self.llm_adapter.get_generate_stream_function(\r\n  File \"/root/DB-GPT/dbgpt/model/adapter/base.py\", line 150, in get_generate_stream_function\r\n    raise NotImplementedError\r\nNotImplementedError\n\n### What you expected to happen\n\n在调用百川api回答知识库内容时出现上述问题\n\n### How to reproduce\n\n1\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "DocKris",
      "author_type": "User",
      "created_at": "2024-08-22T02:43:51Z",
      "updated_at": "2024-12-23T21:04:57Z",
      "closed_at": "2024-12-23T21:04:57Z",
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1864/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1864",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1864",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:12.681994",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-09-23T21:04:47Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue bas been closed, because it has been marked as `stale` and there has been no activity for over 7 days.",
          "created_at": "2024-12-23T21:04:56Z"
        }
      ]
    },
    {
      "issue_number": 2241,
      "title": "[Bug] [Module Name] Bug title ",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nMacOS(M1, M2...)\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [X] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nmacos\n\n### Models information\n\ntext2vec\n\n### What happened\n\nThe atlas can be sliced normally but an error is reported when previewing the knowledge atlas.\r\n\r\n\r\n![1734920037990](https://github.com/user-attachments/assets/b31e1da8-39e3-4f9a-a007-2c97e98814e7)\r\n\n\n### What you expected to happen\n\nThe atlas can be sliced normally but an error is reported when previewing the knowledge atlas.\r\n  \r\n\r\n![1734920037990](https://github.com/user-attachments/assets/b31e1da8-39e3-4f9a-a007-2c97e98814e7)\r\n\n\n### How to reproduce\n\nThe atlas can be sliced normally but an error is reported when previewing the knowledge atlas.\r\n\r\n\r\n![1734920037990](https://github.com/user-attachments/assets/b31e1da8-39e3-4f9a-a007-2c97e98814e7)\r\n\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "zzll22",
      "author_type": "User",
      "created_at": "2024-12-23T02:15:56Z",
      "updated_at": "2024-12-23T02:23:37Z",
      "closed_at": "2024-12-23T02:23:37Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2241/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2241",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2241",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:12.920147",
      "comments": []
    },
    {
      "issue_number": 482,
      "title": "[BUG]使用知识库问答时，会出现文档里没有的内容，回答时常出现胡编乱造的情况: ",
      "body": "Datasource添加的都是md格式的文档。请问将文档处理成怎样的格式会有比较好的问答效果",
      "state": "open",
      "author": "E1zo",
      "author_type": "User",
      "created_at": "2023-08-24T02:25:21Z",
      "updated_at": "2024-12-22T21:04:43Z",
      "closed_at": null,
      "labels": [
        "stale"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/482/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/482",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/482",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:12.920170",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "> Datasource添加的都是md格式的文档。请问将文档处理成怎样的格式会有比较好的问答效果\r\n\r\n可以将一些特殊字符或者和答案不相干的内容都先清洗下。",
          "created_at": "2023-08-24T15:37:30Z"
        },
        {
          "author": "E1zo",
          "body": "> > Datasource添加的都是md格式的文档。请问将文档处理成怎样的格式会有比较好的问答效果\r\n> \r\n> 可以将一些特殊字符或者和答案不相干的内容都先清洗下。\r\n\r\n文档的结构怎么处理比较好呢？项目会根据标题的级别来生成答案的逻辑吗？",
          "created_at": "2023-08-25T02:17:40Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-12-22T21:04:42Z"
        }
      ]
    },
    {
      "issue_number": 491,
      "title": "Show SQL query generated along with result in ChatData",
      "body": "The query generated by model sometime may not be correct or user might want to run query in another tool. It will be good idea to show the generated query on top of the result\r\n\r\nExample\r\nShow query here\r\nselect xxx from xxx where xxx\r\n\r\n<img width=\"644\" alt=\"image\" src=\"https://github.com/eosphoros-ai/DB-GPT/assets/142115839/071dea67-af63-4b9c-8f8d-c06a0dc4e907\">\r\n",
      "state": "open",
      "author": "msangit",
      "author_type": "User",
      "created_at": "2023-08-29T01:34:50Z",
      "updated_at": "2024-12-21T21:04:41Z",
      "closed_at": null,
      "labels": [
        "stale"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/491/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/491",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/491",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:13.125330",
      "comments": [
        {
          "author": "fangyinc",
          "body": "Hi @msangit, it's coming.\r\n\r\n![chat_dashboard_2](https://github.com/eosphoros-ai/DB-GPT/assets/22972572/e0b27330-3bc8-4c8e-94ba-b966b3debfea)\r\n",
          "created_at": "2023-09-03T03:58:36Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-12-21T21:04:40Z"
        }
      ]
    },
    {
      "issue_number": 1644,
      "title": "How to load an existing knowledge base into AWEL pipe？",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n_No response_\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "kevinsummer219",
      "author_type": "User",
      "created_at": "2024-06-19T07:20:13Z",
      "updated_at": "2024-12-21T21:04:38Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 14,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1644/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1644",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1644",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:13.321370",
      "comments": [
        {
          "author": "kevinsummer219",
          "body": "In other words, I want to directly retrieve the knowledge base that I have already registered in AWEL pipe, without having to re-extract features and load the feature library in AWEL，thanks",
          "created_at": "2024-06-19T07:22:58Z"
        },
        {
          "author": "kevinsummer219",
          "body": "我想要在AWEL pipe中直接检索我已经注册的知识库，不需要我在AWEL中重新提取特征和加载特征库，我没有看到这方面的例子，我应该怎么在AWEL中加载呢？谢谢",
          "created_at": "2024-06-19T07:25:01Z"
        },
        {
          "author": "fangyinc",
          "body": "Hi @kevinsummer219, you can build a DAG like [here](https://github.com/eosphoros-ai/dbgpts/tree/main/workflow/rag-url-knowledge-example)\r\n\r\n\r\n![image](https://github.com/eosphoros-ai/DB-GPT/assets/22972572/04bb0bf0-838d-411c-aed4-a9122340bd81)\r\n",
          "created_at": "2024-06-19T12:48:15Z"
        },
        {
          "author": "fangyinc",
          "body": "Here’s a full example of how to use it:\r\nhttps://docs.dbgpt.site/docs/latest/awel/cookbook/first_rag_with_awel",
          "created_at": "2024-06-19T12:50:01Z"
        },
        {
          "author": "paul-yangmy",
          "body": "> Here’s a full example of how to use it: https://docs.dbgpt.site/docs/latest/awel/cookbook/first_rag_with_awel\r\n\r\n大佬，请教一下，我自己编写了一个awel的python文件，本地测试没问题了，我需要放在dbgpt项目的哪个路径下才能自动加载注册呀",
          "created_at": "2024-06-20T01:13:40Z"
        }
      ]
    },
    {
      "issue_number": 2224,
      "title": "[Bug]ChatData when delete database and create same database again metadata error.",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n(base) dusx@dusx:~/projects/DB-GPT/pilot/data$ lscpu\r\n架构：                    x86_64\r\n  CPU 运行模式：          32-bit, 64-bit\r\n  Address sizes:          39 bits physical, 48 bits virtual\r\n  字节序：                Little Endian\r\nCPU:                      20\r\n  在线 CPU 列表：         0-19\r\n厂商 ID：                 GenuineIntel\r\n  型号名称：              12th Gen Intel(R) Core(TM) i7-12700F\r\n    CPU 系列：            6\r\n    型号：                151\r\n    每个核的线程数：      2\r\n    每个座的核数：        12\r\n    座：                  1\r\n    步进：                2\r\n    CPU(s) scaling MHz:   18%\r\n    CPU 最大 MHz：        4900.0000\r\n    CPU 最小 MHz：        800.0000\r\n    BogoMIPS：            4224.00\r\n\n\n### Models information\n\nLLM_MODEL=tongyi_proxyllm,EMBEDDING_MODEL=text2vec\n\n### What happened\n\n删除数据库，再次创建相同的数据库，建立元数据向量库失败\n\n### What you expected to happen\n\n删除数据库后，再次创建成功\n\n### How to reproduce\n\n删除数据库，再次创建\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "dusx1981",
      "author_type": "User",
      "created_at": "2024-12-20T02:56:57Z",
      "updated_at": "2024-12-21T07:44:48Z",
      "closed_at": "2024-12-21T07:44:48Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2224/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2224",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2224",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:13.540825",
      "comments": [
        {
          "author": "dusx1981",
          "body": "VectorStoreConnector::__init__\r\n\r\n```\r\n        try:\r\n            if vector_store_type in pools and config.name in pools[vector_store_type]:\r\n                self.client = pools[vector_store_type][config.name]\r\n            else:\r\n                client = self.connector_class(config)\r\n                ",
          "created_at": "2024-12-20T02:59:22Z"
        },
        {
          "author": "dusx1981",
          "body": "建议：\r\n\r\n1. 把建立向量库的逻辑单独写成一个函数，创建数据库时单独调用\r\n2. 为什么不用 pools[vector_store_type] = client, 直接用类型对应 client\r\n3. 删除向量库时，删除 pools 里面对应的信息\r\n4. 是否可以考虑去掉 pools",
          "created_at": "2024-12-20T03:01:58Z"
        },
        {
          "author": "Aries-ckt",
          "body": "你好，是删除后创建的同名库吗？",
          "created_at": "2024-12-20T07:47:01Z"
        },
        {
          "author": "dusx1981",
          "body": "对，删除了数据库后，重新创建同名的数据库，因为 client（ChromaStore ） 已经存在，不会调用 ChromaStore 的初始化逻辑，所以没有创建存储元数据的向量库\r\n",
          "created_at": "2024-12-20T09:52:00Z"
        },
        {
          "author": "Aries-ckt",
          "body": "非常感谢，我们检查下，可能有这个问题。",
          "created_at": "2024-12-20T10:30:43Z"
        }
      ]
    },
    {
      "issue_number": 497,
      "title": "[Feature]:whatsapp plugins",
      "body": "congratulations excellent project!! It would be super cool to have a whatsapp plugins and be able to chat with the information learned in vector",
      "state": "open",
      "author": "agustin9014",
      "author_type": "User",
      "created_at": "2023-08-29T18:50:33Z",
      "updated_at": "2024-12-20T21:04:51Z",
      "closed_at": null,
      "labels": [
        "stale"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/497/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/497",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/497",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:13.760096",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-12-20T21:04:50Z"
        }
      ]
    },
    {
      "issue_number": 1762,
      "title": "[Bug] 聊天历史更新问题",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [X] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n(dbgpt_env) dusx@dusx:~/projects/DB-GPT/DB-GPT$ nvidia-smi \r\nThu Aug  1 09:42:13 2024       \r\n+---------------------------------------------------------------------------------------+\r\n| NVIDIA-SMI 535.171.04             Driver Version: 535.171.04   CUDA Version: 12.2     |\r\n|-----------------------------------------+----------------------+----------------------+\r\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n|                                         |                      |               MIG M. |\r\n|=========================================+======================+======================|\r\n|   0  NVIDIA GeForce GTX 1660 ...    Off | 00000000:01:00.0  On |                  N/A |\r\n| 28%   40C    P8               5W / 125W |    968MiB /  6144MiB |     13%      Default |\r\n|                                         |                      |                  N/A |\r\n+-----------------------------------------+----------------------+----------------------+\r\n                                                                                         \r\n+---------------------------------------------------------------------------------------+\r\n| Processes:                                                                            |\r\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n|        ID   ID                                                             Usage      |\r\n|=======================================================================================|\r\n|    0   N/A  N/A      2659      G   /usr/lib/xorg/Xorg                          461MiB |\r\n|    0   N/A  N/A      2996      G   /usr/bin/gnome-shell                         71MiB |\r\n|    0   N/A  N/A      3562      G   /usr/libexec/xdg-desktop-portal-gnome        74MiB |\r\n|    0   N/A  N/A      5244      G   /usr/bin/nautilus                            41MiB |\r\n|    0   N/A  N/A      6677      G   ...irefox/4173/usr/lib/firefox/firefox      227MiB |\r\n|    0   N/A  N/A     44749      G   /snap/snap-store/1173/bin/snap-store         23MiB |\r\n|    0   N/A  N/A    293249      G   ...seed-version=20240718-180225.788000       27MiB |\r\n|    0   N/A  N/A    293251      G   ...erProcess --variations-seed-version       36MiB |\r\n+---------------------------------------------------------------------------------------+\r\n\r\n(dbgpt_env) dusx@dusx:~/projects/DB-GPT/DB-GPT$ lscpu \r\n架构：                    x86_64\r\n  CPU 运行模式：          32-bit, 64-bit\r\n  Address sizes:          39 bits physical, 48 bits virtual\r\n  字节序：                Little Endian\r\nCPU:                      20\r\n  在线 CPU 列表：         0-19\r\n厂商 ID：                 GenuineIntel\r\n  型号名称：              12th Gen Intel(R) Core(TM) i7-12700F\r\n    CPU 系列：            6\r\n    型号：                151\r\n    每个核的线程数：      2\r\n    每个座的核数：        12\r\n    座：                  1\r\n    步进：                2\r\n    CPU(s) scaling MHz:   85%\r\n    CPU 最大 MHz：        4900.0000\r\n    CPU 最小 MHz：        800.0000\r\n    BogoMIPS：            4224.00\r\n\n\n### Models information\n\nLLM: tongyi_proxyllm EMBEDDING_MODEL=text2vec\n\n### What happened\n\nChatData 新的聊天，需要刷新才会显示在左边的聊天历史中\n\n### What you expected to happen\n\n新的聊天，自动显示在左侧的聊天历史中\n\n### How to reproduce\n\n创建新的 ChatData 场景\r\n开启新的聊天\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "dusx1981",
      "author_type": "User",
      "created_at": "2024-08-01T01:46:37Z",
      "updated_at": "2024-12-20T21:04:48Z",
      "closed_at": "2024-12-20T21:04:47Z",
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1762/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1762",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1762",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:13.935563",
      "comments": [
        {
          "author": "dusx1981",
          "body": "是否可以接受在聊天的 onDone 处理中，刷新聊天历史列表",
          "created_at": "2024-08-01T03:21:26Z"
        },
        {
          "author": "fangyinc",
          "body": "@dusx1981 Nice suggestion, we will support it in the future. If you are interested, you are also welcome to submit PR ",
          "created_at": "2024-08-05T02:45:12Z"
        },
        {
          "author": "dusx1981",
          "body": "### 前端和 python 对我来说，都是新东西，有些基本的问题：\r\n\r\n**web/components/layout/side-bar.tsx**\r\n```\r\n  const handleDelChat = useCallback(\r\n    (dialogue: IChatDialogueSchema) => {\r\n      Modal.confirm({\r\n        title: 'Delete Chat',\r\n        content: 'Are you sure delete this chat?',\r\n        width: '276px',\r\n      ",
          "created_at": "2024-08-06T09:42:16Z"
        },
        {
          "author": "dusx1981",
          "body": "@fangyinc \r\n\r\n尝试在 web/components/chat/completion.tsx 中添加：\r\n```\r\n  useAsyncEffect(async () => {\r\n    const initMessage = getInitMessage();\r\n    if (initMessage) {\r\n      refreshDialogList();\r\n      localStorage.removeItem(STORAGE_INIT_MESSAGE_KET);\r\n    }\r\n  }, [history.length]);\r\n```\r\n**可以更新，但是对话列表的",
          "created_at": "2024-08-09T05:38:07Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-09-21T21:04:37Z"
        }
      ]
    },
    {
      "issue_number": 1863,
      "title": "[Feature] ",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n我用的是tongyi代理api，没有专门起 一个服务，而是在.env上设置了PROXY_SERVER_URL=http://10.0.12.11:6005/v1/chat/completions，\r\n为什么这个不能用、访问不了？我想服务之外把它当一个正常的openai 风格的api用。难道要把输入构造成model_reqouest的格式？有没有起服务时除了正常的dbgpt服务，还有一个正常的可用api？\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "chuangzhidan",
      "author_type": "User",
      "created_at": "2024-08-22T02:40:50Z",
      "updated_at": "2024-12-20T21:04:46Z",
      "closed_at": "2024-12-20T21:04:45Z",
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1863/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1863",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1863",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:14.123651",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-09-21T21:04:33Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue bas been closed, because it has been marked as `stale` and there has been no activity for over 7 days.",
          "created_at": "2024-12-20T21:04:45Z"
        }
      ]
    },
    {
      "issue_number": 2219,
      "title": "[Bug] [Module Name] Poor context memory.",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n24G x 4\n\n### Models information\n\nglm-9b-chat\n\n### What happened\n\n单summary agent 上下文效果不理想， 第二轮回答不会根据第一轮的内容进行总结\n\n### What you expected to happen\n\n第二轮对话可以根据第一论对话的历史记忆，从引用内容中根据记忆挑选出相应的内容进行回答\n\n### How to reproduce\n\n用户提出问题1：某个指定领域问题 如：去哪里办理军队入职\r\n大模型回答：xxxx\r\n第二轮用户提出问题2：告诉我更多\r\n大模型：乱答\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "classic325",
      "author_type": "User",
      "created_at": "2024-12-19T08:34:07Z",
      "updated_at": "2024-12-20T08:50:09Z",
      "closed_at": "2024-12-20T08:50:09Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2219/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2219",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2219",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:15.962426",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "Agent history feature will add soon.",
          "created_at": "2024-12-20T07:52:08Z"
        }
      ]
    },
    {
      "issue_number": 2206,
      "title": " [Bug] [Module Name] Agent add conversation history context.",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU 24g x 4\n\n### Models information\n\nLLM :Qwen2.5-32B-Instuct\n\n### What happened\n\n![lQLPJwcDMN2i-u3NA-nNB2uwcj2mboFcTkYHRSUe4z4WAA_1899_1001(1)](https://github.com/user-attachments/assets/060edb6f-df78-4e97-af55-7299a9058de7)\r\n如何利用智能体的对话记忆，实现将引用里的内容进行回复，并且实现两轮对话之间的关联\n\n### What you expected to happen\n\n第一轮对话他识别出来是结婚领域，第二论问了个办理地点 由于只输入办理地点他无法识别是哪个领域 他就会乱答，我希望他可以通过记忆知道需要回答的地点是婚姻办理的地点\n\n### How to reproduce\n\n通过意图分类创建不同的app，首先提出一个意图分类可以识别的领域问题，再问一个和前面问题相关但是意图识别无法识别的问题\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "classic325",
      "author_type": "User",
      "created_at": "2024-12-16T07:00:04Z",
      "updated_at": "2024-12-20T08:50:09Z",
      "closed_at": "2024-12-20T08:50:09Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2206/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "Aries-ckt"
      ],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2206",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2206",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:16.198823",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "it need to add app history memory",
          "created_at": "2024-12-16T15:50:25Z"
        },
        {
          "author": "classic325",
          "body": "> it need to add app history memory\r\n\r\nhow to add app history memory， pls tell me. There are no instructions in the documentation",
          "created_at": "2024-12-17T01:08:17Z"
        }
      ]
    },
    {
      "issue_number": 2226,
      "title": "[Doc][Module Name] Documentation bug or improvement",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nWe develop out agent system based on DB-GPT.\n\n### Documentation Links\n\nhttps://arxiv.org/abs/2412.13520\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "HYSMN",
      "author_type": "User",
      "created_at": "2024-12-20T05:14:58Z",
      "updated_at": "2024-12-20T08:02:00Z",
      "closed_at": "2024-12-20T08:02:00Z",
      "labels": [
        "documentation",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2226/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2226",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2226",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:16.365005",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "Please submit a pull request, thank you.",
          "created_at": "2024-12-20T07:58:45Z"
        }
      ]
    },
    {
      "issue_number": 1828,
      "title": "[RAG] Is the RAG in the code used to match and retrieve the query and the entire schema information?",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n因为检索效果不好，如果我想改成用比如表名，列名进行检索，把每张表的列进行单独拆分（不知道哪个文件开始给它做embedding，我想只针对特定信息做embedding），然后根据检索到的信息和id去提取其余的表结构信息，\n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "chuangzhidan",
      "author_type": "User",
      "created_at": "2024-08-14T08:51:14Z",
      "updated_at": "2024-12-19T21:04:55Z",
      "closed_at": "2024-12-19T21:04:54Z",
      "labels": [
        "documentation",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 9,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1828/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1828",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1828",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:16.532613",
      "comments": [
        {
          "author": "dusx1981",
          "body": "ChromaStore 是做相关性检索的默认存储，在工程启动的时候，系统会读取目标数据库的元数据信息，主要是表的列信息，并把这些信息存入 dbname+_profile 的存储文件。如果想存储自己的信息，需要自己添加逻辑",
          "created_at": "2024-08-14T11:06:12Z"
        },
        {
          "author": "chuangzhidan",
          "body": "> 读取目标数据库的元数据信息，主要是表的列信息，并把这些信息存入\r\n\r\n谢谢，你知道是在哪个脚本中读取和存储的吗？没找到 ，谢谢",
          "created_at": "2024-08-14T12:27:54Z"
        },
        {
          "author": "Aries-ckt",
          "body": "@chuangzhidan  `DBSummary`",
          "created_at": "2024-08-15T02:39:23Z"
        },
        {
          "author": "chuangzhidan",
          "body": "> @chuangzhidan `DBSummary`\r\n\r\n仅仅只有这个而已，看不出什么\r\nclass DBSummary:\r\n    \"\"\"Database summary class.\"\"\"\r\n\r\n    def __init__(self, name: str):\r\n        \"\"\"Create a new DBSummary.\"\"\"\r\n        self.name = name\r\n        self.summary: Optional[str] = None\r\n        self.tables: Iterable[str] = []\r\n        self",
          "created_at": "2024-08-15T02:49:14Z"
        },
        {
          "author": "Aries-ckt",
          "body": "@chuangzhidan   `DBSummaryClient` and `RdbmsSummary`\r\n```python\r\ndef _parse_db_summary(\r\n    conn: BaseConnector, summary_template: str = \"{table_name}({columns})\"\r\n) -> List[str]:\r\n    \"\"\"Get db summary for database.\r\n\r\n    Args:\r\n        conn (BaseConnector): database connection\r\n        summary_t",
          "created_at": "2024-08-15T15:07:44Z"
        }
      ]
    },
    {
      "issue_number": 1844,
      "title": "[Bug] [Module Name] Knowledge error",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nproxy ollama\n\n### What happened\n\ndocument embedding failedunable to open database file\r\n![image](https://github.com/user-attachments/assets/ddc2d083-e70d-4c72-8e27-c7590ba80b0f)\r\n\n\n### What you expected to happen\n\nknowledge is ok.\r\n\n\n### How to reproduce\n\n1、create a knowledge\r\n2、select vector db\r\n3、add datasource,input text knowledge.\r\n4、save\r\n\r\n![image](https://github.com/user-attachments/assets/dea78c6d-70a0-42e2-a17d-7412e9929230)\r\n\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "neulf",
      "author_type": "User",
      "created_at": "2024-08-19T09:18:36Z",
      "updated_at": "2024-12-19T21:04:53Z",
      "closed_at": "2024-12-19T21:04:52Z",
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1844/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1844",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1844",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:16.733025",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "@neulf your vectordb is chroma?",
          "created_at": "2024-08-20T11:30:17Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-09-19T21:05:03Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue bas been closed, because it has been marked as `stale` and there has been no activity for over 7 days.",
          "created_at": "2024-12-19T21:04:52Z"
        }
      ]
    },
    {
      "issue_number": 2214,
      "title": "[Bug] [Chat Knowledge] Recreate Knowledge Graph with the same name failed.",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nMacOS(M1, M2...)\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [X] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nLLM: tongyi qwen-turbo\r\nembedding: tongyi text-embedding-v3\n\n### What happened\n\nRecreate Knowledge Graph with the same name failed:\r\n![image](https://github.com/user-attachments/assets/d8317e43-7a32-48c3-b4a0-7687d0e26aae)\r\n\n\n### What you expected to happen\n\nRecreating Knowledge Graph with the same name should be a reasonal behaviour.\n\n### How to reproduce\n\nCreate knowledge with knowledge graph.\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "GITHUBear",
      "author_type": "User",
      "created_at": "2024-12-17T11:58:52Z",
      "updated_at": "2024-12-19T11:33:14Z",
      "closed_at": "2024-12-19T11:33:14Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2214/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2214",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2214",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:16.940959",
      "comments": []
    },
    {
      "issue_number": 498,
      "title": "[Feature]:chat DATA,配置的DB-GPT本地服务器的数据库连接就能回答问题，但配置的远程数据库连接，问问题无反应，这是怎么回事？",
      "body": "**Is your feature request related to a problem? Please describe.**\r\nA clear and concise description of what the problem is. Ex. I'm always frustrated when [...]\r\n\r\n**Describe the solution you'd like**\r\nA clear and concise description of what you want to happen.\r\n\r\n**Describe alternatives you've considered**\r\nA clear and concise description of any alternative solutions or features you've considered.\r\n\r\n**Additional context**\r\nAdd any other context or screenshots about the feature request here.\r\n",
      "state": "open",
      "author": "dencentding",
      "author_type": "User",
      "created_at": "2023-08-30T01:56:10Z",
      "updated_at": "2024-12-18T21:05:00Z",
      "closed_at": null,
      "labels": [
        "stale"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/498/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/498",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/498",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:16.940977",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "> **Is your feature request related to a problem? Please describe.** A clear and concise description of what the problem is. Ex. I'm always frustrated when [...]\r\n> \r\n> **Describe the solution you'd like** A clear and concise description of what you want to happen.\r\n> \r\n> **Describe alternatives you",
          "created_at": "2023-08-30T02:18:51Z"
        },
        {
          "author": "dencentding",
          "body": "> \r\n\r\n\r\n\r\n> > **Is your feature request related to a problem? Please describe.** A clear and concise description of what the problem is. Ex. I'm always frustrated when [...]\r\n> > **Describe the solution you'd like** A clear and concise description of what you want to happen.\r\n> > **Describe alternat",
          "created_at": "2023-08-30T02:36:42Z"
        },
        {
          "author": "paul-yangmy",
          "body": "+1，我也是这个错",
          "created_at": "2023-09-25T06:12:59Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-12-18T21:04:58Z"
        }
      ]
    },
    {
      "issue_number": 1454,
      "title": "[Bug] [Module Name] zhipu——",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nMacOS(x86)\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [X] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nMAc M2 Pro\n\n### Models information\n\n.env:\r\nLLM_MODEL=zhipu_proxyllm\r\nMODEL_SERVER=http://127.0.0.1:8000\r\nLIMIT_MODEL_CONCURRENCY=5\r\nMAX_POSITION_EMBEDDINGS=4096\r\nQUANTIZE_QLORA=True\r\nQUANTIZE_8bit=True\r\nEMBEDDING_MODEL=text2vec\r\nKNOWLEDGE_CHUNK_SIZE=500\r\nKNOWLEDGE_SEARCH_TOP_SIZE=5\r\nKNOWLEDGE_CHAT_SHOW_RELATIONS=False\r\nKNOWLEDGE_SEARCH_REWRITE=False\r\nLOCAL_DB_TYPE=mysql\r\nLOCAL_DB_USER=root\r\nLOCAL_DB_PASSWORD=****\r\nLOCAL_DB_HOST=127.0.0.1\r\nLOCAL_DB_PORT=3306\r\nLOCAL_DB_NAME=dbgpt\r\nEXECUTE_LOCAL_COMMANDS=False\r\nPROXY_SERVER_URL=https://open.bigmodel.cn/api/paas/v4/chat/completions\r\nBARD_PROXY_API_KEY={your-bard-token}\r\nTONGYI_PROXY_API_KEY={your-tongyi-sk}\r\nZHIPU_MODEL_VERSION=glm-3-turbo\r\nZHIPU_PROXY_API_KEY=4af5a6b9011852bc3f38ae193d65b5bf.X6aPkEBJq94yOgds\r\nSUMMARY_CONFIG=FAST\r\nDBGPT_LOG_LEVEL=INFO\r\n\n\n### What happened\n\nfull stream output:\r\n\r\n\r\nmodel generate_stream params:\r\n{'model': 'zhipu_proxyllm', 'messages': [ModelMessage(role='human', content='q', round_index=1), ModelMessage(role='human', content='You are a helpful AI assistant.\\n1', round_index=0)], 'temperature': 0.6, 'max_new_tokens': 1024, 'echo': False, 'span_id': 'f33a549c-553d-4010-874b-6e4e03bd5318:0ffd8a45-ddb4-4d3b-820d-53cde063a7cb', 'context': {'stream': True, 'cache_enable': False, 'user_name': None, 'sys_code': None, 'conv_uid': None, 'span_id': 'f33a549c-553d-4010-874b-6e4e03bd5318:93084696-026a-451e-978e-0925e5e56ad0', 'chat_mode': 'chat_normal', 'chat_param': None, 'extra': {}, 'request_id': None}, 'convert_to_compatible_format': False, 'string_prompt': 'human: q\\nhuman: You are a helpful AI assistant.\\n1'}\r\nTraceback (most recent call last):\r\n  File \"/Library/Studying/privateLLM/DB-GPT/dbgpt/app/scene/base_chat.py\", line 294, in stream_call\r\n    self.current_message.add_ai_message(msg)\r\nUnboundLocalError: local variable 'msg' referenced before assignment\r\n\r\n2024-04-23 17:08:26 MacBook-Pro dbgpt.app.scene.base_chat[77234] ERROR model response parse failed！local variable 'msg' referenced before assignment\r\n\n\n### What you expected to happen\n\n没有连接到zhipu\n\n### How to reproduce\n\n1:直接对话\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "zhangkuo-zk",
      "author_type": "User",
      "created_at": "2024-04-23T09:14:30Z",
      "updated_at": "2024-12-18T21:04:57Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 15,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1454/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1454",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1454",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:17.122380",
      "comments": [
        {
          "author": "zhangkuo-zk",
          "body": "已解决 ，url问题",
          "created_at": "2024-04-24T01:26:59Z"
        },
        {
          "author": "Jimmy1456",
          "body": "> 已解决 ，url问题\r\n\r\n老哥，能详细说下吗，url应该怎么设置",
          "created_at": "2024-04-24T02:20:52Z"
        },
        {
          "author": "Jimmy1456",
          "body": "> > 已解决 ，url问题\r\n> \r\n> 老哥，能详细说下吗，url应该怎么设置\r\n\r\nfix，just pip install zhipuai==1.0.7\r\n#1037 ",
          "created_at": "2024-04-26T02:17:00Z"
        },
        {
          "author": "wangcaizi",
          "body": "> 已解决 ，url问题\r\n\r\nurl哪错了？\r\n",
          "created_at": "2024-05-19T05:28:07Z"
        },
        {
          "author": "zhangkuo-zk",
          "body": "使用1.0.7版本 pip install zhipuai==1.0.7",
          "created_at": "2024-05-21T02:49:00Z"
        }
      ]
    },
    {
      "issue_number": 603,
      "title": "[Bug] [db-gpt] dbgpt_server.py 无法启动",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice : CPU and GPU\r\nGPU : 1\r\nGPU Memory: 12G\r\nGPU type: RTX 3060\n\n### Models information\n\nLLM: vicuna-7b-v1.5\r\nEMBinding: text2vec-large-chinese\n\n### What happened\n\nkas@DESKTOP-M7N9V23:~/app/DB-GPT$ python pilot/server/dbgpt_server.py \r\n\r\n\r\n=========================== WebWerverParameters ===========================\r\n\r\nhost: 0.0.0.0\r\nport: 5000\r\ndaemon: False\r\nshare: False\r\nremote_embedding: False\r\nlog_level: INFO\r\nlight: False\r\n\r\n======================================================================\r\n\r\n\r\n/home/kas/app/DB-GPT/pilot\r\n2023-09-19 17:07:47 | INFO | pilot.component | Register component with name dbgpt_model_controller and instance: <pilot.model.cluster.controller.controller.ModelControllerAdapter object at 0x7f208bf6ea70>\r\n2023-09-19 17:07:47 | INFO | pilot.server.component_configs | Register local LocalEmbeddingFactory\r\n2023-09-19 17:07:47 | INFO | pilot.model.cluster.worker.embedding_worker | [EmbeddingsModelWorker] Parameters of device is None, use cuda\r\n2023-09-19 17:07:47 | INFO | pilot.server.component_configs | \r\n\r\n=========================== EmbeddingModelParameters ===========================\r\n\r\nmodel_name: text2vec\r\nmodel_path: /home/kas/app/DB-GPT/models/text2vec-large-chinese\r\ndevice: cuda\r\nnormalize_embeddings: None\r\n\r\n======================================================================\r\n\r\n\r\n2023-09-19 17:07:48 | INFO | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: /home/kas/app/DB-GPT/models/text2vec-large-chinese\r\n2023-09-19 17:07:48 | WARNING | sentence_transformers.SentenceTransformer | No sentence-transformers model found with name /home/kas/app/DB-GPT/models/text2vec-large-chinese. Creating a new one with MEAN pooling.\r\n2023-09-19 17:07:48 | INFO | torch.distributed.nn.jit.instantiator | Created a temporary directory at /tmp/tmpq32b_nlf\r\n2023-09-19 17:07:48 | INFO | torch.distributed.nn.jit.instantiator | Writing /tmp/tmpq32b_nlf/_remote_module_non_scriptable.py\r\n2023-09-19 17:07:49 | INFO | pilot.component | Register component with name embedding_factory and instance: <pilot.server.component_configs.LocalEmbeddingFactory object at 0x7f205f324730>\r\nModel Unified Deployment Mode!\r\n2023-09-19 17:07:49 | INFO | model_worker | Worker params: \r\n\r\n=========================== ModelWorkerParameters ===========================\r\n\r\nmodel_name: vicuna-7b-v1.5\r\nmodel_path: /home/kas/app/DB-GPT/models/vicuna-7b-v1.5\r\nworker_type: None\r\nworker_class: None\r\nhost: 0.0.0.0\r\nport: 5000\r\ndaemon: False\r\nlimit_model_concurrency: 5\r\nstandalone: True\r\nregister: True\r\nworker_register_host: None\r\ncontroller_addr: None\r\nsend_heartbeat: True\r\nheartbeat_interval: 20\r\n\r\n======================================================================\r\n\r\n\r\n2023-09-19 17:07:49 | INFO | model_worker | Run WorkerManager with standalone mode, controller_addr: http://127.0.0.1:5000\r\n  Found llm model adapter with model name: vicuna-7b-v1.5, <pilot.model.adapter.VicunaLLMAdapater object at 0x7f2125995db0>\r\n2023-09-19 17:07:49 | INFO | LOGGER | Found llm model adapter with model name: vicuna-7b-v1.5, <pilot.model.adapter.VicunaLLMAdapater object at 0x7f2125995db0>\r\n2023-09-19 17:07:49 | INFO | model_worker | model_name: vicuna-7b-v1.5, model_path: /home/kas/app/DB-GPT/models/vicuna-7b-v1.5, model_param_class: <class 'pilot.model.parameter.ModelParameters'>\r\nGet model chat adapter with model name vicuna-7b-v1.5, <pilot.server.chat_adapter.VicunaChatAdapter object at 0x7f21259188b0>\r\n2023-09-19 17:07:49 | INFO | model_worker | [DefaultModelWorker] Parameters of device is None, use cuda\r\n2023-09-19 17:07:49 | INFO | model_worker | Init empty instances list for vicuna-7b-v1.5@llm\r\n2023-09-19 17:07:49 | INFO | pilot.component | Register component with name dbgpt_worker_manager_factory and instance: <pilot.model.cluster.worker.manager._DefaultWorkerManagerFactory object at 0x7f2053a9e5f0>\r\nINFO:     Started server process [2463]\r\nINFO:     Waiting for application startup.\r\n2023-09-19 17:07:49 | INFO | model_worker | Begin start all worker, apply_req: None\r\n2023-09-19 17:07:49 | INFO | model_worker | Apply req: None, apply_func: <function LocalWorkerManager._start_all_worker.<locals>._start_worker at 0x7f205389b520>\r\n2023-09-19 17:07:49 | INFO | model_worker | Apply to all workers\r\nINFO:     Application startup complete.\r\n2023-09-19 17:07:49 | INFO | model_worker | Begin load model, model params: \r\n\r\n=========================== ModelParameters ===========================\r\n\r\nmodel_name: vicuna-7b-v1.5\r\nmodel_path: /home/kas/app/DB-GPT/models/vicuna-7b-v1.5\r\ndevice: cuda\r\nmodel_type: huggingface\r\nprompt_template: None\r\nmax_context_size: 4096\r\nnum_gpus: None\r\nmax_gpu_memory: None\r\ncpu_offloading: False\r\nload_8bit: True\r\nload_4bit: False\r\nquant_type: nf4\r\nuse_double_quant: True\r\ncompute_dtype: None\r\ntrust_remote_code: True\r\nverbose: False\r\n\r\n======================================================================\r\n\r\n\r\n  max_memory: {0: '10GiB'}\r\nINFO:     Uvicorn running on http://0.0.0.0:5000 (Press CTRL+C to quit)\r\n2023-09-19 17:07:49 | DEBUG | LOGGER | max_memory: {0: '10GiB'}\r\nLoading checkpoint shards:   0%|                                                                                                                                        | 0/2 [00:00<?, ?it/s]INFO:     127.0.0.1:54396 - \"GET / HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:54396 - \"GET /css/319e16dd59ffd1d7.css HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:54408 - \"GET /chunks/webpack-e39fb0ddb24a46cf.js HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:54396 - \"GET /chunks/main-106e14a4d176f289.js HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:54408 - \"GET /chunks/framework-0274f228b2a17278.js HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:54396 - \"GET /chunks/pages/_app-edeed3caf45d578a.js HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:54408 - \"GET /chunks/913-b5bc9815149e2ad5.js HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:54408 - \"GET /chunks/66-791bb03098dc9265.js HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:54396 - \"GET /chunks/707-109d4fec9e26030d.js HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:54396 - \"GET /_BY-cQzLf2lL8o4uTsVNy/_buildManifest.js HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:54408 - \"GET /chunks/pages/index-d5aba6bbbc1d8aaa.js HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:54396 - \"GET /_BY-cQzLf2lL8o4uTsVNy/_ssgManifest.js HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:54396 - \"GET /LOGO_1.png HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:54408 - \"GET /LOGO.png HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:54408 - \"GET /api/v1/chat/dialogue/list HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:54396 - \"POST /api/v1/chat/dialogue/scenes HTTP/1.1\" 200 OK\r\n2023-09-19 17:07:55 | INFO | pilot.openapi.api_v1.api_v1 | /controller/model/types\r\n2023-09-19 17:07:55 | INFO | root | Get all instances with None, healthy_only: True\r\ndefaultdict(<class 'list'>, {})\r\nINFO:     127.0.0.1:54408 - \"GET /api/v1/model/types HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:54408 - \"GET /chunks/566-31b5bf29f3e84615.js HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:54396 - \"GET /chunks/902-c56acea399c45e57.js HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:54408 - \"GET /chunks/625-63aa85328eed0b3e.js HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:54396 - \"GET /chunks/455-5c8f2c8bda9b4b83.js HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:54408 - \"GET /chunks/46-2a716444a56f6f08.js HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:54396 - \"GET /chunks/847-4335b5938375e331.js HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:54408 - \"GET /chunks/pages/database-ddf0a72485646c52.js HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:54396 - \"GET /chunks/29107295-90b90cb30c825230.js HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:54396 - \"GET /chunks/939-126a01b0d827f3b4.js HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:54408 - \"GET /chunks/556-26ffce13383f774a.js HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:54396 - \"GET /chunks/589-8dfb35868cafc00b.js HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:54408 - \"GET /chunks/241-4117dd68a591b7fa.js HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:54396 - \"GET /chunks/pages/datastores-4fb48131988df037.js HTTP/1.1\" 200 OK\r\nKilled\r\n(env) kas@DESKTOP-M7N9V23:~/app/DB-GPT$ \n\n### What you expected to happen\n\n![image](https://github.com/eosphoros-ai/DB-GPT/assets/103126/9ab90973-9918-4dad-9987-0bc7fdd840f2)\n\n### How to reproduce\n\n python3 pilot/server/dbgpt_server.py\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "duhaly",
      "author_type": "User",
      "created_at": "2023-09-19T09:21:30Z",
      "updated_at": "2024-12-18T14:33:17Z",
      "closed_at": "2023-12-06T06:21:05Z",
      "labels": [
        "FAQ:Install"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 10,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/603/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/603",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/603",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:17.363242",
      "comments": [
        {
          "author": "fangyinc",
          "body": "你好，根据你的配置和日志信息来看，可能是显存不够了。 \r\n\r\n根据我们之前的一些[简单测试](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html#hardware-requirements)，`vicuna-7b-v1.5` 开启 8bit 量化大概需要  12G 显存，除了 LLM 之外，embedding 模型也会使用 GPU，也需要占用一定的显存。\r\n\r\n推荐以下两种解决方法，你可以使用尝试一下：\r\n\r\n1.  开启 4bit 量化，修改 `.env` 文件：\r\n```\r\nQ",
          "created_at": "2023-09-19T15:40:47Z"
        },
        {
          "author": "duhaly",
          "body": "按照您说的方法，问题依旧，还有什么设置，我可以继续尝试",
          "created_at": "2023-09-20T10:39:55Z"
        },
        {
          "author": "duhaly",
          "body": "(env) kas@DESKTOP-M7N9V23:~/app/DB-GPT$ python pilot/server/dbgpt_server.py\r\n\r\n\r\n=========================== WebWerverParameters ===========================\r\n\r\nhost: 0.0.0.0\r\nport: 5000\r\ndaemon: False\r\nshare: False\r\nremote_embedding: False\r\nlog_level: INFO\r\nlight: False\r\n\r\n==========================",
          "created_at": "2023-09-20T10:41:31Z"
        },
        {
          "author": "fangyinc",
          "body": "我看你的环境写的是 Linux，我看截图是 Windows 任务管理器，你是在虚拟机跑的么还是其它虚拟环境，你可以看看虚拟环境是否已经分配和足够的内存和显存。",
          "created_at": "2023-09-20T11:03:32Z"
        },
        {
          "author": "duhaly",
          "body": "我用的是 wsl2",
          "created_at": "2023-09-20T11:31:43Z"
        }
      ]
    },
    {
      "issue_number": 2192,
      "title": "[Feature][RAG] Hybrid Knowledge Process Workflow with AWEL",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nHybrid Knowledge Process Workflow with AWEL\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "Aries-ckt",
      "author_type": "User",
      "created_at": "2024-12-11T16:01:21Z",
      "updated_at": "2024-12-18T03:16:31Z",
      "closed_at": "2024-12-18T03:16:31Z",
      "labels": [
        "enhancement",
        "Waiting for reply",
        "ChatKnowledge"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2192/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "Aries-ckt"
      ],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2192",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2192",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:17.560413",
      "comments": []
    },
    {
      "issue_number": 1838,
      "title": "[Bug] [ChatExcel] NotImplementedError: The operator 'aten::isin.Tensor_Tensor_out' is not currently implemented for the MPS device. ",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nMacOS(M1, M2...)\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [X] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nmacbookpro m1  RAM 64G\n\n### Models information\n\nLLM: glm-4-9b-chat  embeddingmodel: text2vec-large-chinese\n\n### What happened\n\n2024-08-17 21:08:57 guojie dbgpt.model.llm_out.hf_chat_llm[4218] INFO Predict with parameters: {'max_length': 128000, 'temperature': 0.8, 'streamer': <transformers.generation.streamers.TextIteratorStreamer object at 0x17642d540>, 'top_p': 1.0, 'do_sample': True}\r\ncustom_stop_words: []\r\nException in thread Thread-7 (generate):\r\nTraceback (most recent call last):\r\n  File \"/Users/guojie/miniconda3/envs/dbgpt0510/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\r\n    self.run()\r\n  File \"/Users/guojie/miniconda3/envs/dbgpt0510/lib/python3.10/threading.py\", line 953, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/Users/guojie/miniconda3/envs/dbgpt0510/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File \"/Users/guojie/miniconda3/envs/dbgpt0510/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1713, in generate\r\n    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)\r\n  File \"/Users/guojie/miniconda3/envs/dbgpt0510/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1562, in _prepare_special_tokens\r\n    and torch.isin(elements=eos_token_tensor, test_elements=pad_token_tensor).any()\r\nNotImplementedError: The operator 'aten::isin.Tensor_Tensor_out' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.\n\n### What you expected to happen\n\nwhat should I do to fix this problem , if I want to chat with excel?   Thanks very much \n\n### How to reproduce\n\njust install  DB-GPT on macbookpro  m1, and then use  chat excel \n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "guojie0701",
      "author_type": "User",
      "created_at": "2024-08-17T13:18:56Z",
      "updated_at": "2024-12-17T21:05:00Z",
      "closed_at": "2024-12-17T21:04:59Z",
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1838/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1838",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1838",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:17.560444",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-09-18T21:04:53Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue bas been closed, because it has been marked as `stale` and there has been no activity for over 7 days.",
          "created_at": "2024-12-17T21:04:59Z"
        }
      ]
    },
    {
      "issue_number": 1842,
      "title": "Qianwen needs to change the default value of the new version's key",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [X] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nnull\n\n### Models information\n\nqainwe\n\n### What happened\n\nQianwen needs to change the default value of the new version's key\r\n![1724056590710](https://github.com/user-attachments/assets/f73dc862-b436-47c8-a8c0-6d9cd73dceaf)\r\n\n\n### What you expected to happen\n\nnull\n\n### How to reproduce\n\nnull\n\n### Additional context\n\nnull\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "WangLL98",
      "author_type": "User",
      "created_at": "2024-08-19T08:37:28Z",
      "updated_at": "2024-12-17T21:04:58Z",
      "closed_at": "2024-12-17T21:04:58Z",
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1842/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1842",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1842",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:17.779756",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-09-18T21:04:52Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue bas been closed, because it has been marked as `stale` and there has been no activity for over 7 days.",
          "created_at": "2024-12-17T21:04:57Z"
        }
      ]
    },
    {
      "issue_number": 2204,
      "title": "[Bug] [Module Name] Bug title  Error while deserializing header: HeaderTooLarge",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n<3.9\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [X] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [X] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n2C4G\n\n### Models information\n\n/text2vec-large-chinese\n\n### What happened\n\nwebserver_1  | Traceback (most recent call last):\r\nwebserver_1  |   File \"/app/dbgpt/app/dbgpt_server.py\", line 291, in <module>\r\nwebserver_1  |     run_webserver()\r\nwebserver_1  |   File \"/app/dbgpt/app/dbgpt_server.py\", line 277, in run_webserver\r\nwebserver_1  |     param = initialize_app(param)\r\nwebserver_1  |   File \"/app/dbgpt/app/dbgpt_server.py\", line 173, in initialize_app\r\nwebserver_1  |     initialize_components(\r\nwebserver_1  |   File \"/app/dbgpt/app/component_configs.py\", line 51, in initialize_components\r\nwebserver_1  |     _initialize_embedding_model(\r\nwebserver_1  |   File \"/app/dbgpt/app/initialization/embedding_component.py\", line 32, in _initialize_embedding_model\r\nwebserver_1  |     system_app.register(\r\nwebserver_1  |   File \"/app/dbgpt/component.py\", line 195, in register\r\nwebserver_1  |     instance = component(self, *args, **kwargs)\r\nwebserver_1  |   File \"/app/dbgpt/app/initialization/embedding_component.py\", line 96, in __init__\r\nwebserver_1  |     self._model = self._load_model()\r\nwebserver_1  |   File \"/app/dbgpt/app/initialization/embedding_component.py\", line 131, in _load_model\r\nwebserver_1  |     return loader.load(self._default_model_name, model_params)\r\nwebserver_1  |   File \"/app/dbgpt/model/adapter/embeddings_loader.py\", line 84, in load\r\nwebserver_1  |     return HuggingFaceEmbeddings(**kwargs)\r\nwebserver_1  |   File \"/app/dbgpt/rag/embedding/embeddings.py\", line 93, in __init__\r\nwebserver_1  |     kwargs[\"client\"] = sentence_transformers.SentenceTransformer(\r\nwebserver_1  |   File \"/usr/local/lib/python3.10/dist-packages/sentence_transformers/SentenceTransformer.py\", line 299, in __init__\r\nwebserver_1  |     modules = self._load_auto_model(\r\nwebserver_1  |   File \"/usr/local/lib/python3.10/dist-packages/sentence_transformers/SentenceTransformer.py\", line 1324, in _load_auto_model\r\nwebserver_1  |     transformer_model = Transformer(\r\nwebserver_1  |   File \"/usr/local/lib/python3.10/dist-packages/sentence_transformers/models/Transformer.py\", line 54, in __init__\r\nwebserver_1  |     self._load_model(model_name_or_path, config, cache_dir, **model_args)\r\nwebserver_1  |   File \"/usr/local/lib/python3.10/dist-packages/sentence_transformers/models/Transformer.py\", line 85, in _load_model\r\nwebserver_1  |     self.auto_model = AutoModel.from_pretrained(\r\nwebserver_1  |   File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\", line 564, in from_pretrained\r\nwebserver_1  |     return model_class.from_pretrained(\r\nwebserver_1  |   File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\", line 3701, in from_pretrained\r\nwebserver_1  |     with safe_open(resolved_archive_file, framework=\"pt\") as f:\r\nwebserver_1  | safetensors_rust.SafetensorError: Error while deserializing header: HeaderTooLarge\r\ndb-gpt_webserver_1 exited with code 1\r\n\n\n### What you expected to happen\n\nResolve this issue\n\n### How to reproduce\n\nIt may be that there is a problem with the way I download the model, I can't download the model through the official git clone https://huggingface.co/GanymedeNil/text2vec-large-chinese, I am through git clone Models that https://hf-mirror.com/GanymedeNil/text2vec-large-chinese downloaded are currently not available for download from the official website\n\n### Additional context\n\nI removed nvidia from the docker-compose up file，My profile reads as follows\r\nversion: '3.3'\r\n\r\nservices:\r\n  #db:\r\n    #image: mysql/mysql-server\r\n    #environment:\r\n     # MYSQL_USER: 'user'\r\n     # MYSQL_PASSWORD: 'password'\r\n     # MYSQL_ROOT_PASSWORD: 'aa123456'\r\n    #ports:\r\n      #- 3306:3306\r\n    #volumes:\r\n      #- dbgpt-myql-db:/var/lib/mysql\r\n      #- ./docker/examples/my.cnf:/etc/my.cnf\r\n      #- ./docker/examples/sqls:/docker-entrypoint-initdb.d\r\n      #- ./assets/schema/dbgpt.sql:/docker-entrypoint-initdb.d/dbgpt.sql\r\n    #restart: unless-stopped\r\n    #networks:\r\n      #- dbgptnet\r\n  webserver:\r\n    image: eosphorosai/dbgpt:latest\r\n    command: python3 dbgpt/app/dbgpt_server.py\r\n    environment:\r\n      - LOCAL_DB_HOST=xxxxxxx\r\n      - LOCAL_DB_PORT=3306\r\n      - LOCAL_DB_USER=xxxxxx\r\n      - LOCAL_DB_PASSWORD=xxxxxx\r\n      - ALLOWLISTED_PLUGINS=db_dashboard\r\n      - LLM_MODEL=glm-4-9b-chat\r\n    #depends_on:\r\n     # - db\r\n    volumes:\r\n      - /data:/data\r\n      # Please modify it to your own model directory\r\n      - /data/models:/app/models\r\n      - dbgpt-data:/app/pilot/data\r\n      - dbgpt-message:/app/pilot/message\r\n      #- /opt/db-gpt/DB-GPT/docker/examples/my.cnf:/etc/my.cnf  # 确保宿主机上此文件路径正确且可读，可根据实际情况调整\r\n      #- /opt/db-gpt/DB-GPT/docker/examples/sqls:/docker-entrypoint-initdb.d  # 确保宿主机上此目录及文件可读，可根据实际情况调整\r\n      #- /opt/db-gpt/DB-GPT/assets/schema/dbgpt.sql:/docker-entrypoint-initdb.d/dbgpt.sql  # 确保宿主机上此文件路径及权限正确，可根据实际情况调整\r\n\r\n    env_file:\r\n      - .env.template\r\n    ports:\r\n      - 5670:5670/tcp\r\n    # webserver may be failed, it must wait all sqls in /docker-entrypoint-initdb.d execute finish.\r\n    restart: unless-stopped\r\n    networks:\r\n      - dbgptnet\r\n    ipc: host\r\n    #deploy:\r\n      #resources:\r\n        #reservations:\r\n          #devices:\r\n            #- driver: nvidia\r\n              #capabilities: [gpu]\r\nvolumes:\r\n  dbgpt-myql-db:\r\n  dbgpt-data:\r\n  dbgpt-message:\r\nnetworks:\r\n  dbgptnet:\r\n    driver: bridge\r\n    #name: dbgptnet\r\n\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "cai417",
      "author_type": "User",
      "created_at": "2024-12-16T02:27:14Z",
      "updated_at": "2024-12-17T08:32:16Z",
      "closed_at": "2024-12-17T08:32:16Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2204/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2204",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2204",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:17.990484",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "it looks like you've used a wrong model file. Download again and check you model file.\r\n\r\n",
          "created_at": "2024-12-16T15:52:01Z"
        }
      ]
    },
    {
      "issue_number": 2013,
      "title": "[Bug] [Module Name] Bug title can not save the AWEL workflow",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\ncpu\n\n### Models information\n\nLLM: ERNIE-4.0-Turbo-8K\n\n### What happened\n\n我跟着操作手册创建awel工作流，按照图示创建，然后点保存出现了以下错误：\r\n![1726117497804](https://github.com/user-attachments/assets/428fc9cd-a9d5-4f5b-83d6-fe675753e6bb)\r\nload系统内置工作流保存，同样报错。\r\n根据报错信息确定arbitrary_types_allowed=True 设置没错。\n\n### What you expected to happen\n\n工作流能够顺利保存\n\n### How to reproduce\n\n1. 来到应用管理，工作流\r\n2. 点击创建\r\n3. 创建工作流后点击右上角保存\r\n4. 输入工作流名称和title点击确定\r\n5. 报错。\r\n6. 点击加载默认工作流\r\n7. 点击保存\r\n8. 报错\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "fluentlymos",
      "author_type": "User",
      "created_at": "2024-09-12T05:08:44Z",
      "updated_at": "2024-12-17T08:19:54Z",
      "closed_at": "2024-12-17T08:19:54Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2013/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2013",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2013",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:18.226757",
      "comments": [
        {
          "author": "fangyinc",
          "body": "@fluentlymos  Please provide a screenshot of the AWEL flow and error logs in python server.",
          "created_at": "2024-09-12T11:04:26Z"
        },
        {
          "author": "fluentlymos",
          "body": "sure, @fangyinc please see blow snapshot for the AWEL flow:\r\n![1726143528109](https://github.com/user-attachments/assets/796fd55a-3cd8-4a5d-bc34-64cb53c19408)\r\nand below is the error messge in webpage:\r\n![1726143549104](https://github.com/user-attachments/assets/05032fed-af37-4d97-9712-d97af62c3672)",
          "created_at": "2024-09-12T12:25:54Z"
        },
        {
          "author": "ygbingo",
          "body": "我是用v0.6.0版本也遇到了这个问题，不过源码就没问题，可能是官方提供的镜像有问题，可以试试用 /docker/base/Dockerfile 自己build一下",
          "created_at": "2024-09-18T06:14:07Z"
        },
        {
          "author": "ygbingo",
          "body": "尝试了下，直接build也不行，这个问题应该是pydantic版本不一致导入的，在build镜像时，需要手动把pydantic版本调整下\r\n```Dockerfile\r\n...\r\nRUN pip3 install -i $PIP_INDEX_URL fastapi==0.111.0 pydantic==2.7.4 pydantic_core==2.18.410\r\n...\r\n```",
          "created_at": "2024-09-18T08:45:30Z"
        },
        {
          "author": "leichangqing",
          "body": "I had occur the same issue, but fixed it with  pip install fastapi==0.111.0 -i https://pypi.tuna.tsinghua.edu.cn/simple",
          "created_at": "2024-10-14T12:20:39Z"
        }
      ]
    },
    {
      "issue_number": 2191,
      "title": "[Bug] [Module Name] Bug title document edit error Class 'dbgpt.serve.rag.api.schemas.ChunkServeResponse' is not mapped",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [X] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [X] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nllm:tongyi_proxyllm，EMBEDDING_MODEL:m3e-base\n\n### What happened\n\n![image](https://github.com/user-attachments/assets/acb168ca-ffa8-41b4-9289-b84711833ba3)\r\n知识库添加关联问题，报错document edit error Class 'dbgpt.serve.rag.api.schemas.ChunkServeResponse' is not mapped，版本是0.6.0，表document_chunk是存在的\n\n### What you expected to happen\n\n猜测代码有bug\n\n### How to reproduce\n\n在知识库中添加关联问题，点击“确认”，前端页面即可看到错误信息\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "xuxl2024",
      "author_type": "User",
      "created_at": "2024-12-11T10:14:20Z",
      "updated_at": "2024-12-17T01:39:04Z",
      "closed_at": "2024-12-17T01:39:04Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2191/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2191",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2191",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:18.539181",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "what's your LOCAL_DB_TYPE in `.env`?",
          "created_at": "2024-12-11T11:03:05Z"
        },
        {
          "author": "xuxl2024",
          "body": "> what's your LOCAL_DB_TYPE in `.env`?\r\n\r\nLOCAL_DB_TYPE is mysql",
          "created_at": "2024-12-12T01:13:01Z"
        },
        {
          "author": "Aries-ckt",
          "body": "mysql should not have that problem, but `LOCAL_DB_TYPE =sqlite` has that problem. can you show the error log and your .env setting?",
          "created_at": "2024-12-12T02:47:46Z"
        },
        {
          "author": "xuxl2024",
          "body": ".env setting:\r\n\r\n```\r\n#*******************************************************************#\r\n#**                  DB-GPT METADATA DATABASE SETTINGS            **#\r\n#*******************************************************************#\r\n### SQLite database (Current default database)\r\n# LOCAL_DB_TYPE=s",
          "created_at": "2024-12-12T02:56:15Z"
        },
        {
          "author": "xuxl2024",
          "body": "The version of MySQL is 8.0.32.",
          "created_at": "2024-12-12T03:09:20Z"
        }
      ]
    },
    {
      "issue_number": 1780,
      "title": "[Doc]Don't understand prompt code",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\ndef _register_scene_prompt_template(\r\n    scene_registry: Dict[str, Dict],\r\n    prompt_template,\r\n    language: str,\r\n    model_names: List[str],\r\n):\r\n    for model_name in model_names:\r\n        if model_name not in scene_registry:\r\n            scene_registry[model_name] = dict()\r\n        registry = scene_registry[model_name]\r\n        registry[language] = prompt_template\r\n\r\n不太理解dbgpt/core/_private/prompt_registry.py中为什么language]等于提示词模板 prompt_template\r\n想知道是哪个文件中的函数或变量给提示词模板的{}变量}赋值？\n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "chuangzhidan",
      "author_type": "User",
      "created_at": "2024-08-06T07:53:28Z",
      "updated_at": "2024-12-16T21:05:22Z",
      "closed_at": "2024-12-16T21:05:21Z",
      "labels": [
        "documentation",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1780/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1780",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1780",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:18.753721",
      "comments": [
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-09-17T21:04:52Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue bas been closed, because it has been marked as `stale` and there has been no activity for over 7 days.",
          "created_at": "2024-12-16T21:05:21Z"
        }
      ]
    },
    {
      "issue_number": 2205,
      "title": "[Bug] [Module Name] Agent add conversation history context.",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU 24g x 4\n\n### Models information\n\n LLM :Qwen2.5-32B-Instuct  \n\n### What happened\n\n![iwEcAqNwbmcDAQTRB2sF0QPpBrByPaZugVxORgdFJR7jPhYAB9IlwzAoCAAJomltCgAL0gABGR8 png_720x720q90](https://github.com/user-attachments/assets/093a301e-63b4-4b9f-9477-b406b0791366)\r\n如何利用智能体的对话记忆，实现将引用里的内容进行回复，并且实现两轮对话之间的关联\n\n### What you expected to happen\n\n第一轮对话他识别出来是结婚领域，第二论问了个办理地点 由于只输入办理地点他无法识别是哪个领域 他就会乱答，我希望他可以通过记忆知道需要回答的地点是婚姻办理的地点\n\n### How to reproduce\n\n通过意图分类创建不同的app，首先提出一个意图分类可以识别的领域问题，再问一个和前面问题相关但是意图识别无法识别的问题\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "classic325",
      "author_type": "User",
      "created_at": "2024-12-16T06:43:30Z",
      "updated_at": "2024-12-16T07:01:02Z",
      "closed_at": "2024-12-16T07:01:02Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2205/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2205",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2205",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:18.960315",
      "comments": []
    },
    {
      "issue_number": 1507,
      "title": "When creating an APP, where can I find the required app_id?",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n```\r\nfrom dbgpt.client import Client\r\nfrom dbgpt.client.app import get_app\r\n\r\nDBGPT_API_KEY = \"dbgpt\"\r\napp_id = \"{your_app_id}\"\r\n\r\nclient = Client(api_key=DBGPT_API_KEY)\r\nres = await get_app(client=client, app_id=app_id)\r\n```\r\n\r\n如上所示， \"{your_app_id}\" 是在哪里看的呢\n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "xiaoshuichong",
      "author_type": "User",
      "created_at": "2024-05-10T09:16:32Z",
      "updated_at": "2024-12-16T06:52:42Z",
      "closed_at": "2024-05-14T07:36:14Z",
      "labels": [
        "documentation",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1507/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1507",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1507",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:18.960334",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "@xiaoshuichong  sorry about that, you can check appid in dbgpt database or open your web console,  and find appid in response.",
          "created_at": "2024-05-13T01:48:39Z"
        },
        {
          "author": "xiaoshuichong",
          "body": "got it, thanks!",
          "created_at": "2024-05-14T07:36:11Z"
        },
        {
          "author": "BANGzys",
          "body": "> got it, thanks! 知道了，谢谢!\r\n\r\nPlease, where is the dbgpt database? thanks",
          "created_at": "2024-05-16T07:26:23Z"
        },
        {
          "author": "xiaoshuichong",
          "body": "> > got it, thanks! 知道了，谢谢!\r\n> \r\n> Please, where is the dbgpt database? thanks\r\n\r\nI find it in the terminal, not database",
          "created_at": "2024-05-24T06:17:17Z"
        },
        {
          "author": "whm233",
          "body": "> > > 知道了，谢谢！知道了，谢谢!\r\n> > \r\n> > \r\n> > 请问，dbgpt数据库在哪里？谢谢\r\n> \r\n> 我在终端中找到它，而不是在数据库中找到它\r\n\r\n你好请问这个appid具体是怎么找到的，我点击了数据库看了后台响应也没看到哪个是appid",
          "created_at": "2024-08-06T09:20:53Z"
        }
      ]
    },
    {
      "issue_number": 2202,
      "title": "Front-end compilation failed in window10",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nWindows\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [X] Other\n\n### Device information\n\nGPU\n\n### Models information\n\nqianwen\n\n### What happened\n\nWhen the front-end project runs the compilation command, it cannot be compiled successfully and there is no out file output.\n\n### What you expected to happen\n\nI hope that after running the build command, the out folder will be output, which contains the packaged products of this project.\r\nbut failed， I guess ,During the Next.js building process, ESM (ECMAScript Module) and CommonJS (CJS) in multiple modules are incompatible\n\n### How to reproduce\n\n1. Pull the warehouse\r\n\r\n2. Enter the web folder\r\n\r\n3. node version 20.14.0 npm version 10.7.0\r\n\r\n4. npm install --force\r\n\r\n5. Create .env file\r\n\r\n6. Run npm run compile command\n\n### Additional context\n\n$ npm run compile\r\n\r\n> db-gpt-web@0.1.0 compile\r\n> NODE_OPTIONS=--max_old_space_size=8192 next build && next export\r\n\r\n- info Loaded env from C:\\Users\\gaogao\\Desktop\\DB-GPT\\web\\.env\r\n- warn You have enabled experimental feature (esmExternals) in next.config.js.\r\n- warn Experimental features are not covered by semver, and may cause unexpected or broken application behavior. Use at your own risk.\r\n\r\n- info Creating an optimized production build  \r\n- info Compiled successfully\r\n- info Skipping validation of types\r\n- info Linting ...- warn The Next.js plugin was not detected in your ESLint configuration. See https://nextjs.org/docs/basic-features/eslint#migrating-existing-config\r\n\r\n./pages/chat/index.tsx\r\n116:6  Warning: React Hook useEffect has missing dependencies: 'setIsContract' and 'setIsMenuExpand'. Either include them or remove the dependency array.  react-hooks/exhaustive-deps\r\n\r\n./pages/construct/agent/index.tsx\r\n79:6  Warning: React Hook useEffect has a missing dependency: 'refresh'. Either include it or remove the dependency array.  react-hooks/exhaustive-deps\r\n\r\n./pages/construct/app/extra/components/auto-plan/index.tsx\r\n121:6  Warning: React Hook useMemo has a missing dependency: 'language'. Either include it or remove the dependency array.  react-hooks/exhaustive-deps\r\n155:6  Warning: React Hook useMemo has a missing dependency: 't'. Either include it or remove the dependency array.  react-hooks/exhaustive-deps\r\n\r\n./pages/construct/dbgpts/index.tsx\r\n83:6  Warning: React Hook useEffect has a missing dependency: 'refresh'. Either include it or remove the dependency array.  react-hooks/exhaustive-deps\r\n\r\n./pages/construct/flow/canvas/index.tsx\r\n79:6  Warning: React Hook useEffect has a missing dependency: 'getFlowData'. Either include it or remove the dependency array.  react-hooks/exhaustive-deps\r\n162:5  Warning: React Hook useCallback has a missing dependency: 'setNodes'. Either include it or remove the dependency array.  react-hooks/exhaustive-deps\r\n\r\n./pages/construct/flow/libro/index.tsx\r\n31:6  Warning: React Hook useEffect has a missing dependency: 'i18n'. Either include it or remove the dependency array.  \r\nreact-hooks/exhaustive-deps\r\n\r\n./pages/construct/prompt/index.tsx\r\n137:6  Warning: React Hook useEffect has a missing dependency: 'getPrompts'. Either include it or remove the dependency array.  react-hooks/exhaustive-deps\r\n\r\n./pages/knowledge/graph/index.tsx\r\n52:6  Warning: React Hook useEffect has a missing dependency: 'fetchGraphVis'. Either include it or remove the dependency array.  react-hooks/exhaustive-deps\r\n75:6  Warning: React Hook useEffect has a missing dependency: 'graphData.nodes'. Either include it or remove the dependency array.  react-hooks/exhaustive-deps\r\n\r\n./components/agent/my-plugins.tsx\r\n55:5  Warning: React Hook useCallback has a missing dependency: 'uninstall'. Either include it or remove the dependency array.  react-hooks/exhaustive-deps\r\n\r\n./components/app/agent-panel.tsx\r\n61:6  Warning: React Hook useEffect has a missing dependency: 'detail.llm_strategy'. Either include it or remove the dependency array.  react-hooks/exhaustive-deps\r\n65:6  Warning: React Hook useEffect has a missing dependency: 'updateAgent'. Either include it or remove the dependency array.  react-hooks/exhaustive-deps\r\n\r\n./components/app/app-modal.tsx\r\n150:6  Warning: React Hook useEffect has a missing dependency: 'fetchAgent'. Either include it or remove the dependency array.  react-hooks/exhaustive-deps\r\n154:6  Warning: React Hook useEffect has missing dependencies: 'initApp' and 'type'. Either include them or remove the dependency array.  react-hooks/exhaustive-deps\r\n\r\n./components/app/dag-layout.tsx\r\n35:6  Warning: React Hook useEffect has a missing dependency: 'fetchFlows'. Either include it or remove the dependency array.  react-hooks/exhaustive-deps\r\n\r\n./components/app/resource-card.tsx\r\n61:6  Warning: React Hook useEffect has missing dependencies: 'fetchResource', 'resource.type', and 'updateResource'. Either include them or remove the dependency array.  react-hooks/exhaustive-deps\r\n67:6  Warning: React Hook useEffect has missing dependencies: 'editResource.value', 'resource', and 'updateResource'. Either include them or remove the dependency array. You can also do a functional update 'setResource(r => ...)' if you only \r\nneed 'resource' in the 'setResource' call.  react-hooks/exhaustive-deps\r\n\r\n./components/chart/autoChart/index.tsx\r\n88:6  Warning: React Hook useEffect has missing dependencies: 'data' and 'getMergedAdvices'. Either include them or remove the dependency array.  react-hooks/exhaustive-deps\r\n88:7  Warning: React Hook useEffect has a complex expression in the dependency array. Extract it to a separate variable so it can be statically checked.  react-hooks/exhaustive-deps\r\n125:6  Warning: React Hook useMemo has missing dependencies: 'advisor?.dataAnalyzer' and 'data'. Either include them or remove the dependency array.  react-hooks/exhaustive-deps\r\n\r\n./components/chat/chat-container.tsx\r\n58:6  Warning: React Hook useEffect has missing dependencies: 'history' and 'setModel'. Either include them or remove the dependency array.  react-hooks/exhaustive-deps\r\n64:6  Warning: React Hook useEffect has a missing dependency: 'setHistory'. Either include it or remove the dependency array.  react-hooks/exhaustive-deps\r\n103:5  Warning: React Hook useCallback has a missing dependency: 'setHistory'. Either include it or remove the dependency array.  react-hooks/exhaustive-deps\r\n\r\n./components/chat/chat-content/index.tsx\r\n145:5  Warning: React Hook useMemo has an unnecessary dependency: 'context'. Either exclude it or remove the dependency array.  react-hooks/exhaustive-deps\r\n\r\n./components/chat/monaco-editor.tsx\r\n50:6  Warning: React Hook useMemo has a missing dependency: 'language'. Either include it or remove the dependency array.  react-hooks/exhaustive-deps\r\n\r\n./components/common/chat-dialog.tsx\r\n76:5  Warning: React Hook useCallback has missing dependencies: 'chatMode', 'chatParams', 'data', and 'model'. Either include them or remove the dependency array.  react-hooks/exhaustive-deps\r\n\r\n./components/common/completion-input.tsx\r\n37:6  Warning: React Hook useEffect has missing dependencies: 'fetchDocuments' and 'showUpload'. Either include them or remove the dependency array.  react-hooks/exhaustive-deps\r\n\r\n./components/common/gpt-card.tsx\r\n62:6  Warning: React Hook useMemo has missing dependencies: 'iconBorder' and 'title'. Either include them or remove the dependency array.  react-hooks/exhaustive-deps\r\n\r\n./components/flow/add-nodes-sider.tsx\r\n51:6  Warning: React Hook useEffect has a missing dependency: 'getNodes'. Either include it or remove the dependency array.  react-hooks/exhaustive-deps\r\n134:6  Warning: React Hook useMemo has a missing dependency: 'operators'. Either include it or remove the dependency array.  react-hooks/exhaustive-deps\r\n169:6  Warning: React Hook useMemo has a missing dependency: 'resources'. Either include it or remove the dependency array.  react-hooks/exhaustive-deps\r\n\r\n./components/flow/add-nodes.tsx\r\n24:6  Warning: React Hook useEffect has a missing dependency: 'getNodes'. Either include it or remove the dependency array.  react-hooks/exhaustive-deps\r\n82:6  Warning: React Hook useMemo has a missing dependency: 'operators'. Either include it or remove the dependency array.  react-hooks/exhaustive-deps\r\n113:6  Warning: React Hook useMemo has a missing dependency: 'resources'. Either include it or remove the dependency array.  react-hooks/exhaustive-deps\r\n\r\n./components/flow/node-renderer/upload.tsx\r\n48:6  Warning: React Hook useEffect has a missing dependency: 'data.value'. Either include it or remove the dependency array.  react-hooks/exhaustive-deps\r\n\r\n./components/knowledge/arguments-modal.tsx\r\n29:6  Warning: React Hook useEffect has a missing dependency: 'fetchArguments'. Either include it or remove the dependency array.  react-hooks/exhaustive-deps\r\n\r\n./components/knowledge/space-form.tsx\r\n31:6  Warning: React Hook useEffect has a missing dependency: 'form'. Either include it or remove the dependency array.  \r\nreact-hooks/exhaustive-deps\r\n\r\n./components/layout/side-bar.tsx\r\n409:6  Warning: React Hook useEffect has a missing dependency: 'i18n.language'. Either include it or remove the dependency array.  react-hooks/exhaustive-deps\r\n\r\n./components/prompt/prompt-form.tsx\r\n22:6  Warning: React Hook useEffect has missing dependencies: 'form' and 'prompt'. Either include them or remove the dependency array.  react-hooks/exhaustive-deps\r\n\r\ninfo  - Need to disable some ESLint rules? Learn more here: https://nextjs.org/docs/basic-features/eslint#disabling-rules- info Linting\r\n- info Collecting page data .Error [ERR_REQUIRE_ESM]: require() of ES Module C:\\Users\\gaogao\\Desktop\\DB-GPT\\web\\node_modules\\d3-color\\src\\index.js from C:\\Users\\gaogao\\Desktop\\DB-GPT\\web\\node_modules\\@antv\\g-lite\\dist\\index.js not supported. \r\nInstead change the require of C:\\Users\\gaogao\\Desktop\\DB-GPT\\web\\node_modules\\d3-color\\src\\index.js in C:\\Users\\gaogao\\Desktop\\DB-GPT\\web\\node_modules\\@antv\\g-lite\\dist\\index.js to a dynamic import() which is available in all CommonJS modules.\r\n    at Object.<anonymous> (C:\\Users\\gaogao\\Desktop\\DB-GPT\\web\\node_modules\\@antv\\g-lite\\dist\\index.js:24:10) {\r\n  code: 'ERR_REQUIRE_ESM'\r\n}\r\n\r\n> Build error occurred\r\nError: Failed to collect page data for /knowledge/graph\r\n    at C:\\Users\\gaogao\\Desktop\\DB-GPT\\web\\node_modules\\next\\dist\\build\\utils.js:1161:15\r\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5) {\r\n  type: 'Error'\r\n}\r\n- info Collecting page data .Note: This command was run via npm module 'win-node-env'\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "gaogaomie",
      "author_type": "User",
      "created_at": "2024-12-13T08:50:48Z",
      "updated_at": "2024-12-16T06:42:11Z",
      "closed_at": "2024-12-16T06:42:10Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2202/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2202",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2202",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:19.132564",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "try make sure `d3-color` version is <= 2.0.0 in package.json and package-lock.json and npm install again",
          "created_at": "2024-12-15T12:43:26Z"
        },
        {
          "author": "gaogaomie",
          "body": "It has been solved. I will provide you with my solution ideas for reference only.\r\n1. Use 【**yarn install**】 to install dependent packages, do not use npm！！！\r\n2. The Windows-style line break is CRLF, which is a combination of carriage return and line feed. In the project, Prettier expects the Unix-s",
          "created_at": "2024-12-16T06:42:02Z"
        }
      ]
    },
    {
      "issue_number": 2203,
      "title": "[Bug] [Module Name] Bug title ",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n<3.9\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [X] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [X] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n2C4G\n\n### Models information\n\n1\n\n### What happened\n\n1\n\n### What you expected to happen\n\n1\n\n### How to reproduce\n\n1\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "cai417",
      "author_type": "User",
      "created_at": "2024-12-16T02:21:49Z",
      "updated_at": "2024-12-16T02:23:32Z",
      "closed_at": "2024-12-16T02:23:32Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2203/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2203",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2203",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:19.361202",
      "comments": []
    },
    {
      "issue_number": 1897,
      "title": "tugraph已经启动，无法连接",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\na100 *2\n\n### Models information\n\ndeepseek & m3e\n\n### What happened\n\n已经部署好tugraph\r\n![image](https://github.com/user-attachments/assets/ea691a0c-33ef-4d08-b111-4421d3e67045)\r\n在dbgpt中创建数据源，报错\r\n![image](https://github.com/user-attachments/assets/2fcb3ef7-3cf8-466b-9ba7-35a2150ba14f)\r\ntugraph配置如下：\r\n![image](https://github.com/user-attachments/assets/a55a0663-2ffe-4bdf-882e-b7ef465a09b8)\r\ndb-gpt-webserver-1日志信息：\r\n2024-08-27 10:52:13 9e01e2bc51ef dbgpt.datasource.manages.connector_manager[1] INFO add_db:{'db_type': 'tugraph', 'db_name': 'ThreeKingdoms', 'file_path': '', 'db_host': '127.0.0.1', 'db_port': 7687, 'db_user': 'admin', 'db_pwd': 'tugraph1234', 'comment': ''}\r\nINFO:     192.168.64.1:50862 - \"POST /api/v1/chat/db/add HTTP/1.1\" 200 OK\r\n2024-08-27 10:52:13 9e01e2bc51ef dbgpt.datasource.manages.connect_config_db[1] INFO Result: <sqlalchemy.engine.cursor.CursorResult object at 0x756770167ee0>\r\nINFO:     192.168.64.1:50862 - \"GET /api/v1/chat/db/list HTTP/1.1\" 200 OK\r\n2024-08-27 10:52:44 9e01e2bc51ef dbgpt.datasource.manages.connector_manager[1] ERROR ThreeKingdoms Test connect Failure!Couldn't connect to 127.0.0.1:7687 (resolved to ()):\n\n### What you expected to happen\n\n1\n\n### How to reproduce\n\n1\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "flowertreeML",
      "author_type": "User",
      "created_at": "2024-08-27T10:58:15Z",
      "updated_at": "2024-12-14T09:24:44Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1897/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1897",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1897",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:19.361221",
      "comments": [
        {
          "author": "dkasa",
          "body": "容器中执行 pip install neo4j\r\n\r\n如果是docker-compose.yml\r\ncommand: [\"bash\", \"-c\", \"pip install neo4j; sleep 3; python3 dbgpt/app/dbgpt_server.py\"]",
          "created_at": "2024-08-30T03:59:58Z"
        },
        {
          "author": "ygbingo",
          "body": "我也遇到了这个问题，然后我尝试把127.0.0.1换成宿主机的ip地址之后解决了",
          "created_at": "2024-09-10T02:37:10Z"
        },
        {
          "author": "TodayWei",
          "body": "我换成宿主主机也不行啊",
          "created_at": "2024-10-23T09:56:42Z"
        },
        {
          "author": "GeoZhanglw",
          "body": "遇到了同样的问题，有解决的吗\r\n",
          "created_at": "2024-12-14T09:24:43Z"
        }
      ]
    },
    {
      "issue_number": 2002,
      "title": "[Bug] [Docker Compose] failed to deploy on a server with no GPU",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [X] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nDevice: CPU\r\nrchitecture:             x86_64\r\n  CPU op-mode(s):         32-bit, 64-bit\r\n  Address sizes:          39 bits physical, 48 bits virtual\r\n  Byte Order:             Little Endian\r\nCPU(s):                   8\r\n  On-line CPU(s) list:    0-7\r\nVendor ID:                GenuineIntel\r\n  BIOS Vendor ID:         Intel(R) Corporation\r\n  Model name:             Intel(R) Core(TM) i7-10700 CPU @ 2.90GHz\r\n    BIOS Model name:      Intel(R) Core(TM) i7-10700 CPU @ 2.90GHz None CPU @ 2.9GHz\r\n\n\n### Models information\n\nexternal LLM, Qwen-72B\n\n### What happened\n\nroot@ubuntu2404:~/DB-GPT-main# docker compose -f docker-compose.yml up -d\r\n[+] Running 1/2\r\n ✔ Container db-gpt-main-db-1         Running                                                                                                                                                                                                                                                         0.0s\r\n ⠹ Container db-gpt-main-webserver-1  Starting                                                                                                                                                                                                                                                        0.2s\r\nError response from daemon: failed to create task for container: failed to create shim task: OCI runtime create failed: runc create failed: unable to start container process: error during container init: error running hook #0: error running hook: exit status 1, stdout: , stderr: Auto-detected mode as 'legacy'\r\nnvidia-container-cli: initialization error: load library failed: libnvidia-ml.so.1: cannot open shared object file: no such file or directory: unknown\r\n\n\n### What you expected to happen\n\nShould be able to setup the docker and run with external LLM.\n\n### How to reproduce\n\nJust try to docker compose on a server without GPU.\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "maxpaynebupt",
      "author_type": "User",
      "created_at": "2024-09-11T04:09:03Z",
      "updated_at": "2024-12-13T06:17:30Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 2,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2002/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2002",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2002",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:19.530119",
      "comments": [
        {
          "author": "RENLINA123",
          "body": "Have you found any methods to start DBGPT without a GPU?",
          "created_at": "2024-11-20T07:03:26Z"
        },
        {
          "author": "sliontc",
          "body": "Any solutions？ I have same error when start with docker compose.",
          "created_at": "2024-12-13T06:17:29Z"
        }
      ]
    },
    {
      "issue_number": 2006,
      "title": "[Feature][GraphRAG] Explore knowledge extraction from tabular data",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\nImprove the extraction ability of knowledge graphs and support obtaining triple information from tabular data.\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nMedium\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "fanzhidongyzby",
      "author_type": "User",
      "created_at": "2024-09-11T10:16:19Z",
      "updated_at": "2024-12-12T08:40:40Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "GraphRAG",
        "hacktoberfest"
      ],
      "label_count": 4,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2006/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2006",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2006",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:19.700103",
      "comments": []
    },
    {
      "issue_number": 2173,
      "title": "[Bug] [OpenAILLMClient] Httpx deprecated `proxies` argument in v0.28.0",
      "body": "### Search before asking\r\n\r\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\r\n\r\n\r\n### Operating system information\r\n\r\nMacOS(M1, M2...)\r\n\r\n### Python version information\r\n\r\n>=3.11\r\n\r\n### DB-GPT version\r\n\r\nlatest release\r\n\r\n### Related scenes\r\n\r\n- [ ] Chat Data\r\n- [ ] Chat Excel\r\n- [ ] Chat DB\r\n- [ ] Chat Knowledge\r\n- [X] Model Management\r\n- [ ] Dashboard\r\n- [ ] Plugins\r\n\r\n### Installation Information\r\n\r\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\r\n\r\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\r\n\r\n- [ ] AutoDL Image\r\n- [ ] Other\r\n\r\n### Device information\r\n\r\nMacOS M2\r\n\r\n### Models information\r\n\r\n``` python\r\nimport asyncio\r\n\r\nfrom dbgpt.core import ModelRequest\r\nfrom dbgpt.model.proxy.llms.chatgpt import OpenAILLMClient  # type: ignore\r\n\r\n\r\nasync def main():\r\n    client = OpenAILLMClient(model_alias=\"gpt-4o-mini\")\r\n    response = await client.generate(ModelRequest._build(\"gpt-4o-mini\", \"Hi!\"))\r\n    print(response)\r\n\r\n\r\nasyncio.run(main())\r\n```\r\n\r\n### What happened\r\n\r\n```\r\nModelOutput(text=\"**LLMServer Generate Error, Please CheckErrorInfo.**: AsyncClient.__init__() got an unexpected keyword argument 'proxies'\", error_code=1, incremental=False, model_context=None, finish_reason=None, usage=None, metrics=None)\r\n```\r\n\r\n### What you expected to happen\r\n\r\nCall correctly\r\n\r\n### How to reproduce\r\n\r\nRun the example code.\r\n\r\n### Additional context\r\n\r\nThe iusse is that httpx has updated its init() for AsyncClient\r\n\r\n            **openai_params, http_client=httpx.AsyncClient(proxies=init_params.proxies)\r\n\r\n[Realease note of httpx v0.28.0](https://github.com/encode/httpx/blob/HEAD/CHANGELOG.md#0280-28th-november-2024)\r\n(\"The deprecated `proxies` argument has now been removed.\"\r\n\r\nv0.27.2:\r\n```\r\nclass AsyncClient(BaseClient):\r\n    \"\"\"\r\n    An asynchronous HTTP client, with connection pooling, HTTP/2, redirects,\r\n    cookie persistence, etc.\r\n\r\n    It can be shared between tasks.\r\n\r\n    Usage:\r\n\r\n    ```python\r\n    >>> async with httpx.AsyncClient() as client:\r\n    >>>     response = await client.get('https://example.org')\r\n    ```\r\n\r\n    **Parameters:**\r\n\r\n    * **auth** - *(optional)* An authentication class to use when sending\r\n    requests.\r\n    * **params** - *(optional)* Query parameters to include in request URLs, as\r\n    a string, dictionary, or sequence of two-tuples.\r\n    * **headers** - *(optional)* Dictionary of HTTP headers to include when\r\n    sending requests.\r\n    * **cookies** - *(optional)* Dictionary of Cookie items to include when\r\n    sending requests.\r\n    * **verify** - *(optional)* SSL certificates (a.k.a CA bundle) used to\r\n    verify the identity of requested hosts. Either `True` (default CA bundle),\r\n    a path to an SSL certificate file, an `ssl.SSLContext`, or `False`\r\n    (which will disable verification).\r\n    * **cert** - *(optional)* An SSL certificate used by the requested host\r\n    to authenticate the client. Either a path to an SSL certificate file, or\r\n    two-tuple of (certificate file, key file), or a three-tuple of (certificate\r\n    file, key file, password).\r\n    * **http2** - *(optional)* A boolean indicating if HTTP/2 support should be\r\n    enabled. Defaults to `False`.\r\n    * **proxy** - *(optional)* A proxy URL where all the traffic should be routed.\r\n    * **proxies** - *(optional)* A dictionary mapping HTTP protocols to proxy\r\n    URLs.\r\n    * **timeout** - *(optional)* The timeout configuration to use when sending\r\n    requests.\r\n    * **limits** - *(optional)* The limits configuration to use.\r\n    * **max_redirects** - *(optional)* The maximum number of redirect responses\r\n    that should be followed.\r\n    * **base_url** - *(optional)* A URL to use as the base when building\r\n    request URLs.\r\n    * **transport** - *(optional)* A transport class to use for sending requests\r\n    over the network.\r\n    * **app** - *(optional)* An ASGI application to send requests to,\r\n    rather than sending actual network requests.\r\n    * **trust_env** - *(optional)* Enables or disables usage of environment\r\n    variables for configuration.\r\n    * **default_encoding** - *(optional)* The default encoding to use for decoding\r\n    response text, if no charset information is included in a response Content-Type\r\n    header. Set to a callable for automatic character set detection. Default: \"utf-8\".\r\n    \"\"\"\r\n\r\n    def __init__(\r\n        self,\r\n        *,\r\n        auth: AuthTypes | None = None,\r\n        params: QueryParamTypes | None = None,\r\n        headers: HeaderTypes | None = None,\r\n        cookies: CookieTypes | None = None,\r\n        verify: VerifyTypes = True,\r\n        cert: CertTypes | None = None,\r\n        http1: bool = True,\r\n        http2: bool = False,\r\n        proxy: ProxyTypes | None = None,\r\n        proxies: ProxiesTypes | None = None,\r\n        mounts: None | (typing.Mapping[str, AsyncBaseTransport | None]) = None,\r\n        timeout: TimeoutTypes = DEFAULT_TIMEOUT_CONFIG,\r\n        follow_redirects: bool = False,\r\n        limits: Limits = DEFAULT_LIMITS,\r\n        max_redirects: int = DEFAULT_MAX_REDIRECTS,\r\n        event_hooks: None | (typing.Mapping[str, list[EventHook]]) = None,\r\n        base_url: URL | str = \"\",\r\n        transport: AsyncBaseTransport | None = None,\r\n        app: typing.Callable[..., typing.Any] | None = None,\r\n        trust_env: bool = True,\r\n        default_encoding: str | typing.Callable[[bytes], str] = \"utf-8\",\r\n    ) -> None:\r\n\r\n```\r\n\r\nv0.28.0\r\n```\r\nclass AsyncClient(BaseClient):\r\n    \"\"\"\r\n    An asynchronous HTTP client, with connection pooling, HTTP/2, redirects,\r\n    cookie persistence, etc.\r\n\r\n    It can be shared between tasks.\r\n\r\n    Usage:\r\n\r\n    ```python\r\n    >>> async with httpx.AsyncClient() as client:\r\n    >>>     response = await client.get('https://example.org')\r\n    ```\r\n\r\n    **Parameters:**\r\n\r\n    * **auth** - *(optional)* An authentication class to use when sending\r\n    requests.\r\n    * **params** - *(optional)* Query parameters to include in request URLs, as\r\n    a string, dictionary, or sequence of two-tuples.\r\n    * **headers** - *(optional)* Dictionary of HTTP headers to include when\r\n    sending requests.\r\n    * **cookies** - *(optional)* Dictionary of Cookie items to include when\r\n    sending requests.\r\n    * **verify** - *(optional)* Either `True` to use an SSL context with the\r\n    default CA bundle, `False` to disable verification, or an instance of\r\n    `ssl.SSLContext` to use a custom context.\r\n    * **http2** - *(optional)* A boolean indicating if HTTP/2 support should be\r\n    enabled. Defaults to `False`.\r\n    * **proxy** - *(optional)* A proxy URL where all the traffic should be routed.\r\n    * **timeout** - *(optional)* The timeout configuration to use when sending\r\n    requests.\r\n    * **limits** - *(optional)* The limits configuration to use.\r\n    * **max_redirects** - *(optional)* The maximum number of redirect responses\r\n    that should be followed.\r\n    * **base_url** - *(optional)* A URL to use as the base when building\r\n    request URLs.\r\n    * **transport** - *(optional)* A transport class to use for sending requests\r\n    over the network.\r\n    * **trust_env** - *(optional)* Enables or disables usage of environment\r\n    variables for configuration.\r\n    * **default_encoding** - *(optional)* The default encoding to use for decoding\r\n    response text, if no charset information is included in a response Content-Type\r\n    header. Set to a callable for automatic character set detection. Default: \"utf-8\".\r\n    \"\"\"\r\n\r\n    def __init__(\r\n        self,\r\n        *,\r\n        auth: AuthTypes | None = None,\r\n        params: QueryParamTypes | None = None,\r\n        headers: HeaderTypes | None = None,\r\n        cookies: CookieTypes | None = None,\r\n        verify: ssl.SSLContext | str | bool = True,\r\n        cert: CertTypes | None = None,\r\n        http1: bool = True,\r\n        http2: bool = False,\r\n        proxy: ProxyTypes | None = None,\r\n        mounts: None | (typing.Mapping[str, AsyncBaseTransport | None]) = None,\r\n        timeout: TimeoutTypes = DEFAULT_TIMEOUT_CONFIG,\r\n        follow_redirects: bool = False,\r\n        limits: Limits = DEFAULT_LIMITS,\r\n        max_redirects: int = DEFAULT_MAX_REDIRECTS,\r\n        event_hooks: None | (typing.Mapping[str, list[EventHook]]) = None,\r\n        base_url: URL | str = \"\",\r\n        transport: AsyncBaseTransport | None = None,\r\n        trust_env: bool = True,\r\n        default_encoding: str | typing.Callable[[bytes], str] = \"utf-8\",\r\n    ) -> None:\r\n```\r\n\r\n\r\n## Solution:\r\nfrom:\r\n```\r\ndef _build_openai_client(init_params: OpenAIParameters) -> Tuple[str, ClientType]:\r\n    import httpx\r\n\r\n    openai_params, api_type, api_version, api_azure_deployment = _initialize_openai_v1(\r\n        init_params\r\n    )\r\n    if api_type == \"azure\":\r\n        from openai import AsyncAzureOpenAI\r\n\r\n        return api_type, AsyncAzureOpenAI(\r\n            api_key=openai_params[\"api_key\"],\r\n            api_version=api_version,\r\n            azure_deployment=api_azure_deployment,\r\n            azure_endpoint=openai_params[\"base_url\"],\r\n            http_client=httpx.AsyncClient(proxies=init_params.proxies),\r\n        )\r\n    else:\r\n        from openai import AsyncOpenAI\r\n\r\n        return api_type, AsyncOpenAI(\r\n            **openai_params, http_client=httpx.AsyncClient(proxies=init_params.proxies)\r\n        )\r\n```\r\n\r\nto:\r\n```\r\ndef _build_openai_client(init_params: OpenAIParameters) -> Tuple[str, ClientType]:\r\n    import httpx\r\n\r\n    openai_params, api_type, api_version, api_azure_deployment = _initialize_openai_v1(\r\n        init_params\r\n    )\r\n    if api_type == \"azure\":\r\n        from openai import AsyncAzureOpenAI\r\n\r\n        return api_type, AsyncAzureOpenAI(\r\n            api_key=openai_params[\"api_key\"],\r\n            api_version=api_version,\r\n            azure_deployment=api_azure_deployment,\r\n            azure_endpoint=openai_params[\"base_url\"],\r\n            http_client=httpx.AsyncClient(),\r\n        )\r\n    else:\r\n        from openai import AsyncOpenAI\r\n\r\n        return api_type, AsyncOpenAI(\r\n            **openai_params, http_client=httpx.AsyncClient()\r\n        )\r\n```\r\n\r\n### Are you willing to submit PR?\r\n\r\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "Appointat",
      "author_type": "User",
      "created_at": "2024-12-02T17:33:42Z",
      "updated_at": "2024-12-12T02:34:32Z",
      "closed_at": "2024-12-12T02:34:32Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 0,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2173/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2173",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2173",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:19.700126",
      "comments": []
    },
    {
      "issue_number": 2182,
      "title": "[Bug] [Knowledge] The embeding data will not be deleted in the runtime directory \"pilot/data\" when the space name was delete",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [X] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU 0, 24GB memory\n\n### Models information\n\ntext2vec-large-chinese\r\nQWen2.5-14B-Instruct\n\n### What happened\n\nNither of deletion the knowledge space name from Web or dbgpt command cli will not delete the pilot data, that caused failure when re-create the same space name.\n\n### What you expected to happen\n\nIt should be that when the space name was deleted, the corresponding pilot data was deleted from filesystem. If not, another result maybe that availabe volume of filesystem decreased.\n\n### How to reproduce\n\nJust create knowledge space using name such as 'testknowlegeSpace', then delete the space with name 'testknowlegeSpace', and re-create the space 'testknowlegeSpace', when entered the detail of recreated space, the content failed.\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [x] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "toralee",
      "author_type": "User",
      "created_at": "2024-12-06T04:09:54Z",
      "updated_at": "2024-12-11T07:10:40Z",
      "closed_at": "2024-12-11T07:10:40Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2182/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2182",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2182",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:19.700134",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "what's your dbgpt version and what vector type you use?",
          "created_at": "2024-12-06T10:16:12Z"
        },
        {
          "author": "toralee",
          "body": "> what's your dbgpt version and what vector type you use?\r\n\r\nlatest version: 0.6.2, I tried the Cli command `dbgpt knowledge load` and used the default vector type 'Chroma' ",
          "created_at": "2024-12-06T15:17:22Z"
        },
        {
          "author": "Aries-ckt",
          "body": "Is it like this every time? Is it the same when creating a new knowledge space and deleting it?\r\n ",
          "created_at": "2024-12-07T13:58:23Z"
        },
        {
          "author": "toralee",
          "body": "> Is it like this every time? Is it the same when creating a new knowledge space and deleting it?\r\n\r\nYes, it happened each time. When a new knowledge was created, and then to delete the exist knowledge, the result was that deleting space ([spacename].vectordb) sucessed, while the uploading directory",
          "created_at": "2024-12-07T15:27:43Z"
        },
        {
          "author": "Aries-ckt",
          "body": "That's wired, I see you pull your solution for this issue, we will check it. Thanks for contribution.",
          "created_at": "2024-12-08T16:09:48Z"
        }
      ]
    },
    {
      "issue_number": 2183,
      "title": "[Doc][Module Name] How to find the DB-GPT version?",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n如何查看自己安装的DB-GPT版本呢？\n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "lll-Dragon",
      "author_type": "User",
      "created_at": "2024-12-07T08:26:59Z",
      "updated_at": "2024-12-10T09:03:49Z",
      "closed_at": "2024-12-07T08:39:13Z",
      "labels": [
        "documentation",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2183/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2183",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2183",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:20.042700",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "try look at `_version.py`",
          "created_at": "2024-12-10T09:03:30Z"
        }
      ]
    },
    {
      "issue_number": 2038,
      "title": "[Bug] [Module Name] Health check failed",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\n-\n\n### Models information\n\n-\n\n### What happened\n\n在服务器部署DBGPT服务后，一段时间（可能几分钟、可能几小时）刷新页面会一直出现WARNING Health check failed for http://127.0.0.1:5670, error: HTTPConnectionPool(host='127.0.0.1', port=5670): Read timed out. (read timeout=10)，我调的是zhipu api，服务器也没什么问题，想知道可能原因是什么？\n\n### What you expected to happen\n\n-\n\n### How to reproduce\n\n-\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "yuerf",
      "author_type": "User",
      "created_at": "2024-09-24T01:56:45Z",
      "updated_at": "2024-12-10T08:39:41Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2038/reactions",
        "total_count": 2,
        "+1": 2,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2038",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2038",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:20.348640",
      "comments": [
        {
          "author": "pengnianhhh",
          "body": "请问解决了吗",
          "created_at": "2024-12-10T08:39:40Z"
        }
      ]
    },
    {
      "issue_number": 1268,
      "title": "[Bug] Password should be set if and only if in LDAP or CUSTOM mode; Remove password or use one of those modes",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [X] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU\n\n### Models information\n\nLLM :zhipu\r\n\n\n### What happened\n\nconnect hive:\r\nValueError: Password should be set if and only if in LDAP or CUSTOM mode; Remove password or use one of those modes\n\n### What you expected to happen\n\nfix this bug\n\n### How to reproduce\n\nconnect hive\n\n### Additional context\n\nno\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "Jonsun-N",
      "author_type": "User",
      "created_at": "2024-03-08T03:13:15Z",
      "updated_at": "2024-12-10T03:49:52Z",
      "closed_at": "2024-04-22T21:04:45Z",
      "labels": [
        "bug",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 6,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1268/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1268",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1268",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:20.596478",
      "comments": [
        {
          "author": "fangyinc",
          "body": "@xiuzhu9527 Can you take a look at this issue?",
          "created_at": "2024-03-11T04:10:00Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-04-10T21:04:45Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue bas been closed, because it has been marked as `stale` and there has been no activity for over 7 days.",
          "created_at": "2024-04-22T21:04:45Z"
        },
        {
          "author": "ketingli1",
          "body": "i got the same error.\r\nmy hive version is 3.4 and kerberos is need, i dont know kerberos is affect",
          "created_at": "2024-06-17T03:47:28Z"
        },
        {
          "author": "Sloane9511",
          "body": "i got the same error, how to resolve it?",
          "created_at": "2024-10-12T02:26:41Z"
        }
      ]
    },
    {
      "issue_number": 2082,
      "title": "[Bug] [TuGraph] document sync batch error {code: InputError} {message: No such graph: 1} 无法建立图知识库",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nlatest release\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [X] Chat DB\n- [x] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [X] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\ncentos7.9\r\na800\n\n### Models information\n\nchatglm4-9b-chat\r\ntext2vec-large-chinese\r\n\n\n### What happened\n\n建立图知识库，无论输入什么格式文件，无论选什么切分方式，都报这个错误，无法解决，Tugraph运行正常，建立向量知识库也正常。\r\n\r\n![image](https://github.com/user-attachments/assets/020d0b10-45a5-44b1-9f38-2da4445167b3)\r\n![image](https://github.com/user-attachments/assets/a4d9915c-b4b0-4adc-bb8d-2da3b7970382)\r\n![image](https://github.com/user-attachments/assets/eb0041ed-5c85-4e07-9c8c-3e47ab123a75)\r\n\n\n### What you expected to happen\n\n正常构建图知识库\n\n### How to reproduce\n\n直接dockercompose运行最新doker和Tugraph\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "nmbtwzt",
      "author_type": "User",
      "created_at": "2024-10-18T12:46:53Z",
      "updated_at": "2024-12-10T01:43:32Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2082/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2082",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2082",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:20.852338",
      "comments": [
        {
          "author": "TodayWei",
          "body": "嗯我也遇到了，在图数据库这事上，有好几个错了\r\n",
          "created_at": "2024-10-24T04:03:34Z"
        },
        {
          "author": "Appointat",
          "body": "@nmbtwzt @TodayWei Hi. The name of the graph rag can not be a number. TuGraph DB refuses to create a graph named like \"1\".",
          "created_at": "2024-10-27T17:23:42Z"
        },
        {
          "author": "KaixuanDai",
          "body": "可能是图数据库不能用中文命名，改成英文就可以了",
          "created_at": "2024-12-10T01:43:31Z"
        }
      ]
    },
    {
      "issue_number": 2181,
      "title": "[Feature][Add User Management] Add User Management",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n能否在未来的计划中添加admin管理员与普通用户，分发账号与api并使得能够将页面直接嵌入到项目中。\n\n### Use case\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nNone\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "tangyu-ty",
      "author_type": "User",
      "created_at": "2024-12-05T13:33:23Z",
      "updated_at": "2024-12-07T13:58:37Z",
      "closed_at": "2024-12-07T13:58:37Z",
      "labels": [
        "enhancement",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2181/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2181",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2181",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:21.041617",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "hi, we will not add user management module in the future, we provide `user_code` and `sys_code` fields in our tables in `dbgpt.sql`, we hope that community developers will add user management themselves.",
          "created_at": "2024-12-05T15:28:24Z"
        }
      ]
    },
    {
      "issue_number": 2176,
      "title": "[Bug] [Module Name] Bug title web \"304 Not Modified\"",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n3.10\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [X] Dashboard\n- [X] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nLLM:Qwen2.5-7B-Instruct  嵌入模型：text2vec-large-chinese\n\n### What happened\n\nINFO:     127.0.0.1:52380 - \"GET /favicon.ico HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:52472 - \"GET / HTTP/1.1\" 304 Not Modified\r\nINFO:     127.0.0.1:52470 - \"GET /_next/static/css/56abd552837c60f9.css HTTP/1.1\" 304 Not Modified\r\nINFO:     127.0.0.1:52468 - \"GET /_next/static/css/9b601b4de5d78ac2.css HTTP/1.1\" 304 Not Modified\r\nINFO:     127.0.0.1:52466 - \"GET /_next/static/chunks/webpack-c84cdc13d41d4170.js HTTP/1.1\" 304 Not Modified\r\nINFO:     127.0.0.1:52472 - \"GET /_next/static/chunks/pages/_app-7c76237d5662964a.js HTTP/1.1\" 304 Not Modified\r\nINFO:     127.0.0.1:52462 - \"GET /_next/static/chunks/main-6c4c7f5b8c9b1320.js HTTP/1.1\" 304 Not Modified\r\nINFO:     127.0.0.1:52464 - \"GET /_next/static/chunks/framework-8b06d32cbb857e0e.js HTTP/1.1\" 304 Not Modified\r\nINFO:     127.0.0.1:52470 - \"GET /_next/static/chunks/2648-137ba93003e100f4.js HTTP/1.1\" 304 Not Modified\r\nINFO:     127.0.0.1:52468 - \"GET /_next/static/chunks/3791-58df908ca3784958.js HTTP/1.1\" 304 Not Modified\r\nINFO:     127.0.0.1:52466 - \"GET /_next/static/chunks/2913-9c0ff8bf7b69626b.js HTTP/1.1\" 304 Not Modified\r\nINFO:     127.0.0.1:52472 - \"GET /_next/static/chunks/5278-36ac2f07bcb92504.js HTTP/1.1\" 304 Not Modified\r\nINFO:     127.0.0.1:52464 - \"GET /_next/static/chunks/8791-d36492edb39795c5.js HTTP/1.1\" 304 Not Modified\r\nINFO:     127.0.0.1:52462 - \"GET /_next/static/chunks/4330-a1b5cee9f3b8b8f7.js HTTP/1.1\" 304 Not Modified\r\nINFO:     127.0.0.1:52470 - \"GET /_next/static/chunks/1049-b2925c4c7e1e37be.js HTTP/1.1\" 304 Not Modified\r\nINFO:     127.0.0.1:52468 - \"GET /_next/static/chunks/5030-ed144c49e325cd61.js HTTP/1.1\" 304 Not Modified\r\nINFO:     127.0.0.1:52466 - \"GET /_next/static/chunks/2783-67b811a852a75cad.js HTTP/1.1\" 304 Not Modified\r\nINFO:     127.0.0.1:52472 - \"GET /_next/static/chunks/8733-1e1fc970bff78378.js HTTP/1.1\" 304 Not Modified\r\nINFO:     127.0.0.1:52464 - \"GET /_next/static/chunks/pages/index-9575cac1e78e8e8e.js HTTP/1.1\" 304 Not Modified\r\nINFO:     127.0.0.1:52462 - \"GET /_next/static/uxzFDWvtDY7kRGsQkNbam/_buildManifest.js HTTP/1.1\" 304 Not Modified\r\nINFO:     127.0.0.1:52470 - \"GET /_next/static/uxzFDWvtDY7kRGsQkNbam/_ssgManifest.js HTTP/1.1\" 304 Not Modified\r\nINFO:     127.0.0.1:52468 - \"GET /_next/static/css/antd-output/antd.min.7d5365b5.css HTTP/1.1\" 304 Not Modified\n\n### What you expected to happen\n\nshow the web page\n\n### How to reproduce\n\njust Go to 'http://127.0.0.1:5670/'\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "RedCode-X",
      "author_type": "User",
      "created_at": "2024-12-03T15:21:35Z",
      "updated_at": "2024-12-07T06:08:02Z",
      "closed_at": "2024-12-07T06:08:01Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2176/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2176",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2176",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:21.265223",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "try restart and clear the web browser cache?",
          "created_at": "2024-12-04T01:45:40Z"
        },
        {
          "author": "RedCode-X",
          "body": "> try restart and clear the web browser cache?\r\n[English Answer] I found the problem! I used the built-in Firefox browser of CentOS7.9, and the browser version was too low. Later, I turned off the firewall in VMware and accessed it in Windows computer. Since the Google browser version was higher, th",
          "created_at": "2024-12-07T06:06:43Z"
        },
        {
          "author": "RedCode-X",
          "body": "只需要升级浏览器版本即可!\r\n just need to upgrade the browser version!",
          "created_at": "2024-12-07T06:08:01Z"
        }
      ]
    },
    {
      "issue_number": 2177,
      "title": "[Bug] [create agent app] Column 'sys_code' cannot be null",
      "body": "### Search before asking\r\n\r\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\r\n\r\n\r\n### Operating system information\r\n\r\nLinux\r\n\r\n### Python version information\r\n\r\n>=3.11\r\n\r\n### DB-GPT version\r\n\r\nlatest release V0.6.2\r\n\r\n### Related scenes\r\n\r\n- [ ] Chat Data\r\n- [ ] Chat Excel\r\n- [ ] Chat DB\r\n- [ ] Chat Knowledge\r\n- [ ] Model Management\r\n- [X] Dashboard\r\n- [ ] Plugins\r\n\r\n### Installation Information\r\n\r\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\r\n\r\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\r\n\r\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\r\n\r\n- [ ] AutoDL Image\r\n- [ ] Other\r\n\r\n### Device information\r\n\r\nDevice: CPU\r\n\r\n### Models information\r\n\r\nLLM: ollama  qwen1.5           embedding: normic\r\n\r\n### What happened\r\n\r\n通过dashboard创建单agent app时，报数据库错误， 如下：\r\n  File \"/data/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/pymysql/connections.py\", line 775, in _read_packet\r\n    packet.raise_for_error()\r\n  File \"/data/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/pymysql/protocol.py\", line 219, in raise_for_error\r\n    err.raise_mysql_exception(self._data)\r\n  File \"/data/miniconda3/envs/dbgpt_env/lib/python3.10/site-packages/pymysql/err.py\", line 150, in raise_mysql_exception\r\n    raise errorclass(errno, errval)\r\nsqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1048, \"Column 'sys_code' cannot be null\")\r\n[SQL: INSERT INTO recommend_question (app_code, user_code, sys_code, gmt_create, gmt_modified, question, valid, params, chat_mode, is_hot_question) VALUES (%(app_code)s, %(user_code)s, %(sys_code)s, %(gmt_create)s, %(gmt_modified)s, %(question)s, %(valid)s, %(params)s, %(chat_mode)s, %(is_hot_question)s)]\r\n\r\n### What you expected to happen\r\n\r\nsave success\r\n\r\n### How to reproduce\r\n\r\n1. 通过dashboard--创建应用\r\n2. 单一智能体模式\r\n3. 保存时报错\r\n\r\n### Additional context\r\n\r\n_No response_\r\n\r\n### Are you willing to submit PR?\r\n\r\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "maco6096",
      "author_type": "User",
      "created_at": "2024-12-04T02:38:10Z",
      "updated_at": "2024-12-04T03:25:44Z",
      "closed_at": "2024-12-04T03:25:44Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2177/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2177",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2177",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:21.538972",
      "comments": [
        {
          "author": "maco6096",
          "body": "更新的v0.6.0的sql script， 功能正常了。",
          "created_at": "2024-12-04T03:25:44Z"
        }
      ]
    },
    {
      "issue_number": 2174,
      "title": "能不能再新建一个钉钉群",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n微信群过期了，钉钉群满了，能不能新建一个群聊，真的很需要，谢谢。\n\n### Documentation Links\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "GoranTan",
      "author_type": "User",
      "created_at": "2024-12-03T13:28:42Z",
      "updated_at": "2024-12-04T03:05:49Z",
      "closed_at": "2024-12-04T03:05:49Z",
      "labels": [
        "documentation",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 1,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2174/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2174",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2174",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:21.760113",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "take a minute.",
          "created_at": "2024-12-03T13:36:50Z"
        }
      ]
    },
    {
      "issue_number": 1686,
      "title": "[Feature][ChatKnowledge] ChatKnowledge reference redirect",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar feature requirement.\n\n\n### Description\n\n该功能实用性非常强，在企业实际使用场景成千上万的数据源是很常见的情况，这时若能在对话中直接跳转到问题匹配到源文件则可以很大程度提高系统的实用性。\r\n![image](https://github.com/eosphoros-ai/DB-GPT/assets/60245376/7da369df-d43a-4e04-98dd-7bc8b7c8e8ff)\r\n\n\n### Use case\n\n在对话中点击RAG检索到文件名跳转到源文件中或打开源文件\n\n### Related issues\n\n_No response_\n\n### Feature Priority\n\nHigh\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "zhushen12580",
      "author_type": "User",
      "created_at": "2024-07-02T08:50:41Z",
      "updated_at": "2024-12-03T21:05:08Z",
      "closed_at": null,
      "labels": [
        "enhancement",
        "Waiting for reply",
        "stale"
      ],
      "label_count": 3,
      "has_labels": true,
      "comments_count": 4,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1686/reactions",
        "total_count": 2,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 1,
        "eyes": 1
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/1686",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/1686",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:22.087571",
      "comments": [
        {
          "author": "miluli-web",
          "body": "**建议二次开发业务场景**",
          "created_at": "2024-07-03T01:48:07Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-08-04T21:04:39Z"
        },
        {
          "author": "zhushen12580",
          "body": "这个功能超级实用，建议开发团队先做这个，也算聊天功能能真正实用起来。",
          "created_at": "2024-08-05T01:28:22Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-12-03T21:05:06Z"
        }
      ]
    },
    {
      "issue_number": 2019,
      "title": "[Bug] connect vector store failed: Query execution failed: {code: CypherException}",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nLinux\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [X] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [ ] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [X] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nGPU GTX 3060\n\n### Models information\n\nQwen-72B\n\n### What happened\n\n2024-09-14 14:44:14 2024-09-14 06:44:14 7ba7ee03bbb8 dbgpt.app.knowledge.api[1] INFO Received params: 知识图谱测试, doc_ids=[1] model_name=None pre_separator=None separators=None chunk_size=None chunk_overlap=None\r\n2024-09-14 14:44:15 /usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in BuiltinKnowledgeGraphConfig has conflict with protected namespace \"model_\".\r\n2024-09-14 14:44:15 \r\n2024-09-14 14:44:15 You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\r\n2024-09-14 14:44:15   warnings.warn(\r\n2024-09-14 14:44:15 /usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in CommunitySummaryKnowledgeGraphConfig has conflict with protected namespace \"model_\".\r\n2024-09-14 14:44:15 \r\n2024-09-14 14:44:15 You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\r\n2024-09-14 14:44:15   warnings.warn(\r\n2024-09-14 14:44:15 2024-09-14 06:44:15 7ba7ee03bbb8 dbgpt.serve.rag.connector[1] INFO VectorStore:<class 'dbgpt.storage.knowledge_graph.community_summary.CommunitySummaryKnowledgeGraph'>\r\n2024-09-14 14:44:15 2024-09-14 06:44:15 7ba7ee03bbb8 dbgpt.storage.graph_store.factory[1] ERROR create graph store failed: Query execution failed: {code: CypherException} {message: CypherException: visit(...) failed at src/cypher/arithmetic/ast_expr_evaluator.cpp:480}\r\n2024-09-14 14:44:15 2024-09-14 06:44:15 7ba7ee03bbb8 dbgpt.serve.rag.connector[1] ERROR connect vector store failed: Query execution failed: {code: CypherException} {message: CypherException: visit(...) failed at src/cypher/arithmetic/ast_expr_evaluator.cpp:480}\n\n### What you expected to happen\n\n正常创建知识库，并正常同步\n\n### How to reproduce\n\n在创建知识库的时候，没有create知识库，就进行了连接导致出错。\r\nTuGraph 正常启动\r\n以下是.env配置：\r\n\r\n#*******************************************************************#\r\n#**            VECTOR STORE / KNOWLEDGE GRAPH SETTINGS            **#\r\n#*******************************************************************#\r\nVECTOR_STORE_TYPE=Chroma\r\nGRAPH_STORE_TYPE=TuGraph\r\nGRAPH_COMMUNITY_SUMMARY_ENABLED=True\r\nKNOWLEDGE_GRAPH_EXTRACT_SEARCH_TOP_SIZE=5\r\nKNOWLEDGE_GRAPH_EXTRACT_SEARCH_RECALL_SCORE=0.3\r\nKNOWLEDGE_GRAPH_COMMUNITY_SEARCH_TOP_SIZE=20\r\nKNOWLEDGE_GRAPH_COMMUNITY_SEARCH_RECALL_SCORE=0.0\r\n\r\n### Chroma vector db config\r\nCHROMA_PERSIST_PATH=/root/DB-GPT/pilot/data\r\n\r\n### TuGraph config\r\nTUGRAPH_HOST=192.168.1.102\r\nTUGRAPH_PORT=7687\r\nTUGRAPH_USERNAME=admin\r\nTUGRAPH_PASSWORD=73@TuGraph\r\nTUGRAPH_VERTEX_TYPE=entity\r\nTUGRAPH_EDGE_TYPE=relation\r\nTUGRAPH_PLUGIN_NAMES=leiden\r\n\r\n#开启图社区总结能力\r\nGRAPH_COMMUNITY_SUMMARY_ENABLED=True\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [X] Yes I am willing to submit a PR!",
      "state": "open",
      "author": "AppleJunJiang",
      "author_type": "User",
      "created_at": "2024-09-14T07:05:03Z",
      "updated_at": "2024-12-03T13:15:16Z",
      "closed_at": null,
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 7,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2019/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2019",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2019",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:22.353316",
      "comments": [
        {
          "author": "AppleJunJiang",
          "body": "我发现代码在call createLabel的时候出现错误！\r\n创建标签的时候，数据类型缺少引号\r\n正确的：\r\nCALL db.createLabel('vertex', 'new_label', 'id', ['id','int32',false], ['name','string', true]);\r\n错误的：\r\nCALL db.createLabel('vertex', 'new_label', 'id', ['id',int32,false], ['name',string, true]);",
          "created_at": "2024-09-14T10:46:32Z"
        },
        {
          "author": "Zhaohaoran1997",
          "body": "试了下确实是这样，把参数里的类型用引号引起来就能跑通了",
          "created_at": "2024-09-20T03:58:03Z"
        },
        {
          "author": "maco6096",
          "body": "通过Web UI 添加知识库也存在同样的问题，应该是bug",
          "created_at": "2024-09-26T03:01:02Z"
        },
        {
          "author": "BrucePayton",
          "body": "没错，确实是这样，修改路径：dbgpt\\storage\\graph_store\\tugraph_store.py\r\n修改如下：\r\n![image](https://github.com/user-attachments/assets/041be661-8470-4086-96e0-ac64cba1643b)\r\n",
          "created_at": "2024-10-01T17:51:08Z"
        },
        {
          "author": "abxis",
          "body": "![微信图片_20241011135720](https://github.com/user-attachments/assets/09dceeea-1fa1-46ee-a03f-9ebb1e09fa60)\r\n![微信图片_20241011135851](https://github.com/user-attachments/assets/d8da0240-3b4b-4c4c-9e7c-93745fa99d51)\r\n这个怎么解决呢？\r\n",
          "created_at": "2024-10-11T05:59:24Z"
        }
      ]
    },
    {
      "issue_number": 506,
      "title": "[BUG]: UnicodeEncodeError: 'ascii' codec can't encode characters in position提示字符编码错误",
      "body": "![image](https://github.com/eosphoros-ai/DB-GPT/assets/95067212/ee907d97-811a-4dc0-b530-6103f6422324)\r\n这个报错项目运行一周左右会自动出现，但是复现不出来，不清楚是哪里错误，求指点",
      "state": "closed",
      "author": "taige666",
      "author_type": "User",
      "created_at": "2023-08-31T03:35:08Z",
      "updated_at": "2024-12-02T21:05:10Z",
      "closed_at": "2024-12-02T21:05:09Z",
      "labels": [
        "stale"
      ],
      "label_count": 1,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/506/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/506",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/506",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:22.629001",
      "comments": [
        {
          "author": "fangyinc",
          "body": "@taige666  辛苦拉一下最新的代码再试试。",
          "created_at": "2023-08-31T15:06:42Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue has been marked as `stale`, because it has been over 30 days without any activity.",
          "created_at": "2024-09-03T21:04:58Z"
        },
        {
          "author": "github-actions[bot]",
          "body": "This issue bas been closed, because it has been marked as `stale` and there has been no activity for over 7 days.",
          "created_at": "2024-12-02T21:05:09Z"
        }
      ]
    },
    {
      "issue_number": 2166,
      "title": "[Bug] [AWEL flow] `VectorStoreConnector` can not be attached to `EmbeddingAssemblerOperator`",
      "body": "### Search before asking\n\n- [X] I had searched in the [issues](https://github.com/eosphoros-ai/DB-GPT/issues?q=is%3Aissue) and found no similar issues.\n\n\n### Operating system information\n\nMacOS(M1, M2...)\n\n### Python version information\n\n>=3.11\n\n### DB-GPT version\n\nmain\n\n### Related scenes\n\n- [ ] Chat Data\n- [ ] Chat Excel\n- [ ] Chat DB\n- [ ] Chat Knowledge\n- [ ] Model Management\n- [ ] Dashboard\n- [ ] Plugins\n\n### Installation Information\n\n- [X] [Installation From Source](https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html)\n\n- [ ] [Docker Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Docker Compose Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/docker/docker.html)\n\n- [ ] [Cluster Installation](https://db-gpt.readthedocs.io/en/latest/getting_started/install/llm/cluster/model_cluster.html)\n\n- [ ] AutoDL Image\n- [ ] Other\n\n### Device information\n\nCPU\n\n### Models information\n\nLLM: tongyi_proxyllm\r\nEmbedding Model: text2vec-large-chinese\n\n### What happened\n\nAfter changing the parameters of `EmbeddingAssemblerOperator` from `VectorStoreConnector` to `IndexStoreBase`, it seems that the following connection cannot be established in the workflow:\r\n<img width=\"627\" alt=\"image\" src=\"https://github.com/user-attachments/assets/cecb979b-7205-42d9-bb40-3f5eb7bfbd94\">\r\n\n\n### What you expected to happen\n\nThe connection should be established as follows:\r\n<img width=\"920\" alt=\"image\" src=\"https://github.com/user-attachments/assets/70ab4546-4a02-4852-93d7-8c7b3835ce46\">\r\n\n\n### How to reproduce\n\n1. AWEL flow UI\r\n2. drag `EmbeddingAssemblerOperator` component into canvas\r\n3. drag `VectorStoreConnector` component into canvas\n\n### Additional context\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!",
      "state": "closed",
      "author": "GITHUBear",
      "author_type": "User",
      "created_at": "2024-11-28T13:11:52Z",
      "updated_at": "2024-12-02T12:56:24Z",
      "closed_at": "2024-12-02T12:56:24Z",
      "labels": [
        "bug",
        "Waiting for reply"
      ],
      "label_count": 2,
      "has_labels": true,
      "comments_count": 3,
      "reactions": {
        "url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2166/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
      },
      "assignees": [
        "Aries-ckt"
      ],
      "milestone": null,
      "html_url": "https://github.com/eosphoros-ai/DB-GPT/issues/2166",
      "api_url": "https://api.github.com/repos/eosphoros-ai/DB-GPT/issues/2166",
      "repository": "eosphoros-ai/DB-GPT",
      "extraction_date": "2025-06-21T23:40:22.903945",
      "comments": [
        {
          "author": "Aries-ckt",
          "body": "sorry about that, we will fix that soon.",
          "created_at": "2024-11-28T13:37:52Z"
        },
        {
          "author": "alaap001",
          "body": "Hey, I just got started with AWEL flow, can you help me guide through some resources to learn this? I am going through documentation but not able to find much details of AWEL flow UI",
          "created_at": "2024-11-30T14:04:00Z"
        },
        {
          "author": "Aries-ckt",
          "body": "> Hey, I just got started with AWEL flow, can you help me guide through some resources to learn this? I am going through documentation but not able to find much details of AWEL flow UI\r\n\r\nSorry, our WEB UI tutorials for AWEL are indeed lacking. I will give you the current AWEL related documents.\r\n\r\n",
          "created_at": "2024-11-30T16:03:24Z"
        }
      ]
    }
  ]
}